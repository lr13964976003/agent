digraph LayerWiseDeployment {
    rankdir=TB;
    bgcolor=white;
    
    // Global dimensions
    // batch_size=1024, seq_len=10000, hidden_size=8192, heads=16, d_k=512, ffn_hidden=32768
    
    // Input node - initial data enters on GPU 0
    subgraph cluster_input {
        label="Input Layer";
        color=black;
        input [label="Input\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", shape=parallelogram, style=filled, fillcolor=lightblue];
    }
    
    // Output node - final result from GPU 15
    subgraph cluster_output {
        label="Output Layer";
        color=black;
        output [label="Output\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", shape=parallelogram, style=filled, fillcolor=lightblue];
    }
    
    // Create all 16 layers following the paper's layer-wise deployment
    // Each layer on a separate GPU (0-15)
    
    // Layer 1 (GPU 0)
    subgraph cluster_layer_1 {
        label="Layer 1 (GPU 0)";
        color=blue;
        ln1_1 [label="Layer Norm 1\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightyellow];
        q_proj_1 [label="Q Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        k_proj_1 [label="K Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        v_proj_1 [label="V Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        scaled_dot_attn_1 [label="Scaled Dot-Product Attention\nQ: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nK: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nV: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightcoral];
        concat_1 [label="Concat & Reshape\nInput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightcyan];
        o_proj_1 [label="O Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightgreen];
        residual1_1 [label="Residual Add 1\nInput 1: [batch_size=1024, seq_len=10000, hidden_size=8192]\nInput 2: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightpink, shape=ellipse];
        ln2_1 [label="Layer Norm 2\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightyellow];
        mlp_up_1 [label="MLP Up Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]", style=filled, fillcolor=lightgreen];
        gelu_1 [label="GELU Activation\nInput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]\nOutput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]", style=filled, fillcolor=lightorange];
        mlp_down_1 [label="MLP Down Projection\nInput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightgreen];
        residual2_1 [label="Residual Add 2\nInput 1: [batch_size=1024, seq_len=10000, hidden_size=8192]\nInput 2: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightpink, shape=ellipse];
    }
    
    // Layer 2 (GPU 1)
    subgraph cluster_layer_2 {
        label="Layer 2 (GPU 1)";
        color=blue;
        ln1_2 [label="Layer Norm 1\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightyellow];
        q_proj_2 [label="Q Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        k_proj_2 [label="K Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        v_proj_2 [label="V Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        scaled_dot_attn_2 [label="Scaled Dot-Product Attention\nQ: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nK: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nV: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightcoral];
        concat_2 [label="Concat & Reshape\nInput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightcyan];
        o_proj_2 [label="O Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightgreen];
        residual1_2 [label="Residual Add 1\nInput 1: [batch_size=1024, seq_len=10000, hidden_size=8192]\nInput 2: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightpink, shape=ellipse];
        ln2_2 [label="Layer Norm 2\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightyellow];
        mlp_up_2 [label="MLP Up Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]", style=filled, fillcolor=lightgreen];
        gelu_2 [label="GELU Activation\nInput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]\nOutput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]", style=filled, fillcolor=lightorange];
        mlp_down_2 [label="MLP Down Projection\nInput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightgreen];
        residual2_2 [label="Residual Add 2\nInput 1: [batch_size=1024, seq_len=10000, hidden_size=8192]\nInput 2: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightpink, shape=ellipse];
    }
    
    // Add remaining 14 layers with identical structure
    // Layer 3 (GPU 2)
    subgraph cluster_layer_3 {
        label="Layer 3 (GPU 2)";
        color=blue;
        ln1_3 [label="Layer Norm 1\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightyellow];
        q_proj_3 [label="Q Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        k_proj_3 [label="K Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        v_proj_3 [label="V Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        scaled_dot_attn_3 [label="Scaled Dot-Product Attention\nQ: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nK: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nV: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightcoral];
        concat_3 [label="Concat & Reshape\nInput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightcyan];
        o_proj_3 [label="O Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightgreen];
        residual1_3 [label="Residual Add 1\nInput 1: [batch_size=1024, seq_len=10000, hidden_size=8192]\nInput 2: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightpink, shape=ellipse];
        ln2_3 [label="Layer Norm 2\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightyellow];
        mlp_up_3 [label="MLP Up Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]", style=filled, fillcolor=lightgreen];
        gelu_3 [label="GELU Activation\nInput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]\nOutput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]", style=filled, fillcolor=lightorange];
        mlp_down_3 [label="MLP Down Projection\nInput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightgreen];
        residual2_3 [label="Residual Add 2\nInput 1: [batch_size=1024, seq_len=10000, hidden_size=8192]\nInput 2: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightpink, shape=ellipse];
    }
    
    // Continue pattern for layers 4-16
    // Using abbreviated structure for remaining layers
    // Layer 4 (GPU 3)
    subgraph cluster_layer_4 {
        label="Layer 4 (GPU 3)";
        color=blue;
        ln1_4 [label="Layer Norm 1\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightyellow];
        q_proj_4 [label="Q Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        k_proj_4 [label="K Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        v_proj_4 [label="V Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        scaled_dot_attn_4 [label="Scaled Dot-Product Attention\nQ: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nK: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nV: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightcoral];
        concat_4 [label="Concat & Reshape\nInput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightcyan];
        o_proj_4 [label="O Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightgreen];
        residual1_4 [label="Residual Add 1\nInput 1: [batch_size=1024, seq_len=10000, hidden_size=8192]\nInput 2: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightpink, shape=ellipse];
        ln2_4 [label="Layer Norm 2\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightyellow];
        mlp_up_4 [label="MLP Up Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]", style=filled, fillcolor=lightgreen];
        gelu_4 [label="GELU Activation\nInput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]\nOutput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]", style=filled, fillcolor=lightorange];
        mlp_down_4 [label="MLP Down Projection\nInput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightgreen];
        residual2_4 [label="Residual Add 2\nInput 1: [batch_size=1024, seq_len=10000, hidden_size=8192]\nInput 2: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightpink, shape=ellipse];
    }
    
    // Add remaining layers 5-16 with concise representation
    // Layers 5-16 follow identical pattern, each on GPU 4-15 respectively
    // Using automated generation for brevity
    
    // Add communication nodes between GPUs
    comm_1_2 [label="GPU-to-GPU Transfer\nGPU 0 → GPU 1\n[batch_size=1024, seq_len=10000, hidden_size=8192]", shape=parallelogram, style="filled,dashed", fillcolor=lightgray];
    comm_2_3 [label="GPU-to-GPU Transfer\nGPU 1 → GPU 2\n[batch_size=1024, seq_len=10000, hidden_size=8192]", shape=parallelogram, style="filled,dashed", fillcolor=lightgray];
    comm_3_4 [label="GPU-to-GPU Transfer\nGPU 2 → GPU 3\n[batch_size=1024, seq_len=10000, hidden_size=8192]", shape=parallelogram, style="filled,dashed", fillcolor=lightgray];
    comm_4_5 [label="GPU-to-GPU Transfer\nGPU 3 → GPU 4\n[batch_size=1024, seq_len=10000, hidden_size=8192]", shape=parallelogram, style="filled,dashed", fillcolor=lightgray];
    comm_5_6 [label="GPU-to-GPU Transfer\nGPU 4 → GPU 5\n[batch_size=1024, seq_len=10000, hidden_size=8192]", shape=parallelogram, style="filled,dashed", fillcolor=lightgray];
    comm_6_7 [label="GPU-to-GPU Transfer\nGPU 5 → GPU 6\n[batch_size=1024, seq_len=10000, hidden_size=8192]", shape=parallelogram, style="filled,dashed", fillcolor=lightgray];
    comm_7_8 [label="GPU-to-GPU Transfer\nGPU 6 → GPU 7\n[batch_size=1024, seq_len=10000, hidden_size=8192]", shape=parallelogram, style="filled,dashed", fillcolor=lightgray];
    comm_8_9 [label="GPU-to-GPU Transfer\nGPU 7 → GPU 8\n[batch_size=1024, seq_len=10000, hidden_size=8192]", shape=parallelogram, style="filled,dashed", fillcolor=lightgray];
    comm_9_10 [label="GPU-to-GPU Transfer\nGPU 8 → GPU 9\n[batch_size=1024, seq_len=10000, hidden_size=8192]", shape=parallelogram, style="filled,dashed", fillcolor=lightgray];
    comm_10_11 [label="GPU-to-GPU Transfer\nGPU 9 → GPU 10\n[batch_size=1024, seq_len=10000, hidden_size=8192]", shape=parallelogram, style="filled,dashed", fillcolor=lightgray];
    comm_11_12 [label="GPU-to-GPU Transfer\nGPU 10 → GPU 11\n[batch_size=1024, seq_len=10000, hidden_size=8192]", shape=parallelogram, style="filled,dashed", fillcolor=lightgray];
    comm_12_13 [label="GPU-to-GPU Transfer\nGPU 11 → GPU 12\n[batch_size=1024, seq_len=10000, hidden_size=8192]", shape=parallelogram, style="filled,dashed", fillcolor=lightgray];
    comm_13_14 [label="GPU-to-GPU Transfer\nGPU 12 → GPU 13\n[batch_size=1024, seq_len=10000, hidden_size=8192]", shape=parallelogram, style="filled,dashed", fillcolor=lightgray];
    comm_14_15 [label="GPU-to-GPU Transfer\nGPU 13 → GPU 14\n[batch_size=1024, seq_len=10000, hidden_size=8192]", shape=parallelogram, style="filled,dashed", fillcolor=lightgray];
    comm_15_16 [label="GPU-to-GPU Transfer\nGPU 14 → GPU 15\n[batch_size=1024, seq_len=10000, hidden_size=8192]", shape=parallelogram, style="filled,dashed", fillcolor=lightgray];
    
    // Continue with concise representation for layers 5-16
    // Layers 5-16 follow identical structure, each on GPU 4-15 respectively
    // Layer 5 (GPU 4)
    subgraph cluster_layer_5 {
        label="Layer 5 (GPU 4)";
        color=blue;
        ln1_5 [label="Layer Norm 1\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightyellow];
        q_proj_5 [label="Q Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        k_proj_5 [label="K Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        v_proj_5 [label="V Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        scaled_dot_attn_5 [label="Scaled Dot-Product Attention\nQ: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nK: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nV: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightcoral];
        concat_5 [label="Concat & Reshape\nInput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightcyan];
        o_proj_5 [label="O Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightgreen];
        residual1_5 [label="Residual Add 1\nInput 1: [batch_size=1024, seq_len=10000, hidden_size=8192]\nInput 2: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightpink, shape=ellipse];
        ln2_5 [label="Layer Norm 2\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightyellow];
        mlp_up_5 [label="MLP Up Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]", style=filled, fillcolor=lightgreen];
        gelu_5 [label="GELU Activation\nInput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]\nOutput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]", style=filled, fillcolor=lightorange];
        mlp_down_5 [label="MLP Down Projection\nInput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightgreen];
        residual2_5 [label="Residual Add 2\nInput 1: [batch_size=1024, seq_len=10000, hidden_size=8192]\nInput 2: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightpink, shape=ellipse];
    }
    
    // Continue with remaining layers 6-16 in compact form
    // Due to space, using abbreviated representation for layers 6-16
    // Each follows identical pattern: Layer Norm → MHA → Residual → Layer Norm → MLP → Residual
    
    // Layer 6 (GPU 5)
    subgraph cluster_layer_6 {
        label="Layer 6 (GPU 5)";
        color=blue;
        ln1_6 [label="Layer Norm 1\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightyellow];
        q_proj_6 [label="Q Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        k_proj_6 [label="K Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        v_proj_6 [label="V Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        scaled_dot_attn_6 [label="Scaled Dot-Product Attention\nQ: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nK: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nV: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightcoral];
        concat_6 [label="Concat & Reshape\nInput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightcyan];
        o_proj_6 [label="O Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightgreen];
        residual1_6 [label="Residual Add 1\nInput 1: [batch_size=1024, seq_len=10000, hidden_size=8192]\nInput 2: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightpink, shape=ellipse];
        ln2_6 [label="Layer Norm 2\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightyellow];
        mlp_up_6 [label="MLP Up Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]", style=filled, fillcolor=lightgreen];
        gelu_6 [label="GELU Activation\nInput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]\nOutput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]", style=filled, fillcolor=lightorange];
        mlp_down_6 [label="MLP Down Projection\nInput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightgreen];
        residual2_6 [label="Residual Add 2\nInput 1: [batch_size=1024, seq_len=10000, hidden_size=8192]\nInput 2: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightpink, shape=ellipse];
    }
    
    // Layer 7 (GPU 6)
    subgraph cluster_layer_7 {
        label="Layer 7 (GPU 6)";
        color=blue;
        ln1_7 [label="Layer Norm 1\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightyellow];
        q_proj_7 [label="Q Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        k_proj_7 [label="K Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        v_proj_7 [label="V Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        scaled_dot_attn_7 [label="Scaled Dot-Product Attention\nQ: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nK: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nV: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightcoral];
        concat_7 [label="Concat & Reshape\nInput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightcyan];
        o_proj_7 [label="O Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightgreen];
        residual1_7 [label="Residual Add 1\nInput 1: [batch_size=1024, seq_len=10000, hidden_size=8192]\nInput 2: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightpink, shape=ellipse];
        ln2_7 [label="Layer Norm 2\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightyellow];
        mlp_up_7 [label="MLP Up Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]", style=filled, fillcolor=lightgreen];
        gelu_7 [label="GELU Activation\nInput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]\nOutput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]", style=filled, fillcolor=lightorange];
        mlp_down_7 [label="MLP Down Projection\nInput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightgreen];
        residual2_7 [label="Residual Add 2\nInput 1: [batch_size=1024, seq_len=10000, hidden_size=8192]\nInput 2: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightpink, shape=ellipse];
    }
    
    // Continue with layers 8-16 using efficient representation
    // Layer 8 (GPU 7)
    subgraph cluster_layer_8 {
        label="Layer 8 (GPU 7)";
        color=blue;
        ln1_8 [label="Layer Norm 1\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightyellow];
        q_proj_8 [label="Q Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        k_proj_8 [label="K Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        v_proj_8 [label="V Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        scaled_dot_attn_8 [label="Scaled Dot-Product Attention\nQ: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nK: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nV: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightcoral];
        concat_8 [label="Concat & Reshape\nInput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightcyan];
        o_proj_8 [label="O Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightgreen];
        residual1_8 [label="Residual Add 1\nInput 1: [batch_size=1024, seq_len=10000, hidden_size=8192]\nInput 2: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightpink, shape=ellipse];
        ln2_8 [label="Layer Norm 2\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightyellow];
        mlp_up_8 [label="MLP Up Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]", style=filled, fillcolor=lightgreen];
        gelu_8 [label="GELU Activation\nInput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]\nOutput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]", style=filled, fillcolor=lightorange];
        mlp_down_8 [label="MLP Down Projection\nInput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightgreen];
        residual2_8 [label="Residual Add 2\nInput 1: [batch_size=1024, seq_len=10000, hidden_size=8192]\nInput 2: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightpink, shape=ellipse];
    }
    
    // Layer 9 (GPU 8)
    subgraph cluster_layer_9 {
        label="Layer 9 (GPU 8)";
        color=blue;
        ln1_9 [label="Layer Norm 1\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightyellow];
        q_proj_9 [label="Q Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        k_proj_9 [label="K Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        v_proj_9 [label="V Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        scaled_dot_attn_9 [label="Scaled Dot-Product Attention\nQ: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nK: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nV: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightcoral];
        concat_9 [label="Concat & Reshape\nInput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightcyan];
        o_proj_9 [label="O Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightgreen];
        residual1_9 [label="Residual Add 1\nInput 1: [batch_size=1024, seq_len=10000, hidden_size=8192]\nInput 2: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightpink, shape=ellipse];
        ln2_9 [label="Layer Norm 2\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightyellow];
        mlp_up_9 [label="MLP Up Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]", style=filled, fillcolor=lightgreen];
        gelu_9 [label="GELU Activation\nInput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]\nOutput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]", style=filled, fillcolor=lightorange];
        mlp_down_9 [label="MLP Down Projection\nInput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightgreen];
        residual2_9 [label="Residual Add 2\nInput 1: [batch_size=1024, seq_len=10000, hidden_size=8192]\nInput 2: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightpink, shape=ellipse];
    }
    
    // Layer 10 (GPU 9)
    subgraph cluster_layer_10 {
        label="Layer 10 (GPU 9)";
        color=blue;
        ln1_10 [label="Layer Norm 1\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightyellow];
        q_proj_10 [label="Q Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        k_proj_10 [label="K Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        v_proj_10 [label="V Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        scaled_dot_attn_10 [label="Scaled Dot-Product Attention\nQ: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nK: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nV: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightcoral];
        concat_10 [label="Concat & Reshape\nInput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightcyan];
        o_proj_10 [label="O Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightgreen];
        residual1_10 [label="Residual Add 1\nInput 1: [batch_size=1024, seq_len=10000, hidden_size=8192]\nInput 2: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightpink, shape=ellipse];
        ln2_10 [label="Layer Norm 2\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightyellow];
        mlp_up_10 [label="MLP Up Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]", style=filled, fillcolor=lightgreen];
        gelu_10 [label="GELU Activation\nInput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]\nOutput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]", style=filled, fillcolor=lightorange];
        mlp_down_10 [label="MLP Down Projection\nInput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightgreen];
        residual2_10 [label="Residual Add 2\nInput 1: [batch_size=1024, seq_len=10000, hidden_size=8192]\nInput 2: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightpink, shape=ellipse];
    }
    
    // Layer 11 (GPU 10)
    subgraph cluster_layer_11 {
        label="Layer 11 (GPU 10)";
        color=blue;
        ln1_11 [label="Layer Norm 1\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightyellow];
        q_proj_11 [label="Q Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        k_proj_11 [label="K Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        v_proj_11 [label="V Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        scaled_dot_attn_11 [label="Scaled Dot-Product Attention\nQ: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nK: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nV: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightcoral];
        concat_11 [label="Concat & Reshape\nInput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightcyan];
        o_proj_11 [label="O Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightgreen];
        residual1_11 [label="Residual Add 1\nInput 1: [batch_size=1024, seq_len=10000, hidden_size=8192]\nInput 2: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightpink, shape=ellipse];
        ln2_11 [label="Layer Norm 2\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightyellow];
        mlp_up_11 [label="MLP Up Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]", style=filled, fillcolor=lightgreen];
        gelu_11 [label="GELU Activation\nInput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]\nOutput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]", style=filled, fillcolor=lightorange];
        mlp_down_11 [label="MLP Down Projection\nInput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightgreen];
        residual2_11 [label="Residual Add 2\nInput 1: [batch_size=1024, seq_len=10000, hidden_size=8192]\nInput 2: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightpink, shape=ellipse];
    }
    
    // Layer 12 (GPU 11)
    subgraph cluster_layer_12 {
        label="Layer 12 (GPU 11)";
        color=blue;
        ln1_12 [label="Layer Norm 1\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightyellow];
        q_proj_12 [label="Q Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        k_proj_12 [label="K Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        v_proj_12 [label="V Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        scaled_dot_attn_12 [label="Scaled Dot-Product Attention\nQ: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nK: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nV: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightcoral];
        concat_12 [label="Concat & Reshape\nInput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightcyan];
        o_proj_12 [label="O Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightgreen];
        residual1_12 [label="Residual Add 1\nInput 1: [batch_size=1024, seq_len=10000, hidden_size=8192]\nInput 2: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightpink, shape=ellipse];
        ln2_12 [label="Layer Norm 2\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightyellow];
        mlp_up_12 [label="MLP Up Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]", style=filled, fillcolor=lightgreen];
        gelu_12 [label="GELU Activation\nInput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]\nOutput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]", style=filled, fillcolor=lightorange];
        mlp_down_12 [label="MLP Down Projection\nInput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightgreen];
        residual2_12 [label="Residual Add 2\nInput 1: [batch_size=1024, seq_len=10000, hidden_size=8192]\nInput 2: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightpink, shape=ellipse];
    }
    
    // Layer 13 (GPU 12)
    subgraph cluster_layer_13 {
        label="Layer 13 (GPU 12)";
        color=blue;
        ln1_13 [label="Layer Norm 1\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightyellow];
        q_proj_13 [label="Q Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        k_proj_13 [label="K Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        v_proj_13 [label="V Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        scaled_dot_attn_13 [label="Scaled Dot-Product Attention\nQ: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nK: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nV: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightcoral];
        concat_13 [label="Concat & Reshape\nInput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightcyan];
        o_proj_13 [label="O Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightgreen];
        residual1_13 [label="Residual Add 1\nInput 1: [batch_size=1024, seq_len=10000, hidden_size=8192]\nInput 2: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightpink, shape=ellipse];
        ln2_13 [label="Layer Norm 2\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightyellow];
        mlp_up_13 [label="MLP Up Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]", style=filled, fillcolor=lightgreen];
        gelu_13 [label="GELU Activation\nInput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]\nOutput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]", style=filled, fillcolor=lightorange];
        mlp_down_13 [label="MLP Down Projection\nInput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightgreen];
        residual2_13 [label="Residual Add 2\nInput 1: [batch_size=1024, seq_len=10000, hidden_size=8192]\nInput 2: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightpink, shape=ellipse];
    }
    
    // Layer 14 (GPU 13)
    subgraph cluster_layer_14 {
        label="Layer 14 (GPU 13)";
        color=blue;
        ln1_14 [label="Layer Norm 1\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightyellow];
        q_proj_14 [label="Q Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        k_proj_14 [label="K Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        v_proj_14 [label="V Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightgreen];
        scaled_dot_attn_14 [label="Scaled Dot-Product Attention\nQ: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nK: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nV: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]", style=filled, fillcolor=lightcoral];
        concat_14 [label="Concat & Reshape\nInput: [batch_size=1024, seq_len=10000, heads=16, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightcyan];
        o_proj_14 [label="O Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightgreen];
        residual1_14 [label="Residual Add 1\nInput 1: [batch_size=1024, seq_len=10000, hidden_size=8192]\nInput 2: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightpink, shape=ellipse];
        ln2_14 [label="Layer Norm 2\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, hidden_size=8192]", style=filled, fillcolor=lightyellow];
        mlp_up_14 [label="MLP Up Projection\nInput: [batch_size=1024, seq_len=10000, hidden_size=8192]\nOutput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]", style=filled, fillcolor=lightgreen];
        gelu_14 [label="GELU Activation\nInput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]\nOutput: [batch_size=1024, seq_len=10000, ffn_hidden=32768]", style=filled, fillcolor=lightorange];
        mlp_down_14 [label="MLP Down Projection\nInput: [batch_size=1024, seq_len=10000, f