// MoE Parallel Strategy Deployment DAG - Simplified
digraph {
	rankdir=TB size="15,20"
	node [fontname=Arial fontsize=10]
	edge [fontname=Arial fontsize=8]
	input [label="Input\n[B=128, S=var, D=512]" fillcolor=lightblue shape=ellipse]
	subgraph cluster_gpus {
		fillcolor=lightgray label="16 GPUs (EP=16)" style="rounded,filled"
		subgraph cluster_gpu_0 {
			fillcolor=white label="GPU 0" style="rounded,filled"
			gpu0_start [label="GPU 0 Input\n[B=8, S=var, D=512]" fillcolor=lightyellow shape=parallelogram]
			gpu0_layer0 [label="Layer 0\nAttention+Expert\nTP=4 internal\n[B=8→8, S=var, D=512→512]" fillcolor=lightgreen shape=rectangle]
			gpu0_layer15 [label="Layer 15\nAttention+Expert\nTP=4 internal\n[B=8→8, S=var, D=512→512]" fillcolor=lightgreen shape=rectangle]
			gpu0_end [label="GPU 0 Output\n[B=8, S=var, D=512]" fillcolor=lightyellow shape=parallelogram]
			gpu0_start -> gpu0_layer0
			gpu0_layer0 -> gpu0_layer15 [label="14 more layers" style=dashed]
			gpu0_layer15 -> gpu0_end
		}
		subgraph cluster_gpu_1 {
			fillcolor=white label="GPU 1" style="rounded,filled"
			gpu1_start [label="GPU 1 Input\n[B=8, S=var, D=512]" fillcolor=lightyellow shape=parallelogram]
			gpu1_layer0 [label="Layer 0\nAttention+Expert\nTP=4 internal\n[B=8→8, S=var, D=512→512]" fillcolor=lightgreen shape=rectangle]
			gpu1_layer15 [label="Layer 15\nAttention+Expert\nTP=4 internal\n[B=8→8, S=var, D=512→512]" fillcolor=lightgreen shape=rectangle]
			gpu1_end [label="GPU 1 Output\n[B=8, S=var, D=512]" fillcolor=lightyellow shape=parallelogram]
			gpu1_start -> gpu1_layer0
			gpu1_layer0 -> gpu1_layer15 [label="14 more layers" style=dashed]
			gpu1_layer15 -> gpu1_end
		}
		subgraph cluster_gpu_2 {
			fillcolor=white label="GPU 2" style="rounded,filled"
			gpu2_start [label="GPU 2 Input\n[B=8, S=var, D=512]" fillcolor=lightyellow shape=parallelogram]
			gpu2_layer0 [label="Layer 0\nAttention+Expert\nTP=4 internal\n[B=8→8, S=var, D=512→512]" fillcolor=lightgreen shape=rectangle]
			gpu2_layer15 [label="Layer 15\nAttention+Expert\nTP=4 internal\n[B=8→8, S=var, D=512→512]" fillcolor=lightgreen shape=rectangle]
			gpu2_end [label="GPU 2 Output\n[B=8, S=var, D=512]" fillcolor=lightyellow shape=parallelogram]
			gpu2_start -> gpu2_layer0
			gpu2_layer0 -> gpu2_layer15 [label="14 more layers" style=dashed]
			gpu2_layer15 -> gpu2_end
		}
		subgraph cluster_gpu_3 {
			fillcolor=white label="GPU 3" style="rounded,filled"
			gpu3_start [label="GPU 3 Input\n[B=8, S=var, D=512]" fillcolor=lightyellow shape=parallelogram]
			gpu3_layer0 [label="Layer 0\nAttention+Expert\nTP=4 internal\n[B=8→8, S=var, D=512→512]" fillcolor=lightgreen shape=rectangle]
			gpu3_layer15 [label="Layer 15\nAttention+Expert\nTP=4 internal\n[B=8→8, S=var, D=512→512]" fillcolor=lightgreen shape=rectangle]
			gpu3_end [label="GPU 3 Output\n[B=8, S=var, D=512]" fillcolor=lightyellow shape=parallelogram]
			gpu3_start -> gpu3_layer0
			gpu3_layer0 -> gpu3_layer15 [label="14 more layers" style=dashed]
			gpu3_layer15 -> gpu3_end
		}
		subgraph cluster_gpu_4 {
			fillcolor=white label="GPU 4" style="rounded,filled"
			gpu4_start [label="GPU 4 Input\n[B=8, S=var, D=512]" fillcolor=lightyellow shape=parallelogram]
			gpu4_layer0 [label="Layer 0\nAttention+Expert\nTP=4 internal\n[B=8→8, S=var, D=512→512]" fillcolor=lightgreen shape=rectangle]
			gpu4_layer15 [label="Layer 15\nAttention+Expert\nTP=4 internal\n[B=8→8, S=var, D=512→512]" fillcolor=lightgreen shape=rectangle]
			gpu4_end [label="GPU 4 Output\n[B=8, S=var, D=512]" fillcolor=lightyellow shape=parallelogram]
			gpu4_start -> gpu4_layer0
			gpu4_layer0 -> gpu4_layer15 [label="14 more layers" style=dashed]
			gpu4_layer15 -> gpu4_end
		}
		subgraph cluster_gpu_5 {
			fillcolor=white label="GPU 5" style="rounded,filled"
			gpu5_start [label="GPU 5 Input\n[B=8, S=var, D=512]" fillcolor=lightyellow shape=parallelogram]
			gpu5_layer0 [label="Layer 0\nAttention+Expert\nTP=4 internal\n[B=8→8, S=var, D=512→512]" fillcolor=lightgreen shape=rectangle]
			gpu5_layer15 [label="Layer 15\nAttention+Expert\nTP=4 internal\n[B=8→8, S=var, D=512→512]" fillcolor=lightgreen shape=rectangle]
			gpu5_end [label="GPU 5 Output\n[B=8, S=var, D=512]" fillcolor=lightyellow shape=parallelogram]
			gpu5_start -> gpu5_layer0
			gpu5_layer0 -> gpu5_layer15 [label="14 more layers" style=dashed]
			gpu5_layer15 -> gpu5_end
		}
		subgraph cluster_gpu_6 {
			fillcolor=white label="GPU 6" style="rounded,filled"
			gpu6_start [label="GPU 6 Input\n[B=8, S=var, D=512]" fillcolor=lightyellow shape=parallelogram]
			gpu6_layer0 [label="Layer 0\nAttention+Expert\nTP=4 internal\n[B=8→8, S=var, D=512→512]" fillcolor=lightgreen shape=rectangle]
			gpu6_layer15 [label="Layer 15\nAttention+Expert\nTP=4 internal\n[B=8→8, S=var, D=512→512]" fillcolor=lightgreen shape=rectangle]
			gpu6_end [label="GPU 6 Output\n[B=8, S=var, D=512]" fillcolor=lightyellow shape=parallelogram]
			gpu6_start -> gpu6_layer0
			gpu6_layer0 -> gpu6_layer15 [label="14 more layers" style=dashed]
			gpu6_layer15 -> gpu6_end
		}
		subgraph cluster_gpu_7 {
			fillcolor=white label="GPU 7" style="rounded,filled"
			gpu7_start [label="GPU 7 Input\n[B=8, S=var, D=512]" fillcolor=lightyellow shape=parallelogram]
			gpu7_layer0 [label="Layer 0\nAttention+Expert\nTP=4 internal\n[B=8→8, S=var, D=512→512]" fillcolor=lightgreen shape=rectangle]
			gpu7_layer15 [label="Layer 15\nAttention+Expert\nTP=4 internal\n[B=8→8, S=var, D=512→512]" fillcolor=lightgreen shape=rectangle]
			gpu7_end [label="GPU 7 Output\n[B=8, S=var, D=512]" fillcolor=lightyellow shape=parallelogram]
			gpu7_start -> gpu7_layer0
			gpu7_layer0 -> gpu7_layer15 [label="14 more layers" style=dashed]
			gpu7_layer15 -> gpu7_end
		}
		subgraph cluster_gpu_8 {
			fillcolor=white label="GPU 8" style="rounded,filled"
			gpu8_start [label="GPU 8 Input\n[B=8, S=var, D=512]" fillcolor=lightyellow shape=parallelogram]
			gpu8_layer0 [label="Layer 0\nAttention+Expert\nTP=4 internal\n[B=8→8, S=var, D=512→512]" fillcolor=lightgreen shape=rectangle]
			gpu8_layer15 [label="Layer 15\nAttention+Expert\nTP=4 internal\n[B=8→8, S=var, D=512→512]" fillcolor=lightgreen shape=rectangle]
			gpu8_end [label="GPU 8 Output\n[B=8, S=var, D=512]" fillcolor=lightyellow shape=parallelogram]
			gpu8_start -> gpu8_layer0
			gpu8_layer0 -> gpu8_layer15 [label="14 more layers" style=dashed]
			gpu8_layer15 -> gpu8_end
		}
		subgraph cluster_gpu_9 {
			fillcolor=white label="GPU 9" style="rounded,filled"
			gpu9_start [label="GPU 9 Input\n[B=8, S=var, D=512]" fillcolor=lightyellow shape=parallelogram]
			gpu9_layer0 [label="Layer 0\nAttention+Expert\nTP=4 internal\n[B=8→8, S=var, D=512→512]" fillcolor=lightgreen shape=rectangle]
			gpu9_layer15 [label="Layer 15\nAttention+Expert\nTP=4 internal\n[B=8→8, S=var, D=512→512]" fillcolor=lightgreen shape=rectangle]
			gpu9_end [label="GPU 9 Output\n[B=8, S=var, D=512]" fillcolor=lightyellow shape=parallelogram]
			gpu9_start -> gpu9_layer0
			gpu9_layer0 -> gpu9_layer15 [label="14 more layers" style=dashed]
			gpu9_layer15 -> gpu9_end
		}
		subgraph cluster_gpu_10 {
			fillcolor=white label="GPU 10" style="rounded,filled"
			gpu10_start [label="GPU 10 Input\n[B=8, S=var, D=512]" fillcolor=lightyellow shape=parallelogram]
			gpu10_layer0 [label="Layer 0\nAttention+Expert\nTP=4 internal\n[B=8→8, S=var, D=512→512]" fillcolor=lightgreen shape=rectangle]
			gpu10_layer15 [label="Layer 15\nAttention+Expert\nTP=4 internal\n[B=8→8, S=var, D=512→512]" fillcolor=lightgreen shape=rectangle]
			gpu10_end [label="GPU 10 Output\n[B=8, S=var, D=512]" fillcolor=lightyellow shape=parallelogram]
			gpu10_start -> gpu10_layer0
			gpu10_layer0 -> gpu10_layer15 [label="14 more layers" style=dashed]
			gpu10_layer15 -> gpu10_end
		}
		subgraph cluster_gpu_11 {
			fillcolor=white label="GPU 11" style="rounded,filled"
			gpu11_start [label="GPU 11 Input\n[B=8, S=var, D=512]" fillcolor=lightyellow shape=parallelogram]
			gpu11_layer0 [label="Layer 0\nAttention+Expert\nTP=4 internal\n[B=8→8, S=var, D=512→512]" fillcolor=lightgreen shape=rectangle]
			gpu11_layer15 [label="Layer 15\nAttention+Expert\nTP=4 internal\n[B=8→8, S=var, D=512→512]" fillcolor=lightgreen shape=rectangle]
			gpu11_end [label="GPU 11 Output\n[B=8, S=var, D=512]" fillcolor=lightyellow shape=parallelogram]
			gpu11_start -> gpu11_layer0
			gpu11_layer0 -> gpu11_layer15 [label="14 more layers" style=dashed]
			gpu11_layer15 -> gpu11_end
		}
		subgraph cluster_gpu_12 {
			fillcolor=white label="GPU 12" style="rounded,filled"
			gpu12_start [label="GPU 12 Input\n[B=8, S=var, D=512]" fillcolor=lightyellow shape=parallelogram]
			gpu12_layer0 [label="Layer 0\nAttention+Expert\nTP=4 internal\n[B=8→8, S=var, D=512→512]" fillcolor=lightgreen shape=rectangle]
			gpu12_layer15 [label="Layer 15\nAttention+Expert\nTP=4 internal\n[B=8→8, S=var, D=512→512]" fillcolor=lightgreen shape=rectangle]
			gpu12_end [label="GPU 12 Output\n[B=8, S=var, D=512]" fillcolor=lightyellow shape=parallelogram]
			gpu12_start -> gpu12_layer0
			gpu12_layer0 -> gpu12_layer15 [label="14 more layers" style=dashed]
			gpu12_layer15 -> gpu12_end
		}
		subgraph cluster_gpu_13 {
			fillcolor=white label="GPU 13" style="rounded,filled"
			gpu13_start [label="GPU 13 Input\n[B=8, S=var, D=512]" fillcolor=lightyellow shape=parallelogram]
			gpu13_layer0 [label="Layer 0\nAttention+Expert\nTP=4 internal\n[B=8→8, S=var, D=512→512]" fillcolor=lightgreen shape=rectangle]
			gpu13_layer15 [label="Layer 15\nAttention+Expert\nTP=4 internal\n[B=8→8, S=var, D=512→512]" fillcolor=lightgreen shape=rectangle]
			gpu13_end [label="GPU 13 Output\n[B=8, S=var, D=512]" fillcolor=lightyellow shape=parallelogram]
			gpu13_start -> gpu13_layer0
			gpu13_layer0 -> gpu13_layer15 [label="14 more layers" style=dashed]
			gpu13_layer15 -> gpu13_end
		}
		subgraph cluster_gpu_14 {
			fillcolor=white label="GPU 14" style="rounded,filled"
			gpu14_start [label="GPU 14 Input\n[B=8, S=var, D=512]" fillcolor=lightyellow shape=parallelogram]
			gpu14_layer0 [label="Layer 0\nAttention+Expert\nTP=4 internal\n[B=8→8, S=var, D=512→512]" fillcolor=lightgreen shape=rectangle]
			gpu14_layer15 [label="Layer 15\nAttention+Expert\nTP=4 internal\n[B=8→8, S=var, D=512→512]" fillcolor=lightgreen shape=rectangle]
			gpu14_end [label="GPU 14 Output\n[B=8, S=var, D=512]" fillcolor=lightyellow shape=parallelogram]
			gpu14_start -> gpu14_layer0
			gpu14_layer0 -> gpu14_layer15 [label="14 more layers" style=dashed]
			gpu14_layer15 -> gpu14_end
		}
		subgraph cluster_gpu_15 {
			fillcolor=white label="GPU 15" style="rounded,filled"
			gpu15_start [label="GPU 15 Input\n[B=8, S=var, D=512]" fillcolor=lightyellow shape=parallelogram]
			gpu15_layer0 [label="Layer 0\nAttention+Expert\nTP=4 internal\n[B=8→8, S=var, D=512→512]" fillcolor=lightgreen shape=rectangle]
			gpu15_layer15 [label="Layer 15\nAttention+Expert\nTP=4 internal\n[B=8→8, S=var, D=512→512]" fillcolor=lightgreen shape=rectangle]
			gpu15_end [label="GPU 15 Output\n[B=8, S=var, D=512]" fillcolor=lightyellow shape=parallelogram]
			gpu15_start -> gpu15_layer0
			gpu15_layer0 -> gpu15_layer15 [label="14 more layers" style=dashed]
			gpu15_layer15 -> gpu15_end
		}
	}
	output [label="Final Output\n[B=128, S=var, D=512]" fillcolor=lightblue shape=ellipse]
	input -> gpu0_start
	gpu0_end -> output
	input -> gpu1_start
	gpu1_end -> output
	input -> gpu2_start
	gpu2_end -> output
	input -> gpu3_start
	gpu3_end -> output
	input -> gpu4_start
	gpu4_end -> output
	input -> gpu5_start
	gpu5_end -> output
	input -> gpu6_start
	gpu6_end -> output
	input -> gpu7_start
	gpu7_end -> output
	input -> gpu8_start
	gpu8_end -> output
	input -> gpu9_start
	gpu9_end -> output
	input -> gpu10_start
	gpu10_end -> output
	input -> gpu11_start
	gpu11_end -> output
	input -> gpu12_start
	gpu12_end -> output
	input -> gpu13_start
	gpu13_end -> output
	input -> gpu14_start
	gpu14_end -> output
	input -> gpu15_start
	gpu15_end -> output
	edge [color=red constraint=false style=dashed]
	gpu0_layer0 -> gpu0_layer0 [label="Expert 0 routing\n(within GPU)"]
	gpu1_layer0 -> gpu1_layer0 [label="Expert 1 routing\n(within GPU)"]
	gpu2_layer0 -> gpu2_layer0 [label="Expert 2 routing\n(within GPU)"]
	gpu3_layer0 -> gpu3_layer0 [label="Expert 3 routing\n(within GPU)"]
	gpu4_layer0 -> gpu4_layer0 [label="Expert 4 routing\n(within GPU)"]
	gpu5_layer0 -> gpu5_layer0 [label="Expert 5 routing\n(within GPU)"]
	gpu6_layer0 -> gpu6_layer0 [label="Expert 6 routing\n(within GPU)"]
	gpu7_layer0 -> gpu7_layer0 [label="Expert 7 routing\n(within GPU)"]
	gpu8_layer0 -> gpu8_layer0 [label="Expert 8 routing\n(within GPU)"]
	gpu9_layer0 -> gpu9_layer0 [label="Expert 9 routing\n(within GPU)"]
	gpu10_layer0 -> gpu10_layer0 [label="Expert 10 routing\n(within GPU)"]
	gpu11_layer0 -> gpu11_layer0 [label="Expert 11 routing\n(within GPU)"]
	gpu12_layer0 -> gpu12_layer0 [label="Expert 12 routing\n(within GPU)"]
	gpu13_layer0 -> gpu13_layer0 [label="Expert 13 routing\n(within GPU)"]
	gpu14_layer0 -> gpu14_layer0 [label="Expert 14 routing\n(within GPU)"]
	gpu15_layer0 -> gpu15_layer0 [label="Expert 15 routing\n(within GPU)"]
}
