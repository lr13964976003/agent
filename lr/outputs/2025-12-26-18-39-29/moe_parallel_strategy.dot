// MoE Parallel Strategy DAG - Complete
digraph {
	dpi=300 rankdir=TB size="30,30"
	node [fontsize=9 margin=0.03]
	input [label="Input
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style=filled]
	subgraph cluster_stage_0 {
		fillcolor=lightgray label="Pipeline Stage 0 (Layers 0-1)" style="rounded,filled"
		q_proj_0 [label="Q Projection L0
GPU: 0-31
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		k_proj_0 [label="K Projection L0
GPU: 0-31
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		v_proj_0 [label="V Projection L0
GPU: 0-31
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_scores_0 [label="Attention Scores L0
GPU: 0-31
Input: Q,K,V [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		softmax_0 [label="Softmax L0
GPU: 0-31
Input: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]
Output: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_out_0 [label="Attention Output L0
GPU: 0-31
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_0 [label="Gate L0
GPU: 0-63
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_0_0 [label="Route to Expert 0
GPU: 0,1
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_0_0 [label="Expert 0 TP-0 L0
GPU: 0
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_0_1 [label="Expert 0 TP-1 L0
GPU: 1
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_0 [label="TP All-Reduce Expert 0 L0
GPU: 0↔1
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_1 [label="Route to Expert 1
GPU: 2,3
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_1_0 [label="Expert 1 TP-0 L0
GPU: 2
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_1_1 [label="Expert 1 TP-1 L0
GPU: 3
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_1 [label="TP All-Reduce Expert 1 L0
GPU: 2↔3
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_2 [label="Route to Expert 2
GPU: 4,5
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_2_0 [label="Expert 2 TP-0 L0
GPU: 4
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_2_1 [label="Expert 2 TP-1 L0
GPU: 5
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_2 [label="TP All-Reduce Expert 2 L0
GPU: 4↔5
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_3 [label="Route to Expert 3
GPU: 6,7
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_3_0 [label="Expert 3 TP-0 L0
GPU: 6
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_3_1 [label="Expert 3 TP-1 L0
GPU: 7
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_3 [label="TP All-Reduce Expert 3 L0
GPU: 6↔7
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_4 [label="Route to Expert 4
GPU: 8,9
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_4_0 [label="Expert 4 TP-0 L0
GPU: 8
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_4_1 [label="Expert 4 TP-1 L0
GPU: 9
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_4 [label="TP All-Reduce Expert 4 L0
GPU: 8↔9
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_5 [label="Route to Expert 5
GPU: 10,11
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_5_0 [label="Expert 5 TP-0 L0
GPU: 10
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_5_1 [label="Expert 5 TP-1 L0
GPU: 11
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_5 [label="TP All-Reduce Expert 5 L0
GPU: 10↔11
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_6 [label="Route to Expert 6
GPU: 12,13
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_6_0 [label="Expert 6 TP-0 L0
GPU: 12
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_6_1 [label="Expert 6 TP-1 L0
GPU: 13
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_6 [label="TP All-Reduce Expert 6 L0
GPU: 12↔13
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_7 [label="Route to Expert 7
GPU: 14,15
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_7_0 [label="Expert 7 TP-0 L0
GPU: 14
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_7_1 [label="Expert 7 TP-1 L0
GPU: 15
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_7 [label="TP All-Reduce Expert 7 L0
GPU: 14↔15
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_8 [label="Route to Expert 8
GPU: 32,33
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_8_0 [label="Expert 8 TP-0 L0
GPU: 32
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_8_1 [label="Expert 8 TP-1 L0
GPU: 33
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_8 [label="TP All-Reduce Expert 8 L0
GPU: 32↔33
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_9 [label="Route to Expert 9
GPU: 34,35
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_9_0 [label="Expert 9 TP-0 L0
GPU: 34
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_9_1 [label="Expert 9 TP-1 L0
GPU: 35
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_9 [label="TP All-Reduce Expert 9 L0
GPU: 34↔35
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_10 [label="Route to Expert 10
GPU: 36,37
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_10_0 [label="Expert 10 TP-0 L0
GPU: 36
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_10_1 [label="Expert 10 TP-1 L0
GPU: 37
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_10 [label="TP All-Reduce Expert 10 L0
GPU: 36↔37
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_11 [label="Route to Expert 11
GPU: 38,39
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_11_0 [label="Expert 11 TP-0 L0
GPU: 38
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_11_1 [label="Expert 11 TP-1 L0
GPU: 39
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_11 [label="TP All-Reduce Expert 11 L0
GPU: 38↔39
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_12 [label="Route to Expert 12
GPU: 40,41
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_12_0 [label="Expert 12 TP-0 L0
GPU: 40
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_12_1 [label="Expert 12 TP-1 L0
GPU: 41
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_12 [label="TP All-Reduce Expert 12 L0
GPU: 40↔41
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_13 [label="Route to Expert 13
GPU: 42,43
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_13_0 [label="Expert 13 TP-0 L0
GPU: 42
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_13_1 [label="Expert 13 TP-1 L0
GPU: 43
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_13 [label="TP All-Reduce Expert 13 L0
GPU: 42↔43
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_14 [label="Route to Expert 14
GPU: 44,45
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_14_0 [label="Expert 14 TP-0 L0
GPU: 44
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_14_1 [label="Expert 14 TP-1 L0
GPU: 45
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_14 [label="TP All-Reduce Expert 14 L0
GPU: 44↔45
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_15 [label="Route to Expert 15
GPU: 46,47
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_15_0 [label="Expert 15 TP-0 L0
GPU: 46
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_15_1 [label="Expert 15 TP-1 L0
GPU: 47
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_15 [label="TP All-Reduce Expert 15 L0
GPU: 46↔47
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		q_proj_1 [label="Q Projection L1
GPU: 0-31
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		k_proj_1 [label="K Projection L1
GPU: 0-31
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		v_proj_1 [label="V Projection L1
GPU: 0-31
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_scores_1 [label="Attention Scores L1
GPU: 0-31
Input: Q,K,V [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		softmax_1 [label="Softmax L1
GPU: 0-31
Input: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]
Output: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_out_1 [label="Attention Output L1
GPU: 0-31
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_1 [label="Gate L1
GPU: 0-63
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_1_0 [label="Route to Expert 0
GPU: 0,1
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_0_0 [label="Expert 0 TP-0 L1
GPU: 0
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_0_1 [label="Expert 0 TP-1 L1
GPU: 1
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_0 [label="TP All-Reduce Expert 0 L1
GPU: 0↔1
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_1 [label="Route to Expert 1
GPU: 2,3
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_1_0 [label="Expert 1 TP-0 L1
GPU: 2
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_1_1 [label="Expert 1 TP-1 L1
GPU: 3
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_1 [label="TP All-Reduce Expert 1 L1
GPU: 2↔3
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_2 [label="Route to Expert 2
GPU: 4,5
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_2_0 [label="Expert 2 TP-0 L1
GPU: 4
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_2_1 [label="Expert 2 TP-1 L1
GPU: 5
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_2 [label="TP All-Reduce Expert 2 L1
GPU: 4↔5
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_3 [label="Route to Expert 3
GPU: 6,7
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_3_0 [label="Expert 3 TP-0 L1
GPU: 6
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_3_1 [label="Expert 3 TP-1 L1
GPU: 7
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_3 [label="TP All-Reduce Expert 3 L1
GPU: 6↔7
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_4 [label="Route to Expert 4
GPU: 8,9
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_4_0 [label="Expert 4 TP-0 L1
GPU: 8
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_4_1 [label="Expert 4 TP-1 L1
GPU: 9
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_4 [label="TP All-Reduce Expert 4 L1
GPU: 8↔9
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_5 [label="Route to Expert 5
GPU: 10,11
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_5_0 [label="Expert 5 TP-0 L1
GPU: 10
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_5_1 [label="Expert 5 TP-1 L1
GPU: 11
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_5 [label="TP All-Reduce Expert 5 L1
GPU: 10↔11
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_6 [label="Route to Expert 6
GPU: 12,13
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_6_0 [label="Expert 6 TP-0 L1
GPU: 12
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_6_1 [label="Expert 6 TP-1 L1
GPU: 13
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_6 [label="TP All-Reduce Expert 6 L1
GPU: 12↔13
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_7 [label="Route to Expert 7
GPU: 14,15
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_7_0 [label="Expert 7 TP-0 L1
GPU: 14
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_7_1 [label="Expert 7 TP-1 L1
GPU: 15
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_7 [label="TP All-Reduce Expert 7 L1
GPU: 14↔15
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_8 [label="Route to Expert 8
GPU: 32,33
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_8_0 [label="Expert 8 TP-0 L1
GPU: 32
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_8_1 [label="Expert 8 TP-1 L1
GPU: 33
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_8 [label="TP All-Reduce Expert 8 L1
GPU: 32↔33
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_9 [label="Route to Expert 9
GPU: 34,35
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_9_0 [label="Expert 9 TP-0 L1
GPU: 34
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_9_1 [label="Expert 9 TP-1 L1
GPU: 35
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_9 [label="TP All-Reduce Expert 9 L1
GPU: 34↔35
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_10 [label="Route to Expert 10
GPU: 36,37
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_10_0 [label="Expert 10 TP-0 L1
GPU: 36
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_10_1 [label="Expert 10 TP-1 L1
GPU: 37
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_10 [label="TP All-Reduce Expert 10 L1
GPU: 36↔37
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_11 [label="Route to Expert 11
GPU: 38,39
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_11_0 [label="Expert 11 TP-0 L1
GPU: 38
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_11_1 [label="Expert 11 TP-1 L1
GPU: 39
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_11 [label="TP All-Reduce Expert 11 L1
GPU: 38↔39
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_12 [label="Route to Expert 12
GPU: 40,41
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_12_0 [label="Expert 12 TP-0 L1
GPU: 40
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_12_1 [label="Expert 12 TP-1 L1
GPU: 41
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_12 [label="TP All-Reduce Expert 12 L1
GPU: 40↔41
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_13 [label="Route to Expert 13
GPU: 42,43
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_13_0 [label="Expert 13 TP-0 L1
GPU: 42
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_13_1 [label="Expert 13 TP-1 L1
GPU: 43
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_13 [label="TP All-Reduce Expert 13 L1
GPU: 42↔43
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_14 [label="Route to Expert 14
GPU: 44,45
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_14_0 [label="Expert 14 TP-0 L1
GPU: 44
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_14_1 [label="Expert 14 TP-1 L1
GPU: 45
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_14 [label="TP All-Reduce Expert 14 L1
GPU: 44↔45
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_15 [label="Route to Expert 15
GPU: 46,47
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_15_0 [label="Expert 15 TP-0 L1
GPU: 46
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_15_1 [label="Expert 15 TP-1 L1
GPU: 47
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_15 [label="TP All-Reduce Expert 15 L1
GPU: 46↔47
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
	}
	subgraph cluster_stage_1 {
		fillcolor=lightgray label="Pipeline Stage 1 (Layers 2-3)" style="rounded,filled"
		q_proj_2 [label="Q Projection L2
GPU: 64-95
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		k_proj_2 [label="K Projection L2
GPU: 64-95
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		v_proj_2 [label="V Projection L2
GPU: 64-95
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_scores_2 [label="Attention Scores L2
GPU: 64-95
Input: Q,K,V [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		softmax_2 [label="Softmax L2
GPU: 64-95
Input: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]
Output: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_out_2 [label="Attention Output L2
GPU: 64-95
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_2 [label="Gate L2
GPU: 64-127
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_2_0 [label="Route to Expert 0
GPU: 64,65
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_0_0 [label="Expert 0 TP-0 L2
GPU: 64
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_0_1 [label="Expert 0 TP-1 L2
GPU: 65
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_0 [label="TP All-Reduce Expert 0 L2
GPU: 64↔65
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_1 [label="Route to Expert 1
GPU: 66,67
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_1_0 [label="Expert 1 TP-0 L2
GPU: 66
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_1_1 [label="Expert 1 TP-1 L2
GPU: 67
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_1 [label="TP All-Reduce Expert 1 L2
GPU: 66↔67
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_2 [label="Route to Expert 2
GPU: 68,69
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_2_0 [label="Expert 2 TP-0 L2
GPU: 68
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_2_1 [label="Expert 2 TP-1 L2
GPU: 69
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_2 [label="TP All-Reduce Expert 2 L2
GPU: 68↔69
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_3 [label="Route to Expert 3
GPU: 70,71
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_3_0 [label="Expert 3 TP-0 L2
GPU: 70
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_3_1 [label="Expert 3 TP-1 L2
GPU: 71
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_3 [label="TP All-Reduce Expert 3 L2
GPU: 70↔71
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_4 [label="Route to Expert 4
GPU: 72,73
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_4_0 [label="Expert 4 TP-0 L2
GPU: 72
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_4_1 [label="Expert 4 TP-1 L2
GPU: 73
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_4 [label="TP All-Reduce Expert 4 L2
GPU: 72↔73
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_5 [label="Route to Expert 5
GPU: 74,75
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_5_0 [label="Expert 5 TP-0 L2
GPU: 74
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_5_1 [label="Expert 5 TP-1 L2
GPU: 75
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_5 [label="TP All-Reduce Expert 5 L2
GPU: 74↔75
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_6 [label="Route to Expert 6
GPU: 76,77
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_6_0 [label="Expert 6 TP-0 L2
GPU: 76
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_6_1 [label="Expert 6 TP-1 L2
GPU: 77
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_6 [label="TP All-Reduce Expert 6 L2
GPU: 76↔77
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_7 [label="Route to Expert 7
GPU: 78,79
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_7_0 [label="Expert 7 TP-0 L2
GPU: 78
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_7_1 [label="Expert 7 TP-1 L2
GPU: 79
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_7 [label="TP All-Reduce Expert 7 L2
GPU: 78↔79
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_8 [label="Route to Expert 8
GPU: 96,97
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_8_0 [label="Expert 8 TP-0 L2
GPU: 96
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_8_1 [label="Expert 8 TP-1 L2
GPU: 97
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_8 [label="TP All-Reduce Expert 8 L2
GPU: 96↔97
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_9 [label="Route to Expert 9
GPU: 98,99
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_9_0 [label="Expert 9 TP-0 L2
GPU: 98
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_9_1 [label="Expert 9 TP-1 L2
GPU: 99
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_9 [label="TP All-Reduce Expert 9 L2
GPU: 98↔99
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_10 [label="Route to Expert 10
GPU: 100,101
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_10_0 [label="Expert 10 TP-0 L2
GPU: 100
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_10_1 [label="Expert 10 TP-1 L2
GPU: 101
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_10 [label="TP All-Reduce Expert 10 L2
GPU: 100↔101
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_11 [label="Route to Expert 11
GPU: 102,103
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_11_0 [label="Expert 11 TP-0 L2
GPU: 102
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_11_1 [label="Expert 11 TP-1 L2
GPU: 103
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_11 [label="TP All-Reduce Expert 11 L2
GPU: 102↔103
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_12 [label="Route to Expert 12
GPU: 104,105
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_12_0 [label="Expert 12 TP-0 L2
GPU: 104
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_12_1 [label="Expert 12 TP-1 L2
GPU: 105
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_12 [label="TP All-Reduce Expert 12 L2
GPU: 104↔105
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_13 [label="Route to Expert 13
GPU: 106,107
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_13_0 [label="Expert 13 TP-0 L2
GPU: 106
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_13_1 [label="Expert 13 TP-1 L2
GPU: 107
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_13 [label="TP All-Reduce Expert 13 L2
GPU: 106↔107
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_14 [label="Route to Expert 14
GPU: 108,109
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_14_0 [label="Expert 14 TP-0 L2
GPU: 108
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_14_1 [label="Expert 14 TP-1 L2
GPU: 109
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_14 [label="TP All-Reduce Expert 14 L2
GPU: 108↔109
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_15 [label="Route to Expert 15
GPU: 110,111
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_15_0 [label="Expert 15 TP-0 L2
GPU: 110
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_15_1 [label="Expert 15 TP-1 L2
GPU: 111
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_15 [label="TP All-Reduce Expert 15 L2
GPU: 110↔111
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		q_proj_3 [label="Q Projection L3
GPU: 64-95
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		k_proj_3 [label="K Projection L3
GPU: 64-95
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		v_proj_3 [label="V Projection L3
GPU: 64-95
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_scores_3 [label="Attention Scores L3
GPU: 64-95
Input: Q,K,V [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		softmax_3 [label="Softmax L3
GPU: 64-95
Input: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]
Output: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_out_3 [label="Attention Output L3
GPU: 64-95
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_3 [label="Gate L3
GPU: 64-127
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_3_0 [label="Route to Expert 0
GPU: 64,65
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_0_0 [label="Expert 0 TP-0 L3
GPU: 64
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_0_1 [label="Expert 0 TP-1 L3
GPU: 65
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_0 [label="TP All-Reduce Expert 0 L3
GPU: 64↔65
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_1 [label="Route to Expert 1
GPU: 66,67
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_1_0 [label="Expert 1 TP-0 L3
GPU: 66
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_1_1 [label="Expert 1 TP-1 L3
GPU: 67
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_1 [label="TP All-Reduce Expert 1 L3
GPU: 66↔67
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_2 [label="Route to Expert 2
GPU: 68,69
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_2_0 [label="Expert 2 TP-0 L3
GPU: 68
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_2_1 [label="Expert 2 TP-1 L3
GPU: 69
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_2 [label="TP All-Reduce Expert 2 L3
GPU: 68↔69
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_3 [label="Route to Expert 3
GPU: 70,71
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_3_0 [label="Expert 3 TP-0 L3
GPU: 70
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_3_1 [label="Expert 3 TP-1 L3
GPU: 71
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_3 [label="TP All-Reduce Expert 3 L3
GPU: 70↔71
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_4 [label="Route to Expert 4
GPU: 72,73
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_4_0 [label="Expert 4 TP-0 L3
GPU: 72
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_4_1 [label="Expert 4 TP-1 L3
GPU: 73
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_4 [label="TP All-Reduce Expert 4 L3
GPU: 72↔73
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_5 [label="Route to Expert 5
GPU: 74,75
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_5_0 [label="Expert 5 TP-0 L3
GPU: 74
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_5_1 [label="Expert 5 TP-1 L3
GPU: 75
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_5 [label="TP All-Reduce Expert 5 L3
GPU: 74↔75
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_6 [label="Route to Expert 6
GPU: 76,77
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_6_0 [label="Expert 6 TP-0 L3
GPU: 76
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_6_1 [label="Expert 6 TP-1 L3
GPU: 77
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_6 [label="TP All-Reduce Expert 6 L3
GPU: 76↔77
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_7 [label="Route to Expert 7
GPU: 78,79
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_7_0 [label="Expert 7 TP-0 L3
GPU: 78
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_7_1 [label="Expert 7 TP-1 L3
GPU: 79
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_7 [label="TP All-Reduce Expert 7 L3
GPU: 78↔79
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_8 [label="Route to Expert 8
GPU: 96,97
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_8_0 [label="Expert 8 TP-0 L3
GPU: 96
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_8_1 [label="Expert 8 TP-1 L3
GPU: 97
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_8 [label="TP All-Reduce Expert 8 L3
GPU: 96↔97
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_9 [label="Route to Expert 9
GPU: 98,99
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_9_0 [label="Expert 9 TP-0 L3
GPU: 98
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_9_1 [label="Expert 9 TP-1 L3
GPU: 99
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_9 [label="TP All-Reduce Expert 9 L3
GPU: 98↔99
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_10 [label="Route to Expert 10
GPU: 100,101
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_10_0 [label="Expert 10 TP-0 L3
GPU: 100
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_10_1 [label="Expert 10 TP-1 L3
GPU: 101
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_10 [label="TP All-Reduce Expert 10 L3
GPU: 100↔101
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_11 [label="Route to Expert 11
GPU: 102,103
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_11_0 [label="Expert 11 TP-0 L3
GPU: 102
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_11_1 [label="Expert 11 TP-1 L3
GPU: 103
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_11 [label="TP All-Reduce Expert 11 L3
GPU: 102↔103
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_12 [label="Route to Expert 12
GPU: 104,105
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_12_0 [label="Expert 12 TP-0 L3
GPU: 104
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_12_1 [label="Expert 12 TP-1 L3
GPU: 105
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_12 [label="TP All-Reduce Expert 12 L3
GPU: 104↔105
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_13 [label="Route to Expert 13
GPU: 106,107
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_13_0 [label="Expert 13 TP-0 L3
GPU: 106
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_13_1 [label="Expert 13 TP-1 L3
GPU: 107
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_13 [label="TP All-Reduce Expert 13 L3
GPU: 106↔107
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_14 [label="Route to Expert 14
GPU: 108,109
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_14_0 [label="Expert 14 TP-0 L3
GPU: 108
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_14_1 [label="Expert 14 TP-1 L3
GPU: 109
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_14 [label="TP All-Reduce Expert 14 L3
GPU: 108↔109
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_15 [label="Route to Expert 15
GPU: 110,111
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_15_0 [label="Expert 15 TP-0 L3
GPU: 110
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_15_1 [label="Expert 15 TP-1 L3
GPU: 111
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_15 [label="TP All-Reduce Expert 15 L3
GPU: 110↔111
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
	}
	subgraph cluster_stage_2 {
		fillcolor=lightgray label="Pipeline Stage 2 (Layers 4-5)" style="rounded,filled"
		q_proj_4 [label="Q Projection L4
GPU: 128-159
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		k_proj_4 [label="K Projection L4
GPU: 128-159
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		v_proj_4 [label="V Projection L4
GPU: 128-159
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_scores_4 [label="Attention Scores L4
GPU: 128-159
Input: Q,K,V [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		softmax_4 [label="Softmax L4
GPU: 128-159
Input: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]
Output: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_out_4 [label="Attention Output L4
GPU: 128-159
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_4 [label="Gate L4
GPU: 128-191
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_4_0 [label="Route to Expert 0
GPU: 128,129
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_0_0 [label="Expert 0 TP-0 L4
GPU: 128
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_0_1 [label="Expert 0 TP-1 L4
GPU: 129
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_0 [label="TP All-Reduce Expert 0 L4
GPU: 128↔129
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_1 [label="Route to Expert 1
GPU: 130,131
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_1_0 [label="Expert 1 TP-0 L4
GPU: 130
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_1_1 [label="Expert 1 TP-1 L4
GPU: 131
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_1 [label="TP All-Reduce Expert 1 L4
GPU: 130↔131
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_2 [label="Route to Expert 2
GPU: 132,133
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_2_0 [label="Expert 2 TP-0 L4
GPU: 132
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_2_1 [label="Expert 2 TP-1 L4
GPU: 133
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_2 [label="TP All-Reduce Expert 2 L4
GPU: 132↔133
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_3 [label="Route to Expert 3
GPU: 134,135
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_3_0 [label="Expert 3 TP-0 L4
GPU: 134
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_3_1 [label="Expert 3 TP-1 L4
GPU: 135
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_3 [label="TP All-Reduce Expert 3 L4
GPU: 134↔135
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_4 [label="Route to Expert 4
GPU: 136,137
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_4_0 [label="Expert 4 TP-0 L4
GPU: 136
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_4_1 [label="Expert 4 TP-1 L4
GPU: 137
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_4 [label="TP All-Reduce Expert 4 L4
GPU: 136↔137
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_5 [label="Route to Expert 5
GPU: 138,139
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_5_0 [label="Expert 5 TP-0 L4
GPU: 138
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_5_1 [label="Expert 5 TP-1 L4
GPU: 139
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_5 [label="TP All-Reduce Expert 5 L4
GPU: 138↔139
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_6 [label="Route to Expert 6
GPU: 140,141
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_6_0 [label="Expert 6 TP-0 L4
GPU: 140
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_6_1 [label="Expert 6 TP-1 L4
GPU: 141
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_6 [label="TP All-Reduce Expert 6 L4
GPU: 140↔141
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_7 [label="Route to Expert 7
GPU: 142,143
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_7_0 [label="Expert 7 TP-0 L4
GPU: 142
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_7_1 [label="Expert 7 TP-1 L4
GPU: 143
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_7 [label="TP All-Reduce Expert 7 L4
GPU: 142↔143
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_8 [label="Route to Expert 8
GPU: 160,161
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_8_0 [label="Expert 8 TP-0 L4
GPU: 160
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_8_1 [label="Expert 8 TP-1 L4
GPU: 161
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_8 [label="TP All-Reduce Expert 8 L4
GPU: 160↔161
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_9 [label="Route to Expert 9
GPU: 162,163
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_9_0 [label="Expert 9 TP-0 L4
GPU: 162
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_9_1 [label="Expert 9 TP-1 L4
GPU: 163
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_9 [label="TP All-Reduce Expert 9 L4
GPU: 162↔163
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_10 [label="Route to Expert 10
GPU: 164,165
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_10_0 [label="Expert 10 TP-0 L4
GPU: 164
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_10_1 [label="Expert 10 TP-1 L4
GPU: 165
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_10 [label="TP All-Reduce Expert 10 L4
GPU: 164↔165
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_11 [label="Route to Expert 11
GPU: 166,167
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_11_0 [label="Expert 11 TP-0 L4
GPU: 166
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_11_1 [label="Expert 11 TP-1 L4
GPU: 167
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_11 [label="TP All-Reduce Expert 11 L4
GPU: 166↔167
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_12 [label="Route to Expert 12
GPU: 168,169
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_12_0 [label="Expert 12 TP-0 L4
GPU: 168
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_12_1 [label="Expert 12 TP-1 L4
GPU: 169
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_12 [label="TP All-Reduce Expert 12 L4
GPU: 168↔169
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_13 [label="Route to Expert 13
GPU: 170,171
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_13_0 [label="Expert 13 TP-0 L4
GPU: 170
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_13_1 [label="Expert 13 TP-1 L4
GPU: 171
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_13 [label="TP All-Reduce Expert 13 L4
GPU: 170↔171
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_14 [label="Route to Expert 14
GPU: 172,173
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_14_0 [label="Expert 14 TP-0 L4
GPU: 172
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_14_1 [label="Expert 14 TP-1 L4
GPU: 173
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_14 [label="TP All-Reduce Expert 14 L4
GPU: 172↔173
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_15 [label="Route to Expert 15
GPU: 174,175
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_15_0 [label="Expert 15 TP-0 L4
GPU: 174
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_15_1 [label="Expert 15 TP-1 L4
GPU: 175
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_15 [label="TP All-Reduce Expert 15 L4
GPU: 174↔175
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		q_proj_5 [label="Q Projection L5
GPU: 128-159
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		k_proj_5 [label="K Projection L5
GPU: 128-159
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		v_proj_5 [label="V Projection L5
GPU: 128-159
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_scores_5 [label="Attention Scores L5
GPU: 128-159
Input: Q,K,V [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		softmax_5 [label="Softmax L5
GPU: 128-159
Input: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]
Output: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_out_5 [label="Attention Output L5
GPU: 128-159
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_5 [label="Gate L5
GPU: 128-191
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_5_0 [label="Route to Expert 0
GPU: 128,129
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_0_0 [label="Expert 0 TP-0 L5
GPU: 128
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_0_1 [label="Expert 0 TP-1 L5
GPU: 129
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_0 [label="TP All-Reduce Expert 0 L5
GPU: 128↔129
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_1 [label="Route to Expert 1
GPU: 130,131
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_1_0 [label="Expert 1 TP-0 L5
GPU: 130
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_1_1 [label="Expert 1 TP-1 L5
GPU: 131
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_1 [label="TP All-Reduce Expert 1 L5
GPU: 130↔131
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_2 [label="Route to Expert 2
GPU: 132,133
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_2_0 [label="Expert 2 TP-0 L5
GPU: 132
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_2_1 [label="Expert 2 TP-1 L5
GPU: 133
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_2 [label="TP All-Reduce Expert 2 L5
GPU: 132↔133
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_3 [label="Route to Expert 3
GPU: 134,135
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_3_0 [label="Expert 3 TP-0 L5
GPU: 134
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_3_1 [label="Expert 3 TP-1 L5
GPU: 135
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_3 [label="TP All-Reduce Expert 3 L5
GPU: 134↔135
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_4 [label="Route to Expert 4
GPU: 136,137
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_4_0 [label="Expert 4 TP-0 L5
GPU: 136
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_4_1 [label="Expert 4 TP-1 L5
GPU: 137
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_4 [label="TP All-Reduce Expert 4 L5
GPU: 136↔137
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_5 [label="Route to Expert 5
GPU: 138,139
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_5_0 [label="Expert 5 TP-0 L5
GPU: 138
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_5_1 [label="Expert 5 TP-1 L5
GPU: 139
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_5 [label="TP All-Reduce Expert 5 L5
GPU: 138↔139
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_6 [label="Route to Expert 6
GPU: 140,141
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_6_0 [label="Expert 6 TP-0 L5
GPU: 140
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_6_1 [label="Expert 6 TP-1 L5
GPU: 141
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_6 [label="TP All-Reduce Expert 6 L5
GPU: 140↔141
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_7 [label="Route to Expert 7
GPU: 142,143
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_7_0 [label="Expert 7 TP-0 L5
GPU: 142
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_7_1 [label="Expert 7 TP-1 L5
GPU: 143
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_7 [label="TP All-Reduce Expert 7 L5
GPU: 142↔143
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_8 [label="Route to Expert 8
GPU: 160,161
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_8_0 [label="Expert 8 TP-0 L5
GPU: 160
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_8_1 [label="Expert 8 TP-1 L5
GPU: 161
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_8 [label="TP All-Reduce Expert 8 L5
GPU: 160↔161
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_9 [label="Route to Expert 9
GPU: 162,163
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_9_0 [label="Expert 9 TP-0 L5
GPU: 162
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_9_1 [label="Expert 9 TP-1 L5
GPU: 163
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_9 [label="TP All-Reduce Expert 9 L5
GPU: 162↔163
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_10 [label="Route to Expert 10
GPU: 164,165
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_10_0 [label="Expert 10 TP-0 L5
GPU: 164
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_10_1 [label="Expert 10 TP-1 L5
GPU: 165
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_10 [label="TP All-Reduce Expert 10 L5
GPU: 164↔165
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_11 [label="Route to Expert 11
GPU: 166,167
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_11_0 [label="Expert 11 TP-0 L5
GPU: 166
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_11_1 [label="Expert 11 TP-1 L5
GPU: 167
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_11 [label="TP All-Reduce Expert 11 L5
GPU: 166↔167
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_12 [label="Route to Expert 12
GPU: 168,169
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_12_0 [label="Expert 12 TP-0 L5
GPU: 168
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_12_1 [label="Expert 12 TP-1 L5
GPU: 169
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_12 [label="TP All-Reduce Expert 12 L5
GPU: 168↔169
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_13 [label="Route to Expert 13
GPU: 170,171
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_13_0 [label="Expert 13 TP-0 L5
GPU: 170
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_13_1 [label="Expert 13 TP-1 L5
GPU: 171
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_13 [label="TP All-Reduce Expert 13 L5
GPU: 170↔171
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_14 [label="Route to Expert 14
GPU: 172,173
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_14_0 [label="Expert 14 TP-0 L5
GPU: 172
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_14_1 [label="Expert 14 TP-1 L5
GPU: 173
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_14 [label="TP All-Reduce Expert 14 L5
GPU: 172↔173
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_15 [label="Route to Expert 15
GPU: 174,175
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_15_0 [label="Expert 15 TP-0 L5
GPU: 174
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_15_1 [label="Expert 15 TP-1 L5
GPU: 175
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_15 [label="TP All-Reduce Expert 15 L5
GPU: 174↔175
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
	}
	subgraph cluster_stage_3 {
		fillcolor=lightgray label="Pipeline Stage 3 (Layers 6-7)" style="rounded,filled"
		q_proj_6 [label="Q Projection L6
GPU: 192-223
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		k_proj_6 [label="K Projection L6
GPU: 192-223
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		v_proj_6 [label="V Projection L6
GPU: 192-223
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_scores_6 [label="Attention Scores L6
GPU: 192-223
Input: Q,K,V [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		softmax_6 [label="Softmax L6
GPU: 192-223
Input: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]
Output: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_out_6 [label="Attention Output L6
GPU: 192-223
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_6 [label="Gate L6
GPU: 192-255
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_6_0 [label="Route to Expert 0
GPU: 192,193
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_0_0 [label="Expert 0 TP-0 L6
GPU: 192
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_0_1 [label="Expert 0 TP-1 L6
GPU: 193
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_0 [label="TP All-Reduce Expert 0 L6
GPU: 192↔193
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_1 [label="Route to Expert 1
GPU: 194,195
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_1_0 [label="Expert 1 TP-0 L6
GPU: 194
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_1_1 [label="Expert 1 TP-1 L6
GPU: 195
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_1 [label="TP All-Reduce Expert 1 L6
GPU: 194↔195
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_2 [label="Route to Expert 2
GPU: 196,197
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_2_0 [label="Expert 2 TP-0 L6
GPU: 196
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_2_1 [label="Expert 2 TP-1 L6
GPU: 197
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_2 [label="TP All-Reduce Expert 2 L6
GPU: 196↔197
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_3 [label="Route to Expert 3
GPU: 198,199
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_3_0 [label="Expert 3 TP-0 L6
GPU: 198
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_3_1 [label="Expert 3 TP-1 L6
GPU: 199
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_3 [label="TP All-Reduce Expert 3 L6
GPU: 198↔199
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_4 [label="Route to Expert 4
GPU: 200,201
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_4_0 [label="Expert 4 TP-0 L6
GPU: 200
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_4_1 [label="Expert 4 TP-1 L6
GPU: 201
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_4 [label="TP All-Reduce Expert 4 L6
GPU: 200↔201
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_5 [label="Route to Expert 5
GPU: 202,203
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_5_0 [label="Expert 5 TP-0 L6
GPU: 202
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_5_1 [label="Expert 5 TP-1 L6
GPU: 203
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_5 [label="TP All-Reduce Expert 5 L6
GPU: 202↔203
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_6 [label="Route to Expert 6
GPU: 204,205
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_6_0 [label="Expert 6 TP-0 L6
GPU: 204
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_6_1 [label="Expert 6 TP-1 L6
GPU: 205
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_6 [label="TP All-Reduce Expert 6 L6
GPU: 204↔205
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_7 [label="Route to Expert 7
GPU: 206,207
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_7_0 [label="Expert 7 TP-0 L6
GPU: 206
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_7_1 [label="Expert 7 TP-1 L6
GPU: 207
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_7 [label="TP All-Reduce Expert 7 L6
GPU: 206↔207
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_8 [label="Route to Expert 8
GPU: 224,225
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_8_0 [label="Expert 8 TP-0 L6
GPU: 224
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_8_1 [label="Expert 8 TP-1 L6
GPU: 225
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_8 [label="TP All-Reduce Expert 8 L6
GPU: 224↔225
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_9 [label="Route to Expert 9
GPU: 226,227
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_9_0 [label="Expert 9 TP-0 L6
GPU: 226
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_9_1 [label="Expert 9 TP-1 L6
GPU: 227
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_9 [label="TP All-Reduce Expert 9 L6
GPU: 226↔227
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_10 [label="Route to Expert 10
GPU: 228,229
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_10_0 [label="Expert 10 TP-0 L6
GPU: 228
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_10_1 [label="Expert 10 TP-1 L6
GPU: 229
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_10 [label="TP All-Reduce Expert 10 L6
GPU: 228↔229
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_11 [label="Route to Expert 11
GPU: 230,231
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_11_0 [label="Expert 11 TP-0 L6
GPU: 230
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_11_1 [label="Expert 11 TP-1 L6
GPU: 231
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_11 [label="TP All-Reduce Expert 11 L6
GPU: 230↔231
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_12 [label="Route to Expert 12
GPU: 232,233
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_12_0 [label="Expert 12 TP-0 L6
GPU: 232
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_12_1 [label="Expert 12 TP-1 L6
GPU: 233
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_12 [label="TP All-Reduce Expert 12 L6
GPU: 232↔233
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_13 [label="Route to Expert 13
GPU: 234,235
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_13_0 [label="Expert 13 TP-0 L6
GPU: 234
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_13_1 [label="Expert 13 TP-1 L6
GPU: 235
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_13 [label="TP All-Reduce Expert 13 L6
GPU: 234↔235
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_14 [label="Route to Expert 14
GPU: 236,237
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_14_0 [label="Expert 14 TP-0 L6
GPU: 236
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_14_1 [label="Expert 14 TP-1 L6
GPU: 237
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_14 [label="TP All-Reduce Expert 14 L6
GPU: 236↔237
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_15 [label="Route to Expert 15
GPU: 238,239
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_15_0 [label="Expert 15 TP-0 L6
GPU: 238
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_15_1 [label="Expert 15 TP-1 L6
GPU: 239
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_15 [label="TP All-Reduce Expert 15 L6
GPU: 238↔239
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		q_proj_7 [label="Q Projection L7
GPU: 192-223
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		k_proj_7 [label="K Projection L7
GPU: 192-223
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		v_proj_7 [label="V Projection L7
GPU: 192-223
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_scores_7 [label="Attention Scores L7
GPU: 192-223
Input: Q,K,V [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		softmax_7 [label="Softmax L7
GPU: 192-223
Input: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]
Output: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_out_7 [label="Attention Output L7
GPU: 192-223
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_7 [label="Gate L7
GPU: 192-255
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_7_0 [label="Route to Expert 0
GPU: 192,193
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_0_0 [label="Expert 0 TP-0 L7
GPU: 192
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_0_1 [label="Expert 0 TP-1 L7
GPU: 193
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_0 [label="TP All-Reduce Expert 0 L7
GPU: 192↔193
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_1 [label="Route to Expert 1
GPU: 194,195
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_1_0 [label="Expert 1 TP-0 L7
GPU: 194
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_1_1 [label="Expert 1 TP-1 L7
GPU: 195
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_1 [label="TP All-Reduce Expert 1 L7
GPU: 194↔195
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_2 [label="Route to Expert 2
GPU: 196,197
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_2_0 [label="Expert 2 TP-0 L7
GPU: 196
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_2_1 [label="Expert 2 TP-1 L7
GPU: 197
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_2 [label="TP All-Reduce Expert 2 L7
GPU: 196↔197
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_3 [label="Route to Expert 3
GPU: 198,199
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_3_0 [label="Expert 3 TP-0 L7
GPU: 198
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_3_1 [label="Expert 3 TP-1 L7
GPU: 199
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_3 [label="TP All-Reduce Expert 3 L7
GPU: 198↔199
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_4 [label="Route to Expert 4
GPU: 200,201
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_4_0 [label="Expert 4 TP-0 L7
GPU: 200
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_4_1 [label="Expert 4 TP-1 L7
GPU: 201
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_4 [label="TP All-Reduce Expert 4 L7
GPU: 200↔201
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_5 [label="Route to Expert 5
GPU: 202,203
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_5_0 [label="Expert 5 TP-0 L7
GPU: 202
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_5_1 [label="Expert 5 TP-1 L7
GPU: 203
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_5 [label="TP All-Reduce Expert 5 L7
GPU: 202↔203
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_6 [label="Route to Expert 6
GPU: 204,205
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_6_0 [label="Expert 6 TP-0 L7
GPU: 204
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_6_1 [label="Expert 6 TP-1 L7
GPU: 205
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_6 [label="TP All-Reduce Expert 6 L7
GPU: 204↔205
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_7 [label="Route to Expert 7
GPU: 206,207
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_7_0 [label="Expert 7 TP-0 L7
GPU: 206
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_7_1 [label="Expert 7 TP-1 L7
GPU: 207
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_7 [label="TP All-Reduce Expert 7 L7
GPU: 206↔207
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_8 [label="Route to Expert 8
GPU: 224,225
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_8_0 [label="Expert 8 TP-0 L7
GPU: 224
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_8_1 [label="Expert 8 TP-1 L7
GPU: 225
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_8 [label="TP All-Reduce Expert 8 L7
GPU: 224↔225
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_9 [label="Route to Expert 9
GPU: 226,227
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_9_0 [label="Expert 9 TP-0 L7
GPU: 226
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_9_1 [label="Expert 9 TP-1 L7
GPU: 227
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_9 [label="TP All-Reduce Expert 9 L7
GPU: 226↔227
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_10 [label="Route to Expert 10
GPU: 228,229
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_10_0 [label="Expert 10 TP-0 L7
GPU: 228
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_10_1 [label="Expert 10 TP-1 L7
GPU: 229
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_10 [label="TP All-Reduce Expert 10 L7
GPU: 228↔229
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_11 [label="Route to Expert 11
GPU: 230,231
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_11_0 [label="Expert 11 TP-0 L7
GPU: 230
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_11_1 [label="Expert 11 TP-1 L7
GPU: 231
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_11 [label="TP All-Reduce Expert 11 L7
GPU: 230↔231
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_12 [label="Route to Expert 12
GPU: 232,233
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_12_0 [label="Expert 12 TP-0 L7
GPU: 232
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_12_1 [label="Expert 12 TP-1 L7
GPU: 233
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_12 [label="TP All-Reduce Expert 12 L7
GPU: 232↔233
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_13 [label="Route to Expert 13
GPU: 234,235
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_13_0 [label="Expert 13 TP-0 L7
GPU: 234
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_13_1 [label="Expert 13 TP-1 L7
GPU: 235
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_13 [label="TP All-Reduce Expert 13 L7
GPU: 234↔235
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_14 [label="Route to Expert 14
GPU: 236,237
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_14_0 [label="Expert 14 TP-0 L7
GPU: 236
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_14_1 [label="Expert 14 TP-1 L7
GPU: 237
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_14 [label="TP All-Reduce Expert 14 L7
GPU: 236↔237
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_15 [label="Route to Expert 15
GPU: 238,239
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_15_0 [label="Expert 15 TP-0 L7
GPU: 238
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_15_1 [label="Expert 15 TP-1 L7
GPU: 239
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_15 [label="TP All-Reduce Expert 15 L7
GPU: 238↔239
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
	}
	subgraph cluster_stage_4 {
		fillcolor=lightgray label="Pipeline Stage 4 (Layers 8-9)" style="rounded,filled"
		q_proj_8 [label="Q Projection L8
GPU: 256-287
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		k_proj_8 [label="K Projection L8
GPU: 256-287
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		v_proj_8 [label="V Projection L8
GPU: 256-287
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_scores_8 [label="Attention Scores L8
GPU: 256-287
Input: Q,K,V [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		softmax_8 [label="Softmax L8
GPU: 256-287
Input: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]
Output: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_out_8 [label="Attention Output L8
GPU: 256-287
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_8 [label="Gate L8
GPU: 256-319
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_8_0 [label="Route to Expert 0
GPU: 256,257
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_0_0 [label="Expert 0 TP-0 L8
GPU: 256
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_0_1 [label="Expert 0 TP-1 L8
GPU: 257
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_0 [label="TP All-Reduce Expert 0 L8
GPU: 256↔257
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_1 [label="Route to Expert 1
GPU: 258,259
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_1_0 [label="Expert 1 TP-0 L8
GPU: 258
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_1_1 [label="Expert 1 TP-1 L8
GPU: 259
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_1 [label="TP All-Reduce Expert 1 L8
GPU: 258↔259
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_2 [label="Route to Expert 2
GPU: 260,261
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_2_0 [label="Expert 2 TP-0 L8
GPU: 260
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_2_1 [label="Expert 2 TP-1 L8
GPU: 261
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_2 [label="TP All-Reduce Expert 2 L8
GPU: 260↔261
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_3 [label="Route to Expert 3
GPU: 262,263
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_3_0 [label="Expert 3 TP-0 L8
GPU: 262
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_3_1 [label="Expert 3 TP-1 L8
GPU: 263
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_3 [label="TP All-Reduce Expert 3 L8
GPU: 262↔263
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_4 [label="Route to Expert 4
GPU: 264,265
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_4_0 [label="Expert 4 TP-0 L8
GPU: 264
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_4_1 [label="Expert 4 TP-1 L8
GPU: 265
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_4 [label="TP All-Reduce Expert 4 L8
GPU: 264↔265
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_5 [label="Route to Expert 5
GPU: 266,267
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_5_0 [label="Expert 5 TP-0 L8
GPU: 266
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_5_1 [label="Expert 5 TP-1 L8
GPU: 267
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_5 [label="TP All-Reduce Expert 5 L8
GPU: 266↔267
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_6 [label="Route to Expert 6
GPU: 268,269
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_6_0 [label="Expert 6 TP-0 L8
GPU: 268
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_6_1 [label="Expert 6 TP-1 L8
GPU: 269
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_6 [label="TP All-Reduce Expert 6 L8
GPU: 268↔269
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_7 [label="Route to Expert 7
GPU: 270,271
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_7_0 [label="Expert 7 TP-0 L8
GPU: 270
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_7_1 [label="Expert 7 TP-1 L8
GPU: 271
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_7 [label="TP All-Reduce Expert 7 L8
GPU: 270↔271
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_8 [label="Route to Expert 8
GPU: 288,289
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_8_0 [label="Expert 8 TP-0 L8
GPU: 288
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_8_1 [label="Expert 8 TP-1 L8
GPU: 289
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_8 [label="TP All-Reduce Expert 8 L8
GPU: 288↔289
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_9 [label="Route to Expert 9
GPU: 290,291
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_9_0 [label="Expert 9 TP-0 L8
GPU: 290
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_9_1 [label="Expert 9 TP-1 L8
GPU: 291
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_9 [label="TP All-Reduce Expert 9 L8
GPU: 290↔291
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_10 [label="Route to Expert 10
GPU: 292,293
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_10_0 [label="Expert 10 TP-0 L8
GPU: 292
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_10_1 [label="Expert 10 TP-1 L8
GPU: 293
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_10 [label="TP All-Reduce Expert 10 L8
GPU: 292↔293
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_11 [label="Route to Expert 11
GPU: 294,295
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_11_0 [label="Expert 11 TP-0 L8
GPU: 294
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_11_1 [label="Expert 11 TP-1 L8
GPU: 295
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_11 [label="TP All-Reduce Expert 11 L8
GPU: 294↔295
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_12 [label="Route to Expert 12
GPU: 296,297
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_12_0 [label="Expert 12 TP-0 L8
GPU: 296
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_12_1 [label="Expert 12 TP-1 L8
GPU: 297
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_12 [label="TP All-Reduce Expert 12 L8
GPU: 296↔297
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_13 [label="Route to Expert 13
GPU: 298,299
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_13_0 [label="Expert 13 TP-0 L8
GPU: 298
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_13_1 [label="Expert 13 TP-1 L8
GPU: 299
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_13 [label="TP All-Reduce Expert 13 L8
GPU: 298↔299
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_14 [label="Route to Expert 14
GPU: 300,301
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_14_0 [label="Expert 14 TP-0 L8
GPU: 300
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_14_1 [label="Expert 14 TP-1 L8
GPU: 301
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_14 [label="TP All-Reduce Expert 14 L8
GPU: 300↔301
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_15 [label="Route to Expert 15
GPU: 302,303
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_15_0 [label="Expert 15 TP-0 L8
GPU: 302
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_15_1 [label="Expert 15 TP-1 L8
GPU: 303
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_15 [label="TP All-Reduce Expert 15 L8
GPU: 302↔303
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		q_proj_9 [label="Q Projection L9
GPU: 256-287
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		k_proj_9 [label="K Projection L9
GPU: 256-287
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		v_proj_9 [label="V Projection L9
GPU: 256-287
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_scores_9 [label="Attention Scores L9
GPU: 256-287
Input: Q,K,V [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		softmax_9 [label="Softmax L9
GPU: 256-287
Input: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]
Output: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_out_9 [label="Attention Output L9
GPU: 256-287
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_9 [label="Gate L9
GPU: 256-319
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_9_0 [label="Route to Expert 0
GPU: 256,257
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_0_0 [label="Expert 0 TP-0 L9
GPU: 256
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_0_1 [label="Expert 0 TP-1 L9
GPU: 257
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_0 [label="TP All-Reduce Expert 0 L9
GPU: 256↔257
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_1 [label="Route to Expert 1
GPU: 258,259
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_1_0 [label="Expert 1 TP-0 L9
GPU: 258
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_1_1 [label="Expert 1 TP-1 L9
GPU: 259
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_1 [label="TP All-Reduce Expert 1 L9
GPU: 258↔259
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_2 [label="Route to Expert 2
GPU: 260,261
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_2_0 [label="Expert 2 TP-0 L9
GPU: 260
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_2_1 [label="Expert 2 TP-1 L9
GPU: 261
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_2 [label="TP All-Reduce Expert 2 L9
GPU: 260↔261
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_3 [label="Route to Expert 3
GPU: 262,263
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_3_0 [label="Expert 3 TP-0 L9
GPU: 262
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_3_1 [label="Expert 3 TP-1 L9
GPU: 263
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_3 [label="TP All-Reduce Expert 3 L9
GPU: 262↔263
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_4 [label="Route to Expert 4
GPU: 264,265
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_4_0 [label="Expert 4 TP-0 L9
GPU: 264
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_4_1 [label="Expert 4 TP-1 L9
GPU: 265
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_4 [label="TP All-Reduce Expert 4 L9
GPU: 264↔265
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_5 [label="Route to Expert 5
GPU: 266,267
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_5_0 [label="Expert 5 TP-0 L9
GPU: 266
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_5_1 [label="Expert 5 TP-1 L9
GPU: 267
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_5 [label="TP All-Reduce Expert 5 L9
GPU: 266↔267
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_6 [label="Route to Expert 6
GPU: 268,269
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_6_0 [label="Expert 6 TP-0 L9
GPU: 268
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_6_1 [label="Expert 6 TP-1 L9
GPU: 269
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_6 [label="TP All-Reduce Expert 6 L9
GPU: 268↔269
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_7 [label="Route to Expert 7
GPU: 270,271
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_7_0 [label="Expert 7 TP-0 L9
GPU: 270
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_7_1 [label="Expert 7 TP-1 L9
GPU: 271
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_7 [label="TP All-Reduce Expert 7 L9
GPU: 270↔271
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_8 [label="Route to Expert 8
GPU: 288,289
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_8_0 [label="Expert 8 TP-0 L9
GPU: 288
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_8_1 [label="Expert 8 TP-1 L9
GPU: 289
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_8 [label="TP All-Reduce Expert 8 L9
GPU: 288↔289
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_9 [label="Route to Expert 9
GPU: 290,291
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_9_0 [label="Expert 9 TP-0 L9
GPU: 290
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_9_1 [label="Expert 9 TP-1 L9
GPU: 291
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_9 [label="TP All-Reduce Expert 9 L9
GPU: 290↔291
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_10 [label="Route to Expert 10
GPU: 292,293
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_10_0 [label="Expert 10 TP-0 L9
GPU: 292
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_10_1 [label="Expert 10 TP-1 L9
GPU: 293
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_10 [label="TP All-Reduce Expert 10 L9
GPU: 292↔293
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_11 [label="Route to Expert 11
GPU: 294,295
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_11_0 [label="Expert 11 TP-0 L9
GPU: 294
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_11_1 [label="Expert 11 TP-1 L9
GPU: 295
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_11 [label="TP All-Reduce Expert 11 L9
GPU: 294↔295
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_12 [label="Route to Expert 12
GPU: 296,297
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_12_0 [label="Expert 12 TP-0 L9
GPU: 296
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_12_1 [label="Expert 12 TP-1 L9
GPU: 297
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_12 [label="TP All-Reduce Expert 12 L9
GPU: 296↔297
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_13 [label="Route to Expert 13
GPU: 298,299
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_13_0 [label="Expert 13 TP-0 L9
GPU: 298
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_13_1 [label="Expert 13 TP-1 L9
GPU: 299
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_13 [label="TP All-Reduce Expert 13 L9
GPU: 298↔299
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_14 [label="Route to Expert 14
GPU: 300,301
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_14_0 [label="Expert 14 TP-0 L9
GPU: 300
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_14_1 [label="Expert 14 TP-1 L9
GPU: 301
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_14 [label="TP All-Reduce Expert 14 L9
GPU: 300↔301
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_15 [label="Route to Expert 15
GPU: 302,303
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_15_0 [label="Expert 15 TP-0 L9
GPU: 302
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_15_1 [label="Expert 15 TP-1 L9
GPU: 303
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_15 [label="TP All-Reduce Expert 15 L9
GPU: 302↔303
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
	}
	subgraph cluster_stage_5 {
		fillcolor=lightgray label="Pipeline Stage 5 (Layers 10-11)" style="rounded,filled"
		q_proj_10 [label="Q Projection L10
GPU: 320-351
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		k_proj_10 [label="K Projection L10
GPU: 320-351
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		v_proj_10 [label="V Projection L10
GPU: 320-351
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_scores_10 [label="Attention Scores L10
GPU: 320-351
Input: Q,K,V [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		softmax_10 [label="Softmax L10
GPU: 320-351
Input: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]
Output: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_out_10 [label="Attention Output L10
GPU: 320-351
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_10 [label="Gate L10
GPU: 320-383
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_10_0 [label="Route to Expert 0
GPU: 320,321
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_0_0 [label="Expert 0 TP-0 L10
GPU: 320
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_0_1 [label="Expert 0 TP-1 L10
GPU: 321
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_0 [label="TP All-Reduce Expert 0 L10
GPU: 320↔321
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_1 [label="Route to Expert 1
GPU: 322,323
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_1_0 [label="Expert 1 TP-0 L10
GPU: 322
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_1_1 [label="Expert 1 TP-1 L10
GPU: 323
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_1 [label="TP All-Reduce Expert 1 L10
GPU: 322↔323
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_2 [label="Route to Expert 2
GPU: 324,325
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_2_0 [label="Expert 2 TP-0 L10
GPU: 324
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_2_1 [label="Expert 2 TP-1 L10
GPU: 325
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_2 [label="TP All-Reduce Expert 2 L10
GPU: 324↔325
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_3 [label="Route to Expert 3
GPU: 326,327
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_3_0 [label="Expert 3 TP-0 L10
GPU: 326
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_3_1 [label="Expert 3 TP-1 L10
GPU: 327
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_3 [label="TP All-Reduce Expert 3 L10
GPU: 326↔327
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_4 [label="Route to Expert 4
GPU: 328,329
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_4_0 [label="Expert 4 TP-0 L10
GPU: 328
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_4_1 [label="Expert 4 TP-1 L10
GPU: 329
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_4 [label="TP All-Reduce Expert 4 L10
GPU: 328↔329
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_5 [label="Route to Expert 5
GPU: 330,331
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_5_0 [label="Expert 5 TP-0 L10
GPU: 330
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_5_1 [label="Expert 5 TP-1 L10
GPU: 331
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_5 [label="TP All-Reduce Expert 5 L10
GPU: 330↔331
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_6 [label="Route to Expert 6
GPU: 332,333
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_6_0 [label="Expert 6 TP-0 L10
GPU: 332
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_6_1 [label="Expert 6 TP-1 L10
GPU: 333
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_6 [label="TP All-Reduce Expert 6 L10
GPU: 332↔333
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_7 [label="Route to Expert 7
GPU: 334,335
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_7_0 [label="Expert 7 TP-0 L10
GPU: 334
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_7_1 [label="Expert 7 TP-1 L10
GPU: 335
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_7 [label="TP All-Reduce Expert 7 L10
GPU: 334↔335
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_8 [label="Route to Expert 8
GPU: 352,353
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_8_0 [label="Expert 8 TP-0 L10
GPU: 352
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_8_1 [label="Expert 8 TP-1 L10
GPU: 353
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_8 [label="TP All-Reduce Expert 8 L10
GPU: 352↔353
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_9 [label="Route to Expert 9
GPU: 354,355
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_9_0 [label="Expert 9 TP-0 L10
GPU: 354
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_9_1 [label="Expert 9 TP-1 L10
GPU: 355
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_9 [label="TP All-Reduce Expert 9 L10
GPU: 354↔355
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_10 [label="Route to Expert 10
GPU: 356,357
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_10_0 [label="Expert 10 TP-0 L10
GPU: 356
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_10_1 [label="Expert 10 TP-1 L10
GPU: 357
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_10 [label="TP All-Reduce Expert 10 L10
GPU: 356↔357
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_11 [label="Route to Expert 11
GPU: 358,359
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_11_0 [label="Expert 11 TP-0 L10
GPU: 358
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_11_1 [label="Expert 11 TP-1 L10
GPU: 359
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_11 [label="TP All-Reduce Expert 11 L10
GPU: 358↔359
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_12 [label="Route to Expert 12
GPU: 360,361
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_12_0 [label="Expert 12 TP-0 L10
GPU: 360
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_12_1 [label="Expert 12 TP-1 L10
GPU: 361
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_12 [label="TP All-Reduce Expert 12 L10
GPU: 360↔361
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_13 [label="Route to Expert 13
GPU: 362,363
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_13_0 [label="Expert 13 TP-0 L10
GPU: 362
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_13_1 [label="Expert 13 TP-1 L10
GPU: 363
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_13 [label="TP All-Reduce Expert 13 L10
GPU: 362↔363
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_14 [label="Route to Expert 14
GPU: 364,365
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_14_0 [label="Expert 14 TP-0 L10
GPU: 364
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_14_1 [label="Expert 14 TP-1 L10
GPU: 365
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_14 [label="TP All-Reduce Expert 14 L10
GPU: 364↔365
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_15 [label="Route to Expert 15
GPU: 366,367
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_15_0 [label="Expert 15 TP-0 L10
GPU: 366
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_15_1 [label="Expert 15 TP-1 L10
GPU: 367
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_15 [label="TP All-Reduce Expert 15 L10
GPU: 366↔367
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		q_proj_11 [label="Q Projection L11
GPU: 320-351
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		k_proj_11 [label="K Projection L11
GPU: 320-351
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		v_proj_11 [label="V Projection L11
GPU: 320-351
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_scores_11 [label="Attention Scores L11
GPU: 320-351
Input: Q,K,V [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		softmax_11 [label="Softmax L11
GPU: 320-351
Input: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]
Output: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_out_11 [label="Attention Output L11
GPU: 320-351
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_11 [label="Gate L11
GPU: 320-383
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_11_0 [label="Route to Expert 0
GPU: 320,321
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_0_0 [label="Expert 0 TP-0 L11
GPU: 320
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_0_1 [label="Expert 0 TP-1 L11
GPU: 321
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_0 [label="TP All-Reduce Expert 0 L11
GPU: 320↔321
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_1 [label="Route to Expert 1
GPU: 322,323
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_1_0 [label="Expert 1 TP-0 L11
GPU: 322
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_1_1 [label="Expert 1 TP-1 L11
GPU: 323
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_1 [label="TP All-Reduce Expert 1 L11
GPU: 322↔323
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_2 [label="Route to Expert 2
GPU: 324,325
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_2_0 [label="Expert 2 TP-0 L11
GPU: 324
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_2_1 [label="Expert 2 TP-1 L11
GPU: 325
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_2 [label="TP All-Reduce Expert 2 L11
GPU: 324↔325
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_3 [label="Route to Expert 3
GPU: 326,327
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_3_0 [label="Expert 3 TP-0 L11
GPU: 326
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_3_1 [label="Expert 3 TP-1 L11
GPU: 327
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_3 [label="TP All-Reduce Expert 3 L11
GPU: 326↔327
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_4 [label="Route to Expert 4
GPU: 328,329
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_4_0 [label="Expert 4 TP-0 L11
GPU: 328
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_4_1 [label="Expert 4 TP-1 L11
GPU: 329
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_4 [label="TP All-Reduce Expert 4 L11
GPU: 328↔329
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_5 [label="Route to Expert 5
GPU: 330,331
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_5_0 [label="Expert 5 TP-0 L11
GPU: 330
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_5_1 [label="Expert 5 TP-1 L11
GPU: 331
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_5 [label="TP All-Reduce Expert 5 L11
GPU: 330↔331
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_6 [label="Route to Expert 6
GPU: 332,333
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_6_0 [label="Expert 6 TP-0 L11
GPU: 332
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_6_1 [label="Expert 6 TP-1 L11
GPU: 333
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_6 [label="TP All-Reduce Expert 6 L11
GPU: 332↔333
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_7 [label="Route to Expert 7
GPU: 334,335
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_7_0 [label="Expert 7 TP-0 L11
GPU: 334
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_7_1 [label="Expert 7 TP-1 L11
GPU: 335
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_7 [label="TP All-Reduce Expert 7 L11
GPU: 334↔335
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_8 [label="Route to Expert 8
GPU: 352,353
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_8_0 [label="Expert 8 TP-0 L11
GPU: 352
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_8_1 [label="Expert 8 TP-1 L11
GPU: 353
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_8 [label="TP All-Reduce Expert 8 L11
GPU: 352↔353
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_9 [label="Route to Expert 9
GPU: 354,355
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_9_0 [label="Expert 9 TP-0 L11
GPU: 354
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_9_1 [label="Expert 9 TP-1 L11
GPU: 355
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_9 [label="TP All-Reduce Expert 9 L11
GPU: 354↔355
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_10 [label="Route to Expert 10
GPU: 356,357
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_10_0 [label="Expert 10 TP-0 L11
GPU: 356
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_10_1 [label="Expert 10 TP-1 L11
GPU: 357
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_10 [label="TP All-Reduce Expert 10 L11
GPU: 356↔357
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_11 [label="Route to Expert 11
GPU: 358,359
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_11_0 [label="Expert 11 TP-0 L11
GPU: 358
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_11_1 [label="Expert 11 TP-1 L11
GPU: 359
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_11 [label="TP All-Reduce Expert 11 L11
GPU: 358↔359
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_12 [label="Route to Expert 12
GPU: 360,361
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_12_0 [label="Expert 12 TP-0 L11
GPU: 360
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_12_1 [label="Expert 12 TP-1 L11
GPU: 361
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_12 [label="TP All-Reduce Expert 12 L11
GPU: 360↔361
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_13 [label="Route to Expert 13
GPU: 362,363
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_13_0 [label="Expert 13 TP-0 L11
GPU: 362
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_13_1 [label="Expert 13 TP-1 L11
GPU: 363
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_13 [label="TP All-Reduce Expert 13 L11
GPU: 362↔363
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_14 [label="Route to Expert 14
GPU: 364,365
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_14_0 [label="Expert 14 TP-0 L11
GPU: 364
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_14_1 [label="Expert 14 TP-1 L11
GPU: 365
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_14 [label="TP All-Reduce Expert 14 L11
GPU: 364↔365
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_15 [label="Route to Expert 15
GPU: 366,367
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_15_0 [label="Expert 15 TP-0 L11
GPU: 366
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_15_1 [label="Expert 15 TP-1 L11
GPU: 367
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_15 [label="TP All-Reduce Expert 15 L11
GPU: 366↔367
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
	}
	subgraph cluster_stage_6 {
		fillcolor=lightgray label="Pipeline Stage 6 (Layers 12-13)" style="rounded,filled"
		q_proj_12 [label="Q Projection L12
GPU: 384-415
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		k_proj_12 [label="K Projection L12
GPU: 384-415
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		v_proj_12 [label="V Projection L12
GPU: 384-415
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_scores_12 [label="Attention Scores L12
GPU: 384-415
Input: Q,K,V [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		softmax_12 [label="Softmax L12
GPU: 384-415
Input: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]
Output: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_out_12 [label="Attention Output L12
GPU: 384-415
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_12 [label="Gate L12
GPU: 384-447
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_12_0 [label="Route to Expert 0
GPU: 384,385
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_0_0 [label="Expert 0 TP-0 L12
GPU: 384
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_0_1 [label="Expert 0 TP-1 L12
GPU: 385
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_0 [label="TP All-Reduce Expert 0 L12
GPU: 384↔385
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_1 [label="Route to Expert 1
GPU: 386,387
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_1_0 [label="Expert 1 TP-0 L12
GPU: 386
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_1_1 [label="Expert 1 TP-1 L12
GPU: 387
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_1 [label="TP All-Reduce Expert 1 L12
GPU: 386↔387
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_2 [label="Route to Expert 2
GPU: 388,389
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_2_0 [label="Expert 2 TP-0 L12
GPU: 388
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_2_1 [label="Expert 2 TP-1 L12
GPU: 389
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_2 [label="TP All-Reduce Expert 2 L12
GPU: 388↔389
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_3 [label="Route to Expert 3
GPU: 390,391
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_3_0 [label="Expert 3 TP-0 L12
GPU: 390
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_3_1 [label="Expert 3 TP-1 L12
GPU: 391
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_3 [label="TP All-Reduce Expert 3 L12
GPU: 390↔391
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_4 [label="Route to Expert 4
GPU: 392,393
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_4_0 [label="Expert 4 TP-0 L12
GPU: 392
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_4_1 [label="Expert 4 TP-1 L12
GPU: 393
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_4 [label="TP All-Reduce Expert 4 L12
GPU: 392↔393
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_5 [label="Route to Expert 5
GPU: 394,395
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_5_0 [label="Expert 5 TP-0 L12
GPU: 394
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_5_1 [label="Expert 5 TP-1 L12
GPU: 395
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_5 [label="TP All-Reduce Expert 5 L12
GPU: 394↔395
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_6 [label="Route to Expert 6
GPU: 396,397
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_6_0 [label="Expert 6 TP-0 L12
GPU: 396
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_6_1 [label="Expert 6 TP-1 L12
GPU: 397
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_6 [label="TP All-Reduce Expert 6 L12
GPU: 396↔397
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_7 [label="Route to Expert 7
GPU: 398,399
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_7_0 [label="Expert 7 TP-0 L12
GPU: 398
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_7_1 [label="Expert 7 TP-1 L12
GPU: 399
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_7 [label="TP All-Reduce Expert 7 L12
GPU: 398↔399
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_8 [label="Route to Expert 8
GPU: 416,417
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_8_0 [label="Expert 8 TP-0 L12
GPU: 416
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_8_1 [label="Expert 8 TP-1 L12
GPU: 417
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_8 [label="TP All-Reduce Expert 8 L12
GPU: 416↔417
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_9 [label="Route to Expert 9
GPU: 418,419
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_9_0 [label="Expert 9 TP-0 L12
GPU: 418
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_9_1 [label="Expert 9 TP-1 L12
GPU: 419
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_9 [label="TP All-Reduce Expert 9 L12
GPU: 418↔419
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_10 [label="Route to Expert 10
GPU: 420,421
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_10_0 [label="Expert 10 TP-0 L12
GPU: 420
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_10_1 [label="Expert 10 TP-1 L12
GPU: 421
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_10 [label="TP All-Reduce Expert 10 L12
GPU: 420↔421
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_11 [label="Route to Expert 11
GPU: 422,423
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_11_0 [label="Expert 11 TP-0 L12
GPU: 422
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_11_1 [label="Expert 11 TP-1 L12
GPU: 423
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_11 [label="TP All-Reduce Expert 11 L12
GPU: 422↔423
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_12 [label="Route to Expert 12
GPU: 424,425
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_12_0 [label="Expert 12 TP-0 L12
GPU: 424
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_12_1 [label="Expert 12 TP-1 L12
GPU: 425
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_12 [label="TP All-Reduce Expert 12 L12
GPU: 424↔425
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_13 [label="Route to Expert 13
GPU: 426,427
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_13_0 [label="Expert 13 TP-0 L12
GPU: 426
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_13_1 [label="Expert 13 TP-1 L12
GPU: 427
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_13 [label="TP All-Reduce Expert 13 L12
GPU: 426↔427
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_14 [label="Route to Expert 14
GPU: 428,429
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_14_0 [label="Expert 14 TP-0 L12
GPU: 428
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_14_1 [label="Expert 14 TP-1 L12
GPU: 429
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_14 [label="TP All-Reduce Expert 14 L12
GPU: 428↔429
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_15 [label="Route to Expert 15
GPU: 430,431
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_15_0 [label="Expert 15 TP-0 L12
GPU: 430
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_15_1 [label="Expert 15 TP-1 L12
GPU: 431
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_15 [label="TP All-Reduce Expert 15 L12
GPU: 430↔431
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		q_proj_13 [label="Q Projection L13
GPU: 384-415
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		k_proj_13 [label="K Projection L13
GPU: 384-415
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		v_proj_13 [label="V Projection L13
GPU: 384-415
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_scores_13 [label="Attention Scores L13
GPU: 384-415
Input: Q,K,V [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		softmax_13 [label="Softmax L13
GPU: 384-415
Input: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]
Output: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_out_13 [label="Attention Output L13
GPU: 384-415
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_13 [label="Gate L13
GPU: 384-447
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_13_0 [label="Route to Expert 0
GPU: 384,385
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_0_0 [label="Expert 0 TP-0 L13
GPU: 384
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_0_1 [label="Expert 0 TP-1 L13
GPU: 385
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_0 [label="TP All-Reduce Expert 0 L13
GPU: 384↔385
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_1 [label="Route to Expert 1
GPU: 386,387
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_1_0 [label="Expert 1 TP-0 L13
GPU: 386
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_1_1 [label="Expert 1 TP-1 L13
GPU: 387
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_1 [label="TP All-Reduce Expert 1 L13
GPU: 386↔387
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_2 [label="Route to Expert 2
GPU: 388,389
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_2_0 [label="Expert 2 TP-0 L13
GPU: 388
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_2_1 [label="Expert 2 TP-1 L13
GPU: 389
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_2 [label="TP All-Reduce Expert 2 L13
GPU: 388↔389
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_3 [label="Route to Expert 3
GPU: 390,391
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_3_0 [label="Expert 3 TP-0 L13
GPU: 390
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_3_1 [label="Expert 3 TP-1 L13
GPU: 391
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_3 [label="TP All-Reduce Expert 3 L13
GPU: 390↔391
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_4 [label="Route to Expert 4
GPU: 392,393
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_4_0 [label="Expert 4 TP-0 L13
GPU: 392
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_4_1 [label="Expert 4 TP-1 L13
GPU: 393
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_4 [label="TP All-Reduce Expert 4 L13
GPU: 392↔393
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_5 [label="Route to Expert 5
GPU: 394,395
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_5_0 [label="Expert 5 TP-0 L13
GPU: 394
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_5_1 [label="Expert 5 TP-1 L13
GPU: 395
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_5 [label="TP All-Reduce Expert 5 L13
GPU: 394↔395
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_6 [label="Route to Expert 6
GPU: 396,397
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_6_0 [label="Expert 6 TP-0 L13
GPU: 396
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_6_1 [label="Expert 6 TP-1 L13
GPU: 397
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_6 [label="TP All-Reduce Expert 6 L13
GPU: 396↔397
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_7 [label="Route to Expert 7
GPU: 398,399
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_7_0 [label="Expert 7 TP-0 L13
GPU: 398
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_7_1 [label="Expert 7 TP-1 L13
GPU: 399
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_7 [label="TP All-Reduce Expert 7 L13
GPU: 398↔399
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_8 [label="Route to Expert 8
GPU: 416,417
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_8_0 [label="Expert 8 TP-0 L13
GPU: 416
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_8_1 [label="Expert 8 TP-1 L13
GPU: 417
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_8 [label="TP All-Reduce Expert 8 L13
GPU: 416↔417
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_9 [label="Route to Expert 9
GPU: 418,419
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_9_0 [label="Expert 9 TP-0 L13
GPU: 418
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_9_1 [label="Expert 9 TP-1 L13
GPU: 419
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_9 [label="TP All-Reduce Expert 9 L13
GPU: 418↔419
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_10 [label="Route to Expert 10
GPU: 420,421
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_10_0 [label="Expert 10 TP-0 L13
GPU: 420
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_10_1 [label="Expert 10 TP-1 L13
GPU: 421
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_10 [label="TP All-Reduce Expert 10 L13
GPU: 420↔421
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_11 [label="Route to Expert 11
GPU: 422,423
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_11_0 [label="Expert 11 TP-0 L13
GPU: 422
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_11_1 [label="Expert 11 TP-1 L13
GPU: 423
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_11 [label="TP All-Reduce Expert 11 L13
GPU: 422↔423
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_12 [label="Route to Expert 12
GPU: 424,425
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_12_0 [label="Expert 12 TP-0 L13
GPU: 424
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_12_1 [label="Expert 12 TP-1 L13
GPU: 425
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_12 [label="TP All-Reduce Expert 12 L13
GPU: 424↔425
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_13 [label="Route to Expert 13
GPU: 426,427
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_13_0 [label="Expert 13 TP-0 L13
GPU: 426
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_13_1 [label="Expert 13 TP-1 L13
GPU: 427
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_13 [label="TP All-Reduce Expert 13 L13
GPU: 426↔427
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_14 [label="Route to Expert 14
GPU: 428,429
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_14_0 [label="Expert 14 TP-0 L13
GPU: 428
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_14_1 [label="Expert 14 TP-1 L13
GPU: 429
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_14 [label="TP All-Reduce Expert 14 L13
GPU: 428↔429
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_15 [label="Route to Expert 15
GPU: 430,431
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_15_0 [label="Expert 15 TP-0 L13
GPU: 430
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_15_1 [label="Expert 15 TP-1 L13
GPU: 431
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_15 [label="TP All-Reduce Expert 15 L13
GPU: 430↔431
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
	}
	subgraph cluster_stage_7 {
		fillcolor=lightgray label="Pipeline Stage 7 (Layers 14-15)" style="rounded,filled"
		q_proj_14 [label="Q Projection L14
GPU: 448-479
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		k_proj_14 [label="K Projection L14
GPU: 448-479
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		v_proj_14 [label="V Projection L14
GPU: 448-479
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_scores_14 [label="Attention Scores L14
GPU: 448-479
Input: Q,K,V [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		softmax_14 [label="Softmax L14
GPU: 448-479
Input: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]
Output: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_out_14 [label="Attention Output L14
GPU: 448-479
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_14 [label="Gate L14
GPU: 448-511
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_14_0 [label="Route to Expert 0
GPU: 448,449
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_0_0 [label="Expert 0 TP-0 L14
GPU: 448
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_0_1 [label="Expert 0 TP-1 L14
GPU: 449
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_0 [label="TP All-Reduce Expert 0 L14
GPU: 448↔449
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_1 [label="Route to Expert 1
GPU: 450,451
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_1_0 [label="Expert 1 TP-0 L14
GPU: 450
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_1_1 [label="Expert 1 TP-1 L14
GPU: 451
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_1 [label="TP All-Reduce Expert 1 L14
GPU: 450↔451
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_2 [label="Route to Expert 2
GPU: 452,453
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_2_0 [label="Expert 2 TP-0 L14
GPU: 452
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_2_1 [label="Expert 2 TP-1 L14
GPU: 453
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_2 [label="TP All-Reduce Expert 2 L14
GPU: 452↔453
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_3 [label="Route to Expert 3
GPU: 454,455
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_3_0 [label="Expert 3 TP-0 L14
GPU: 454
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_3_1 [label="Expert 3 TP-1 L14
GPU: 455
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_3 [label="TP All-Reduce Expert 3 L14
GPU: 454↔455
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_4 [label="Route to Expert 4
GPU: 456,457
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_4_0 [label="Expert 4 TP-0 L14
GPU: 456
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_4_1 [label="Expert 4 TP-1 L14
GPU: 457
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_4 [label="TP All-Reduce Expert 4 L14
GPU: 456↔457
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_5 [label="Route to Expert 5
GPU: 458,459
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_5_0 [label="Expert 5 TP-0 L14
GPU: 458
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_5_1 [label="Expert 5 TP-1 L14
GPU: 459
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_5 [label="TP All-Reduce Expert 5 L14
GPU: 458↔459
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_6 [label="Route to Expert 6
GPU: 460,461
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_6_0 [label="Expert 6 TP-0 L14
GPU: 460
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_6_1 [label="Expert 6 TP-1 L14
GPU: 461
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_6 [label="TP All-Reduce Expert 6 L14
GPU: 460↔461
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_7 [label="Route to Expert 7
GPU: 462,463
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_7_0 [label="Expert 7 TP-0 L14
GPU: 462
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_7_1 [label="Expert 7 TP-1 L14
GPU: 463
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_7 [label="TP All-Reduce Expert 7 L14
GPU: 462↔463
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_8 [label="Route to Expert 8
GPU: 480,481
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_8_0 [label="Expert 8 TP-0 L14
GPU: 480
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_8_1 [label="Expert 8 TP-1 L14
GPU: 481
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_8 [label="TP All-Reduce Expert 8 L14
GPU: 480↔481
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_9 [label="Route to Expert 9
GPU: 482,483
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_9_0 [label="Expert 9 TP-0 L14
GPU: 482
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_9_1 [label="Expert 9 TP-1 L14
GPU: 483
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_9 [label="TP All-Reduce Expert 9 L14
GPU: 482↔483
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_10 [label="Route to Expert 10
GPU: 484,485
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_10_0 [label="Expert 10 TP-0 L14
GPU: 484
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_10_1 [label="Expert 10 TP-1 L14
GPU: 485
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_10 [label="TP All-Reduce Expert 10 L14
GPU: 484↔485
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_11 [label="Route to Expert 11
GPU: 486,487
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_11_0 [label="Expert 11 TP-0 L14
GPU: 486
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_11_1 [label="Expert 11 TP-1 L14
GPU: 487
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_11 [label="TP All-Reduce Expert 11 L14
GPU: 486↔487
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_12 [label="Route to Expert 12
GPU: 488,489
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_12_0 [label="Expert 12 TP-0 L14
GPU: 488
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_12_1 [label="Expert 12 TP-1 L14
GPU: 489
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_12 [label="TP All-Reduce Expert 12 L14
GPU: 488↔489
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_13 [label="Route to Expert 13
GPU: 490,491
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_13_0 [label="Expert 13 TP-0 L14
GPU: 490
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_13_1 [label="Expert 13 TP-1 L14
GPU: 491
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_13 [label="TP All-Reduce Expert 13 L14
GPU: 490↔491
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_14 [label="Route to Expert 14
GPU: 492,493
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_14_0 [label="Expert 14 TP-0 L14
GPU: 492
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_14_1 [label="Expert 14 TP-1 L14
GPU: 493
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_14 [label="TP All-Reduce Expert 14 L14
GPU: 492↔493
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_15 [label="Route to Expert 15
GPU: 494,495
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_15_0 [label="Expert 15 TP-0 L14
GPU: 494
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_15_1 [label="Expert 15 TP-1 L14
GPU: 495
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_15 [label="TP All-Reduce Expert 15 L14
GPU: 494↔495
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		q_proj_15 [label="Q Projection L15
GPU: 448-479
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		k_proj_15 [label="K Projection L15
GPU: 448-479
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		v_proj_15 [label="V Projection L15
GPU: 448-479
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_scores_15 [label="Attention Scores L15
GPU: 448-479
Input: Q,K,V [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		softmax_15 [label="Softmax L15
GPU: 448-479
Input: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]
Output: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_out_15 [label="Attention Output L15
GPU: 448-479
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_15 [label="Gate L15
GPU: 448-511
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_15_0 [label="Route to Expert 0
GPU: 448,449
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_0_0 [label="Expert 0 TP-0 L15
GPU: 448
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_0_1 [label="Expert 0 TP-1 L15
GPU: 449
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_0 [label="TP All-Reduce Expert 0 L15
GPU: 448↔449
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_1 [label="Route to Expert 1
GPU: 450,451
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_1_0 [label="Expert 1 TP-0 L15
GPU: 450
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_1_1 [label="Expert 1 TP-1 L15
GPU: 451
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_1 [label="TP All-Reduce Expert 1 L15
GPU: 450↔451
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_2 [label="Route to Expert 2
GPU: 452,453
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_2_0 [label="Expert 2 TP-0 L15
GPU: 452
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_2_1 [label="Expert 2 TP-1 L15
GPU: 453
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_2 [label="TP All-Reduce Expert 2 L15
GPU: 452↔453
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_3 [label="Route to Expert 3
GPU: 454,455
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_3_0 [label="Expert 3 TP-0 L15
GPU: 454
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_3_1 [label="Expert 3 TP-1 L15
GPU: 455
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_3 [label="TP All-Reduce Expert 3 L15
GPU: 454↔455
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_4 [label="Route to Expert 4
GPU: 456,457
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_4_0 [label="Expert 4 TP-0 L15
GPU: 456
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_4_1 [label="Expert 4 TP-1 L15
GPU: 457
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_4 [label="TP All-Reduce Expert 4 L15
GPU: 456↔457
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_5 [label="Route to Expert 5
GPU: 458,459
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_5_0 [label="Expert 5 TP-0 L15
GPU: 458
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_5_1 [label="Expert 5 TP-1 L15
GPU: 459
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_5 [label="TP All-Reduce Expert 5 L15
GPU: 458↔459
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_6 [label="Route to Expert 6
GPU: 460,461
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_6_0 [label="Expert 6 TP-0 L15
GPU: 460
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_6_1 [label="Expert 6 TP-1 L15
GPU: 461
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_6 [label="TP All-Reduce Expert 6 L15
GPU: 460↔461
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_7 [label="Route to Expert 7
GPU: 462,463
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_7_0 [label="Expert 7 TP-0 L15
GPU: 462
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_7_1 [label="Expert 7 TP-1 L15
GPU: 463
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_7 [label="TP All-Reduce Expert 7 L15
GPU: 462↔463
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_8 [label="Route to Expert 8
GPU: 480,481
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_8_0 [label="Expert 8 TP-0 L15
GPU: 480
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_8_1 [label="Expert 8 TP-1 L15
GPU: 481
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_8 [label="TP All-Reduce Expert 8 L15
GPU: 480↔481
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_9 [label="Route to Expert 9
GPU: 482,483
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_9_0 [label="Expert 9 TP-0 L15
GPU: 482
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_9_1 [label="Expert 9 TP-1 L15
GPU: 483
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_9 [label="TP All-Reduce Expert 9 L15
GPU: 482↔483
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_10 [label="Route to Expert 10
GPU: 484,485
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_10_0 [label="Expert 10 TP-0 L15
GPU: 484
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_10_1 [label="Expert 10 TP-1 L15
GPU: 485
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_10 [label="TP All-Reduce Expert 10 L15
GPU: 484↔485
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_11 [label="Route to Expert 11
GPU: 486,487
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_11_0 [label="Expert 11 TP-0 L15
GPU: 486
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_11_1 [label="Expert 11 TP-1 L15
GPU: 487
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_11 [label="TP All-Reduce Expert 11 L15
GPU: 486↔487
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_12 [label="Route to Expert 12
GPU: 488,489
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_12_0 [label="Expert 12 TP-0 L15
GPU: 488
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_12_1 [label="Expert 12 TP-1 L15
GPU: 489
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_12 [label="TP All-Reduce Expert 12 L15
GPU: 488↔489
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_13 [label="Route to Expert 13
GPU: 490,491
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_13_0 [label="Expert 13 TP-0 L15
GPU: 490
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_13_1 [label="Expert 13 TP-1 L15
GPU: 491
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_13 [label="TP All-Reduce Expert 13 L15
GPU: 490↔491
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_14 [label="Route to Expert 14
GPU: 492,493
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_14_0 [label="Expert 14 TP-0 L15
GPU: 492
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_14_1 [label="Expert 14 TP-1 L15
GPU: 493
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_14 [label="TP All-Reduce Expert 14 L15
GPU: 492↔493
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_15 [label="Route to Expert 15
GPU: 494,495
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_15_0 [label="Expert 15 TP-0 L15
GPU: 494
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_15_1 [label="Expert 15 TP-1 L15
GPU: 495
Input: [batch_size=128, seq_len=640, heads=16, d_k=32]
Output: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_15 [label="TP All-Reduce Expert 15 L15
GPU: 494↔495
Input: expert_out[hidden=512]
Output: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
	}
	output [label="Output
Input: [batch_size=128, seq_len=10240, heads=16, d_k=32]
Output: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style=filled]
	input -> q_proj_0
	input -> k_proj_0
	input -> v_proj_0
	q_proj_0 -> attn_scores_0
	k_proj_0 -> attn_scores_0
	v_proj_0 -> attn_scores_0
	attn_scores_0 -> softmax_0
	softmax_0 -> attn_out_0
	attn_out_0 -> gate_0
	gate_0 -> route_0_0
	route_0_0 -> expert_0_0_0
	route_0_0 -> expert_0_0_1
	expert_0_0_0 -> tp_0_0
	expert_0_0_1 -> tp_0_0
	gate_0 -> route_0_1
	route_0_1 -> expert_0_1_0
	route_0_1 -> expert_0_1_1
	expert_0_1_0 -> tp_0_1
	expert_0_1_1 -> tp_0_1
	gate_0 -> route_0_2
	route_0_2 -> expert_0_2_0
	route_0_2 -> expert_0_2_1
	expert_0_2_0 -> tp_0_2
	expert_0_2_1 -> tp_0_2
	gate_0 -> route_0_3
	route_0_3 -> expert_0_3_0
	route_0_3 -> expert_0_3_1
	expert_0_3_0 -> tp_0_3
	expert_0_3_1 -> tp_0_3
	gate_0 -> route_0_4
	route_0_4 -> expert_0_4_0
	route_0_4 -> expert_0_4_1
	expert_0_4_0 -> tp_0_4
	expert_0_4_1 -> tp_0_4
	gate_0 -> route_0_5
	route_0_5 -> expert_0_5_0
	route_0_5 -> expert_0_5_1
	expert_0_5_0 -> tp_0_5
	expert_0_5_1 -> tp_0_5
	gate_0 -> route_0_6
	route_0_6 -> expert_0_6_0
	route_0_6 -> expert_0_6_1
	expert_0_6_0 -> tp_0_6
	expert_0_6_1 -> tp_0_6
	gate_0 -> route_0_7
	route_0_7 -> expert_0_7_0
	route_0_7 -> expert_0_7_1
	expert_0_7_0 -> tp_0_7
	expert_0_7_1 -> tp_0_7
	gate_0 -> route_0_8
	route_0_8 -> expert_0_8_0
	route_0_8 -> expert_0_8_1
	expert_0_8_0 -> tp_0_8
	expert_0_8_1 -> tp_0_8
	gate_0 -> route_0_9
	route_0_9 -> expert_0_9_0
	route_0_9 -> expert_0_9_1
	expert_0_9_0 -> tp_0_9
	expert_0_9_1 -> tp_0_9
	gate_0 -> route_0_10
	route_0_10 -> expert_0_10_0
	route_0_10 -> expert_0_10_1
	expert_0_10_0 -> tp_0_10
	expert_0_10_1 -> tp_0_10
	gate_0 -> route_0_11
	route_0_11 -> expert_0_11_0
	route_0_11 -> expert_0_11_1
	expert_0_11_0 -> tp_0_11
	expert_0_11_1 -> tp_0_11
	gate_0 -> route_0_12
	route_0_12 -> expert_0_12_0
	route_0_12 -> expert_0_12_1
	expert_0_12_0 -> tp_0_12
	expert_0_12_1 -> tp_0_12
	gate_0 -> route_0_13
	route_0_13 -> expert_0_13_0
	route_0_13 -> expert_0_13_1
	expert_0_13_0 -> tp_0_13
	expert_0_13_1 -> tp_0_13
	gate_0 -> route_0_14
	route_0_14 -> expert_0_14_0
	route_0_14 -> expert_0_14_1
	expert_0_14_0 -> tp_0_14
	expert_0_14_1 -> tp_0_14
	gate_0 -> route_0_15
	route_0_15 -> expert_0_15_0
	route_0_15 -> expert_0_15_1
	expert_0_15_0 -> tp_0_15
	expert_0_15_1 -> tp_0_15
	q_proj_1 -> attn_scores_1
	k_proj_1 -> attn_scores_1
	v_proj_1 -> attn_scores_1
	attn_scores_1 -> softmax_1
	softmax_1 -> attn_out_1
	attn_out_1 -> gate_1
	gate_1 -> route_1_0
	route_1_0 -> expert_1_0_0
	route_1_0 -> expert_1_0_1
	expert_1_0_0 -> tp_1_0
	expert_1_0_1 -> tp_1_0
	gate_1 -> route_1_1
	route_1_1 -> expert_1_1_0
	route_1_1 -> expert_1_1_1
	expert_1_1_0 -> tp_1_1
	expert_1_1_1 -> tp_1_1
	gate_1 -> route_1_2
	route_1_2 -> expert_1_2_0
	route_1_2 -> expert_1_2_1
	expert_1_2_0 -> tp_1_2
	expert_1_2_1 -> tp_1_2
	gate_1 -> route_1_3
	route_1_3 -> expert_1_3_0
	route_1_3 -> expert_1_3_1
	expert_1_3_0 -> tp_1_3
	expert_1_3_1 -> tp_1_3
	gate_1 -> route_1_4
	route_1_4 -> expert_1_4_0
	route_1_4 -> expert_1_4_1
	expert_1_4_0 -> tp_1_4
	expert_1_4_1 -> tp_1_4
	gate_1 -> route_1_5
	route_1_5 -> expert_1_5_0
	route_1_5 -> expert_1_5_1
	expert_1_5_0 -> tp_1_5
	expert_1_5_1 -> tp_1_5
	gate_1 -> route_1_6
	route_1_6 -> expert_1_6_0
	route_1_6 -> expert_1_6_1
	expert_1_6_0 -> tp_1_6
	expert_1_6_1 -> tp_1_6
	gate_1 -> route_1_7
	route_1_7 -> expert_1_7_0
	route_1_7 -> expert_1_7_1
	expert_1_7_0 -> tp_1_7
	expert_1_7_1 -> tp_1_7
	gate_1 -> route_1_8
	route_1_8 -> expert_1_8_0
	route_1_8 -> expert_1_8_1
	expert_1_8_0 -> tp_1_8
	expert_1_8_1 -> tp_1_8
	gate_1 -> route_1_9
	route_1_9 -> expert_1_9_0
	route_1_9 -> expert_1_9_1
	expert_1_9_0 -> tp_1_9
	expert_1_9_1 -> tp_1_9
	gate_1 -> route_1_10
	route_1_10 -> expert_1_10_0
	route_1_10 -> expert_1_10_1
	expert_1_10_0 -> tp_1_10
	expert_1_10_1 -> tp_1_10
	gate_1 -> route_1_11
	route_1_11 -> expert_1_11_0
	route_1_11 -> expert_1_11_1
	expert_1_11_0 -> tp_1_11
	expert_1_11_1 -> tp_1_11
	gate_1 -> route_1_12
	route_1_12 -> expert_1_12_0
	route_1_12 -> expert_1_12_1
	expert_1_12_0 -> tp_1_12
	expert_1_12_1 -> tp_1_12
	gate_1 -> route_1_13
	route_1_13 -> expert_1_13_0
	route_1_13 -> expert_1_13_1
	expert_1_13_0 -> tp_1_13
	expert_1_13_1 -> tp_1_13
	gate_1 -> route_1_14
	route_1_14 -> expert_1_14_0
	route_1_14 -> expert_1_14_1
	expert_1_14_0 -> tp_1_14
	expert_1_14_1 -> tp_1_14
	gate_1 -> route_1_15
	route_1_15 -> expert_1_15_0
	route_1_15 -> expert_1_15_1
	expert_1_15_0 -> tp_1_15
	expert_1_15_1 -> tp_1_15
	q_proj_2 -> attn_scores_2
	k_proj_2 -> attn_scores_2
	v_proj_2 -> attn_scores_2
	attn_scores_2 -> softmax_2
	softmax_2 -> attn_out_2
	attn_out_2 -> gate_2
	gate_2 -> route_2_0
	route_2_0 -> expert_2_0_0
	route_2_0 -> expert_2_0_1
	expert_2_0_0 -> tp_2_0
	expert_2_0_1 -> tp_2_0
	gate_2 -> route_2_1
	route_2_1 -> expert_2_1_0
	route_2_1 -> expert_2_1_1
	expert_2_1_0 -> tp_2_1
	expert_2_1_1 -> tp_2_1
	gate_2 -> route_2_2
	route_2_2 -> expert_2_2_0
	route_2_2 -> expert_2_2_1
	expert_2_2_0 -> tp_2_2
	expert_2_2_1 -> tp_2_2
	gate_2 -> route_2_3
	route_2_3 -> expert_2_3_0
	route_2_3 -> expert_2_3_1
	expert_2_3_0 -> tp_2_3
	expert_2_3_1 -> tp_2_3
	gate_2 -> route_2_4
	route_2_4 -> expert_2_4_0
	route_2_4 -> expert_2_4_1
	expert_2_4_0 -> tp_2_4
	expert_2_4_1 -> tp_2_4
	gate_2 -> route_2_5
	route_2_5 -> expert_2_5_0
	route_2_5 -> expert_2_5_1
	expert_2_5_0 -> tp_2_5
	expert_2_5_1 -> tp_2_5
	gate_2 -> route_2_6
	route_2_6 -> expert_2_6_0
	route_2_6 -> expert_2_6_1
	expert_2_6_0 -> tp_2_6
	expert_2_6_1 -> tp_2_6
	gate_2 -> route_2_7
	route_2_7 -> expert_2_7_0
	route_2_7 -> expert_2_7_1
	expert_2_7_0 -> tp_2_7
	expert_2_7_1 -> tp_2_7
	gate_2 -> route_2_8
	route_2_8 -> expert_2_8_0
	route_2_8 -> expert_2_8_1
	expert_2_8_0 -> tp_2_8
	expert_2_8_1 -> tp_2_8
	gate_2 -> route_2_9
	route_2_9 -> expert_2_9_0
	route_2_9 -> expert_2_9_1
	expert_2_9_0 -> tp_2_9
	expert_2_9_1 -> tp_2_9
	gate_2 -> route_2_10
	route_2_10 -> expert_2_10_0
	route_2_10 -> expert_2_10_1
	expert_2_10_0 -> tp_2_10
	expert_2_10_1 -> tp_2_10
	gate_2 -> route_2_11
	route_2_11 -> expert_2_11_0
	route_2_11 -> expert_2_11_1
	expert_2_11_0 -> tp_2_11
	expert_2_11_1 -> tp_2_11
	gate_2 -> route_2_12
	route_2_12 -> expert_2_12_0
	route_2_12 -> expert_2_12_1
	expert_2_12_0 -> tp_2_12
	expert_2_12_1 -> tp_2_12
	gate_2 -> route_2_13
	route_2_13 -> expert_2_13_0
	route_2_13 -> expert_2_13_1
	expert_2_13_0 -> tp_2_13
	expert_2_13_1 -> tp_2_13
	gate_2 -> route_2_14
	route_2_14 -> expert_2_14_0
	route_2_14 -> expert_2_14_1
	expert_2_14_0 -> tp_2_14
	expert_2_14_1 -> tp_2_14
	gate_2 -> route_2_15
	route_2_15 -> expert_2_15_0
	route_2_15 -> expert_2_15_1
	expert_2_15_0 -> tp_2_15
	expert_2_15_1 -> tp_2_15
	q_proj_3 -> attn_scores_3
	k_proj_3 -> attn_scores_3
	v_proj_3 -> attn_scores_3
	attn_scores_3 -> softmax_3
	softmax_3 -> attn_out_3
	attn_out_3 -> gate_3
	gate_3 -> route_3_0
	route_3_0 -> expert_3_0_0
	route_3_0 -> expert_3_0_1
	expert_3_0_0 -> tp_3_0
	expert_3_0_1 -> tp_3_0
	gate_3 -> route_3_1
	route_3_1 -> expert_3_1_0
	route_3_1 -> expert_3_1_1
	expert_3_1_0 -> tp_3_1
	expert_3_1_1 -> tp_3_1
	gate_3 -> route_3_2
	route_3_2 -> expert_3_2_0
	route_3_2 -> expert_3_2_1
	expert_3_2_0 -> tp_3_2
	expert_3_2_1 -> tp_3_2
	gate_3 -> route_3_3
	route_3_3 -> expert_3_3_0
	route_3_3 -> expert_3_3_1
	expert_3_3_0 -> tp_3_3
	expert_3_3_1 -> tp_3_3
	gate_3 -> route_3_4
	route_3_4 -> expert_3_4_0
	route_3_4 -> expert_3_4_1
	expert_3_4_0 -> tp_3_4
	expert_3_4_1 -> tp_3_4
	gate_3 -> route_3_5
	route_3_5 -> expert_3_5_0
	route_3_5 -> expert_3_5_1
	expert_3_5_0 -> tp_3_5
	expert_3_5_1 -> tp_3_5
	gate_3 -> route_3_6
	route_3_6 -> expert_3_6_0
	route_3_6 -> expert_3_6_1
	expert_3_6_0 -> tp_3_6
	expert_3_6_1 -> tp_3_6
	gate_3 -> route_3_7
	route_3_7 -> expert_3_7_0
	route_3_7 -> expert_3_7_1
	expert_3_7_0 -> tp_3_7
	expert_3_7_1 -> tp_3_7
	gate_3 -> route_3_8
	route_3_8 -> expert_3_8_0
	route_3_8 -> expert_3_8_1
	expert_3_8_0 -> tp_3_8
	expert_3_8_1 -> tp_3_8
	gate_3 -> route_3_9
	route_3_9 -> expert_3_9_0
	route_3_9 -> expert_3_9_1
	expert_3_9_0 -> tp_3_9
	expert_3_9_1 -> tp_3_9
	gate_3 -> route_3_10
	route_3_10 -> expert_3_10_0
	route_3_10 -> expert_3_10_1
	expert_3_10_0 -> tp_3_10
	expert_3_10_1 -> tp_3_10
	gate_3 -> route_3_11
	route_3_11 -> expert_3_11_0
	route_3_11 -> expert_3_11_1
	expert_3_11_0 -> tp_3_11
	expert_3_11_1 -> tp_3_11
	gate_3 -> route_3_12
	route_3_12 -> expert_3_12_0
	route_3_12 -> expert_3_12_1
	expert_3_12_0 -> tp_3_12
	expert_3_12_1 -> tp_3_12
	gate_3 -> route_3_13
	route_3_13 -> expert_3_13_0
	route_3_13 -> expert_3_13_1
	expert_3_13_0 -> tp_3_13
	expert_3_13_1 -> tp_3_13
	gate_3 -> route_3_14
	route_3_14 -> expert_3_14_0
	route_3_14 -> expert_3_14_1
	expert_3_14_0 -> tp_3_14
	expert_3_14_1 -> tp_3_14
	gate_3 -> route_3_15
	route_3_15 -> expert_3_15_0
	route_3_15 -> expert_3_15_1
	expert_3_15_0 -> tp_3_15
	expert_3_15_1 -> tp_3_15
	q_proj_4 -> attn_scores_4
	k_proj_4 -> attn_scores_4
	v_proj_4 -> attn_scores_4
	attn_scores_4 -> softmax_4
	softmax_4 -> attn_out_4
	attn_out_4 -> gate_4
	gate_4 -> route_4_0
	route_4_0 -> expert_4_0_0
	route_4_0 -> expert_4_0_1
	expert_4_0_0 -> tp_4_0
	expert_4_0_1 -> tp_4_0
	gate_4 -> route_4_1
	route_4_1 -> expert_4_1_0
	route_4_1 -> expert_4_1_1
	expert_4_1_0 -> tp_4_1
	expert_4_1_1 -> tp_4_1
	gate_4 -> route_4_2
	route_4_2 -> expert_4_2_0
	route_4_2 -> expert_4_2_1
	expert_4_2_0 -> tp_4_2
	expert_4_2_1 -> tp_4_2
	gate_4 -> route_4_3
	route_4_3 -> expert_4_3_0
	route_4_3 -> expert_4_3_1
	expert_4_3_0 -> tp_4_3
	expert_4_3_1 -> tp_4_3
	gate_4 -> route_4_4
	route_4_4 -> expert_4_4_0
	route_4_4 -> expert_4_4_1
	expert_4_4_0 -> tp_4_4
	expert_4_4_1 -> tp_4_4
	gate_4 -> route_4_5
	route_4_5 -> expert_4_5_0
	route_4_5 -> expert_4_5_1
	expert_4_5_0 -> tp_4_5
	expert_4_5_1 -> tp_4_5
	gate_4 -> route_4_6
	route_4_6 -> expert_4_6_0
	route_4_6 -> expert_4_6_1
	expert_4_6_0 -> tp_4_6
	expert_4_6_1 -> tp_4_6
	gate_4 -> route_4_7
	route_4_7 -> expert_4_7_0
	route_4_7 -> expert_4_7_1
	expert_4_7_0 -> tp_4_7
	expert_4_7_1 -> tp_4_7
	gate_4 -> route_4_8
	route_4_8 -> expert_4_8_0
	route_4_8 -> expert_4_8_1
	expert_4_8_0 -> tp_4_8
	expert_4_8_1 -> tp_4_8
	gate_4 -> route_4_9
	route_4_9 -> expert_4_9_0
	route_4_9 -> expert_4_9_1
	expert_4_9_0 -> tp_4_9
	expert_4_9_1 -> tp_4_9
	gate_4 -> route_4_10
	route_4_10 -> expert_4_10_0
	route_4_10 -> expert_4_10_1
	expert_4_10_0 -> tp_4_10
	expert_4_10_1 -> tp_4_10
	gate_4 -> route_4_11
	route_4_11 -> expert_4_11_0
	route_4_11 -> expert_4_11_1
	expert_4_11_0 -> tp_4_11
	expert_4_11_1 -> tp_4_11
	gate_4 -> route_4_12
	route_4_12 -> expert_4_12_0
	route_4_12 -> expert_4_12_1
	expert_4_12_0 -> tp_4_12
	expert_4_12_1 -> tp_4_12
	gate_4 -> route_4_13
	route_4_13 -> expert_4_13_0
	route_4_13 -> expert_4_13_1
	expert_4_13_0 -> tp_4_13
	expert_4_13_1 -> tp_4_13
	gate_4 -> route_4_14
	route_4_14 -> expert_4_14_0
	route_4_14 -> expert_4_14_1
	expert_4_14_0 -> tp_4_14
	expert_4_14_1 -> tp_4_14
	gate_4 -> route_4_15
	route_4_15 -> expert_4_15_0
	route_4_15 -> expert_4_15_1
	expert_4_15_0 -> tp_4_15
	expert_4_15_1 -> tp_4_15
	q_proj_5 -> attn_scores_5
	k_proj_5 -> attn_scores_5
	v_proj_5 -> attn_scores_5
	attn_scores_5 -> softmax_5
	softmax_5 -> attn_out_5
	attn_out_5 -> gate_5
	gate_5 -> route_5_0
	route_5_0 -> expert_5_0_0
	route_5_0 -> expert_5_0_1
	expert_5_0_0 -> tp_5_0
	expert_5_0_1 -> tp_5_0
	gate_5 -> route_5_1
	route_5_1 -> expert_5_1_0
	route_5_1 -> expert_5_1_1
	expert_5_1_0 -> tp_5_1
	expert_5_1_1 -> tp_5_1
	gate_5 -> route_5_2
	route_5_2 -> expert_5_2_0
	route_5_2 -> expert_5_2_1
	expert_5_2_0 -> tp_5_2
	expert_5_2_1 -> tp_5_2
	gate_5 -> route_5_3
	route_5_3 -> expert_5_3_0
	route_5_3 -> expert_5_3_1
	expert_5_3_0 -> tp_5_3
	expert_5_3_1 -> tp_5_3
	gate_5 -> route_5_4
	route_5_4 -> expert_5_4_0
	route_5_4 -> expert_5_4_1
	expert_5_4_0 -> tp_5_4
	expert_5_4_1 -> tp_5_4
	gate_5 -> route_5_5
	route_5_5 -> expert_5_5_0
	route_5_5 -> expert_5_5_1
	expert_5_5_0 -> tp_5_5
	expert_5_5_1 -> tp_5_5
	gate_5 -> route_5_6
	route_5_6 -> expert_5_6_0
	route_5_6 -> expert_5_6_1
	expert_5_6_0 -> tp_5_6
	expert_5_6_1 -> tp_5_6
	gate_5 -> route_5_7
	route_5_7 -> expert_5_7_0
	route_5_7 -> expert_5_7_1
	expert_5_7_0 -> tp_5_7
	expert_5_7_1 -> tp_5_7
	gate_5 -> route_5_8
	route_5_8 -> expert_5_8_0
	route_5_8 -> expert_5_8_1
	expert_5_8_0 -> tp_5_8
	expert_5_8_1 -> tp_5_8
	gate_5 -> route_5_9
	route_5_9 -> expert_5_9_0
	route_5_9 -> expert_5_9_1
	expert_5_9_0 -> tp_5_9
	expert_5_9_1 -> tp_5_9
	gate_5 -> route_5_10
	route_5_10 -> expert_5_10_0
	route_5_10 -> expert_5_10_1
	expert_5_10_0 -> tp_5_10
	expert_5_10_1 -> tp_5_10
	gate_5 -> route_5_11
	route_5_11 -> expert_5_11_0
	route_5_11 -> expert_5_11_1
	expert_5_11_0 -> tp_5_11
	expert_5_11_1 -> tp_5_11
	gate_5 -> route_5_12
	route_5_12 -> expert_5_12_0
	route_5_12 -> expert_5_12_1
	expert_5_12_0 -> tp_5_12
	expert_5_12_1 -> tp_5_12
	gate_5 -> route_5_13
	route_5_13 -> expert_5_13_0
	route_5_13 -> expert_5_13_1
	expert_5_13_0 -> tp_5_13
	expert_5_13_1 -> tp_5_13
	gate_5 -> route_5_14
	route_5_14 -> expert_5_14_0
	route_5_14 -> expert_5_14_1
	expert_5_14_0 -> tp_5_14
	expert_5_14_1 -> tp_5_14
	gate_5 -> route_5_15
	route_5_15 -> expert_5_15_0
	route_5_15 -> expert_5_15_1
	expert_5_15_0 -> tp_5_15
	expert_5_15_1 -> tp_5_15
	q_proj_6 -> attn_scores_6
	k_proj_6 -> attn_scores_6
	v_proj_6 -> attn_scores_6
	attn_scores_6 -> softmax_6
	softmax_6 -> attn_out_6
	attn_out_6 -> gate_6
	gate_6 -> route_6_0
	route_6_0 -> expert_6_0_0
	route_6_0 -> expert_6_0_1
	expert_6_0_0 -> tp_6_0
	expert_6_0_1 -> tp_6_0
	gate_6 -> route_6_1
	route_6_1 -> expert_6_1_0
	route_6_1 -> expert_6_1_1
	expert_6_1_0 -> tp_6_1
	expert_6_1_1 -> tp_6_1
	gate_6 -> route_6_2
	route_6_2 -> expert_6_2_0
	route_6_2 -> expert_6_2_1
	expert_6_2_0 -> tp_6_2
	expert_6_2_1 -> tp_6_2
	gate_6 -> route_6_3
	route_6_3 -> expert_6_3_0
	route_6_3 -> expert_6_3_1
	expert_6_3_0 -> tp_6_3
	expert_6_3_1 -> tp_6_3
	gate_6 -> route_6_4
	route_6_4 -> expert_6_4_0
	route_6_4 -> expert_6_4_1
	expert_6_4_0 -> tp_6_4
	expert_6_4_1 -> tp_6_4
	gate_6 -> route_6_5
	route_6_5 -> expert_6_5_0
	route_6_5 -> expert_6_5_1
	expert_6_5_0 -> tp_6_5
	expert_6_5_1 -> tp_6_5
	gate_6 -> route_6_6
	route_6_6 -> expert_6_6_0
	route_6_6 -> expert_6_6_1
	expert_6_6_0 -> tp_6_6
	expert_6_6_1 -> tp_6_6
	gate_6 -> route_6_7
	route_6_7 -> expert_6_7_0
	route_6_7 -> expert_6_7_1
	expert_6_7_0 -> tp_6_7
	expert_6_7_1 -> tp_6_7
	gate_6 -> route_6_8
	route_6_8 -> expert_6_8_0
	route_6_8 -> expert_6_8_1
	expert_6_8_0 -> tp_6_8
	expert_6_8_1 -> tp_6_8
	gate_6 -> route_6_9
	route_6_9 -> expert_6_9_0
	route_6_9 -> expert_6_9_1
	expert_6_9_0 -> tp_6_9
	expert_6_9_1 -> tp_6_9
	gate_6 -> route_6_10
	route_6_10 -> expert_6_10_0
	route_6_10 -> expert_6_10_1
	expert_6_10_0 -> tp_6_10
	expert_6_10_1 -> tp_6_10
	gate_6 -> route_6_11
	route_6_11 -> expert_6_11_0
	route_6_11 -> expert_6_11_1
	expert_6_11_0 -> tp_6_11
	expert_6_11_1 -> tp_6_11
	gate_6 -> route_6_12
	route_6_12 -> expert_6_12_0
	route_6_12 -> expert_6_12_1
	expert_6_12_0 -> tp_6_12
	expert_6_12_1 -> tp_6_12
	gate_6 -> route_6_13
	route_6_13 -> expert_6_13_0
	route_6_13 -> expert_6_13_1
	expert_6_13_0 -> tp_6_13
	expert_6_13_1 -> tp_6_13
	gate_6 -> route_6_14
	route_6_14 -> expert_6_14_0
	route_6_14 -> expert_6_14_1
	expert_6_14_0 -> tp_6_14
	expert_6_14_1 -> tp_6_14
	gate_6 -> route_6_15
	route_6_15 -> expert_6_15_0
	route_6_15 -> expert_6_15_1
	expert_6_15_0 -> tp_6_15
	expert_6_15_1 -> tp_6_15
	q_proj_7 -> attn_scores_7
	k_proj_7 -> attn_scores_7
	v_proj_7 -> attn_scores_7
	attn_scores_7 -> softmax_7
	softmax_7 -> attn_out_7
	attn_out_7 -> gate_7
	gate_7 -> route_7_0
	route_7_0 -> expert_7_0_0
	route_7_0 -> expert_7_0_1
	expert_7_0_0 -> tp_7_0
	expert_7_0_1 -> tp_7_0
	gate_7 -> route_7_1
	route_7_1 -> expert_7_1_0
	route_7_1 -> expert_7_1_1
	expert_7_1_0 -> tp_7_1
	expert_7_1_1 -> tp_7_1
	gate_7 -> route_7_2
	route_7_2 -> expert_7_2_0
	route_7_2 -> expert_7_2_1
	expert_7_2_0 -> tp_7_2
	expert_7_2_1 -> tp_7_2
	gate_7 -> route_7_3
	route_7_3 -> expert_7_3_0
	route_7_3 -> expert_7_3_1
	expert_7_3_0 -> tp_7_3
	expert_7_3_1 -> tp_7_3
	gate_7 -> route_7_4
	route_7_4 -> expert_7_4_0
	route_7_4 -> expert_7_4_1
	expert_7_4_0 -> tp_7_4
	expert_7_4_1 -> tp_7_4
	gate_7 -> route_7_5
	route_7_5 -> expert_7_5_0
	route_7_5 -> expert_7_5_1
	expert_7_5_0 -> tp_7_5
	expert_7_5_1 -> tp_7_5
	gate_7 -> route_7_6
	route_7_6 -> expert_7_6_0
	route_7_6 -> expert_7_6_1
	expert_7_6_0 -> tp_7_6
	expert_7_6_1 -> tp_7_6
	gate_7 -> route_7_7
	route_7_7 -> expert_7_7_0
	route_7_7 -> expert_7_7_1
	expert_7_7_0 -> tp_7_7
	expert_7_7_1 -> tp_7_7
	gate_7 -> route_7_8
	route_7_8 -> expert_7_8_0
	route_7_8 -> expert_7_8_1
	expert_7_8_0 -> tp_7_8
	expert_7_8_1 -> tp_7_8
	gate_7 -> route_7_9
	route_7_9 -> expert_7_9_0
	route_7_9 -> expert_7_9_1
	expert_7_9_0 -> tp_7_9
	expert_7_9_1 -> tp_7_9
	gate_7 -> route_7_10
	route_7_10 -> expert_7_10_0
	route_7_10 -> expert_7_10_1
	expert_7_10_0 -> tp_7_10
	expert_7_10_1 -> tp_7_10
	gate_7 -> route_7_11
	route_7_11 -> expert_7_11_0
	route_7_11 -> expert_7_11_1
	expert_7_11_0 -> tp_7_11
	expert_7_11_1 -> tp_7_11
	gate_7 -> route_7_12
	route_7_12 -> expert_7_12_0
	route_7_12 -> expert_7_12_1
	expert_7_12_0 -> tp_7_12
	expert_7_12_1 -> tp_7_12
	gate_7 -> route_7_13
	route_7_13 -> expert_7_13_0
	route_7_13 -> expert_7_13_1
	expert_7_13_0 -> tp_7_13
	expert_7_13_1 -> tp_7_13
	gate_7 -> route_7_14
	route_7_14 -> expert_7_14_0
	route_7_14 -> expert_7_14_1
	expert_7_14_0 -> tp_7_14
	expert_7_14_1 -> tp_7_14
	gate_7 -> route_7_15
	route_7_15 -> expert_7_15_0
	route_7_15 -> expert_7_15_1
	expert_7_15_0 -> tp_7_15
	expert_7_15_1 -> tp_7_15
	q_proj_8 -> attn_scores_8
	k_proj_8 -> attn_scores_8
	v_proj_8 -> attn_scores_8
	attn_scores_8 -> softmax_8
	softmax_8 -> attn_out_8
	attn_out_8 -> gate_8
	gate_8 -> route_8_0
	route_8_0 -> expert_8_0_0
	route_8_0 -> expert_8_0_1
	expert_8_0_0 -> tp_8_0
	expert_8_0_1 -> tp_8_0
	gate_8 -> route_8_1
	route_8_1 -> expert_8_1_0
	route_8_1 -> expert_8_1_1
	expert_8_1_0 -> tp_8_1
	expert_8_1_1 -> tp_8_1
	gate_8 -> route_8_2
	route_8_2 -> expert_8_2_0
	route_8_2 -> expert_8_2_1
	expert_8_2_0 -> tp_8_2
	expert_8_2_1 -> tp_8_2
	gate_8 -> route_8_3
	route_8_3 -> expert_8_3_0
	route_8_3 -> expert_8_3_1
	expert_8_3_0 -> tp_8_3
	expert_8_3_1 -> tp_8_3
	gate_8 -> route_8_4
	route_8_4 -> expert_8_4_0
	route_8_4 -> expert_8_4_1
	expert_8_4_0 -> tp_8_4
	expert_8_4_1 -> tp_8_4
	gate_8 -> route_8_5
	route_8_5 -> expert_8_5_0
	route_8_5 -> expert_8_5_1
	expert_8_5_0 -> tp_8_5
	expert_8_5_1 -> tp_8_5
	gate_8 -> route_8_6
	route_8_6 -> expert_8_6_0
	route_8_6 -> expert_8_6_1
	expert_8_6_0 -> tp_8_6
	expert_8_6_1 -> tp_8_6
	gate_8 -> route_8_7
	route_8_7 -> expert_8_7_0
	route_8_7 -> expert_8_7_1
	expert_8_7_0 -> tp_8_7
	expert_8_7_1 -> tp_8_7
	gate_8 -> route_8_8
	route_8_8 -> expert_8_8_0
	route_8_8 -> expert_8_8_1
	expert_8_8_0 -> tp_8_8
	expert_8_8_1 -> tp_8_8
	gate_8 -> route_8_9
	route_8_9 -> expert_8_9_0
	route_8_9 -> expert_8_9_1
	expert_8_9_0 -> tp_8_9
	expert_8_9_1 -> tp_8_9
	gate_8 -> route_8_10
	route_8_10 -> expert_8_10_0
	route_8_10 -> expert_8_10_1
	expert_8_10_0 -> tp_8_10
	expert_8_10_1 -> tp_8_10
	gate_8 -> route_8_11
	route_8_11 -> expert_8_11_0
	route_8_11 -> expert_8_11_1
	expert_8_11_0 -> tp_8_11
	expert_8_11_1 -> tp_8_11
	gate_8 -> route_8_12
	route_8_12 -> expert_8_12_0
	route_8_12 -> expert_8_12_1
	expert_8_12_0 -> tp_8_12
	expert_8_12_1 -> tp_8_12
	gate_8 -> route_8_13
	route_8_13 -> expert_8_13_0
	route_8_13 -> expert_8_13_1
	expert_8_13_0 -> tp_8_13
	expert_8_13_1 -> tp_8_13
	gate_8 -> route_8_14
	route_8_14 -> expert_8_14_0
	route_8_14 -> expert_8_14_1
	expert_8_14_0 -> tp_8_14
	expert_8_14_1 -> tp_8_14
	gate_8 -> route_8_15
	route_8_15 -> expert_8_15_0
	route_8_15 -> expert_8_15_1
	expert_8_15_0 -> tp_8_15
	expert_8_15_1 -> tp_8_15
	q_proj_9 -> attn_scores_9
	k_proj_9 -> attn_scores_9
	v_proj_9 -> attn_scores_9
	attn_scores_9 -> softmax_9
	softmax_9 -> attn_out_9
	attn_out_9 -> gate_9
	gate_9 -> route_9_0
	route_9_0 -> expert_9_0_0
	route_9_0 -> expert_9_0_1
	expert_9_0_0 -> tp_9_0
	expert_9_0_1 -> tp_9_0
	gate_9 -> route_9_1
	route_9_1 -> expert_9_1_0
	route_9_1 -> expert_9_1_1
	expert_9_1_0 -> tp_9_1
	expert_9_1_1 -> tp_9_1
	gate_9 -> route_9_2
	route_9_2 -> expert_9_2_0
	route_9_2 -> expert_9_2_1
	expert_9_2_0 -> tp_9_2
	expert_9_2_1 -> tp_9_2
	gate_9 -> route_9_3
	route_9_3 -> expert_9_3_0
	route_9_3 -> expert_9_3_1
	expert_9_3_0 -> tp_9_3
	expert_9_3_1 -> tp_9_3
	gate_9 -> route_9_4
	route_9_4 -> expert_9_4_0
	route_9_4 -> expert_9_4_1
	expert_9_4_0 -> tp_9_4
	expert_9_4_1 -> tp_9_4
	gate_9 -> route_9_5
	route_9_5 -> expert_9_5_0
	route_9_5 -> expert_9_5_1
	expert_9_5_0 -> tp_9_5
	expert_9_5_1 -> tp_9_5
	gate_9 -> route_9_6
	route_9_6 -> expert_9_6_0
	route_9_6 -> expert_9_6_1
	expert_9_6_0 -> tp_9_6
	expert_9_6_1 -> tp_9_6
	gate_9 -> route_9_7
	route_9_7 -> expert_9_7_0
	route_9_7 -> expert_9_7_1
	expert_9_7_0 -> tp_9_7
	expert_9_7_1 -> tp_9_7
	gate_9 -> route_9_8
	route_9_8 -> expert_9_8_0
	route_9_8 -> expert_9_8_1
	expert_9_8_0 -> tp_9_8
	expert_9_8_1 -> tp_9_8
	gate_9 -> route_9_9
	route_9_9 -> expert_9_9_0
	route_9_9 -> expert_9_9_1
	expert_9_9_0 -> tp_9_9
	expert_9_9_1 -> tp_9_9
	gate_9 -> route_9_10
	route_9_10 -> expert_9_10_0
	route_9_10 -> expert_9_10_1
	expert_9_10_0 -> tp_9_10
	expert_9_10_1 -> tp_9_10
	gate_9 -> route_9_11
	route_9_11 -> expert_9_11_0
	route_9_11 -> expert_9_11_1
	expert_9_11_0 -> tp_9_11
	expert_9_11_1 -> tp_9_11
	gate_9 -> route_9_12
	route_9_12 -> expert_9_12_0
	route_9_12 -> expert_9_12_1
	expert_9_12_0 -> tp_9_12
	expert_9_12_1 -> tp_9_12
	gate_9 -> route_9_13
	route_9_13 -> expert_9_13_0
	route_9_13 -> expert_9_13_1
	expert_9_13_0 -> tp_9_13
	expert_9_13_1 -> tp_9_13
	gate_9 -> route_9_14
	route_9_14 -> expert_9_14_0
	route_9_14 -> expert_9_14_1
	expert_9_14_0 -> tp_9_14
	expert_9_14_1 -> tp_9_14
	gate_9 -> route_9_15
	route_9_15 -> expert_9_15_0
	route_9_15 -> expert_9_15_1
	expert_9_15_0 -> tp_9_15
	expert_9_15_1 -> tp_9_15
	q_proj_10 -> attn_scores_10
	k_proj_10 -> attn_scores_10
	v_proj_10 -> attn_scores_10
	attn_scores_10 -> softmax_10
	softmax_10 -> attn_out_10
	attn_out_10 -> gate_10
	gate_10 -> route_10_0
	route_10_0 -> expert_10_0_0
	route_10_0 -> expert_10_0_1
	expert_10_0_0 -> tp_10_0
	expert_10_0_1 -> tp_10_0
	gate_10 -> route_10_1
	route_10_1 -> expert_10_1_0
	route_10_1 -> expert_10_1_1
	expert_10_1_0 -> tp_10_1
	expert_10_1_1 -> tp_10_1
	gate_10 -> route_10_2
	route_10_2 -> expert_10_2_0
	route_10_2 -> expert_10_2_1
	expert_10_2_0 -> tp_10_2
	expert_10_2_1 -> tp_10_2
	gate_10 -> route_10_3
	route_10_3 -> expert_10_3_0
	route_10_3 -> expert_10_3_1
	expert_10_3_0 -> tp_10_3
	expert_10_3_1 -> tp_10_3
	gate_10 -> route_10_4
	route_10_4 -> expert_10_4_0
	route_10_4 -> expert_10_4_1
	expert_10_4_0 -> tp_10_4
	expert_10_4_1 -> tp_10_4
	gate_10 -> route_10_5
	route_10_5 -> expert_10_5_0
	route_10_5 -> expert_10_5_1
	expert_10_5_0 -> tp_10_5
	expert_10_5_1 -> tp_10_5
	gate_10 -> route_10_6
	route_10_6 -> expert_10_6_0
	route_10_6 -> expert_10_6_1
	expert_10_6_0 -> tp_10_6
	expert_10_6_1 -> tp_10_6
	gate_10 -> route_10_7
	route_10_7 -> expert_10_7_0
	route_10_7 -> expert_10_7_1
	expert_10_7_0 -> tp_10_7
	expert_10_7_1 -> tp_10_7
	gate_10 -> route_10_8
	route_10_8 -> expert_10_8_0
	route_10_8 -> expert_10_8_1
	expert_10_8_0 -> tp_10_8
	expert_10_8_1 -> tp_10_8
	gate_10 -> route_10_9
	route_10_9 -> expert_10_9_0
	route_10_9 -> expert_10_9_1
	expert_10_9_0 -> tp_10_9
	expert_10_9_1 -> tp_10_9
	gate_10 -> route_10_10
	route_10_10 -> expert_10_10_0
	route_10_10 -> expert_10_10_1
	expert_10_10_0 -> tp_10_10
	expert_10_10_1 -> tp_10_10
	gate_10 -> route_10_11
	route_10_11 -> expert_10_11_0
	route_10_11 -> expert_10_11_1
	expert_10_11_0 -> tp_10_11
	expert_10_11_1 -> tp_10_11
	gate_10 -> route_10_12
	route_10_12 -> expert_10_12_0
	route_10_12 -> expert_10_12_1
	expert_10_12_0 -> tp_10_12
	expert_10_12_1 -> tp_10_12
	gate_10 -> route_10_13
	route_10_13 -> expert_10_13_0
	route_10_13 -> expert_10_13_1
	expert_10_13_0 -> tp_10_13
	expert_10_13_1 -> tp_10_13
	gate_10 -> route_10_14
	route_10_14 -> expert_10_14_0
	route_10_14 -> expert_10_14_1
	expert_10_14_0 -> tp_10_14
	expert_10_14_1 -> tp_10_14
	gate_10 -> route_10_15
	route_10_15 -> expert_10_15_0
	route_10_15 -> expert_10_15_1
	expert_10_15_0 -> tp_10_15
	expert_10_15_1 -> tp_10_15
	q_proj_11 -> attn_scores_11
	k_proj_11 -> attn_scores_11
	v_proj_11 -> attn_scores_11
	attn_scores_11 -> softmax_11
	softmax_11 -> attn_out_11
	attn_out_11 -> gate_11
	gate_11 -> route_11_0
	route_11_0 -> expert_11_0_0
	route_11_0 -> expert_11_0_1
	expert_11_0_0 -> tp_11_0
	expert_11_0_1 -> tp_11_0
	gate_11 -> route_11_1
	route_11_1 -> expert_11_1_0
	route_11_1 -> expert_11_1_1
	expert_11_1_0 -> tp_11_1
	expert_11_1_1 -> tp_11_1
	gate_11 -> route_11_2
	route_11_2 -> expert_11_2_0
	route_11_2 -> expert_11_2_1
	expert_11_2_0 -> tp_11_2
	expert_11_2_1 -> tp_11_2
	gate_11 -> route_11_3
	route_11_3 -> expert_11_3_0
	route_11_3 -> expert_11_3_1
	expert_11_3_0 -> tp_11_3
	expert_11_3_1 -> tp_11_3
	gate_11 -> route_11_4
	route_11_4 -> expert_11_4_0
	route_11_4 -> expert_11_4_1
	expert_11_4_0 -> tp_11_4
	expert_11_4_1 -> tp_11_4
	gate_11 -> route_11_5
	route_11_5 -> expert_11_5_0
	route_11_5 -> expert_11_5_1
	expert_11_5_0 -> tp_11_5
	expert_11_5_1 -> tp_11_5
	gate_11 -> route_11_6
	route_11_6 -> expert_11_6_0
	route_11_6 -> expert_11_6_1
	expert_11_6_0 -> tp_11_6
	expert_11_6_1 -> tp_11_6
	gate_11 -> route_11_7
	route_11_7 -> expert_11_7_0
	route_11_7 -> expert_11_7_1
	expert_11_7_0 -> tp_11_7
	expert_11_7_1 -> tp_11_7
	gate_11 -> route_11_8
	route_11_8 -> expert_11_8_0
	route_11_8 -> expert_11_8_1
	expert_11_8_0 -> tp_11_8
	expert_11_8_1 -> tp_11_8
	gate_11 -> route_11_9
	route_11_9 -> expert_11_9_0
	route_11_9 -> expert_11_9_1
	expert_11_9_0 -> tp_11_9
	expert_11_9_1 -> tp_11_9
	gate_11 -> route_11_10
	route_11_10 -> expert_11_10_0
	route_11_10 -> expert_11_10_1
	expert_11_10_0 -> tp_11_10
	expert_11_10_1 -> tp_11_10
	gate_11 -> route_11_11
	route_11_11 -> expert_11_11_0
	route_11_11 -> expert_11_11_1
	expert_11_11_0 -> tp_11_11
	expert_11_11_1 -> tp_11_11
	gate_11 -> route_11_12
	route_11_12 -> expert_11_12_0
	route_11_12 -> expert_11_12_1
	expert_11_12_0 -> tp_11_12
	expert_11_12_1 -> tp_11_12
	gate_11 -> route_11_13
	route_11_13 -> expert_11_13_0
	route_11_13 -> expert_11_13_1
	expert_11_13_0 -> tp_11_13
	expert_11_13_1 -> tp_11_13
	gate_11 -> route_11_14
	route_11_14 -> expert_11_14_0
	route_11_14 -> expert_11_14_1
	expert_11_14_0 -> tp_11_14
	expert_11_14_1 -> tp_11_14
	gate_11 -> route_11_15
	route_11_15 -> expert_11_15_0
	route_11_15 -> expert_11_15_1
	expert_11_15_0 -> tp_11_15
	expert_11_15_1 -> tp_11_15
	q_proj_12 -> attn_scores_12
	k_proj_12 -> attn_scores_12
	v_proj_12 -> attn_scores_12
	attn_scores_12 -> softmax_12
	softmax_12 -> attn_out_12
	attn_out_12 -> gate_12
	gate_12 -> route_12_0
	route_12_0 -> expert_12_0_0
	route_12_0 -> expert_12_0_1
	expert_12_0_0 -> tp_12_0
	expert_12_0_1 -> tp_12_0
	gate_12 -> route_12_1
	route_12_1 -> expert_12_1_0
	route_12_1 -> expert_12_1_1
	expert_12_1_0 -> tp_12_1
	expert_12_1_1 -> tp_12_1
	gate_12 -> route_12_2
	route_12_2 -> expert_12_2_0
	route_12_2 -> expert_12_2_1
	expert_12_2_0 -> tp_12_2
	expert_12_2_1 -> tp_12_2
	gate_12 -> route_12_3
	route_12_3 -> expert_12_3_0
	route_12_3 -> expert_12_3_1
	expert_12_3_0 -> tp_12_3
	expert_12_3_1 -> tp_12_3
	gate_12 -> route_12_4
	route_12_4 -> expert_12_4_0
	route_12_4 -> expert_12_4_1
	expert_12_4_0 -> tp_12_4
	expert_12_4_1 -> tp_12_4
	gate_12 -> route_12_5
	route_12_5 -> expert_12_5_0
	route_12_5 -> expert_12_5_1
	expert_12_5_0 -> tp_12_5
	expert_12_5_1 -> tp_12_5
	gate_12 -> route_12_6
	route_12_6 -> expert_12_6_0
	route_12_6 -> expert_12_6_1
	expert_12_6_0 -> tp_12_6
	expert_12_6_1 -> tp_12_6
	gate_12 -> route_12_7
	route_12_7 -> expert_12_7_0
	route_12_7 -> expert_12_7_1
	expert_12_7_0 -> tp_12_7
	expert_12_7_1 -> tp_12_7
	gate_12 -> route_12_8
	route_12_8 -> expert_12_8_0
	route_12_8 -> expert_12_8_1
	expert_12_8_0 -> tp_12_8
	expert_12_8_1 -> tp_12_8
	gate_12 -> route_12_9
	route_12_9 -> expert_12_9_0
	route_12_9 -> expert_12_9_1
	expert_12_9_0 -> tp_12_9
	expert_12_9_1 -> tp_12_9
	gate_12 -> route_12_10
	route_12_10 -> expert_12_10_0
	route_12_10 -> expert_12_10_1
	expert_12_10_0 -> tp_12_10
	expert_12_10_1 -> tp_12_10
	gate_12 -> route_12_11
	route_12_11 -> expert_12_11_0
	route_12_11 -> expert_12_11_1
	expert_12_11_0 -> tp_12_11
	expert_12_11_1 -> tp_12_11
	gate_12 -> route_12_12
	route_12_12 -> expert_12_12_0
	route_12_12 -> expert_12_12_1
	expert_12_12_0 -> tp_12_12
	expert_12_12_1 -> tp_12_12
	gate_12 -> route_12_13
	route_12_13 -> expert_12_13_0
	route_12_13 -> expert_12_13_1
	expert_12_13_0 -> tp_12_13
	expert_12_13_1 -> tp_12_13
	gate_12 -> route_12_14
	route_12_14 -> expert_12_14_0
	route_12_14 -> expert_12_14_1
	expert_12_14_0 -> tp_12_14
	expert_12_14_1 -> tp_12_14
	gate_12 -> route_12_15
	route_12_15 -> expert_12_15_0
	route_12_15 -> expert_12_15_1
	expert_12_15_0 -> tp_12_15
	expert_12_15_1 -> tp_12_15
	q_proj_13 -> attn_scores_13
	k_proj_13 -> attn_scores_13
	v_proj_13 -> attn_scores_13
	attn_scores_13 -> softmax_13
	softmax_13 -> attn_out_13
	attn_out_13 -> gate_13
	gate_13 -> route_13_0
	route_13_0 -> expert_13_0_0
	route_13_0 -> expert_13_0_1
	expert_13_0_0 -> tp_13_0
	expert_13_0_1 -> tp_13_0
	gate_13 -> route_13_1
	route_13_1 -> expert_13_1_0
	route_13_1 -> expert_13_1_1
	expert_13_1_0 -> tp_13_1
	expert_13_1_1 -> tp_13_1
	gate_13 -> route_13_2
	route_13_2 -> expert_13_2_0
	route_13_2 -> expert_13_2_1
	expert_13_2_0 -> tp_13_2
	expert_13_2_1 -> tp_13_2
	gate_13 -> route_13_3
	route_13_3 -> expert_13_3_0
	route_13_3 -> expert_13_3_1
	expert_13_3_0 -> tp_13_3
	expert_13_3_1 -> tp_13_3
	gate_13 -> route_13_4
	route_13_4 -> expert_13_4_0
	route_13_4 -> expert_13_4_1
	expert_13_4_0 -> tp_13_4
	expert_13_4_1 -> tp_13_4
	gate_13 -> route_13_5
	route_13_5 -> expert_13_5_0
	route_13_5 -> expert_13_5_1
	expert_13_5_0 -> tp_13_5
	expert_13_5_1 -> tp_13_5
	gate_13 -> route_13_6
	route_13_6 -> expert_13_6_0
	route_13_6 -> expert_13_6_1
	expert_13_6_0 -> tp_13_6
	expert_13_6_1 -> tp_13_6
	gate_13 -> route_13_7
	route_13_7 -> expert_13_7_0
	route_13_7 -> expert_13_7_1
	expert_13_7_0 -> tp_13_7
	expert_13_7_1 -> tp_13_7
	gate_13 -> route_13_8
	route_13_8 -> expert_13_8_0
	route_13_8 -> expert_13_8_1
	expert_13_8_0 -> tp_13_8
	expert_13_8_1 -> tp_13_8
	gate_13 -> route_13_9
	route_13_9 -> expert_13_9_0
	route_13_9 -> expert_13_9_1
	expert_13_9_0 -> tp_13_9
	expert_13_9_1 -> tp_13_9
	gate_13 -> route_13_10
	route_13_10 -> expert_13_10_0
	route_13_10 -> expert_13_10_1
	expert_13_10_0 -> tp_13_10
	expert_13_10_1 -> tp_13_10
	gate_13 -> route_13_11
	route_13_11 -> expert_13_11_0
	route_13_11 -> expert_13_11_1
	expert_13_11_0 -> tp_13_11
	expert_13_11_1 -> tp_13_11
	gate_13 -> route_13_12
	route_13_12 -> expert_13_12_0
	route_13_12 -> expert_13_12_1
	expert_13_12_0 -> tp_13_12
	expert_13_12_1 -> tp_13_12
	gate_13 -> route_13_13
	route_13_13 -> expert_13_13_0
	route_13_13 -> expert_13_13_1
	expert_13_13_0 -> tp_13_13
	expert_13_13_1 -> tp_13_13
	gate_13 -> route_13_14
	route_13_14 -> expert_13_14_0
	route_13_14 -> expert_13_14_1
	expert_13_14_0 -> tp_13_14
	expert_13_14_1 -> tp_13_14
	gate_13 -> route_13_15
	route_13_15 -> expert_13_15_0
	route_13_15 -> expert_13_15_1
	expert_13_15_0 -> tp_13_15
	expert_13_15_1 -> tp_13_15
	q_proj_14 -> attn_scores_14
	k_proj_14 -> attn_scores_14
	v_proj_14 -> attn_scores_14
	attn_scores_14 -> softmax_14
	softmax_14 -> attn_out_14
	attn_out_14 -> gate_14
	gate_14 -> route_14_0
	route_14_0 -> expert_14_0_0
	route_14_0 -> expert_14_0_1
	expert_14_0_0 -> tp_14_0
	expert_14_0_1 -> tp_14_0
	gate_14 -> route_14_1
	route_14_1 -> expert_14_1_0
	route_14_1 -> expert_14_1_1
	expert_14_1_0 -> tp_14_1
	expert_14_1_1 -> tp_14_1
	gate_14 -> route_14_2
	route_14_2 -> expert_14_2_0
	route_14_2 -> expert_14_2_1
	expert_14_2_0 -> tp_14_2
	expert_14_2_1 -> tp_14_2
	gate_14 -> route_14_3
	route_14_3 -> expert_14_3_0
	route_14_3 -> expert_14_3_1
	expert_14_3_0 -> tp_14_3
	expert_14_3_1 -> tp_14_3
	gate_14 -> route_14_4
	route_14_4 -> expert_14_4_0
	route_14_4 -> expert_14_4_1
	expert_14_4_0 -> tp_14_4
	expert_14_4_1 -> tp_14_4
	gate_14 -> route_14_5
	route_14_5 -> expert_14_5_0
	route_14_5 -> expert_14_5_1
	expert_14_5_0 -> tp_14_5
	expert_14_5_1 -> tp_14_5
	gate_14 -> route_14_6
	route_14_6 -> expert_14_6_0
	route_14_6 -> expert_14_6_1
	expert_14_6_0 -> tp_14_6
	expert_14_6_1 -> tp_14_6
	gate_14 -> route_14_7
	route_14_7 -> expert_14_7_0
	route_14_7 -> expert_14_7_1
	expert_14_7_0 -> tp_14_7
	expert_14_7_1 -> tp_14_7
	gate_14 -> route_14_8
	route_14_8 -> expert_14_8_0
	route_14_8 -> expert_14_8_1
	expert_14_8_0 -> tp_14_8
	expert_14_8_1 -> tp_14_8
	gate_14 -> route_14_9
	route_14_9 -> expert_14_9_0
	route_14_9 -> expert_14_9_1
	expert_14_9_0 -> tp_14_9
	expert_14_9_1 -> tp_14_9
	gate_14 -> route_14_10
	route_14_10 -> expert_14_10_0
	route_14_10 -> expert_14_10_1
	expert_14_10_0 -> tp_14_10
	expert_14_10_1 -> tp_14_10
	gate_14 -> route_14_11
	route_14_11 -> expert_14_11_0
	route_14_11 -> expert_14_11_1
	expert_14_11_0 -> tp_14_11
	expert_14_11_1 -> tp_14_11
	gate_14 -> route_14_12
	route_14_12 -> expert_14_12_0
	route_14_12 -> expert_14_12_1
	expert_14_12_0 -> tp_14_12
	expert_14_12_1 -> tp_14_12
	gate_14 -> route_14_13
	route_14_13 -> expert_14_13_0
	route_14_13 -> expert_14_13_1
	expert_14_13_0 -> tp_14_13
	expert_14_13_1 -> tp_14_13
	gate_14 -> route_14_14
	route_14_14 -> expert_14_14_0
	route_14_14 -> expert_14_14_1
	expert_14_14_0 -> tp_14_14
	expert_14_14_1 -> tp_14_14
	gate_14 -> route_14_15
	route_14_15 -> expert_14_15_0
	route_14_15 -> expert_14_15_1
	expert_14_15_0 -> tp_14_15
	expert_14_15_1 -> tp_14_15
	q_proj_15 -> attn_scores_15
	k_proj_15 -> attn_scores_15
	v_proj_15 -> attn_scores_15
	attn_scores_15 -> softmax_15
	softmax_15 -> attn_out_15
	attn_out_15 -> gate_15
	gate_15 -> route_15_0
	route_15_0 -> expert_15_0_0
	route_15_0 -> expert_15_0_1
	expert_15_0_0 -> tp_15_0
	expert_15_0_1 -> tp_15_0
	gate_15 -> route_15_1
	route_15_1 -> expert_15_1_0
	route_15_1 -> expert_15_1_1
	expert_15_1_0 -> tp_15_1
	expert_15_1_1 -> tp_15_1
	gate_15 -> route_15_2
	route_15_2 -> expert_15_2_0
	route_15_2 -> expert_15_2_1
	expert_15_2_0 -> tp_15_2
	expert_15_2_1 -> tp_15_2
	gate_15 -> route_15_3
	route_15_3 -> expert_15_3_0
	route_15_3 -> expert_15_3_1
	expert_15_3_0 -> tp_15_3
	expert_15_3_1 -> tp_15_3
	gate_15 -> route_15_4
	route_15_4 -> expert_15_4_0
	route_15_4 -> expert_15_4_1
	expert_15_4_0 -> tp_15_4
	expert_15_4_1 -> tp_15_4
	gate_15 -> route_15_5
	route_15_5 -> expert_15_5_0
	route_15_5 -> expert_15_5_1
	expert_15_5_0 -> tp_15_5
	expert_15_5_1 -> tp_15_5
	gate_15 -> route_15_6
	route_15_6 -> expert_15_6_0
	route_15_6 -> expert_15_6_1
	expert_15_6_0 -> tp_15_6
	expert_15_6_1 -> tp_15_6
	gate_15 -> route_15_7
	route_15_7 -> expert_15_7_0
	route_15_7 -> expert_15_7_1
	expert_15_7_0 -> tp_15_7
	expert_15_7_1 -> tp_15_7
	gate_15 -> route_15_8
	route_15_8 -> expert_15_8_0
	route_15_8 -> expert_15_8_1
	expert_15_8_0 -> tp_15_8
	expert_15_8_1 -> tp_15_8
	gate_15 -> route_15_9
	route_15_9 -> expert_15_9_0
	route_15_9 -> expert_15_9_1
	expert_15_9_0 -> tp_15_9
	expert_15_9_1 -> tp_15_9
	gate_15 -> route_15_10
	route_15_10 -> expert_15_10_0
	route_15_10 -> expert_15_10_1
	expert_15_10_0 -> tp_15_10
	expert_15_10_1 -> tp_15_10
	gate_15 -> route_15_11
	route_15_11 -> expert_15_11_0
	route_15_11 -> expert_15_11_1
	expert_15_11_0 -> tp_15_11
	expert_15_11_1 -> tp_15_11
	gate_15 -> route_15_12
	route_15_12 -> expert_15_12_0
	route_15_12 -> expert_15_12_1
	expert_15_12_0 -> tp_15_12
	expert_15_12_1 -> tp_15_12
	gate_15 -> route_15_13
	route_15_13 -> expert_15_13_0
	route_15_13 -> expert_15_13_1
	expert_15_13_0 -> tp_15_13
	expert_15_13_1 -> tp_15_13
	gate_15 -> route_15_14
	route_15_14 -> expert_15_14_0
	route_15_14 -> expert_15_14_1
	expert_15_14_0 -> tp_15_14
	expert_15_14_1 -> tp_15_14
	gate_15 -> route_15_15
	route_15_15 -> expert_15_15_0
	route_15_15 -> expert_15_15_1
	expert_15_15_0 -> tp_15_15
	expert_15_15_1 -> tp_15_15
	tp_0_0 -> q_proj_1
	tp_0_0 -> k_proj_1
	tp_0_0 -> v_proj_1
	tp_0_1 -> q_proj_1
	tp_0_1 -> k_proj_1
	tp_0_1 -> v_proj_1
	tp_0_2 -> q_proj_1
	tp_0_2 -> k_proj_1
	tp_0_2 -> v_proj_1
	tp_0_3 -> q_proj_1
	tp_0_3 -> k_proj_1
	tp_0_3 -> v_proj_1
	tp_0_4 -> q_proj_1
	tp_0_4 -> k_proj_1
	tp_0_4 -> v_proj_1
	tp_0_5 -> q_proj_1
	tp_0_5 -> k_proj_1
	tp_0_5 -> v_proj_1
	tp_0_6 -> q_proj_1
	tp_0_6 -> k_proj_1
	tp_0_6 -> v_proj_1
	tp_0_7 -> q_proj_1
	tp_0_7 -> k_proj_1
	tp_0_7 -> v_proj_1
	tp_0_8 -> q_proj_1
	tp_0_8 -> k_proj_1
	tp_0_8 -> v_proj_1
	tp_0_9 -> q_proj_1
	tp_0_9 -> k_proj_1
	tp_0_9 -> v_proj_1
	tp_0_10 -> q_proj_1
	tp_0_10 -> k_proj_1
	tp_0_10 -> v_proj_1
	tp_0_11 -> q_proj_1
	tp_0_11 -> k_proj_1
	tp_0_11 -> v_proj_1
	tp_0_12 -> q_proj_1
	tp_0_12 -> k_proj_1
	tp_0_12 -> v_proj_1
	tp_0_13 -> q_proj_1
	tp_0_13 -> k_proj_1
	tp_0_13 -> v_proj_1
	tp_0_14 -> q_proj_1
	tp_0_14 -> k_proj_1
	tp_0_14 -> v_proj_1
	tp_0_15 -> q_proj_1
	tp_0_15 -> k_proj_1
	tp_0_15 -> v_proj_1
	tp_1_0 -> q_proj_2
	tp_1_0 -> k_proj_2
	tp_1_0 -> v_proj_2
	tp_1_1 -> q_proj_2
	tp_1_1 -> k_proj_2
	tp_1_1 -> v_proj_2
	tp_1_2 -> q_proj_2
	tp_1_2 -> k_proj_2
	tp_1_2 -> v_proj_2
	tp_1_3 -> q_proj_2
	tp_1_3 -> k_proj_2
	tp_1_3 -> v_proj_2
	tp_1_4 -> q_proj_2
	tp_1_4 -> k_proj_2
	tp_1_4 -> v_proj_2
	tp_1_5 -> q_proj_2
	tp_1_5 -> k_proj_2
	tp_1_5 -> v_proj_2
	tp_1_6 -> q_proj_2
	tp_1_6 -> k_proj_2
	tp_1_6 -> v_proj_2
	tp_1_7 -> q_proj_2
	tp_1_7 -> k_proj_2
	tp_1_7 -> v_proj_2
	tp_1_8 -> q_proj_2
	tp_1_8 -> k_proj_2
	tp_1_8 -> v_proj_2
	tp_1_9 -> q_proj_2
	tp_1_9 -> k_proj_2
	tp_1_9 -> v_proj_2
	tp_1_10 -> q_proj_2
	tp_1_10 -> k_proj_2
	tp_1_10 -> v_proj_2
	tp_1_11 -> q_proj_2
	tp_1_11 -> k_proj_2
	tp_1_11 -> v_proj_2
	tp_1_12 -> q_proj_2
	tp_1_12 -> k_proj_2
	tp_1_12 -> v_proj_2
	tp_1_13 -> q_proj_2
	tp_1_13 -> k_proj_2
	tp_1_13 -> v_proj_2
	tp_1_14 -> q_proj_2
	tp_1_14 -> k_proj_2
	tp_1_14 -> v_proj_2
	tp_1_15 -> q_proj_2
	tp_1_15 -> k_proj_2
	tp_1_15 -> v_proj_2
	tp_2_0 -> q_proj_3
	tp_2_0 -> k_proj_3
	tp_2_0 -> v_proj_3
	tp_2_1 -> q_proj_3
	tp_2_1 -> k_proj_3
	tp_2_1 -> v_proj_3
	tp_2_2 -> q_proj_3
	tp_2_2 -> k_proj_3
	tp_2_2 -> v_proj_3
	tp_2_3 -> q_proj_3
	tp_2_3 -> k_proj_3
	tp_2_3 -> v_proj_3
	tp_2_4 -> q_proj_3
	tp_2_4 -> k_proj_3
	tp_2_4 -> v_proj_3
	tp_2_5 -> q_proj_3
	tp_2_5 -> k_proj_3
	tp_2_5 -> v_proj_3
	tp_2_6 -> q_proj_3
	tp_2_6 -> k_proj_3
	tp_2_6 -> v_proj_3
	tp_2_7 -> q_proj_3
	tp_2_7 -> k_proj_3
	tp_2_7 -> v_proj_3
	tp_2_8 -> q_proj_3
	tp_2_8 -> k_proj_3
	tp_2_8 -> v_proj_3
	tp_2_9 -> q_proj_3
	tp_2_9 -> k_proj_3
	tp_2_9 -> v_proj_3
	tp_2_10 -> q_proj_3
	tp_2_10 -> k_proj_3
	tp_2_10 -> v_proj_3
	tp_2_11 -> q_proj_3
	tp_2_11 -> k_proj_3
	tp_2_11 -> v_proj_3
	tp_2_12 -> q_proj_3
	tp_2_12 -> k_proj_3
	tp_2_12 -> v_proj_3
	tp_2_13 -> q_proj_3
	tp_2_13 -> k_proj_3
	tp_2_13 -> v_proj_3
	tp_2_14 -> q_proj_3
	tp_2_14 -> k_proj_3
	tp_2_14 -> v_proj_3
	tp_2_15 -> q_proj_3
	tp_2_15 -> k_proj_3
	tp_2_15 -> v_proj_3
	tp_3_0 -> q_proj_4
	tp_3_0 -> k_proj_4
	tp_3_0 -> v_proj_4
	tp_3_1 -> q_proj_4
	tp_3_1 -> k_proj_4
	tp_3_1 -> v_proj_4
	tp_3_2 -> q_proj_4
	tp_3_2 -> k_proj_4
	tp_3_2 -> v_proj_4
	tp_3_3 -> q_proj_4
	tp_3_3 -> k_proj_4
	tp_3_3 -> v_proj_4
	tp_3_4 -> q_proj_4
	tp_3_4 -> k_proj_4
	tp_3_4 -> v_proj_4
	tp_3_5 -> q_proj_4
	tp_3_5 -> k_proj_4
	tp_3_5 -> v_proj_4
	tp_3_6 -> q_proj_4
	tp_3_6 -> k_proj_4
	tp_3_6 -> v_proj_4
	tp_3_7 -> q_proj_4
	tp_3_7 -> k_proj_4
	tp_3_7 -> v_proj_4
	tp_3_8 -> q_proj_4
	tp_3_8 -> k_proj_4
	tp_3_8 -> v_proj_4
	tp_3_9 -> q_proj_4
	tp_3_9 -> k_proj_4
	tp_3_9 -> v_proj_4
	tp_3_10 -> q_proj_4
	tp_3_10 -> k_proj_4
	tp_3_10 -> v_proj_4
	tp_3_11 -> q_proj_4
	tp_3_11 -> k_proj_4
	tp_3_11 -> v_proj_4
	tp_3_12 -> q_proj_4
	tp_3_12 -> k_proj_4
	tp_3_12 -> v_proj_4
	tp_3_13 -> q_proj_4
	tp_3_13 -> k_proj_4
	tp_3_13 -> v_proj_4
	tp_3_14 -> q_proj_4
	tp_3_14 -> k_proj_4
	tp_3_14 -> v_proj_4
	tp_3_15 -> q_proj_4
	tp_3_15 -> k_proj_4
	tp_3_15 -> v_proj_4
	tp_4_0 -> q_proj_5
	tp_4_0 -> k_proj_5
	tp_4_0 -> v_proj_5
	tp_4_1 -> q_proj_5
	tp_4_1 -> k_proj_5
	tp_4_1 -> v_proj_5
	tp_4_2 -> q_proj_5
	tp_4_2 -> k_proj_5
	tp_4_2 -> v_proj_5
	tp_4_3 -> q_proj_5
	tp_4_3 -> k_proj_5
	tp_4_3 -> v_proj_5
	tp_4_4 -> q_proj_5
	tp_4_4 -> k_proj_5
	tp_4_4 -> v_proj_5
	tp_4_5 -> q_proj_5
	tp_4_5 -> k_proj_5
	tp_4_5 -> v_proj_5
	tp_4_6 -> q_proj_5
	tp_4_6 -> k_proj_5
	tp_4_6 -> v_proj_5
	tp_4_7 -> q_proj_5
	tp_4_7 -> k_proj_5
	tp_4_7 -> v_proj_5
	tp_4_8 -> q_proj_5
	tp_4_8 -> k_proj_5
	tp_4_8 -> v_proj_5
	tp_4_9 -> q_proj_5
	tp_4_9 -> k_proj_5
	tp_4_9 -> v_proj_5
	tp_4_10 -> q_proj_5
	tp_4_10 -> k_proj_5
	tp_4_10 -> v_proj_5
	tp_4_11 -> q_proj_5
	tp_4_11 -> k_proj_5
	tp_4_11 -> v_proj_5
	tp_4_12 -> q_proj_5
	tp_4_12 -> k_proj_5
	tp_4_12 -> v_proj_5
	tp_4_13 -> q_proj_5
	tp_4_13 -> k_proj_5
	tp_4_13 -> v_proj_5
	tp_4_14 -> q_proj_5
	tp_4_14 -> k_proj_5
	tp_4_14 -> v_proj_5
	tp_4_15 -> q_proj_5
	tp_4_15 -> k_proj_5
	tp_4_15 -> v_proj_5
	tp_5_0 -> q_proj_6
	tp_5_0 -> k_proj_6
	tp_5_0 -> v_proj_6
	tp_5_1 -> q_proj_6
	tp_5_1 -> k_proj_6
	tp_5_1 -> v_proj_6
	tp_5_2 -> q_proj_6
	tp_5_2 -> k_proj_6
	tp_5_2 -> v_proj_6
	tp_5_3 -> q_proj_6
	tp_5_3 -> k_proj_6
	tp_5_3 -> v_proj_6
	tp_5_4 -> q_proj_6
	tp_5_4 -> k_proj_6
	tp_5_4 -> v_proj_6
	tp_5_5 -> q_proj_6
	tp_5_5 -> k_proj_6
	tp_5_5 -> v_proj_6
	tp_5_6 -> q_proj_6
	tp_5_6 -> k_proj_6
	tp_5_6 -> v_proj_6
	tp_5_7 -> q_proj_6
	tp_5_7 -> k_proj_6
	tp_5_7 -> v_proj_6
	tp_5_8 -> q_proj_6
	tp_5_8 -> k_proj_6
	tp_5_8 -> v_proj_6
	tp_5_9 -> q_proj_6
	tp_5_9 -> k_proj_6
	tp_5_9 -> v_proj_6
	tp_5_10 -> q_proj_6
	tp_5_10 -> k_proj_6
	tp_5_10 -> v_proj_6
	tp_5_11 -> q_proj_6
	tp_5_11 -> k_proj_6
	tp_5_11 -> v_proj_6
	tp_5_12 -> q_proj_6
	tp_5_12 -> k_proj_6
	tp_5_12 -> v_proj_6
	tp_5_13 -> q_proj_6
	tp_5_13 -> k_proj_6
	tp_5_13 -> v_proj_6
	tp_5_14 -> q_proj_6
	tp_5_14 -> k_proj_6
	tp_5_14 -> v_proj_6
	tp_5_15 -> q_proj_6
	tp_5_15 -> k_proj_6
	tp_5_15 -> v_proj_6
	tp_6_0 -> q_proj_7
	tp_6_0 -> k_proj_7
	tp_6_0 -> v_proj_7
	tp_6_1 -> q_proj_7
	tp_6_1 -> k_proj_7
	tp_6_1 -> v_proj_7
	tp_6_2 -> q_proj_7
	tp_6_2 -> k_proj_7
	tp_6_2 -> v_proj_7
	tp_6_3 -> q_proj_7
	tp_6_3 -> k_proj_7
	tp_6_3 -> v_proj_7
	tp_6_4 -> q_proj_7
	tp_6_4 -> k_proj_7
	tp_6_4 -> v_proj_7
	tp_6_5 -> q_proj_7
	tp_6_5 -> k_proj_7
	tp_6_5 -> v_proj_7
	tp_6_6 -> q_proj_7
	tp_6_6 -> k_proj_7
	tp_6_6 -> v_proj_7
	tp_6_7 -> q_proj_7
	tp_6_7 -> k_proj_7
	tp_6_7 -> v_proj_7
	tp_6_8 -> q_proj_7
	tp_6_8 -> k_proj_7
	tp_6_8 -> v_proj_7
	tp_6_9 -> q_proj_7
	tp_6_9 -> k_proj_7
	tp_6_9 -> v_proj_7
	tp_6_10 -> q_proj_7
	tp_6_10 -> k_proj_7
	tp_6_10 -> v_proj_7
	tp_6_11 -> q_proj_7
	tp_6_11 -> k_proj_7
	tp_6_11 -> v_proj_7
	tp_6_12 -> q_proj_7
	tp_6_12 -> k_proj_7
	tp_6_12 -> v_proj_7
	tp_6_13 -> q_proj_7
	tp_6_13 -> k_proj_7
	tp_6_13 -> v_proj_7
	tp_6_14 -> q_proj_7
	tp_6_14 -> k_proj_7
	tp_6_14 -> v_proj_7
	tp_6_15 -> q_proj_7
	tp_6_15 -> k_proj_7
	tp_6_15 -> v_proj_7
	tp_7_0 -> q_proj_8
	tp_7_0 -> k_proj_8
	tp_7_0 -> v_proj_8
	tp_7_1 -> q_proj_8
	tp_7_1 -> k_proj_8
	tp_7_1 -> v_proj_8
	tp_7_2 -> q_proj_8
	tp_7_2 -> k_proj_8
	tp_7_2 -> v_proj_8
	tp_7_3 -> q_proj_8
	tp_7_3 -> k_proj_8
	tp_7_3 -> v_proj_8
	tp_7_4 -> q_proj_8
	tp_7_4 -> k_proj_8
	tp_7_4 -> v_proj_8
	tp_7_5 -> q_proj_8
	tp_7_5 -> k_proj_8
	tp_7_5 -> v_proj_8
	tp_7_6 -> q_proj_8
	tp_7_6 -> k_proj_8
	tp_7_6 -> v_proj_8
	tp_7_7 -> q_proj_8
	tp_7_7 -> k_proj_8
	tp_7_7 -> v_proj_8
	tp_7_8 -> q_proj_8
	tp_7_8 -> k_proj_8
	tp_7_8 -> v_proj_8
	tp_7_9 -> q_proj_8
	tp_7_9 -> k_proj_8
	tp_7_9 -> v_proj_8
	tp_7_10 -> q_proj_8
	tp_7_10 -> k_proj_8
	tp_7_10 -> v_proj_8
	tp_7_11 -> q_proj_8
	tp_7_11 -> k_proj_8
	tp_7_11 -> v_proj_8
	tp_7_12 -> q_proj_8
	tp_7_12 -> k_proj_8
	tp_7_12 -> v_proj_8
	tp_7_13 -> q_proj_8
	tp_7_13 -> k_proj_8
	tp_7_13 -> v_proj_8
	tp_7_14 -> q_proj_8
	tp_7_14 -> k_proj_8
	tp_7_14 -> v_proj_8
	tp_7_15 -> q_proj_8
	tp_7_15 -> k_proj_8
	tp_7_15 -> v_proj_8
	tp_8_0 -> q_proj_9
	tp_8_0 -> k_proj_9
	tp_8_0 -> v_proj_9
	tp_8_1 -> q_proj_9
	tp_8_1 -> k_proj_9
	tp_8_1 -> v_proj_9
	tp_8_2 -> q_proj_9
	tp_8_2 -> k_proj_9
	tp_8_2 -> v_proj_9
	tp_8_3 -> q_proj_9
	tp_8_3 -> k_proj_9
	tp_8_3 -> v_proj_9
	tp_8_4 -> q_proj_9
	tp_8_4 -> k_proj_9
	tp_8_4 -> v_proj_9
	tp_8_5 -> q_proj_9
	tp_8_5 -> k_proj_9
	tp_8_5 -> v_proj_9
	tp_8_6 -> q_proj_9
	tp_8_6 -> k_proj_9
	tp_8_6 -> v_proj_9
	tp_8_7 -> q_proj_9
	tp_8_7 -> k_proj_9
	tp_8_7 -> v_proj_9
	tp_8_8 -> q_proj_9
	tp_8_8 -> k_proj_9
	tp_8_8 -> v_proj_9
	tp_8_9 -> q_proj_9
	tp_8_9 -> k_proj_9
	tp_8_9 -> v_proj_9
	tp_8_10 -> q_proj_9
	tp_8_10 -> k_proj_9
	tp_8_10 -> v_proj_9
	tp_8_11 -> q_proj_9
	tp_8_11 -> k_proj_9
	tp_8_11 -> v_proj_9
	tp_8_12 -> q_proj_9
	tp_8_12 -> k_proj_9
	tp_8_12 -> v_proj_9
	tp_8_13 -> q_proj_9
	tp_8_13 -> k_proj_9
	tp_8_13 -> v_proj_9
	tp_8_14 -> q_proj_9
	tp_8_14 -> k_proj_9
	tp_8_14 -> v_proj_9
	tp_8_15 -> q_proj_9
	tp_8_15 -> k_proj_9
	tp_8_15 -> v_proj_9
	tp_9_0 -> q_proj_10
	tp_9_0 -> k_proj_10
	tp_9_0 -> v_proj_10
	tp_9_1 -> q_proj_10
	tp_9_1 -> k_proj_10
	tp_9_1 -> v_proj_10
	tp_9_2 -> q_proj_10
	tp_9_2 -> k_proj_10
	tp_9_2 -> v_proj_10
	tp_9_3 -> q_proj_10
	tp_9_3 -> k_proj_10
	tp_9_3 -> v_proj_10
	tp_9_4 -> q_proj_10
	tp_9_4 -> k_proj_10
	tp_9_4 -> v_proj_10
	tp_9_5 -> q_proj_10
	tp_9_5 -> k_proj_10
	tp_9_5 -> v_proj_10
	tp_9_6 -> q_proj_10
	tp_9_6 -> k_proj_10
	tp_9_6 -> v_proj_10
	tp_9_7 -> q_proj_10
	tp_9_7 -> k_proj_10
	tp_9_7 -> v_proj_10
	tp_9_8 -> q_proj_10
	tp_9_8 -> k_proj_10
	tp_9_8 -> v_proj_10
	tp_9_9 -> q_proj_10
	tp_9_9 -> k_proj_10
	tp_9_9 -> v_proj_10
	tp_9_10 -> q_proj_10
	tp_9_10 -> k_proj_10
	tp_9_10 -> v_proj_10
	tp_9_11 -> q_proj_10
	tp_9_11 -> k_proj_10
	tp_9_11 -> v_proj_10
	tp_9_12 -> q_proj_10
	tp_9_12 -> k_proj_10
	tp_9_12 -> v_proj_10
	tp_9_13 -> q_proj_10
	tp_9_13 -> k_proj_10
	tp_9_13 -> v_proj_10
	tp_9_14 -> q_proj_10
	tp_9_14 -> k_proj_10
	tp_9_14 -> v_proj_10
	tp_9_15 -> q_proj_10
	tp_9_15 -> k_proj_10
	tp_9_15 -> v_proj_10
	tp_10_0 -> q_proj_11
	tp_10_0 -> k_proj_11
	tp_10_0 -> v_proj_11
	tp_10_1 -> q_proj_11
	tp_10_1 -> k_proj_11
	tp_10_1 -> v_proj_11
	tp_10_2 -> q_proj_11
	tp_10_2 -> k_proj_11
	tp_10_2 -> v_proj_11
	tp_10_3 -> q_proj_11
	tp_10_3 -> k_proj_11
	tp_10_3 -> v_proj_11
	tp_10_4 -> q_proj_11
	tp_10_4 -> k_proj_11
	tp_10_4 -> v_proj_11
	tp_10_5 -> q_proj_11
	tp_10_5 -> k_proj_11
	tp_10_5 -> v_proj_11
	tp_10_6 -> q_proj_11
	tp_10_6 -> k_proj_11
	tp_10_6 -> v_proj_11
	tp_10_7 -> q_proj_11
	tp_10_7 -> k_proj_11
	tp_10_7 -> v_proj_11
	tp_10_8 -> q_proj_11
	tp_10_8 -> k_proj_11
	tp_10_8 -> v_proj_11
	tp_10_9 -> q_proj_11
	tp_10_9 -> k_proj_11
	tp_10_9 -> v_proj_11
	tp_10_10 -> q_proj_11
	tp_10_10 -> k_proj_11
	tp_10_10 -> v_proj_11
	tp_10_11 -> q_proj_11
	tp_10_11 -> k_proj_11
	tp_10_11 -> v_proj_11
	tp_10_12 -> q_proj_11
	tp_10_12 -> k_proj_11
	tp_10_12 -> v_proj_11
	tp_10_13 -> q_proj_11
	tp_10_13 -> k_proj_11
	tp_10_13 -> v_proj_11
	tp_10_14 -> q_proj_11
	tp_10_14 -> k_proj_11
	tp_10_14 -> v_proj_11
	tp_10_15 -> q_proj_11
	tp_10_15 -> k_proj_11
	tp_10_15 -> v_proj_11
	tp_11_0 -> q_proj_12
	tp_11_0 -> k_proj_12
	tp_11_0 -> v_proj_12
	tp_11_1 -> q_proj_12
	tp_11_1 -> k_proj_12
	tp_11_1 -> v_proj_12
	tp_11_2 -> q_proj_12
	tp_11_2 -> k_proj_12
	tp_11_2 -> v_proj_12
	tp_11_3 -> q_proj_12
	tp_11_3 -> k_proj_12
	tp_11_3 -> v_proj_12
	tp_11_4 -> q_proj_12
	tp_11_4 -> k_proj_12
	tp_11_4 -> v_proj_12
	tp_11_5 -> q_proj_12
	tp_11_5 -> k_proj_12
	tp_11_5 -> v_proj_12
	tp_11_6 -> q_proj_12
	tp_11_6 -> k_proj_12
	tp_11_6 -> v_proj_12
	tp_11_7 -> q_proj_12
	tp_11_7 -> k_proj_12
	tp_11_7 -> v_proj_12
	tp_11_8 -> q_proj_12
	tp_11_8 -> k_proj_12
	tp_11_8 -> v_proj_12
	tp_11_9 -> q_proj_12
	tp_11_9 -> k_proj_12
	tp_11_9 -> v_proj_12
	tp_11_10 -> q_proj_12
	tp_11_10 -> k_proj_12
	tp_11_10 -> v_proj_12
	tp_11_11 -> q_proj_12
	tp_11_11 -> k_proj_12
	tp_11_11 -> v_proj_12
	tp_11_12 -> q_proj_12
	tp_11_12 -> k_proj_12
	tp_11_12 -> v_proj_12
	tp_11_13 -> q_proj_12
	tp_11_13 -> k_proj_12
	tp_11_13 -> v_proj_12
	tp_11_14 -> q_proj_12
	tp_11_14 -> k_proj_12
	tp_11_14 -> v_proj_12
	tp_11_15 -> q_proj_12
	tp_11_15 -> k_proj_12
	tp_11_15 -> v_proj_12
	tp_12_0 -> q_proj_13
	tp_12_0 -> k_proj_13
	tp_12_0 -> v_proj_13
	tp_12_1 -> q_proj_13
	tp_12_1 -> k_proj_13
	tp_12_1 -> v_proj_13
	tp_12_2 -> q_proj_13
	tp_12_2 -> k_proj_13
	tp_12_2 -> v_proj_13
	tp_12_3 -> q_proj_13
	tp_12_3 -> k_proj_13
	tp_12_3 -> v_proj_13
	tp_12_4 -> q_proj_13
	tp_12_4 -> k_proj_13
	tp_12_4 -> v_proj_13
	tp_12_5 -> q_proj_13
	tp_12_5 -> k_proj_13
	tp_12_5 -> v_proj_13
	tp_12_6 -> q_proj_13
	tp_12_6 -> k_proj_13
	tp_12_6 -> v_proj_13
	tp_12_7 -> q_proj_13
	tp_12_7 -> k_proj_13
	tp_12_7 -> v_proj_13
	tp_12_8 -> q_proj_13
	tp_12_8 -> k_proj_13
	tp_12_8 -> v_proj_13
	tp_12_9 -> q_proj_13
	tp_12_9 -> k_proj_13
	tp_12_9 -> v_proj_13
	tp_12_10 -> q_proj_13
	tp_12_10 -> k_proj_13
	tp_12_10 -> v_proj_13
	tp_12_11 -> q_proj_13
	tp_12_11 -> k_proj_13
	tp_12_11 -> v_proj_13
	tp_12_12 -> q_proj_13
	tp_12_12 -> k_proj_13
	tp_12_12 -> v_proj_13
	tp_12_13 -> q_proj_13
	tp_12_13 -> k_proj_13
	tp_12_13 -> v_proj_13
	tp_12_14 -> q_proj_13
	tp_12_14 -> k_proj_13
	tp_12_14 -> v_proj_13
	tp_12_15 -> q_proj_13
	tp_12_15 -> k_proj_13
	tp_12_15 -> v_proj_13
	tp_13_0 -> q_proj_14
	tp_13_0 -> k_proj_14
	tp_13_0 -> v_proj_14
	tp_13_1 -> q_proj_14
	tp_13_1 -> k_proj_14
	tp_13_1 -> v_proj_14
	tp_13_2 -> q_proj_14
	tp_13_2 -> k_proj_14
	tp_13_2 -> v_proj_14
	tp_13_3 -> q_proj_14
	tp_13_3 -> k_proj_14
	tp_13_3 -> v_proj_14
	tp_13_4 -> q_proj_14
	tp_13_4 -> k_proj_14
	tp_13_4 -> v_proj_14
	tp_13_5 -> q_proj_14
	tp_13_5 -> k_proj_14
	tp_13_5 -> v_proj_14
	tp_13_6 -> q_proj_14
	tp_13_6 -> k_proj_14
	tp_13_6 -> v_proj_14
	tp_13_7 -> q_proj_14
	tp_13_7 -> k_proj_14
	tp_13_7 -> v_proj_14
	tp_13_8 -> q_proj_14
	tp_13_8 -> k_proj_14
	tp_13_8 -> v_proj_14
	tp_13_9 -> q_proj_14
	tp_13_9 -> k_proj_14
	tp_13_9 -> v_proj_14
	tp_13_10 -> q_proj_14
	tp_13_10 -> k_proj_14
	tp_13_10 -> v_proj_14
	tp_13_11 -> q_proj_14
	tp_13_11 -> k_proj_14
	tp_13_11 -> v_proj_14
	tp_13_12 -> q_proj_14
	tp_13_12 -> k_proj_14
	tp_13_12 -> v_proj_14
	tp_13_13 -> q_proj_14
	tp_13_13 -> k_proj_14
	tp_13_13 -> v_proj_14
	tp_13_14 -> q_proj_14
	tp_13_14 -> k_proj_14
	tp_13_14 -> v_proj_14
	tp_13_15 -> q_proj_14
	tp_13_15 -> k_proj_14
	tp_13_15 -> v_proj_14
	tp_14_0 -> q_proj_15
	tp_14_0 -> k_proj_15
	tp_14_0 -> v_proj_15
	tp_14_1 -> q_proj_15
	tp_14_1 -> k_proj_15
	tp_14_1 -> v_proj_15
	tp_14_2 -> q_proj_15
	tp_14_2 -> k_proj_15
	tp_14_2 -> v_proj_15
	tp_14_3 -> q_proj_15
	tp_14_3 -> k_proj_15
	tp_14_3 -> v_proj_15
	tp_14_4 -> q_proj_15
	tp_14_4 -> k_proj_15
	tp_14_4 -> v_proj_15
	tp_14_5 -> q_proj_15
	tp_14_5 -> k_proj_15
	tp_14_5 -> v_proj_15
	tp_14_6 -> q_proj_15
	tp_14_6 -> k_proj_15
	tp_14_6 -> v_proj_15
	tp_14_7 -> q_proj_15
	tp_14_7 -> k_proj_15
	tp_14_7 -> v_proj_15
	tp_14_8 -> q_proj_15
	tp_14_8 -> k_proj_15
	tp_14_8 -> v_proj_15
	tp_14_9 -> q_proj_15
	tp_14_9 -> k_proj_15
	tp_14_9 -> v_proj_15
	tp_14_10 -> q_proj_15
	tp_14_10 -> k_proj_15
	tp_14_10 -> v_proj_15
	tp_14_11 -> q_proj_15
	tp_14_11 -> k_proj_15
	tp_14_11 -> v_proj_15
	tp_14_12 -> q_proj_15
	tp_14_12 -> k_proj_15
	tp_14_12 -> v_proj_15
	tp_14_13 -> q_proj_15
	tp_14_13 -> k_proj_15
	tp_14_13 -> v_proj_15
	tp_14_14 -> q_proj_15
	tp_14_14 -> k_proj_15
	tp_14_14 -> v_proj_15
	tp_14_15 -> q_proj_15
	tp_14_15 -> k_proj_15
	tp_14_15 -> v_proj_15
	tp_15_0 -> output
	tp_15_1 -> output
	tp_15_2 -> output
	tp_15_3 -> output
	tp_15_4 -> output
	tp_15_5 -> output
	tp_15_6 -> output
	tp_15_7 -> output
	tp_15_8 -> output
	tp_15_9 -> output
	tp_15_10 -> output
	tp_15_11 -> output
	tp_15_12 -> output
	tp_15_13 -> output
	tp_15_14 -> output
	tp_15_15 -> output
}
