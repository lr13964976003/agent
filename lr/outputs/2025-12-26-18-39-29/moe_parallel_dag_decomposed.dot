// MoE Parallel Strategy DAG - Decomposed Attention
digraph {
	dpi=300 rankdir=TB size="30,30"
	node [fontsize=9 margin=0.03]
	input [label="Input\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style=filled]
	subgraph cluster_stage_0 {
		fillcolor=lightgray label="Pipeline Stage 0 (Layers 0-1)" style="rounded,filled"
		q_proj_0 [label="Q Projection L0\nGPU: 0-31\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		k_proj_0 [label="K Projection L0\nGPU: 0-31\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		v_proj_0 [label="V Projection L0\nGPU: 0-31\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_scores_0 [label="Attention Scores L0\nGPU: 0-31\nInput: Q,K,V [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		softmax_0 [label="Softmax L0\nGPU: 0-31\nInput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]\nOutput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_out_0 [label="Attention Output L0\nGPU: 0-31\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_0 [label="Gate L0\nGPU: 0-63\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_0_0 [label="Route to Expert 0\nGPU: 0,1\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_0_0 [label="Expert 0 TP-0 L0\nGPU: 0\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_0_1 [label="Expert 0 TP-1 L0\nGPU: 1\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_0 [label="TP All-Reduce Expert 0 L0\nGPU: 0↔1\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_1 [label="Route to Expert 1\nGPU: 0,1\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_1_0 [label="Expert 1 TP-0 L0\nGPU: 0\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_1_1 [label="Expert 1 TP-1 L0\nGPU: 1\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_1 [label="TP All-Reduce Expert 1 L0\nGPU: 0↔1\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_2 [label="Route to Expert 2\nGPU: 0,1\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_2_0 [label="Expert 2 TP-0 L0\nGPU: 0\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_2_1 [label="Expert 2 TP-1 L0\nGPU: 1\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_2 [label="TP All-Reduce Expert 2 L0\nGPU: 0↔1\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_3 [label="Route to Expert 3\nGPU: 0,1\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_3_0 [label="Expert 3 TP-0 L0\nGPU: 0\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_3_1 [label="Expert 3 TP-1 L0\nGPU: 1\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_3 [label="TP All-Reduce Expert 3 L0\nGPU: 0↔1\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_4 [label="Route to Expert 4\nGPU: 0,1\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_4_0 [label="Expert 4 TP-0 L0\nGPU: 0\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_4_1 [label="Expert 4 TP-1 L0\nGPU: 1\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_4 [label="TP All-Reduce Expert 4 L0\nGPU: 0↔1\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_5 [label="Route to Expert 5\nGPU: 0,1\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_5_0 [label="Expert 5 TP-0 L0\nGPU: 0\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_5_1 [label="Expert 5 TP-1 L0\nGPU: 1\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_5 [label="TP All-Reduce Expert 5 L0\nGPU: 0↔1\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_6 [label="Route to Expert 6\nGPU: 0,1\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_6_0 [label="Expert 6 TP-0 L0\nGPU: 0\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_6_1 [label="Expert 6 TP-1 L0\nGPU: 1\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_6 [label="TP All-Reduce Expert 6 L0\nGPU: 0↔1\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_7 [label="Route to Expert 7\nGPU: 0,1\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_7_0 [label="Expert 7 TP-0 L0\nGPU: 0\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_7_1 [label="Expert 7 TP-1 L0\nGPU: 1\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_7 [label="TP All-Reduce Expert 7 L0\nGPU: 0↔1\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_8 [label="Route to Expert 8\nGPU: 32,33\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_8_0 [label="Expert 8 TP-0 L0\nGPU: 32\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_8_1 [label="Expert 8 TP-1 L0\nGPU: 33\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_8 [label="TP All-Reduce Expert 8 L0\nGPU: 32↔33\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_9 [label="Route to Expert 9\nGPU: 32,33\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_9_0 [label="Expert 9 TP-0 L0\nGPU: 32\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_9_1 [label="Expert 9 TP-1 L0\nGPU: 33\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_9 [label="TP All-Reduce Expert 9 L0\nGPU: 32↔33\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_10 [label="Route to Expert 10\nGPU: 32,33\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_10_0 [label="Expert 10 TP-0 L0\nGPU: 32\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_10_1 [label="Expert 10 TP-1 L0\nGPU: 33\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_10 [label="TP All-Reduce Expert 10 L0\nGPU: 32↔33\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_11 [label="Route to Expert 11\nGPU: 32,33\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_11_0 [label="Expert 11 TP-0 L0\nGPU: 32\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_11_1 [label="Expert 11 TP-1 L0\nGPU: 33\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_11 [label="TP All-Reduce Expert 11 L0\nGPU: 32↔33\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_12 [label="Route to Expert 12\nGPU: 32,33\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_12_0 [label="Expert 12 TP-0 L0\nGPU: 32\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_12_1 [label="Expert 12 TP-1 L0\nGPU: 33\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_12 [label="TP All-Reduce Expert 12 L0\nGPU: 32↔33\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_13 [label="Route to Expert 13\nGPU: 32,33\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_13_0 [label="Expert 13 TP-0 L0\nGPU: 32\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_13_1 [label="Expert 13 TP-1 L0\nGPU: 33\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_13 [label="TP All-Reduce Expert 13 L0\nGPU: 32↔33\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_14 [label="Route to Expert 14\nGPU: 32,33\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_14_0 [label="Expert 14 TP-0 L0\nGPU: 32\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_14_1 [label="Expert 14 TP-1 L0\nGPU: 33\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_14 [label="TP All-Reduce Expert 14 L0\nGPU: 32↔33\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_15 [label="Route to Expert 15\nGPU: 32,33\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_15_0 [label="Expert 15 TP-0 L0\nGPU: 32\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_15_1 [label="Expert 15 TP-1 L0\nGPU: 33\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_15 [label="TP All-Reduce Expert 15 L0\nGPU: 32↔33\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		q_proj_1 [label="Q Projection L1\nGPU: 0-31\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		k_proj_1 [label="K Projection L1\nGPU: 0-31\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		v_proj_1 [label="V Projection L1\nGPU: 0-31\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_scores_1 [label="Attention Scores L1\nGPU: 0-31\nInput: Q,K,V [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		softmax_1 [label="Softmax L1\nGPU: 0-31\nInput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]\nOutput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_out_1 [label="Attention Output L1\nGPU: 0-31\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_1 [label="Gate L1\nGPU: 0-63\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_1_0 [label="Route to Expert 0\nGPU: 0,1\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_0_0 [label="Expert 0 TP-0 L1\nGPU: 0\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_0_1 [label="Expert 0 TP-1 L1\nGPU: 1\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_0 [label="TP All-Reduce Expert 0 L1\nGPU: 0↔1\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_1 [label="Route to Expert 1\nGPU: 0,1\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_1_0 [label="Expert 1 TP-0 L1\nGPU: 0\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_1_1 [label="Expert 1 TP-1 L1\nGPU: 1\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_1 [label="TP All-Reduce Expert 1 L1\nGPU: 0↔1\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_2 [label="Route to Expert 2\nGPU: 0,1\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_2_0 [label="Expert 2 TP-0 L1\nGPU: 0\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_2_1 [label="Expert 2 TP-1 L1\nGPU: 1\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_2 [label="TP All-Reduce Expert 2 L1\nGPU: 0↔1\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_3 [label="Route to Expert 3\nGPU: 0,1\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_3_0 [label="Expert 3 TP-0 L1\nGPU: 0\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_3_1 [label="Expert 3 TP-1 L1\nGPU: 1\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_3 [label="TP All-Reduce Expert 3 L1\nGPU: 0↔1\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_4 [label="Route to Expert 4\nGPU: 0,1\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_4_0 [label="Expert 4 TP-0 L1\nGPU: 0\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_4_1 [label="Expert 4 TP-1 L1\nGPU: 1\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_4 [label="TP All-Reduce Expert 4 L1\nGPU: 0↔1\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_5 [label="Route to Expert 5\nGPU: 0,1\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_5_0 [label="Expert 5 TP-0 L1\nGPU: 0\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_5_1 [label="Expert 5 TP-1 L1\nGPU: 1\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_5 [label="TP All-Reduce Expert 5 L1\nGPU: 0↔1\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_6 [label="Route to Expert 6\nGPU: 0,1\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_6_0 [label="Expert 6 TP-0 L1\nGPU: 0\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_6_1 [label="Expert 6 TP-1 L1\nGPU: 1\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_6 [label="TP All-Reduce Expert 6 L1\nGPU: 0↔1\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_7 [label="Route to Expert 7\nGPU: 0,1\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_7_0 [label="Expert 7 TP-0 L1\nGPU: 0\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_7_1 [label="Expert 7 TP-1 L1\nGPU: 1\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_7 [label="TP All-Reduce Expert 7 L1\nGPU: 0↔1\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_8 [label="Route to Expert 8\nGPU: 32,33\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_8_0 [label="Expert 8 TP-0 L1\nGPU: 32\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_8_1 [label="Expert 8 TP-1 L1\nGPU: 33\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_8 [label="TP All-Reduce Expert 8 L1\nGPU: 32↔33\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_9 [label="Route to Expert 9\nGPU: 32,33\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_9_0 [label="Expert 9 TP-0 L1\nGPU: 32\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_9_1 [label="Expert 9 TP-1 L1\nGPU: 33\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_9 [label="TP All-Reduce Expert 9 L1\nGPU: 32↔33\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_10 [label="Route to Expert 10\nGPU: 32,33\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_10_0 [label="Expert 10 TP-0 L1\nGPU: 32\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_10_1 [label="Expert 10 TP-1 L1\nGPU: 33\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_10 [label="TP All-Reduce Expert 10 L1\nGPU: 32↔33\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_11 [label="Route to Expert 11\nGPU: 32,33\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_11_0 [label="Expert 11 TP-0 L1\nGPU: 32\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_11_1 [label="Expert 11 TP-1 L1\nGPU: 33\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_11 [label="TP All-Reduce Expert 11 L1\nGPU: 32↔33\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_12 [label="Route to Expert 12\nGPU: 32,33\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_12_0 [label="Expert 12 TP-0 L1\nGPU: 32\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_12_1 [label="Expert 12 TP-1 L1\nGPU: 33\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_12 [label="TP All-Reduce Expert 12 L1\nGPU: 32↔33\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_13 [label="Route to Expert 13\nGPU: 32,33\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_13_0 [label="Expert 13 TP-0 L1\nGPU: 32\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_13_1 [label="Expert 13 TP-1 L1\nGPU: 33\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_13 [label="TP All-Reduce Expert 13 L1\nGPU: 32↔33\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_14 [label="Route to Expert 14\nGPU: 32,33\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_14_0 [label="Expert 14 TP-0 L1\nGPU: 32\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_14_1 [label="Expert 14 TP-1 L1\nGPU: 33\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_14 [label="TP All-Reduce Expert 14 L1\nGPU: 32↔33\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_15 [label="Route to Expert 15\nGPU: 32,33\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_15_0 [label="Expert 15 TP-0 L1\nGPU: 32\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_15_1 [label="Expert 15 TP-1 L1\nGPU: 33\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_15 [label="TP All-Reduce Expert 15 L1\nGPU: 32↔33\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
	}
	subgraph cluster_stage_1 {
		fillcolor=lightgray label="Pipeline Stage 1 (Layers 2-3)" style="rounded,filled"
		q_proj_2 [label="Q Projection L2\nGPU: 64-95\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		k_proj_2 [label="K Projection L2\nGPU: 64-95\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		v_proj_2 [label="V Projection L2\nGPU: 64-95\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_scores_2 [label="Attention Scores L2\nGPU: 64-95\nInput: Q,K,V [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		softmax_2 [label="Softmax L2\nGPU: 64-95\nInput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]\nOutput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_out_2 [label="Attention Output L2\nGPU: 64-95\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_2 [label="Gate L2\nGPU: 64-127\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_2_0 [label="Route to Expert 0\nGPU: 64,65\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_0_0 [label="Expert 0 TP-0 L2\nGPU: 64\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_0_1 [label="Expert 0 TP-1 L2\nGPU: 65\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_0 [label="TP All-Reduce Expert 0 L2\nGPU: 64↔65\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_1 [label="Route to Expert 1\nGPU: 64,65\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_1_0 [label="Expert 1 TP-0 L2\nGPU: 64\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_1_1 [label="Expert 1 TP-1 L2\nGPU: 65\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_1 [label="TP All-Reduce Expert 1 L2\nGPU: 64↔65\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_2 [label="Route to Expert 2\nGPU: 64,65\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_2_0 [label="Expert 2 TP-0 L2\nGPU: 64\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_2_1 [label="Expert 2 TP-1 L2\nGPU: 65\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_2 [label="TP All-Reduce Expert 2 L2\nGPU: 64↔65\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_3 [label="Route to Expert 3\nGPU: 64,65\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_3_0 [label="Expert 3 TP-0 L2\nGPU: 64\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_3_1 [label="Expert 3 TP-1 L2\nGPU: 65\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_3 [label="TP All-Reduce Expert 3 L2\nGPU: 64↔65\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_4 [label="Route to Expert 4\nGPU: 64,65\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_4_0 [label="Expert 4 TP-0 L2\nGPU: 64\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_4_1 [label="Expert 4 TP-1 L2\nGPU: 65\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_4 [label="TP All-Reduce Expert 4 L2\nGPU: 64↔65\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_5 [label="Route to Expert 5\nGPU: 64,65\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_5_0 [label="Expert 5 TP-0 L2\nGPU: 64\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_5_1 [label="Expert 5 TP-1 L2\nGPU: 65\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_5 [label="TP All-Reduce Expert 5 L2\nGPU: 64↔65\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_6 [label="Route to Expert 6\nGPU: 64,65\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_6_0 [label="Expert 6 TP-0 L2\nGPU: 64\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_6_1 [label="Expert 6 TP-1 L2\nGPU: 65\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_6 [label="TP All-Reduce Expert 6 L2\nGPU: 64↔65\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_7 [label="Route to Expert 7\nGPU: 64,65\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_7_0 [label="Expert 7 TP-0 L2\nGPU: 64\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_7_1 [label="Expert 7 TP-1 L2\nGPU: 65\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_7 [label="TP All-Reduce Expert 7 L2\nGPU: 64↔65\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_8 [label="Route to Expert 8\nGPU: 96,97\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_8_0 [label="Expert 8 TP-0 L2\nGPU: 96\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_8_1 [label="Expert 8 TP-1 L2\nGPU: 97\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_8 [label="TP All-Reduce Expert 8 L2\nGPU: 96↔97\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_9 [label="Route to Expert 9\nGPU: 96,97\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_9_0 [label="Expert 9 TP-0 L2\nGPU: 96\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_9_1 [label="Expert 9 TP-1 L2\nGPU: 97\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_9 [label="TP All-Reduce Expert 9 L2\nGPU: 96↔97\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_10 [label="Route to Expert 10\nGPU: 96,97\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_10_0 [label="Expert 10 TP-0 L2\nGPU: 96\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_10_1 [label="Expert 10 TP-1 L2\nGPU: 97\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_10 [label="TP All-Reduce Expert 10 L2\nGPU: 96↔97\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_11 [label="Route to Expert 11\nGPU: 96,97\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_11_0 [label="Expert 11 TP-0 L2\nGPU: 96\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_11_1 [label="Expert 11 TP-1 L2\nGPU: 97\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_11 [label="TP All-Reduce Expert 11 L2\nGPU: 96↔97\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_12 [label="Route to Expert 12\nGPU: 96,97\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_12_0 [label="Expert 12 TP-0 L2\nGPU: 96\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_12_1 [label="Expert 12 TP-1 L2\nGPU: 97\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_12 [label="TP All-Reduce Expert 12 L2\nGPU: 96↔97\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_13 [label="Route to Expert 13\nGPU: 96,97\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_13_0 [label="Expert 13 TP-0 L2\nGPU: 96\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_13_1 [label="Expert 13 TP-1 L2\nGPU: 97\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_13 [label="TP All-Reduce Expert 13 L2\nGPU: 96↔97\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_14 [label="Route to Expert 14\nGPU: 96,97\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_14_0 [label="Expert 14 TP-0 L2\nGPU: 96\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_14_1 [label="Expert 14 TP-1 L2\nGPU: 97\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_14 [label="TP All-Reduce Expert 14 L2\nGPU: 96↔97\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_15 [label="Route to Expert 15\nGPU: 96,97\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_15_0 [label="Expert 15 TP-0 L2\nGPU: 96\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_15_1 [label="Expert 15 TP-1 L2\nGPU: 97\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_15 [label="TP All-Reduce Expert 15 L2\nGPU: 96↔97\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		q_proj_3 [label="Q Projection L3\nGPU: 64-95\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		k_proj_3 [label="K Projection L3\nGPU: 64-95\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		v_proj_3 [label="V Projection L3\nGPU: 64-95\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_scores_3 [label="Attention Scores L3\nGPU: 64-95\nInput: Q,K,V [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		softmax_3 [label="Softmax L3\nGPU: 64-95\nInput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]\nOutput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_out_3 [label="Attention Output L3\nGPU: 64-95\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_3 [label="Gate L3\nGPU: 64-127\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_3_0 [label="Route to Expert 0\nGPU: 64,65\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_0_0 [label="Expert 0 TP-0 L3\nGPU: 64\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_0_1 [label="Expert 0 TP-1 L3\nGPU: 65\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_0 [label="TP All-Reduce Expert 0 L3\nGPU: 64↔65\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_1 [label="Route to Expert 1\nGPU: 64,65\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_1_0 [label="Expert 1 TP-0 L3\nGPU: 64\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_1_1 [label="Expert 1 TP-1 L3\nGPU: 65\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_1 [label="TP All-Reduce Expert 1 L3\nGPU: 64↔65\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_2 [label="Route to Expert 2\nGPU: 64,65\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_2_0 [label="Expert 2 TP-0 L3\nGPU: 64\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_2_1 [label="Expert 2 TP-1 L3\nGPU: 65\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_2 [label="TP All-Reduce Expert 2 L3\nGPU: 64↔65\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_3 [label="Route to Expert 3\nGPU: 64,65\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_3_0 [label="Expert 3 TP-0 L3\nGPU: 64\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_3_1 [label="Expert 3 TP-1 L3\nGPU: 65\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_3 [label="TP All-Reduce Expert 3 L3\nGPU: 64↔65\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_4 [label="Route to Expert 4\nGPU: 64,65\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_4_0 [label="Expert 4 TP-0 L3\nGPU: 64\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_4_1 [label="Expert 4 TP-1 L3\nGPU: 65\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_4 [label="TP All-Reduce Expert 4 L3\nGPU: 64↔65\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_5 [label="Route to Expert 5\nGPU: 64,65\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_5_0 [label="Expert 5 TP-0 L3\nGPU: 64\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_5_1 [label="Expert 5 TP-1 L3\nGPU: 65\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_5 [label="TP All-Reduce Expert 5 L3\nGPU: 64↔65\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_6 [label="Route to Expert 6\nGPU: 64,65\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_6_0 [label="Expert 6 TP-0 L3\nGPU: 64\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_6_1 [label="Expert 6 TP-1 L3\nGPU: 65\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_6 [label="TP All-Reduce Expert 6 L3\nGPU: 64↔65\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_7 [label="Route to Expert 7\nGPU: 64,65\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_7_0 [label="Expert 7 TP-0 L3\nGPU: 64\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_7_1 [label="Expert 7 TP-1 L3\nGPU: 65\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_7 [label="TP All-Reduce Expert 7 L3\nGPU: 64↔65\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_8 [label="Route to Expert 8\nGPU: 96,97\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_8_0 [label="Expert 8 TP-0 L3\nGPU: 96\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_8_1 [label="Expert 8 TP-1 L3\nGPU: 97\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_8 [label="TP All-Reduce Expert 8 L3\nGPU: 96↔97\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_9 [label="Route to Expert 9\nGPU: 96,97\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_9_0 [label="Expert 9 TP-0 L3\nGPU: 96\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_9_1 [label="Expert 9 TP-1 L3\nGPU: 97\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_9 [label="TP All-Reduce Expert 9 L3\nGPU: 96↔97\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_10 [label="Route to Expert 10\nGPU: 96,97\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_10_0 [label="Expert 10 TP-0 L3\nGPU: 96\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_10_1 [label="Expert 10 TP-1 L3\nGPU: 97\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_10 [label="TP All-Reduce Expert 10 L3\nGPU: 96↔97\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_11 [label="Route to Expert 11\nGPU: 96,97\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_11_0 [label="Expert 11 TP-0 L3\nGPU: 96\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_11_1 [label="Expert 11 TP-1 L3\nGPU: 97\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_11 [label="TP All-Reduce Expert 11 L3\nGPU: 96↔97\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_12 [label="Route to Expert 12\nGPU: 96,97\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_12_0 [label="Expert 12 TP-0 L3\nGPU: 96\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_12_1 [label="Expert 12 TP-1 L3\nGPU: 97\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_12 [label="TP All-Reduce Expert 12 L3\nGPU: 96↔97\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_13 [label="Route to Expert 13\nGPU: 96,97\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_13_0 [label="Expert 13 TP-0 L3\nGPU: 96\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_13_1 [label="Expert 13 TP-1 L3\nGPU: 97\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_13 [label="TP All-Reduce Expert 13 L3\nGPU: 96↔97\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_14 [label="Route to Expert 14\nGPU: 96,97\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_14_0 [label="Expert 14 TP-0 L3\nGPU: 96\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_14_1 [label="Expert 14 TP-1 L3\nGPU: 97\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_14 [label="TP All-Reduce Expert 14 L3\nGPU: 96↔97\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_15 [label="Route to Expert 15\nGPU: 96,97\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_15_0 [label="Expert 15 TP-0 L3\nGPU: 96\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_15_1 [label="Expert 15 TP-1 L3\nGPU: 97\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_15 [label="TP All-Reduce Expert 15 L3\nGPU: 96↔97\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
	}
	subgraph cluster_stage_2 {
		fillcolor=lightgray label="Pipeline Stage 2 (Layers 4-5)" style="rounded,filled"
		q_proj_4 [label="Q Projection L4\nGPU: 128-159\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		k_proj_4 [label="K Projection L4\nGPU: 128-159\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		v_proj_4 [label="V Projection L4\nGPU: 128-159\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_scores_4 [label="Attention Scores L4\nGPU: 128-159\nInput: Q,K,V [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		softmax_4 [label="Softmax L4\nGPU: 128-159\nInput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]\nOutput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_out_4 [label="Attention Output L4\nGPU: 128-159\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_4 [label="Gate L4\nGPU: 128-191\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_4_0 [label="Route to Expert 0\nGPU: 128,129\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_0_0 [label="Expert 0 TP-0 L4\nGPU: 128\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_0_1 [label="Expert 0 TP-1 L4\nGPU: 129\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_0 [label="TP All-Reduce Expert 0 L4\nGPU: 128↔129\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_1 [label="Route to Expert 1\nGPU: 128,129\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_1_0 [label="Expert 1 TP-0 L4\nGPU: 128\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_1_1 [label="Expert 1 TP-1 L4\nGPU: 129\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_1 [label="TP All-Reduce Expert 1 L4\nGPU: 128↔129\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_2 [label="Route to Expert 2\nGPU: 128,129\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_2_0 [label="Expert 2 TP-0 L4\nGPU: 128\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_2_1 [label="Expert 2 TP-1 L4\nGPU: 129\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_2 [label="TP All-Reduce Expert 2 L4\nGPU: 128↔129\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_3 [label="Route to Expert 3\nGPU: 128,129\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_3_0 [label="Expert 3 TP-0 L4\nGPU: 128\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_3_1 [label="Expert 3 TP-1 L4\nGPU: 129\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_3 [label="TP All-Reduce Expert 3 L4\nGPU: 128↔129\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_4 [label="Route to Expert 4\nGPU: 128,129\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_4_0 [label="Expert 4 TP-0 L4\nGPU: 128\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_4_1 [label="Expert 4 TP-1 L4\nGPU: 129\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_4 [label="TP All-Reduce Expert 4 L4\nGPU: 128↔129\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_5 [label="Route to Expert 5\nGPU: 128,129\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_5_0 [label="Expert 5 TP-0 L4\nGPU: 128\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_5_1 [label="Expert 5 TP-1 L4\nGPU: 129\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_5 [label="TP All-Reduce Expert 5 L4\nGPU: 128↔129\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_6 [label="Route to Expert 6\nGPU: 128,129\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_6_0 [label="Expert 6 TP-0 L4\nGPU: 128\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_6_1 [label="Expert 6 TP-1 L4\nGPU: 129\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_6 [label="TP All-Reduce Expert 6 L4\nGPU: 128↔129\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_7 [label="Route to Expert 7\nGPU: 128,129\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_7_0 [label="Expert 7 TP-0 L4\nGPU: 128\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_7_1 [label="Expert 7 TP-1 L4\nGPU: 129\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_7 [label="TP All-Reduce Expert 7 L4\nGPU: 128↔129\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_8 [label="Route to Expert 8\nGPU: 160,161\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_8_0 [label="Expert 8 TP-0 L4\nGPU: 160\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_8_1 [label="Expert 8 TP-1 L4\nGPU: 161\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_8 [label="TP All-Reduce Expert 8 L4\nGPU: 160↔161\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_9 [label="Route to Expert 9\nGPU: 160,161\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_9_0 [label="Expert 9 TP-0 L4\nGPU: 160\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_9_1 [label="Expert 9 TP-1 L4\nGPU: 161\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_9 [label="TP All-Reduce Expert 9 L4\nGPU: 160↔161\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_10 [label="Route to Expert 10\nGPU: 160,161\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_10_0 [label="Expert 10 TP-0 L4\nGPU: 160\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_10_1 [label="Expert 10 TP-1 L4\nGPU: 161\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_10 [label="TP All-Reduce Expert 10 L4\nGPU: 160↔161\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_11 [label="Route to Expert 11\nGPU: 160,161\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_11_0 [label="Expert 11 TP-0 L4\nGPU: 160\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_11_1 [label="Expert 11 TP-1 L4\nGPU: 161\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_11 [label="TP All-Reduce Expert 11 L4\nGPU: 160↔161\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_12 [label="Route to Expert 12\nGPU: 160,161\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_12_0 [label="Expert 12 TP-0 L4\nGPU: 160\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_12_1 [label="Expert 12 TP-1 L4\nGPU: 161\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_12 [label="TP All-Reduce Expert 12 L4\nGPU: 160↔161\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_13 [label="Route to Expert 13\nGPU: 160,161\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_13_0 [label="Expert 13 TP-0 L4\nGPU: 160\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_13_1 [label="Expert 13 TP-1 L4\nGPU: 161\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_13 [label="TP All-Reduce Expert 13 L4\nGPU: 160↔161\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_14 [label="Route to Expert 14\nGPU: 160,161\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_14_0 [label="Expert 14 TP-0 L4\nGPU: 160\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_14_1 [label="Expert 14 TP-1 L4\nGPU: 161\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_14 [label="TP All-Reduce Expert 14 L4\nGPU: 160↔161\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_15 [label="Route to Expert 15\nGPU: 160,161\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_15_0 [label="Expert 15 TP-0 L4\nGPU: 160\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_15_1 [label="Expert 15 TP-1 L4\nGPU: 161\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_15 [label="TP All-Reduce Expert 15 L4\nGPU: 160↔161\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		q_proj_5 [label="Q Projection L5\nGPU: 128-159\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		k_proj_5 [label="K Projection L5\nGPU: 128-159\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		v_proj_5 [label="V Projection L5\nGPU: 128-159\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_scores_5 [label="Attention Scores L5\nGPU: 128-159\nInput: Q,K,V [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		softmax_5 [label="Softmax L5\nGPU: 128-159\nInput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]\nOutput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_out_5 [label="Attention Output L5\nGPU: 128-159\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_5 [label="Gate L5\nGPU: 128-191\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_5_0 [label="Route to Expert 0\nGPU: 128,129\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_0_0 [label="Expert 0 TP-0 L5\nGPU: 128\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_0_1 [label="Expert 0 TP-1 L5\nGPU: 129\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_0 [label="TP All-Reduce Expert 0 L5\nGPU: 128↔129\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_1 [label="Route to Expert 1\nGPU: 128,129\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_1_0 [label="Expert 1 TP-0 L5\nGPU: 128\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_1_1 [label="Expert 1 TP-1 L5\nGPU: 129\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_1 [label="TP All-Reduce Expert 1 L5\nGPU: 128↔129\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_2 [label="Route to Expert 2\nGPU: 128,129\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_2_0 [label="Expert 2 TP-0 L5\nGPU: 128\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_2_1 [label="Expert 2 TP-1 L5\nGPU: 129\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_2 [label="TP All-Reduce Expert 2 L5\nGPU: 128↔129\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_3 [label="Route to Expert 3\nGPU: 128,129\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_3_0 [label="Expert 3 TP-0 L5\nGPU: 128\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_3_1 [label="Expert 3 TP-1 L5\nGPU: 129\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_3 [label="TP All-Reduce Expert 3 L5\nGPU: 128↔129\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_4 [label="Route to Expert 4\nGPU: 128,129\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_4_0 [label="Expert 4 TP-0 L5\nGPU: 128\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_4_1 [label="Expert 4 TP-1 L5\nGPU: 129\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_4 [label="TP All-Reduce Expert 4 L5\nGPU: 128↔129\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_5 [label="Route to Expert 5\nGPU: 128,129\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_5_0 [label="Expert 5 TP-0 L5\nGPU: 128\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_5_1 [label="Expert 5 TP-1 L5\nGPU: 129\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_5 [label="TP All-Reduce Expert 5 L5\nGPU: 128↔129\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_6 [label="Route to Expert 6\nGPU: 128,129\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_6_0 [label="Expert 6 TP-0 L5\nGPU: 128\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_6_1 [label="Expert 6 TP-1 L5\nGPU: 129\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_6 [label="TP All-Reduce Expert 6 L5\nGPU: 128↔129\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_7 [label="Route to Expert 7\nGPU: 128,129\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_7_0 [label="Expert 7 TP-0 L5\nGPU: 128\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_7_1 [label="Expert 7 TP-1 L5\nGPU: 129\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_7 [label="TP All-Reduce Expert 7 L5\nGPU: 128↔129\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_8 [label="Route to Expert 8\nGPU: 160,161\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_8_0 [label="Expert 8 TP-0 L5\nGPU: 160\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_8_1 [label="Expert 8 TP-1 L5\nGPU: 161\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_8 [label="TP All-Reduce Expert 8 L5\nGPU: 160↔161\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_9 [label="Route to Expert 9\nGPU: 160,161\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_9_0 [label="Expert 9 TP-0 L5\nGPU: 160\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_9_1 [label="Expert 9 TP-1 L5\nGPU: 161\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_9 [label="TP All-Reduce Expert 9 L5\nGPU: 160↔161\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_10 [label="Route to Expert 10\nGPU: 160,161\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_10_0 [label="Expert 10 TP-0 L5\nGPU: 160\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_10_1 [label="Expert 10 TP-1 L5\nGPU: 161\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_10 [label="TP All-Reduce Expert 10 L5\nGPU: 160↔161\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_11 [label="Route to Expert 11\nGPU: 160,161\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_11_0 [label="Expert 11 TP-0 L5\nGPU: 160\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_11_1 [label="Expert 11 TP-1 L5\nGPU: 161\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_11 [label="TP All-Reduce Expert 11 L5\nGPU: 160↔161\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_12 [label="Route to Expert 12\nGPU: 160,161\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_12_0 [label="Expert 12 TP-0 L5\nGPU: 160\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_12_1 [label="Expert 12 TP-1 L5\nGPU: 161\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_12 [label="TP All-Reduce Expert 12 L5\nGPU: 160↔161\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_13 [label="Route to Expert 13\nGPU: 160,161\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_13_0 [label="Expert 13 TP-0 L5\nGPU: 160\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_13_1 [label="Expert 13 TP-1 L5\nGPU: 161\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_13 [label="TP All-Reduce Expert 13 L5\nGPU: 160↔161\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_14 [label="Route to Expert 14\nGPU: 160,161\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_14_0 [label="Expert 14 TP-0 L5\nGPU: 160\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_14_1 [label="Expert 14 TP-1 L5\nGPU: 161\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_14 [label="TP All-Reduce Expert 14 L5\nGPU: 160↔161\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_15 [label="Route to Expert 15\nGPU: 160,161\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_15_0 [label="Expert 15 TP-0 L5\nGPU: 160\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_15_1 [label="Expert 15 TP-1 L5\nGPU: 161\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_15 [label="TP All-Reduce Expert 15 L5\nGPU: 160↔161\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
	}
	subgraph cluster_stage_3 {
		fillcolor=lightgray label="Pipeline Stage 3 (Layers 6-7)" style="rounded,filled"
		q_proj_6 [label="Q Projection L6\nGPU: 192-223\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		k_proj_6 [label="K Projection L6\nGPU: 192-223\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		v_proj_6 [label="V Projection L6\nGPU: 192-223\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_scores_6 [label="Attention Scores L6\nGPU: 192-223\nInput: Q,K,V [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		softmax_6 [label="Softmax L6\nGPU: 192-223\nInput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]\nOutput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_out_6 [label="Attention Output L6\nGPU: 192-223\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_6 [label="Gate L6\nGPU: 192-255\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_6_0 [label="Route to Expert 0\nGPU: 192,193\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_0_0 [label="Expert 0 TP-0 L6\nGPU: 192\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_0_1 [label="Expert 0 TP-1 L6\nGPU: 193\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_0 [label="TP All-Reduce Expert 0 L6\nGPU: 192↔193\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_1 [label="Route to Expert 1\nGPU: 192,193\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_1_0 [label="Expert 1 TP-0 L6\nGPU: 192\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_1_1 [label="Expert 1 TP-1 L6\nGPU: 193\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_1 [label="TP All-Reduce Expert 1 L6\nGPU: 192↔193\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_2 [label="Route to Expert 2\nGPU: 192,193\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_2_0 [label="Expert 2 TP-0 L6\nGPU: 192\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_2_1 [label="Expert 2 TP-1 L6\nGPU: 193\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_2 [label="TP All-Reduce Expert 2 L6\nGPU: 192↔193\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_3 [label="Route to Expert 3\nGPU: 192,193\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_3_0 [label="Expert 3 TP-0 L6\nGPU: 192\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_3_1 [label="Expert 3 TP-1 L6\nGPU: 193\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_3 [label="TP All-Reduce Expert 3 L6\nGPU: 192↔193\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_4 [label="Route to Expert 4\nGPU: 192,193\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_4_0 [label="Expert 4 TP-0 L6\nGPU: 192\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_4_1 [label="Expert 4 TP-1 L6\nGPU: 193\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_4 [label="TP All-Reduce Expert 4 L6\nGPU: 192↔193\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_5 [label="Route to Expert 5\nGPU: 192,193\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_5_0 [label="Expert 5 TP-0 L6\nGPU: 192\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_5_1 [label="Expert 5 TP-1 L6\nGPU: 193\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_5 [label="TP All-Reduce Expert 5 L6\nGPU: 192↔193\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_6 [label="Route to Expert 6\nGPU: 192,193\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_6_0 [label="Expert 6 TP-0 L6\nGPU: 192\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_6_1 [label="Expert 6 TP-1 L6\nGPU: 193\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_6 [label="TP All-Reduce Expert 6 L6\nGPU: 192↔193\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_7 [label="Route to Expert 7\nGPU: 192,193\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_7_0 [label="Expert 7 TP-0 L6\nGPU: 192\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_7_1 [label="Expert 7 TP-1 L6\nGPU: 193\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_7 [label="TP All-Reduce Expert 7 L6\nGPU: 192↔193\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_8 [label="Route to Expert 8\nGPU: 224,225\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_8_0 [label="Expert 8 TP-0 L6\nGPU: 224\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_8_1 [label="Expert 8 TP-1 L6\nGPU: 225\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_8 [label="TP All-Reduce Expert 8 L6\nGPU: 224↔225\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_9 [label="Route to Expert 9\nGPU: 224,225\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_9_0 [label="Expert 9 TP-0 L6\nGPU: 224\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_9_1 [label="Expert 9 TP-1 L6\nGPU: 225\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_9 [label="TP All-Reduce Expert 9 L6\nGPU: 224↔225\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_10 [label="Route to Expert 10\nGPU: 224,225\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_10_0 [label="Expert 10 TP-0 L6\nGPU: 224\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_10_1 [label="Expert 10 TP-1 L6\nGPU: 225\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_10 [label="TP All-Reduce Expert 10 L6\nGPU: 224↔225\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_11 [label="Route to Expert 11\nGPU: 224,225\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_11_0 [label="Expert 11 TP-0 L6\nGPU: 224\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_11_1 [label="Expert 11 TP-1 L6\nGPU: 225\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_11 [label="TP All-Reduce Expert 11 L6\nGPU: 224↔225\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_12 [label="Route to Expert 12\nGPU: 224,225\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_12_0 [label="Expert 12 TP-0 L6\nGPU: 224\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_12_1 [label="Expert 12 TP-1 L6\nGPU: 225\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_12 [label="TP All-Reduce Expert 12 L6\nGPU: 224↔225\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_13 [label="Route to Expert 13\nGPU: 224,225\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_13_0 [label="Expert 13 TP-0 L6\nGPU: 224\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_13_1 [label="Expert 13 TP-1 L6\nGPU: 225\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_13 [label="TP All-Reduce Expert 13 L6\nGPU: 224↔225\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_14 [label="Route to Expert 14\nGPU: 224,225\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_14_0 [label="Expert 14 TP-0 L6\nGPU: 224\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_14_1 [label="Expert 14 TP-1 L6\nGPU: 225\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_14 [label="TP All-Reduce Expert 14 L6\nGPU: 224↔225\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_15 [label="Route to Expert 15\nGPU: 224,225\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_15_0 [label="Expert 15 TP-0 L6\nGPU: 224\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_15_1 [label="Expert 15 TP-1 L6\nGPU: 225\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_15 [label="TP All-Reduce Expert 15 L6\nGPU: 224↔225\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		q_proj_7 [label="Q Projection L7\nGPU: 192-223\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		k_proj_7 [label="K Projection L7\nGPU: 192-223\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		v_proj_7 [label="V Projection L7\nGPU: 192-223\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_scores_7 [label="Attention Scores L7\nGPU: 192-223\nInput: Q,K,V [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		softmax_7 [label="Softmax L7\nGPU: 192-223\nInput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]\nOutput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_out_7 [label="Attention Output L7\nGPU: 192-223\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_7 [label="Gate L7\nGPU: 192-255\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_7_0 [label="Route to Expert 0\nGPU: 192,193\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_0_0 [label="Expert 0 TP-0 L7\nGPU: 192\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_0_1 [label="Expert 0 TP-1 L7\nGPU: 193\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_0 [label="TP All-Reduce Expert 0 L7\nGPU: 192↔193\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_1 [label="Route to Expert 1\nGPU: 192,193\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_1_0 [label="Expert 1 TP-0 L7\nGPU: 192\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_1_1 [label="Expert 1 TP-1 L7\nGPU: 193\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_1 [label="TP All-Reduce Expert 1 L7\nGPU: 192↔193\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_2 [label="Route to Expert 2\nGPU: 192,193\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_2_0 [label="Expert 2 TP-0 L7\nGPU: 192\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_2_1 [label="Expert 2 TP-1 L7\nGPU: 193\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_2 [label="TP All-Reduce Expert 2 L7\nGPU: 192↔193\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_3 [label="Route to Expert 3\nGPU: 192,193\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_3_0 [label="Expert 3 TP-0 L7\nGPU: 192\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_3_1 [label="Expert 3 TP-1 L7\nGPU: 193\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_3 [label="TP All-Reduce Expert 3 L7\nGPU: 192↔193\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_4 [label="Route to Expert 4\nGPU: 192,193\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_4_0 [label="Expert 4 TP-0 L7\nGPU: 192\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_4_1 [label="Expert 4 TP-1 L7\nGPU: 193\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_4 [label="TP All-Reduce Expert 4 L7\nGPU: 192↔193\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_5 [label="Route to Expert 5\nGPU: 192,193\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_5_0 [label="Expert 5 TP-0 L7\nGPU: 192\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_5_1 [label="Expert 5 TP-1 L7\nGPU: 193\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_5 [label="TP All-Reduce Expert 5 L7\nGPU: 192↔193\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_6 [label="Route to Expert 6\nGPU: 192,193\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_6_0 [label="Expert 6 TP-0 L7\nGPU: 192\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_6_1 [label="Expert 6 TP-1 L7\nGPU: 193\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_6 [label="TP All-Reduce Expert 6 L7\nGPU: 192↔193\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_7 [label="Route to Expert 7\nGPU: 192,193\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_7_0 [label="Expert 7 TP-0 L7\nGPU: 192\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_7_1 [label="Expert 7 TP-1 L7\nGPU: 193\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_7 [label="TP All-Reduce Expert 7 L7\nGPU: 192↔193\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_8 [label="Route to Expert 8\nGPU: 224,225\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_8_0 [label="Expert 8 TP-0 L7\nGPU: 224\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_8_1 [label="Expert 8 TP-1 L7\nGPU: 225\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_8 [label="TP All-Reduce Expert 8 L7\nGPU: 224↔225\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_9 [label="Route to Expert 9\nGPU: 224,225\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_9_0 [label="Expert 9 TP-0 L7\nGPU: 224\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_9_1 [label="Expert 9 TP-1 L7\nGPU: 225\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_9 [label="TP All-Reduce Expert 9 L7\nGPU: 224↔225\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_10 [label="Route to Expert 10\nGPU: 224,225\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_10_0 [label="Expert 10 TP-0 L7\nGPU: 224\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_10_1 [label="Expert 10 TP-1 L7\nGPU: 225\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_10 [label="TP All-Reduce Expert 10 L7\nGPU: 224↔225\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_11 [label="Route to Expert 11\nGPU: 224,225\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_11_0 [label="Expert 11 TP-0 L7\nGPU: 224\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_11_1 [label="Expert 11 TP-1 L7\nGPU: 225\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_11 [label="TP All-Reduce Expert 11 L7\nGPU: 224↔225\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_12 [label="Route to Expert 12\nGPU: 224,225\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_12_0 [label="Expert 12 TP-0 L7\nGPU: 224\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_12_1 [label="Expert 12 TP-1 L7\nGPU: 225\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_12 [label="TP All-Reduce Expert 12 L7\nGPU: 224↔225\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_13 [label="Route to Expert 13\nGPU: 224,225\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_13_0 [label="Expert 13 TP-0 L7\nGPU: 224\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_13_1 [label="Expert 13 TP-1 L7\nGPU: 225\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_13 [label="TP All-Reduce Expert 13 L7\nGPU: 224↔225\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_14 [label="Route to Expert 14\nGPU: 224,225\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_14_0 [label="Expert 14 TP-0 L7\nGPU: 224\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_14_1 [label="Expert 14 TP-1 L7\nGPU: 225\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_14 [label="TP All-Reduce Expert 14 L7\nGPU: 224↔225\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_15 [label="Route to Expert 15\nGPU: 224,225\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_15_0 [label="Expert 15 TP-0 L7\nGPU: 224\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_15_1 [label="Expert 15 TP-1 L7\nGPU: 225\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_15 [label="TP All-Reduce Expert 15 L7\nGPU: 224↔225\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
	}
	subgraph cluster_stage_4 {
		fillcolor=lightgray label="Pipeline Stage 4 (Layers 8-9)" style="rounded,filled"
		q_proj_8 [label="Q Projection L8\nGPU: 256-287\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		k_proj_8 [label="K Projection L8\nGPU: 256-287\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		v_proj_8 [label="V Projection L8\nGPU: 256-287\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_scores_8 [label="Attention Scores L8\nGPU: 256-287\nInput: Q,K,V [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		softmax_8 [label="Softmax L8\nGPU: 256-287\nInput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]\nOutput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_out_8 [label="Attention Output L8\nGPU: 256-287\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_8 [label="Gate L8\nGPU: 256-319\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_8_0 [label="Route to Expert 0\nGPU: 256,257\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_0_0 [label="Expert 0 TP-0 L8\nGPU: 256\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_0_1 [label="Expert 0 TP-1 L8\nGPU: 257\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_0 [label="TP All-Reduce Expert 0 L8\nGPU: 256↔257\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_1 [label="Route to Expert 1\nGPU: 256,257\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_1_0 [label="Expert 1 TP-0 L8\nGPU: 256\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_1_1 [label="Expert 1 TP-1 L8\nGPU: 257\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_1 [label="TP All-Reduce Expert 1 L8\nGPU: 256↔257\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_2 [label="Route to Expert 2\nGPU: 256,257\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_2_0 [label="Expert 2 TP-0 L8\nGPU: 256\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_2_1 [label="Expert 2 TP-1 L8\nGPU: 257\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_2 [label="TP All-Reduce Expert 2 L8\nGPU: 256↔257\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_3 [label="Route to Expert 3\nGPU: 256,257\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_3_0 [label="Expert 3 TP-0 L8\nGPU: 256\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_3_1 [label="Expert 3 TP-1 L8\nGPU: 257\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_3 [label="TP All-Reduce Expert 3 L8\nGPU: 256↔257\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_4 [label="Route to Expert 4\nGPU: 256,257\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_4_0 [label="Expert 4 TP-0 L8\nGPU: 256\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_4_1 [label="Expert 4 TP-1 L8\nGPU: 257\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_4 [label="TP All-Reduce Expert 4 L8\nGPU: 256↔257\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_5 [label="Route to Expert 5\nGPU: 256,257\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_5_0 [label="Expert 5 TP-0 L8\nGPU: 256\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_5_1 [label="Expert 5 TP-1 L8\nGPU: 257\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_5 [label="TP All-Reduce Expert 5 L8\nGPU: 256↔257\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_6 [label="Route to Expert 6\nGPU: 256,257\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_6_0 [label="Expert 6 TP-0 L8\nGPU: 256\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_6_1 [label="Expert 6 TP-1 L8\nGPU: 257\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_6 [label="TP All-Reduce Expert 6 L8\nGPU: 256↔257\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_7 [label="Route to Expert 7\nGPU: 256,257\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_7_0 [label="Expert 7 TP-0 L8\nGPU: 256\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_7_1 [label="Expert 7 TP-1 L8\nGPU: 257\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_7 [label="TP All-Reduce Expert 7 L8\nGPU: 256↔257\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_8 [label="Route to Expert 8\nGPU: 288,289\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_8_0 [label="Expert 8 TP-0 L8\nGPU: 288\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_8_1 [label="Expert 8 TP-1 L8\nGPU: 289\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_8 [label="TP All-Reduce Expert 8 L8\nGPU: 288↔289\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_9 [label="Route to Expert 9\nGPU: 288,289\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_9_0 [label="Expert 9 TP-0 L8\nGPU: 288\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_9_1 [label="Expert 9 TP-1 L8\nGPU: 289\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_9 [label="TP All-Reduce Expert 9 L8\nGPU: 288↔289\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_10 [label="Route to Expert 10\nGPU: 288,289\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_10_0 [label="Expert 10 TP-0 L8\nGPU: 288\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_10_1 [label="Expert 10 TP-1 L8\nGPU: 289\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_10 [label="TP All-Reduce Expert 10 L8\nGPU: 288↔289\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_11 [label="Route to Expert 11\nGPU: 288,289\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_11_0 [label="Expert 11 TP-0 L8\nGPU: 288\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_11_1 [label="Expert 11 TP-1 L8\nGPU: 289\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_11 [label="TP All-Reduce Expert 11 L8\nGPU: 288↔289\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_12 [label="Route to Expert 12\nGPU: 288,289\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_12_0 [label="Expert 12 TP-0 L8\nGPU: 288\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_12_1 [label="Expert 12 TP-1 L8\nGPU: 289\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_12 [label="TP All-Reduce Expert 12 L8\nGPU: 288↔289\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_13 [label="Route to Expert 13\nGPU: 288,289\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_13_0 [label="Expert 13 TP-0 L8\nGPU: 288\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_13_1 [label="Expert 13 TP-1 L8\nGPU: 289\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_13 [label="TP All-Reduce Expert 13 L8\nGPU: 288↔289\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_14 [label="Route to Expert 14\nGPU: 288,289\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_14_0 [label="Expert 14 TP-0 L8\nGPU: 288\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_14_1 [label="Expert 14 TP-1 L8\nGPU: 289\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_14 [label="TP All-Reduce Expert 14 L8\nGPU: 288↔289\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_15 [label="Route to Expert 15\nGPU: 288,289\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_15_0 [label="Expert 15 TP-0 L8\nGPU: 288\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_15_1 [label="Expert 15 TP-1 L8\nGPU: 289\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_15 [label="TP All-Reduce Expert 15 L8\nGPU: 288↔289\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		q_proj_9 [label="Q Projection L9\nGPU: 256-287\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		k_proj_9 [label="K Projection L9\nGPU: 256-287\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		v_proj_9 [label="V Projection L9\nGPU: 256-287\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_scores_9 [label="Attention Scores L9\nGPU: 256-287\nInput: Q,K,V [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		softmax_9 [label="Softmax L9\nGPU: 256-287\nInput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]\nOutput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_out_9 [label="Attention Output L9\nGPU: 256-287\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_9 [label="Gate L9\nGPU: 256-319\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_9_0 [label="Route to Expert 0\nGPU: 256,257\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_0_0 [label="Expert 0 TP-0 L9\nGPU: 256\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_0_1 [label="Expert 0 TP-1 L9\nGPU: 257\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_0 [label="TP All-Reduce Expert 0 L9\nGPU: 256↔257\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_1 [label="Route to Expert 1\nGPU: 256,257\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_1_0 [label="Expert 1 TP-0 L9\nGPU: 256\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_1_1 [label="Expert 1 TP-1 L9\nGPU: 257\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_1 [label="TP All-Reduce Expert 1 L9\nGPU: 256↔257\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_2 [label="Route to Expert 2\nGPU: 256,257\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_2_0 [label="Expert 2 TP-0 L9\nGPU: 256\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_2_1 [label="Expert 2 TP-1 L9\nGPU: 257\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_2 [label="TP All-Reduce Expert 2 L9\nGPU: 256↔257\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_3 [label="Route to Expert 3\nGPU: 256,257\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_3_0 [label="Expert 3 TP-0 L9\nGPU: 256\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_3_1 [label="Expert 3 TP-1 L9\nGPU: 257\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_3 [label="TP All-Reduce Expert 3 L9\nGPU: 256↔257\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_4 [label="Route to Expert 4\nGPU: 256,257\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_4_0 [label="Expert 4 TP-0 L9\nGPU: 256\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_4_1 [label="Expert 4 TP-1 L9\nGPU: 257\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_4 [label="TP All-Reduce Expert 4 L9\nGPU: 256↔257\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_5 [label="Route to Expert 5\nGPU: 256,257\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_5_0 [label="Expert 5 TP-0 L9\nGPU: 256\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_5_1 [label="Expert 5 TP-1 L9\nGPU: 257\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_5 [label="TP All-Reduce Expert 5 L9\nGPU: 256↔257\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_6 [label="Route to Expert 6\nGPU: 256,257\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_6_0 [label="Expert 6 TP-0 L9\nGPU: 256\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_6_1 [label="Expert 6 TP-1 L9\nGPU: 257\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_6 [label="TP All-Reduce Expert 6 L9\nGPU: 256↔257\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_7 [label="Route to Expert 7\nGPU: 256,257\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_7_0 [label="Expert 7 TP-0 L9\nGPU: 256\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_7_1 [label="Expert 7 TP-1 L9\nGPU: 257\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_7 [label="TP All-Reduce Expert 7 L9\nGPU: 256↔257\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_8 [label="Route to Expert 8\nGPU: 288,289\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_8_0 [label="Expert 8 TP-0 L9\nGPU: 288\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_8_1 [label="Expert 8 TP-1 L9\nGPU: 289\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_8 [label="TP All-Reduce Expert 8 L9\nGPU: 288↔289\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_9 [label="Route to Expert 9\nGPU: 288,289\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_9_0 [label="Expert 9 TP-0 L9\nGPU: 288\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_9_1 [label="Expert 9 TP-1 L9\nGPU: 289\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_9 [label="TP All-Reduce Expert 9 L9\nGPU: 288↔289\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_10 [label="Route to Expert 10\nGPU: 288,289\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_10_0 [label="Expert 10 TP-0 L9\nGPU: 288\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_10_1 [label="Expert 10 TP-1 L9\nGPU: 289\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_10 [label="TP All-Reduce Expert 10 L9\nGPU: 288↔289\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_11 [label="Route to Expert 11\nGPU: 288,289\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_11_0 [label="Expert 11 TP-0 L9\nGPU: 288\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_11_1 [label="Expert 11 TP-1 L9\nGPU: 289\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_11 [label="TP All-Reduce Expert 11 L9\nGPU: 288↔289\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_12 [label="Route to Expert 12\nGPU: 288,289\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_12_0 [label="Expert 12 TP-0 L9\nGPU: 288\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_12_1 [label="Expert 12 TP-1 L9\nGPU: 289\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_12 [label="TP All-Reduce Expert 12 L9\nGPU: 288↔289\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_13 [label="Route to Expert 13\nGPU: 288,289\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_13_0 [label="Expert 13 TP-0 L9\nGPU: 288\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_13_1 [label="Expert 13 TP-1 L9\nGPU: 289\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_13 [label="TP All-Reduce Expert 13 L9\nGPU: 288↔289\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_14 [label="Route to Expert 14\nGPU: 288,289\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_14_0 [label="Expert 14 TP-0 L9\nGPU: 288\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_14_1 [label="Expert 14 TP-1 L9\nGPU: 289\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_14 [label="TP All-Reduce Expert 14 L9\nGPU: 288↔289\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_15 [label="Route to Expert 15\nGPU: 288,289\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_15_0 [label="Expert 15 TP-0 L9\nGPU: 288\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_15_1 [label="Expert 15 TP-1 L9\nGPU: 289\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_15 [label="TP All-Reduce Expert 15 L9\nGPU: 288↔289\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
	}
	subgraph cluster_stage_5 {
		fillcolor=lightgray label="Pipeline Stage 5 (Layers 10-11)" style="rounded,filled"
		q_proj_10 [label="Q Projection L10\nGPU: 320-351\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		k_proj_10 [label="K Projection L10\nGPU: 320-351\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		v_proj_10 [label="V Projection L10\nGPU: 320-351\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_scores_10 [label="Attention Scores L10\nGPU: 320-351\nInput: Q,K,V [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		softmax_10 [label="Softmax L10\nGPU: 320-351\nInput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]\nOutput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_out_10 [label="Attention Output L10\nGPU: 320-351\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_10 [label="Gate L10\nGPU: 320-383\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_10_0 [label="Route to Expert 0\nGPU: 320,321\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_0_0 [label="Expert 0 TP-0 L10\nGPU: 320\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_0_1 [label="Expert 0 TP-1 L10\nGPU: 321\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_0 [label="TP All-Reduce Expert 0 L10\nGPU: 320↔321\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_1 [label="Route to Expert 1\nGPU: 320,321\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_1_0 [label="Expert 1 TP-0 L10\nGPU: 320\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_1_1 [label="Expert 1 TP-1 L10\nGPU: 321\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_1 [label="TP All-Reduce Expert 1 L10\nGPU: 320↔321\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_2 [label="Route to Expert 2\nGPU: 320,321\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_2_0 [label="Expert 2 TP-0 L10\nGPU: 320\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_2_1 [label="Expert 2 TP-1 L10\nGPU: 321\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_2 [label="TP All-Reduce Expert 2 L10\nGPU: 320↔321\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_3 [label="Route to Expert 3\nGPU: 320,321\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_3_0 [label="Expert 3 TP-0 L10\nGPU: 320\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_3_1 [label="Expert 3 TP-1 L10\nGPU: 321\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_3 [label="TP All-Reduce Expert 3 L10\nGPU: 320↔321\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_4 [label="Route to Expert 4\nGPU: 320,321\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_4_0 [label="Expert 4 TP-0 L10\nGPU: 320\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_4_1 [label="Expert 4 TP-1 L10\nGPU: 321\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_4 [label="TP All-Reduce Expert 4 L10\nGPU: 320↔321\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_5 [label="Route to Expert 5\nGPU: 320,321\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_5_0 [label="Expert 5 TP-0 L10\nGPU: 320\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_5_1 [label="Expert 5 TP-1 L10\nGPU: 321\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_5 [label="TP All-Reduce Expert 5 L10\nGPU: 320↔321\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_6 [label="Route to Expert 6\nGPU: 320,321\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_6_0 [label="Expert 6 TP-0 L10\nGPU: 320\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_6_1 [label="Expert 6 TP-1 L10\nGPU: 321\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_6 [label="TP All-Reduce Expert 6 L10\nGPU: 320↔321\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_7 [label="Route to Expert 7\nGPU: 320,321\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_7_0 [label="Expert 7 TP-0 L10\nGPU: 320\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_7_1 [label="Expert 7 TP-1 L10\nGPU: 321\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_7 [label="TP All-Reduce Expert 7 L10\nGPU: 320↔321\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_8 [label="Route to Expert 8\nGPU: 352,353\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_8_0 [label="Expert 8 TP-0 L10\nGPU: 352\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_8_1 [label="Expert 8 TP-1 L10\nGPU: 353\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_8 [label="TP All-Reduce Expert 8 L10\nGPU: 352↔353\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_9 [label="Route to Expert 9\nGPU: 352,353\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_9_0 [label="Expert 9 TP-0 L10\nGPU: 352\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_9_1 [label="Expert 9 TP-1 L10\nGPU: 353\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_9 [label="TP All-Reduce Expert 9 L10\nGPU: 352↔353\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_10 [label="Route to Expert 10\nGPU: 352,353\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_10_0 [label="Expert 10 TP-0 L10\nGPU: 352\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_10_1 [label="Expert 10 TP-1 L10\nGPU: 353\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_10 [label="TP All-Reduce Expert 10 L10\nGPU: 352↔353\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_11 [label="Route to Expert 11\nGPU: 352,353\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_11_0 [label="Expert 11 TP-0 L10\nGPU: 352\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_11_1 [label="Expert 11 TP-1 L10\nGPU: 353\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_11 [label="TP All-Reduce Expert 11 L10\nGPU: 352↔353\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_12 [label="Route to Expert 12\nGPU: 352,353\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_12_0 [label="Expert 12 TP-0 L10\nGPU: 352\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_12_1 [label="Expert 12 TP-1 L10\nGPU: 353\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_12 [label="TP All-Reduce Expert 12 L10\nGPU: 352↔353\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_13 [label="Route to Expert 13\nGPU: 352,353\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_13_0 [label="Expert 13 TP-0 L10\nGPU: 352\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_13_1 [label="Expert 13 TP-1 L10\nGPU: 353\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_13 [label="TP All-Reduce Expert 13 L10\nGPU: 352↔353\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_14 [label="Route to Expert 14\nGPU: 352,353\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_14_0 [label="Expert 14 TP-0 L10\nGPU: 352\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_14_1 [label="Expert 14 TP-1 L10\nGPU: 353\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_14 [label="TP All-Reduce Expert 14 L10\nGPU: 352↔353\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_15 [label="Route to Expert 15\nGPU: 352,353\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_15_0 [label="Expert 15 TP-0 L10\nGPU: 352\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_15_1 [label="Expert 15 TP-1 L10\nGPU: 353\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_15 [label="TP All-Reduce Expert 15 L10\nGPU: 352↔353\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		q_proj_11 [label="Q Projection L11\nGPU: 320-351\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		k_proj_11 [label="K Projection L11\nGPU: 320-351\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		v_proj_11 [label="V Projection L11\nGPU: 320-351\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_scores_11 [label="Attention Scores L11\nGPU: 320-351\nInput: Q,K,V [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		softmax_11 [label="Softmax L11\nGPU: 320-351\nInput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]\nOutput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_out_11 [label="Attention Output L11\nGPU: 320-351\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_11 [label="Gate L11\nGPU: 320-383\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_11_0 [label="Route to Expert 0\nGPU: 320,321\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_0_0 [label="Expert 0 TP-0 L11\nGPU: 320\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_0_1 [label="Expert 0 TP-1 L11\nGPU: 321\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_0 [label="TP All-Reduce Expert 0 L11\nGPU: 320↔321\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_1 [label="Route to Expert 1\nGPU: 320,321\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_1_0 [label="Expert 1 TP-0 L11\nGPU: 320\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_1_1 [label="Expert 1 TP-1 L11\nGPU: 321\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_1 [label="TP All-Reduce Expert 1 L11\nGPU: 320↔321\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_2 [label="Route to Expert 2\nGPU: 320,321\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_2_0 [label="Expert 2 TP-0 L11\nGPU: 320\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_2_1 [label="Expert 2 TP-1 L11\nGPU: 321\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_2 [label="TP All-Reduce Expert 2 L11\nGPU: 320↔321\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_3 [label="Route to Expert 3\nGPU: 320,321\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_3_0 [label="Expert 3 TP-0 L11\nGPU: 320\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_3_1 [label="Expert 3 TP-1 L11\nGPU: 321\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_3 [label="TP All-Reduce Expert 3 L11\nGPU: 320↔321\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_4 [label="Route to Expert 4\nGPU: 320,321\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_4_0 [label="Expert 4 TP-0 L11\nGPU: 320\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_4_1 [label="Expert 4 TP-1 L11\nGPU: 321\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_4 [label="TP All-Reduce Expert 4 L11\nGPU: 320↔321\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_5 [label="Route to Expert 5\nGPU: 320,321\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_5_0 [label="Expert 5 TP-0 L11\nGPU: 320\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_5_1 [label="Expert 5 TP-1 L11\nGPU: 321\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_5 [label="TP All-Reduce Expert 5 L11\nGPU: 320↔321\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_6 [label="Route to Expert 6\nGPU: 320,321\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_6_0 [label="Expert 6 TP-0 L11\nGPU: 320\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_6_1 [label="Expert 6 TP-1 L11\nGPU: 321\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_6 [label="TP All-Reduce Expert 6 L11\nGPU: 320↔321\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_7 [label="Route to Expert 7\nGPU: 320,321\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_7_0 [label="Expert 7 TP-0 L11\nGPU: 320\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_7_1 [label="Expert 7 TP-1 L11\nGPU: 321\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_7 [label="TP All-Reduce Expert 7 L11\nGPU: 320↔321\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_8 [label="Route to Expert 8\nGPU: 352,353\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_8_0 [label="Expert 8 TP-0 L11\nGPU: 352\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_8_1 [label="Expert 8 TP-1 L11\nGPU: 353\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_8 [label="TP All-Reduce Expert 8 L11\nGPU: 352↔353\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_9 [label="Route to Expert 9\nGPU: 352,353\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_9_0 [label="Expert 9 TP-0 L11\nGPU: 352\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_9_1 [label="Expert 9 TP-1 L11\nGPU: 353\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_9 [label="TP All-Reduce Expert 9 L11\nGPU: 352↔353\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_10 [label="Route to Expert 10\nGPU: 352,353\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_10_0 [label="Expert 10 TP-0 L11\nGPU: 352\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_10_1 [label="Expert 10 TP-1 L11\nGPU: 353\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_10 [label="TP All-Reduce Expert 10 L11\nGPU: 352↔353\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_11 [label="Route to Expert 11\nGPU: 352,353\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_11_0 [label="Expert 11 TP-0 L11\nGPU: 352\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_11_1 [label="Expert 11 TP-1 L11\nGPU: 353\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_11 [label="TP All-Reduce Expert 11 L11\nGPU: 352↔353\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_12 [label="Route to Expert 12\nGPU: 352,353\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_12_0 [label="Expert 12 TP-0 L11\nGPU: 352\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_12_1 [label="Expert 12 TP-1 L11\nGPU: 353\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_12 [label="TP All-Reduce Expert 12 L11\nGPU: 352↔353\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_13 [label="Route to Expert 13\nGPU: 352,353\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_13_0 [label="Expert 13 TP-0 L11\nGPU: 352\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_13_1 [label="Expert 13 TP-1 L11\nGPU: 353\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_13 [label="TP All-Reduce Expert 13 L11\nGPU: 352↔353\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_14 [label="Route to Expert 14\nGPU: 352,353\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_14_0 [label="Expert 14 TP-0 L11\nGPU: 352\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_14_1 [label="Expert 14 TP-1 L11\nGPU: 353\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_14 [label="TP All-Reduce Expert 14 L11\nGPU: 352↔353\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_15 [label="Route to Expert 15\nGPU: 352,353\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_15_0 [label="Expert 15 TP-0 L11\nGPU: 352\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_15_1 [label="Expert 15 TP-1 L11\nGPU: 353\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_15 [label="TP All-Reduce Expert 15 L11\nGPU: 352↔353\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
	}
	subgraph cluster_stage_6 {
		fillcolor=lightgray label="Pipeline Stage 6 (Layers 12-13)" style="rounded,filled"
		q_proj_12 [label="Q Projection L12\nGPU: 384-415\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		k_proj_12 [label="K Projection L12\nGPU: 384-415\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		v_proj_12 [label="V Projection L12\nGPU: 384-415\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_scores_12 [label="Attention Scores L12\nGPU: 384-415\nInput: Q,K,V [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		softmax_12 [label="Softmax L12\nGPU: 384-415\nInput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]\nOutput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_out_12 [label="Attention Output L12\nGPU: 384-415\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_12 [label="Gate L12\nGPU: 384-447\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_12_0 [label="Route to Expert 0\nGPU: 384,385\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_0_0 [label="Expert 0 TP-0 L12\nGPU: 384\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_0_1 [label="Expert 0 TP-1 L12\nGPU: 385\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_0 [label="TP All-Reduce Expert 0 L12\nGPU: 384↔385\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_1 [label="Route to Expert 1\nGPU: 384,385\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_1_0 [label="Expert 1 TP-0 L12\nGPU: 384\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_1_1 [label="Expert 1 TP-1 L12\nGPU: 385\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_1 [label="TP All-Reduce Expert 1 L12\nGPU: 384↔385\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_2 [label="Route to Expert 2\nGPU: 384,385\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_2_0 [label="Expert 2 TP-0 L12\nGPU: 384\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_2_1 [label="Expert 2 TP-1 L12\nGPU: 385\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_2 [label="TP All-Reduce Expert 2 L12\nGPU: 384↔385\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_3 [label="Route to Expert 3\nGPU: 384,385\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_3_0 [label="Expert 3 TP-0 L12\nGPU: 384\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_3_1 [label="Expert 3 TP-1 L12\nGPU: 385\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_3 [label="TP All-Reduce Expert 3 L12\nGPU: 384↔385\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_4 [label="Route to Expert 4\nGPU: 384,385\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_4_0 [label="Expert 4 TP-0 L12\nGPU: 384\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_4_1 [label="Expert 4 TP-1 L12\nGPU: 385\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_4 [label="TP All-Reduce Expert 4 L12\nGPU: 384↔385\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_5 [label="Route to Expert 5\nGPU: 384,385\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_5_0 [label="Expert 5 TP-0 L12\nGPU: 384\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_5_1 [label="Expert 5 TP-1 L12\nGPU: 385\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_5 [label="TP All-Reduce Expert 5 L12\nGPU: 384↔385\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_6 [label="Route to Expert 6\nGPU: 384,385\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_6_0 [label="Expert 6 TP-0 L12\nGPU: 384\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_6_1 [label="Expert 6 TP-1 L12\nGPU: 385\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_6 [label="TP All-Reduce Expert 6 L12\nGPU: 384↔385\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_7 [label="Route to Expert 7\nGPU: 384,385\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_7_0 [label="Expert 7 TP-0 L12\nGPU: 384\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_7_1 [label="Expert 7 TP-1 L12\nGPU: 385\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_7 [label="TP All-Reduce Expert 7 L12\nGPU: 384↔385\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_8 [label="Route to Expert 8\nGPU: 416,417\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_8_0 [label="Expert 8 TP-0 L12\nGPU: 416\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_8_1 [label="Expert 8 TP-1 L12\nGPU: 417\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_8 [label="TP All-Reduce Expert 8 L12\nGPU: 416↔417\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_9 [label="Route to Expert 9\nGPU: 416,417\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_9_0 [label="Expert 9 TP-0 L12\nGPU: 416\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_9_1 [label="Expert 9 TP-1 L12\nGPU: 417\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_9 [label="TP All-Reduce Expert 9 L12\nGPU: 416↔417\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_10 [label="Route to Expert 10\nGPU: 416,417\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_10_0 [label="Expert 10 TP-0 L12\nGPU: 416\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_10_1 [label="Expert 10 TP-1 L12\nGPU: 417\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_10 [label="TP All-Reduce Expert 10 L12\nGPU: 416↔417\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_11 [label="Route to Expert 11\nGPU: 416,417\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_11_0 [label="Expert 11 TP-0 L12\nGPU: 416\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_11_1 [label="Expert 11 TP-1 L12\nGPU: 417\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_11 [label="TP All-Reduce Expert 11 L12\nGPU: 416↔417\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_12 [label="Route to Expert 12\nGPU: 416,417\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_12_0 [label="Expert 12 TP-0 L12\nGPU: 416\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_12_1 [label="Expert 12 TP-1 L12\nGPU: 417\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_12 [label="TP All-Reduce Expert 12 L12\nGPU: 416↔417\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_13 [label="Route to Expert 13\nGPU: 416,417\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_13_0 [label="Expert 13 TP-0 L12\nGPU: 416\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_13_1 [label="Expert 13 TP-1 L12\nGPU: 417\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_13 [label="TP All-Reduce Expert 13 L12\nGPU: 416↔417\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_14 [label="Route to Expert 14\nGPU: 416,417\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_14_0 [label="Expert 14 TP-0 L12\nGPU: 416\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_14_1 [label="Expert 14 TP-1 L12\nGPU: 417\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_14 [label="TP All-Reduce Expert 14 L12\nGPU: 416↔417\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_15 [label="Route to Expert 15\nGPU: 416,417\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_15_0 [label="Expert 15 TP-0 L12\nGPU: 416\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_15_1 [label="Expert 15 TP-1 L12\nGPU: 417\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_15 [label="TP All-Reduce Expert 15 L12\nGPU: 416↔417\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		q_proj_13 [label="Q Projection L13\nGPU: 384-415\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		k_proj_13 [label="K Projection L13\nGPU: 384-415\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		v_proj_13 [label="V Projection L13\nGPU: 384-415\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_scores_13 [label="Attention Scores L13\nGPU: 384-415\nInput: Q,K,V [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		softmax_13 [label="Softmax L13\nGPU: 384-415\nInput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]\nOutput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_out_13 [label="Attention Output L13\nGPU: 384-415\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_13 [label="Gate L13\nGPU: 384-447\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_13_0 [label="Route to Expert 0\nGPU: 384,385\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_0_0 [label="Expert 0 TP-0 L13\nGPU: 384\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_0_1 [label="Expert 0 TP-1 L13\nGPU: 385\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_0 [label="TP All-Reduce Expert 0 L13\nGPU: 384↔385\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_1 [label="Route to Expert 1\nGPU: 384,385\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_1_0 [label="Expert 1 TP-0 L13\nGPU: 384\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_1_1 [label="Expert 1 TP-1 L13\nGPU: 385\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_1 [label="TP All-Reduce Expert 1 L13\nGPU: 384↔385\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_2 [label="Route to Expert 2\nGPU: 384,385\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_2_0 [label="Expert 2 TP-0 L13\nGPU: 384\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_2_1 [label="Expert 2 TP-1 L13\nGPU: 385\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_2 [label="TP All-Reduce Expert 2 L13\nGPU: 384↔385\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_3 [label="Route to Expert 3\nGPU: 384,385\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_3_0 [label="Expert 3 TP-0 L13\nGPU: 384\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_3_1 [label="Expert 3 TP-1 L13\nGPU: 385\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_3 [label="TP All-Reduce Expert 3 L13\nGPU: 384↔385\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_4 [label="Route to Expert 4\nGPU: 384,385\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_4_0 [label="Expert 4 TP-0 L13\nGPU: 384\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_4_1 [label="Expert 4 TP-1 L13\nGPU: 385\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_4 [label="TP All-Reduce Expert 4 L13\nGPU: 384↔385\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_5 [label="Route to Expert 5\nGPU: 384,385\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_5_0 [label="Expert 5 TP-0 L13\nGPU: 384\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_5_1 [label="Expert 5 TP-1 L13\nGPU: 385\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_5 [label="TP All-Reduce Expert 5 L13\nGPU: 384↔385\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_6 [label="Route to Expert 6\nGPU: 384,385\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_6_0 [label="Expert 6 TP-0 L13\nGPU: 384\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_6_1 [label="Expert 6 TP-1 L13\nGPU: 385\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_6 [label="TP All-Reduce Expert 6 L13\nGPU: 384↔385\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_7 [label="Route to Expert 7\nGPU: 384,385\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_7_0 [label="Expert 7 TP-0 L13\nGPU: 384\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_7_1 [label="Expert 7 TP-1 L13\nGPU: 385\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_7 [label="TP All-Reduce Expert 7 L13\nGPU: 384↔385\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_8 [label="Route to Expert 8\nGPU: 416,417\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_8_0 [label="Expert 8 TP-0 L13\nGPU: 416\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_8_1 [label="Expert 8 TP-1 L13\nGPU: 417\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_8 [label="TP All-Reduce Expert 8 L13\nGPU: 416↔417\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_9 [label="Route to Expert 9\nGPU: 416,417\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_9_0 [label="Expert 9 TP-0 L13\nGPU: 416\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_9_1 [label="Expert 9 TP-1 L13\nGPU: 417\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_9 [label="TP All-Reduce Expert 9 L13\nGPU: 416↔417\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_10 [label="Route to Expert 10\nGPU: 416,417\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_10_0 [label="Expert 10 TP-0 L13\nGPU: 416\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_10_1 [label="Expert 10 TP-1 L13\nGPU: 417\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_10 [label="TP All-Reduce Expert 10 L13\nGPU: 416↔417\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_11 [label="Route to Expert 11\nGPU: 416,417\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_11_0 [label="Expert 11 TP-0 L13\nGPU: 416\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_11_1 [label="Expert 11 TP-1 L13\nGPU: 417\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_11 [label="TP All-Reduce Expert 11 L13\nGPU: 416↔417\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_12 [label="Route to Expert 12\nGPU: 416,417\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_12_0 [label="Expert 12 TP-0 L13\nGPU: 416\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_12_1 [label="Expert 12 TP-1 L13\nGPU: 417\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_12 [label="TP All-Reduce Expert 12 L13\nGPU: 416↔417\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_13 [label="Route to Expert 13\nGPU: 416,417\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_13_0 [label="Expert 13 TP-0 L13\nGPU: 416\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_13_1 [label="Expert 13 TP-1 L13\nGPU: 417\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_13 [label="TP All-Reduce Expert 13 L13\nGPU: 416↔417\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_14 [label="Route to Expert 14\nGPU: 416,417\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_14_0 [label="Expert 14 TP-0 L13\nGPU: 416\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_14_1 [label="Expert 14 TP-1 L13\nGPU: 417\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_14 [label="TP All-Reduce Expert 14 L13\nGPU: 416↔417\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_15 [label="Route to Expert 15\nGPU: 416,417\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_15_0 [label="Expert 15 TP-0 L13\nGPU: 416\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_15_1 [label="Expert 15 TP-1 L13\nGPU: 417\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_15 [label="TP All-Reduce Expert 15 L13\nGPU: 416↔417\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
	}
	subgraph cluster_stage_7 {
		fillcolor=lightgray label="Pipeline Stage 7 (Layers 14-15)" style="rounded,filled"
		q_proj_14 [label="Q Projection L14\nGPU: 448-479\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		k_proj_14 [label="K Projection L14\nGPU: 448-479\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		v_proj_14 [label="V Projection L14\nGPU: 448-479\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_scores_14 [label="Attention Scores L14\nGPU: 448-479\nInput: Q,K,V [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		softmax_14 [label="Softmax L14\nGPU: 448-479\nInput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]\nOutput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_out_14 [label="Attention Output L14\nGPU: 448-479\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_14 [label="Gate L14\nGPU: 448-511\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_14_0 [label="Route to Expert 0\nGPU: 448,449\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_0_0 [label="Expert 0 TP-0 L14\nGPU: 448\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_0_1 [label="Expert 0 TP-1 L14\nGPU: 449\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_0 [label="TP All-Reduce Expert 0 L14\nGPU: 448↔449\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_1 [label="Route to Expert 1\nGPU: 448,449\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_1_0 [label="Expert 1 TP-0 L14\nGPU: 448\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_1_1 [label="Expert 1 TP-1 L14\nGPU: 449\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_1 [label="TP All-Reduce Expert 1 L14\nGPU: 448↔449\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_2 [label="Route to Expert 2\nGPU: 448,449\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_2_0 [label="Expert 2 TP-0 L14\nGPU: 448\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_2_1 [label="Expert 2 TP-1 L14\nGPU: 449\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_2 [label="TP All-Reduce Expert 2 L14\nGPU: 448↔449\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_3 [label="Route to Expert 3\nGPU: 448,449\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_3_0 [label="Expert 3 TP-0 L14\nGPU: 448\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_3_1 [label="Expert 3 TP-1 L14\nGPU: 449\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_3 [label="TP All-Reduce Expert 3 L14\nGPU: 448↔449\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_4 [label="Route to Expert 4\nGPU: 448,449\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_4_0 [label="Expert 4 TP-0 L14\nGPU: 448\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_4_1 [label="Expert 4 TP-1 L14\nGPU: 449\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_4 [label="TP All-Reduce Expert 4 L14\nGPU: 448↔449\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_5 [label="Route to Expert 5\nGPU: 448,449\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_5_0 [label="Expert 5 TP-0 L14\nGPU: 448\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_5_1 [label="Expert 5 TP-1 L14\nGPU: 449\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_5 [label="TP All-Reduce Expert 5 L14\nGPU: 448↔449\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_6 [label="Route to Expert 6\nGPU: 448,449\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_6_0 [label="Expert 6 TP-0 L14\nGPU: 448\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_6_1 [label="Expert 6 TP-1 L14\nGPU: 449\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_6 [label="TP All-Reduce Expert 6 L14\nGPU: 448↔449\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_7 [label="Route to Expert 7\nGPU: 448,449\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_7_0 [label="Expert 7 TP-0 L14\nGPU: 448\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_7_1 [label="Expert 7 TP-1 L14\nGPU: 449\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_7 [label="TP All-Reduce Expert 7 L14\nGPU: 448↔449\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_8 [label="Route to Expert 8\nGPU: 480,481\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_8_0 [label="Expert 8 TP-0 L14\nGPU: 480\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_8_1 [label="Expert 8 TP-1 L14\nGPU: 481\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_8 [label="TP All-Reduce Expert 8 L14\nGPU: 480↔481\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_9 [label="Route to Expert 9\nGPU: 480,481\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_9_0 [label="Expert 9 TP-0 L14\nGPU: 480\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_9_1 [label="Expert 9 TP-1 L14\nGPU: 481\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_9 [label="TP All-Reduce Expert 9 L14\nGPU: 480↔481\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_10 [label="Route to Expert 10\nGPU: 480,481\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_10_0 [label="Expert 10 TP-0 L14\nGPU: 480\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_10_1 [label="Expert 10 TP-1 L14\nGPU: 481\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_10 [label="TP All-Reduce Expert 10 L14\nGPU: 480↔481\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_11 [label="Route to Expert 11\nGPU: 480,481\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_11_0 [label="Expert 11 TP-0 L14\nGPU: 480\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_11_1 [label="Expert 11 TP-1 L14\nGPU: 481\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_11 [label="TP All-Reduce Expert 11 L14\nGPU: 480↔481\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_12 [label="Route to Expert 12\nGPU: 480,481\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_12_0 [label="Expert 12 TP-0 L14\nGPU: 480\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_12_1 [label="Expert 12 TP-1 L14\nGPU: 481\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_12 [label="TP All-Reduce Expert 12 L14\nGPU: 480↔481\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_13 [label="Route to Expert 13\nGPU: 480,481\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_13_0 [label="Expert 13 TP-0 L14\nGPU: 480\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_13_1 [label="Expert 13 TP-1 L14\nGPU: 481\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_13 [label="TP All-Reduce Expert 13 L14\nGPU: 480↔481\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_14 [label="Route to Expert 14\nGPU: 480,481\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_14_0 [label="Expert 14 TP-0 L14\nGPU: 480\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_14_1 [label="Expert 14 TP-1 L14\nGPU: 481\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_14 [label="TP All-Reduce Expert 14 L14\nGPU: 480↔481\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_15 [label="Route to Expert 15\nGPU: 480,481\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_15_0 [label="Expert 15 TP-0 L14\nGPU: 480\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_15_1 [label="Expert 15 TP-1 L14\nGPU: 481\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_15 [label="TP All-Reduce Expert 15 L14\nGPU: 480↔481\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		q_proj_15 [label="Q Projection L15\nGPU: 448-479\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		k_proj_15 [label="K Projection L15\nGPU: 448-479\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		v_proj_15 [label="V Projection L15\nGPU: 448-479\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_scores_15 [label="Attention Scores L15\nGPU: 448-479\nInput: Q,K,V [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		softmax_15 [label="Softmax L15\nGPU: 448-479\nInput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]\nOutput: [batch_size=128, seq_len=10240, heads=16, seq_len=10240]" fillcolor=lightgreen shape=rectangle style=filled]
		attn_out_15 [label="Attention Output L15\nGPU: 448-479\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_15 [label="Gate L15\nGPU: 448-511\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_15_0 [label="Route to Expert 0\nGPU: 448,449\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_0_0 [label="Expert 0 TP-0 L15\nGPU: 448\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_0_1 [label="Expert 0 TP-1 L15\nGPU: 449\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_0 [label="TP All-Reduce Expert 0 L15\nGPU: 448↔449\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_1 [label="Route to Expert 1\nGPU: 448,449\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_1_0 [label="Expert 1 TP-0 L15\nGPU: 448\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_1_1 [label="Expert 1 TP-1 L15\nGPU: 449\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_1 [label="TP All-Reduce Expert 1 L15\nGPU: 448↔449\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_2 [label="Route to Expert 2\nGPU: 448,449\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_2_0 [label="Expert 2 TP-0 L15\nGPU: 448\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_2_1 [label="Expert 2 TP-1 L15\nGPU: 449\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_2 [label="TP All-Reduce Expert 2 L15\nGPU: 448↔449\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_3 [label="Route to Expert 3\nGPU: 448,449\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_3_0 [label="Expert 3 TP-0 L15\nGPU: 448\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_3_1 [label="Expert 3 TP-1 L15\nGPU: 449\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_3 [label="TP All-Reduce Expert 3 L15\nGPU: 448↔449\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_4 [label="Route to Expert 4\nGPU: 448,449\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_4_0 [label="Expert 4 TP-0 L15\nGPU: 448\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_4_1 [label="Expert 4 TP-1 L15\nGPU: 449\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_4 [label="TP All-Reduce Expert 4 L15\nGPU: 448↔449\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_5 [label="Route to Expert 5\nGPU: 448,449\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_5_0 [label="Expert 5 TP-0 L15\nGPU: 448\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_5_1 [label="Expert 5 TP-1 L15\nGPU: 449\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_5 [label="TP All-Reduce Expert 5 L15\nGPU: 448↔449\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_6 [label="Route to Expert 6\nGPU: 448,449\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_6_0 [label="Expert 6 TP-0 L15\nGPU: 448\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_6_1 [label="Expert 6 TP-1 L15\nGPU: 449\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_6 [label="TP All-Reduce Expert 6 L15\nGPU: 448↔449\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_7 [label="Route to Expert 7\nGPU: 448,449\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_7_0 [label="Expert 7 TP-0 L15\nGPU: 448\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_7_1 [label="Expert 7 TP-1 L15\nGPU: 449\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_7 [label="TP All-Reduce Expert 7 L15\nGPU: 448↔449\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_8 [label="Route to Expert 8\nGPU: 480,481\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_8_0 [label="Expert 8 TP-0 L15\nGPU: 480\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_8_1 [label="Expert 8 TP-1 L15\nGPU: 481\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_8 [label="TP All-Reduce Expert 8 L15\nGPU: 480↔481\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_9 [label="Route to Expert 9\nGPU: 480,481\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_9_0 [label="Expert 9 TP-0 L15\nGPU: 480\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_9_1 [label="Expert 9 TP-1 L15\nGPU: 481\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_9 [label="TP All-Reduce Expert 9 L15\nGPU: 480↔481\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_10 [label="Route to Expert 10\nGPU: 480,481\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_10_0 [label="Expert 10 TP-0 L15\nGPU: 480\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_10_1 [label="Expert 10 TP-1 L15\nGPU: 481\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_10 [label="TP All-Reduce Expert 10 L15\nGPU: 480↔481\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_11 [label="Route to Expert 11\nGPU: 480,481\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_11_0 [label="Expert 11 TP-0 L15\nGPU: 480\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_11_1 [label="Expert 11 TP-1 L15\nGPU: 481\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_11 [label="TP All-Reduce Expert 11 L15\nGPU: 480↔481\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_12 [label="Route to Expert 12\nGPU: 480,481\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_12_0 [label="Expert 12 TP-0 L15\nGPU: 480\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_12_1 [label="Expert 12 TP-1 L15\nGPU: 481\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_12 [label="TP All-Reduce Expert 12 L15\nGPU: 480↔481\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_13 [label="Route to Expert 13\nGPU: 480,481\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_13_0 [label="Expert 13 TP-0 L15\nGPU: 480\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_13_1 [label="Expert 13 TP-1 L15\nGPU: 481\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_13 [label="TP All-Reduce Expert 13 L15\nGPU: 480↔481\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_14 [label="Route to Expert 14\nGPU: 480,481\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_14_0 [label="Expert 14 TP-0 L15\nGPU: 480\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_14_1 [label="Expert 14 TP-1 L15\nGPU: 481\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_14 [label="TP All-Reduce Expert 14 L15\nGPU: 480↔481\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_15 [label="Route to Expert 15\nGPU: 480,481\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_15_0 [label="Expert 15 TP-0 L15\nGPU: 480\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_15_1 [label="Expert 15 TP-1 L15\nGPU: 481\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_15 [label="TP All-Reduce Expert 15 L15\nGPU: 480↔481\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
	}
	output [label="Output\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style=filled]
	input -> q_proj_0
	input -> k_proj_0
	input -> v_proj_0
	q_proj_0 -> attn_scores_0
	k_proj_0 -> attn_scores_0
	v_proj_0 -> attn_scores_0
	attn_scores_0 -> softmax_0
	softmax_0 -> attn_out_0
	attn_out_0 -> gate_0
	gate_0 -> route_0_0 [style=dashed]
	route_0_0 -> expert_0_0_0
	route_0_0 -> expert_0_0_1
	expert_0_0_0 -> tp_0_0
	expert_0_0_1 -> tp_0_0
	gate_0 -> route_0_1 [style=dashed]
	route_0_1 -> expert_0_1_0
	route_0_1 -> expert_0_1_1
	expert_0_1_0 -> tp_0_1
	expert_0_1_1 -> tp_0_1
	gate_0 -> route_0_2 [style=dashed]
	route_0_2 -> expert_0_2_0
	route_0_2 -> expert_0_2_1
	expert_0_2_0 -> tp_0_2
	expert_0_2_1 -> tp_0_2
	gate_0 -> route_0_3 [style=dashed]
	route_0_3 -> expert_0_3_0
	route_0_3 -> expert_0_3_1
	expert_0_3_0 -> tp_0_3
	expert_0_3_1 -> tp_0_3
	gate_0 -> route_0_4 [style=dashed]
	route_0_4 -> expert_0_4_0
	route_0_4 -> expert_0_4_1
	expert_0_4_0 -> tp_0_4
	expert_0_4_1 -> tp_0_4
	gate_0 -> route_0_5 [style=dashed]
	route_0_5 -> expert_0_5_0
	route_0_5 -> expert_0_5_1
	expert_0_5_0 -> tp_0_5
	expert_0_5_1 -> tp_0_5
	gate_0 -> route_0_6 [style=dashed]
	route_0_6 -> expert_0_6_0
	route_0_6 -> expert_0_6_1
	expert_0_6_0 -> tp_0_6
	expert_0_6_1 -> tp_0_6
	gate_0 -> route_0_7 [style=dashed]
	route_0_7 -> expert_0_7_0
	route_0_7 -> expert_0_7_1
	expert_0_7_0 -> tp_0_7
	expert_0_7_1 -> tp_0_7
	gate_0 -> route_0_8 [style=dashed]
	route_0_8 -> expert_0_8_0
	route_0_8 -> expert_0_8_1
	expert_0_8_0 -> tp_0_8
	expert_0_8_1 -> tp_0_8
	gate_0 -> route_0_9 [style=dashed]
	route_0_9 -> expert_0_9_0
	route_0_9 -> expert_0_9_1
	expert_0_9_0 -> tp_0_9
	expert_0_9_1 -> tp_0_9
	gate_0 -> route_0_10 [style=dashed]
	route_0_10 -> expert_0_10_0
	route_0_10 -> expert_0_10_1
	expert_0_10_0 -> tp_0_10
	expert_0_10_1 -> tp_0_10
	gate_0 -> route_0_11 [style=dashed]
	route_0_11 -> expert_0_11_0
	route_0_11 -> expert_0_11_1
	expert_0_11_0 -> tp_0_11
	expert_0_11_1 -> tp_0_11
	gate_0 -> route_0_12 [style=dashed]
	route_0_12 -> expert_0_12_0
	route_0_12 -> expert_0_12_1
	expert_0_12_0 -> tp_0_12
	expert_0_12_1 -> tp_0_12
	gate_0 -> route_0_13 [style=dashed]
	route_0_13 -> expert_0_13_0
	route_0_13 -> expert_0_13_1
	expert_0_13_0 -> tp_0_13
	expert_0_13_1 -> tp_0_13
	gate_0 -> route_0_14 [style=dashed]
	route_0_14 -> expert_0_14_0
	route_0_14 -> expert_0_14_1
	expert_0_14_0 -> tp_0_14
	expert_0_14_1 -> tp_0_14
	gate_0 -> route_0_15 [style=dashed]
	route_0_15 -> expert_0_15_0
	route_0_15 -> expert_0_15_1
	expert_0_15_0 -> tp_0_15
	expert_0_15_1 -> tp_0_15
	tp_15_15 -> output
}
