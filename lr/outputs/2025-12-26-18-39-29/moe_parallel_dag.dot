// MoE Parallel Strategy DAG
digraph {
	dpi=300 rankdir=TB size="30,30"
	node [fontsize=9 margin=0.03]
	input [label="Input\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style=filled]
	subgraph cluster_stage_0 {
		fillcolor=lightgray label="Pipeline Stage 0 (Layers 0-1)" style="rounded,filled"
		mha_0 [label="MHA L0\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_0 [label="Gate L0\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_0_0 [label="Route to Expert 0\nGPU: 0,1\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_0_0 [label="Expert 0 TP-0\nGPU: 0\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_0_1 [label="Expert 0 TP-1\nGPU: 1\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_0 [label="TP All-Reduce\nGPU: 0↔1\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_1 [label="Route to Expert 1\nGPU: 2,3\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_1_0 [label="Expert 1 TP-0\nGPU: 2\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_1_1 [label="Expert 1 TP-1\nGPU: 3\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_1 [label="TP All-Reduce\nGPU: 2↔3\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_2 [label="Route to Expert 2\nGPU: 4,5\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_2_0 [label="Expert 2 TP-0\nGPU: 4\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_2_1 [label="Expert 2 TP-1\nGPU: 5\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_2 [label="TP All-Reduce\nGPU: 4↔5\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_3 [label="Route to Expert 3\nGPU: 6,7\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_3_0 [label="Expert 3 TP-0\nGPU: 6\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_3_1 [label="Expert 3 TP-1\nGPU: 7\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_3 [label="TP All-Reduce\nGPU: 6↔7\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_4 [label="Route to Expert 4\nGPU: 8,9\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_4_0 [label="Expert 4 TP-0\nGPU: 8\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_4_1 [label="Expert 4 TP-1\nGPU: 9\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_4 [label="TP All-Reduce\nGPU: 8↔9\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_5 [label="Route to Expert 5\nGPU: 10,11\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_5_0 [label="Expert 5 TP-0\nGPU: 10\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_5_1 [label="Expert 5 TP-1\nGPU: 11\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_5 [label="TP All-Reduce\nGPU: 10↔11\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_6 [label="Route to Expert 6\nGPU: 12,13\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_6_0 [label="Expert 6 TP-0\nGPU: 12\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_6_1 [label="Expert 6 TP-1\nGPU: 13\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_6 [label="TP All-Reduce\nGPU: 12↔13\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_7 [label="Route to Expert 7\nGPU: 14,15\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_7_0 [label="Expert 7 TP-0\nGPU: 14\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_7_1 [label="Expert 7 TP-1\nGPU: 15\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_7 [label="TP All-Reduce\nGPU: 14↔15\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_8 [label="Route to Expert 8\nGPU: 16,17\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_8_0 [label="Expert 8 TP-0\nGPU: 16\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_8_1 [label="Expert 8 TP-1\nGPU: 17\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_8 [label="TP All-Reduce\nGPU: 16↔17\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_9 [label="Route to Expert 9\nGPU: 18,19\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_9_0 [label="Expert 9 TP-0\nGPU: 18\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_9_1 [label="Expert 9 TP-1\nGPU: 19\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_9 [label="TP All-Reduce\nGPU: 18↔19\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_10 [label="Route to Expert 10\nGPU: 20,21\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_10_0 [label="Expert 10 TP-0\nGPU: 20\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_10_1 [label="Expert 10 TP-1\nGPU: 21\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_10 [label="TP All-Reduce\nGPU: 20↔21\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_11 [label="Route to Expert 11\nGPU: 22,23\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_11_0 [label="Expert 11 TP-0\nGPU: 22\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_11_1 [label="Expert 11 TP-1\nGPU: 23\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_11 [label="TP All-Reduce\nGPU: 22↔23\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_12 [label="Route to Expert 12\nGPU: 24,25\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_12_0 [label="Expert 12 TP-0\nGPU: 24\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_12_1 [label="Expert 12 TP-1\nGPU: 25\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_12 [label="TP All-Reduce\nGPU: 24↔25\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_13 [label="Route to Expert 13\nGPU: 26,27\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_13_0 [label="Expert 13 TP-0\nGPU: 26\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_13_1 [label="Expert 13 TP-1\nGPU: 27\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_13 [label="TP All-Reduce\nGPU: 26↔27\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_14 [label="Route to Expert 14\nGPU: 28,29\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_14_0 [label="Expert 14 TP-0\nGPU: 28\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_14_1 [label="Expert 14 TP-1\nGPU: 29\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_14 [label="TP All-Reduce\nGPU: 28↔29\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_0_15 [label="Route to Expert 15\nGPU: 30,31\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_0_15_0 [label="Expert 15 TP-0\nGPU: 30\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_0_15_1 [label="Expert 15 TP-1\nGPU: 31\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_0_15 [label="TP All-Reduce\nGPU: 30↔31\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		agg_0 [label="Aggregate Experts L0\nGPU: 0-511\nInput: 16 expert outputs\nOutput: [batch_size=128, seq_len=10240, hidden=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
		output_0 [label="Layer 0 Output\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, hidden=1024]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		mha_1 [label="MHA L1\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_1 [label="Gate L1\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_1_0 [label="Route to Expert 0\nGPU: 32,33\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_0_0 [label="Expert 0 TP-0\nGPU: 32\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_0_1 [label="Expert 0 TP-1\nGPU: 33\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_0 [label="TP All-Reduce\nGPU: 32↔33\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_1 [label="Route to Expert 1\nGPU: 34,35\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_1_0 [label="Expert 1 TP-0\nGPU: 34\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_1_1 [label="Expert 1 TP-1\nGPU: 35\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_1 [label="TP All-Reduce\nGPU: 34↔35\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_2 [label="Route to Expert 2\nGPU: 36,37\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_2_0 [label="Expert 2 TP-0\nGPU: 36\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_2_1 [label="Expert 2 TP-1\nGPU: 37\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_2 [label="TP All-Reduce\nGPU: 36↔37\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_3 [label="Route to Expert 3\nGPU: 38,39\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_3_0 [label="Expert 3 TP-0\nGPU: 38\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_3_1 [label="Expert 3 TP-1\nGPU: 39\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_3 [label="TP All-Reduce\nGPU: 38↔39\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_4 [label="Route to Expert 4\nGPU: 40,41\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_4_0 [label="Expert 4 TP-0\nGPU: 40\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_4_1 [label="Expert 4 TP-1\nGPU: 41\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_4 [label="TP All-Reduce\nGPU: 40↔41\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_5 [label="Route to Expert 5\nGPU: 42,43\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_5_0 [label="Expert 5 TP-0\nGPU: 42\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_5_1 [label="Expert 5 TP-1\nGPU: 43\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_5 [label="TP All-Reduce\nGPU: 42↔43\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_6 [label="Route to Expert 6\nGPU: 44,45\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_6_0 [label="Expert 6 TP-0\nGPU: 44\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_6_1 [label="Expert 6 TP-1\nGPU: 45\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_6 [label="TP All-Reduce\nGPU: 44↔45\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_7 [label="Route to Expert 7\nGPU: 46,47\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_7_0 [label="Expert 7 TP-0\nGPU: 46\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_7_1 [label="Expert 7 TP-1\nGPU: 47\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_7 [label="TP All-Reduce\nGPU: 46↔47\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_8 [label="Route to Expert 8\nGPU: 48,49\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_8_0 [label="Expert 8 TP-0\nGPU: 48\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_8_1 [label="Expert 8 TP-1\nGPU: 49\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_8 [label="TP All-Reduce\nGPU: 48↔49\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_9 [label="Route to Expert 9\nGPU: 50,51\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_9_0 [label="Expert 9 TP-0\nGPU: 50\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_9_1 [label="Expert 9 TP-1\nGPU: 51\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_9 [label="TP All-Reduce\nGPU: 50↔51\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_10 [label="Route to Expert 10\nGPU: 52,53\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_10_0 [label="Expert 10 TP-0\nGPU: 52\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_10_1 [label="Expert 10 TP-1\nGPU: 53\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_10 [label="TP All-Reduce\nGPU: 52↔53\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_11 [label="Route to Expert 11\nGPU: 54,55\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_11_0 [label="Expert 11 TP-0\nGPU: 54\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_11_1 [label="Expert 11 TP-1\nGPU: 55\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_11 [label="TP All-Reduce\nGPU: 54↔55\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_12 [label="Route to Expert 12\nGPU: 56,57\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_12_0 [label="Expert 12 TP-0\nGPU: 56\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_12_1 [label="Expert 12 TP-1\nGPU: 57\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_12 [label="TP All-Reduce\nGPU: 56↔57\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_13 [label="Route to Expert 13\nGPU: 58,59\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_13_0 [label="Expert 13 TP-0\nGPU: 58\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_13_1 [label="Expert 13 TP-1\nGPU: 59\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_13 [label="TP All-Reduce\nGPU: 58↔59\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_14 [label="Route to Expert 14\nGPU: 60,61\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_14_0 [label="Expert 14 TP-0\nGPU: 60\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_14_1 [label="Expert 14 TP-1\nGPU: 61\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_14 [label="TP All-Reduce\nGPU: 60↔61\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_1_15 [label="Route to Expert 15\nGPU: 62,63\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_1_15_0 [label="Expert 15 TP-0\nGPU: 62\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_1_15_1 [label="Expert 15 TP-1\nGPU: 63\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_1_15 [label="TP All-Reduce\nGPU: 62↔63\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		agg_1 [label="Aggregate Experts L1\nGPU: 0-511\nInput: 16 expert outputs\nOutput: [batch_size=128, seq_len=10240, hidden=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
		output_1 [label="Layer 1 Output\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, hidden=1024]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
	}
	subgraph cluster_stage_1 {
		fillcolor=lightgray label="Pipeline Stage 1 (Layers 2-3)" style="rounded,filled"
		mha_2 [label="MHA L2\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_2 [label="Gate L2\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_2_0 [label="Route to Expert 0\nGPU: 64,65\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_0_0 [label="Expert 0 TP-0\nGPU: 64\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_0_1 [label="Expert 0 TP-1\nGPU: 65\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_0 [label="TP All-Reduce\nGPU: 64↔65\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_1 [label="Route to Expert 1\nGPU: 66,67\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_1_0 [label="Expert 1 TP-0\nGPU: 66\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_1_1 [label="Expert 1 TP-1\nGPU: 67\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_1 [label="TP All-Reduce\nGPU: 66↔67\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_2 [label="Route to Expert 2\nGPU: 68,69\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_2_0 [label="Expert 2 TP-0\nGPU: 68\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_2_1 [label="Expert 2 TP-1\nGPU: 69\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_2 [label="TP All-Reduce\nGPU: 68↔69\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_3 [label="Route to Expert 3\nGPU: 70,71\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_3_0 [label="Expert 3 TP-0\nGPU: 70\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_3_1 [label="Expert 3 TP-1\nGPU: 71\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_3 [label="TP All-Reduce\nGPU: 70↔71\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_4 [label="Route to Expert 4\nGPU: 72,73\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_4_0 [label="Expert 4 TP-0\nGPU: 72\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_4_1 [label="Expert 4 TP-1\nGPU: 73\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_4 [label="TP All-Reduce\nGPU: 72↔73\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_5 [label="Route to Expert 5\nGPU: 74,75\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_5_0 [label="Expert 5 TP-0\nGPU: 74\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_5_1 [label="Expert 5 TP-1\nGPU: 75\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_5 [label="TP All-Reduce\nGPU: 74↔75\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_6 [label="Route to Expert 6\nGPU: 76,77\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_6_0 [label="Expert 6 TP-0\nGPU: 76\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_6_1 [label="Expert 6 TP-1\nGPU: 77\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_6 [label="TP All-Reduce\nGPU: 76↔77\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_7 [label="Route to Expert 7\nGPU: 78,79\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_7_0 [label="Expert 7 TP-0\nGPU: 78\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_7_1 [label="Expert 7 TP-1\nGPU: 79\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_7 [label="TP All-Reduce\nGPU: 78↔79\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_8 [label="Route to Expert 8\nGPU: 80,81\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_8_0 [label="Expert 8 TP-0\nGPU: 80\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_8_1 [label="Expert 8 TP-1\nGPU: 81\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_8 [label="TP All-Reduce\nGPU: 80↔81\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_9 [label="Route to Expert 9\nGPU: 82,83\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_9_0 [label="Expert 9 TP-0\nGPU: 82\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_9_1 [label="Expert 9 TP-1\nGPU: 83\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_9 [label="TP All-Reduce\nGPU: 82↔83\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_10 [label="Route to Expert 10\nGPU: 84,85\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_10_0 [label="Expert 10 TP-0\nGPU: 84\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_10_1 [label="Expert 10 TP-1\nGPU: 85\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_10 [label="TP All-Reduce\nGPU: 84↔85\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_11 [label="Route to Expert 11\nGPU: 86,87\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_11_0 [label="Expert 11 TP-0\nGPU: 86\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_11_1 [label="Expert 11 TP-1\nGPU: 87\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_11 [label="TP All-Reduce\nGPU: 86↔87\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_12 [label="Route to Expert 12\nGPU: 88,89\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_12_0 [label="Expert 12 TP-0\nGPU: 88\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_12_1 [label="Expert 12 TP-1\nGPU: 89\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_12 [label="TP All-Reduce\nGPU: 88↔89\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_13 [label="Route to Expert 13\nGPU: 90,91\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_13_0 [label="Expert 13 TP-0\nGPU: 90\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_13_1 [label="Expert 13 TP-1\nGPU: 91\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_13 [label="TP All-Reduce\nGPU: 90↔91\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_14 [label="Route to Expert 14\nGPU: 92,93\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_14_0 [label="Expert 14 TP-0\nGPU: 92\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_14_1 [label="Expert 14 TP-1\nGPU: 93\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_14 [label="TP All-Reduce\nGPU: 92↔93\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_2_15 [label="Route to Expert 15\nGPU: 94,95\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_2_15_0 [label="Expert 15 TP-0\nGPU: 94\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_2_15_1 [label="Expert 15 TP-1\nGPU: 95\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_2_15 [label="TP All-Reduce\nGPU: 94↔95\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		agg_2 [label="Aggregate Experts L2\nGPU: 0-511\nInput: 16 expert outputs\nOutput: [batch_size=128, seq_len=10240, hidden=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
		output_2 [label="Layer 2 Output\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, hidden=1024]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		mha_3 [label="MHA L3\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_3 [label="Gate L3\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_3_0 [label="Route to Expert 0\nGPU: 96,97\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_0_0 [label="Expert 0 TP-0\nGPU: 96\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_0_1 [label="Expert 0 TP-1\nGPU: 97\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_0 [label="TP All-Reduce\nGPU: 96↔97\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_1 [label="Route to Expert 1\nGPU: 98,99\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_1_0 [label="Expert 1 TP-0\nGPU: 98\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_1_1 [label="Expert 1 TP-1\nGPU: 99\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_1 [label="TP All-Reduce\nGPU: 98↔99\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_2 [label="Route to Expert 2\nGPU: 100,101\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_2_0 [label="Expert 2 TP-0\nGPU: 100\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_2_1 [label="Expert 2 TP-1\nGPU: 101\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_2 [label="TP All-Reduce\nGPU: 100↔101\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_3 [label="Route to Expert 3\nGPU: 102,103\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_3_0 [label="Expert 3 TP-0\nGPU: 102\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_3_1 [label="Expert 3 TP-1\nGPU: 103\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_3 [label="TP All-Reduce\nGPU: 102↔103\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_4 [label="Route to Expert 4\nGPU: 104,105\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_4_0 [label="Expert 4 TP-0\nGPU: 104\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_4_1 [label="Expert 4 TP-1\nGPU: 105\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_4 [label="TP All-Reduce\nGPU: 104↔105\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_5 [label="Route to Expert 5\nGPU: 106,107\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_5_0 [label="Expert 5 TP-0\nGPU: 106\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_5_1 [label="Expert 5 TP-1\nGPU: 107\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_5 [label="TP All-Reduce\nGPU: 106↔107\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_6 [label="Route to Expert 6\nGPU: 108,109\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_6_0 [label="Expert 6 TP-0\nGPU: 108\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_6_1 [label="Expert 6 TP-1\nGPU: 109\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_6 [label="TP All-Reduce\nGPU: 108↔109\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_7 [label="Route to Expert 7\nGPU: 110,111\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_7_0 [label="Expert 7 TP-0\nGPU: 110\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_7_1 [label="Expert 7 TP-1\nGPU: 111\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_7 [label="TP All-Reduce\nGPU: 110↔111\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_8 [label="Route to Expert 8\nGPU: 112,113\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_8_0 [label="Expert 8 TP-0\nGPU: 112\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_8_1 [label="Expert 8 TP-1\nGPU: 113\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_8 [label="TP All-Reduce\nGPU: 112↔113\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_9 [label="Route to Expert 9\nGPU: 114,115\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_9_0 [label="Expert 9 TP-0\nGPU: 114\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_9_1 [label="Expert 9 TP-1\nGPU: 115\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_9 [label="TP All-Reduce\nGPU: 114↔115\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_10 [label="Route to Expert 10\nGPU: 116,117\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_10_0 [label="Expert 10 TP-0\nGPU: 116\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_10_1 [label="Expert 10 TP-1\nGPU: 117\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_10 [label="TP All-Reduce\nGPU: 116↔117\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_11 [label="Route to Expert 11\nGPU: 118,119\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_11_0 [label="Expert 11 TP-0\nGPU: 118\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_11_1 [label="Expert 11 TP-1\nGPU: 119\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_11 [label="TP All-Reduce\nGPU: 118↔119\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_12 [label="Route to Expert 12\nGPU: 120,121\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_12_0 [label="Expert 12 TP-0\nGPU: 120\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_12_1 [label="Expert 12 TP-1\nGPU: 121\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_12 [label="TP All-Reduce\nGPU: 120↔121\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_13 [label="Route to Expert 13\nGPU: 122,123\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_13_0 [label="Expert 13 TP-0\nGPU: 122\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_13_1 [label="Expert 13 TP-1\nGPU: 123\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_13 [label="TP All-Reduce\nGPU: 122↔123\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_14 [label="Route to Expert 14\nGPU: 124,125\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_14_0 [label="Expert 14 TP-0\nGPU: 124\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_14_1 [label="Expert 14 TP-1\nGPU: 125\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_14 [label="TP All-Reduce\nGPU: 124↔125\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_3_15 [label="Route to Expert 15\nGPU: 126,127\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_3_15_0 [label="Expert 15 TP-0\nGPU: 126\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_3_15_1 [label="Expert 15 TP-1\nGPU: 127\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_3_15 [label="TP All-Reduce\nGPU: 126↔127\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		agg_3 [label="Aggregate Experts L3\nGPU: 0-511\nInput: 16 expert outputs\nOutput: [batch_size=128, seq_len=10240, hidden=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
		output_3 [label="Layer 3 Output\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, hidden=1024]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
	}
	subgraph cluster_stage_2 {
		fillcolor=lightgray label="Pipeline Stage 2 (Layers 4-5)" style="rounded,filled"
		mha_4 [label="MHA L4\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_4 [label="Gate L4\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_4_0 [label="Route to Expert 0\nGPU: 128,129\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_0_0 [label="Expert 0 TP-0\nGPU: 128\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_0_1 [label="Expert 0 TP-1\nGPU: 129\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_0 [label="TP All-Reduce\nGPU: 128↔129\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_1 [label="Route to Expert 1\nGPU: 130,131\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_1_0 [label="Expert 1 TP-0\nGPU: 130\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_1_1 [label="Expert 1 TP-1\nGPU: 131\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_1 [label="TP All-Reduce\nGPU: 130↔131\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_2 [label="Route to Expert 2\nGPU: 132,133\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_2_0 [label="Expert 2 TP-0\nGPU: 132\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_2_1 [label="Expert 2 TP-1\nGPU: 133\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_2 [label="TP All-Reduce\nGPU: 132↔133\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_3 [label="Route to Expert 3\nGPU: 134,135\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_3_0 [label="Expert 3 TP-0\nGPU: 134\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_3_1 [label="Expert 3 TP-1\nGPU: 135\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_3 [label="TP All-Reduce\nGPU: 134↔135\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_4 [label="Route to Expert 4\nGPU: 136,137\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_4_0 [label="Expert 4 TP-0\nGPU: 136\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_4_1 [label="Expert 4 TP-1\nGPU: 137\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_4 [label="TP All-Reduce\nGPU: 136↔137\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_5 [label="Route to Expert 5\nGPU: 138,139\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_5_0 [label="Expert 5 TP-0\nGPU: 138\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_5_1 [label="Expert 5 TP-1\nGPU: 139\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_5 [label="TP All-Reduce\nGPU: 138↔139\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_6 [label="Route to Expert 6\nGPU: 140,141\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_6_0 [label="Expert 6 TP-0\nGPU: 140\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_6_1 [label="Expert 6 TP-1\nGPU: 141\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_6 [label="TP All-Reduce\nGPU: 140↔141\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_7 [label="Route to Expert 7\nGPU: 142,143\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_7_0 [label="Expert 7 TP-0\nGPU: 142\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_7_1 [label="Expert 7 TP-1\nGPU: 143\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_7 [label="TP All-Reduce\nGPU: 142↔143\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_8 [label="Route to Expert 8\nGPU: 144,145\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_8_0 [label="Expert 8 TP-0\nGPU: 144\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_8_1 [label="Expert 8 TP-1\nGPU: 145\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_8 [label="TP All-Reduce\nGPU: 144↔145\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_9 [label="Route to Expert 9\nGPU: 146,147\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_9_0 [label="Expert 9 TP-0\nGPU: 146\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_9_1 [label="Expert 9 TP-1\nGPU: 147\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_9 [label="TP All-Reduce\nGPU: 146↔147\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_10 [label="Route to Expert 10\nGPU: 148,149\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_10_0 [label="Expert 10 TP-0\nGPU: 148\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_10_1 [label="Expert 10 TP-1\nGPU: 149\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_10 [label="TP All-Reduce\nGPU: 148↔149\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_11 [label="Route to Expert 11\nGPU: 150,151\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_11_0 [label="Expert 11 TP-0\nGPU: 150\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_11_1 [label="Expert 11 TP-1\nGPU: 151\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_11 [label="TP All-Reduce\nGPU: 150↔151\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_12 [label="Route to Expert 12\nGPU: 152,153\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_12_0 [label="Expert 12 TP-0\nGPU: 152\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_12_1 [label="Expert 12 TP-1\nGPU: 153\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_12 [label="TP All-Reduce\nGPU: 152↔153\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_13 [label="Route to Expert 13\nGPU: 154,155\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_13_0 [label="Expert 13 TP-0\nGPU: 154\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_13_1 [label="Expert 13 TP-1\nGPU: 155\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_13 [label="TP All-Reduce\nGPU: 154↔155\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_14 [label="Route to Expert 14\nGPU: 156,157\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_14_0 [label="Expert 14 TP-0\nGPU: 156\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_14_1 [label="Expert 14 TP-1\nGPU: 157\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_14 [label="TP All-Reduce\nGPU: 156↔157\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_4_15 [label="Route to Expert 15\nGPU: 158,159\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_4_15_0 [label="Expert 15 TP-0\nGPU: 158\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_4_15_1 [label="Expert 15 TP-1\nGPU: 159\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_4_15 [label="TP All-Reduce\nGPU: 158↔159\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		agg_4 [label="Aggregate Experts L4\nGPU: 0-511\nInput: 16 expert outputs\nOutput: [batch_size=128, seq_len=10240, hidden=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
		output_4 [label="Layer 4 Output\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, hidden=1024]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		mha_5 [label="MHA L5\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_5 [label="Gate L5\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_5_0 [label="Route to Expert 0\nGPU: 160,161\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_0_0 [label="Expert 0 TP-0\nGPU: 160\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_0_1 [label="Expert 0 TP-1\nGPU: 161\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_0 [label="TP All-Reduce\nGPU: 160↔161\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_1 [label="Route to Expert 1\nGPU: 162,163\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_1_0 [label="Expert 1 TP-0\nGPU: 162\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_1_1 [label="Expert 1 TP-1\nGPU: 163\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_1 [label="TP All-Reduce\nGPU: 162↔163\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_2 [label="Route to Expert 2\nGPU: 164,165\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_2_0 [label="Expert 2 TP-0\nGPU: 164\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_2_1 [label="Expert 2 TP-1\nGPU: 165\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_2 [label="TP All-Reduce\nGPU: 164↔165\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_3 [label="Route to Expert 3\nGPU: 166,167\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_3_0 [label="Expert 3 TP-0\nGPU: 166\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_3_1 [label="Expert 3 TP-1\nGPU: 167\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_3 [label="TP All-Reduce\nGPU: 166↔167\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_4 [label="Route to Expert 4\nGPU: 168,169\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_4_0 [label="Expert 4 TP-0\nGPU: 168\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_4_1 [label="Expert 4 TP-1\nGPU: 169\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_4 [label="TP All-Reduce\nGPU: 168↔169\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_5 [label="Route to Expert 5\nGPU: 170,171\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_5_0 [label="Expert 5 TP-0\nGPU: 170\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_5_1 [label="Expert 5 TP-1\nGPU: 171\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_5 [label="TP All-Reduce\nGPU: 170↔171\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_6 [label="Route to Expert 6\nGPU: 172,173\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_6_0 [label="Expert 6 TP-0\nGPU: 172\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_6_1 [label="Expert 6 TP-1\nGPU: 173\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_6 [label="TP All-Reduce\nGPU: 172↔173\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_7 [label="Route to Expert 7\nGPU: 174,175\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_7_0 [label="Expert 7 TP-0\nGPU: 174\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_7_1 [label="Expert 7 TP-1\nGPU: 175\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_7 [label="TP All-Reduce\nGPU: 174↔175\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_8 [label="Route to Expert 8\nGPU: 176,177\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_8_0 [label="Expert 8 TP-0\nGPU: 176\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_8_1 [label="Expert 8 TP-1\nGPU: 177\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_8 [label="TP All-Reduce\nGPU: 176↔177\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_9 [label="Route to Expert 9\nGPU: 178,179\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_9_0 [label="Expert 9 TP-0\nGPU: 178\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_9_1 [label="Expert 9 TP-1\nGPU: 179\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_9 [label="TP All-Reduce\nGPU: 178↔179\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_10 [label="Route to Expert 10\nGPU: 180,181\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_10_0 [label="Expert 10 TP-0\nGPU: 180\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_10_1 [label="Expert 10 TP-1\nGPU: 181\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_10 [label="TP All-Reduce\nGPU: 180↔181\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_11 [label="Route to Expert 11\nGPU: 182,183\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_11_0 [label="Expert 11 TP-0\nGPU: 182\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_11_1 [label="Expert 11 TP-1\nGPU: 183\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_11 [label="TP All-Reduce\nGPU: 182↔183\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_12 [label="Route to Expert 12\nGPU: 184,185\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_12_0 [label="Expert 12 TP-0\nGPU: 184\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_12_1 [label="Expert 12 TP-1\nGPU: 185\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_12 [label="TP All-Reduce\nGPU: 184↔185\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_13 [label="Route to Expert 13\nGPU: 186,187\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_13_0 [label="Expert 13 TP-0\nGPU: 186\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_13_1 [label="Expert 13 TP-1\nGPU: 187\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_13 [label="TP All-Reduce\nGPU: 186↔187\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_14 [label="Route to Expert 14\nGPU: 188,189\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_14_0 [label="Expert 14 TP-0\nGPU: 188\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_14_1 [label="Expert 14 TP-1\nGPU: 189\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_14 [label="TP All-Reduce\nGPU: 188↔189\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_5_15 [label="Route to Expert 15\nGPU: 190,191\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_5_15_0 [label="Expert 15 TP-0\nGPU: 190\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_5_15_1 [label="Expert 15 TP-1\nGPU: 191\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_5_15 [label="TP All-Reduce\nGPU: 190↔191\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		agg_5 [label="Aggregate Experts L5\nGPU: 0-511\nInput: 16 expert outputs\nOutput: [batch_size=128, seq_len=10240, hidden=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
		output_5 [label="Layer 5 Output\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, hidden=1024]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
	}
	subgraph cluster_stage_3 {
		fillcolor=lightgray label="Pipeline Stage 3 (Layers 6-7)" style="rounded,filled"
		mha_6 [label="MHA L6\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_6 [label="Gate L6\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_6_0 [label="Route to Expert 0\nGPU: 192,193\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_0_0 [label="Expert 0 TP-0\nGPU: 192\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_0_1 [label="Expert 0 TP-1\nGPU: 193\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_0 [label="TP All-Reduce\nGPU: 192↔193\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_1 [label="Route to Expert 1\nGPU: 194,195\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_1_0 [label="Expert 1 TP-0\nGPU: 194\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_1_1 [label="Expert 1 TP-1\nGPU: 195\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_1 [label="TP All-Reduce\nGPU: 194↔195\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_2 [label="Route to Expert 2\nGPU: 196,197\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_2_0 [label="Expert 2 TP-0\nGPU: 196\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_2_1 [label="Expert 2 TP-1\nGPU: 197\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_2 [label="TP All-Reduce\nGPU: 196↔197\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_3 [label="Route to Expert 3\nGPU: 198,199\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_3_0 [label="Expert 3 TP-0\nGPU: 198\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_3_1 [label="Expert 3 TP-1\nGPU: 199\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_3 [label="TP All-Reduce\nGPU: 198↔199\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_4 [label="Route to Expert 4\nGPU: 200,201\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_4_0 [label="Expert 4 TP-0\nGPU: 200\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_4_1 [label="Expert 4 TP-1\nGPU: 201\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_4 [label="TP All-Reduce\nGPU: 200↔201\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_5 [label="Route to Expert 5\nGPU: 202,203\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_5_0 [label="Expert 5 TP-0\nGPU: 202\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_5_1 [label="Expert 5 TP-1\nGPU: 203\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_5 [label="TP All-Reduce\nGPU: 202↔203\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_6 [label="Route to Expert 6\nGPU: 204,205\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_6_0 [label="Expert 6 TP-0\nGPU: 204\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_6_1 [label="Expert 6 TP-1\nGPU: 205\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_6 [label="TP All-Reduce\nGPU: 204↔205\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_7 [label="Route to Expert 7\nGPU: 206,207\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_7_0 [label="Expert 7 TP-0\nGPU: 206\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_7_1 [label="Expert 7 TP-1\nGPU: 207\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_7 [label="TP All-Reduce\nGPU: 206↔207\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_8 [label="Route to Expert 8\nGPU: 208,209\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_8_0 [label="Expert 8 TP-0\nGPU: 208\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_8_1 [label="Expert 8 TP-1\nGPU: 209\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_8 [label="TP All-Reduce\nGPU: 208↔209\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_9 [label="Route to Expert 9\nGPU: 210,211\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_9_0 [label="Expert 9 TP-0\nGPU: 210\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_9_1 [label="Expert 9 TP-1\nGPU: 211\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_9 [label="TP All-Reduce\nGPU: 210↔211\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_10 [label="Route to Expert 10\nGPU: 212,213\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_10_0 [label="Expert 10 TP-0\nGPU: 212\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_10_1 [label="Expert 10 TP-1\nGPU: 213\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_10 [label="TP All-Reduce\nGPU: 212↔213\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_11 [label="Route to Expert 11\nGPU: 214,215\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_11_0 [label="Expert 11 TP-0\nGPU: 214\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_11_1 [label="Expert 11 TP-1\nGPU: 215\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_11 [label="TP All-Reduce\nGPU: 214↔215\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_12 [label="Route to Expert 12\nGPU: 216,217\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_12_0 [label="Expert 12 TP-0\nGPU: 216\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_12_1 [label="Expert 12 TP-1\nGPU: 217\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_12 [label="TP All-Reduce\nGPU: 216↔217\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_13 [label="Route to Expert 13\nGPU: 218,219\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_13_0 [label="Expert 13 TP-0\nGPU: 218\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_13_1 [label="Expert 13 TP-1\nGPU: 219\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_13 [label="TP All-Reduce\nGPU: 218↔219\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_14 [label="Route to Expert 14\nGPU: 220,221\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_14_0 [label="Expert 14 TP-0\nGPU: 220\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_14_1 [label="Expert 14 TP-1\nGPU: 221\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_14 [label="TP All-Reduce\nGPU: 220↔221\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_6_15 [label="Route to Expert 15\nGPU: 222,223\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_6_15_0 [label="Expert 15 TP-0\nGPU: 222\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_6_15_1 [label="Expert 15 TP-1\nGPU: 223\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_6_15 [label="TP All-Reduce\nGPU: 222↔223\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		agg_6 [label="Aggregate Experts L6\nGPU: 0-511\nInput: 16 expert outputs\nOutput: [batch_size=128, seq_len=10240, hidden=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
		output_6 [label="Layer 6 Output\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, hidden=1024]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		mha_7 [label="MHA L7\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_7 [label="Gate L7\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_7_0 [label="Route to Expert 0\nGPU: 224,225\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_0_0 [label="Expert 0 TP-0\nGPU: 224\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_0_1 [label="Expert 0 TP-1\nGPU: 225\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_0 [label="TP All-Reduce\nGPU: 224↔225\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_1 [label="Route to Expert 1\nGPU: 226,227\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_1_0 [label="Expert 1 TP-0\nGPU: 226\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_1_1 [label="Expert 1 TP-1\nGPU: 227\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_1 [label="TP All-Reduce\nGPU: 226↔227\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_2 [label="Route to Expert 2\nGPU: 228,229\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_2_0 [label="Expert 2 TP-0\nGPU: 228\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_2_1 [label="Expert 2 TP-1\nGPU: 229\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_2 [label="TP All-Reduce\nGPU: 228↔229\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_3 [label="Route to Expert 3\nGPU: 230,231\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_3_0 [label="Expert 3 TP-0\nGPU: 230\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_3_1 [label="Expert 3 TP-1\nGPU: 231\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_3 [label="TP All-Reduce\nGPU: 230↔231\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_4 [label="Route to Expert 4\nGPU: 232,233\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_4_0 [label="Expert 4 TP-0\nGPU: 232\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_4_1 [label="Expert 4 TP-1\nGPU: 233\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_4 [label="TP All-Reduce\nGPU: 232↔233\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_5 [label="Route to Expert 5\nGPU: 234,235\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_5_0 [label="Expert 5 TP-0\nGPU: 234\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_5_1 [label="Expert 5 TP-1\nGPU: 235\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_5 [label="TP All-Reduce\nGPU: 234↔235\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_6 [label="Route to Expert 6\nGPU: 236,237\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_6_0 [label="Expert 6 TP-0\nGPU: 236\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_6_1 [label="Expert 6 TP-1\nGPU: 237\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_6 [label="TP All-Reduce\nGPU: 236↔237\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_7 [label="Route to Expert 7\nGPU: 238,239\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_7_0 [label="Expert 7 TP-0\nGPU: 238\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_7_1 [label="Expert 7 TP-1\nGPU: 239\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_7 [label="TP All-Reduce\nGPU: 238↔239\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_8 [label="Route to Expert 8\nGPU: 240,241\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_8_0 [label="Expert 8 TP-0\nGPU: 240\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_8_1 [label="Expert 8 TP-1\nGPU: 241\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_8 [label="TP All-Reduce\nGPU: 240↔241\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_9 [label="Route to Expert 9\nGPU: 242,243\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_9_0 [label="Expert 9 TP-0\nGPU: 242\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_9_1 [label="Expert 9 TP-1\nGPU: 243\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_9 [label="TP All-Reduce\nGPU: 242↔243\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_10 [label="Route to Expert 10\nGPU: 244,245\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_10_0 [label="Expert 10 TP-0\nGPU: 244\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_10_1 [label="Expert 10 TP-1\nGPU: 245\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_10 [label="TP All-Reduce\nGPU: 244↔245\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_11 [label="Route to Expert 11\nGPU: 246,247\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_11_0 [label="Expert 11 TP-0\nGPU: 246\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_11_1 [label="Expert 11 TP-1\nGPU: 247\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_11 [label="TP All-Reduce\nGPU: 246↔247\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_12 [label="Route to Expert 12\nGPU: 248,249\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_12_0 [label="Expert 12 TP-0\nGPU: 248\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_12_1 [label="Expert 12 TP-1\nGPU: 249\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_12 [label="TP All-Reduce\nGPU: 248↔249\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_13 [label="Route to Expert 13\nGPU: 250,251\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_13_0 [label="Expert 13 TP-0\nGPU: 250\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_13_1 [label="Expert 13 TP-1\nGPU: 251\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_13 [label="TP All-Reduce\nGPU: 250↔251\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_14 [label="Route to Expert 14\nGPU: 252,253\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_14_0 [label="Expert 14 TP-0\nGPU: 252\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_14_1 [label="Expert 14 TP-1\nGPU: 253\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_14 [label="TP All-Reduce\nGPU: 252↔253\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_7_15 [label="Route to Expert 15\nGPU: 254,255\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_7_15_0 [label="Expert 15 TP-0\nGPU: 254\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_7_15_1 [label="Expert 15 TP-1\nGPU: 255\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_7_15 [label="TP All-Reduce\nGPU: 254↔255\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		agg_7 [label="Aggregate Experts L7\nGPU: 0-511\nInput: 16 expert outputs\nOutput: [batch_size=128, seq_len=10240, hidden=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
		output_7 [label="Layer 7 Output\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, hidden=1024]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
	}
	subgraph cluster_stage_4 {
		fillcolor=lightgray label="Pipeline Stage 4 (Layers 8-9)" style="rounded,filled"
		mha_8 [label="MHA L8\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_8 [label="Gate L8\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_8_0 [label="Route to Expert 0\nGPU: 256,257\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_0_0 [label="Expert 0 TP-0\nGPU: 256\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_0_1 [label="Expert 0 TP-1\nGPU: 257\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_0 [label="TP All-Reduce\nGPU: 256↔257\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_1 [label="Route to Expert 1\nGPU: 258,259\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_1_0 [label="Expert 1 TP-0\nGPU: 258\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_1_1 [label="Expert 1 TP-1\nGPU: 259\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_1 [label="TP All-Reduce\nGPU: 258↔259\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_2 [label="Route to Expert 2\nGPU: 260,261\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_2_0 [label="Expert 2 TP-0\nGPU: 260\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_2_1 [label="Expert 2 TP-1\nGPU: 261\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_2 [label="TP All-Reduce\nGPU: 260↔261\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_3 [label="Route to Expert 3\nGPU: 262,263\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_3_0 [label="Expert 3 TP-0\nGPU: 262\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_3_1 [label="Expert 3 TP-1\nGPU: 263\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_3 [label="TP All-Reduce\nGPU: 262↔263\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_4 [label="Route to Expert 4\nGPU: 264,265\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_4_0 [label="Expert 4 TP-0\nGPU: 264\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_4_1 [label="Expert 4 TP-1\nGPU: 265\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_4 [label="TP All-Reduce\nGPU: 264↔265\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_5 [label="Route to Expert 5\nGPU: 266,267\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_5_0 [label="Expert 5 TP-0\nGPU: 266\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_5_1 [label="Expert 5 TP-1\nGPU: 267\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_5 [label="TP All-Reduce\nGPU: 266↔267\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_6 [label="Route to Expert 6\nGPU: 268,269\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_6_0 [label="Expert 6 TP-0\nGPU: 268\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_6_1 [label="Expert 6 TP-1\nGPU: 269\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_6 [label="TP All-Reduce\nGPU: 268↔269\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_7 [label="Route to Expert 7\nGPU: 270,271\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_7_0 [label="Expert 7 TP-0\nGPU: 270\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_7_1 [label="Expert 7 TP-1\nGPU: 271\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_7 [label="TP All-Reduce\nGPU: 270↔271\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_8 [label="Route to Expert 8\nGPU: 272,273\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_8_0 [label="Expert 8 TP-0\nGPU: 272\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_8_1 [label="Expert 8 TP-1\nGPU: 273\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_8 [label="TP All-Reduce\nGPU: 272↔273\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_9 [label="Route to Expert 9\nGPU: 274,275\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_9_0 [label="Expert 9 TP-0\nGPU: 274\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_9_1 [label="Expert 9 TP-1\nGPU: 275\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_9 [label="TP All-Reduce\nGPU: 274↔275\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_10 [label="Route to Expert 10\nGPU: 276,277\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_10_0 [label="Expert 10 TP-0\nGPU: 276\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_10_1 [label="Expert 10 TP-1\nGPU: 277\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_10 [label="TP All-Reduce\nGPU: 276↔277\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_11 [label="Route to Expert 11\nGPU: 278,279\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_11_0 [label="Expert 11 TP-0\nGPU: 278\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_11_1 [label="Expert 11 TP-1\nGPU: 279\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_11 [label="TP All-Reduce\nGPU: 278↔279\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_12 [label="Route to Expert 12\nGPU: 280,281\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_12_0 [label="Expert 12 TP-0\nGPU: 280\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_12_1 [label="Expert 12 TP-1\nGPU: 281\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_12 [label="TP All-Reduce\nGPU: 280↔281\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_13 [label="Route to Expert 13\nGPU: 282,283\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_13_0 [label="Expert 13 TP-0\nGPU: 282\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_13_1 [label="Expert 13 TP-1\nGPU: 283\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_13 [label="TP All-Reduce\nGPU: 282↔283\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_14 [label="Route to Expert 14\nGPU: 284,285\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_14_0 [label="Expert 14 TP-0\nGPU: 284\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_14_1 [label="Expert 14 TP-1\nGPU: 285\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_14 [label="TP All-Reduce\nGPU: 284↔285\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_8_15 [label="Route to Expert 15\nGPU: 286,287\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_8_15_0 [label="Expert 15 TP-0\nGPU: 286\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_8_15_1 [label="Expert 15 TP-1\nGPU: 287\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_8_15 [label="TP All-Reduce\nGPU: 286↔287\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		agg_8 [label="Aggregate Experts L8\nGPU: 0-511\nInput: 16 expert outputs\nOutput: [batch_size=128, seq_len=10240, hidden=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
		output_8 [label="Layer 8 Output\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, hidden=1024]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		mha_9 [label="MHA L9\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_9 [label="Gate L9\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_9_0 [label="Route to Expert 0\nGPU: 288,289\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_0_0 [label="Expert 0 TP-0\nGPU: 288\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_0_1 [label="Expert 0 TP-1\nGPU: 289\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_0 [label="TP All-Reduce\nGPU: 288↔289\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_1 [label="Route to Expert 1\nGPU: 290,291\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_1_0 [label="Expert 1 TP-0\nGPU: 290\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_1_1 [label="Expert 1 TP-1\nGPU: 291\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_1 [label="TP All-Reduce\nGPU: 290↔291\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_2 [label="Route to Expert 2\nGPU: 292,293\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_2_0 [label="Expert 2 TP-0\nGPU: 292\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_2_1 [label="Expert 2 TP-1\nGPU: 293\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_2 [label="TP All-Reduce\nGPU: 292↔293\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_3 [label="Route to Expert 3\nGPU: 294,295\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_3_0 [label="Expert 3 TP-0\nGPU: 294\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_3_1 [label="Expert 3 TP-1\nGPU: 295\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_3 [label="TP All-Reduce\nGPU: 294↔295\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_4 [label="Route to Expert 4\nGPU: 296,297\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_4_0 [label="Expert 4 TP-0\nGPU: 296\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_4_1 [label="Expert 4 TP-1\nGPU: 297\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_4 [label="TP All-Reduce\nGPU: 296↔297\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_5 [label="Route to Expert 5\nGPU: 298,299\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_5_0 [label="Expert 5 TP-0\nGPU: 298\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_5_1 [label="Expert 5 TP-1\nGPU: 299\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_5 [label="TP All-Reduce\nGPU: 298↔299\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_6 [label="Route to Expert 6\nGPU: 300,301\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_6_0 [label="Expert 6 TP-0\nGPU: 300\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_6_1 [label="Expert 6 TP-1\nGPU: 301\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_6 [label="TP All-Reduce\nGPU: 300↔301\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_7 [label="Route to Expert 7\nGPU: 302,303\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_7_0 [label="Expert 7 TP-0\nGPU: 302\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_7_1 [label="Expert 7 TP-1\nGPU: 303\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_7 [label="TP All-Reduce\nGPU: 302↔303\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_8 [label="Route to Expert 8\nGPU: 304,305\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_8_0 [label="Expert 8 TP-0\nGPU: 304\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_8_1 [label="Expert 8 TP-1\nGPU: 305\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_8 [label="TP All-Reduce\nGPU: 304↔305\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_9 [label="Route to Expert 9\nGPU: 306,307\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_9_0 [label="Expert 9 TP-0\nGPU: 306\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_9_1 [label="Expert 9 TP-1\nGPU: 307\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_9 [label="TP All-Reduce\nGPU: 306↔307\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_10 [label="Route to Expert 10\nGPU: 308,309\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_10_0 [label="Expert 10 TP-0\nGPU: 308\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_10_1 [label="Expert 10 TP-1\nGPU: 309\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_10 [label="TP All-Reduce\nGPU: 308↔309\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_11 [label="Route to Expert 11\nGPU: 310,311\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_11_0 [label="Expert 11 TP-0\nGPU: 310\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_11_1 [label="Expert 11 TP-1\nGPU: 311\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_11 [label="TP All-Reduce\nGPU: 310↔311\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_12 [label="Route to Expert 12\nGPU: 312,313\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_12_0 [label="Expert 12 TP-0\nGPU: 312\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_12_1 [label="Expert 12 TP-1\nGPU: 313\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_12 [label="TP All-Reduce\nGPU: 312↔313\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_13 [label="Route to Expert 13\nGPU: 314,315\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_13_0 [label="Expert 13 TP-0\nGPU: 314\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_13_1 [label="Expert 13 TP-1\nGPU: 315\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_13 [label="TP All-Reduce\nGPU: 314↔315\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_14 [label="Route to Expert 14\nGPU: 316,317\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_14_0 [label="Expert 14 TP-0\nGPU: 316\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_14_1 [label="Expert 14 TP-1\nGPU: 317\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_14 [label="TP All-Reduce\nGPU: 316↔317\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_9_15 [label="Route to Expert 15\nGPU: 318,319\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_9_15_0 [label="Expert 15 TP-0\nGPU: 318\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_9_15_1 [label="Expert 15 TP-1\nGPU: 319\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_9_15 [label="TP All-Reduce\nGPU: 318↔319\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		agg_9 [label="Aggregate Experts L9\nGPU: 0-511\nInput: 16 expert outputs\nOutput: [batch_size=128, seq_len=10240, hidden=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
		output_9 [label="Layer 9 Output\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, hidden=1024]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
	}
	subgraph cluster_stage_5 {
		fillcolor=lightgray label="Pipeline Stage 5 (Layers 10-11)" style="rounded,filled"
		mha_10 [label="MHA L10\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_10 [label="Gate L10\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_10_0 [label="Route to Expert 0\nGPU: 320,321\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_0_0 [label="Expert 0 TP-0\nGPU: 320\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_0_1 [label="Expert 0 TP-1\nGPU: 321\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_0 [label="TP All-Reduce\nGPU: 320↔321\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_1 [label="Route to Expert 1\nGPU: 322,323\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_1_0 [label="Expert 1 TP-0\nGPU: 322\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_1_1 [label="Expert 1 TP-1\nGPU: 323\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_1 [label="TP All-Reduce\nGPU: 322↔323\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_2 [label="Route to Expert 2\nGPU: 324,325\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_2_0 [label="Expert 2 TP-0\nGPU: 324\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_2_1 [label="Expert 2 TP-1\nGPU: 325\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_2 [label="TP All-Reduce\nGPU: 324↔325\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_3 [label="Route to Expert 3\nGPU: 326,327\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_3_0 [label="Expert 3 TP-0\nGPU: 326\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_3_1 [label="Expert 3 TP-1\nGPU: 327\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_3 [label="TP All-Reduce\nGPU: 326↔327\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_4 [label="Route to Expert 4\nGPU: 328,329\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_4_0 [label="Expert 4 TP-0\nGPU: 328\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_4_1 [label="Expert 4 TP-1\nGPU: 329\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_4 [label="TP All-Reduce\nGPU: 328↔329\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_5 [label="Route to Expert 5\nGPU: 330,331\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_5_0 [label="Expert 5 TP-0\nGPU: 330\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_5_1 [label="Expert 5 TP-1\nGPU: 331\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_5 [label="TP All-Reduce\nGPU: 330↔331\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_6 [label="Route to Expert 6\nGPU: 332,333\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_6_0 [label="Expert 6 TP-0\nGPU: 332\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_6_1 [label="Expert 6 TP-1\nGPU: 333\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_6 [label="TP All-Reduce\nGPU: 332↔333\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_7 [label="Route to Expert 7\nGPU: 334,335\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_7_0 [label="Expert 7 TP-0\nGPU: 334\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_7_1 [label="Expert 7 TP-1\nGPU: 335\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_7 [label="TP All-Reduce\nGPU: 334↔335\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_8 [label="Route to Expert 8\nGPU: 336,337\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_8_0 [label="Expert 8 TP-0\nGPU: 336\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_8_1 [label="Expert 8 TP-1\nGPU: 337\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_8 [label="TP All-Reduce\nGPU: 336↔337\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_9 [label="Route to Expert 9\nGPU: 338,339\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_9_0 [label="Expert 9 TP-0\nGPU: 338\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_9_1 [label="Expert 9 TP-1\nGPU: 339\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_9 [label="TP All-Reduce\nGPU: 338↔339\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_10 [label="Route to Expert 10\nGPU: 340,341\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_10_0 [label="Expert 10 TP-0\nGPU: 340\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_10_1 [label="Expert 10 TP-1\nGPU: 341\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_10 [label="TP All-Reduce\nGPU: 340↔341\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_11 [label="Route to Expert 11\nGPU: 342,343\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_11_0 [label="Expert 11 TP-0\nGPU: 342\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_11_1 [label="Expert 11 TP-1\nGPU: 343\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_11 [label="TP All-Reduce\nGPU: 342↔343\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_12 [label="Route to Expert 12\nGPU: 344,345\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_12_0 [label="Expert 12 TP-0\nGPU: 344\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_12_1 [label="Expert 12 TP-1\nGPU: 345\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_12 [label="TP All-Reduce\nGPU: 344↔345\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_13 [label="Route to Expert 13\nGPU: 346,347\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_13_0 [label="Expert 13 TP-0\nGPU: 346\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_13_1 [label="Expert 13 TP-1\nGPU: 347\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_13 [label="TP All-Reduce\nGPU: 346↔347\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_14 [label="Route to Expert 14\nGPU: 348,349\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_14_0 [label="Expert 14 TP-0\nGPU: 348\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_14_1 [label="Expert 14 TP-1\nGPU: 349\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_14 [label="TP All-Reduce\nGPU: 348↔349\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_10_15 [label="Route to Expert 15\nGPU: 350,351\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_10_15_0 [label="Expert 15 TP-0\nGPU: 350\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_10_15_1 [label="Expert 15 TP-1\nGPU: 351\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_10_15 [label="TP All-Reduce\nGPU: 350↔351\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		agg_10 [label="Aggregate Experts L10\nGPU: 0-511\nInput: 16 expert outputs\nOutput: [batch_size=128, seq_len=10240, hidden=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
		output_10 [label="Layer 10 Output\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, hidden=1024]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		mha_11 [label="MHA L11\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_11 [label="Gate L11\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_11_0 [label="Route to Expert 0\nGPU: 352,353\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_0_0 [label="Expert 0 TP-0\nGPU: 352\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_0_1 [label="Expert 0 TP-1\nGPU: 353\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_0 [label="TP All-Reduce\nGPU: 352↔353\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_1 [label="Route to Expert 1\nGPU: 354,355\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_1_0 [label="Expert 1 TP-0\nGPU: 354\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_1_1 [label="Expert 1 TP-1\nGPU: 355\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_1 [label="TP All-Reduce\nGPU: 354↔355\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_2 [label="Route to Expert 2\nGPU: 356,357\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_2_0 [label="Expert 2 TP-0\nGPU: 356\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_2_1 [label="Expert 2 TP-1\nGPU: 357\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_2 [label="TP All-Reduce\nGPU: 356↔357\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_3 [label="Route to Expert 3\nGPU: 358,359\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_3_0 [label="Expert 3 TP-0\nGPU: 358\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_3_1 [label="Expert 3 TP-1\nGPU: 359\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_3 [label="TP All-Reduce\nGPU: 358↔359\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_4 [label="Route to Expert 4\nGPU: 360,361\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_4_0 [label="Expert 4 TP-0\nGPU: 360\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_4_1 [label="Expert 4 TP-1\nGPU: 361\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_4 [label="TP All-Reduce\nGPU: 360↔361\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_5 [label="Route to Expert 5\nGPU: 362,363\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_5_0 [label="Expert 5 TP-0\nGPU: 362\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_5_1 [label="Expert 5 TP-1\nGPU: 363\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_5 [label="TP All-Reduce\nGPU: 362↔363\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_6 [label="Route to Expert 6\nGPU: 364,365\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_6_0 [label="Expert 6 TP-0\nGPU: 364\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_6_1 [label="Expert 6 TP-1\nGPU: 365\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_6 [label="TP All-Reduce\nGPU: 364↔365\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_7 [label="Route to Expert 7\nGPU: 366,367\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_7_0 [label="Expert 7 TP-0\nGPU: 366\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_7_1 [label="Expert 7 TP-1\nGPU: 367\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_7 [label="TP All-Reduce\nGPU: 366↔367\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_8 [label="Route to Expert 8\nGPU: 368,369\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_8_0 [label="Expert 8 TP-0\nGPU: 368\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_8_1 [label="Expert 8 TP-1\nGPU: 369\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_8 [label="TP All-Reduce\nGPU: 368↔369\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_9 [label="Route to Expert 9\nGPU: 370,371\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_9_0 [label="Expert 9 TP-0\nGPU: 370\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_9_1 [label="Expert 9 TP-1\nGPU: 371\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_9 [label="TP All-Reduce\nGPU: 370↔371\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_10 [label="Route to Expert 10\nGPU: 372,373\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_10_0 [label="Expert 10 TP-0\nGPU: 372\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_10_1 [label="Expert 10 TP-1\nGPU: 373\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_10 [label="TP All-Reduce\nGPU: 372↔373\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_11 [label="Route to Expert 11\nGPU: 374,375\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_11_0 [label="Expert 11 TP-0\nGPU: 374\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_11_1 [label="Expert 11 TP-1\nGPU: 375\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_11 [label="TP All-Reduce\nGPU: 374↔375\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_12 [label="Route to Expert 12\nGPU: 376,377\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_12_0 [label="Expert 12 TP-0\nGPU: 376\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_12_1 [label="Expert 12 TP-1\nGPU: 377\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_12 [label="TP All-Reduce\nGPU: 376↔377\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_13 [label="Route to Expert 13\nGPU: 378,379\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_13_0 [label="Expert 13 TP-0\nGPU: 378\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_13_1 [label="Expert 13 TP-1\nGPU: 379\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_13 [label="TP All-Reduce\nGPU: 378↔379\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_14 [label="Route to Expert 14\nGPU: 380,381\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_14_0 [label="Expert 14 TP-0\nGPU: 380\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_14_1 [label="Expert 14 TP-1\nGPU: 381\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_14 [label="TP All-Reduce\nGPU: 380↔381\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_11_15 [label="Route to Expert 15\nGPU: 382,383\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_11_15_0 [label="Expert 15 TP-0\nGPU: 382\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_11_15_1 [label="Expert 15 TP-1\nGPU: 383\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_11_15 [label="TP All-Reduce\nGPU: 382↔383\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		agg_11 [label="Aggregate Experts L11\nGPU: 0-511\nInput: 16 expert outputs\nOutput: [batch_size=128, seq_len=10240, hidden=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
		output_11 [label="Layer 11 Output\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, hidden=1024]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
	}
	subgraph cluster_stage_6 {
		fillcolor=lightgray label="Pipeline Stage 6 (Layers 12-13)" style="rounded,filled"
		mha_12 [label="MHA L12\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_12 [label="Gate L12\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_12_0 [label="Route to Expert 0\nGPU: 384,385\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_0_0 [label="Expert 0 TP-0\nGPU: 384\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_0_1 [label="Expert 0 TP-1\nGPU: 385\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_0 [label="TP All-Reduce\nGPU: 384↔385\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_1 [label="Route to Expert 1\nGPU: 386,387\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_1_0 [label="Expert 1 TP-0\nGPU: 386\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_1_1 [label="Expert 1 TP-1\nGPU: 387\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_1 [label="TP All-Reduce\nGPU: 386↔387\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_2 [label="Route to Expert 2\nGPU: 388,389\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_2_0 [label="Expert 2 TP-0\nGPU: 388\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_2_1 [label="Expert 2 TP-1\nGPU: 389\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_2 [label="TP All-Reduce\nGPU: 388↔389\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_3 [label="Route to Expert 3\nGPU: 390,391\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_3_0 [label="Expert 3 TP-0\nGPU: 390\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_3_1 [label="Expert 3 TP-1\nGPU: 391\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_3 [label="TP All-Reduce\nGPU: 390↔391\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_4 [label="Route to Expert 4\nGPU: 392,393\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_4_0 [label="Expert 4 TP-0\nGPU: 392\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_4_1 [label="Expert 4 TP-1\nGPU: 393\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_4 [label="TP All-Reduce\nGPU: 392↔393\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_5 [label="Route to Expert 5\nGPU: 394,395\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_5_0 [label="Expert 5 TP-0\nGPU: 394\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_5_1 [label="Expert 5 TP-1\nGPU: 395\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_5 [label="TP All-Reduce\nGPU: 394↔395\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_6 [label="Route to Expert 6\nGPU: 396,397\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_6_0 [label="Expert 6 TP-0\nGPU: 396\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_6_1 [label="Expert 6 TP-1\nGPU: 397\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_6 [label="TP All-Reduce\nGPU: 396↔397\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_7 [label="Route to Expert 7\nGPU: 398,399\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_7_0 [label="Expert 7 TP-0\nGPU: 398\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_7_1 [label="Expert 7 TP-1\nGPU: 399\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_7 [label="TP All-Reduce\nGPU: 398↔399\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_8 [label="Route to Expert 8\nGPU: 400,401\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_8_0 [label="Expert 8 TP-0\nGPU: 400\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_8_1 [label="Expert 8 TP-1\nGPU: 401\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_8 [label="TP All-Reduce\nGPU: 400↔401\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_9 [label="Route to Expert 9\nGPU: 402,403\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_9_0 [label="Expert 9 TP-0\nGPU: 402\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_9_1 [label="Expert 9 TP-1\nGPU: 403\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_9 [label="TP All-Reduce\nGPU: 402↔403\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_10 [label="Route to Expert 10\nGPU: 404,405\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_10_0 [label="Expert 10 TP-0\nGPU: 404\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_10_1 [label="Expert 10 TP-1\nGPU: 405\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_10 [label="TP All-Reduce\nGPU: 404↔405\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_11 [label="Route to Expert 11\nGPU: 406,407\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_11_0 [label="Expert 11 TP-0\nGPU: 406\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_11_1 [label="Expert 11 TP-1\nGPU: 407\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_11 [label="TP All-Reduce\nGPU: 406↔407\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_12 [label="Route to Expert 12\nGPU: 408,409\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_12_0 [label="Expert 12 TP-0\nGPU: 408\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_12_1 [label="Expert 12 TP-1\nGPU: 409\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_12 [label="TP All-Reduce\nGPU: 408↔409\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_13 [label="Route to Expert 13\nGPU: 410,411\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_13_0 [label="Expert 13 TP-0\nGPU: 410\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_13_1 [label="Expert 13 TP-1\nGPU: 411\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_13 [label="TP All-Reduce\nGPU: 410↔411\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_14 [label="Route to Expert 14\nGPU: 412,413\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_14_0 [label="Expert 14 TP-0\nGPU: 412\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_14_1 [label="Expert 14 TP-1\nGPU: 413\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_14 [label="TP All-Reduce\nGPU: 412↔413\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_12_15 [label="Route to Expert 15\nGPU: 414,415\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_12_15_0 [label="Expert 15 TP-0\nGPU: 414\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_12_15_1 [label="Expert 15 TP-1\nGPU: 415\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_12_15 [label="TP All-Reduce\nGPU: 414↔415\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		agg_12 [label="Aggregate Experts L12\nGPU: 0-511\nInput: 16 expert outputs\nOutput: [batch_size=128, seq_len=10240, hidden=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
		output_12 [label="Layer 12 Output\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, hidden=1024]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		mha_13 [label="MHA L13\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_13 [label="Gate L13\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_13_0 [label="Route to Expert 0\nGPU: 416,417\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_0_0 [label="Expert 0 TP-0\nGPU: 416\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_0_1 [label="Expert 0 TP-1\nGPU: 417\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_0 [label="TP All-Reduce\nGPU: 416↔417\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_1 [label="Route to Expert 1\nGPU: 418,419\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_1_0 [label="Expert 1 TP-0\nGPU: 418\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_1_1 [label="Expert 1 TP-1\nGPU: 419\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_1 [label="TP All-Reduce\nGPU: 418↔419\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_2 [label="Route to Expert 2\nGPU: 420,421\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_2_0 [label="Expert 2 TP-0\nGPU: 420\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_2_1 [label="Expert 2 TP-1\nGPU: 421\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_2 [label="TP All-Reduce\nGPU: 420↔421\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_3 [label="Route to Expert 3\nGPU: 422,423\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_3_0 [label="Expert 3 TP-0\nGPU: 422\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_3_1 [label="Expert 3 TP-1\nGPU: 423\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_3 [label="TP All-Reduce\nGPU: 422↔423\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_4 [label="Route to Expert 4\nGPU: 424,425\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_4_0 [label="Expert 4 TP-0\nGPU: 424\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_4_1 [label="Expert 4 TP-1\nGPU: 425\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_4 [label="TP All-Reduce\nGPU: 424↔425\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_5 [label="Route to Expert 5\nGPU: 426,427\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_5_0 [label="Expert 5 TP-0\nGPU: 426\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_5_1 [label="Expert 5 TP-1\nGPU: 427\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_5 [label="TP All-Reduce\nGPU: 426↔427\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_6 [label="Route to Expert 6\nGPU: 428,429\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_6_0 [label="Expert 6 TP-0\nGPU: 428\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_6_1 [label="Expert 6 TP-1\nGPU: 429\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_6 [label="TP All-Reduce\nGPU: 428↔429\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_7 [label="Route to Expert 7\nGPU: 430,431\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_7_0 [label="Expert 7 TP-0\nGPU: 430\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_7_1 [label="Expert 7 TP-1\nGPU: 431\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_7 [label="TP All-Reduce\nGPU: 430↔431\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_8 [label="Route to Expert 8\nGPU: 432,433\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_8_0 [label="Expert 8 TP-0\nGPU: 432\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_8_1 [label="Expert 8 TP-1\nGPU: 433\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_8 [label="TP All-Reduce\nGPU: 432↔433\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_9 [label="Route to Expert 9\nGPU: 434,435\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_9_0 [label="Expert 9 TP-0\nGPU: 434\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_9_1 [label="Expert 9 TP-1\nGPU: 435\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_9 [label="TP All-Reduce\nGPU: 434↔435\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_10 [label="Route to Expert 10\nGPU: 436,437\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_10_0 [label="Expert 10 TP-0\nGPU: 436\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_10_1 [label="Expert 10 TP-1\nGPU: 437\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_10 [label="TP All-Reduce\nGPU: 436↔437\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_11 [label="Route to Expert 11\nGPU: 438,439\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_11_0 [label="Expert 11 TP-0\nGPU: 438\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_11_1 [label="Expert 11 TP-1\nGPU: 439\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_11 [label="TP All-Reduce\nGPU: 438↔439\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_12 [label="Route to Expert 12\nGPU: 440,441\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_12_0 [label="Expert 12 TP-0\nGPU: 440\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_12_1 [label="Expert 12 TP-1\nGPU: 441\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_12 [label="TP All-Reduce\nGPU: 440↔441\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_13 [label="Route to Expert 13\nGPU: 442,443\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_13_0 [label="Expert 13 TP-0\nGPU: 442\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_13_1 [label="Expert 13 TP-1\nGPU: 443\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_13 [label="TP All-Reduce\nGPU: 442↔443\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_14 [label="Route to Expert 14\nGPU: 444,445\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_14_0 [label="Expert 14 TP-0\nGPU: 444\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_14_1 [label="Expert 14 TP-1\nGPU: 445\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_14 [label="TP All-Reduce\nGPU: 444↔445\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_13_15 [label="Route to Expert 15\nGPU: 446,447\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_13_15_0 [label="Expert 15 TP-0\nGPU: 446\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_13_15_1 [label="Expert 15 TP-1\nGPU: 447\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_13_15 [label="TP All-Reduce\nGPU: 446↔447\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		agg_13 [label="Aggregate Experts L13\nGPU: 0-511\nInput: 16 expert outputs\nOutput: [batch_size=128, seq_len=10240, hidden=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
		output_13 [label="Layer 13 Output\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, hidden=1024]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
	}
	subgraph cluster_stage_7 {
		fillcolor=lightgray label="Pipeline Stage 7 (Layers 14-15)" style="rounded,filled"
		mha_14 [label="MHA L14\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_14 [label="Gate L14\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_14_0 [label="Route to Expert 0\nGPU: 448,449\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_0_0 [label="Expert 0 TP-0\nGPU: 448\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_0_1 [label="Expert 0 TP-1\nGPU: 449\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_0 [label="TP All-Reduce\nGPU: 448↔449\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_1 [label="Route to Expert 1\nGPU: 450,451\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_1_0 [label="Expert 1 TP-0\nGPU: 450\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_1_1 [label="Expert 1 TP-1\nGPU: 451\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_1 [label="TP All-Reduce\nGPU: 450↔451\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_2 [label="Route to Expert 2\nGPU: 452,453\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_2_0 [label="Expert 2 TP-0\nGPU: 452\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_2_1 [label="Expert 2 TP-1\nGPU: 453\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_2 [label="TP All-Reduce\nGPU: 452↔453\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_3 [label="Route to Expert 3\nGPU: 454,455\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_3_0 [label="Expert 3 TP-0\nGPU: 454\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_3_1 [label="Expert 3 TP-1\nGPU: 455\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_3 [label="TP All-Reduce\nGPU: 454↔455\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_4 [label="Route to Expert 4\nGPU: 456,457\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_4_0 [label="Expert 4 TP-0\nGPU: 456\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_4_1 [label="Expert 4 TP-1\nGPU: 457\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_4 [label="TP All-Reduce\nGPU: 456↔457\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_5 [label="Route to Expert 5\nGPU: 458,459\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_5_0 [label="Expert 5 TP-0\nGPU: 458\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_5_1 [label="Expert 5 TP-1\nGPU: 459\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_5 [label="TP All-Reduce\nGPU: 458↔459\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_6 [label="Route to Expert 6\nGPU: 460,461\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_6_0 [label="Expert 6 TP-0\nGPU: 460\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_6_1 [label="Expert 6 TP-1\nGPU: 461\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_6 [label="TP All-Reduce\nGPU: 460↔461\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_7 [label="Route to Expert 7\nGPU: 462,463\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_7_0 [label="Expert 7 TP-0\nGPU: 462\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_7_1 [label="Expert 7 TP-1\nGPU: 463\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_7 [label="TP All-Reduce\nGPU: 462↔463\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_8 [label="Route to Expert 8\nGPU: 464,465\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_8_0 [label="Expert 8 TP-0\nGPU: 464\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_8_1 [label="Expert 8 TP-1\nGPU: 465\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_8 [label="TP All-Reduce\nGPU: 464↔465\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_9 [label="Route to Expert 9\nGPU: 466,467\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_9_0 [label="Expert 9 TP-0\nGPU: 466\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_9_1 [label="Expert 9 TP-1\nGPU: 467\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_9 [label="TP All-Reduce\nGPU: 466↔467\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_10 [label="Route to Expert 10\nGPU: 468,469\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_10_0 [label="Expert 10 TP-0\nGPU: 468\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_10_1 [label="Expert 10 TP-1\nGPU: 469\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_10 [label="TP All-Reduce\nGPU: 468↔469\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_11 [label="Route to Expert 11\nGPU: 470,471\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_11_0 [label="Expert 11 TP-0\nGPU: 470\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_11_1 [label="Expert 11 TP-1\nGPU: 471\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_11 [label="TP All-Reduce\nGPU: 470↔471\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_12 [label="Route to Expert 12\nGPU: 472,473\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_12_0 [label="Expert 12 TP-0\nGPU: 472\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_12_1 [label="Expert 12 TP-1\nGPU: 473\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_12 [label="TP All-Reduce\nGPU: 472↔473\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_13 [label="Route to Expert 13\nGPU: 474,475\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_13_0 [label="Expert 13 TP-0\nGPU: 474\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_13_1 [label="Expert 13 TP-1\nGPU: 475\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_13 [label="TP All-Reduce\nGPU: 474↔475\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_14 [label="Route to Expert 14\nGPU: 476,477\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_14_0 [label="Expert 14 TP-0\nGPU: 476\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_14_1 [label="Expert 14 TP-1\nGPU: 477\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_14 [label="TP All-Reduce\nGPU: 476↔477\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_14_15 [label="Route to Expert 15\nGPU: 478,479\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_14_15_0 [label="Expert 15 TP-0\nGPU: 478\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_14_15_1 [label="Expert 15 TP-1\nGPU: 479\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_14_15 [label="TP All-Reduce\nGPU: 478↔479\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		agg_14 [label="Aggregate Experts L14\nGPU: 0-511\nInput: 16 expert outputs\nOutput: [batch_size=128, seq_len=10240, hidden=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
		output_14 [label="Layer 14 Output\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, hidden=1024]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		mha_15 [label="MHA L15\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
		gate_15 [label="Gate L15\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: routing_decisions" fillcolor=lightyellow shape=parallelogram style=filled]
		route_15_0 [label="Route to Expert 0\nGPU: 480,481\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_0_0 [label="Expert 0 TP-0\nGPU: 480\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_0_1 [label="Expert 0 TP-1\nGPU: 481\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_0 [label="TP All-Reduce\nGPU: 480↔481\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_1 [label="Route to Expert 1\nGPU: 482,483\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_1_0 [label="Expert 1 TP-0\nGPU: 482\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_1_1 [label="Expert 1 TP-1\nGPU: 483\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_1 [label="TP All-Reduce\nGPU: 482↔483\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_2 [label="Route to Expert 2\nGPU: 484,485\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_2_0 [label="Expert 2 TP-0\nGPU: 484\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_2_1 [label="Expert 2 TP-1\nGPU: 485\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_2 [label="TP All-Reduce\nGPU: 484↔485\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_3 [label="Route to Expert 3\nGPU: 486,487\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_3_0 [label="Expert 3 TP-0\nGPU: 486\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_3_1 [label="Expert 3 TP-1\nGPU: 487\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_3 [label="TP All-Reduce\nGPU: 486↔487\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_4 [label="Route to Expert 4\nGPU: 488,489\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_4_0 [label="Expert 4 TP-0\nGPU: 488\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_4_1 [label="Expert 4 TP-1\nGPU: 489\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_4 [label="TP All-Reduce\nGPU: 488↔489\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_5 [label="Route to Expert 5\nGPU: 490,491\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_5_0 [label="Expert 5 TP-0\nGPU: 490\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_5_1 [label="Expert 5 TP-1\nGPU: 491\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_5 [label="TP All-Reduce\nGPU: 490↔491\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_6 [label="Route to Expert 6\nGPU: 492,493\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_6_0 [label="Expert 6 TP-0\nGPU: 492\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_6_1 [label="Expert 6 TP-1\nGPU: 493\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_6 [label="TP All-Reduce\nGPU: 492↔493\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_7 [label="Route to Expert 7\nGPU: 494,495\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_7_0 [label="Expert 7 TP-0\nGPU: 494\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_7_1 [label="Expert 7 TP-1\nGPU: 495\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_7 [label="TP All-Reduce\nGPU: 494↔495\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_8 [label="Route to Expert 8\nGPU: 496,497\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_8_0 [label="Expert 8 TP-0\nGPU: 496\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_8_1 [label="Expert 8 TP-1\nGPU: 497\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_8 [label="TP All-Reduce\nGPU: 496↔497\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_9 [label="Route to Expert 9\nGPU: 498,499\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_9_0 [label="Expert 9 TP-0\nGPU: 498\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_9_1 [label="Expert 9 TP-1\nGPU: 499\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_9 [label="TP All-Reduce\nGPU: 498↔499\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_10 [label="Route to Expert 10\nGPU: 500,501\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_10_0 [label="Expert 10 TP-0\nGPU: 500\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_10_1 [label="Expert 10 TP-1\nGPU: 501\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_10 [label="TP All-Reduce\nGPU: 500↔501\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_11 [label="Route to Expert 11\nGPU: 502,503\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_11_0 [label="Expert 11 TP-0\nGPU: 502\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_11_1 [label="Expert 11 TP-1\nGPU: 503\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_11 [label="TP All-Reduce\nGPU: 502↔503\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_12 [label="Route to Expert 12\nGPU: 504,505\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_12_0 [label="Expert 12 TP-0\nGPU: 504\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_12_1 [label="Expert 12 TP-1\nGPU: 505\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_12 [label="TP All-Reduce\nGPU: 504↔505\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_13 [label="Route to Expert 13\nGPU: 506,507\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_13_0 [label="Expert 13 TP-0\nGPU: 506\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_13_1 [label="Expert 13 TP-1\nGPU: 507\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_13 [label="TP All-Reduce\nGPU: 506↔507\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_14 [label="Route to Expert 14\nGPU: 508,509\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_14_0 [label="Expert 14 TP-0\nGPU: 508\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_14_1 [label="Expert 14 TP-1\nGPU: 509\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_14 [label="TP All-Reduce\nGPU: 508↔509\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		route_15_15 [label="Route to Expert 15\nGPU: 510,511\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=640, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style="dashed,filled"]
		expert_15_15_0 [label="Expert 15 TP-0\nGPU: 510\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		expert_15_15_1 [label="Expert 15 TP-1\nGPU: 511\nInput: [batch_size=128, seq_len=640, heads=16, d_k=32]\nOutput: expert_out[hidden=512]" fillcolor=lightgreen shape=rectangle style=filled]
		tp_15_15 [label="TP All-Reduce\nGPU: 510↔511\nInput: expert_out[hidden=512]\nOutput: expert_full[hidden=1024]" fillcolor=lightblue shape=ellipse style=filled]
		agg_15 [label="Aggregate Experts L15\nGPU: 0-511\nInput: 16 expert outputs\nOutput: [batch_size=128, seq_len=10240, hidden=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
		output_15 [label="Layer 15 Output\nGPU: 0-511\nInput: [batch_size=128, seq_len=10240, hidden=1024]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightgreen shape=rectangle style=filled]
	}
	input -> mha_0
	mha_0 -> gate_0
	gate_0 -> route_0_0 [style=dashed]
	route_0_0 -> expert_0_0_0
	route_0_0 -> expert_0_0_1
	expert_0_0_0 -> tp_0_0
	expert_0_0_1 -> tp_0_0
	tp_0_0 -> agg_0
	gate_0 -> route_0_1 [style=dashed]
	route_0_1 -> expert_0_1_0
	route_0_1 -> expert_0_1_1
	expert_0_1_0 -> tp_0_1
	expert_0_1_1 -> tp_0_1
	tp_0_1 -> agg_0
	gate_0 -> route_0_2 [style=dashed]
	route_0_2 -> expert_0_2_0
	route_0_2 -> expert_0_2_1
	expert_0_2_0 -> tp_0_2
	expert_0_2_1 -> tp_0_2
	tp_0_2 -> agg_0
	gate_0 -> route_0_3 [style=dashed]
	route_0_3 -> expert_0_3_0
	route_0_3 -> expert_0_3_1
	expert_0_3_0 -> tp_0_3
	expert_0_3_1 -> tp_0_3
	tp_0_3 -> agg_0
	gate_0 -> route_0_4 [style=dashed]
	route_0_4 -> expert_0_4_0
	route_0_4 -> expert_0_4_1
	expert_0_4_0 -> tp_0_4
	expert_0_4_1 -> tp_0_4
	tp_0_4 -> agg_0
	gate_0 -> route_0_5 [style=dashed]
	route_0_5 -> expert_0_5_0
	route_0_5 -> expert_0_5_1
	expert_0_5_0 -> tp_0_5
	expert_0_5_1 -> tp_0_5
	tp_0_5 -> agg_0
	gate_0 -> route_0_6 [style=dashed]
	route_0_6 -> expert_0_6_0
	route_0_6 -> expert_0_6_1
	expert_0_6_0 -> tp_0_6
	expert_0_6_1 -> tp_0_6
	tp_0_6 -> agg_0
	gate_0 -> route_0_7 [style=dashed]
	route_0_7 -> expert_0_7_0
	route_0_7 -> expert_0_7_1
	expert_0_7_0 -> tp_0_7
	expert_0_7_1 -> tp_0_7
	tp_0_7 -> agg_0
	gate_0 -> route_0_8 [style=dashed]
	route_0_8 -> expert_0_8_0
	route_0_8 -> expert_0_8_1
	expert_0_8_0 -> tp_0_8
	expert_0_8_1 -> tp_0_8
	tp_0_8 -> agg_0
	gate_0 -> route_0_9 [style=dashed]
	route_0_9 -> expert_0_9_0
	route_0_9 -> expert_0_9_1
	expert_0_9_0 -> tp_0_9
	expert_0_9_1 -> tp_0_9
	tp_0_9 -> agg_0
	gate_0 -> route_0_10 [style=dashed]
	route_0_10 -> expert_0_10_0
	route_0_10 -> expert_0_10_1
	expert_0_10_0 -> tp_0_10
	expert_0_10_1 -> tp_0_10
	tp_0_10 -> agg_0
	gate_0 -> route_0_11 [style=dashed]
	route_0_11 -> expert_0_11_0
	route_0_11 -> expert_0_11_1
	expert_0_11_0 -> tp_0_11
	expert_0_11_1 -> tp_0_11
	tp_0_11 -> agg_0
	gate_0 -> route_0_12 [style=dashed]
	route_0_12 -> expert_0_12_0
	route_0_12 -> expert_0_12_1
	expert_0_12_0 -> tp_0_12
	expert_0_12_1 -> tp_0_12
	tp_0_12 -> agg_0
	gate_0 -> route_0_13 [style=dashed]
	route_0_13 -> expert_0_13_0
	route_0_13 -> expert_0_13_1
	expert_0_13_0 -> tp_0_13
	expert_0_13_1 -> tp_0_13
	tp_0_13 -> agg_0
	gate_0 -> route_0_14 [style=dashed]
	route_0_14 -> expert_0_14_0
	route_0_14 -> expert_0_14_1
	expert_0_14_0 -> tp_0_14
	expert_0_14_1 -> tp_0_14
	tp_0_14 -> agg_0
	gate_0 -> route_0_15 [style=dashed]
	route_0_15 -> expert_0_15_0
	route_0_15 -> expert_0_15_1
	expert_0_15_0 -> tp_0_15
	expert_0_15_1 -> tp_0_15
	tp_0_15 -> agg_0
	agg_0 -> output_0
	output_0 -> mha_1
	mha_1 -> gate_1
	gate_1 -> route_1_0 [style=dashed]
	route_1_0 -> expert_1_0_0
	route_1_0 -> expert_1_0_1
	expert_1_0_0 -> tp_1_0
	expert_1_0_1 -> tp_1_0
	tp_1_0 -> agg_1
	gate_1 -> route_1_1 [style=dashed]
	route_1_1 -> expert_1_1_0
	route_1_1 -> expert_1_1_1
	expert_1_1_0 -> tp_1_1
	expert_1_1_1 -> tp_1_1
	tp_1_1 -> agg_1
	gate_1 -> route_1_2 [style=dashed]
	route_1_2 -> expert_1_2_0
	route_1_2 -> expert_1_2_1
	expert_1_2_0 -> tp_1_2
	expert_1_2_1 -> tp_1_2
	tp_1_2 -> agg_1
	gate_1 -> route_1_3 [style=dashed]
	route_1_3 -> expert_1_3_0
	route_1_3 -> expert_1_3_1
	expert_1_3_0 -> tp_1_3
	expert_1_3_1 -> tp_1_3
	tp_1_3 -> agg_1
	gate_1 -> route_1_4 [style=dashed]
	route_1_4 -> expert_1_4_0
	route_1_4 -> expert_1_4_1
	expert_1_4_0 -> tp_1_4
	expert_1_4_1 -> tp_1_4
	tp_1_4 -> agg_1
	gate_1 -> route_1_5 [style=dashed]
	route_1_5 -> expert_1_5_0
	route_1_5 -> expert_1_5_1
	expert_1_5_0 -> tp_1_5
	expert_1_5_1 -> tp_1_5
	tp_1_5 -> agg_1
	gate_1 -> route_1_6 [style=dashed]
	route_1_6 -> expert_1_6_0
	route_1_6 -> expert_1_6_1
	expert_1_6_0 -> tp_1_6
	expert_1_6_1 -> tp_1_6
	tp_1_6 -> agg_1
	gate_1 -> route_1_7 [style=dashed]
	route_1_7 -> expert_1_7_0
	route_1_7 -> expert_1_7_1
	expert_1_7_0 -> tp_1_7
	expert_1_7_1 -> tp_1_7
	tp_1_7 -> agg_1
	gate_1 -> route_1_8 [style=dashed]
	route_1_8 -> expert_1_8_0
	route_1_8 -> expert_1_8_1
	expert_1_8_0 -> tp_1_8
	expert_1_8_1 -> tp_1_8
	tp_1_8 -> agg_1
	gate_1 -> route_1_9 [style=dashed]
	route_1_9 -> expert_1_9_0
	route_1_9 -> expert_1_9_1
	expert_1_9_0 -> tp_1_9
	expert_1_9_1 -> tp_1_9
	tp_1_9 -> agg_1
	gate_1 -> route_1_10 [style=dashed]
	route_1_10 -> expert_1_10_0
	route_1_10 -> expert_1_10_1
	expert_1_10_0 -> tp_1_10
	expert_1_10_1 -> tp_1_10
	tp_1_10 -> agg_1
	gate_1 -> route_1_11 [style=dashed]
	route_1_11 -> expert_1_11_0
	route_1_11 -> expert_1_11_1
	expert_1_11_0 -> tp_1_11
	expert_1_11_1 -> tp_1_11
	tp_1_11 -> agg_1
	gate_1 -> route_1_12 [style=dashed]
	route_1_12 -> expert_1_12_0
	route_1_12 -> expert_1_12_1
	expert_1_12_0 -> tp_1_12
	expert_1_12_1 -> tp_1_12
	tp_1_12 -> agg_1
	gate_1 -> route_1_13 [style=dashed]
	route_1_13 -> expert_1_13_0
	route_1_13 -> expert_1_13_1
	expert_1_13_0 -> tp_1_13
	expert_1_13_1 -> tp_1_13
	tp_1_13 -> agg_1
	gate_1 -> route_1_14 [style=dashed]
	route_1_14 -> expert_1_14_0
	route_1_14 -> expert_1_14_1
	expert_1_14_0 -> tp_1_14
	expert_1_14_1 -> tp_1_14
	tp_1_14 -> agg_1
	gate_1 -> route_1_15 [style=dashed]
	route_1_15 -> expert_1_15_0
	route_1_15 -> expert_1_15_1
	expert_1_15_0 -> tp_1_15
	expert_1_15_1 -> tp_1_15
	tp_1_15 -> agg_1
	agg_1 -> output_1
	output_1 -> mha_2
	mha_2 -> gate_2
	gate_2 -> route_2_0 [style=dashed]
	route_2_0 -> expert_2_0_0
	route_2_0 -> expert_2_0_1
	expert_2_0_0 -> tp_2_0
	expert_2_0_1 -> tp_2_0
	tp_2_0 -> agg_2
	gate_2 -> route_2_1 [style=dashed]
	route_2_1 -> expert_2_1_0
	route_2_1 -> expert_2_1_1
	expert_2_1_0 -> tp_2_1
	expert_2_1_1 -> tp_2_1
	tp_2_1 -> agg_2
	gate_2 -> route_2_2 [style=dashed]
	route_2_2 -> expert_2_2_0
	route_2_2 -> expert_2_2_1
	expert_2_2_0 -> tp_2_2
	expert_2_2_1 -> tp_2_2
	tp_2_2 -> agg_2
	gate_2 -> route_2_3 [style=dashed]
	route_2_3 -> expert_2_3_0
	route_2_3 -> expert_2_3_1
	expert_2_3_0 -> tp_2_3
	expert_2_3_1 -> tp_2_3
	tp_2_3 -> agg_2
	gate_2 -> route_2_4 [style=dashed]
	route_2_4 -> expert_2_4_0
	route_2_4 -> expert_2_4_1
	expert_2_4_0 -> tp_2_4
	expert_2_4_1 -> tp_2_4
	tp_2_4 -> agg_2
	gate_2 -> route_2_5 [style=dashed]
	route_2_5 -> expert_2_5_0
	route_2_5 -> expert_2_5_1
	expert_2_5_0 -> tp_2_5
	expert_2_5_1 -> tp_2_5
	tp_2_5 -> agg_2
	gate_2 -> route_2_6 [style=dashed]
	route_2_6 -> expert_2_6_0
	route_2_6 -> expert_2_6_1
	expert_2_6_0 -> tp_2_6
	expert_2_6_1 -> tp_2_6
	tp_2_6 -> agg_2
	gate_2 -> route_2_7 [style=dashed]
	route_2_7 -> expert_2_7_0
	route_2_7 -> expert_2_7_1
	expert_2_7_0 -> tp_2_7
	expert_2_7_1 -> tp_2_7
	tp_2_7 -> agg_2
	gate_2 -> route_2_8 [style=dashed]
	route_2_8 -> expert_2_8_0
	route_2_8 -> expert_2_8_1
	expert_2_8_0 -> tp_2_8
	expert_2_8_1 -> tp_2_8
	tp_2_8 -> agg_2
	gate_2 -> route_2_9 [style=dashed]
	route_2_9 -> expert_2_9_0
	route_2_9 -> expert_2_9_1
	expert_2_9_0 -> tp_2_9
	expert_2_9_1 -> tp_2_9
	tp_2_9 -> agg_2
	gate_2 -> route_2_10 [style=dashed]
	route_2_10 -> expert_2_10_0
	route_2_10 -> expert_2_10_1
	expert_2_10_0 -> tp_2_10
	expert_2_10_1 -> tp_2_10
	tp_2_10 -> agg_2
	gate_2 -> route_2_11 [style=dashed]
	route_2_11 -> expert_2_11_0
	route_2_11 -> expert_2_11_1
	expert_2_11_0 -> tp_2_11
	expert_2_11_1 -> tp_2_11
	tp_2_11 -> agg_2
	gate_2 -> route_2_12 [style=dashed]
	route_2_12 -> expert_2_12_0
	route_2_12 -> expert_2_12_1
	expert_2_12_0 -> tp_2_12
	expert_2_12_1 -> tp_2_12
	tp_2_12 -> agg_2
	gate_2 -> route_2_13 [style=dashed]
	route_2_13 -> expert_2_13_0
	route_2_13 -> expert_2_13_1
	expert_2_13_0 -> tp_2_13
	expert_2_13_1 -> tp_2_13
	tp_2_13 -> agg_2
	gate_2 -> route_2_14 [style=dashed]
	route_2_14 -> expert_2_14_0
	route_2_14 -> expert_2_14_1
	expert_2_14_0 -> tp_2_14
	expert_2_14_1 -> tp_2_14
	tp_2_14 -> agg_2
	gate_2 -> route_2_15 [style=dashed]
	route_2_15 -> expert_2_15_0
	route_2_15 -> expert_2_15_1
	expert_2_15_0 -> tp_2_15
	expert_2_15_1 -> tp_2_15
	tp_2_15 -> agg_2
	agg_2 -> output_2
	output_2 -> mha_3
	mha_3 -> gate_3
	gate_3 -> route_3_0 [style=dashed]
	route_3_0 -> expert_3_0_0
	route_3_0 -> expert_3_0_1
	expert_3_0_0 -> tp_3_0
	expert_3_0_1 -> tp_3_0
	tp_3_0 -> agg_3
	gate_3 -> route_3_1 [style=dashed]
	route_3_1 -> expert_3_1_0
	route_3_1 -> expert_3_1_1
	expert_3_1_0 -> tp_3_1
	expert_3_1_1 -> tp_3_1
	tp_3_1 -> agg_3
	gate_3 -> route_3_2 [style=dashed]
	route_3_2 -> expert_3_2_0
	route_3_2 -> expert_3_2_1
	expert_3_2_0 -> tp_3_2
	expert_3_2_1 -> tp_3_2
	tp_3_2 -> agg_3
	gate_3 -> route_3_3 [style=dashed]
	route_3_3 -> expert_3_3_0
	route_3_3 -> expert_3_3_1
	expert_3_3_0 -> tp_3_3
	expert_3_3_1 -> tp_3_3
	tp_3_3 -> agg_3
	gate_3 -> route_3_4 [style=dashed]
	route_3_4 -> expert_3_4_0
	route_3_4 -> expert_3_4_1
	expert_3_4_0 -> tp_3_4
	expert_3_4_1 -> tp_3_4
	tp_3_4 -> agg_3
	gate_3 -> route_3_5 [style=dashed]
	route_3_5 -> expert_3_5_0
	route_3_5 -> expert_3_5_1
	expert_3_5_0 -> tp_3_5
	expert_3_5_1 -> tp_3_5
	tp_3_5 -> agg_3
	gate_3 -> route_3_6 [style=dashed]
	route_3_6 -> expert_3_6_0
	route_3_6 -> expert_3_6_1
	expert_3_6_0 -> tp_3_6
	expert_3_6_1 -> tp_3_6
	tp_3_6 -> agg_3
	gate_3 -> route_3_7 [style=dashed]
	route_3_7 -> expert_3_7_0
	route_3_7 -> expert_3_7_1
	expert_3_7_0 -> tp_3_7
	expert_3_7_1 -> tp_3_7
	tp_3_7 -> agg_3
	gate_3 -> route_3_8 [style=dashed]
	route_3_8 -> expert_3_8_0
	route_3_8 -> expert_3_8_1
	expert_3_8_0 -> tp_3_8
	expert_3_8_1 -> tp_3_8
	tp_3_8 -> agg_3
	gate_3 -> route_3_9 [style=dashed]
	route_3_9 -> expert_3_9_0
	route_3_9 -> expert_3_9_1
	expert_3_9_0 -> tp_3_9
	expert_3_9_1 -> tp_3_9
	tp_3_9 -> agg_3
	gate_3 -> route_3_10 [style=dashed]
	route_3_10 -> expert_3_10_0
	route_3_10 -> expert_3_10_1
	expert_3_10_0 -> tp_3_10
	expert_3_10_1 -> tp_3_10
	tp_3_10 -> agg_3
	gate_3 -> route_3_11 [style=dashed]
	route_3_11 -> expert_3_11_0
	route_3_11 -> expert_3_11_1
	expert_3_11_0 -> tp_3_11
	expert_3_11_1 -> tp_3_11
	tp_3_11 -> agg_3
	gate_3 -> route_3_12 [style=dashed]
	route_3_12 -> expert_3_12_0
	route_3_12 -> expert_3_12_1
	expert_3_12_0 -> tp_3_12
	expert_3_12_1 -> tp_3_12
	tp_3_12 -> agg_3
	gate_3 -> route_3_13 [style=dashed]
	route_3_13 -> expert_3_13_0
	route_3_13 -> expert_3_13_1
	expert_3_13_0 -> tp_3_13
	expert_3_13_1 -> tp_3_13
	tp_3_13 -> agg_3
	gate_3 -> route_3_14 [style=dashed]
	route_3_14 -> expert_3_14_0
	route_3_14 -> expert_3_14_1
	expert_3_14_0 -> tp_3_14
	expert_3_14_1 -> tp_3_14
	tp_3_14 -> agg_3
	gate_3 -> route_3_15 [style=dashed]
	route_3_15 -> expert_3_15_0
	route_3_15 -> expert_3_15_1
	expert_3_15_0 -> tp_3_15
	expert_3_15_1 -> tp_3_15
	tp_3_15 -> agg_3
	agg_3 -> output_3
	output_3 -> mha_4
	mha_4 -> gate_4
	gate_4 -> route_4_0 [style=dashed]
	route_4_0 -> expert_4_0_0
	route_4_0 -> expert_4_0_1
	expert_4_0_0 -> tp_4_0
	expert_4_0_1 -> tp_4_0
	tp_4_0 -> agg_4
	gate_4 -> route_4_1 [style=dashed]
	route_4_1 -> expert_4_1_0
	route_4_1 -> expert_4_1_1
	expert_4_1_0 -> tp_4_1
	expert_4_1_1 -> tp_4_1
	tp_4_1 -> agg_4
	gate_4 -> route_4_2 [style=dashed]
	route_4_2 -> expert_4_2_0
	route_4_2 -> expert_4_2_1
	expert_4_2_0 -> tp_4_2
	expert_4_2_1 -> tp_4_2
	tp_4_2 -> agg_4
	gate_4 -> route_4_3 [style=dashed]
	route_4_3 -> expert_4_3_0
	route_4_3 -> expert_4_3_1
	expert_4_3_0 -> tp_4_3
	expert_4_3_1 -> tp_4_3
	tp_4_3 -> agg_4
	gate_4 -> route_4_4 [style=dashed]
	route_4_4 -> expert_4_4_0
	route_4_4 -> expert_4_4_1
	expert_4_4_0 -> tp_4_4
	expert_4_4_1 -> tp_4_4
	tp_4_4 -> agg_4
	gate_4 -> route_4_5 [style=dashed]
	route_4_5 -> expert_4_5_0
	route_4_5 -> expert_4_5_1
	expert_4_5_0 -> tp_4_5
	expert_4_5_1 -> tp_4_5
	tp_4_5 -> agg_4
	gate_4 -> route_4_6 [style=dashed]
	route_4_6 -> expert_4_6_0
	route_4_6 -> expert_4_6_1
	expert_4_6_0 -> tp_4_6
	expert_4_6_1 -> tp_4_6
	tp_4_6 -> agg_4
	gate_4 -> route_4_7 [style=dashed]
	route_4_7 -> expert_4_7_0
	route_4_7 -> expert_4_7_1
	expert_4_7_0 -> tp_4_7
	expert_4_7_1 -> tp_4_7
	tp_4_7 -> agg_4
	gate_4 -> route_4_8 [style=dashed]
	route_4_8 -> expert_4_8_0
	route_4_8 -> expert_4_8_1
	expert_4_8_0 -> tp_4_8
	expert_4_8_1 -> tp_4_8
	tp_4_8 -> agg_4
	gate_4 -> route_4_9 [style=dashed]
	route_4_9 -> expert_4_9_0
	route_4_9 -> expert_4_9_1
	expert_4_9_0 -> tp_4_9
	expert_4_9_1 -> tp_4_9
	tp_4_9 -> agg_4
	gate_4 -> route_4_10 [style=dashed]
	route_4_10 -> expert_4_10_0
	route_4_10 -> expert_4_10_1
	expert_4_10_0 -> tp_4_10
	expert_4_10_1 -> tp_4_10
	tp_4_10 -> agg_4
	gate_4 -> route_4_11 [style=dashed]
	route_4_11 -> expert_4_11_0
	route_4_11 -> expert_4_11_1
	expert_4_11_0 -> tp_4_11
	expert_4_11_1 -> tp_4_11
	tp_4_11 -> agg_4
	gate_4 -> route_4_12 [style=dashed]
	route_4_12 -> expert_4_12_0
	route_4_12 -> expert_4_12_1
	expert_4_12_0 -> tp_4_12
	expert_4_12_1 -> tp_4_12
	tp_4_12 -> agg_4
	gate_4 -> route_4_13 [style=dashed]
	route_4_13 -> expert_4_13_0
	route_4_13 -> expert_4_13_1
	expert_4_13_0 -> tp_4_13
	expert_4_13_1 -> tp_4_13
	tp_4_13 -> agg_4
	gate_4 -> route_4_14 [style=dashed]
	route_4_14 -> expert_4_14_0
	route_4_14 -> expert_4_14_1
	expert_4_14_0 -> tp_4_14
	expert_4_14_1 -> tp_4_14
	tp_4_14 -> agg_4
	gate_4 -> route_4_15 [style=dashed]
	route_4_15 -> expert_4_15_0
	route_4_15 -> expert_4_15_1
	expert_4_15_0 -> tp_4_15
	expert_4_15_1 -> tp_4_15
	tp_4_15 -> agg_4
	agg_4 -> output_4
	output_4 -> mha_5
	mha_5 -> gate_5
	gate_5 -> route_5_0 [style=dashed]
	route_5_0 -> expert_5_0_0
	route_5_0 -> expert_5_0_1
	expert_5_0_0 -> tp_5_0
	expert_5_0_1 -> tp_5_0
	tp_5_0 -> agg_5
	gate_5 -> route_5_1 [style=dashed]
	route_5_1 -> expert_5_1_0
	route_5_1 -> expert_5_1_1
	expert_5_1_0 -> tp_5_1
	expert_5_1_1 -> tp_5_1
	tp_5_1 -> agg_5
	gate_5 -> route_5_2 [style=dashed]
	route_5_2 -> expert_5_2_0
	route_5_2 -> expert_5_2_1
	expert_5_2_0 -> tp_5_2
	expert_5_2_1 -> tp_5_2
	tp_5_2 -> agg_5
	gate_5 -> route_5_3 [style=dashed]
	route_5_3 -> expert_5_3_0
	route_5_3 -> expert_5_3_1
	expert_5_3_0 -> tp_5_3
	expert_5_3_1 -> tp_5_3
	tp_5_3 -> agg_5
	gate_5 -> route_5_4 [style=dashed]
	route_5_4 -> expert_5_4_0
	route_5_4 -> expert_5_4_1
	expert_5_4_0 -> tp_5_4
	expert_5_4_1 -> tp_5_4
	tp_5_4 -> agg_5
	gate_5 -> route_5_5 [style=dashed]
	route_5_5 -> expert_5_5_0
	route_5_5 -> expert_5_5_1
	expert_5_5_0 -> tp_5_5
	expert_5_5_1 -> tp_5_5
	tp_5_5 -> agg_5
	gate_5 -> route_5_6 [style=dashed]
	route_5_6 -> expert_5_6_0
	route_5_6 -> expert_5_6_1
	expert_5_6_0 -> tp_5_6
	expert_5_6_1 -> tp_5_6
	tp_5_6 -> agg_5
	gate_5 -> route_5_7 [style=dashed]
	route_5_7 -> expert_5_7_0
	route_5_7 -> expert_5_7_1
	expert_5_7_0 -> tp_5_7
	expert_5_7_1 -> tp_5_7
	tp_5_7 -> agg_5
	gate_5 -> route_5_8 [style=dashed]
	route_5_8 -> expert_5_8_0
	route_5_8 -> expert_5_8_1
	expert_5_8_0 -> tp_5_8
	expert_5_8_1 -> tp_5_8
	tp_5_8 -> agg_5
	gate_5 -> route_5_9 [style=dashed]
	route_5_9 -> expert_5_9_0
	route_5_9 -> expert_5_9_1
	expert_5_9_0 -> tp_5_9
	expert_5_9_1 -> tp_5_9
	tp_5_9 -> agg_5
	gate_5 -> route_5_10 [style=dashed]
	route_5_10 -> expert_5_10_0
	route_5_10 -> expert_5_10_1
	expert_5_10_0 -> tp_5_10
	expert_5_10_1 -> tp_5_10
	tp_5_10 -> agg_5
	gate_5 -> route_5_11 [style=dashed]
	route_5_11 -> expert_5_11_0
	route_5_11 -> expert_5_11_1
	expert_5_11_0 -> tp_5_11
	expert_5_11_1 -> tp_5_11
	tp_5_11 -> agg_5
	gate_5 -> route_5_12 [style=dashed]
	route_5_12 -> expert_5_12_0
	route_5_12 -> expert_5_12_1
	expert_5_12_0 -> tp_5_12
	expert_5_12_1 -> tp_5_12
	tp_5_12 -> agg_5
	gate_5 -> route_5_13 [style=dashed]
	route_5_13 -> expert_5_13_0
	route_5_13 -> expert_5_13_1
	expert_5_13_0 -> tp_5_13
	expert_5_13_1 -> tp_5_13
	tp_5_13 -> agg_5
	gate_5 -> route_5_14 [style=dashed]
	route_5_14 -> expert_5_14_0
	route_5_14 -> expert_5_14_1
	expert_5_14_0 -> tp_5_14
	expert_5_14_1 -> tp_5_14
	tp_5_14 -> agg_5
	gate_5 -> route_5_15 [style=dashed]
	route_5_15 -> expert_5_15_0
	route_5_15 -> expert_5_15_1
	expert_5_15_0 -> tp_5_15
	expert_5_15_1 -> tp_5_15
	tp_5_15 -> agg_5
	agg_5 -> output_5
	output_5 -> mha_6
	mha_6 -> gate_6
	gate_6 -> route_6_0 [style=dashed]
	route_6_0 -> expert_6_0_0
	route_6_0 -> expert_6_0_1
	expert_6_0_0 -> tp_6_0
	expert_6_0_1 -> tp_6_0
	tp_6_0 -> agg_6
	gate_6 -> route_6_1 [style=dashed]
	route_6_1 -> expert_6_1_0
	route_6_1 -> expert_6_1_1
	expert_6_1_0 -> tp_6_1
	expert_6_1_1 -> tp_6_1
	tp_6_1 -> agg_6
	gate_6 -> route_6_2 [style=dashed]
	route_6_2 -> expert_6_2_0
	route_6_2 -> expert_6_2_1
	expert_6_2_0 -> tp_6_2
	expert_6_2_1 -> tp_6_2
	tp_6_2 -> agg_6
	gate_6 -> route_6_3 [style=dashed]
	route_6_3 -> expert_6_3_0
	route_6_3 -> expert_6_3_1
	expert_6_3_0 -> tp_6_3
	expert_6_3_1 -> tp_6_3
	tp_6_3 -> agg_6
	gate_6 -> route_6_4 [style=dashed]
	route_6_4 -> expert_6_4_0
	route_6_4 -> expert_6_4_1
	expert_6_4_0 -> tp_6_4
	expert_6_4_1 -> tp_6_4
	tp_6_4 -> agg_6
	gate_6 -> route_6_5 [style=dashed]
	route_6_5 -> expert_6_5_0
	route_6_5 -> expert_6_5_1
	expert_6_5_0 -> tp_6_5
	expert_6_5_1 -> tp_6_5
	tp_6_5 -> agg_6
	gate_6 -> route_6_6 [style=dashed]
	route_6_6 -> expert_6_6_0
	route_6_6 -> expert_6_6_1
	expert_6_6_0 -> tp_6_6
	expert_6_6_1 -> tp_6_6
	tp_6_6 -> agg_6
	gate_6 -> route_6_7 [style=dashed]
	route_6_7 -> expert_6_7_0
	route_6_7 -> expert_6_7_1
	expert_6_7_0 -> tp_6_7
	expert_6_7_1 -> tp_6_7
	tp_6_7 -> agg_6
	gate_6 -> route_6_8 [style=dashed]
	route_6_8 -> expert_6_8_0
	route_6_8 -> expert_6_8_1
	expert_6_8_0 -> tp_6_8
	expert_6_8_1 -> tp_6_8
	tp_6_8 -> agg_6
	gate_6 -> route_6_9 [style=dashed]
	route_6_9 -> expert_6_9_0
	route_6_9 -> expert_6_9_1
	expert_6_9_0 -> tp_6_9
	expert_6_9_1 -> tp_6_9
	tp_6_9 -> agg_6
	gate_6 -> route_6_10 [style=dashed]
	route_6_10 -> expert_6_10_0
	route_6_10 -> expert_6_10_1
	expert_6_10_0 -> tp_6_10
	expert_6_10_1 -> tp_6_10
	tp_6_10 -> agg_6
	gate_6 -> route_6_11 [style=dashed]
	route_6_11 -> expert_6_11_0
	route_6_11 -> expert_6_11_1
	expert_6_11_0 -> tp_6_11
	expert_6_11_1 -> tp_6_11
	tp_6_11 -> agg_6
	gate_6 -> route_6_12 [style=dashed]
	route_6_12 -> expert_6_12_0
	route_6_12 -> expert_6_12_1
	expert_6_12_0 -> tp_6_12
	expert_6_12_1 -> tp_6_12
	tp_6_12 -> agg_6
	gate_6 -> route_6_13 [style=dashed]
	route_6_13 -> expert_6_13_0
	route_6_13 -> expert_6_13_1
	expert_6_13_0 -> tp_6_13
	expert_6_13_1 -> tp_6_13
	tp_6_13 -> agg_6
	gate_6 -> route_6_14 [style=dashed]
	route_6_14 -> expert_6_14_0
	route_6_14 -> expert_6_14_1
	expert_6_14_0 -> tp_6_14
	expert_6_14_1 -> tp_6_14
	tp_6_14 -> agg_6
	gate_6 -> route_6_15 [style=dashed]
	route_6_15 -> expert_6_15_0
	route_6_15 -> expert_6_15_1
	expert_6_15_0 -> tp_6_15
	expert_6_15_1 -> tp_6_15
	tp_6_15 -> agg_6
	agg_6 -> output_6
	output_6 -> mha_7
	mha_7 -> gate_7
	gate_7 -> route_7_0 [style=dashed]
	route_7_0 -> expert_7_0_0
	route_7_0 -> expert_7_0_1
	expert_7_0_0 -> tp_7_0
	expert_7_0_1 -> tp_7_0
	tp_7_0 -> agg_7
	gate_7 -> route_7_1 [style=dashed]
	route_7_1 -> expert_7_1_0
	route_7_1 -> expert_7_1_1
	expert_7_1_0 -> tp_7_1
	expert_7_1_1 -> tp_7_1
	tp_7_1 -> agg_7
	gate_7 -> route_7_2 [style=dashed]
	route_7_2 -> expert_7_2_0
	route_7_2 -> expert_7_2_1
	expert_7_2_0 -> tp_7_2
	expert_7_2_1 -> tp_7_2
	tp_7_2 -> agg_7
	gate_7 -> route_7_3 [style=dashed]
	route_7_3 -> expert_7_3_0
	route_7_3 -> expert_7_3_1
	expert_7_3_0 -> tp_7_3
	expert_7_3_1 -> tp_7_3
	tp_7_3 -> agg_7
	gate_7 -> route_7_4 [style=dashed]
	route_7_4 -> expert_7_4_0
	route_7_4 -> expert_7_4_1
	expert_7_4_0 -> tp_7_4
	expert_7_4_1 -> tp_7_4
	tp_7_4 -> agg_7
	gate_7 -> route_7_5 [style=dashed]
	route_7_5 -> expert_7_5_0
	route_7_5 -> expert_7_5_1
	expert_7_5_0 -> tp_7_5
	expert_7_5_1 -> tp_7_5
	tp_7_5 -> agg_7
	gate_7 -> route_7_6 [style=dashed]
	route_7_6 -> expert_7_6_0
	route_7_6 -> expert_7_6_1
	expert_7_6_0 -> tp_7_6
	expert_7_6_1 -> tp_7_6
	tp_7_6 -> agg_7
	gate_7 -> route_7_7 [style=dashed]
	route_7_7 -> expert_7_7_0
	route_7_7 -> expert_7_7_1
	expert_7_7_0 -> tp_7_7
	expert_7_7_1 -> tp_7_7
	tp_7_7 -> agg_7
	gate_7 -> route_7_8 [style=dashed]
	route_7_8 -> expert_7_8_0
	route_7_8 -> expert_7_8_1
	expert_7_8_0 -> tp_7_8
	expert_7_8_1 -> tp_7_8
	tp_7_8 -> agg_7
	gate_7 -> route_7_9 [style=dashed]
	route_7_9 -> expert_7_9_0
	route_7_9 -> expert_7_9_1
	expert_7_9_0 -> tp_7_9
	expert_7_9_1 -> tp_7_9
	tp_7_9 -> agg_7
	gate_7 -> route_7_10 [style=dashed]
	route_7_10 -> expert_7_10_0
	route_7_10 -> expert_7_10_1
	expert_7_10_0 -> tp_7_10
	expert_7_10_1 -> tp_7_10
	tp_7_10 -> agg_7
	gate_7 -> route_7_11 [style=dashed]
	route_7_11 -> expert_7_11_0
	route_7_11 -> expert_7_11_1
	expert_7_11_0 -> tp_7_11
	expert_7_11_1 -> tp_7_11
	tp_7_11 -> agg_7
	gate_7 -> route_7_12 [style=dashed]
	route_7_12 -> expert_7_12_0
	route_7_12 -> expert_7_12_1
	expert_7_12_0 -> tp_7_12
	expert_7_12_1 -> tp_7_12
	tp_7_12 -> agg_7
	gate_7 -> route_7_13 [style=dashed]
	route_7_13 -> expert_7_13_0
	route_7_13 -> expert_7_13_1
	expert_7_13_0 -> tp_7_13
	expert_7_13_1 -> tp_7_13
	tp_7_13 -> agg_7
	gate_7 -> route_7_14 [style=dashed]
	route_7_14 -> expert_7_14_0
	route_7_14 -> expert_7_14_1
	expert_7_14_0 -> tp_7_14
	expert_7_14_1 -> tp_7_14
	tp_7_14 -> agg_7
	gate_7 -> route_7_15 [style=dashed]
	route_7_15 -> expert_7_15_0
	route_7_15 -> expert_7_15_1
	expert_7_15_0 -> tp_7_15
	expert_7_15_1 -> tp_7_15
	tp_7_15 -> agg_7
	agg_7 -> output_7
	output_7 -> mha_8
	mha_8 -> gate_8
	gate_8 -> route_8_0 [style=dashed]
	route_8_0 -> expert_8_0_0
	route_8_0 -> expert_8_0_1
	expert_8_0_0 -> tp_8_0
	expert_8_0_1 -> tp_8_0
	tp_8_0 -> agg_8
	gate_8 -> route_8_1 [style=dashed]
	route_8_1 -> expert_8_1_0
	route_8_1 -> expert_8_1_1
	expert_8_1_0 -> tp_8_1
	expert_8_1_1 -> tp_8_1
	tp_8_1 -> agg_8
	gate_8 -> route_8_2 [style=dashed]
	route_8_2 -> expert_8_2_0
	route_8_2 -> expert_8_2_1
	expert_8_2_0 -> tp_8_2
	expert_8_2_1 -> tp_8_2
	tp_8_2 -> agg_8
	gate_8 -> route_8_3 [style=dashed]
	route_8_3 -> expert_8_3_0
	route_8_3 -> expert_8_3_1
	expert_8_3_0 -> tp_8_3
	expert_8_3_1 -> tp_8_3
	tp_8_3 -> agg_8
	gate_8 -> route_8_4 [style=dashed]
	route_8_4 -> expert_8_4_0
	route_8_4 -> expert_8_4_1
	expert_8_4_0 -> tp_8_4
	expert_8_4_1 -> tp_8_4
	tp_8_4 -> agg_8
	gate_8 -> route_8_5 [style=dashed]
	route_8_5 -> expert_8_5_0
	route_8_5 -> expert_8_5_1
	expert_8_5_0 -> tp_8_5
	expert_8_5_1 -> tp_8_5
	tp_8_5 -> agg_8
	gate_8 -> route_8_6 [style=dashed]
	route_8_6 -> expert_8_6_0
	route_8_6 -> expert_8_6_1
	expert_8_6_0 -> tp_8_6
	expert_8_6_1 -> tp_8_6
	tp_8_6 -> agg_8
	gate_8 -> route_8_7 [style=dashed]
	route_8_7 -> expert_8_7_0
	route_8_7 -> expert_8_7_1
	expert_8_7_0 -> tp_8_7
	expert_8_7_1 -> tp_8_7
	tp_8_7 -> agg_8
	gate_8 -> route_8_8 [style=dashed]
	route_8_8 -> expert_8_8_0
	route_8_8 -> expert_8_8_1
	expert_8_8_0 -> tp_8_8
	expert_8_8_1 -> tp_8_8
	tp_8_8 -> agg_8
	gate_8 -> route_8_9 [style=dashed]
	route_8_9 -> expert_8_9_0
	route_8_9 -> expert_8_9_1
	expert_8_9_0 -> tp_8_9
	expert_8_9_1 -> tp_8_9
	tp_8_9 -> agg_8
	gate_8 -> route_8_10 [style=dashed]
	route_8_10 -> expert_8_10_0
	route_8_10 -> expert_8_10_1
	expert_8_10_0 -> tp_8_10
	expert_8_10_1 -> tp_8_10
	tp_8_10 -> agg_8
	gate_8 -> route_8_11 [style=dashed]
	route_8_11 -> expert_8_11_0
	route_8_11 -> expert_8_11_1
	expert_8_11_0 -> tp_8_11
	expert_8_11_1 -> tp_8_11
	tp_8_11 -> agg_8
	gate_8 -> route_8_12 [style=dashed]
	route_8_12 -> expert_8_12_0
	route_8_12 -> expert_8_12_1
	expert_8_12_0 -> tp_8_12
	expert_8_12_1 -> tp_8_12
	tp_8_12 -> agg_8
	gate_8 -> route_8_13 [style=dashed]
	route_8_13 -> expert_8_13_0
	route_8_13 -> expert_8_13_1
	expert_8_13_0 -> tp_8_13
	expert_8_13_1 -> tp_8_13
	tp_8_13 -> agg_8
	gate_8 -> route_8_14 [style=dashed]
	route_8_14 -> expert_8_14_0
	route_8_14 -> expert_8_14_1
	expert_8_14_0 -> tp_8_14
	expert_8_14_1 -> tp_8_14
	tp_8_14 -> agg_8
	gate_8 -> route_8_15 [style=dashed]
	route_8_15 -> expert_8_15_0
	route_8_15 -> expert_8_15_1
	expert_8_15_0 -> tp_8_15
	expert_8_15_1 -> tp_8_15
	tp_8_15 -> agg_8
	agg_8 -> output_8
	output_8 -> mha_9
	mha_9 -> gate_9
	gate_9 -> route_9_0 [style=dashed]
	route_9_0 -> expert_9_0_0
	route_9_0 -> expert_9_0_1
	expert_9_0_0 -> tp_9_0
	expert_9_0_1 -> tp_9_0
	tp_9_0 -> agg_9
	gate_9 -> route_9_1 [style=dashed]
	route_9_1 -> expert_9_1_0
	route_9_1 -> expert_9_1_1
	expert_9_1_0 -> tp_9_1
	expert_9_1_1 -> tp_9_1
	tp_9_1 -> agg_9
	gate_9 -> route_9_2 [style=dashed]
	route_9_2 -> expert_9_2_0
	route_9_2 -> expert_9_2_1
	expert_9_2_0 -> tp_9_2
	expert_9_2_1 -> tp_9_2
	tp_9_2 -> agg_9
	gate_9 -> route_9_3 [style=dashed]
	route_9_3 -> expert_9_3_0
	route_9_3 -> expert_9_3_1
	expert_9_3_0 -> tp_9_3
	expert_9_3_1 -> tp_9_3
	tp_9_3 -> agg_9
	gate_9 -> route_9_4 [style=dashed]
	route_9_4 -> expert_9_4_0
	route_9_4 -> expert_9_4_1
	expert_9_4_0 -> tp_9_4
	expert_9_4_1 -> tp_9_4
	tp_9_4 -> agg_9
	gate_9 -> route_9_5 [style=dashed]
	route_9_5 -> expert_9_5_0
	route_9_5 -> expert_9_5_1
	expert_9_5_0 -> tp_9_5
	expert_9_5_1 -> tp_9_5
	tp_9_5 -> agg_9
	gate_9 -> route_9_6 [style=dashed]
	route_9_6 -> expert_9_6_0
	route_9_6 -> expert_9_6_1
	expert_9_6_0 -> tp_9_6
	expert_9_6_1 -> tp_9_6
	tp_9_6 -> agg_9
	gate_9 -> route_9_7 [style=dashed]
	route_9_7 -> expert_9_7_0
	route_9_7 -> expert_9_7_1
	expert_9_7_0 -> tp_9_7
	expert_9_7_1 -> tp_9_7
	tp_9_7 -> agg_9
	gate_9 -> route_9_8 [style=dashed]
	route_9_8 -> expert_9_8_0
	route_9_8 -> expert_9_8_1
	expert_9_8_0 -> tp_9_8
	expert_9_8_1 -> tp_9_8
	tp_9_8 -> agg_9
	gate_9 -> route_9_9 [style=dashed]
	route_9_9 -> expert_9_9_0
	route_9_9 -> expert_9_9_1
	expert_9_9_0 -> tp_9_9
	expert_9_9_1 -> tp_9_9
	tp_9_9 -> agg_9
	gate_9 -> route_9_10 [style=dashed]
	route_9_10 -> expert_9_10_0
	route_9_10 -> expert_9_10_1
	expert_9_10_0 -> tp_9_10
	expert_9_10_1 -> tp_9_10
	tp_9_10 -> agg_9
	gate_9 -> route_9_11 [style=dashed]
	route_9_11 -> expert_9_11_0
	route_9_11 -> expert_9_11_1
	expert_9_11_0 -> tp_9_11
	expert_9_11_1 -> tp_9_11
	tp_9_11 -> agg_9
	gate_9 -> route_9_12 [style=dashed]
	route_9_12 -> expert_9_12_0
	route_9_12 -> expert_9_12_1
	expert_9_12_0 -> tp_9_12
	expert_9_12_1 -> tp_9_12
	tp_9_12 -> agg_9
	gate_9 -> route_9_13 [style=dashed]
	route_9_13 -> expert_9_13_0
	route_9_13 -> expert_9_13_1
	expert_9_13_0 -> tp_9_13
	expert_9_13_1 -> tp_9_13
	tp_9_13 -> agg_9
	gate_9 -> route_9_14 [style=dashed]
	route_9_14 -> expert_9_14_0
	route_9_14 -> expert_9_14_1
	expert_9_14_0 -> tp_9_14
	expert_9_14_1 -> tp_9_14
	tp_9_14 -> agg_9
	gate_9 -> route_9_15 [style=dashed]
	route_9_15 -> expert_9_15_0
	route_9_15 -> expert_9_15_1
	expert_9_15_0 -> tp_9_15
	expert_9_15_1 -> tp_9_15
	tp_9_15 -> agg_9
	agg_9 -> output_9
	output_9 -> mha_10
	mha_10 -> gate_10
	gate_10 -> route_10_0 [style=dashed]
	route_10_0 -> expert_10_0_0
	route_10_0 -> expert_10_0_1
	expert_10_0_0 -> tp_10_0
	expert_10_0_1 -> tp_10_0
	tp_10_0 -> agg_10
	gate_10 -> route_10_1 [style=dashed]
	route_10_1 -> expert_10_1_0
	route_10_1 -> expert_10_1_1
	expert_10_1_0 -> tp_10_1
	expert_10_1_1 -> tp_10_1
	tp_10_1 -> agg_10
	gate_10 -> route_10_2 [style=dashed]
	route_10_2 -> expert_10_2_0
	route_10_2 -> expert_10_2_1
	expert_10_2_0 -> tp_10_2
	expert_10_2_1 -> tp_10_2
	tp_10_2 -> agg_10
	gate_10 -> route_10_3 [style=dashed]
	route_10_3 -> expert_10_3_0
	route_10_3 -> expert_10_3_1
	expert_10_3_0 -> tp_10_3
	expert_10_3_1 -> tp_10_3
	tp_10_3 -> agg_10
	gate_10 -> route_10_4 [style=dashed]
	route_10_4 -> expert_10_4_0
	route_10_4 -> expert_10_4_1
	expert_10_4_0 -> tp_10_4
	expert_10_4_1 -> tp_10_4
	tp_10_4 -> agg_10
	gate_10 -> route_10_5 [style=dashed]
	route_10_5 -> expert_10_5_0
	route_10_5 -> expert_10_5_1
	expert_10_5_0 -> tp_10_5
	expert_10_5_1 -> tp_10_5
	tp_10_5 -> agg_10
	gate_10 -> route_10_6 [style=dashed]
	route_10_6 -> expert_10_6_0
	route_10_6 -> expert_10_6_1
	expert_10_6_0 -> tp_10_6
	expert_10_6_1 -> tp_10_6
	tp_10_6 -> agg_10
	gate_10 -> route_10_7 [style=dashed]
	route_10_7 -> expert_10_7_0
	route_10_7 -> expert_10_7_1
	expert_10_7_0 -> tp_10_7
	expert_10_7_1 -> tp_10_7
	tp_10_7 -> agg_10
	gate_10 -> route_10_8 [style=dashed]
	route_10_8 -> expert_10_8_0
	route_10_8 -> expert_10_8_1
	expert_10_8_0 -> tp_10_8
	expert_10_8_1 -> tp_10_8
	tp_10_8 -> agg_10
	gate_10 -> route_10_9 [style=dashed]
	route_10_9 -> expert_10_9_0
	route_10_9 -> expert_10_9_1
	expert_10_9_0 -> tp_10_9
	expert_10_9_1 -> tp_10_9
	tp_10_9 -> agg_10
	gate_10 -> route_10_10 [style=dashed]
	route_10_10 -> expert_10_10_0
	route_10_10 -> expert_10_10_1
	expert_10_10_0 -> tp_10_10
	expert_10_10_1 -> tp_10_10
	tp_10_10 -> agg_10
	gate_10 -> route_10_11 [style=dashed]
	route_10_11 -> expert_10_11_0
	route_10_11 -> expert_10_11_1
	expert_10_11_0 -> tp_10_11
	expert_10_11_1 -> tp_10_11
	tp_10_11 -> agg_10
	gate_10 -> route_10_12 [style=dashed]
	route_10_12 -> expert_10_12_0
	route_10_12 -> expert_10_12_1
	expert_10_12_0 -> tp_10_12
	expert_10_12_1 -> tp_10_12
	tp_10_12 -> agg_10
	gate_10 -> route_10_13 [style=dashed]
	route_10_13 -> expert_10_13_0
	route_10_13 -> expert_10_13_1
	expert_10_13_0 -> tp_10_13
	expert_10_13_1 -> tp_10_13
	tp_10_13 -> agg_10
	gate_10 -> route_10_14 [style=dashed]
	route_10_14 -> expert_10_14_0
	route_10_14 -> expert_10_14_1
	expert_10_14_0 -> tp_10_14
	expert_10_14_1 -> tp_10_14
	tp_10_14 -> agg_10
	gate_10 -> route_10_15 [style=dashed]
	route_10_15 -> expert_10_15_0
	route_10_15 -> expert_10_15_1
	expert_10_15_0 -> tp_10_15
	expert_10_15_1 -> tp_10_15
	tp_10_15 -> agg_10
	agg_10 -> output_10
	output_10 -> mha_11
	mha_11 -> gate_11
	gate_11 -> route_11_0 [style=dashed]
	route_11_0 -> expert_11_0_0
	route_11_0 -> expert_11_0_1
	expert_11_0_0 -> tp_11_0
	expert_11_0_1 -> tp_11_0
	tp_11_0 -> agg_11
	gate_11 -> route_11_1 [style=dashed]
	route_11_1 -> expert_11_1_0
	route_11_1 -> expert_11_1_1
	expert_11_1_0 -> tp_11_1
	expert_11_1_1 -> tp_11_1
	tp_11_1 -> agg_11
	gate_11 -> route_11_2 [style=dashed]
	route_11_2 -> expert_11_2_0
	route_11_2 -> expert_11_2_1
	expert_11_2_0 -> tp_11_2
	expert_11_2_1 -> tp_11_2
	tp_11_2 -> agg_11
	gate_11 -> route_11_3 [style=dashed]
	route_11_3 -> expert_11_3_0
	route_11_3 -> expert_11_3_1
	expert_11_3_0 -> tp_11_3
	expert_11_3_1 -> tp_11_3
	tp_11_3 -> agg_11
	gate_11 -> route_11_4 [style=dashed]
	route_11_4 -> expert_11_4_0
	route_11_4 -> expert_11_4_1
	expert_11_4_0 -> tp_11_4
	expert_11_4_1 -> tp_11_4
	tp_11_4 -> agg_11
	gate_11 -> route_11_5 [style=dashed]
	route_11_5 -> expert_11_5_0
	route_11_5 -> expert_11_5_1
	expert_11_5_0 -> tp_11_5
	expert_11_5_1 -> tp_11_5
	tp_11_5 -> agg_11
	gate_11 -> route_11_6 [style=dashed]
	route_11_6 -> expert_11_6_0
	route_11_6 -> expert_11_6_1
	expert_11_6_0 -> tp_11_6
	expert_11_6_1 -> tp_11_6
	tp_11_6 -> agg_11
	gate_11 -> route_11_7 [style=dashed]
	route_11_7 -> expert_11_7_0
	route_11_7 -> expert_11_7_1
	expert_11_7_0 -> tp_11_7
	expert_11_7_1 -> tp_11_7
	tp_11_7 -> agg_11
	gate_11 -> route_11_8 [style=dashed]
	route_11_8 -> expert_11_8_0
	route_11_8 -> expert_11_8_1
	expert_11_8_0 -> tp_11_8
	expert_11_8_1 -> tp_11_8
	tp_11_8 -> agg_11
	gate_11 -> route_11_9 [style=dashed]
	route_11_9 -> expert_11_9_0
	route_11_9 -> expert_11_9_1
	expert_11_9_0 -> tp_11_9
	expert_11_9_1 -> tp_11_9
	tp_11_9 -> agg_11
	gate_11 -> route_11_10 [style=dashed]
	route_11_10 -> expert_11_10_0
	route_11_10 -> expert_11_10_1
	expert_11_10_0 -> tp_11_10
	expert_11_10_1 -> tp_11_10
	tp_11_10 -> agg_11
	gate_11 -> route_11_11 [style=dashed]
	route_11_11 -> expert_11_11_0
	route_11_11 -> expert_11_11_1
	expert_11_11_0 -> tp_11_11
	expert_11_11_1 -> tp_11_11
	tp_11_11 -> agg_11
	gate_11 -> route_11_12 [style=dashed]
	route_11_12 -> expert_11_12_0
	route_11_12 -> expert_11_12_1
	expert_11_12_0 -> tp_11_12
	expert_11_12_1 -> tp_11_12
	tp_11_12 -> agg_11
	gate_11 -> route_11_13 [style=dashed]
	route_11_13 -> expert_11_13_0
	route_11_13 -> expert_11_13_1
	expert_11_13_0 -> tp_11_13
	expert_11_13_1 -> tp_11_13
	tp_11_13 -> agg_11
	gate_11 -> route_11_14 [style=dashed]
	route_11_14 -> expert_11_14_0
	route_11_14 -> expert_11_14_1
	expert_11_14_0 -> tp_11_14
	expert_11_14_1 -> tp_11_14
	tp_11_14 -> agg_11
	gate_11 -> route_11_15 [style=dashed]
	route_11_15 -> expert_11_15_0
	route_11_15 -> expert_11_15_1
	expert_11_15_0 -> tp_11_15
	expert_11_15_1 -> tp_11_15
	tp_11_15 -> agg_11
	agg_11 -> output_11
	output_11 -> mha_12
	mha_12 -> gate_12
	gate_12 -> route_12_0 [style=dashed]
	route_12_0 -> expert_12_0_0
	route_12_0 -> expert_12_0_1
	expert_12_0_0 -> tp_12_0
	expert_12_0_1 -> tp_12_0
	tp_12_0 -> agg_12
	gate_12 -> route_12_1 [style=dashed]
	route_12_1 -> expert_12_1_0
	route_12_1 -> expert_12_1_1
	expert_12_1_0 -> tp_12_1
	expert_12_1_1 -> tp_12_1
	tp_12_1 -> agg_12
	gate_12 -> route_12_2 [style=dashed]
	route_12_2 -> expert_12_2_0
	route_12_2 -> expert_12_2_1
	expert_12_2_0 -> tp_12_2
	expert_12_2_1 -> tp_12_2
	tp_12_2 -> agg_12
	gate_12 -> route_12_3 [style=dashed]
	route_12_3 -> expert_12_3_0
	route_12_3 -> expert_12_3_1
	expert_12_3_0 -> tp_12_3
	expert_12_3_1 -> tp_12_3
	tp_12_3 -> agg_12
	gate_12 -> route_12_4 [style=dashed]
	route_12_4 -> expert_12_4_0
	route_12_4 -> expert_12_4_1
	expert_12_4_0 -> tp_12_4
	expert_12_4_1 -> tp_12_4
	tp_12_4 -> agg_12
	gate_12 -> route_12_5 [style=dashed]
	route_12_5 -> expert_12_5_0
	route_12_5 -> expert_12_5_1
	expert_12_5_0 -> tp_12_5
	expert_12_5_1 -> tp_12_5
	tp_12_5 -> agg_12
	gate_12 -> route_12_6 [style=dashed]
	route_12_6 -> expert_12_6_0
	route_12_6 -> expert_12_6_1
	expert_12_6_0 -> tp_12_6
	expert_12_6_1 -> tp_12_6
	tp_12_6 -> agg_12
	gate_12 -> route_12_7 [style=dashed]
	route_12_7 -> expert_12_7_0
	route_12_7 -> expert_12_7_1
	expert_12_7_0 -> tp_12_7
	expert_12_7_1 -> tp_12_7
	tp_12_7 -> agg_12
	gate_12 -> route_12_8 [style=dashed]
	route_12_8 -> expert_12_8_0
	route_12_8 -> expert_12_8_1
	expert_12_8_0 -> tp_12_8
	expert_12_8_1 -> tp_12_8
	tp_12_8 -> agg_12
	gate_12 -> route_12_9 [style=dashed]
	route_12_9 -> expert_12_9_0
	route_12_9 -> expert_12_9_1
	expert_12_9_0 -> tp_12_9
	expert_12_9_1 -> tp_12_9
	tp_12_9 -> agg_12
	gate_12 -> route_12_10 [style=dashed]
	route_12_10 -> expert_12_10_0
	route_12_10 -> expert_12_10_1
	expert_12_10_0 -> tp_12_10
	expert_12_10_1 -> tp_12_10
	tp_12_10 -> agg_12
	gate_12 -> route_12_11 [style=dashed]
	route_12_11 -> expert_12_11_0
	route_12_11 -> expert_12_11_1
	expert_12_11_0 -> tp_12_11
	expert_12_11_1 -> tp_12_11
	tp_12_11 -> agg_12
	gate_12 -> route_12_12 [style=dashed]
	route_12_12 -> expert_12_12_0
	route_12_12 -> expert_12_12_1
	expert_12_12_0 -> tp_12_12
	expert_12_12_1 -> tp_12_12
	tp_12_12 -> agg_12
	gate_12 -> route_12_13 [style=dashed]
	route_12_13 -> expert_12_13_0
	route_12_13 -> expert_12_13_1
	expert_12_13_0 -> tp_12_13
	expert_12_13_1 -> tp_12_13
	tp_12_13 -> agg_12
	gate_12 -> route_12_14 [style=dashed]
	route_12_14 -> expert_12_14_0
	route_12_14 -> expert_12_14_1
	expert_12_14_0 -> tp_12_14
	expert_12_14_1 -> tp_12_14
	tp_12_14 -> agg_12
	gate_12 -> route_12_15 [style=dashed]
	route_12_15 -> expert_12_15_0
	route_12_15 -> expert_12_15_1
	expert_12_15_0 -> tp_12_15
	expert_12_15_1 -> tp_12_15
	tp_12_15 -> agg_12
	agg_12 -> output_12
	output_12 -> mha_13
	mha_13 -> gate_13
	gate_13 -> route_13_0 [style=dashed]
	route_13_0 -> expert_13_0_0
	route_13_0 -> expert_13_0_1
	expert_13_0_0 -> tp_13_0
	expert_13_0_1 -> tp_13_0
	tp_13_0 -> agg_13
	gate_13 -> route_13_1 [style=dashed]
	route_13_1 -> expert_13_1_0
	route_13_1 -> expert_13_1_1
	expert_13_1_0 -> tp_13_1
	expert_13_1_1 -> tp_13_1
	tp_13_1 -> agg_13
	gate_13 -> route_13_2 [style=dashed]
	route_13_2 -> expert_13_2_0
	route_13_2 -> expert_13_2_1
	expert_13_2_0 -> tp_13_2
	expert_13_2_1 -> tp_13_2
	tp_13_2 -> agg_13
	gate_13 -> route_13_3 [style=dashed]
	route_13_3 -> expert_13_3_0
	route_13_3 -> expert_13_3_1
	expert_13_3_0 -> tp_13_3
	expert_13_3_1 -> tp_13_3
	tp_13_3 -> agg_13
	gate_13 -> route_13_4 [style=dashed]
	route_13_4 -> expert_13_4_0
	route_13_4 -> expert_13_4_1
	expert_13_4_0 -> tp_13_4
	expert_13_4_1 -> tp_13_4
	tp_13_4 -> agg_13
	gate_13 -> route_13_5 [style=dashed]
	route_13_5 -> expert_13_5_0
	route_13_5 -> expert_13_5_1
	expert_13_5_0 -> tp_13_5
	expert_13_5_1 -> tp_13_5
	tp_13_5 -> agg_13
	gate_13 -> route_13_6 [style=dashed]
	route_13_6 -> expert_13_6_0
	route_13_6 -> expert_13_6_1
	expert_13_6_0 -> tp_13_6
	expert_13_6_1 -> tp_13_6
	tp_13_6 -> agg_13
	gate_13 -> route_13_7 [style=dashed]
	route_13_7 -> expert_13_7_0
	route_13_7 -> expert_13_7_1
	expert_13_7_0 -> tp_13_7
	expert_13_7_1 -> tp_13_7
	tp_13_7 -> agg_13
	gate_13 -> route_13_8 [style=dashed]
	route_13_8 -> expert_13_8_0
	route_13_8 -> expert_13_8_1
	expert_13_8_0 -> tp_13_8
	expert_13_8_1 -> tp_13_8
	tp_13_8 -> agg_13
	gate_13 -> route_13_9 [style=dashed]
	route_13_9 -> expert_13_9_0
	route_13_9 -> expert_13_9_1
	expert_13_9_0 -> tp_13_9
	expert_13_9_1 -> tp_13_9
	tp_13_9 -> agg_13
	gate_13 -> route_13_10 [style=dashed]
	route_13_10 -> expert_13_10_0
	route_13_10 -> expert_13_10_1
	expert_13_10_0 -> tp_13_10
	expert_13_10_1 -> tp_13_10
	tp_13_10 -> agg_13
	gate_13 -> route_13_11 [style=dashed]
	route_13_11 -> expert_13_11_0
	route_13_11 -> expert_13_11_1
	expert_13_11_0 -> tp_13_11
	expert_13_11_1 -> tp_13_11
	tp_13_11 -> agg_13
	gate_13 -> route_13_12 [style=dashed]
	route_13_12 -> expert_13_12_0
	route_13_12 -> expert_13_12_1
	expert_13_12_0 -> tp_13_12
	expert_13_12_1 -> tp_13_12
	tp_13_12 -> agg_13
	gate_13 -> route_13_13 [style=dashed]
	route_13_13 -> expert_13_13_0
	route_13_13 -> expert_13_13_1
	expert_13_13_0 -> tp_13_13
	expert_13_13_1 -> tp_13_13
	tp_13_13 -> agg_13
	gate_13 -> route_13_14 [style=dashed]
	route_13_14 -> expert_13_14_0
	route_13_14 -> expert_13_14_1
	expert_13_14_0 -> tp_13_14
	expert_13_14_1 -> tp_13_14
	tp_13_14 -> agg_13
	gate_13 -> route_13_15 [style=dashed]
	route_13_15 -> expert_13_15_0
	route_13_15 -> expert_13_15_1
	expert_13_15_0 -> tp_13_15
	expert_13_15_1 -> tp_13_15
	tp_13_15 -> agg_13
	agg_13 -> output_13
	output_13 -> mha_14
	mha_14 -> gate_14
	gate_14 -> route_14_0 [style=dashed]
	route_14_0 -> expert_14_0_0
	route_14_0 -> expert_14_0_1
	expert_14_0_0 -> tp_14_0
	expert_14_0_1 -> tp_14_0
	tp_14_0 -> agg_14
	gate_14 -> route_14_1 [style=dashed]
	route_14_1 -> expert_14_1_0
	route_14_1 -> expert_14_1_1
	expert_14_1_0 -> tp_14_1
	expert_14_1_1 -> tp_14_1
	tp_14_1 -> agg_14
	gate_14 -> route_14_2 [style=dashed]
	route_14_2 -> expert_14_2_0
	route_14_2 -> expert_14_2_1
	expert_14_2_0 -> tp_14_2
	expert_14_2_1 -> tp_14_2
	tp_14_2 -> agg_14
	gate_14 -> route_14_3 [style=dashed]
	route_14_3 -> expert_14_3_0
	route_14_3 -> expert_14_3_1
	expert_14_3_0 -> tp_14_3
	expert_14_3_1 -> tp_14_3
	tp_14_3 -> agg_14
	gate_14 -> route_14_4 [style=dashed]
	route_14_4 -> expert_14_4_0
	route_14_4 -> expert_14_4_1
	expert_14_4_0 -> tp_14_4
	expert_14_4_1 -> tp_14_4
	tp_14_4 -> agg_14
	gate_14 -> route_14_5 [style=dashed]
	route_14_5 -> expert_14_5_0
	route_14_5 -> expert_14_5_1
	expert_14_5_0 -> tp_14_5
	expert_14_5_1 -> tp_14_5
	tp_14_5 -> agg_14
	gate_14 -> route_14_6 [style=dashed]
	route_14_6 -> expert_14_6_0
	route_14_6 -> expert_14_6_1
	expert_14_6_0 -> tp_14_6
	expert_14_6_1 -> tp_14_6
	tp_14_6 -> agg_14
	gate_14 -> route_14_7 [style=dashed]
	route_14_7 -> expert_14_7_0
	route_14_7 -> expert_14_7_1
	expert_14_7_0 -> tp_14_7
	expert_14_7_1 -> tp_14_7
	tp_14_7 -> agg_14
	gate_14 -> route_14_8 [style=dashed]
	route_14_8 -> expert_14_8_0
	route_14_8 -> expert_14_8_1
	expert_14_8_0 -> tp_14_8
	expert_14_8_1 -> tp_14_8
	tp_14_8 -> agg_14
	gate_14 -> route_14_9 [style=dashed]
	route_14_9 -> expert_14_9_0
	route_14_9 -> expert_14_9_1
	expert_14_9_0 -> tp_14_9
	expert_14_9_1 -> tp_14_9
	tp_14_9 -> agg_14
	gate_14 -> route_14_10 [style=dashed]
	route_14_10 -> expert_14_10_0
	route_14_10 -> expert_14_10_1
	expert_14_10_0 -> tp_14_10
	expert_14_10_1 -> tp_14_10
	tp_14_10 -> agg_14
	gate_14 -> route_14_11 [style=dashed]
	route_14_11 -> expert_14_11_0
	route_14_11 -> expert_14_11_1
	expert_14_11_0 -> tp_14_11
	expert_14_11_1 -> tp_14_11
	tp_14_11 -> agg_14
	gate_14 -> route_14_12 [style=dashed]
	route_14_12 -> expert_14_12_0
	route_14_12 -> expert_14_12_1
	expert_14_12_0 -> tp_14_12
	expert_14_12_1 -> tp_14_12
	tp_14_12 -> agg_14
	gate_14 -> route_14_13 [style=dashed]
	route_14_13 -> expert_14_13_0
	route_14_13 -> expert_14_13_1
	expert_14_13_0 -> tp_14_13
	expert_14_13_1 -> tp_14_13
	tp_14_13 -> agg_14
	gate_14 -> route_14_14 [style=dashed]
	route_14_14 -> expert_14_14_0
	route_14_14 -> expert_14_14_1
	expert_14_14_0 -> tp_14_14
	expert_14_14_1 -> tp_14_14
	tp_14_14 -> agg_14
	gate_14 -> route_14_15 [style=dashed]
	route_14_15 -> expert_14_15_0
	route_14_15 -> expert_14_15_1
	expert_14_15_0 -> tp_14_15
	expert_14_15_1 -> tp_14_15
	tp_14_15 -> agg_14
	agg_14 -> output_14
	output_14 -> mha_15
	mha_15 -> gate_15
	gate_15 -> route_15_0 [style=dashed]
	route_15_0 -> expert_15_0_0
	route_15_0 -> expert_15_0_1
	expert_15_0_0 -> tp_15_0
	expert_15_0_1 -> tp_15_0
	tp_15_0 -> agg_15
	gate_15 -> route_15_1 [style=dashed]
	route_15_1 -> expert_15_1_0
	route_15_1 -> expert_15_1_1
	expert_15_1_0 -> tp_15_1
	expert_15_1_1 -> tp_15_1
	tp_15_1 -> agg_15
	gate_15 -> route_15_2 [style=dashed]
	route_15_2 -> expert_15_2_0
	route_15_2 -> expert_15_2_1
	expert_15_2_0 -> tp_15_2
	expert_15_2_1 -> tp_15_2
	tp_15_2 -> agg_15
	gate_15 -> route_15_3 [style=dashed]
	route_15_3 -> expert_15_3_0
	route_15_3 -> expert_15_3_1
	expert_15_3_0 -> tp_15_3
	expert_15_3_1 -> tp_15_3
	tp_15_3 -> agg_15
	gate_15 -> route_15_4 [style=dashed]
	route_15_4 -> expert_15_4_0
	route_15_4 -> expert_15_4_1
	expert_15_4_0 -> tp_15_4
	expert_15_4_1 -> tp_15_4
	tp_15_4 -> agg_15
	gate_15 -> route_15_5 [style=dashed]
	route_15_5 -> expert_15_5_0
	route_15_5 -> expert_15_5_1
	expert_15_5_0 -> tp_15_5
	expert_15_5_1 -> tp_15_5
	tp_15_5 -> agg_15
	gate_15 -> route_15_6 [style=dashed]
	route_15_6 -> expert_15_6_0
	route_15_6 -> expert_15_6_1
	expert_15_6_0 -> tp_15_6
	expert_15_6_1 -> tp_15_6
	tp_15_6 -> agg_15
	gate_15 -> route_15_7 [style=dashed]
	route_15_7 -> expert_15_7_0
	route_15_7 -> expert_15_7_1
	expert_15_7_0 -> tp_15_7
	expert_15_7_1 -> tp_15_7
	tp_15_7 -> agg_15
	gate_15 -> route_15_8 [style=dashed]
	route_15_8 -> expert_15_8_0
	route_15_8 -> expert_15_8_1
	expert_15_8_0 -> tp_15_8
	expert_15_8_1 -> tp_15_8
	tp_15_8 -> agg_15
	gate_15 -> route_15_9 [style=dashed]
	route_15_9 -> expert_15_9_0
	route_15_9 -> expert_15_9_1
	expert_15_9_0 -> tp_15_9
	expert_15_9_1 -> tp_15_9
	tp_15_9 -> agg_15
	gate_15 -> route_15_10 [style=dashed]
	route_15_10 -> expert_15_10_0
	route_15_10 -> expert_15_10_1
	expert_15_10_0 -> tp_15_10
	expert_15_10_1 -> tp_15_10
	tp_15_10 -> agg_15
	gate_15 -> route_15_11 [style=dashed]
	route_15_11 -> expert_15_11_0
	route_15_11 -> expert_15_11_1
	expert_15_11_0 -> tp_15_11
	expert_15_11_1 -> tp_15_11
	tp_15_11 -> agg_15
	gate_15 -> route_15_12 [style=dashed]
	route_15_12 -> expert_15_12_0
	route_15_12 -> expert_15_12_1
	expert_15_12_0 -> tp_15_12
	expert_15_12_1 -> tp_15_12
	tp_15_12 -> agg_15
	gate_15 -> route_15_13 [style=dashed]
	route_15_13 -> expert_15_13_0
	route_15_13 -> expert_15_13_1
	expert_15_13_0 -> tp_15_13
	expert_15_13_1 -> tp_15_13
	tp_15_13 -> agg_15
	gate_15 -> route_15_14 [style=dashed]
	route_15_14 -> expert_15_14_0
	route_15_14 -> expert_15_14_1
	expert_15_14_0 -> tp_15_14
	expert_15_14_1 -> tp_15_14
	tp_15_14 -> agg_15
	gate_15 -> route_15_15 [style=dashed]
	route_15_15 -> expert_15_15_0
	route_15_15 -> expert_15_15_1
	expert_15_15_0 -> tp_15_15
	expert_15_15_1 -> tp_15_15
	tp_15_15 -> agg_15
	agg_15 -> output_15
	final_output [label="Final Output\nInput: [batch_size=128, seq_len=10240, heads=16, d_k=32]\nOutput: [batch_size=128, seq_len=10240, heads=16, d_k=32]" fillcolor=lightblue shape=ellipse style=filled]
	output_15 -> final_output
}
