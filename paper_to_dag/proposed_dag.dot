digraph MoE_Proposed_EP16 {
    rankdir=TB;
    size="25,35";
    node [fontname="Arial", fontsize=10];
    
    // Input
    input [label="Model Input\nbatch_size=128, seq_len=10000, d_model=4096" 
           shape=ellipse, fillcolor=lightgreen, style=filled];
    
    // Representative Layer 0 (all 16 layers follow same pattern)
    subgraph cluster_layer0 {
        label="Layer 0 (Representative)\n16 Total Layers";
        color=blue;
        
        // MHA - split across 256 GPUs as needed
        l0_mha [label="Multi-Head Attention\nIn: [128,10000,4096]\nOut: [128,10000,4096]\nParallel across GPUs" 
               shape=rectangle, fillcolor=lightcoral, style=filled];
        
        // Routing
        l0_route [label="Token Routing\nIn: [128,10000,4096]\nOut: [128,10000,2] gate scores + [tokens,4096] data\nGPUs: 0-15" 
                 shape=parallelogram, fillcolor=orange, style=filled];
        
        // 16 experts - one per GPU
        subgraph cluster_experts_l0 {
            label="16 Experts (1 per GPU)";
            color=lightgray;
            
            l0_exp0 [label="Expert 0\nIn: [tokens,4096]\nOut: [tokens,4096]\nGPU: 0" 
                    shape=rectangle, fillcolor=lightyellow, style=filled];
            l0_exp1 [label="Expert 1\nIn: [tokens,4096]\nOut: [tokens,4096]\nGPU: 1" 
                    shape=rectangle, fillcolor=lightyellow, style=filled];
            l0_exp2 [label="Expert 2\nIn: [tokens,4096]\nOut: [tokens,4096]\nGPU: 2" 
                    shape=rectangle, fillcolor=lightyellow, style=filled];
            l0_exp3 [label="Expert 3\nIn: [tokens,4096]\nOut: [tokens,4096]\nGPU: 3" 
                    shape=rectangle, fillcolor=lightyellow, style=filled];
            l0_exp4 [label="Expert 4\nIn: [tokens,4096]\nOut: [tokens,4096]\nGPU: 4" 
                    shape=rectangle, fillcolor=lightyellow, style=filled];
            l0_exp5 [label="Expert 5\nIn: [tokens,4096]\nOut: [tokens,4096]\nGPU: 5" 
                    shape=rectangle, fillcolor=lightyellow, style=filled];
            l0_exp6 [label="Expert 6\nIn: [tokens,4096]\nOut: [tokens,4096]\nGPU: 6" 
                    shape=rectangle, fillcolor=lightyellow, style=filled];
            l0_exp7 [label="Expert 7\nIn: [tokens,4096]\nOut: [tokens,4096]\nGPU: 7" 
                    shape=rectangle, fillcolor=lightyellow, style=filled];
            l0_exp8 [label="Expert 8\nIn: [tokens,4096]\nOut: [tokens,4096]\nGPU: 8" 
                    shape=rectangle, fillcolor=lightyellow, style=filled];
            l0_exp9 [label="Expert 9\nIn: [tokens,4096]\nOut: [tokens,4096]\nGPU: 9" 
                    shape=rectangle, fillcolor=lightyellow, style=filled];
            l0_exp10 [label="Expert 10\nIn: [tokens,4096]\nOut: [tokens,4096]\nGPU: 10" 
                     shape=rectangle, fillcolor=lightyellow, style=filled];
            l0_exp11 [label="Expert 11\nIn: [tokens,4096]\nOut: [tokens,4096]\nGPU: 11" 
                      shape=rectangle, fillcolor=lightyellow, style=filled];
            l0_exp12 [label="Expert 12\nIn: [tokens,4096]\nOut: [tokens,4096]\nGPU: 12" 
                      shape=rectangle, fillcolor=lightyellow, style=filled];
            l0_exp13 [label="Expert 13\nIn: [tokens,4096]\nOut: [tokens,4096]\nGPU: 13" 
                      shape=rectangle, fillcolor=lightyellow, style=filled];
            l0_exp14 [label="Expert 14\nIn: [tokens,4096]\nOut: [tokens,4096]\nGPU: 14" 
                      shape=rectangle, fillcolor=lightyellow, style=filled];
            l0_exp15 [label="Expert 15\nIn: [tokens,4096]\nOut: [tokens,4096]\nGPU: 15" 
                      shape=rectangle, fillcolor=lightyellow, style=filled];
        }
        
        // Aggregation
        l0_aggregate [label="Token Aggregation\nIn: [tokens,4096] from 16 experts\nOut: [128,10000,4096]\nGPUs: 0-15" 
                     shape=parallelogram, fillcolor=lightblue, style=filled];
        
        // Residual
        l0_residual [label="Add & LayerNorm\nIn: [128,10000,4096] + [128,10000,4096]\nOut: [128,10000,4096]\nAll GPUs" 
                    shape=ellipse, fillcolor=lightgreen, style=filled];
    }
    
    // Layer connections (representing all 16 layers)
    input -> l0_mha;
    l0_mha -> l0_route;
    l0_route -> l0_exp0 [label="async route"];
    l0_route -> l0_exp1 [label="async route"];
    l0_route -> l0_exp2 [label="async route"];
    l0_route -> l0_exp3 [label="async route"];
    l0_route -> l0_exp4 [label="async route"];
    l0_route -> l0_exp5 [label="async route"];
    l0_route -> l0_exp6 [label="async route"];
    l0_route -> l0_exp7 [label="async route"];
    l0_route -> l0_exp8 [label="async route"];
    l0_route -> l0_exp9 [label="async route"];
    l0_route -> l0_exp10 [label="async route"];
    l0_route -> l0_exp11 [label="async route"];
    l0_route -> l0_exp12 [label="async route"];
    l0_route -> l0_exp13 [label="async route"];
    l0_route -> l0_exp14 [label="async route"];
    l0_route -> l0_exp15 [label="async route"];
    
    l0_exp0 -> l0_aggregate [label="async gather"];
    l0_exp1 -> l0_aggregate [label="async gather"];
    l0_exp2 -> l0_aggregate [label="async gather"];
    l0_exp3 -> l0_aggregate [label="async gather"];
    l0_exp4 -> l0_aggregate [label="async gather"];
    l0_exp5 -> l0_aggregate [label="async gather"];
    l0_exp6 -> l0_aggregate [label="async gather"];
    l0_exp7 -> l0_aggregate [label="async gather"];
    l0_exp8 -> l0_aggregate [label="async gather"];
    l0_exp9 -> l0_aggregate [label="async gather"];
    l0_exp10 -> l0_aggregate [label="async gather"];
    l0_exp11 -> l0_aggregate [label="async gather"];
    l0_exp12 -> l0_aggregate [label="async gather"];
    l0_exp13 -> l0_aggregate [label="async gather"];
    l0_exp14 -> l0_aggregate [label="async gather"];
    l0_exp15 -> l0_aggregate [label="async gather"];
    
    l0_aggregate -> l0_residual;
    
    // Output
    output [label="Model Output\nbatch_size=128, seq_len=10000, d_model=4096" 
           shape=ellipse, fillcolor=lightgreen, style=filled];
    
    // Layer repetition indication
    layer_rep [label=<<table border="0" cellborder="1" cellspacing="0">
        <tr><td><b>Architecture Overview</b></td></tr>
        <tr><td>16 Total Layers (0-15)</td></tr>
        <tr><td>256 GPUs (16 layers Ã— 16 experts)</td></tr>
        <tr><td>1 Expert per GPU</td></tr>
        <tr><td>Each layer: MHA -> Route -> 16 Experts -> Aggregate -> Residual</td></tr>
        <tr><td>Async all-to-all communication</td></tr>
        </table>>, shape=plaintext];
    
    l0_residual -> output [label="x16 layers"];
}