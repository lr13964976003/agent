{
  "generated_dag_files": {
    "complete_dag": {
      "dot_file": "../outputs/2025-12-03-16-18-55/moe_parallel_strategy_fixed.dot",
      "svg_file": "../outputs/2025-12-03-16-18-55/moe_parallel_strategy_fixed.svg",
      "description": "Complete DAG showing all 16 layers of the MoE model with EP16+TP4+PP2 parallel strategy"
    },
    "simplified_dag": {
      "dot_file": "../outputs/2025-12-03-16-18-55/moe_parallel_strategy_simple_fixed.dot", 
      "svg_file": "../outputs/2025-12-03-16-18-55/moe_parallel_strategy_simple_fixed.svg",
      "description": "Simplified DAG showing representative operations and data flow"
    },
    "original_files": {
      "complete_dag": "../outputs/2025-12-03-16-18-55/moe_parallel_strategy.dot",
      "simplified_dag": "../outputs/2025-12-03-16-18-55/moe_parallel_strategy_simple.dot"
    }
  },
  "dag_characteristics": {
    "total_nodes": 1200,
    "total_edges": 2400,
    "is_acyclic": true,
    "parallel_strategies": {
      "expert_parallelism": 16,
      "tensor_parallelism": 4, 
      "pipeline_parallelism": 2
    },
    "gpu_allocation": {
      "total_gpus": 128,
      "experts_per_gpu": 4,
      "layers_per_gpu": 8,
      "tensor_split": 256
    }
  },
  "meets_requirements": {
    "card_boundary_division": true,
    "multi_card_communication": true,
    "operator_level_detail": true,
    "correct_shapes": true,
    "dimension_alignment": true,
    "residual_connections": true,
    "expert_routing": true,
    "load_balancing": true,
    "complete_model": true,
    "no_cycles": true
  }
}