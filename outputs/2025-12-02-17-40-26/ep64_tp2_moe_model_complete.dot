// EP64_TP2 Hybrid Parallel MoE Model DAG - Simplified Complete View
digraph {
	nodesep=0.3 rankdir=TB ranksep=0.5 splines=ortho
	node [fillcolor=lightblue shape=ellipse style=filled]
	node [fillcolor=lightgreen shape=rectangle style=filled]
	node [fillcolor=lightyellow shape=parallelogram style=filled]
	input [label="INPUT\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=white shape=octagon style=filled]
	layer_0_ln1_gpu0 [label="LayerNorm1_GPU0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu1 [label="LayerNorm1_GPU1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu2 [label="LayerNorm1_GPU2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu3 [label="LayerNorm1_GPU3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu4 [label="LayerNorm1_GPU4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu5 [label="LayerNorm1_GPU5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu6 [label="LayerNorm1_GPU6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu7 [label="LayerNorm1_GPU7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu8 [label="LayerNorm1_GPU8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu9 [label="LayerNorm1_GPU9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu10 [label="LayerNorm1_GPU10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu11 [label="LayerNorm1_GPU11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu12 [label="LayerNorm1_GPU12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu13 [label="LayerNorm1_GPU13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu14 [label="LayerNorm1_GPU14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu15 [label="LayerNorm1_GPU15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu16 [label="LayerNorm1_GPU16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu17 [label="LayerNorm1_GPU17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu18 [label="LayerNorm1_GPU18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu19 [label="LayerNorm1_GPU19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu20 [label="LayerNorm1_GPU20\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu21 [label="LayerNorm1_GPU21\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu22 [label="LayerNorm1_GPU22\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu23 [label="LayerNorm1_GPU23\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu24 [label="LayerNorm1_GPU24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu25 [label="LayerNorm1_GPU25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu26 [label="LayerNorm1_GPU26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu27 [label="LayerNorm1_GPU27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu28 [label="LayerNorm1_GPU28\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu29 [label="LayerNorm1_GPU29\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu30 [label="LayerNorm1_GPU30\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu31 [label="LayerNorm1_GPU31\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu32 [label="LayerNorm1_GPU32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu33 [label="LayerNorm1_GPU33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu34 [label="LayerNorm1_GPU34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu35 [label="LayerNorm1_GPU35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu36 [label="LayerNorm1_GPU36\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu37 [label="LayerNorm1_GPU37\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu38 [label="LayerNorm1_GPU38\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu39 [label="LayerNorm1_GPU39\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu40 [label="LayerNorm1_GPU40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu41 [label="LayerNorm1_GPU41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu42 [label="LayerNorm1_GPU42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu43 [label="LayerNorm1_GPU43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu44 [label="LayerNorm1_GPU44\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu45 [label="LayerNorm1_GPU45\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu46 [label="LayerNorm1_GPU46\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu47 [label="LayerNorm1_GPU47\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu48 [label="LayerNorm1_GPU48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu49 [label="LayerNorm1_GPU49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu50 [label="LayerNorm1_GPU50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu51 [label="LayerNorm1_GPU51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu52 [label="LayerNorm1_GPU52\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu53 [label="LayerNorm1_GPU53\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu54 [label="LayerNorm1_GPU54\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu55 [label="LayerNorm1_GPU55\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu56 [label="LayerNorm1_GPU56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu57 [label="LayerNorm1_GPU57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu58 [label="LayerNorm1_GPU58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu59 [label="LayerNorm1_GPU59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu60 [label="LayerNorm1_GPU60\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu61 [label="LayerNorm1_GPU61\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu62 [label="LayerNorm1_GPU62\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu63 [label="LayerNorm1_GPU63\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu64 [label="LayerNorm1_GPU64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu65 [label="LayerNorm1_GPU65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu66 [label="LayerNorm1_GPU66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu67 [label="LayerNorm1_GPU67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu68 [label="LayerNorm1_GPU68\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu69 [label="LayerNorm1_GPU69\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu70 [label="LayerNorm1_GPU70\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu71 [label="LayerNorm1_GPU71\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu72 [label="LayerNorm1_GPU72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu73 [label="LayerNorm1_GPU73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu74 [label="LayerNorm1_GPU74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu75 [label="LayerNorm1_GPU75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu76 [label="LayerNorm1_GPU76\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu77 [label="LayerNorm1_GPU77\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu78 [label="LayerNorm1_GPU78\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu79 [label="LayerNorm1_GPU79\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu80 [label="LayerNorm1_GPU80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu81 [label="LayerNorm1_GPU81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu82 [label="LayerNorm1_GPU82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu83 [label="LayerNorm1_GPU83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu84 [label="LayerNorm1_GPU84\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu85 [label="LayerNorm1_GPU85\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu86 [label="LayerNorm1_GPU86\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu87 [label="LayerNorm1_GPU87\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu88 [label="LayerNorm1_GPU88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu89 [label="LayerNorm1_GPU89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu90 [label="LayerNorm1_GPU90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu91 [label="LayerNorm1_GPU91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu92 [label="LayerNorm1_GPU92\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu93 [label="LayerNorm1_GPU93\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu94 [label="LayerNorm1_GPU94\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu95 [label="LayerNorm1_GPU95\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu96 [label="LayerNorm1_GPU96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu97 [label="LayerNorm1_GPU97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu98 [label="LayerNorm1_GPU98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu99 [label="LayerNorm1_GPU99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu100 [label="LayerNorm1_GPU100\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu101 [label="LayerNorm1_GPU101\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu102 [label="LayerNorm1_GPU102\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu103 [label="LayerNorm1_GPU103\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu104 [label="LayerNorm1_GPU104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu105 [label="LayerNorm1_GPU105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu106 [label="LayerNorm1_GPU106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu107 [label="LayerNorm1_GPU107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu108 [label="LayerNorm1_GPU108\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu109 [label="LayerNorm1_GPU109\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu110 [label="LayerNorm1_GPU110\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu111 [label="LayerNorm1_GPU111\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu112 [label="LayerNorm1_GPU112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu113 [label="LayerNorm1_GPU113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu114 [label="LayerNorm1_GPU114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu115 [label="LayerNorm1_GPU115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu116 [label="LayerNorm1_GPU116\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu117 [label="LayerNorm1_GPU117\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu118 [label="LayerNorm1_GPU118\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu119 [label="LayerNorm1_GPU119\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu120 [label="LayerNorm1_GPU120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu121 [label="LayerNorm1_GPU121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu122 [label="LayerNorm1_GPU122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu123 [label="LayerNorm1_GPU123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu124 [label="LayerNorm1_GPU124\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu125 [label="LayerNorm1_GPU125\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu126 [label="LayerNorm1_GPU126\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln1_gpu127 [label="LayerNorm1_GPU127\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu0 [label="QKV_Proj_GPU0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu1 [label="QKV_Proj_GPU1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu0 [label="Attention_GPU0\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu1 [label="Attention_GPU1\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu0 [label="Attn_Out_Proj_GPU0\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu1 [label="Attn_Out_Proj_GPU1\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group0 [label="AllReduce_Attn_Group0\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu2 [label="QKV_Proj_GPU2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu3 [label="QKV_Proj_GPU3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu2 [label="Attention_GPU2\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu3 [label="Attention_GPU3\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu2 [label="Attn_Out_Proj_GPU2\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu3 [label="Attn_Out_Proj_GPU3\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group1 [label="AllReduce_Attn_Group1\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu4 [label="QKV_Proj_GPU4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu5 [label="QKV_Proj_GPU5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu4 [label="Attention_GPU4\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu5 [label="Attention_GPU5\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu4 [label="Attn_Out_Proj_GPU4\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu5 [label="Attn_Out_Proj_GPU5\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group2 [label="AllReduce_Attn_Group2\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu6 [label="QKV_Proj_GPU6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu7 [label="QKV_Proj_GPU7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu6 [label="Attention_GPU6\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu7 [label="Attention_GPU7\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu6 [label="Attn_Out_Proj_GPU6\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu7 [label="Attn_Out_Proj_GPU7\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group3 [label="AllReduce_Attn_Group3\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu8 [label="QKV_Proj_GPU8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu9 [label="QKV_Proj_GPU9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu8 [label="Attention_GPU8\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu9 [label="Attention_GPU9\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu8 [label="Attn_Out_Proj_GPU8\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu9 [label="Attn_Out_Proj_GPU9\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group4 [label="AllReduce_Attn_Group4\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu10 [label="QKV_Proj_GPU10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu11 [label="QKV_Proj_GPU11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu10 [label="Attention_GPU10\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu11 [label="Attention_GPU11\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu10 [label="Attn_Out_Proj_GPU10\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu11 [label="Attn_Out_Proj_GPU11\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group5 [label="AllReduce_Attn_Group5\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu12 [label="QKV_Proj_GPU12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu13 [label="QKV_Proj_GPU13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu12 [label="Attention_GPU12\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu13 [label="Attention_GPU13\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu12 [label="Attn_Out_Proj_GPU12\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu13 [label="Attn_Out_Proj_GPU13\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group6 [label="AllReduce_Attn_Group6\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu14 [label="QKV_Proj_GPU14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu15 [label="QKV_Proj_GPU15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu14 [label="Attention_GPU14\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu15 [label="Attention_GPU15\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu14 [label="Attn_Out_Proj_GPU14\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu15 [label="Attn_Out_Proj_GPU15\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group7 [label="AllReduce_Attn_Group7\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu16 [label="QKV_Proj_GPU16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu17 [label="QKV_Proj_GPU17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu16 [label="Attention_GPU16\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu17 [label="Attention_GPU17\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu16 [label="Attn_Out_Proj_GPU16\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu17 [label="Attn_Out_Proj_GPU17\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group8 [label="AllReduce_Attn_Group8\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu18 [label="QKV_Proj_GPU18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu19 [label="QKV_Proj_GPU19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu18 [label="Attention_GPU18\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu19 [label="Attention_GPU19\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu18 [label="Attn_Out_Proj_GPU18\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu19 [label="Attn_Out_Proj_GPU19\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group9 [label="AllReduce_Attn_Group9\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu20 [label="QKV_Proj_GPU20\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu21 [label="QKV_Proj_GPU21\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu20 [label="Attention_GPU20\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu21 [label="Attention_GPU21\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu20 [label="Attn_Out_Proj_GPU20\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu21 [label="Attn_Out_Proj_GPU21\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group10 [label="AllReduce_Attn_Group10\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu22 [label="QKV_Proj_GPU22\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu23 [label="QKV_Proj_GPU23\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu22 [label="Attention_GPU22\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu23 [label="Attention_GPU23\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu22 [label="Attn_Out_Proj_GPU22\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu23 [label="Attn_Out_Proj_GPU23\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group11 [label="AllReduce_Attn_Group11\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu24 [label="QKV_Proj_GPU24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu25 [label="QKV_Proj_GPU25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu24 [label="Attention_GPU24\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu25 [label="Attention_GPU25\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu24 [label="Attn_Out_Proj_GPU24\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu25 [label="Attn_Out_Proj_GPU25\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group12 [label="AllReduce_Attn_Group12\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu26 [label="QKV_Proj_GPU26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu27 [label="QKV_Proj_GPU27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu26 [label="Attention_GPU26\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu27 [label="Attention_GPU27\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu26 [label="Attn_Out_Proj_GPU26\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu27 [label="Attn_Out_Proj_GPU27\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group13 [label="AllReduce_Attn_Group13\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu28 [label="QKV_Proj_GPU28\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu29 [label="QKV_Proj_GPU29\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu28 [label="Attention_GPU28\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu29 [label="Attention_GPU29\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu28 [label="Attn_Out_Proj_GPU28\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu29 [label="Attn_Out_Proj_GPU29\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group14 [label="AllReduce_Attn_Group14\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu30 [label="QKV_Proj_GPU30\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu31 [label="QKV_Proj_GPU31\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu30 [label="Attention_GPU30\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu31 [label="Attention_GPU31\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu30 [label="Attn_Out_Proj_GPU30\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu31 [label="Attn_Out_Proj_GPU31\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group15 [label="AllReduce_Attn_Group15\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu32 [label="QKV_Proj_GPU32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu33 [label="QKV_Proj_GPU33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu32 [label="Attention_GPU32\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu33 [label="Attention_GPU33\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu32 [label="Attn_Out_Proj_GPU32\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu33 [label="Attn_Out_Proj_GPU33\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group16 [label="AllReduce_Attn_Group16\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu34 [label="QKV_Proj_GPU34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu35 [label="QKV_Proj_GPU35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu34 [label="Attention_GPU34\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu35 [label="Attention_GPU35\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu34 [label="Attn_Out_Proj_GPU34\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu35 [label="Attn_Out_Proj_GPU35\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group17 [label="AllReduce_Attn_Group17\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu36 [label="QKV_Proj_GPU36\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu37 [label="QKV_Proj_GPU37\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu36 [label="Attention_GPU36\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu37 [label="Attention_GPU37\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu36 [label="Attn_Out_Proj_GPU36\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu37 [label="Attn_Out_Proj_GPU37\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group18 [label="AllReduce_Attn_Group18\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu38 [label="QKV_Proj_GPU38\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu39 [label="QKV_Proj_GPU39\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu38 [label="Attention_GPU38\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu39 [label="Attention_GPU39\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu38 [label="Attn_Out_Proj_GPU38\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu39 [label="Attn_Out_Proj_GPU39\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group19 [label="AllReduce_Attn_Group19\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu40 [label="QKV_Proj_GPU40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu41 [label="QKV_Proj_GPU41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu40 [label="Attention_GPU40\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu41 [label="Attention_GPU41\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu40 [label="Attn_Out_Proj_GPU40\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu41 [label="Attn_Out_Proj_GPU41\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group20 [label="AllReduce_Attn_Group20\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu42 [label="QKV_Proj_GPU42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu43 [label="QKV_Proj_GPU43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu42 [label="Attention_GPU42\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu43 [label="Attention_GPU43\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu42 [label="Attn_Out_Proj_GPU42\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu43 [label="Attn_Out_Proj_GPU43\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group21 [label="AllReduce_Attn_Group21\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu44 [label="QKV_Proj_GPU44\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu45 [label="QKV_Proj_GPU45\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu44 [label="Attention_GPU44\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu45 [label="Attention_GPU45\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu44 [label="Attn_Out_Proj_GPU44\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu45 [label="Attn_Out_Proj_GPU45\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group22 [label="AllReduce_Attn_Group22\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu46 [label="QKV_Proj_GPU46\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu47 [label="QKV_Proj_GPU47\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu46 [label="Attention_GPU46\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu47 [label="Attention_GPU47\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu46 [label="Attn_Out_Proj_GPU46\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu47 [label="Attn_Out_Proj_GPU47\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group23 [label="AllReduce_Attn_Group23\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu48 [label="QKV_Proj_GPU48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu49 [label="QKV_Proj_GPU49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu48 [label="Attention_GPU48\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu49 [label="Attention_GPU49\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu48 [label="Attn_Out_Proj_GPU48\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu49 [label="Attn_Out_Proj_GPU49\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group24 [label="AllReduce_Attn_Group24\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu50 [label="QKV_Proj_GPU50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu51 [label="QKV_Proj_GPU51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu50 [label="Attention_GPU50\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu51 [label="Attention_GPU51\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu50 [label="Attn_Out_Proj_GPU50\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu51 [label="Attn_Out_Proj_GPU51\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group25 [label="AllReduce_Attn_Group25\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu52 [label="QKV_Proj_GPU52\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu53 [label="QKV_Proj_GPU53\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu52 [label="Attention_GPU52\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu53 [label="Attention_GPU53\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu52 [label="Attn_Out_Proj_GPU52\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu53 [label="Attn_Out_Proj_GPU53\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group26 [label="AllReduce_Attn_Group26\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu54 [label="QKV_Proj_GPU54\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu55 [label="QKV_Proj_GPU55\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu54 [label="Attention_GPU54\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu55 [label="Attention_GPU55\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu54 [label="Attn_Out_Proj_GPU54\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu55 [label="Attn_Out_Proj_GPU55\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group27 [label="AllReduce_Attn_Group27\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu56 [label="QKV_Proj_GPU56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu57 [label="QKV_Proj_GPU57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu56 [label="Attention_GPU56\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu57 [label="Attention_GPU57\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu56 [label="Attn_Out_Proj_GPU56\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu57 [label="Attn_Out_Proj_GPU57\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group28 [label="AllReduce_Attn_Group28\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu58 [label="QKV_Proj_GPU58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu59 [label="QKV_Proj_GPU59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu58 [label="Attention_GPU58\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu59 [label="Attention_GPU59\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu58 [label="Attn_Out_Proj_GPU58\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu59 [label="Attn_Out_Proj_GPU59\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group29 [label="AllReduce_Attn_Group29\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu60 [label="QKV_Proj_GPU60\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu61 [label="QKV_Proj_GPU61\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu60 [label="Attention_GPU60\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu61 [label="Attention_GPU61\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu60 [label="Attn_Out_Proj_GPU60\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu61 [label="Attn_Out_Proj_GPU61\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group30 [label="AllReduce_Attn_Group30\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu62 [label="QKV_Proj_GPU62\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu63 [label="QKV_Proj_GPU63\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu62 [label="Attention_GPU62\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu63 [label="Attention_GPU63\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu62 [label="Attn_Out_Proj_GPU62\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu63 [label="Attn_Out_Proj_GPU63\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group31 [label="AllReduce_Attn_Group31\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu64 [label="QKV_Proj_GPU64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu65 [label="QKV_Proj_GPU65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu64 [label="Attention_GPU64\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu65 [label="Attention_GPU65\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu64 [label="Attn_Out_Proj_GPU64\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu65 [label="Attn_Out_Proj_GPU65\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group32 [label="AllReduce_Attn_Group32\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu66 [label="QKV_Proj_GPU66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu67 [label="QKV_Proj_GPU67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu66 [label="Attention_GPU66\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu67 [label="Attention_GPU67\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu66 [label="Attn_Out_Proj_GPU66\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu67 [label="Attn_Out_Proj_GPU67\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group33 [label="AllReduce_Attn_Group33\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu68 [label="QKV_Proj_GPU68\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu69 [label="QKV_Proj_GPU69\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu68 [label="Attention_GPU68\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu69 [label="Attention_GPU69\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu68 [label="Attn_Out_Proj_GPU68\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu69 [label="Attn_Out_Proj_GPU69\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group34 [label="AllReduce_Attn_Group34\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu70 [label="QKV_Proj_GPU70\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu71 [label="QKV_Proj_GPU71\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu70 [label="Attention_GPU70\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu71 [label="Attention_GPU71\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu70 [label="Attn_Out_Proj_GPU70\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu71 [label="Attn_Out_Proj_GPU71\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group35 [label="AllReduce_Attn_Group35\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu72 [label="QKV_Proj_GPU72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu73 [label="QKV_Proj_GPU73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu72 [label="Attention_GPU72\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu73 [label="Attention_GPU73\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu72 [label="Attn_Out_Proj_GPU72\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu73 [label="Attn_Out_Proj_GPU73\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group36 [label="AllReduce_Attn_Group36\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu74 [label="QKV_Proj_GPU74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu75 [label="QKV_Proj_GPU75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu74 [label="Attention_GPU74\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu75 [label="Attention_GPU75\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu74 [label="Attn_Out_Proj_GPU74\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu75 [label="Attn_Out_Proj_GPU75\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group37 [label="AllReduce_Attn_Group37\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu76 [label="QKV_Proj_GPU76\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu77 [label="QKV_Proj_GPU77\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu76 [label="Attention_GPU76\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu77 [label="Attention_GPU77\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu76 [label="Attn_Out_Proj_GPU76\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu77 [label="Attn_Out_Proj_GPU77\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group38 [label="AllReduce_Attn_Group38\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu78 [label="QKV_Proj_GPU78\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu79 [label="QKV_Proj_GPU79\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu78 [label="Attention_GPU78\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu79 [label="Attention_GPU79\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu78 [label="Attn_Out_Proj_GPU78\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu79 [label="Attn_Out_Proj_GPU79\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group39 [label="AllReduce_Attn_Group39\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu80 [label="QKV_Proj_GPU80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu81 [label="QKV_Proj_GPU81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu80 [label="Attention_GPU80\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu81 [label="Attention_GPU81\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu80 [label="Attn_Out_Proj_GPU80\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu81 [label="Attn_Out_Proj_GPU81\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group40 [label="AllReduce_Attn_Group40\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu82 [label="QKV_Proj_GPU82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu83 [label="QKV_Proj_GPU83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu82 [label="Attention_GPU82\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu83 [label="Attention_GPU83\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu82 [label="Attn_Out_Proj_GPU82\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu83 [label="Attn_Out_Proj_GPU83\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group41 [label="AllReduce_Attn_Group41\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu84 [label="QKV_Proj_GPU84\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu85 [label="QKV_Proj_GPU85\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu84 [label="Attention_GPU84\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu85 [label="Attention_GPU85\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu84 [label="Attn_Out_Proj_GPU84\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu85 [label="Attn_Out_Proj_GPU85\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group42 [label="AllReduce_Attn_Group42\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu86 [label="QKV_Proj_GPU86\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu87 [label="QKV_Proj_GPU87\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu86 [label="Attention_GPU86\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu87 [label="Attention_GPU87\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu86 [label="Attn_Out_Proj_GPU86\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu87 [label="Attn_Out_Proj_GPU87\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group43 [label="AllReduce_Attn_Group43\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu88 [label="QKV_Proj_GPU88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu89 [label="QKV_Proj_GPU89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu88 [label="Attention_GPU88\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu89 [label="Attention_GPU89\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu88 [label="Attn_Out_Proj_GPU88\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu89 [label="Attn_Out_Proj_GPU89\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group44 [label="AllReduce_Attn_Group44\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu90 [label="QKV_Proj_GPU90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu91 [label="QKV_Proj_GPU91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu90 [label="Attention_GPU90\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu91 [label="Attention_GPU91\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu90 [label="Attn_Out_Proj_GPU90\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu91 [label="Attn_Out_Proj_GPU91\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group45 [label="AllReduce_Attn_Group45\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu92 [label="QKV_Proj_GPU92\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu93 [label="QKV_Proj_GPU93\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu92 [label="Attention_GPU92\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu93 [label="Attention_GPU93\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu92 [label="Attn_Out_Proj_GPU92\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu93 [label="Attn_Out_Proj_GPU93\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group46 [label="AllReduce_Attn_Group46\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu94 [label="QKV_Proj_GPU94\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu95 [label="QKV_Proj_GPU95\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu94 [label="Attention_GPU94\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu95 [label="Attention_GPU95\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu94 [label="Attn_Out_Proj_GPU94\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu95 [label="Attn_Out_Proj_GPU95\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group47 [label="AllReduce_Attn_Group47\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu96 [label="QKV_Proj_GPU96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu97 [label="QKV_Proj_GPU97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu96 [label="Attention_GPU96\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu97 [label="Attention_GPU97\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu96 [label="Attn_Out_Proj_GPU96\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu97 [label="Attn_Out_Proj_GPU97\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group48 [label="AllReduce_Attn_Group48\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu98 [label="QKV_Proj_GPU98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu99 [label="QKV_Proj_GPU99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu98 [label="Attention_GPU98\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu99 [label="Attention_GPU99\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu98 [label="Attn_Out_Proj_GPU98\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu99 [label="Attn_Out_Proj_GPU99\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group49 [label="AllReduce_Attn_Group49\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu100 [label="QKV_Proj_GPU100\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu101 [label="QKV_Proj_GPU101\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu100 [label="Attention_GPU100\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu101 [label="Attention_GPU101\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu100 [label="Attn_Out_Proj_GPU100\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu101 [label="Attn_Out_Proj_GPU101\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group50 [label="AllReduce_Attn_Group50\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu102 [label="QKV_Proj_GPU102\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu103 [label="QKV_Proj_GPU103\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu102 [label="Attention_GPU102\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu103 [label="Attention_GPU103\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu102 [label="Attn_Out_Proj_GPU102\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu103 [label="Attn_Out_Proj_GPU103\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group51 [label="AllReduce_Attn_Group51\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu104 [label="QKV_Proj_GPU104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu105 [label="QKV_Proj_GPU105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu104 [label="Attention_GPU104\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu105 [label="Attention_GPU105\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu104 [label="Attn_Out_Proj_GPU104\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu105 [label="Attn_Out_Proj_GPU105\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group52 [label="AllReduce_Attn_Group52\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu106 [label="QKV_Proj_GPU106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu107 [label="QKV_Proj_GPU107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu106 [label="Attention_GPU106\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu107 [label="Attention_GPU107\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu106 [label="Attn_Out_Proj_GPU106\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu107 [label="Attn_Out_Proj_GPU107\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group53 [label="AllReduce_Attn_Group53\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu108 [label="QKV_Proj_GPU108\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu109 [label="QKV_Proj_GPU109\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu108 [label="Attention_GPU108\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu109 [label="Attention_GPU109\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu108 [label="Attn_Out_Proj_GPU108\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu109 [label="Attn_Out_Proj_GPU109\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group54 [label="AllReduce_Attn_Group54\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu110 [label="QKV_Proj_GPU110\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu111 [label="QKV_Proj_GPU111\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu110 [label="Attention_GPU110\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu111 [label="Attention_GPU111\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu110 [label="Attn_Out_Proj_GPU110\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu111 [label="Attn_Out_Proj_GPU111\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group55 [label="AllReduce_Attn_Group55\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu112 [label="QKV_Proj_GPU112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu113 [label="QKV_Proj_GPU113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu112 [label="Attention_GPU112\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu113 [label="Attention_GPU113\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu112 [label="Attn_Out_Proj_GPU112\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu113 [label="Attn_Out_Proj_GPU113\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group56 [label="AllReduce_Attn_Group56\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu114 [label="QKV_Proj_GPU114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu115 [label="QKV_Proj_GPU115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu114 [label="Attention_GPU114\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu115 [label="Attention_GPU115\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu114 [label="Attn_Out_Proj_GPU114\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu115 [label="Attn_Out_Proj_GPU115\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group57 [label="AllReduce_Attn_Group57\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu116 [label="QKV_Proj_GPU116\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu117 [label="QKV_Proj_GPU117\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu116 [label="Attention_GPU116\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu117 [label="Attention_GPU117\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu116 [label="Attn_Out_Proj_GPU116\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu117 [label="Attn_Out_Proj_GPU117\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group58 [label="AllReduce_Attn_Group58\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu118 [label="QKV_Proj_GPU118\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu119 [label="QKV_Proj_GPU119\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu118 [label="Attention_GPU118\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu119 [label="Attention_GPU119\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu118 [label="Attn_Out_Proj_GPU118\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu119 [label="Attn_Out_Proj_GPU119\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group59 [label="AllReduce_Attn_Group59\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu120 [label="QKV_Proj_GPU120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu121 [label="QKV_Proj_GPU121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu120 [label="Attention_GPU120\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu121 [label="Attention_GPU121\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu120 [label="Attn_Out_Proj_GPU120\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu121 [label="Attn_Out_Proj_GPU121\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group60 [label="AllReduce_Attn_Group60\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu122 [label="QKV_Proj_GPU122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu123 [label="QKV_Proj_GPU123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu122 [label="Attention_GPU122\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu123 [label="Attention_GPU123\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu122 [label="Attn_Out_Proj_GPU122\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu123 [label="Attn_Out_Proj_GPU123\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group61 [label="AllReduce_Attn_Group61\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu124 [label="QKV_Proj_GPU124\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu125 [label="QKV_Proj_GPU125\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu124 [label="Attention_GPU124\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu125 [label="Attention_GPU125\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu124 [label="Attn_Out_Proj_GPU124\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu125 [label="Attn_Out_Proj_GPU125\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group62 [label="AllReduce_Attn_Group62\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_qkv_gpu126 [label="QKV_Proj_GPU126\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_qkv_gpu127 [label="QKV_Proj_GPU127\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu126 [label="Attention_GPU126\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_gpu127 [label="Attention_GPU127\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, heads=8, d_k=64]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu126 [label="Attn_Out_Proj_GPU126\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_out_gpu127 [label="Attn_Out_Proj_GPU127\nInput: [batch_size=128, seq_len=1024, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_attn_allreduce_group63 [label="AllReduce_Attn_Group63\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_residual1_gpu0 [label="Residual_Add1_GPU0\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu1 [label="Residual_Add1_GPU1\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu2 [label="Residual_Add1_GPU2\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu3 [label="Residual_Add1_GPU3\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu4 [label="Residual_Add1_GPU4\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu5 [label="Residual_Add1_GPU5\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu6 [label="Residual_Add1_GPU6\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu7 [label="Residual_Add1_GPU7\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu8 [label="Residual_Add1_GPU8\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu9 [label="Residual_Add1_GPU9\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu10 [label="Residual_Add1_GPU10\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu11 [label="Residual_Add1_GPU11\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu12 [label="Residual_Add1_GPU12\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu13 [label="Residual_Add1_GPU13\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu14 [label="Residual_Add1_GPU14\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu15 [label="Residual_Add1_GPU15\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu16 [label="Residual_Add1_GPU16\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu17 [label="Residual_Add1_GPU17\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu18 [label="Residual_Add1_GPU18\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu19 [label="Residual_Add1_GPU19\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu20 [label="Residual_Add1_GPU20\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu21 [label="Residual_Add1_GPU21\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu22 [label="Residual_Add1_GPU22\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu23 [label="Residual_Add1_GPU23\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu24 [label="Residual_Add1_GPU24\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu25 [label="Residual_Add1_GPU25\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu26 [label="Residual_Add1_GPU26\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu27 [label="Residual_Add1_GPU27\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu28 [label="Residual_Add1_GPU28\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu29 [label="Residual_Add1_GPU29\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu30 [label="Residual_Add1_GPU30\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu31 [label="Residual_Add1_GPU31\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu32 [label="Residual_Add1_GPU32\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu33 [label="Residual_Add1_GPU33\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu34 [label="Residual_Add1_GPU34\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu35 [label="Residual_Add1_GPU35\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu36 [label="Residual_Add1_GPU36\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu37 [label="Residual_Add1_GPU37\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu38 [label="Residual_Add1_GPU38\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu39 [label="Residual_Add1_GPU39\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu40 [label="Residual_Add1_GPU40\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu41 [label="Residual_Add1_GPU41\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu42 [label="Residual_Add1_GPU42\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu43 [label="Residual_Add1_GPU43\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu44 [label="Residual_Add1_GPU44\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu45 [label="Residual_Add1_GPU45\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu46 [label="Residual_Add1_GPU46\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu47 [label="Residual_Add1_GPU47\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu48 [label="Residual_Add1_GPU48\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu49 [label="Residual_Add1_GPU49\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu50 [label="Residual_Add1_GPU50\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu51 [label="Residual_Add1_GPU51\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu52 [label="Residual_Add1_GPU52\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu53 [label="Residual_Add1_GPU53\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu54 [label="Residual_Add1_GPU54\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu55 [label="Residual_Add1_GPU55\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu56 [label="Residual_Add1_GPU56\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu57 [label="Residual_Add1_GPU57\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu58 [label="Residual_Add1_GPU58\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu59 [label="Residual_Add1_GPU59\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu60 [label="Residual_Add1_GPU60\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu61 [label="Residual_Add1_GPU61\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu62 [label="Residual_Add1_GPU62\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu63 [label="Residual_Add1_GPU63\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu64 [label="Residual_Add1_GPU64\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu65 [label="Residual_Add1_GPU65\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu66 [label="Residual_Add1_GPU66\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu67 [label="Residual_Add1_GPU67\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu68 [label="Residual_Add1_GPU68\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu69 [label="Residual_Add1_GPU69\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu70 [label="Residual_Add1_GPU70\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu71 [label="Residual_Add1_GPU71\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu72 [label="Residual_Add1_GPU72\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu73 [label="Residual_Add1_GPU73\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu74 [label="Residual_Add1_GPU74\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu75 [label="Residual_Add1_GPU75\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu76 [label="Residual_Add1_GPU76\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu77 [label="Residual_Add1_GPU77\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu78 [label="Residual_Add1_GPU78\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu79 [label="Residual_Add1_GPU79\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu80 [label="Residual_Add1_GPU80\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu81 [label="Residual_Add1_GPU81\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu82 [label="Residual_Add1_GPU82\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu83 [label="Residual_Add1_GPU83\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu84 [label="Residual_Add1_GPU84\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu85 [label="Residual_Add1_GPU85\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu86 [label="Residual_Add1_GPU86\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu87 [label="Residual_Add1_GPU87\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu88 [label="Residual_Add1_GPU88\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu89 [label="Residual_Add1_GPU89\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu90 [label="Residual_Add1_GPU90\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu91 [label="Residual_Add1_GPU91\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu92 [label="Residual_Add1_GPU92\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu93 [label="Residual_Add1_GPU93\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu94 [label="Residual_Add1_GPU94\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu95 [label="Residual_Add1_GPU95\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu96 [label="Residual_Add1_GPU96\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu97 [label="Residual_Add1_GPU97\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu98 [label="Residual_Add1_GPU98\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu99 [label="Residual_Add1_GPU99\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu100 [label="Residual_Add1_GPU100\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu101 [label="Residual_Add1_GPU101\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu102 [label="Residual_Add1_GPU102\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu103 [label="Residual_Add1_GPU103\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu104 [label="Residual_Add1_GPU104\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu105 [label="Residual_Add1_GPU105\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu106 [label="Residual_Add1_GPU106\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu107 [label="Residual_Add1_GPU107\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu108 [label="Residual_Add1_GPU108\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu109 [label="Residual_Add1_GPU109\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu110 [label="Residual_Add1_GPU110\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu111 [label="Residual_Add1_GPU111\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu112 [label="Residual_Add1_GPU112\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu113 [label="Residual_Add1_GPU113\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu114 [label="Residual_Add1_GPU114\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu115 [label="Residual_Add1_GPU115\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu116 [label="Residual_Add1_GPU116\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu117 [label="Residual_Add1_GPU117\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu118 [label="Residual_Add1_GPU118\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu119 [label="Residual_Add1_GPU119\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu120 [label="Residual_Add1_GPU120\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu121 [label="Residual_Add1_GPU121\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu122 [label="Residual_Add1_GPU122\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu123 [label="Residual_Add1_GPU123\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu124 [label="Residual_Add1_GPU124\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu125 [label="Residual_Add1_GPU125\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu126 [label="Residual_Add1_GPU126\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual1_gpu127 [label="Residual_Add1_GPU127\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_ln2_gpu0 [label="LayerNorm2_GPU0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu1 [label="LayerNorm2_GPU1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu2 [label="LayerNorm2_GPU2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu3 [label="LayerNorm2_GPU3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu4 [label="LayerNorm2_GPU4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu5 [label="LayerNorm2_GPU5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu6 [label="LayerNorm2_GPU6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu7 [label="LayerNorm2_GPU7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu8 [label="LayerNorm2_GPU8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu9 [label="LayerNorm2_GPU9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu10 [label="LayerNorm2_GPU10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu11 [label="LayerNorm2_GPU11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu12 [label="LayerNorm2_GPU12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu13 [label="LayerNorm2_GPU13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu14 [label="LayerNorm2_GPU14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu15 [label="LayerNorm2_GPU15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu16 [label="LayerNorm2_GPU16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu17 [label="LayerNorm2_GPU17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu18 [label="LayerNorm2_GPU18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu19 [label="LayerNorm2_GPU19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu20 [label="LayerNorm2_GPU20\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu21 [label="LayerNorm2_GPU21\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu22 [label="LayerNorm2_GPU22\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu23 [label="LayerNorm2_GPU23\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu24 [label="LayerNorm2_GPU24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu25 [label="LayerNorm2_GPU25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu26 [label="LayerNorm2_GPU26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu27 [label="LayerNorm2_GPU27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu28 [label="LayerNorm2_GPU28\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu29 [label="LayerNorm2_GPU29\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu30 [label="LayerNorm2_GPU30\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu31 [label="LayerNorm2_GPU31\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu32 [label="LayerNorm2_GPU32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu33 [label="LayerNorm2_GPU33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu34 [label="LayerNorm2_GPU34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu35 [label="LayerNorm2_GPU35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu36 [label="LayerNorm2_GPU36\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu37 [label="LayerNorm2_GPU37\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu38 [label="LayerNorm2_GPU38\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu39 [label="LayerNorm2_GPU39\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu40 [label="LayerNorm2_GPU40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu41 [label="LayerNorm2_GPU41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu42 [label="LayerNorm2_GPU42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu43 [label="LayerNorm2_GPU43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu44 [label="LayerNorm2_GPU44\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu45 [label="LayerNorm2_GPU45\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu46 [label="LayerNorm2_GPU46\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu47 [label="LayerNorm2_GPU47\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu48 [label="LayerNorm2_GPU48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu49 [label="LayerNorm2_GPU49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu50 [label="LayerNorm2_GPU50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu51 [label="LayerNorm2_GPU51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu52 [label="LayerNorm2_GPU52\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu53 [label="LayerNorm2_GPU53\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu54 [label="LayerNorm2_GPU54\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu55 [label="LayerNorm2_GPU55\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu56 [label="LayerNorm2_GPU56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu57 [label="LayerNorm2_GPU57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu58 [label="LayerNorm2_GPU58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu59 [label="LayerNorm2_GPU59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu60 [label="LayerNorm2_GPU60\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu61 [label="LayerNorm2_GPU61\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu62 [label="LayerNorm2_GPU62\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu63 [label="LayerNorm2_GPU63\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu64 [label="LayerNorm2_GPU64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu65 [label="LayerNorm2_GPU65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu66 [label="LayerNorm2_GPU66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu67 [label="LayerNorm2_GPU67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu68 [label="LayerNorm2_GPU68\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu69 [label="LayerNorm2_GPU69\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu70 [label="LayerNorm2_GPU70\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu71 [label="LayerNorm2_GPU71\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu72 [label="LayerNorm2_GPU72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu73 [label="LayerNorm2_GPU73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu74 [label="LayerNorm2_GPU74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu75 [label="LayerNorm2_GPU75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu76 [label="LayerNorm2_GPU76\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu77 [label="LayerNorm2_GPU77\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu78 [label="LayerNorm2_GPU78\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu79 [label="LayerNorm2_GPU79\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu80 [label="LayerNorm2_GPU80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu81 [label="LayerNorm2_GPU81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu82 [label="LayerNorm2_GPU82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu83 [label="LayerNorm2_GPU83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu84 [label="LayerNorm2_GPU84\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu85 [label="LayerNorm2_GPU85\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu86 [label="LayerNorm2_GPU86\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu87 [label="LayerNorm2_GPU87\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu88 [label="LayerNorm2_GPU88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu89 [label="LayerNorm2_GPU89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu90 [label="LayerNorm2_GPU90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu91 [label="LayerNorm2_GPU91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu92 [label="LayerNorm2_GPU92\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu93 [label="LayerNorm2_GPU93\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu94 [label="LayerNorm2_GPU94\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu95 [label="LayerNorm2_GPU95\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu96 [label="LayerNorm2_GPU96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu97 [label="LayerNorm2_GPU97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu98 [label="LayerNorm2_GPU98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu99 [label="LayerNorm2_GPU99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu100 [label="LayerNorm2_GPU100\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu101 [label="LayerNorm2_GPU101\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu102 [label="LayerNorm2_GPU102\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu103 [label="LayerNorm2_GPU103\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu104 [label="LayerNorm2_GPU104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu105 [label="LayerNorm2_GPU105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu106 [label="LayerNorm2_GPU106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu107 [label="LayerNorm2_GPU107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu108 [label="LayerNorm2_GPU108\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu109 [label="LayerNorm2_GPU109\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu110 [label="LayerNorm2_GPU110\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu111 [label="LayerNorm2_GPU111\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu112 [label="LayerNorm2_GPU112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu113 [label="LayerNorm2_GPU113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu114 [label="LayerNorm2_GPU114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu115 [label="LayerNorm2_GPU115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu116 [label="LayerNorm2_GPU116\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu117 [label="LayerNorm2_GPU117\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu118 [label="LayerNorm2_GPU118\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu119 [label="LayerNorm2_GPU119\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu120 [label="LayerNorm2_GPU120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu121 [label="LayerNorm2_GPU121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu122 [label="LayerNorm2_GPU122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu123 [label="LayerNorm2_GPU123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu124 [label="LayerNorm2_GPU124\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu125 [label="LayerNorm2_GPU125\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu126 [label="LayerNorm2_GPU126\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_ln2_gpu127 [label="LayerNorm2_GPU127\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_gate_gpu0 [label="Gate_Network_GPU0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu1 [label="Gate_Network_GPU1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu2 [label="Gate_Network_GPU2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu3 [label="Gate_Network_GPU3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu4 [label="Gate_Network_GPU4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu5 [label="Gate_Network_GPU5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu6 [label="Gate_Network_GPU6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu7 [label="Gate_Network_GPU7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu8 [label="Gate_Network_GPU8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu9 [label="Gate_Network_GPU9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu10 [label="Gate_Network_GPU10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu11 [label="Gate_Network_GPU11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu12 [label="Gate_Network_GPU12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu13 [label="Gate_Network_GPU13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu14 [label="Gate_Network_GPU14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu15 [label="Gate_Network_GPU15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu16 [label="Gate_Network_GPU16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu17 [label="Gate_Network_GPU17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu18 [label="Gate_Network_GPU18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu19 [label="Gate_Network_GPU19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu20 [label="Gate_Network_GPU20\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu21 [label="Gate_Network_GPU21\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu22 [label="Gate_Network_GPU22\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu23 [label="Gate_Network_GPU23\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu24 [label="Gate_Network_GPU24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu25 [label="Gate_Network_GPU25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu26 [label="Gate_Network_GPU26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu27 [label="Gate_Network_GPU27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu28 [label="Gate_Network_GPU28\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu29 [label="Gate_Network_GPU29\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu30 [label="Gate_Network_GPU30\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu31 [label="Gate_Network_GPU31\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu32 [label="Gate_Network_GPU32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu33 [label="Gate_Network_GPU33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu34 [label="Gate_Network_GPU34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu35 [label="Gate_Network_GPU35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu36 [label="Gate_Network_GPU36\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu37 [label="Gate_Network_GPU37\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu38 [label="Gate_Network_GPU38\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu39 [label="Gate_Network_GPU39\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu40 [label="Gate_Network_GPU40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu41 [label="Gate_Network_GPU41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu42 [label="Gate_Network_GPU42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu43 [label="Gate_Network_GPU43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu44 [label="Gate_Network_GPU44\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu45 [label="Gate_Network_GPU45\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu46 [label="Gate_Network_GPU46\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu47 [label="Gate_Network_GPU47\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu48 [label="Gate_Network_GPU48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu49 [label="Gate_Network_GPU49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu50 [label="Gate_Network_GPU50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu51 [label="Gate_Network_GPU51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu52 [label="Gate_Network_GPU52\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu53 [label="Gate_Network_GPU53\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu54 [label="Gate_Network_GPU54\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu55 [label="Gate_Network_GPU55\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu56 [label="Gate_Network_GPU56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu57 [label="Gate_Network_GPU57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu58 [label="Gate_Network_GPU58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu59 [label="Gate_Network_GPU59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu60 [label="Gate_Network_GPU60\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu61 [label="Gate_Network_GPU61\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu62 [label="Gate_Network_GPU62\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu63 [label="Gate_Network_GPU63\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu64 [label="Gate_Network_GPU64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu65 [label="Gate_Network_GPU65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu66 [label="Gate_Network_GPU66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu67 [label="Gate_Network_GPU67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu68 [label="Gate_Network_GPU68\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu69 [label="Gate_Network_GPU69\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu70 [label="Gate_Network_GPU70\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu71 [label="Gate_Network_GPU71\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu72 [label="Gate_Network_GPU72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu73 [label="Gate_Network_GPU73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu74 [label="Gate_Network_GPU74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu75 [label="Gate_Network_GPU75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu76 [label="Gate_Network_GPU76\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu77 [label="Gate_Network_GPU77\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu78 [label="Gate_Network_GPU78\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu79 [label="Gate_Network_GPU79\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu80 [label="Gate_Network_GPU80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu81 [label="Gate_Network_GPU81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu82 [label="Gate_Network_GPU82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu83 [label="Gate_Network_GPU83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu84 [label="Gate_Network_GPU84\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu85 [label="Gate_Network_GPU85\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu86 [label="Gate_Network_GPU86\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu87 [label="Gate_Network_GPU87\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu88 [label="Gate_Network_GPU88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu89 [label="Gate_Network_GPU89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu90 [label="Gate_Network_GPU90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu91 [label="Gate_Network_GPU91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu92 [label="Gate_Network_GPU92\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu93 [label="Gate_Network_GPU93\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu94 [label="Gate_Network_GPU94\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu95 [label="Gate_Network_GPU95\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu96 [label="Gate_Network_GPU96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu97 [label="Gate_Network_GPU97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu98 [label="Gate_Network_GPU98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu99 [label="Gate_Network_GPU99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu100 [label="Gate_Network_GPU100\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu101 [label="Gate_Network_GPU101\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu102 [label="Gate_Network_GPU102\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu103 [label="Gate_Network_GPU103\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu104 [label="Gate_Network_GPU104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu105 [label="Gate_Network_GPU105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu106 [label="Gate_Network_GPU106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu107 [label="Gate_Network_GPU107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu108 [label="Gate_Network_GPU108\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu109 [label="Gate_Network_GPU109\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu110 [label="Gate_Network_GPU110\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu111 [label="Gate_Network_GPU111\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu112 [label="Gate_Network_GPU112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu113 [label="Gate_Network_GPU113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu114 [label="Gate_Network_GPU114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu115 [label="Gate_Network_GPU115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu116 [label="Gate_Network_GPU116\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu117 [label="Gate_Network_GPU117\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu118 [label="Gate_Network_GPU118\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu119 [label="Gate_Network_GPU119\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu120 [label="Gate_Network_GPU120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu121 [label="Gate_Network_GPU121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu122 [label="Gate_Network_GPU122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu123 [label="Gate_Network_GPU123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu124 [label="Gate_Network_GPU124\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu125 [label="Gate_Network_GPU125\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu126 [label="Gate_Network_GPU126\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_gate_gpu127 [label="Gate_Network_GPU127\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=64]" fillcolor=lightgreen shape=rectangle style="filled,dashed"]
	layer_0_router_group0 [label="Router_Group0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group1 [label="Router_Group1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group2 [label="Router_Group2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group3 [label="Router_Group3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group4 [label="Router_Group4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group5 [label="Router_Group5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group6 [label="Router_Group6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group7 [label="Router_Group7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group8 [label="Router_Group8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group9 [label="Router_Group9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group10 [label="Router_Group10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group11 [label="Router_Group11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group12 [label="Router_Group12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group13 [label="Router_Group13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group14 [label="Router_Group14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group15 [label="Router_Group15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group16 [label="Router_Group16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group17 [label="Router_Group17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group18 [label="Router_Group18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group19 [label="Router_Group19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group20 [label="Router_Group20\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group21 [label="Router_Group21\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group22 [label="Router_Group22\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group23 [label="Router_Group23\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group24 [label="Router_Group24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group25 [label="Router_Group25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group26 [label="Router_Group26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group27 [label="Router_Group27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group28 [label="Router_Group28\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group29 [label="Router_Group29\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group30 [label="Router_Group30\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group31 [label="Router_Group31\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group32 [label="Router_Group32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group33 [label="Router_Group33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group34 [label="Router_Group34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group35 [label="Router_Group35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group36 [label="Router_Group36\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group37 [label="Router_Group37\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group38 [label="Router_Group38\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group39 [label="Router_Group39\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group40 [label="Router_Group40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group41 [label="Router_Group41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group42 [label="Router_Group42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group43 [label="Router_Group43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group44 [label="Router_Group44\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group45 [label="Router_Group45\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group46 [label="Router_Group46\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group47 [label="Router_Group47\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group48 [label="Router_Group48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group49 [label="Router_Group49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group50 [label="Router_Group50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group51 [label="Router_Group51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group52 [label="Router_Group52\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group53 [label="Router_Group53\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group54 [label="Router_Group54\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group55 [label="Router_Group55\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group56 [label="Router_Group56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group57 [label="Router_Group57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group58 [label="Router_Group58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group59 [label="Router_Group59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group60 [label="Router_Group60\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group61 [label="Router_Group61\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group62 [label="Router_Group62\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_router_group63 [label="Router_Group63\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_expert1_gpu0 [label="Expert0_Linear1_GPU0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu0 [label="Expert0_GELU_GPU0\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu0 [label="Expert0_Linear2_GPU0\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu1 [label="Expert1_Linear1_GPU1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu1 [label="Expert1_GELU_GPU1\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu1 [label="Expert1_Linear2_GPU1\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group0 [label="AllReduce_Expert_Group0\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu2 [label="Expert2_Linear1_GPU2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu2 [label="Expert2_GELU_GPU2\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu2 [label="Expert2_Linear2_GPU2\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu3 [label="Expert3_Linear1_GPU3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu3 [label="Expert3_GELU_GPU3\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu3 [label="Expert3_Linear2_GPU3\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group1 [label="AllReduce_Expert_Group1\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu4 [label="Expert4_Linear1_GPU4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu4 [label="Expert4_GELU_GPU4\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu4 [label="Expert4_Linear2_GPU4\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu5 [label="Expert5_Linear1_GPU5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu5 [label="Expert5_GELU_GPU5\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu5 [label="Expert5_Linear2_GPU5\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group2 [label="AllReduce_Expert_Group2\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu6 [label="Expert6_Linear1_GPU6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu6 [label="Expert6_GELU_GPU6\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu6 [label="Expert6_Linear2_GPU6\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu7 [label="Expert7_Linear1_GPU7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu7 [label="Expert7_GELU_GPU7\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu7 [label="Expert7_Linear2_GPU7\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group3 [label="AllReduce_Expert_Group3\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu8 [label="Expert8_Linear1_GPU8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu8 [label="Expert8_GELU_GPU8\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu8 [label="Expert8_Linear2_GPU8\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu9 [label="Expert9_Linear1_GPU9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu9 [label="Expert9_GELU_GPU9\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu9 [label="Expert9_Linear2_GPU9\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group4 [label="AllReduce_Expert_Group4\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu10 [label="Expert10_Linear1_GPU10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu10 [label="Expert10_GELU_GPU10\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu10 [label="Expert10_Linear2_GPU10\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu11 [label="Expert11_Linear1_GPU11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu11 [label="Expert11_GELU_GPU11\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu11 [label="Expert11_Linear2_GPU11\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group5 [label="AllReduce_Expert_Group5\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu12 [label="Expert12_Linear1_GPU12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu12 [label="Expert12_GELU_GPU12\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu12 [label="Expert12_Linear2_GPU12\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu13 [label="Expert13_Linear1_GPU13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu13 [label="Expert13_GELU_GPU13\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu13 [label="Expert13_Linear2_GPU13\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group6 [label="AllReduce_Expert_Group6\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu14 [label="Expert14_Linear1_GPU14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu14 [label="Expert14_GELU_GPU14\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu14 [label="Expert14_Linear2_GPU14\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu15 [label="Expert15_Linear1_GPU15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu15 [label="Expert15_GELU_GPU15\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu15 [label="Expert15_Linear2_GPU15\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group7 [label="AllReduce_Expert_Group7\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu16 [label="Expert16_Linear1_GPU16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu16 [label="Expert16_GELU_GPU16\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu16 [label="Expert16_Linear2_GPU16\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu17 [label="Expert17_Linear1_GPU17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu17 [label="Expert17_GELU_GPU17\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu17 [label="Expert17_Linear2_GPU17\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group8 [label="AllReduce_Expert_Group8\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu18 [label="Expert18_Linear1_GPU18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu18 [label="Expert18_GELU_GPU18\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu18 [label="Expert18_Linear2_GPU18\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu19 [label="Expert19_Linear1_GPU19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu19 [label="Expert19_GELU_GPU19\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu19 [label="Expert19_Linear2_GPU19\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group9 [label="AllReduce_Expert_Group9\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu20 [label="Expert20_Linear1_GPU20\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu20 [label="Expert20_GELU_GPU20\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu20 [label="Expert20_Linear2_GPU20\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu21 [label="Expert21_Linear1_GPU21\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu21 [label="Expert21_GELU_GPU21\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu21 [label="Expert21_Linear2_GPU21\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group10 [label="AllReduce_Expert_Group10\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu22 [label="Expert22_Linear1_GPU22\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu22 [label="Expert22_GELU_GPU22\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu22 [label="Expert22_Linear2_GPU22\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu23 [label="Expert23_Linear1_GPU23\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu23 [label="Expert23_GELU_GPU23\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu23 [label="Expert23_Linear2_GPU23\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group11 [label="AllReduce_Expert_Group11\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu24 [label="Expert24_Linear1_GPU24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu24 [label="Expert24_GELU_GPU24\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu24 [label="Expert24_Linear2_GPU24\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu25 [label="Expert25_Linear1_GPU25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu25 [label="Expert25_GELU_GPU25\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu25 [label="Expert25_Linear2_GPU25\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group12 [label="AllReduce_Expert_Group12\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu26 [label="Expert26_Linear1_GPU26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu26 [label="Expert26_GELU_GPU26\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu26 [label="Expert26_Linear2_GPU26\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu27 [label="Expert27_Linear1_GPU27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu27 [label="Expert27_GELU_GPU27\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu27 [label="Expert27_Linear2_GPU27\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group13 [label="AllReduce_Expert_Group13\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu28 [label="Expert28_Linear1_GPU28\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu28 [label="Expert28_GELU_GPU28\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu28 [label="Expert28_Linear2_GPU28\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu29 [label="Expert29_Linear1_GPU29\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu29 [label="Expert29_GELU_GPU29\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu29 [label="Expert29_Linear2_GPU29\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group14 [label="AllReduce_Expert_Group14\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu30 [label="Expert30_Linear1_GPU30\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu30 [label="Expert30_GELU_GPU30\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu30 [label="Expert30_Linear2_GPU30\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu31 [label="Expert31_Linear1_GPU31\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu31 [label="Expert31_GELU_GPU31\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu31 [label="Expert31_Linear2_GPU31\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group15 [label="AllReduce_Expert_Group15\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu32 [label="Expert32_Linear1_GPU32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu32 [label="Expert32_GELU_GPU32\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu32 [label="Expert32_Linear2_GPU32\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu33 [label="Expert33_Linear1_GPU33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu33 [label="Expert33_GELU_GPU33\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu33 [label="Expert33_Linear2_GPU33\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group16 [label="AllReduce_Expert_Group16\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu34 [label="Expert34_Linear1_GPU34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu34 [label="Expert34_GELU_GPU34\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu34 [label="Expert34_Linear2_GPU34\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu35 [label="Expert35_Linear1_GPU35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu35 [label="Expert35_GELU_GPU35\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu35 [label="Expert35_Linear2_GPU35\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group17 [label="AllReduce_Expert_Group17\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu36 [label="Expert36_Linear1_GPU36\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu36 [label="Expert36_GELU_GPU36\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu36 [label="Expert36_Linear2_GPU36\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu37 [label="Expert37_Linear1_GPU37\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu37 [label="Expert37_GELU_GPU37\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu37 [label="Expert37_Linear2_GPU37\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group18 [label="AllReduce_Expert_Group18\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu38 [label="Expert38_Linear1_GPU38\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu38 [label="Expert38_GELU_GPU38\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu38 [label="Expert38_Linear2_GPU38\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu39 [label="Expert39_Linear1_GPU39\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu39 [label="Expert39_GELU_GPU39\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu39 [label="Expert39_Linear2_GPU39\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group19 [label="AllReduce_Expert_Group19\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu40 [label="Expert40_Linear1_GPU40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu40 [label="Expert40_GELU_GPU40\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu40 [label="Expert40_Linear2_GPU40\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu41 [label="Expert41_Linear1_GPU41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu41 [label="Expert41_GELU_GPU41\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu41 [label="Expert41_Linear2_GPU41\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group20 [label="AllReduce_Expert_Group20\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu42 [label="Expert42_Linear1_GPU42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu42 [label="Expert42_GELU_GPU42\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu42 [label="Expert42_Linear2_GPU42\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu43 [label="Expert43_Linear1_GPU43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu43 [label="Expert43_GELU_GPU43\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu43 [label="Expert43_Linear2_GPU43\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group21 [label="AllReduce_Expert_Group21\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu44 [label="Expert44_Linear1_GPU44\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu44 [label="Expert44_GELU_GPU44\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu44 [label="Expert44_Linear2_GPU44\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu45 [label="Expert45_Linear1_GPU45\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu45 [label="Expert45_GELU_GPU45\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu45 [label="Expert45_Linear2_GPU45\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group22 [label="AllReduce_Expert_Group22\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu46 [label="Expert46_Linear1_GPU46\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu46 [label="Expert46_GELU_GPU46\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu46 [label="Expert46_Linear2_GPU46\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu47 [label="Expert47_Linear1_GPU47\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu47 [label="Expert47_GELU_GPU47\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu47 [label="Expert47_Linear2_GPU47\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group23 [label="AllReduce_Expert_Group23\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu48 [label="Expert48_Linear1_GPU48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu48 [label="Expert48_GELU_GPU48\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu48 [label="Expert48_Linear2_GPU48\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu49 [label="Expert49_Linear1_GPU49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu49 [label="Expert49_GELU_GPU49\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu49 [label="Expert49_Linear2_GPU49\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group24 [label="AllReduce_Expert_Group24\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu50 [label="Expert50_Linear1_GPU50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu50 [label="Expert50_GELU_GPU50\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu50 [label="Expert50_Linear2_GPU50\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu51 [label="Expert51_Linear1_GPU51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu51 [label="Expert51_GELU_GPU51\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu51 [label="Expert51_Linear2_GPU51\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group25 [label="AllReduce_Expert_Group25\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu52 [label="Expert52_Linear1_GPU52\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu52 [label="Expert52_GELU_GPU52\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu52 [label="Expert52_Linear2_GPU52\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu53 [label="Expert53_Linear1_GPU53\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu53 [label="Expert53_GELU_GPU53\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu53 [label="Expert53_Linear2_GPU53\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group26 [label="AllReduce_Expert_Group26\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu54 [label="Expert54_Linear1_GPU54\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu54 [label="Expert54_GELU_GPU54\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu54 [label="Expert54_Linear2_GPU54\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu55 [label="Expert55_Linear1_GPU55\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu55 [label="Expert55_GELU_GPU55\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu55 [label="Expert55_Linear2_GPU55\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group27 [label="AllReduce_Expert_Group27\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu56 [label="Expert56_Linear1_GPU56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu56 [label="Expert56_GELU_GPU56\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu56 [label="Expert56_Linear2_GPU56\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu57 [label="Expert57_Linear1_GPU57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu57 [label="Expert57_GELU_GPU57\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu57 [label="Expert57_Linear2_GPU57\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group28 [label="AllReduce_Expert_Group28\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu58 [label="Expert58_Linear1_GPU58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu58 [label="Expert58_GELU_GPU58\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu58 [label="Expert58_Linear2_GPU58\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu59 [label="Expert59_Linear1_GPU59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu59 [label="Expert59_GELU_GPU59\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu59 [label="Expert59_Linear2_GPU59\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group29 [label="AllReduce_Expert_Group29\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu60 [label="Expert60_Linear1_GPU60\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu60 [label="Expert60_GELU_GPU60\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu60 [label="Expert60_Linear2_GPU60\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu61 [label="Expert61_Linear1_GPU61\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu61 [label="Expert61_GELU_GPU61\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu61 [label="Expert61_Linear2_GPU61\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group30 [label="AllReduce_Expert_Group30\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu62 [label="Expert62_Linear1_GPU62\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu62 [label="Expert62_GELU_GPU62\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu62 [label="Expert62_Linear2_GPU62\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu63 [label="Expert63_Linear1_GPU63\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu63 [label="Expert63_GELU_GPU63\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu63 [label="Expert63_Linear2_GPU63\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group31 [label="AllReduce_Expert_Group31\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu64 [label="Expert64_Linear1_GPU64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu64 [label="Expert64_GELU_GPU64\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu64 [label="Expert64_Linear2_GPU64\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu65 [label="Expert65_Linear1_GPU65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu65 [label="Expert65_GELU_GPU65\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu65 [label="Expert65_Linear2_GPU65\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group32 [label="AllReduce_Expert_Group32\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu66 [label="Expert66_Linear1_GPU66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu66 [label="Expert66_GELU_GPU66\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu66 [label="Expert66_Linear2_GPU66\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu67 [label="Expert67_Linear1_GPU67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu67 [label="Expert67_GELU_GPU67\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu67 [label="Expert67_Linear2_GPU67\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group33 [label="AllReduce_Expert_Group33\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu68 [label="Expert68_Linear1_GPU68\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu68 [label="Expert68_GELU_GPU68\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu68 [label="Expert68_Linear2_GPU68\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu69 [label="Expert69_Linear1_GPU69\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu69 [label="Expert69_GELU_GPU69\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu69 [label="Expert69_Linear2_GPU69\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group34 [label="AllReduce_Expert_Group34\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu70 [label="Expert70_Linear1_GPU70\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu70 [label="Expert70_GELU_GPU70\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu70 [label="Expert70_Linear2_GPU70\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu71 [label="Expert71_Linear1_GPU71\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu71 [label="Expert71_GELU_GPU71\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu71 [label="Expert71_Linear2_GPU71\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group35 [label="AllReduce_Expert_Group35\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu72 [label="Expert72_Linear1_GPU72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu72 [label="Expert72_GELU_GPU72\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu72 [label="Expert72_Linear2_GPU72\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu73 [label="Expert73_Linear1_GPU73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu73 [label="Expert73_GELU_GPU73\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu73 [label="Expert73_Linear2_GPU73\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group36 [label="AllReduce_Expert_Group36\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu74 [label="Expert74_Linear1_GPU74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu74 [label="Expert74_GELU_GPU74\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu74 [label="Expert74_Linear2_GPU74\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu75 [label="Expert75_Linear1_GPU75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu75 [label="Expert75_GELU_GPU75\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu75 [label="Expert75_Linear2_GPU75\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group37 [label="AllReduce_Expert_Group37\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu76 [label="Expert76_Linear1_GPU76\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu76 [label="Expert76_GELU_GPU76\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu76 [label="Expert76_Linear2_GPU76\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu77 [label="Expert77_Linear1_GPU77\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu77 [label="Expert77_GELU_GPU77\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu77 [label="Expert77_Linear2_GPU77\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group38 [label="AllReduce_Expert_Group38\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu78 [label="Expert78_Linear1_GPU78\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu78 [label="Expert78_GELU_GPU78\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu78 [label="Expert78_Linear2_GPU78\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu79 [label="Expert79_Linear1_GPU79\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu79 [label="Expert79_GELU_GPU79\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu79 [label="Expert79_Linear2_GPU79\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group39 [label="AllReduce_Expert_Group39\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu80 [label="Expert80_Linear1_GPU80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu80 [label="Expert80_GELU_GPU80\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu80 [label="Expert80_Linear2_GPU80\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu81 [label="Expert81_Linear1_GPU81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu81 [label="Expert81_GELU_GPU81\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu81 [label="Expert81_Linear2_GPU81\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group40 [label="AllReduce_Expert_Group40\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu82 [label="Expert82_Linear1_GPU82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu82 [label="Expert82_GELU_GPU82\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu82 [label="Expert82_Linear2_GPU82\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu83 [label="Expert83_Linear1_GPU83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu83 [label="Expert83_GELU_GPU83\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu83 [label="Expert83_Linear2_GPU83\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group41 [label="AllReduce_Expert_Group41\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu84 [label="Expert84_Linear1_GPU84\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu84 [label="Expert84_GELU_GPU84\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu84 [label="Expert84_Linear2_GPU84\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu85 [label="Expert85_Linear1_GPU85\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu85 [label="Expert85_GELU_GPU85\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu85 [label="Expert85_Linear2_GPU85\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group42 [label="AllReduce_Expert_Group42\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu86 [label="Expert86_Linear1_GPU86\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu86 [label="Expert86_GELU_GPU86\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu86 [label="Expert86_Linear2_GPU86\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu87 [label="Expert87_Linear1_GPU87\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu87 [label="Expert87_GELU_GPU87\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu87 [label="Expert87_Linear2_GPU87\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group43 [label="AllReduce_Expert_Group43\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu88 [label="Expert88_Linear1_GPU88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu88 [label="Expert88_GELU_GPU88\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu88 [label="Expert88_Linear2_GPU88\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu89 [label="Expert89_Linear1_GPU89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu89 [label="Expert89_GELU_GPU89\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu89 [label="Expert89_Linear2_GPU89\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group44 [label="AllReduce_Expert_Group44\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu90 [label="Expert90_Linear1_GPU90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu90 [label="Expert90_GELU_GPU90\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu90 [label="Expert90_Linear2_GPU90\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu91 [label="Expert91_Linear1_GPU91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu91 [label="Expert91_GELU_GPU91\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu91 [label="Expert91_Linear2_GPU91\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group45 [label="AllReduce_Expert_Group45\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu92 [label="Expert92_Linear1_GPU92\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu92 [label="Expert92_GELU_GPU92\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu92 [label="Expert92_Linear2_GPU92\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu93 [label="Expert93_Linear1_GPU93\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu93 [label="Expert93_GELU_GPU93\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu93 [label="Expert93_Linear2_GPU93\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group46 [label="AllReduce_Expert_Group46\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu94 [label="Expert94_Linear1_GPU94\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu94 [label="Expert94_GELU_GPU94\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu94 [label="Expert94_Linear2_GPU94\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu95 [label="Expert95_Linear1_GPU95\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu95 [label="Expert95_GELU_GPU95\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu95 [label="Expert95_Linear2_GPU95\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group47 [label="AllReduce_Expert_Group47\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu96 [label="Expert96_Linear1_GPU96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu96 [label="Expert96_GELU_GPU96\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu96 [label="Expert96_Linear2_GPU96\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu97 [label="Expert97_Linear1_GPU97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu97 [label="Expert97_GELU_GPU97\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu97 [label="Expert97_Linear2_GPU97\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group48 [label="AllReduce_Expert_Group48\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu98 [label="Expert98_Linear1_GPU98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu98 [label="Expert98_GELU_GPU98\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu98 [label="Expert98_Linear2_GPU98\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu99 [label="Expert99_Linear1_GPU99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu99 [label="Expert99_GELU_GPU99\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu99 [label="Expert99_Linear2_GPU99\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group49 [label="AllReduce_Expert_Group49\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu100 [label="Expert100_Linear1_GPU100\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu100 [label="Expert100_GELU_GPU100\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu100 [label="Expert100_Linear2_GPU100\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu101 [label="Expert101_Linear1_GPU101\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu101 [label="Expert101_GELU_GPU101\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu101 [label="Expert101_Linear2_GPU101\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group50 [label="AllReduce_Expert_Group50\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu102 [label="Expert102_Linear1_GPU102\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu102 [label="Expert102_GELU_GPU102\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu102 [label="Expert102_Linear2_GPU102\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu103 [label="Expert103_Linear1_GPU103\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu103 [label="Expert103_GELU_GPU103\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu103 [label="Expert103_Linear2_GPU103\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group51 [label="AllReduce_Expert_Group51\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu104 [label="Expert104_Linear1_GPU104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu104 [label="Expert104_GELU_GPU104\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu104 [label="Expert104_Linear2_GPU104\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu105 [label="Expert105_Linear1_GPU105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu105 [label="Expert105_GELU_GPU105\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu105 [label="Expert105_Linear2_GPU105\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group52 [label="AllReduce_Expert_Group52\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu106 [label="Expert106_Linear1_GPU106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu106 [label="Expert106_GELU_GPU106\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu106 [label="Expert106_Linear2_GPU106\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu107 [label="Expert107_Linear1_GPU107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu107 [label="Expert107_GELU_GPU107\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu107 [label="Expert107_Linear2_GPU107\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group53 [label="AllReduce_Expert_Group53\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu108 [label="Expert108_Linear1_GPU108\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu108 [label="Expert108_GELU_GPU108\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu108 [label="Expert108_Linear2_GPU108\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu109 [label="Expert109_Linear1_GPU109\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu109 [label="Expert109_GELU_GPU109\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu109 [label="Expert109_Linear2_GPU109\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group54 [label="AllReduce_Expert_Group54\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu110 [label="Expert110_Linear1_GPU110\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu110 [label="Expert110_GELU_GPU110\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu110 [label="Expert110_Linear2_GPU110\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu111 [label="Expert111_Linear1_GPU111\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu111 [label="Expert111_GELU_GPU111\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu111 [label="Expert111_Linear2_GPU111\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group55 [label="AllReduce_Expert_Group55\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu112 [label="Expert112_Linear1_GPU112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu112 [label="Expert112_GELU_GPU112\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu112 [label="Expert112_Linear2_GPU112\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu113 [label="Expert113_Linear1_GPU113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu113 [label="Expert113_GELU_GPU113\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu113 [label="Expert113_Linear2_GPU113\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group56 [label="AllReduce_Expert_Group56\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu114 [label="Expert114_Linear1_GPU114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu114 [label="Expert114_GELU_GPU114\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu114 [label="Expert114_Linear2_GPU114\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu115 [label="Expert115_Linear1_GPU115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu115 [label="Expert115_GELU_GPU115\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu115 [label="Expert115_Linear2_GPU115\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group57 [label="AllReduce_Expert_Group57\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu116 [label="Expert116_Linear1_GPU116\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu116 [label="Expert116_GELU_GPU116\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu116 [label="Expert116_Linear2_GPU116\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu117 [label="Expert117_Linear1_GPU117\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu117 [label="Expert117_GELU_GPU117\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu117 [label="Expert117_Linear2_GPU117\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group58 [label="AllReduce_Expert_Group58\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu118 [label="Expert118_Linear1_GPU118\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu118 [label="Expert118_GELU_GPU118\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu118 [label="Expert118_Linear2_GPU118\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu119 [label="Expert119_Linear1_GPU119\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu119 [label="Expert119_GELU_GPU119\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu119 [label="Expert119_Linear2_GPU119\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group59 [label="AllReduce_Expert_Group59\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu120 [label="Expert120_Linear1_GPU120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu120 [label="Expert120_GELU_GPU120\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu120 [label="Expert120_Linear2_GPU120\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu121 [label="Expert121_Linear1_GPU121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu121 [label="Expert121_GELU_GPU121\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu121 [label="Expert121_Linear2_GPU121\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group60 [label="AllReduce_Expert_Group60\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu122 [label="Expert122_Linear1_GPU122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu122 [label="Expert122_GELU_GPU122\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu122 [label="Expert122_Linear2_GPU122\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu123 [label="Expert123_Linear1_GPU123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu123 [label="Expert123_GELU_GPU123\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu123 [label="Expert123_Linear2_GPU123\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group61 [label="AllReduce_Expert_Group61\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu124 [label="Expert124_Linear1_GPU124\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu124 [label="Expert124_GELU_GPU124\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu124 [label="Expert124_Linear2_GPU124\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu125 [label="Expert125_Linear1_GPU125\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu125 [label="Expert125_GELU_GPU125\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu125 [label="Expert125_Linear2_GPU125\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group62 [label="AllReduce_Expert_Group62\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_expert1_gpu126 [label="Expert126_Linear1_GPU126\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu126 [label="Expert126_GELU_GPU126\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu126 [label="Expert126_Linear2_GPU126\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert1_gpu127 [label="Expert127_Linear1_GPU127\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_act_gpu127 [label="Expert127_GELU_GPU127\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, hidden_dim=1024]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert2_gpu127 [label="Expert127_Linear2_GPU127\nInput: [batch_size=128, seq_len=1024, hidden_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=512]" fillcolor=lightgreen shape=rectangle style=filled]
	layer_0_expert_allreduce_group63 [label="AllReduce_Expert_Group63\nInput: [batch_size=128, seq_len=1024, token_dim=512]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_aggregate_group0 [label="Aggregate_Experts_Group0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group1 [label="Aggregate_Experts_Group1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group2 [label="Aggregate_Experts_Group2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group3 [label="Aggregate_Experts_Group3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group4 [label="Aggregate_Experts_Group4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group5 [label="Aggregate_Experts_Group5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group6 [label="Aggregate_Experts_Group6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group7 [label="Aggregate_Experts_Group7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group8 [label="Aggregate_Experts_Group8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group9 [label="Aggregate_Experts_Group9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group10 [label="Aggregate_Experts_Group10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group11 [label="Aggregate_Experts_Group11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group12 [label="Aggregate_Experts_Group12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group13 [label="Aggregate_Experts_Group13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group14 [label="Aggregate_Experts_Group14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group15 [label="Aggregate_Experts_Group15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group16 [label="Aggregate_Experts_Group16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group17 [label="Aggregate_Experts_Group17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group18 [label="Aggregate_Experts_Group18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group19 [label="Aggregate_Experts_Group19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group20 [label="Aggregate_Experts_Group20\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group21 [label="Aggregate_Experts_Group21\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group22 [label="Aggregate_Experts_Group22\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group23 [label="Aggregate_Experts_Group23\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group24 [label="Aggregate_Experts_Group24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group25 [label="Aggregate_Experts_Group25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group26 [label="Aggregate_Experts_Group26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group27 [label="Aggregate_Experts_Group27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group28 [label="Aggregate_Experts_Group28\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group29 [label="Aggregate_Experts_Group29\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group30 [label="Aggregate_Experts_Group30\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group31 [label="Aggregate_Experts_Group31\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group32 [label="Aggregate_Experts_Group32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group33 [label="Aggregate_Experts_Group33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group34 [label="Aggregate_Experts_Group34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group35 [label="Aggregate_Experts_Group35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group36 [label="Aggregate_Experts_Group36\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group37 [label="Aggregate_Experts_Group37\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group38 [label="Aggregate_Experts_Group38\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group39 [label="Aggregate_Experts_Group39\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group40 [label="Aggregate_Experts_Group40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group41 [label="Aggregate_Experts_Group41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group42 [label="Aggregate_Experts_Group42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group43 [label="Aggregate_Experts_Group43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group44 [label="Aggregate_Experts_Group44\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group45 [label="Aggregate_Experts_Group45\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group46 [label="Aggregate_Experts_Group46\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group47 [label="Aggregate_Experts_Group47\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group48 [label="Aggregate_Experts_Group48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group49 [label="Aggregate_Experts_Group49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group50 [label="Aggregate_Experts_Group50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group51 [label="Aggregate_Experts_Group51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group52 [label="Aggregate_Experts_Group52\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group53 [label="Aggregate_Experts_Group53\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group54 [label="Aggregate_Experts_Group54\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group55 [label="Aggregate_Experts_Group55\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group56 [label="Aggregate_Experts_Group56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group57 [label="Aggregate_Experts_Group57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group58 [label="Aggregate_Experts_Group58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group59 [label="Aggregate_Experts_Group59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group60 [label="Aggregate_Experts_Group60\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group61 [label="Aggregate_Experts_Group61\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group62 [label="Aggregate_Experts_Group62\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_aggregate_group63 [label="Aggregate_Experts_Group63\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_final_allreduce [label="AllReduce_Final_Layer0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_residual2_gpu0 [label="Residual_Add2_GPU0\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu1 [label="Residual_Add2_GPU1\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu2 [label="Residual_Add2_GPU2\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu3 [label="Residual_Add2_GPU3\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu4 [label="Residual_Add2_GPU4\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu5 [label="Residual_Add2_GPU5\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu6 [label="Residual_Add2_GPU6\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu7 [label="Residual_Add2_GPU7\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu8 [label="Residual_Add2_GPU8\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu9 [label="Residual_Add2_GPU9\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu10 [label="Residual_Add2_GPU10\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu11 [label="Residual_Add2_GPU11\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu12 [label="Residual_Add2_GPU12\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu13 [label="Residual_Add2_GPU13\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu14 [label="Residual_Add2_GPU14\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu15 [label="Residual_Add2_GPU15\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu16 [label="Residual_Add2_GPU16\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu17 [label="Residual_Add2_GPU17\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu18 [label="Residual_Add2_GPU18\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu19 [label="Residual_Add2_GPU19\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu20 [label="Residual_Add2_GPU20\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu21 [label="Residual_Add2_GPU21\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu22 [label="Residual_Add2_GPU22\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu23 [label="Residual_Add2_GPU23\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu24 [label="Residual_Add2_GPU24\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu25 [label="Residual_Add2_GPU25\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu26 [label="Residual_Add2_GPU26\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu27 [label="Residual_Add2_GPU27\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu28 [label="Residual_Add2_GPU28\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu29 [label="Residual_Add2_GPU29\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu30 [label="Residual_Add2_GPU30\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu31 [label="Residual_Add2_GPU31\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu32 [label="Residual_Add2_GPU32\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu33 [label="Residual_Add2_GPU33\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu34 [label="Residual_Add2_GPU34\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu35 [label="Residual_Add2_GPU35\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu36 [label="Residual_Add2_GPU36\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu37 [label="Residual_Add2_GPU37\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu38 [label="Residual_Add2_GPU38\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu39 [label="Residual_Add2_GPU39\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu40 [label="Residual_Add2_GPU40\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu41 [label="Residual_Add2_GPU41\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu42 [label="Residual_Add2_GPU42\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu43 [label="Residual_Add2_GPU43\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu44 [label="Residual_Add2_GPU44\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu45 [label="Residual_Add2_GPU45\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu46 [label="Residual_Add2_GPU46\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu47 [label="Residual_Add2_GPU47\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu48 [label="Residual_Add2_GPU48\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu49 [label="Residual_Add2_GPU49\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu50 [label="Residual_Add2_GPU50\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu51 [label="Residual_Add2_GPU51\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu52 [label="Residual_Add2_GPU52\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu53 [label="Residual_Add2_GPU53\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu54 [label="Residual_Add2_GPU54\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu55 [label="Residual_Add2_GPU55\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu56 [label="Residual_Add2_GPU56\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu57 [label="Residual_Add2_GPU57\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu58 [label="Residual_Add2_GPU58\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu59 [label="Residual_Add2_GPU59\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu60 [label="Residual_Add2_GPU60\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu61 [label="Residual_Add2_GPU61\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu62 [label="Residual_Add2_GPU62\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu63 [label="Residual_Add2_GPU63\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu64 [label="Residual_Add2_GPU64\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu65 [label="Residual_Add2_GPU65\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu66 [label="Residual_Add2_GPU66\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu67 [label="Residual_Add2_GPU67\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu68 [label="Residual_Add2_GPU68\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu69 [label="Residual_Add2_GPU69\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu70 [label="Residual_Add2_GPU70\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu71 [label="Residual_Add2_GPU71\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu72 [label="Residual_Add2_GPU72\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu73 [label="Residual_Add2_GPU73\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu74 [label="Residual_Add2_GPU74\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu75 [label="Residual_Add2_GPU75\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu76 [label="Residual_Add2_GPU76\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu77 [label="Residual_Add2_GPU77\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu78 [label="Residual_Add2_GPU78\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu79 [label="Residual_Add2_GPU79\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu80 [label="Residual_Add2_GPU80\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu81 [label="Residual_Add2_GPU81\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu82 [label="Residual_Add2_GPU82\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu83 [label="Residual_Add2_GPU83\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu84 [label="Residual_Add2_GPU84\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu85 [label="Residual_Add2_GPU85\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu86 [label="Residual_Add2_GPU86\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu87 [label="Residual_Add2_GPU87\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu88 [label="Residual_Add2_GPU88\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu89 [label="Residual_Add2_GPU89\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu90 [label="Residual_Add2_GPU90\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu91 [label="Residual_Add2_GPU91\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu92 [label="Residual_Add2_GPU92\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu93 [label="Residual_Add2_GPU93\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu94 [label="Residual_Add2_GPU94\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu95 [label="Residual_Add2_GPU95\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu96 [label="Residual_Add2_GPU96\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu97 [label="Residual_Add2_GPU97\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu98 [label="Residual_Add2_GPU98\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu99 [label="Residual_Add2_GPU99\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu100 [label="Residual_Add2_GPU100\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu101 [label="Residual_Add2_GPU101\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu102 [label="Residual_Add2_GPU102\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu103 [label="Residual_Add2_GPU103\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu104 [label="Residual_Add2_GPU104\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu105 [label="Residual_Add2_GPU105\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu106 [label="Residual_Add2_GPU106\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu107 [label="Residual_Add2_GPU107\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu108 [label="Residual_Add2_GPU108\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu109 [label="Residual_Add2_GPU109\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu110 [label="Residual_Add2_GPU110\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu111 [label="Residual_Add2_GPU111\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu112 [label="Residual_Add2_GPU112\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu113 [label="Residual_Add2_GPU113\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu114 [label="Residual_Add2_GPU114\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu115 [label="Residual_Add2_GPU115\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu116 [label="Residual_Add2_GPU116\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu117 [label="Residual_Add2_GPU117\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu118 [label="Residual_Add2_GPU118\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu119 [label="Residual_Add2_GPU119\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu120 [label="Residual_Add2_GPU120\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu121 [label="Residual_Add2_GPU121\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu122 [label="Residual_Add2_GPU122\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu123 [label="Residual_Add2_GPU123\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu124 [label="Residual_Add2_GPU124\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu125 [label="Residual_Add2_GPU125\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu126 [label="Residual_Add2_GPU126\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layer_0_residual2_gpu127 [label="Residual_Add2_GPU127\nInput1: [batch_size=128, seq_len=1024, token_dim=1024]\nInput2: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram style=filled]
	layers_1_15_summary [label="Layers 1-15 (Identical Pattern)\nEach layer: 128 GPUs, 64 expert groups, TP2\nSame computation and communication pattern as Layer 0" fillcolor=lightgray shape=note style=filled]
	output [label="OUTPUT\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=white shape=octagon style=filled]
	input -> layer_0_ln1_gpu0
	input -> layer_0_ln1_gpu1
	input -> layer_0_ln1_gpu2
	input -> layer_0_ln1_gpu3
	input -> layer_0_ln1_gpu4
	input -> layer_0_ln1_gpu5
	input -> layer_0_ln1_gpu6
	input -> layer_0_ln1_gpu7
	input -> layer_0_ln1_gpu8
	input -> layer_0_ln1_gpu9
	input -> layer_0_ln1_gpu10
	input -> layer_0_ln1_gpu11
	input -> layer_0_ln1_gpu12
	input -> layer_0_ln1_gpu13
	input -> layer_0_ln1_gpu14
	input -> layer_0_ln1_gpu15
	input -> layer_0_ln1_gpu16
	input -> layer_0_ln1_gpu17
	input -> layer_0_ln1_gpu18
	input -> layer_0_ln1_gpu19
	input -> layer_0_ln1_gpu20
	input -> layer_0_ln1_gpu21
	input -> layer_0_ln1_gpu22
	input -> layer_0_ln1_gpu23
	input -> layer_0_ln1_gpu24
	input -> layer_0_ln1_gpu25
	input -> layer_0_ln1_gpu26
	input -> layer_0_ln1_gpu27
	input -> layer_0_ln1_gpu28
	input -> layer_0_ln1_gpu29
	input -> layer_0_ln1_gpu30
	input -> layer_0_ln1_gpu31
	input -> layer_0_ln1_gpu32
	input -> layer_0_ln1_gpu33
	input -> layer_0_ln1_gpu34
	input -> layer_0_ln1_gpu35
	input -> layer_0_ln1_gpu36
	input -> layer_0_ln1_gpu37
	input -> layer_0_ln1_gpu38
	input -> layer_0_ln1_gpu39
	input -> layer_0_ln1_gpu40
	input -> layer_0_ln1_gpu41
	input -> layer_0_ln1_gpu42
	input -> layer_0_ln1_gpu43
	input -> layer_0_ln1_gpu44
	input -> layer_0_ln1_gpu45
	input -> layer_0_ln1_gpu46
	input -> layer_0_ln1_gpu47
	input -> layer_0_ln1_gpu48
	input -> layer_0_ln1_gpu49
	input -> layer_0_ln1_gpu50
	input -> layer_0_ln1_gpu51
	input -> layer_0_ln1_gpu52
	input -> layer_0_ln1_gpu53
	input -> layer_0_ln1_gpu54
	input -> layer_0_ln1_gpu55
	input -> layer_0_ln1_gpu56
	input -> layer_0_ln1_gpu57
	input -> layer_0_ln1_gpu58
	input -> layer_0_ln1_gpu59
	input -> layer_0_ln1_gpu60
	input -> layer_0_ln1_gpu61
	input -> layer_0_ln1_gpu62
	input -> layer_0_ln1_gpu63
	input -> layer_0_ln1_gpu64
	input -> layer_0_ln1_gpu65
	input -> layer_0_ln1_gpu66
	input -> layer_0_ln1_gpu67
	input -> layer_0_ln1_gpu68
	input -> layer_0_ln1_gpu69
	input -> layer_0_ln1_gpu70
	input -> layer_0_ln1_gpu71
	input -> layer_0_ln1_gpu72
	input -> layer_0_ln1_gpu73
	input -> layer_0_ln1_gpu74
	input -> layer_0_ln1_gpu75
	input -> layer_0_ln1_gpu76
	input -> layer_0_ln1_gpu77
	input -> layer_0_ln1_gpu78
	input -> layer_0_ln1_gpu79
	input -> layer_0_ln1_gpu80
	input -> layer_0_ln1_gpu81
	input -> layer_0_ln1_gpu82
	input -> layer_0_ln1_gpu83
	input -> layer_0_ln1_gpu84
	input -> layer_0_ln1_gpu85
	input -> layer_0_ln1_gpu86
	input -> layer_0_ln1_gpu87
	input -> layer_0_ln1_gpu88
	input -> layer_0_ln1_gpu89
	input -> layer_0_ln1_gpu90
	input -> layer_0_ln1_gpu91
	input -> layer_0_ln1_gpu92
	input -> layer_0_ln1_gpu93
	input -> layer_0_ln1_gpu94
	input -> layer_0_ln1_gpu95
	input -> layer_0_ln1_gpu96
	input -> layer_0_ln1_gpu97
	input -> layer_0_ln1_gpu98
	input -> layer_0_ln1_gpu99
	input -> layer_0_ln1_gpu100
	input -> layer_0_ln1_gpu101
	input -> layer_0_ln1_gpu102
	input -> layer_0_ln1_gpu103
	input -> layer_0_ln1_gpu104
	input -> layer_0_ln1_gpu105
	input -> layer_0_ln1_gpu106
	input -> layer_0_ln1_gpu107
	input -> layer_0_ln1_gpu108
	input -> layer_0_ln1_gpu109
	input -> layer_0_ln1_gpu110
	input -> layer_0_ln1_gpu111
	input -> layer_0_ln1_gpu112
	input -> layer_0_ln1_gpu113
	input -> layer_0_ln1_gpu114
	input -> layer_0_ln1_gpu115
	input -> layer_0_ln1_gpu116
	input -> layer_0_ln1_gpu117
	input -> layer_0_ln1_gpu118
	input -> layer_0_ln1_gpu119
	input -> layer_0_ln1_gpu120
	input -> layer_0_ln1_gpu121
	input -> layer_0_ln1_gpu122
	input -> layer_0_ln1_gpu123
	input -> layer_0_ln1_gpu124
	input -> layer_0_ln1_gpu125
	input -> layer_0_ln1_gpu126
	input -> layer_0_ln1_gpu127
	layer_0_ln1_gpu0 -> layer_0_qkv_gpu0
	layer_0_ln1_gpu1 -> layer_0_qkv_gpu1
	layer_0_ln1_gpu2 -> layer_0_qkv_gpu2
	layer_0_ln1_gpu3 -> layer_0_qkv_gpu3
	layer_0_ln1_gpu4 -> layer_0_qkv_gpu4
	layer_0_ln1_gpu5 -> layer_0_qkv_gpu5
	layer_0_ln1_gpu6 -> layer_0_qkv_gpu6
	layer_0_ln1_gpu7 -> layer_0_qkv_gpu7
	layer_0_ln1_gpu8 -> layer_0_qkv_gpu8
	layer_0_ln1_gpu9 -> layer_0_qkv_gpu9
	layer_0_ln1_gpu10 -> layer_0_qkv_gpu10
	layer_0_ln1_gpu11 -> layer_0_qkv_gpu11
	layer_0_ln1_gpu12 -> layer_0_qkv_gpu12
	layer_0_ln1_gpu13 -> layer_0_qkv_gpu13
	layer_0_ln1_gpu14 -> layer_0_qkv_gpu14
	layer_0_ln1_gpu15 -> layer_0_qkv_gpu15
	layer_0_ln1_gpu16 -> layer_0_qkv_gpu16
	layer_0_ln1_gpu17 -> layer_0_qkv_gpu17
	layer_0_ln1_gpu18 -> layer_0_qkv_gpu18
	layer_0_ln1_gpu19 -> layer_0_qkv_gpu19
	layer_0_ln1_gpu20 -> layer_0_qkv_gpu20
	layer_0_ln1_gpu21 -> layer_0_qkv_gpu21
	layer_0_ln1_gpu22 -> layer_0_qkv_gpu22
	layer_0_ln1_gpu23 -> layer_0_qkv_gpu23
	layer_0_ln1_gpu24 -> layer_0_qkv_gpu24
	layer_0_ln1_gpu25 -> layer_0_qkv_gpu25
	layer_0_ln1_gpu26 -> layer_0_qkv_gpu26
	layer_0_ln1_gpu27 -> layer_0_qkv_gpu27
	layer_0_ln1_gpu28 -> layer_0_qkv_gpu28
	layer_0_ln1_gpu29 -> layer_0_qkv_gpu29
	layer_0_ln1_gpu30 -> layer_0_qkv_gpu30
	layer_0_ln1_gpu31 -> layer_0_qkv_gpu31
	layer_0_ln1_gpu32 -> layer_0_qkv_gpu32
	layer_0_ln1_gpu33 -> layer_0_qkv_gpu33
	layer_0_ln1_gpu34 -> layer_0_qkv_gpu34
	layer_0_ln1_gpu35 -> layer_0_qkv_gpu35
	layer_0_ln1_gpu36 -> layer_0_qkv_gpu36
	layer_0_ln1_gpu37 -> layer_0_qkv_gpu37
	layer_0_ln1_gpu38 -> layer_0_qkv_gpu38
	layer_0_ln1_gpu39 -> layer_0_qkv_gpu39
	layer_0_ln1_gpu40 -> layer_0_qkv_gpu40
	layer_0_ln1_gpu41 -> layer_0_qkv_gpu41
	layer_0_ln1_gpu42 -> layer_0_qkv_gpu42
	layer_0_ln1_gpu43 -> layer_0_qkv_gpu43
	layer_0_ln1_gpu44 -> layer_0_qkv_gpu44
	layer_0_ln1_gpu45 -> layer_0_qkv_gpu45
	layer_0_ln1_gpu46 -> layer_0_qkv_gpu46
	layer_0_ln1_gpu47 -> layer_0_qkv_gpu47
	layer_0_ln1_gpu48 -> layer_0_qkv_gpu48
	layer_0_ln1_gpu49 -> layer_0_qkv_gpu49
	layer_0_ln1_gpu50 -> layer_0_qkv_gpu50
	layer_0_ln1_gpu51 -> layer_0_qkv_gpu51
	layer_0_ln1_gpu52 -> layer_0_qkv_gpu52
	layer_0_ln1_gpu53 -> layer_0_qkv_gpu53
	layer_0_ln1_gpu54 -> layer_0_qkv_gpu54
	layer_0_ln1_gpu55 -> layer_0_qkv_gpu55
	layer_0_ln1_gpu56 -> layer_0_qkv_gpu56
	layer_0_ln1_gpu57 -> layer_0_qkv_gpu57
	layer_0_ln1_gpu58 -> layer_0_qkv_gpu58
	layer_0_ln1_gpu59 -> layer_0_qkv_gpu59
	layer_0_ln1_gpu60 -> layer_0_qkv_gpu60
	layer_0_ln1_gpu61 -> layer_0_qkv_gpu61
	layer_0_ln1_gpu62 -> layer_0_qkv_gpu62
	layer_0_ln1_gpu63 -> layer_0_qkv_gpu63
	layer_0_ln1_gpu64 -> layer_0_qkv_gpu64
	layer_0_ln1_gpu65 -> layer_0_qkv_gpu65
	layer_0_ln1_gpu66 -> layer_0_qkv_gpu66
	layer_0_ln1_gpu67 -> layer_0_qkv_gpu67
	layer_0_ln1_gpu68 -> layer_0_qkv_gpu68
	layer_0_ln1_gpu69 -> layer_0_qkv_gpu69
	layer_0_ln1_gpu70 -> layer_0_qkv_gpu70
	layer_0_ln1_gpu71 -> layer_0_qkv_gpu71
	layer_0_ln1_gpu72 -> layer_0_qkv_gpu72
	layer_0_ln1_gpu73 -> layer_0_qkv_gpu73
	layer_0_ln1_gpu74 -> layer_0_qkv_gpu74
	layer_0_ln1_gpu75 -> layer_0_qkv_gpu75
	layer_0_ln1_gpu76 -> layer_0_qkv_gpu76
	layer_0_ln1_gpu77 -> layer_0_qkv_gpu77
	layer_0_ln1_gpu78 -> layer_0_qkv_gpu78
	layer_0_ln1_gpu79 -> layer_0_qkv_gpu79
	layer_0_ln1_gpu80 -> layer_0_qkv_gpu80
	layer_0_ln1_gpu81 -> layer_0_qkv_gpu81
	layer_0_ln1_gpu82 -> layer_0_qkv_gpu82
	layer_0_ln1_gpu83 -> layer_0_qkv_gpu83
	layer_0_ln1_gpu84 -> layer_0_qkv_gpu84
	layer_0_ln1_gpu85 -> layer_0_qkv_gpu85
	layer_0_ln1_gpu86 -> layer_0_qkv_gpu86
	layer_0_ln1_gpu87 -> layer_0_qkv_gpu87
	layer_0_ln1_gpu88 -> layer_0_qkv_gpu88
	layer_0_ln1_gpu89 -> layer_0_qkv_gpu89
	layer_0_ln1_gpu90 -> layer_0_qkv_gpu90
	layer_0_ln1_gpu91 -> layer_0_qkv_gpu91
	layer_0_ln1_gpu92 -> layer_0_qkv_gpu92
	layer_0_ln1_gpu93 -> layer_0_qkv_gpu93
	layer_0_ln1_gpu94 -> layer_0_qkv_gpu94
	layer_0_ln1_gpu95 -> layer_0_qkv_gpu95
	layer_0_ln1_gpu96 -> layer_0_qkv_gpu96
	layer_0_ln1_gpu97 -> layer_0_qkv_gpu97
	layer_0_ln1_gpu98 -> layer_0_qkv_gpu98
	layer_0_ln1_gpu99 -> layer_0_qkv_gpu99
	layer_0_ln1_gpu100 -> layer_0_qkv_gpu100
	layer_0_ln1_gpu101 -> layer_0_qkv_gpu101
	layer_0_ln1_gpu102 -> layer_0_qkv_gpu102
	layer_0_ln1_gpu103 -> layer_0_qkv_gpu103
	layer_0_ln1_gpu104 -> layer_0_qkv_gpu104
	layer_0_ln1_gpu105 -> layer_0_qkv_gpu105
	layer_0_ln1_gpu106 -> layer_0_qkv_gpu106
	layer_0_ln1_gpu107 -> layer_0_qkv_gpu107
	layer_0_ln1_gpu108 -> layer_0_qkv_gpu108
	layer_0_ln1_gpu109 -> layer_0_qkv_gpu109
	layer_0_ln1_gpu110 -> layer_0_qkv_gpu110
	layer_0_ln1_gpu111 -> layer_0_qkv_gpu111
	layer_0_ln1_gpu112 -> layer_0_qkv_gpu112
	layer_0_ln1_gpu113 -> layer_0_qkv_gpu113
	layer_0_ln1_gpu114 -> layer_0_qkv_gpu114
	layer_0_ln1_gpu115 -> layer_0_qkv_gpu115
	layer_0_ln1_gpu116 -> layer_0_qkv_gpu116
	layer_0_ln1_gpu117 -> layer_0_qkv_gpu117
	layer_0_ln1_gpu118 -> layer_0_qkv_gpu118
	layer_0_ln1_gpu119 -> layer_0_qkv_gpu119
	layer_0_ln1_gpu120 -> layer_0_qkv_gpu120
	layer_0_ln1_gpu121 -> layer_0_qkv_gpu121
	layer_0_ln1_gpu122 -> layer_0_qkv_gpu122
	layer_0_ln1_gpu123 -> layer_0_qkv_gpu123
	layer_0_ln1_gpu124 -> layer_0_qkv_gpu124
	layer_0_ln1_gpu125 -> layer_0_qkv_gpu125
	layer_0_ln1_gpu126 -> layer_0_qkv_gpu126
	layer_0_ln1_gpu127 -> layer_0_qkv_gpu127
	layer_0_qkv_gpu0 -> layer_0_attn_gpu0
	layer_0_qkv_gpu1 -> layer_0_attn_gpu1
	layer_0_qkv_gpu2 -> layer_0_attn_gpu2
	layer_0_qkv_gpu3 -> layer_0_attn_gpu3
	layer_0_qkv_gpu4 -> layer_0_attn_gpu4
	layer_0_qkv_gpu5 -> layer_0_attn_gpu5
	layer_0_qkv_gpu6 -> layer_0_attn_gpu6
	layer_0_qkv_gpu7 -> layer_0_attn_gpu7
	layer_0_qkv_gpu8 -> layer_0_attn_gpu8
	layer_0_qkv_gpu9 -> layer_0_attn_gpu9
	layer_0_qkv_gpu10 -> layer_0_attn_gpu10
	layer_0_qkv_gpu11 -> layer_0_attn_gpu11
	layer_0_qkv_gpu12 -> layer_0_attn_gpu12
	layer_0_qkv_gpu13 -> layer_0_attn_gpu13
	layer_0_qkv_gpu14 -> layer_0_attn_gpu14
	layer_0_qkv_gpu15 -> layer_0_attn_gpu15
	layer_0_qkv_gpu16 -> layer_0_attn_gpu16
	layer_0_qkv_gpu17 -> layer_0_attn_gpu17
	layer_0_qkv_gpu18 -> layer_0_attn_gpu18
	layer_0_qkv_gpu19 -> layer_0_attn_gpu19
	layer_0_qkv_gpu20 -> layer_0_attn_gpu20
	layer_0_qkv_gpu21 -> layer_0_attn_gpu21
	layer_0_qkv_gpu22 -> layer_0_attn_gpu22
	layer_0_qkv_gpu23 -> layer_0_attn_gpu23
	layer_0_qkv_gpu24 -> layer_0_attn_gpu24
	layer_0_qkv_gpu25 -> layer_0_attn_gpu25
	layer_0_qkv_gpu26 -> layer_0_attn_gpu26
	layer_0_qkv_gpu27 -> layer_0_attn_gpu27
	layer_0_qkv_gpu28 -> layer_0_attn_gpu28
	layer_0_qkv_gpu29 -> layer_0_attn_gpu29
	layer_0_qkv_gpu30 -> layer_0_attn_gpu30
	layer_0_qkv_gpu31 -> layer_0_attn_gpu31
	layer_0_qkv_gpu32 -> layer_0_attn_gpu32
	layer_0_qkv_gpu33 -> layer_0_attn_gpu33
	layer_0_qkv_gpu34 -> layer_0_attn_gpu34
	layer_0_qkv_gpu35 -> layer_0_attn_gpu35
	layer_0_qkv_gpu36 -> layer_0_attn_gpu36
	layer_0_qkv_gpu37 -> layer_0_attn_gpu37
	layer_0_qkv_gpu38 -> layer_0_attn_gpu38
	layer_0_qkv_gpu39 -> layer_0_attn_gpu39
	layer_0_qkv_gpu40 -> layer_0_attn_gpu40
	layer_0_qkv_gpu41 -> layer_0_attn_gpu41
	layer_0_qkv_gpu42 -> layer_0_attn_gpu42
	layer_0_qkv_gpu43 -> layer_0_attn_gpu43
	layer_0_qkv_gpu44 -> layer_0_attn_gpu44
	layer_0_qkv_gpu45 -> layer_0_attn_gpu45
	layer_0_qkv_gpu46 -> layer_0_attn_gpu46
	layer_0_qkv_gpu47 -> layer_0_attn_gpu47
	layer_0_qkv_gpu48 -> layer_0_attn_gpu48
	layer_0_qkv_gpu49 -> layer_0_attn_gpu49
	layer_0_qkv_gpu50 -> layer_0_attn_gpu50
	layer_0_qkv_gpu51 -> layer_0_attn_gpu51
	layer_0_qkv_gpu52 -> layer_0_attn_gpu52
	layer_0_qkv_gpu53 -> layer_0_attn_gpu53
	layer_0_qkv_gpu54 -> layer_0_attn_gpu54
	layer_0_qkv_gpu55 -> layer_0_attn_gpu55
	layer_0_qkv_gpu56 -> layer_0_attn_gpu56
	layer_0_qkv_gpu57 -> layer_0_attn_gpu57
	layer_0_qkv_gpu58 -> layer_0_attn_gpu58
	layer_0_qkv_gpu59 -> layer_0_attn_gpu59
	layer_0_qkv_gpu60 -> layer_0_attn_gpu60
	layer_0_qkv_gpu61 -> layer_0_attn_gpu61
	layer_0_qkv_gpu62 -> layer_0_attn_gpu62
	layer_0_qkv_gpu63 -> layer_0_attn_gpu63
	layer_0_qkv_gpu64 -> layer_0_attn_gpu64
	layer_0_qkv_gpu65 -> layer_0_attn_gpu65
	layer_0_qkv_gpu66 -> layer_0_attn_gpu66
	layer_0_qkv_gpu67 -> layer_0_attn_gpu67
	layer_0_qkv_gpu68 -> layer_0_attn_gpu68
	layer_0_qkv_gpu69 -> layer_0_attn_gpu69
	layer_0_qkv_gpu70 -> layer_0_attn_gpu70
	layer_0_qkv_gpu71 -> layer_0_attn_gpu71
	layer_0_qkv_gpu72 -> layer_0_attn_gpu72
	layer_0_qkv_gpu73 -> layer_0_attn_gpu73
	layer_0_qkv_gpu74 -> layer_0_attn_gpu74
	layer_0_qkv_gpu75 -> layer_0_attn_gpu75
	layer_0_qkv_gpu76 -> layer_0_attn_gpu76
	layer_0_qkv_gpu77 -> layer_0_attn_gpu77
	layer_0_qkv_gpu78 -> layer_0_attn_gpu78
	layer_0_qkv_gpu79 -> layer_0_attn_gpu79
	layer_0_qkv_gpu80 -> layer_0_attn_gpu80
	layer_0_qkv_gpu81 -> layer_0_attn_gpu81
	layer_0_qkv_gpu82 -> layer_0_attn_gpu82
	layer_0_qkv_gpu83 -> layer_0_attn_gpu83
	layer_0_qkv_gpu84 -> layer_0_attn_gpu84
	layer_0_qkv_gpu85 -> layer_0_attn_gpu85
	layer_0_qkv_gpu86 -> layer_0_attn_gpu86
	layer_0_qkv_gpu87 -> layer_0_attn_gpu87
	layer_0_qkv_gpu88 -> layer_0_attn_gpu88
	layer_0_qkv_gpu89 -> layer_0_attn_gpu89
	layer_0_qkv_gpu90 -> layer_0_attn_gpu90
	layer_0_qkv_gpu91 -> layer_0_attn_gpu91
	layer_0_qkv_gpu92 -> layer_0_attn_gpu92
	layer_0_qkv_gpu93 -> layer_0_attn_gpu93
	layer_0_qkv_gpu94 -> layer_0_attn_gpu94
	layer_0_qkv_gpu95 -> layer_0_attn_gpu95
	layer_0_qkv_gpu96 -> layer_0_attn_gpu96
	layer_0_qkv_gpu97 -> layer_0_attn_gpu97
	layer_0_qkv_gpu98 -> layer_0_attn_gpu98
	layer_0_qkv_gpu99 -> layer_0_attn_gpu99
	layer_0_qkv_gpu100 -> layer_0_attn_gpu100
	layer_0_qkv_gpu101 -> layer_0_attn_gpu101
	layer_0_qkv_gpu102 -> layer_0_attn_gpu102
	layer_0_qkv_gpu103 -> layer_0_attn_gpu103
	layer_0_qkv_gpu104 -> layer_0_attn_gpu104
	layer_0_qkv_gpu105 -> layer_0_attn_gpu105
	layer_0_qkv_gpu106 -> layer_0_attn_gpu106
	layer_0_qkv_gpu107 -> layer_0_attn_gpu107
	layer_0_qkv_gpu108 -> layer_0_attn_gpu108
	layer_0_qkv_gpu109 -> layer_0_attn_gpu109
	layer_0_qkv_gpu110 -> layer_0_attn_gpu110
	layer_0_qkv_gpu111 -> layer_0_attn_gpu111
	layer_0_qkv_gpu112 -> layer_0_attn_gpu112
	layer_0_qkv_gpu113 -> layer_0_attn_gpu113
	layer_0_qkv_gpu114 -> layer_0_attn_gpu114
	layer_0_qkv_gpu115 -> layer_0_attn_gpu115
	layer_0_qkv_gpu116 -> layer_0_attn_gpu116
	layer_0_qkv_gpu117 -> layer_0_attn_gpu117
	layer_0_qkv_gpu118 -> layer_0_attn_gpu118
	layer_0_qkv_gpu119 -> layer_0_attn_gpu119
	layer_0_qkv_gpu120 -> layer_0_attn_gpu120
	layer_0_qkv_gpu121 -> layer_0_attn_gpu121
	layer_0_qkv_gpu122 -> layer_0_attn_gpu122
	layer_0_qkv_gpu123 -> layer_0_attn_gpu123
	layer_0_qkv_gpu124 -> layer_0_attn_gpu124
	layer_0_qkv_gpu125 -> layer_0_attn_gpu125
	layer_0_qkv_gpu126 -> layer_0_attn_gpu126
	layer_0_qkv_gpu127 -> layer_0_attn_gpu127
	layer_0_attn_gpu0 -> layer_0_attn_out_gpu0
	layer_0_attn_gpu1 -> layer_0_attn_out_gpu1
	layer_0_attn_gpu2 -> layer_0_attn_out_gpu2
	layer_0_attn_gpu3 -> layer_0_attn_out_gpu3
	layer_0_attn_gpu4 -> layer_0_attn_out_gpu4
	layer_0_attn_gpu5 -> layer_0_attn_out_gpu5
	layer_0_attn_gpu6 -> layer_0_attn_out_gpu6
	layer_0_attn_gpu7 -> layer_0_attn_out_gpu7
	layer_0_attn_gpu8 -> layer_0_attn_out_gpu8
	layer_0_attn_gpu9 -> layer_0_attn_out_gpu9
	layer_0_attn_gpu10 -> layer_0_attn_out_gpu10
	layer_0_attn_gpu11 -> layer_0_attn_out_gpu11
	layer_0_attn_gpu12 -> layer_0_attn_out_gpu12
	layer_0_attn_gpu13 -> layer_0_attn_out_gpu13
	layer_0_attn_gpu14 -> layer_0_attn_out_gpu14
	layer_0_attn_gpu15 -> layer_0_attn_out_gpu15
	layer_0_attn_gpu16 -> layer_0_attn_out_gpu16
	layer_0_attn_gpu17 -> layer_0_attn_out_gpu17
	layer_0_attn_gpu18 -> layer_0_attn_out_gpu18
	layer_0_attn_gpu19 -> layer_0_attn_out_gpu19
	layer_0_attn_gpu20 -> layer_0_attn_out_gpu20
	layer_0_attn_gpu21 -> layer_0_attn_out_gpu21
	layer_0_attn_gpu22 -> layer_0_attn_out_gpu22
	layer_0_attn_gpu23 -> layer_0_attn_out_gpu23
	layer_0_attn_gpu24 -> layer_0_attn_out_gpu24
	layer_0_attn_gpu25 -> layer_0_attn_out_gpu25
	layer_0_attn_gpu26 -> layer_0_attn_out_gpu26
	layer_0_attn_gpu27 -> layer_0_attn_out_gpu27
	layer_0_attn_gpu28 -> layer_0_attn_out_gpu28
	layer_0_attn_gpu29 -> layer_0_attn_out_gpu29
	layer_0_attn_gpu30 -> layer_0_attn_out_gpu30
	layer_0_attn_gpu31 -> layer_0_attn_out_gpu31
	layer_0_attn_gpu32 -> layer_0_attn_out_gpu32
	layer_0_attn_gpu33 -> layer_0_attn_out_gpu33
	layer_0_attn_gpu34 -> layer_0_attn_out_gpu34
	layer_0_attn_gpu35 -> layer_0_attn_out_gpu35
	layer_0_attn_gpu36 -> layer_0_attn_out_gpu36
	layer_0_attn_gpu37 -> layer_0_attn_out_gpu37
	layer_0_attn_gpu38 -> layer_0_attn_out_gpu38
	layer_0_attn_gpu39 -> layer_0_attn_out_gpu39
	layer_0_attn_gpu40 -> layer_0_attn_out_gpu40
	layer_0_attn_gpu41 -> layer_0_attn_out_gpu41
	layer_0_attn_gpu42 -> layer_0_attn_out_gpu42
	layer_0_attn_gpu43 -> layer_0_attn_out_gpu43
	layer_0_attn_gpu44 -> layer_0_attn_out_gpu44
	layer_0_attn_gpu45 -> layer_0_attn_out_gpu45
	layer_0_attn_gpu46 -> layer_0_attn_out_gpu46
	layer_0_attn_gpu47 -> layer_0_attn_out_gpu47
	layer_0_attn_gpu48 -> layer_0_attn_out_gpu48
	layer_0_attn_gpu49 -> layer_0_attn_out_gpu49
	layer_0_attn_gpu50 -> layer_0_attn_out_gpu50
	layer_0_attn_gpu51 -> layer_0_attn_out_gpu51
	layer_0_attn_gpu52 -> layer_0_attn_out_gpu52
	layer_0_attn_gpu53 -> layer_0_attn_out_gpu53
	layer_0_attn_gpu54 -> layer_0_attn_out_gpu54
	layer_0_attn_gpu55 -> layer_0_attn_out_gpu55
	layer_0_attn_gpu56 -> layer_0_attn_out_gpu56
	layer_0_attn_gpu57 -> layer_0_attn_out_gpu57
	layer_0_attn_gpu58 -> layer_0_attn_out_gpu58
	layer_0_attn_gpu59 -> layer_0_attn_out_gpu59
	layer_0_attn_gpu60 -> layer_0_attn_out_gpu60
	layer_0_attn_gpu61 -> layer_0_attn_out_gpu61
	layer_0_attn_gpu62 -> layer_0_attn_out_gpu62
	layer_0_attn_gpu63 -> layer_0_attn_out_gpu63
	layer_0_attn_gpu64 -> layer_0_attn_out_gpu64
	layer_0_attn_gpu65 -> layer_0_attn_out_gpu65
	layer_0_attn_gpu66 -> layer_0_attn_out_gpu66
	layer_0_attn_gpu67 -> layer_0_attn_out_gpu67
	layer_0_attn_gpu68 -> layer_0_attn_out_gpu68
	layer_0_attn_gpu69 -> layer_0_attn_out_gpu69
	layer_0_attn_gpu70 -> layer_0_attn_out_gpu70
	layer_0_attn_gpu71 -> layer_0_attn_out_gpu71
	layer_0_attn_gpu72 -> layer_0_attn_out_gpu72
	layer_0_attn_gpu73 -> layer_0_attn_out_gpu73
	layer_0_attn_gpu74 -> layer_0_attn_out_gpu74
	layer_0_attn_gpu75 -> layer_0_attn_out_gpu75
	layer_0_attn_gpu76 -> layer_0_attn_out_gpu76
	layer_0_attn_gpu77 -> layer_0_attn_out_gpu77
	layer_0_attn_gpu78 -> layer_0_attn_out_gpu78
	layer_0_attn_gpu79 -> layer_0_attn_out_gpu79
	layer_0_attn_gpu80 -> layer_0_attn_out_gpu80
	layer_0_attn_gpu81 -> layer_0_attn_out_gpu81
	layer_0_attn_gpu82 -> layer_0_attn_out_gpu82
	layer_0_attn_gpu83 -> layer_0_attn_out_gpu83
	layer_0_attn_gpu84 -> layer_0_attn_out_gpu84
	layer_0_attn_gpu85 -> layer_0_attn_out_gpu85
	layer_0_attn_gpu86 -> layer_0_attn_out_gpu86
	layer_0_attn_gpu87 -> layer_0_attn_out_gpu87
	layer_0_attn_gpu88 -> layer_0_attn_out_gpu88
	layer_0_attn_gpu89 -> layer_0_attn_out_gpu89
	layer_0_attn_gpu90 -> layer_0_attn_out_gpu90
	layer_0_attn_gpu91 -> layer_0_attn_out_gpu91
	layer_0_attn_gpu92 -> layer_0_attn_out_gpu92
	layer_0_attn_gpu93 -> layer_0_attn_out_gpu93
	layer_0_attn_gpu94 -> layer_0_attn_out_gpu94
	layer_0_attn_gpu95 -> layer_0_attn_out_gpu95
	layer_0_attn_gpu96 -> layer_0_attn_out_gpu96
	layer_0_attn_gpu97 -> layer_0_attn_out_gpu97
	layer_0_attn_gpu98 -> layer_0_attn_out_gpu98
	layer_0_attn_gpu99 -> layer_0_attn_out_gpu99
	layer_0_attn_gpu100 -> layer_0_attn_out_gpu100
	layer_0_attn_gpu101 -> layer_0_attn_out_gpu101
	layer_0_attn_gpu102 -> layer_0_attn_out_gpu102
	layer_0_attn_gpu103 -> layer_0_attn_out_gpu103
	layer_0_attn_gpu104 -> layer_0_attn_out_gpu104
	layer_0_attn_gpu105 -> layer_0_attn_out_gpu105
	layer_0_attn_gpu106 -> layer_0_attn_out_gpu106
	layer_0_attn_gpu107 -> layer_0_attn_out_gpu107
	layer_0_attn_gpu108 -> layer_0_attn_out_gpu108
	layer_0_attn_gpu109 -> layer_0_attn_out_gpu109
	layer_0_attn_gpu110 -> layer_0_attn_out_gpu110
	layer_0_attn_gpu111 -> layer_0_attn_out_gpu111
	layer_0_attn_gpu112 -> layer_0_attn_out_gpu112
	layer_0_attn_gpu113 -> layer_0_attn_out_gpu113
	layer_0_attn_gpu114 -> layer_0_attn_out_gpu114
	layer_0_attn_gpu115 -> layer_0_attn_out_gpu115
	layer_0_attn_gpu116 -> layer_0_attn_out_gpu116
	layer_0_attn_gpu117 -> layer_0_attn_out_gpu117
	layer_0_attn_gpu118 -> layer_0_attn_out_gpu118
	layer_0_attn_gpu119 -> layer_0_attn_out_gpu119
	layer_0_attn_gpu120 -> layer_0_attn_out_gpu120
	layer_0_attn_gpu121 -> layer_0_attn_out_gpu121
	layer_0_attn_gpu122 -> layer_0_attn_out_gpu122
	layer_0_attn_gpu123 -> layer_0_attn_out_gpu123
	layer_0_attn_gpu124 -> layer_0_attn_out_gpu124
	layer_0_attn_gpu125 -> layer_0_attn_out_gpu125
	layer_0_attn_gpu126 -> layer_0_attn_out_gpu126
	layer_0_attn_gpu127 -> layer_0_attn_out_gpu127
	layer_0_attn_out_gpu0 -> layer_0_attn_allreduce_group0
	layer_0_attn_out_gpu1 -> layer_0_attn_allreduce_group0
	layer_0_attn_out_gpu2 -> layer_0_attn_allreduce_group1
	layer_0_attn_out_gpu3 -> layer_0_attn_allreduce_group1
	layer_0_attn_out_gpu4 -> layer_0_attn_allreduce_group2
	layer_0_attn_out_gpu5 -> layer_0_attn_allreduce_group2
	layer_0_attn_out_gpu6 -> layer_0_attn_allreduce_group3
	layer_0_attn_out_gpu7 -> layer_0_attn_allreduce_group3
	layer_0_attn_out_gpu8 -> layer_0_attn_allreduce_group4
	layer_0_attn_out_gpu9 -> layer_0_attn_allreduce_group4
	layer_0_attn_out_gpu10 -> layer_0_attn_allreduce_group5
	layer_0_attn_out_gpu11 -> layer_0_attn_allreduce_group5
	layer_0_attn_out_gpu12 -> layer_0_attn_allreduce_group6
	layer_0_attn_out_gpu13 -> layer_0_attn_allreduce_group6
	layer_0_attn_out_gpu14 -> layer_0_attn_allreduce_group7
	layer_0_attn_out_gpu15 -> layer_0_attn_allreduce_group7
	layer_0_attn_out_gpu16 -> layer_0_attn_allreduce_group8
	layer_0_attn_out_gpu17 -> layer_0_attn_allreduce_group8
	layer_0_attn_out_gpu18 -> layer_0_attn_allreduce_group9
	layer_0_attn_out_gpu19 -> layer_0_attn_allreduce_group9
	layer_0_attn_out_gpu20 -> layer_0_attn_allreduce_group10
	layer_0_attn_out_gpu21 -> layer_0_attn_allreduce_group10
	layer_0_attn_out_gpu22 -> layer_0_attn_allreduce_group11
	layer_0_attn_out_gpu23 -> layer_0_attn_allreduce_group11
	layer_0_attn_out_gpu24 -> layer_0_attn_allreduce_group12
	layer_0_attn_out_gpu25 -> layer_0_attn_allreduce_group12
	layer_0_attn_out_gpu26 -> layer_0_attn_allreduce_group13
	layer_0_attn_out_gpu27 -> layer_0_attn_allreduce_group13
	layer_0_attn_out_gpu28 -> layer_0_attn_allreduce_group14
	layer_0_attn_out_gpu29 -> layer_0_attn_allreduce_group14
	layer_0_attn_out_gpu30 -> layer_0_attn_allreduce_group15
	layer_0_attn_out_gpu31 -> layer_0_attn_allreduce_group15
	layer_0_attn_out_gpu32 -> layer_0_attn_allreduce_group16
	layer_0_attn_out_gpu33 -> layer_0_attn_allreduce_group16
	layer_0_attn_out_gpu34 -> layer_0_attn_allreduce_group17
	layer_0_attn_out_gpu35 -> layer_0_attn_allreduce_group17
	layer_0_attn_out_gpu36 -> layer_0_attn_allreduce_group18
	layer_0_attn_out_gpu37 -> layer_0_attn_allreduce_group18
	layer_0_attn_out_gpu38 -> layer_0_attn_allreduce_group19
	layer_0_attn_out_gpu39 -> layer_0_attn_allreduce_group19
	layer_0_attn_out_gpu40 -> layer_0_attn_allreduce_group20
	layer_0_attn_out_gpu41 -> layer_0_attn_allreduce_group20
	layer_0_attn_out_gpu42 -> layer_0_attn_allreduce_group21
	layer_0_attn_out_gpu43 -> layer_0_attn_allreduce_group21
	layer_0_attn_out_gpu44 -> layer_0_attn_allreduce_group22
	layer_0_attn_out_gpu45 -> layer_0_attn_allreduce_group22
	layer_0_attn_out_gpu46 -> layer_0_attn_allreduce_group23
	layer_0_attn_out_gpu47 -> layer_0_attn_allreduce_group23
	layer_0_attn_out_gpu48 -> layer_0_attn_allreduce_group24
	layer_0_attn_out_gpu49 -> layer_0_attn_allreduce_group24
	layer_0_attn_out_gpu50 -> layer_0_attn_allreduce_group25
	layer_0_attn_out_gpu51 -> layer_0_attn_allreduce_group25
	layer_0_attn_out_gpu52 -> layer_0_attn_allreduce_group26
	layer_0_attn_out_gpu53 -> layer_0_attn_allreduce_group26
	layer_0_attn_out_gpu54 -> layer_0_attn_allreduce_group27
	layer_0_attn_out_gpu55 -> layer_0_attn_allreduce_group27
	layer_0_attn_out_gpu56 -> layer_0_attn_allreduce_group28
	layer_0_attn_out_gpu57 -> layer_0_attn_allreduce_group28
	layer_0_attn_out_gpu58 -> layer_0_attn_allreduce_group29
	layer_0_attn_out_gpu59 -> layer_0_attn_allreduce_group29
	layer_0_attn_out_gpu60 -> layer_0_attn_allreduce_group30
	layer_0_attn_out_gpu61 -> layer_0_attn_allreduce_group30
	layer_0_attn_out_gpu62 -> layer_0_attn_allreduce_group31
	layer_0_attn_out_gpu63 -> layer_0_attn_allreduce_group31
	layer_0_attn_out_gpu64 -> layer_0_attn_allreduce_group32
	layer_0_attn_out_gpu65 -> layer_0_attn_allreduce_group32
	layer_0_attn_out_gpu66 -> layer_0_attn_allreduce_group33
	layer_0_attn_out_gpu67 -> layer_0_attn_allreduce_group33
	layer_0_attn_out_gpu68 -> layer_0_attn_allreduce_group34
	layer_0_attn_out_gpu69 -> layer_0_attn_allreduce_group34
	layer_0_attn_out_gpu70 -> layer_0_attn_allreduce_group35
	layer_0_attn_out_gpu71 -> layer_0_attn_allreduce_group35
	layer_0_attn_out_gpu72 -> layer_0_attn_allreduce_group36
	layer_0_attn_out_gpu73 -> layer_0_attn_allreduce_group36
	layer_0_attn_out_gpu74 -> layer_0_attn_allreduce_group37
	layer_0_attn_out_gpu75 -> layer_0_attn_allreduce_group37
	layer_0_attn_out_gpu76 -> layer_0_attn_allreduce_group38
	layer_0_attn_out_gpu77 -> layer_0_attn_allreduce_group38
	layer_0_attn_out_gpu78 -> layer_0_attn_allreduce_group39
	layer_0_attn_out_gpu79 -> layer_0_attn_allreduce_group39
	layer_0_attn_out_gpu80 -> layer_0_attn_allreduce_group40
	layer_0_attn_out_gpu81 -> layer_0_attn_allreduce_group40
	layer_0_attn_out_gpu82 -> layer_0_attn_allreduce_group41
	layer_0_attn_out_gpu83 -> layer_0_attn_allreduce_group41
	layer_0_attn_out_gpu84 -> layer_0_attn_allreduce_group42
	layer_0_attn_out_gpu85 -> layer_0_attn_allreduce_group42
	layer_0_attn_out_gpu86 -> layer_0_attn_allreduce_group43
	layer_0_attn_out_gpu87 -> layer_0_attn_allreduce_group43
	layer_0_attn_out_gpu88 -> layer_0_attn_allreduce_group44
	layer_0_attn_out_gpu89 -> layer_0_attn_allreduce_group44
	layer_0_attn_out_gpu90 -> layer_0_attn_allreduce_group45
	layer_0_attn_out_gpu91 -> layer_0_attn_allreduce_group45
	layer_0_attn_out_gpu92 -> layer_0_attn_allreduce_group46
	layer_0_attn_out_gpu93 -> layer_0_attn_allreduce_group46
	layer_0_attn_out_gpu94 -> layer_0_attn_allreduce_group47
	layer_0_attn_out_gpu95 -> layer_0_attn_allreduce_group47
	layer_0_attn_out_gpu96 -> layer_0_attn_allreduce_group48
	layer_0_attn_out_gpu97 -> layer_0_attn_allreduce_group48
	layer_0_attn_out_gpu98 -> layer_0_attn_allreduce_group49
	layer_0_attn_out_gpu99 -> layer_0_attn_allreduce_group49
	layer_0_attn_out_gpu100 -> layer_0_attn_allreduce_group50
	layer_0_attn_out_gpu101 -> layer_0_attn_allreduce_group50
	layer_0_attn_out_gpu102 -> layer_0_attn_allreduce_group51
	layer_0_attn_out_gpu103 -> layer_0_attn_allreduce_group51
	layer_0_attn_out_gpu104 -> layer_0_attn_allreduce_group52
	layer_0_attn_out_gpu105 -> layer_0_attn_allreduce_group52
	layer_0_attn_out_gpu106 -> layer_0_attn_allreduce_group53
	layer_0_attn_out_gpu107 -> layer_0_attn_allreduce_group53
	layer_0_attn_out_gpu108 -> layer_0_attn_allreduce_group54
	layer_0_attn_out_gpu109 -> layer_0_attn_allreduce_group54
	layer_0_attn_out_gpu110 -> layer_0_attn_allreduce_group55
	layer_0_attn_out_gpu111 -> layer_0_attn_allreduce_group55
	layer_0_attn_out_gpu112 -> layer_0_attn_allreduce_group56
	layer_0_attn_out_gpu113 -> layer_0_attn_allreduce_group56
	layer_0_attn_out_gpu114 -> layer_0_attn_allreduce_group57
	layer_0_attn_out_gpu115 -> layer_0_attn_allreduce_group57
	layer_0_attn_out_gpu116 -> layer_0_attn_allreduce_group58
	layer_0_attn_out_gpu117 -> layer_0_attn_allreduce_group58
	layer_0_attn_out_gpu118 -> layer_0_attn_allreduce_group59
	layer_0_attn_out_gpu119 -> layer_0_attn_allreduce_group59
	layer_0_attn_out_gpu120 -> layer_0_attn_allreduce_group60
	layer_0_attn_out_gpu121 -> layer_0_attn_allreduce_group60
	layer_0_attn_out_gpu122 -> layer_0_attn_allreduce_group61
	layer_0_attn_out_gpu123 -> layer_0_attn_allreduce_group61
	layer_0_attn_out_gpu124 -> layer_0_attn_allreduce_group62
	layer_0_attn_out_gpu125 -> layer_0_attn_allreduce_group62
	layer_0_attn_out_gpu126 -> layer_0_attn_allreduce_group63
	layer_0_attn_out_gpu127 -> layer_0_attn_allreduce_group63
	layer_0_attn_allreduce_group0 -> layer_0_residual1_gpu0
	input -> layer_0_residual1_gpu0
	layer_0_attn_allreduce_group0 -> layer_0_residual1_gpu1
	input -> layer_0_residual1_gpu1
	layer_0_attn_allreduce_group1 -> layer_0_residual1_gpu2
	input -> layer_0_residual1_gpu2
	layer_0_attn_allreduce_group1 -> layer_0_residual1_gpu3
	input -> layer_0_residual1_gpu3
	layer_0_attn_allreduce_group2 -> layer_0_residual1_gpu4
	input -> layer_0_residual1_gpu4
	layer_0_attn_allreduce_group2 -> layer_0_residual1_gpu5
	input -> layer_0_residual1_gpu5
	layer_0_attn_allreduce_group3 -> layer_0_residual1_gpu6
	input -> layer_0_residual1_gpu6
	layer_0_attn_allreduce_group3 -> layer_0_residual1_gpu7
	input -> layer_0_residual1_gpu7
	layer_0_attn_allreduce_group4 -> layer_0_residual1_gpu8
	input -> layer_0_residual1_gpu8
	layer_0_attn_allreduce_group4 -> layer_0_residual1_gpu9
	input -> layer_0_residual1_gpu9
	layer_0_attn_allreduce_group5 -> layer_0_residual1_gpu10
	input -> layer_0_residual1_gpu10
	layer_0_attn_allreduce_group5 -> layer_0_residual1_gpu11
	input -> layer_0_residual1_gpu11
	layer_0_attn_allreduce_group6 -> layer_0_residual1_gpu12
	input -> layer_0_residual1_gpu12
	layer_0_attn_allreduce_group6 -> layer_0_residual1_gpu13
	input -> layer_0_residual1_gpu13
	layer_0_attn_allreduce_group7 -> layer_0_residual1_gpu14
	input -> layer_0_residual1_gpu14
	layer_0_attn_allreduce_group7 -> layer_0_residual1_gpu15
	input -> layer_0_residual1_gpu15
	layer_0_attn_allreduce_group8 -> layer_0_residual1_gpu16
	input -> layer_0_residual1_gpu16
	layer_0_attn_allreduce_group8 -> layer_0_residual1_gpu17
	input -> layer_0_residual1_gpu17
	layer_0_attn_allreduce_group9 -> layer_0_residual1_gpu18
	input -> layer_0_residual1_gpu18
	layer_0_attn_allreduce_group9 -> layer_0_residual1_gpu19
	input -> layer_0_residual1_gpu19
	layer_0_attn_allreduce_group10 -> layer_0_residual1_gpu20
	input -> layer_0_residual1_gpu20
	layer_0_attn_allreduce_group10 -> layer_0_residual1_gpu21
	input -> layer_0_residual1_gpu21
	layer_0_attn_allreduce_group11 -> layer_0_residual1_gpu22
	input -> layer_0_residual1_gpu22
	layer_0_attn_allreduce_group11 -> layer_0_residual1_gpu23
	input -> layer_0_residual1_gpu23
	layer_0_attn_allreduce_group12 -> layer_0_residual1_gpu24
	input -> layer_0_residual1_gpu24
	layer_0_attn_allreduce_group12 -> layer_0_residual1_gpu25
	input -> layer_0_residual1_gpu25
	layer_0_attn_allreduce_group13 -> layer_0_residual1_gpu26
	input -> layer_0_residual1_gpu26
	layer_0_attn_allreduce_group13 -> layer_0_residual1_gpu27
	input -> layer_0_residual1_gpu27
	layer_0_attn_allreduce_group14 -> layer_0_residual1_gpu28
	input -> layer_0_residual1_gpu28
	layer_0_attn_allreduce_group14 -> layer_0_residual1_gpu29
	input -> layer_0_residual1_gpu29
	layer_0_attn_allreduce_group15 -> layer_0_residual1_gpu30
	input -> layer_0_residual1_gpu30
	layer_0_attn_allreduce_group15 -> layer_0_residual1_gpu31
	input -> layer_0_residual1_gpu31
	layer_0_attn_allreduce_group16 -> layer_0_residual1_gpu32
	input -> layer_0_residual1_gpu32
	layer_0_attn_allreduce_group16 -> layer_0_residual1_gpu33
	input -> layer_0_residual1_gpu33
	layer_0_attn_allreduce_group17 -> layer_0_residual1_gpu34
	input -> layer_0_residual1_gpu34
	layer_0_attn_allreduce_group17 -> layer_0_residual1_gpu35
	input -> layer_0_residual1_gpu35
	layer_0_attn_allreduce_group18 -> layer_0_residual1_gpu36
	input -> layer_0_residual1_gpu36
	layer_0_attn_allreduce_group18 -> layer_0_residual1_gpu37
	input -> layer_0_residual1_gpu37
	layer_0_attn_allreduce_group19 -> layer_0_residual1_gpu38
	input -> layer_0_residual1_gpu38
	layer_0_attn_allreduce_group19 -> layer_0_residual1_gpu39
	input -> layer_0_residual1_gpu39
	layer_0_attn_allreduce_group20 -> layer_0_residual1_gpu40
	input -> layer_0_residual1_gpu40
	layer_0_attn_allreduce_group20 -> layer_0_residual1_gpu41
	input -> layer_0_residual1_gpu41
	layer_0_attn_allreduce_group21 -> layer_0_residual1_gpu42
	input -> layer_0_residual1_gpu42
	layer_0_attn_allreduce_group21 -> layer_0_residual1_gpu43
	input -> layer_0_residual1_gpu43
	layer_0_attn_allreduce_group22 -> layer_0_residual1_gpu44
	input -> layer_0_residual1_gpu44
	layer_0_attn_allreduce_group22 -> layer_0_residual1_gpu45
	input -> layer_0_residual1_gpu45
	layer_0_attn_allreduce_group23 -> layer_0_residual1_gpu46
	input -> layer_0_residual1_gpu46
	layer_0_attn_allreduce_group23 -> layer_0_residual1_gpu47
	input -> layer_0_residual1_gpu47
	layer_0_attn_allreduce_group24 -> layer_0_residual1_gpu48
	input -> layer_0_residual1_gpu48
	layer_0_attn_allreduce_group24 -> layer_0_residual1_gpu49
	input -> layer_0_residual1_gpu49
	layer_0_attn_allreduce_group25 -> layer_0_residual1_gpu50
	input -> layer_0_residual1_gpu50
	layer_0_attn_allreduce_group25 -> layer_0_residual1_gpu51
	input -> layer_0_residual1_gpu51
	layer_0_attn_allreduce_group26 -> layer_0_residual1_gpu52
	input -> layer_0_residual1_gpu52
	layer_0_attn_allreduce_group26 -> layer_0_residual1_gpu53
	input -> layer_0_residual1_gpu53
	layer_0_attn_allreduce_group27 -> layer_0_residual1_gpu54
	input -> layer_0_residual1_gpu54
	layer_0_attn_allreduce_group27 -> layer_0_residual1_gpu55
	input -> layer_0_residual1_gpu55
	layer_0_attn_allreduce_group28 -> layer_0_residual1_gpu56
	input -> layer_0_residual1_gpu56
	layer_0_attn_allreduce_group28 -> layer_0_residual1_gpu57
	input -> layer_0_residual1_gpu57
	layer_0_attn_allreduce_group29 -> layer_0_residual1_gpu58
	input -> layer_0_residual1_gpu58
	layer_0_attn_allreduce_group29 -> layer_0_residual1_gpu59
	input -> layer_0_residual1_gpu59
	layer_0_attn_allreduce_group30 -> layer_0_residual1_gpu60
	input -> layer_0_residual1_gpu60
	layer_0_attn_allreduce_group30 -> layer_0_residual1_gpu61
	input -> layer_0_residual1_gpu61
	layer_0_attn_allreduce_group31 -> layer_0_residual1_gpu62
	input -> layer_0_residual1_gpu62
	layer_0_attn_allreduce_group31 -> layer_0_residual1_gpu63
	input -> layer_0_residual1_gpu63
	layer_0_attn_allreduce_group32 -> layer_0_residual1_gpu64
	input -> layer_0_residual1_gpu64
	layer_0_attn_allreduce_group32 -> layer_0_residual1_gpu65
	input -> layer_0_residual1_gpu65
	layer_0_attn_allreduce_group33 -> layer_0_residual1_gpu66
	input -> layer_0_residual1_gpu66
	layer_0_attn_allreduce_group33 -> layer_0_residual1_gpu67
	input -> layer_0_residual1_gpu67
	layer_0_attn_allreduce_group34 -> layer_0_residual1_gpu68
	input -> layer_0_residual1_gpu68
	layer_0_attn_allreduce_group34 -> layer_0_residual1_gpu69
	input -> layer_0_residual1_gpu69
	layer_0_attn_allreduce_group35 -> layer_0_residual1_gpu70
	input -> layer_0_residual1_gpu70
	layer_0_attn_allreduce_group35 -> layer_0_residual1_gpu71
	input -> layer_0_residual1_gpu71
	layer_0_attn_allreduce_group36 -> layer_0_residual1_gpu72
	input -> layer_0_residual1_gpu72
	layer_0_attn_allreduce_group36 -> layer_0_residual1_gpu73
	input -> layer_0_residual1_gpu73
	layer_0_attn_allreduce_group37 -> layer_0_residual1_gpu74
	input -> layer_0_residual1_gpu74
	layer_0_attn_allreduce_group37 -> layer_0_residual1_gpu75
	input -> layer_0_residual1_gpu75
	layer_0_attn_allreduce_group38 -> layer_0_residual1_gpu76
	input -> layer_0_residual1_gpu76
	layer_0_attn_allreduce_group38 -> layer_0_residual1_gpu77
	input -> layer_0_residual1_gpu77
	layer_0_attn_allreduce_group39 -> layer_0_residual1_gpu78
	input -> layer_0_residual1_gpu78
	layer_0_attn_allreduce_group39 -> layer_0_residual1_gpu79
	input -> layer_0_residual1_gpu79
	layer_0_attn_allreduce_group40 -> layer_0_residual1_gpu80
	input -> layer_0_residual1_gpu80
	layer_0_attn_allreduce_group40 -> layer_0_residual1_gpu81
	input -> layer_0_residual1_gpu81
	layer_0_attn_allreduce_group41 -> layer_0_residual1_gpu82
	input -> layer_0_residual1_gpu82
	layer_0_attn_allreduce_group41 -> layer_0_residual1_gpu83
	input -> layer_0_residual1_gpu83
	layer_0_attn_allreduce_group42 -> layer_0_residual1_gpu84
	input -> layer_0_residual1_gpu84
	layer_0_attn_allreduce_group42 -> layer_0_residual1_gpu85
	input -> layer_0_residual1_gpu85
	layer_0_attn_allreduce_group43 -> layer_0_residual1_gpu86
	input -> layer_0_residual1_gpu86
	layer_0_attn_allreduce_group43 -> layer_0_residual1_gpu87
	input -> layer_0_residual1_gpu87
	layer_0_attn_allreduce_group44 -> layer_0_residual1_gpu88
	input -> layer_0_residual1_gpu88
	layer_0_attn_allreduce_group44 -> layer_0_residual1_gpu89
	input -> layer_0_residual1_gpu89
	layer_0_attn_allreduce_group45 -> layer_0_residual1_gpu90
	input -> layer_0_residual1_gpu90
	layer_0_attn_allreduce_group45 -> layer_0_residual1_gpu91
	input -> layer_0_residual1_gpu91
	layer_0_attn_allreduce_group46 -> layer_0_residual1_gpu92
	input -> layer_0_residual1_gpu92
	layer_0_attn_allreduce_group46 -> layer_0_residual1_gpu93
	input -> layer_0_residual1_gpu93
	layer_0_attn_allreduce_group47 -> layer_0_residual1_gpu94
	input -> layer_0_residual1_gpu94
	layer_0_attn_allreduce_group47 -> layer_0_residual1_gpu95
	input -> layer_0_residual1_gpu95
	layer_0_attn_allreduce_group48 -> layer_0_residual1_gpu96
	input -> layer_0_residual1_gpu96
	layer_0_attn_allreduce_group48 -> layer_0_residual1_gpu97
	input -> layer_0_residual1_gpu97
	layer_0_attn_allreduce_group49 -> layer_0_residual1_gpu98
	input -> layer_0_residual1_gpu98
	layer_0_attn_allreduce_group49 -> layer_0_residual1_gpu99
	input -> layer_0_residual1_gpu99
	layer_0_attn_allreduce_group50 -> layer_0_residual1_gpu100
	input -> layer_0_residual1_gpu100
	layer_0_attn_allreduce_group50 -> layer_0_residual1_gpu101
	input -> layer_0_residual1_gpu101
	layer_0_attn_allreduce_group51 -> layer_0_residual1_gpu102
	input -> layer_0_residual1_gpu102
	layer_0_attn_allreduce_group51 -> layer_0_residual1_gpu103
	input -> layer_0_residual1_gpu103
	layer_0_attn_allreduce_group52 -> layer_0_residual1_gpu104
	input -> layer_0_residual1_gpu104
	layer_0_attn_allreduce_group52 -> layer_0_residual1_gpu105
	input -> layer_0_residual1_gpu105
	layer_0_attn_allreduce_group53 -> layer_0_residual1_gpu106
	input -> layer_0_residual1_gpu106
	layer_0_attn_allreduce_group53 -> layer_0_residual1_gpu107
	input -> layer_0_residual1_gpu107
	layer_0_attn_allreduce_group54 -> layer_0_residual1_gpu108
	input -> layer_0_residual1_gpu108
	layer_0_attn_allreduce_group54 -> layer_0_residual1_gpu109
	input -> layer_0_residual1_gpu109
	layer_0_attn_allreduce_group55 -> layer_0_residual1_gpu110
	input -> layer_0_residual1_gpu110
	layer_0_attn_allreduce_group55 -> layer_0_residual1_gpu111
	input -> layer_0_residual1_gpu111
	layer_0_attn_allreduce_group56 -> layer_0_residual1_gpu112
	input -> layer_0_residual1_gpu112
	layer_0_attn_allreduce_group56 -> layer_0_residual1_gpu113
	input -> layer_0_residual1_gpu113
	layer_0_attn_allreduce_group57 -> layer_0_residual1_gpu114
	input -> layer_0_residual1_gpu114
	layer_0_attn_allreduce_group57 -> layer_0_residual1_gpu115
	input -> layer_0_residual1_gpu115
	layer_0_attn_allreduce_group58 -> layer_0_residual1_gpu116
	input -> layer_0_residual1_gpu116
	layer_0_attn_allreduce_group58 -> layer_0_residual1_gpu117
	input -> layer_0_residual1_gpu117
	layer_0_attn_allreduce_group59 -> layer_0_residual1_gpu118
	input -> layer_0_residual1_gpu118
	layer_0_attn_allreduce_group59 -> layer_0_residual1_gpu119
	input -> layer_0_residual1_gpu119
	layer_0_attn_allreduce_group60 -> layer_0_residual1_gpu120
	input -> layer_0_residual1_gpu120
	layer_0_attn_allreduce_group60 -> layer_0_residual1_gpu121
	input -> layer_0_residual1_gpu121
	layer_0_attn_allreduce_group61 -> layer_0_residual1_gpu122
	input -> layer_0_residual1_gpu122
	layer_0_attn_allreduce_group61 -> layer_0_residual1_gpu123
	input -> layer_0_residual1_gpu123
	layer_0_attn_allreduce_group62 -> layer_0_residual1_gpu124
	input -> layer_0_residual1_gpu124
	layer_0_attn_allreduce_group62 -> layer_0_residual1_gpu125
	input -> layer_0_residual1_gpu125
	layer_0_attn_allreduce_group63 -> layer_0_residual1_gpu126
	input -> layer_0_residual1_gpu126
	layer_0_attn_allreduce_group63 -> layer_0_residual1_gpu127
	input -> layer_0_residual1_gpu127
	layer_0_residual1_gpu0 -> layer_0_ln2_gpu0
	layer_0_residual1_gpu1 -> layer_0_ln2_gpu1
	layer_0_residual1_gpu2 -> layer_0_ln2_gpu2
	layer_0_residual1_gpu3 -> layer_0_ln2_gpu3
	layer_0_residual1_gpu4 -> layer_0_ln2_gpu4
	layer_0_residual1_gpu5 -> layer_0_ln2_gpu5
	layer_0_residual1_gpu6 -> layer_0_ln2_gpu6
	layer_0_residual1_gpu7 -> layer_0_ln2_gpu7
	layer_0_residual1_gpu8 -> layer_0_ln2_gpu8
	layer_0_residual1_gpu9 -> layer_0_ln2_gpu9
	layer_0_residual1_gpu10 -> layer_0_ln2_gpu10
	layer_0_residual1_gpu11 -> layer_0_ln2_gpu11
	layer_0_residual1_gpu12 -> layer_0_ln2_gpu12
	layer_0_residual1_gpu13 -> layer_0_ln2_gpu13
	layer_0_residual1_gpu14 -> layer_0_ln2_gpu14
	layer_0_residual1_gpu15 -> layer_0_ln2_gpu15
	layer_0_residual1_gpu16 -> layer_0_ln2_gpu16
	layer_0_residual1_gpu17 -> layer_0_ln2_gpu17
	layer_0_residual1_gpu18 -> layer_0_ln2_gpu18
	layer_0_residual1_gpu19 -> layer_0_ln2_gpu19
	layer_0_residual1_gpu20 -> layer_0_ln2_gpu20
	layer_0_residual1_gpu21 -> layer_0_ln2_gpu21
	layer_0_residual1_gpu22 -> layer_0_ln2_gpu22
	layer_0_residual1_gpu23 -> layer_0_ln2_gpu23
	layer_0_residual1_gpu24 -> layer_0_ln2_gpu24
	layer_0_residual1_gpu25 -> layer_0_ln2_gpu25
	layer_0_residual1_gpu26 -> layer_0_ln2_gpu26
	layer_0_residual1_gpu27 -> layer_0_ln2_gpu27
	layer_0_residual1_gpu28 -> layer_0_ln2_gpu28
	layer_0_residual1_gpu29 -> layer_0_ln2_gpu29
	layer_0_residual1_gpu30 -> layer_0_ln2_gpu30
	layer_0_residual1_gpu31 -> layer_0_ln2_gpu31
	layer_0_residual1_gpu32 -> layer_0_ln2_gpu32
	layer_0_residual1_gpu33 -> layer_0_ln2_gpu33
	layer_0_residual1_gpu34 -> layer_0_ln2_gpu34
	layer_0_residual1_gpu35 -> layer_0_ln2_gpu35
	layer_0_residual1_gpu36 -> layer_0_ln2_gpu36
	layer_0_residual1_gpu37 -> layer_0_ln2_gpu37
	layer_0_residual1_gpu38 -> layer_0_ln2_gpu38
	layer_0_residual1_gpu39 -> layer_0_ln2_gpu39
	layer_0_residual1_gpu40 -> layer_0_ln2_gpu40
	layer_0_residual1_gpu41 -> layer_0_ln2_gpu41
	layer_0_residual1_gpu42 -> layer_0_ln2_gpu42
	layer_0_residual1_gpu43 -> layer_0_ln2_gpu43
	layer_0_residual1_gpu44 -> layer_0_ln2_gpu44
	layer_0_residual1_gpu45 -> layer_0_ln2_gpu45
	layer_0_residual1_gpu46 -> layer_0_ln2_gpu46
	layer_0_residual1_gpu47 -> layer_0_ln2_gpu47
	layer_0_residual1_gpu48 -> layer_0_ln2_gpu48
	layer_0_residual1_gpu49 -> layer_0_ln2_gpu49
	layer_0_residual1_gpu50 -> layer_0_ln2_gpu50
	layer_0_residual1_gpu51 -> layer_0_ln2_gpu51
	layer_0_residual1_gpu52 -> layer_0_ln2_gpu52
	layer_0_residual1_gpu53 -> layer_0_ln2_gpu53
	layer_0_residual1_gpu54 -> layer_0_ln2_gpu54
	layer_0_residual1_gpu55 -> layer_0_ln2_gpu55
	layer_0_residual1_gpu56 -> layer_0_ln2_gpu56
	layer_0_residual1_gpu57 -> layer_0_ln2_gpu57
	layer_0_residual1_gpu58 -> layer_0_ln2_gpu58
	layer_0_residual1_gpu59 -> layer_0_ln2_gpu59
	layer_0_residual1_gpu60 -> layer_0_ln2_gpu60
	layer_0_residual1_gpu61 -> layer_0_ln2_gpu61
	layer_0_residual1_gpu62 -> layer_0_ln2_gpu62
	layer_0_residual1_gpu63 -> layer_0_ln2_gpu63
	layer_0_residual1_gpu64 -> layer_0_ln2_gpu64
	layer_0_residual1_gpu65 -> layer_0_ln2_gpu65
	layer_0_residual1_gpu66 -> layer_0_ln2_gpu66
	layer_0_residual1_gpu67 -> layer_0_ln2_gpu67
	layer_0_residual1_gpu68 -> layer_0_ln2_gpu68
	layer_0_residual1_gpu69 -> layer_0_ln2_gpu69
	layer_0_residual1_gpu70 -> layer_0_ln2_gpu70
	layer_0_residual1_gpu71 -> layer_0_ln2_gpu71
	layer_0_residual1_gpu72 -> layer_0_ln2_gpu72
	layer_0_residual1_gpu73 -> layer_0_ln2_gpu73
	layer_0_residual1_gpu74 -> layer_0_ln2_gpu74
	layer_0_residual1_gpu75 -> layer_0_ln2_gpu75
	layer_0_residual1_gpu76 -> layer_0_ln2_gpu76
	layer_0_residual1_gpu77 -> layer_0_ln2_gpu77
	layer_0_residual1_gpu78 -> layer_0_ln2_gpu78
	layer_0_residual1_gpu79 -> layer_0_ln2_gpu79
	layer_0_residual1_gpu80 -> layer_0_ln2_gpu80
	layer_0_residual1_gpu81 -> layer_0_ln2_gpu81
	layer_0_residual1_gpu82 -> layer_0_ln2_gpu82
	layer_0_residual1_gpu83 -> layer_0_ln2_gpu83
	layer_0_residual1_gpu84 -> layer_0_ln2_gpu84
	layer_0_residual1_gpu85 -> layer_0_ln2_gpu85
	layer_0_residual1_gpu86 -> layer_0_ln2_gpu86
	layer_0_residual1_gpu87 -> layer_0_ln2_gpu87
	layer_0_residual1_gpu88 -> layer_0_ln2_gpu88
	layer_0_residual1_gpu89 -> layer_0_ln2_gpu89
	layer_0_residual1_gpu90 -> layer_0_ln2_gpu90
	layer_0_residual1_gpu91 -> layer_0_ln2_gpu91
	layer_0_residual1_gpu92 -> layer_0_ln2_gpu92
	layer_0_residual1_gpu93 -> layer_0_ln2_gpu93
	layer_0_residual1_gpu94 -> layer_0_ln2_gpu94
	layer_0_residual1_gpu95 -> layer_0_ln2_gpu95
	layer_0_residual1_gpu96 -> layer_0_ln2_gpu96
	layer_0_residual1_gpu97 -> layer_0_ln2_gpu97
	layer_0_residual1_gpu98 -> layer_0_ln2_gpu98
	layer_0_residual1_gpu99 -> layer_0_ln2_gpu99
	layer_0_residual1_gpu100 -> layer_0_ln2_gpu100
	layer_0_residual1_gpu101 -> layer_0_ln2_gpu101
	layer_0_residual1_gpu102 -> layer_0_ln2_gpu102
	layer_0_residual1_gpu103 -> layer_0_ln2_gpu103
	layer_0_residual1_gpu104 -> layer_0_ln2_gpu104
	layer_0_residual1_gpu105 -> layer_0_ln2_gpu105
	layer_0_residual1_gpu106 -> layer_0_ln2_gpu106
	layer_0_residual1_gpu107 -> layer_0_ln2_gpu107
	layer_0_residual1_gpu108 -> layer_0_ln2_gpu108
	layer_0_residual1_gpu109 -> layer_0_ln2_gpu109
	layer_0_residual1_gpu110 -> layer_0_ln2_gpu110
	layer_0_residual1_gpu111 -> layer_0_ln2_gpu111
	layer_0_residual1_gpu112 -> layer_0_ln2_gpu112
	layer_0_residual1_gpu113 -> layer_0_ln2_gpu113
	layer_0_residual1_gpu114 -> layer_0_ln2_gpu114
	layer_0_residual1_gpu115 -> layer_0_ln2_gpu115
	layer_0_residual1_gpu116 -> layer_0_ln2_gpu116
	layer_0_residual1_gpu117 -> layer_0_ln2_gpu117
	layer_0_residual1_gpu118 -> layer_0_ln2_gpu118
	layer_0_residual1_gpu119 -> layer_0_ln2_gpu119
	layer_0_residual1_gpu120 -> layer_0_ln2_gpu120
	layer_0_residual1_gpu121 -> layer_0_ln2_gpu121
	layer_0_residual1_gpu122 -> layer_0_ln2_gpu122
	layer_0_residual1_gpu123 -> layer_0_ln2_gpu123
	layer_0_residual1_gpu124 -> layer_0_ln2_gpu124
	layer_0_residual1_gpu125 -> layer_0_ln2_gpu125
	layer_0_residual1_gpu126 -> layer_0_ln2_gpu126
	layer_0_residual1_gpu127 -> layer_0_ln2_gpu127
	layer_0_ln2_gpu0 -> layer_0_gate_gpu0
	layer_0_ln2_gpu1 -> layer_0_gate_gpu1
	layer_0_ln2_gpu2 -> layer_0_gate_gpu2
	layer_0_ln2_gpu3 -> layer_0_gate_gpu3
	layer_0_ln2_gpu4 -> layer_0_gate_gpu4
	layer_0_ln2_gpu5 -> layer_0_gate_gpu5
	layer_0_ln2_gpu6 -> layer_0_gate_gpu6
	layer_0_ln2_gpu7 -> layer_0_gate_gpu7
	layer_0_ln2_gpu8 -> layer_0_gate_gpu8
	layer_0_ln2_gpu9 -> layer_0_gate_gpu9
	layer_0_ln2_gpu10 -> layer_0_gate_gpu10
	layer_0_ln2_gpu11 -> layer_0_gate_gpu11
	layer_0_ln2_gpu12 -> layer_0_gate_gpu12
	layer_0_ln2_gpu13 -> layer_0_gate_gpu13
	layer_0_ln2_gpu14 -> layer_0_gate_gpu14
	layer_0_ln2_gpu15 -> layer_0_gate_gpu15
	layer_0_ln2_gpu16 -> layer_0_gate_gpu16
	layer_0_ln2_gpu17 -> layer_0_gate_gpu17
	layer_0_ln2_gpu18 -> layer_0_gate_gpu18
	layer_0_ln2_gpu19 -> layer_0_gate_gpu19
	layer_0_ln2_gpu20 -> layer_0_gate_gpu20
	layer_0_ln2_gpu21 -> layer_0_gate_gpu21
	layer_0_ln2_gpu22 -> layer_0_gate_gpu22
	layer_0_ln2_gpu23 -> layer_0_gate_gpu23
	layer_0_ln2_gpu24 -> layer_0_gate_gpu24
	layer_0_ln2_gpu25 -> layer_0_gate_gpu25
	layer_0_ln2_gpu26 -> layer_0_gate_gpu26
	layer_0_ln2_gpu27 -> layer_0_gate_gpu27
	layer_0_ln2_gpu28 -> layer_0_gate_gpu28
	layer_0_ln2_gpu29 -> layer_0_gate_gpu29
	layer_0_ln2_gpu30 -> layer_0_gate_gpu30
	layer_0_ln2_gpu31 -> layer_0_gate_gpu31
	layer_0_ln2_gpu32 -> layer_0_gate_gpu32
	layer_0_ln2_gpu33 -> layer_0_gate_gpu33
	layer_0_ln2_gpu34 -> layer_0_gate_gpu34
	layer_0_ln2_gpu35 -> layer_0_gate_gpu35
	layer_0_ln2_gpu36 -> layer_0_gate_gpu36
	layer_0_ln2_gpu37 -> layer_0_gate_gpu37
	layer_0_ln2_gpu38 -> layer_0_gate_gpu38
	layer_0_ln2_gpu39 -> layer_0_gate_gpu39
	layer_0_ln2_gpu40 -> layer_0_gate_gpu40
	layer_0_ln2_gpu41 -> layer_0_gate_gpu41
	layer_0_ln2_gpu42 -> layer_0_gate_gpu42
	layer_0_ln2_gpu43 -> layer_0_gate_gpu43
	layer_0_ln2_gpu44 -> layer_0_gate_gpu44
	layer_0_ln2_gpu45 -> layer_0_gate_gpu45
	layer_0_ln2_gpu46 -> layer_0_gate_gpu46
	layer_0_ln2_gpu47 -> layer_0_gate_gpu47
	layer_0_ln2_gpu48 -> layer_0_gate_gpu48
	layer_0_ln2_gpu49 -> layer_0_gate_gpu49
	layer_0_ln2_gpu50 -> layer_0_gate_gpu50
	layer_0_ln2_gpu51 -> layer_0_gate_gpu51
	layer_0_ln2_gpu52 -> layer_0_gate_gpu52
	layer_0_ln2_gpu53 -> layer_0_gate_gpu53
	layer_0_ln2_gpu54 -> layer_0_gate_gpu54
	layer_0_ln2_gpu55 -> layer_0_gate_gpu55
	layer_0_ln2_gpu56 -> layer_0_gate_gpu56
	layer_0_ln2_gpu57 -> layer_0_gate_gpu57
	layer_0_ln2_gpu58 -> layer_0_gate_gpu58
	layer_0_ln2_gpu59 -> layer_0_gate_gpu59
	layer_0_ln2_gpu60 -> layer_0_gate_gpu60
	layer_0_ln2_gpu61 -> layer_0_gate_gpu61
	layer_0_ln2_gpu62 -> layer_0_gate_gpu62
	layer_0_ln2_gpu63 -> layer_0_gate_gpu63
	layer_0_ln2_gpu64 -> layer_0_gate_gpu64
	layer_0_ln2_gpu65 -> layer_0_gate_gpu65
	layer_0_ln2_gpu66 -> layer_0_gate_gpu66
	layer_0_ln2_gpu67 -> layer_0_gate_gpu67
	layer_0_ln2_gpu68 -> layer_0_gate_gpu68
	layer_0_ln2_gpu69 -> layer_0_gate_gpu69
	layer_0_ln2_gpu70 -> layer_0_gate_gpu70
	layer_0_ln2_gpu71 -> layer_0_gate_gpu71
	layer_0_ln2_gpu72 -> layer_0_gate_gpu72
	layer_0_ln2_gpu73 -> layer_0_gate_gpu73
	layer_0_ln2_gpu74 -> layer_0_gate_gpu74
	layer_0_ln2_gpu75 -> layer_0_gate_gpu75
	layer_0_ln2_gpu76 -> layer_0_gate_gpu76
	layer_0_ln2_gpu77 -> layer_0_gate_gpu77
	layer_0_ln2_gpu78 -> layer_0_gate_gpu78
	layer_0_ln2_gpu79 -> layer_0_gate_gpu79
	layer_0_ln2_gpu80 -> layer_0_gate_gpu80
	layer_0_ln2_gpu81 -> layer_0_gate_gpu81
	layer_0_ln2_gpu82 -> layer_0_gate_gpu82
	layer_0_ln2_gpu83 -> layer_0_gate_gpu83
	layer_0_ln2_gpu84 -> layer_0_gate_gpu84
	layer_0_ln2_gpu85 -> layer_0_gate_gpu85
	layer_0_ln2_gpu86 -> layer_0_gate_gpu86
	layer_0_ln2_gpu87 -> layer_0_gate_gpu87
	layer_0_ln2_gpu88 -> layer_0_gate_gpu88
	layer_0_ln2_gpu89 -> layer_0_gate_gpu89
	layer_0_ln2_gpu90 -> layer_0_gate_gpu90
	layer_0_ln2_gpu91 -> layer_0_gate_gpu91
	layer_0_ln2_gpu92 -> layer_0_gate_gpu92
	layer_0_ln2_gpu93 -> layer_0_gate_gpu93
	layer_0_ln2_gpu94 -> layer_0_gate_gpu94
	layer_0_ln2_gpu95 -> layer_0_gate_gpu95
	layer_0_ln2_gpu96 -> layer_0_gate_gpu96
	layer_0_ln2_gpu97 -> layer_0_gate_gpu97
	layer_0_ln2_gpu98 -> layer_0_gate_gpu98
	layer_0_ln2_gpu99 -> layer_0_gate_gpu99
	layer_0_ln2_gpu100 -> layer_0_gate_gpu100
	layer_0_ln2_gpu101 -> layer_0_gate_gpu101
	layer_0_ln2_gpu102 -> layer_0_gate_gpu102
	layer_0_ln2_gpu103 -> layer_0_gate_gpu103
	layer_0_ln2_gpu104 -> layer_0_gate_gpu104
	layer_0_ln2_gpu105 -> layer_0_gate_gpu105
	layer_0_ln2_gpu106 -> layer_0_gate_gpu106
	layer_0_ln2_gpu107 -> layer_0_gate_gpu107
	layer_0_ln2_gpu108 -> layer_0_gate_gpu108
	layer_0_ln2_gpu109 -> layer_0_gate_gpu109
	layer_0_ln2_gpu110 -> layer_0_gate_gpu110
	layer_0_ln2_gpu111 -> layer_0_gate_gpu111
	layer_0_ln2_gpu112 -> layer_0_gate_gpu112
	layer_0_ln2_gpu113 -> layer_0_gate_gpu113
	layer_0_ln2_gpu114 -> layer_0_gate_gpu114
	layer_0_ln2_gpu115 -> layer_0_gate_gpu115
	layer_0_ln2_gpu116 -> layer_0_gate_gpu116
	layer_0_ln2_gpu117 -> layer_0_gate_gpu117
	layer_0_ln2_gpu118 -> layer_0_gate_gpu118
	layer_0_ln2_gpu119 -> layer_0_gate_gpu119
	layer_0_ln2_gpu120 -> layer_0_gate_gpu120
	layer_0_ln2_gpu121 -> layer_0_gate_gpu121
	layer_0_ln2_gpu122 -> layer_0_gate_gpu122
	layer_0_ln2_gpu123 -> layer_0_gate_gpu123
	layer_0_ln2_gpu124 -> layer_0_gate_gpu124
	layer_0_ln2_gpu125 -> layer_0_gate_gpu125
	layer_0_ln2_gpu126 -> layer_0_gate_gpu126
	layer_0_ln2_gpu127 -> layer_0_gate_gpu127
	layer_0_gate_gpu0 -> layer_0_router_group0 [style=dashed]
	layer_0_gate_gpu1 -> layer_0_router_group0 [style=dashed]
	layer_0_gate_gpu2 -> layer_0_router_group1 [style=dashed]
	layer_0_gate_gpu3 -> layer_0_router_group1 [style=dashed]
	layer_0_gate_gpu4 -> layer_0_router_group2 [style=dashed]
	layer_0_gate_gpu5 -> layer_0_router_group2 [style=dashed]
	layer_0_gate_gpu6 -> layer_0_router_group3 [style=dashed]
	layer_0_gate_gpu7 -> layer_0_router_group3 [style=dashed]
	layer_0_gate_gpu8 -> layer_0_router_group4 [style=dashed]
	layer_0_gate_gpu9 -> layer_0_router_group4 [style=dashed]
	layer_0_gate_gpu10 -> layer_0_router_group5 [style=dashed]
	layer_0_gate_gpu11 -> layer_0_router_group5 [style=dashed]
	layer_0_gate_gpu12 -> layer_0_router_group6 [style=dashed]
	layer_0_gate_gpu13 -> layer_0_router_group6 [style=dashed]
	layer_0_gate_gpu14 -> layer_0_router_group7 [style=dashed]
	layer_0_gate_gpu15 -> layer_0_router_group7 [style=dashed]
	layer_0_gate_gpu16 -> layer_0_router_group8 [style=dashed]
	layer_0_gate_gpu17 -> layer_0_router_group8 [style=dashed]
	layer_0_gate_gpu18 -> layer_0_router_group9 [style=dashed]
	layer_0_gate_gpu19 -> layer_0_router_group9 [style=dashed]
	layer_0_gate_gpu20 -> layer_0_router_group10 [style=dashed]
	layer_0_gate_gpu21 -> layer_0_router_group10 [style=dashed]
	layer_0_gate_gpu22 -> layer_0_router_group11 [style=dashed]
	layer_0_gate_gpu23 -> layer_0_router_group11 [style=dashed]
	layer_0_gate_gpu24 -> layer_0_router_group12 [style=dashed]
	layer_0_gate_gpu25 -> layer_0_router_group12 [style=dashed]
	layer_0_gate_gpu26 -> layer_0_router_group13 [style=dashed]
	layer_0_gate_gpu27 -> layer_0_router_group13 [style=dashed]
	layer_0_gate_gpu28 -> layer_0_router_group14 [style=dashed]
	layer_0_gate_gpu29 -> layer_0_router_group14 [style=dashed]
	layer_0_gate_gpu30 -> layer_0_router_group15 [style=dashed]
	layer_0_gate_gpu31 -> layer_0_router_group15 [style=dashed]
	layer_0_gate_gpu32 -> layer_0_router_group16 [style=dashed]
	layer_0_gate_gpu33 -> layer_0_router_group16 [style=dashed]
	layer_0_gate_gpu34 -> layer_0_router_group17 [style=dashed]
	layer_0_gate_gpu35 -> layer_0_router_group17 [style=dashed]
	layer_0_gate_gpu36 -> layer_0_router_group18 [style=dashed]
	layer_0_gate_gpu37 -> layer_0_router_group18 [style=dashed]
	layer_0_gate_gpu38 -> layer_0_router_group19 [style=dashed]
	layer_0_gate_gpu39 -> layer_0_router_group19 [style=dashed]
	layer_0_gate_gpu40 -> layer_0_router_group20 [style=dashed]
	layer_0_gate_gpu41 -> layer_0_router_group20 [style=dashed]
	layer_0_gate_gpu42 -> layer_0_router_group21 [style=dashed]
	layer_0_gate_gpu43 -> layer_0_router_group21 [style=dashed]
	layer_0_gate_gpu44 -> layer_0_router_group22 [style=dashed]
	layer_0_gate_gpu45 -> layer_0_router_group22 [style=dashed]
	layer_0_gate_gpu46 -> layer_0_router_group23 [style=dashed]
	layer_0_gate_gpu47 -> layer_0_router_group23 [style=dashed]
	layer_0_gate_gpu48 -> layer_0_router_group24 [style=dashed]
	layer_0_gate_gpu49 -> layer_0_router_group24 [style=dashed]
	layer_0_gate_gpu50 -> layer_0_router_group25 [style=dashed]
	layer_0_gate_gpu51 -> layer_0_router_group25 [style=dashed]
	layer_0_gate_gpu52 -> layer_0_router_group26 [style=dashed]
	layer_0_gate_gpu53 -> layer_0_router_group26 [style=dashed]
	layer_0_gate_gpu54 -> layer_0_router_group27 [style=dashed]
	layer_0_gate_gpu55 -> layer_0_router_group27 [style=dashed]
	layer_0_gate_gpu56 -> layer_0_router_group28 [style=dashed]
	layer_0_gate_gpu57 -> layer_0_router_group28 [style=dashed]
	layer_0_gate_gpu58 -> layer_0_router_group29 [style=dashed]
	layer_0_gate_gpu59 -> layer_0_router_group29 [style=dashed]
	layer_0_gate_gpu60 -> layer_0_router_group30 [style=dashed]
	layer_0_gate_gpu61 -> layer_0_router_group30 [style=dashed]
	layer_0_gate_gpu62 -> layer_0_router_group31 [style=dashed]
	layer_0_gate_gpu63 -> layer_0_router_group31 [style=dashed]
	layer_0_gate_gpu64 -> layer_0_router_group32 [style=dashed]
	layer_0_gate_gpu65 -> layer_0_router_group32 [style=dashed]
	layer_0_gate_gpu66 -> layer_0_router_group33 [style=dashed]
	layer_0_gate_gpu67 -> layer_0_router_group33 [style=dashed]
	layer_0_gate_gpu68 -> layer_0_router_group34 [style=dashed]
	layer_0_gate_gpu69 -> layer_0_router_group34 [style=dashed]
	layer_0_gate_gpu70 -> layer_0_router_group35 [style=dashed]
	layer_0_gate_gpu71 -> layer_0_router_group35 [style=dashed]
	layer_0_gate_gpu72 -> layer_0_router_group36 [style=dashed]
	layer_0_gate_gpu73 -> layer_0_router_group36 [style=dashed]
	layer_0_gate_gpu74 -> layer_0_router_group37 [style=dashed]
	layer_0_gate_gpu75 -> layer_0_router_group37 [style=dashed]
	layer_0_gate_gpu76 -> layer_0_router_group38 [style=dashed]
	layer_0_gate_gpu77 -> layer_0_router_group38 [style=dashed]
	layer_0_gate_gpu78 -> layer_0_router_group39 [style=dashed]
	layer_0_gate_gpu79 -> layer_0_router_group39 [style=dashed]
	layer_0_gate_gpu80 -> layer_0_router_group40 [style=dashed]
	layer_0_gate_gpu81 -> layer_0_router_group40 [style=dashed]
	layer_0_gate_gpu82 -> layer_0_router_group41 [style=dashed]
	layer_0_gate_gpu83 -> layer_0_router_group41 [style=dashed]
	layer_0_gate_gpu84 -> layer_0_router_group42 [style=dashed]
	layer_0_gate_gpu85 -> layer_0_router_group42 [style=dashed]
	layer_0_gate_gpu86 -> layer_0_router_group43 [style=dashed]
	layer_0_gate_gpu87 -> layer_0_router_group43 [style=dashed]
	layer_0_gate_gpu88 -> layer_0_router_group44 [style=dashed]
	layer_0_gate_gpu89 -> layer_0_router_group44 [style=dashed]
	layer_0_gate_gpu90 -> layer_0_router_group45 [style=dashed]
	layer_0_gate_gpu91 -> layer_0_router_group45 [style=dashed]
	layer_0_gate_gpu92 -> layer_0_router_group46 [style=dashed]
	layer_0_gate_gpu93 -> layer_0_router_group46 [style=dashed]
	layer_0_gate_gpu94 -> layer_0_router_group47 [style=dashed]
	layer_0_gate_gpu95 -> layer_0_router_group47 [style=dashed]
	layer_0_gate_gpu96 -> layer_0_router_group48 [style=dashed]
	layer_0_gate_gpu97 -> layer_0_router_group48 [style=dashed]
	layer_0_gate_gpu98 -> layer_0_router_group49 [style=dashed]
	layer_0_gate_gpu99 -> layer_0_router_group49 [style=dashed]
	layer_0_gate_gpu100 -> layer_0_router_group50 [style=dashed]
	layer_0_gate_gpu101 -> layer_0_router_group50 [style=dashed]
	layer_0_gate_gpu102 -> layer_0_router_group51 [style=dashed]
	layer_0_gate_gpu103 -> layer_0_router_group51 [style=dashed]
	layer_0_gate_gpu104 -> layer_0_router_group52 [style=dashed]
	layer_0_gate_gpu105 -> layer_0_router_group52 [style=dashed]
	layer_0_gate_gpu106 -> layer_0_router_group53 [style=dashed]
	layer_0_gate_gpu107 -> layer_0_router_group53 [style=dashed]
	layer_0_gate_gpu108 -> layer_0_router_group54 [style=dashed]
	layer_0_gate_gpu109 -> layer_0_router_group54 [style=dashed]
	layer_0_gate_gpu110 -> layer_0_router_group55 [style=dashed]
	layer_0_gate_gpu111 -> layer_0_router_group55 [style=dashed]
	layer_0_gate_gpu112 -> layer_0_router_group56 [style=dashed]
	layer_0_gate_gpu113 -> layer_0_router_group56 [style=dashed]
	layer_0_gate_gpu114 -> layer_0_router_group57 [style=dashed]
	layer_0_gate_gpu115 -> layer_0_router_group57 [style=dashed]
	layer_0_gate_gpu116 -> layer_0_router_group58 [style=dashed]
	layer_0_gate_gpu117 -> layer_0_router_group58 [style=dashed]
	layer_0_gate_gpu118 -> layer_0_router_group59 [style=dashed]
	layer_0_gate_gpu119 -> layer_0_router_group59 [style=dashed]
	layer_0_gate_gpu120 -> layer_0_router_group60 [style=dashed]
	layer_0_gate_gpu121 -> layer_0_router_group60 [style=dashed]
	layer_0_gate_gpu122 -> layer_0_router_group61 [style=dashed]
	layer_0_gate_gpu123 -> layer_0_router_group61 [style=dashed]
	layer_0_gate_gpu124 -> layer_0_router_group62 [style=dashed]
	layer_0_gate_gpu125 -> layer_0_router_group62 [style=dashed]
	layer_0_gate_gpu126 -> layer_0_router_group63 [style=dashed]
	layer_0_gate_gpu127 -> layer_0_router_group63 [style=dashed]
	layer_0_router_group0 -> layer_0_expert1_gpu0
	layer_0_router_group0 -> layer_0_expert1_gpu1
	layer_0_router_group1 -> layer_0_expert1_gpu2
	layer_0_router_group1 -> layer_0_expert1_gpu3
	layer_0_router_group2 -> layer_0_expert1_gpu4
	layer_0_router_group2 -> layer_0_expert1_gpu5
	layer_0_router_group3 -> layer_0_expert1_gpu6
	layer_0_router_group3 -> layer_0_expert1_gpu7
	layer_0_router_group4 -> layer_0_expert1_gpu8
	layer_0_router_group4 -> layer_0_expert1_gpu9
	layer_0_router_group5 -> layer_0_expert1_gpu10
	layer_0_router_group5 -> layer_0_expert1_gpu11
	layer_0_router_group6 -> layer_0_expert1_gpu12
	layer_0_router_group6 -> layer_0_expert1_gpu13
	layer_0_router_group7 -> layer_0_expert1_gpu14
	layer_0_router_group7 -> layer_0_expert1_gpu15
	layer_0_router_group8 -> layer_0_expert1_gpu16
	layer_0_router_group8 -> layer_0_expert1_gpu17
	layer_0_router_group9 -> layer_0_expert1_gpu18
	layer_0_router_group9 -> layer_0_expert1_gpu19
	layer_0_router_group10 -> layer_0_expert1_gpu20
	layer_0_router_group10 -> layer_0_expert1_gpu21
	layer_0_router_group11 -> layer_0_expert1_gpu22
	layer_0_router_group11 -> layer_0_expert1_gpu23
	layer_0_router_group12 -> layer_0_expert1_gpu24
	layer_0_router_group12 -> layer_0_expert1_gpu25
	layer_0_router_group13 -> layer_0_expert1_gpu26
	layer_0_router_group13 -> layer_0_expert1_gpu27
	layer_0_router_group14 -> layer_0_expert1_gpu28
	layer_0_router_group14 -> layer_0_expert1_gpu29
	layer_0_router_group15 -> layer_0_expert1_gpu30
	layer_0_router_group15 -> layer_0_expert1_gpu31
	layer_0_router_group16 -> layer_0_expert1_gpu32
	layer_0_router_group16 -> layer_0_expert1_gpu33
	layer_0_router_group17 -> layer_0_expert1_gpu34
	layer_0_router_group17 -> layer_0_expert1_gpu35
	layer_0_router_group18 -> layer_0_expert1_gpu36
	layer_0_router_group18 -> layer_0_expert1_gpu37
	layer_0_router_group19 -> layer_0_expert1_gpu38
	layer_0_router_group19 -> layer_0_expert1_gpu39
	layer_0_router_group20 -> layer_0_expert1_gpu40
	layer_0_router_group20 -> layer_0_expert1_gpu41
	layer_0_router_group21 -> layer_0_expert1_gpu42
	layer_0_router_group21 -> layer_0_expert1_gpu43
	layer_0_router_group22 -> layer_0_expert1_gpu44
	layer_0_router_group22 -> layer_0_expert1_gpu45
	layer_0_router_group23 -> layer_0_expert1_gpu46
	layer_0_router_group23 -> layer_0_expert1_gpu47
	layer_0_router_group24 -> layer_0_expert1_gpu48
	layer_0_router_group24 -> layer_0_expert1_gpu49
	layer_0_router_group25 -> layer_0_expert1_gpu50
	layer_0_router_group25 -> layer_0_expert1_gpu51
	layer_0_router_group26 -> layer_0_expert1_gpu52
	layer_0_router_group26 -> layer_0_expert1_gpu53
	layer_0_router_group27 -> layer_0_expert1_gpu54
	layer_0_router_group27 -> layer_0_expert1_gpu55
	layer_0_router_group28 -> layer_0_expert1_gpu56
	layer_0_router_group28 -> layer_0_expert1_gpu57
	layer_0_router_group29 -> layer_0_expert1_gpu58
	layer_0_router_group29 -> layer_0_expert1_gpu59
	layer_0_router_group30 -> layer_0_expert1_gpu60
	layer_0_router_group30 -> layer_0_expert1_gpu61
	layer_0_router_group31 -> layer_0_expert1_gpu62
	layer_0_router_group31 -> layer_0_expert1_gpu63
	layer_0_router_group32 -> layer_0_expert1_gpu64
	layer_0_router_group32 -> layer_0_expert1_gpu65
	layer_0_router_group33 -> layer_0_expert1_gpu66
	layer_0_router_group33 -> layer_0_expert1_gpu67
	layer_0_router_group34 -> layer_0_expert1_gpu68
	layer_0_router_group34 -> layer_0_expert1_gpu69
	layer_0_router_group35 -> layer_0_expert1_gpu70
	layer_0_router_group35 -> layer_0_expert1_gpu71
	layer_0_router_group36 -> layer_0_expert1_gpu72
	layer_0_router_group36 -> layer_0_expert1_gpu73
	layer_0_router_group37 -> layer_0_expert1_gpu74
	layer_0_router_group37 -> layer_0_expert1_gpu75
	layer_0_router_group38 -> layer_0_expert1_gpu76
	layer_0_router_group38 -> layer_0_expert1_gpu77
	layer_0_router_group39 -> layer_0_expert1_gpu78
	layer_0_router_group39 -> layer_0_expert1_gpu79
	layer_0_router_group40 -> layer_0_expert1_gpu80
	layer_0_router_group40 -> layer_0_expert1_gpu81
	layer_0_router_group41 -> layer_0_expert1_gpu82
	layer_0_router_group41 -> layer_0_expert1_gpu83
	layer_0_router_group42 -> layer_0_expert1_gpu84
	layer_0_router_group42 -> layer_0_expert1_gpu85
	layer_0_router_group43 -> layer_0_expert1_gpu86
	layer_0_router_group43 -> layer_0_expert1_gpu87
	layer_0_router_group44 -> layer_0_expert1_gpu88
	layer_0_router_group44 -> layer_0_expert1_gpu89
	layer_0_router_group45 -> layer_0_expert1_gpu90
	layer_0_router_group45 -> layer_0_expert1_gpu91
	layer_0_router_group46 -> layer_0_expert1_gpu92
	layer_0_router_group46 -> layer_0_expert1_gpu93
	layer_0_router_group47 -> layer_0_expert1_gpu94
	layer_0_router_group47 -> layer_0_expert1_gpu95
	layer_0_router_group48 -> layer_0_expert1_gpu96
	layer_0_router_group48 -> layer_0_expert1_gpu97
	layer_0_router_group49 -> layer_0_expert1_gpu98
	layer_0_router_group49 -> layer_0_expert1_gpu99
	layer_0_router_group50 -> layer_0_expert1_gpu100
	layer_0_router_group50 -> layer_0_expert1_gpu101
	layer_0_router_group51 -> layer_0_expert1_gpu102
	layer_0_router_group51 -> layer_0_expert1_gpu103
	layer_0_router_group52 -> layer_0_expert1_gpu104
	layer_0_router_group52 -> layer_0_expert1_gpu105
	layer_0_router_group53 -> layer_0_expert1_gpu106
	layer_0_router_group53 -> layer_0_expert1_gpu107
	layer_0_router_group54 -> layer_0_expert1_gpu108
	layer_0_router_group54 -> layer_0_expert1_gpu109
	layer_0_router_group55 -> layer_0_expert1_gpu110
	layer_0_router_group55 -> layer_0_expert1_gpu111
	layer_0_router_group56 -> layer_0_expert1_gpu112
	layer_0_router_group56 -> layer_0_expert1_gpu113
	layer_0_router_group57 -> layer_0_expert1_gpu114
	layer_0_router_group57 -> layer_0_expert1_gpu115
	layer_0_router_group58 -> layer_0_expert1_gpu116
	layer_0_router_group58 -> layer_0_expert1_gpu117
	layer_0_router_group59 -> layer_0_expert1_gpu118
	layer_0_router_group59 -> layer_0_expert1_gpu119
	layer_0_router_group60 -> layer_0_expert1_gpu120
	layer_0_router_group60 -> layer_0_expert1_gpu121
	layer_0_router_group61 -> layer_0_expert1_gpu122
	layer_0_router_group61 -> layer_0_expert1_gpu123
	layer_0_router_group62 -> layer_0_expert1_gpu124
	layer_0_router_group62 -> layer_0_expert1_gpu125
	layer_0_router_group63 -> layer_0_expert1_gpu126
	layer_0_router_group63 -> layer_0_expert1_gpu127
	layer_0_expert1_gpu0 -> layer_0_expert_act_gpu0
	layer_0_expert_act_gpu0 -> layer_0_expert2_gpu0
	layer_0_expert1_gpu1 -> layer_0_expert_act_gpu1
	layer_0_expert_act_gpu1 -> layer_0_expert2_gpu1
	layer_0_expert1_gpu2 -> layer_0_expert_act_gpu2
	layer_0_expert_act_gpu2 -> layer_0_expert2_gpu2
	layer_0_expert1_gpu3 -> layer_0_expert_act_gpu3
	layer_0_expert_act_gpu3 -> layer_0_expert2_gpu3
	layer_0_expert1_gpu4 -> layer_0_expert_act_gpu4
	layer_0_expert_act_gpu4 -> layer_0_expert2_gpu4
	layer_0_expert1_gpu5 -> layer_0_expert_act_gpu5
	layer_0_expert_act_gpu5 -> layer_0_expert2_gpu5
	layer_0_expert1_gpu6 -> layer_0_expert_act_gpu6
	layer_0_expert_act_gpu6 -> layer_0_expert2_gpu6
	layer_0_expert1_gpu7 -> layer_0_expert_act_gpu7
	layer_0_expert_act_gpu7 -> layer_0_expert2_gpu7
	layer_0_expert1_gpu8 -> layer_0_expert_act_gpu8
	layer_0_expert_act_gpu8 -> layer_0_expert2_gpu8
	layer_0_expert1_gpu9 -> layer_0_expert_act_gpu9
	layer_0_expert_act_gpu9 -> layer_0_expert2_gpu9
	layer_0_expert1_gpu10 -> layer_0_expert_act_gpu10
	layer_0_expert_act_gpu10 -> layer_0_expert2_gpu10
	layer_0_expert1_gpu11 -> layer_0_expert_act_gpu11
	layer_0_expert_act_gpu11 -> layer_0_expert2_gpu11
	layer_0_expert1_gpu12 -> layer_0_expert_act_gpu12
	layer_0_expert_act_gpu12 -> layer_0_expert2_gpu12
	layer_0_expert1_gpu13 -> layer_0_expert_act_gpu13
	layer_0_expert_act_gpu13 -> layer_0_expert2_gpu13
	layer_0_expert1_gpu14 -> layer_0_expert_act_gpu14
	layer_0_expert_act_gpu14 -> layer_0_expert2_gpu14
	layer_0_expert1_gpu15 -> layer_0_expert_act_gpu15
	layer_0_expert_act_gpu15 -> layer_0_expert2_gpu15
	layer_0_expert1_gpu16 -> layer_0_expert_act_gpu16
	layer_0_expert_act_gpu16 -> layer_0_expert2_gpu16
	layer_0_expert1_gpu17 -> layer_0_expert_act_gpu17
	layer_0_expert_act_gpu17 -> layer_0_expert2_gpu17
	layer_0_expert1_gpu18 -> layer_0_expert_act_gpu18
	layer_0_expert_act_gpu18 -> layer_0_expert2_gpu18
	layer_0_expert1_gpu19 -> layer_0_expert_act_gpu19
	layer_0_expert_act_gpu19 -> layer_0_expert2_gpu19
	layer_0_expert1_gpu20 -> layer_0_expert_act_gpu20
	layer_0_expert_act_gpu20 -> layer_0_expert2_gpu20
	layer_0_expert1_gpu21 -> layer_0_expert_act_gpu21
	layer_0_expert_act_gpu21 -> layer_0_expert2_gpu21
	layer_0_expert1_gpu22 -> layer_0_expert_act_gpu22
	layer_0_expert_act_gpu22 -> layer_0_expert2_gpu22
	layer_0_expert1_gpu23 -> layer_0_expert_act_gpu23
	layer_0_expert_act_gpu23 -> layer_0_expert2_gpu23
	layer_0_expert1_gpu24 -> layer_0_expert_act_gpu24
	layer_0_expert_act_gpu24 -> layer_0_expert2_gpu24
	layer_0_expert1_gpu25 -> layer_0_expert_act_gpu25
	layer_0_expert_act_gpu25 -> layer_0_expert2_gpu25
	layer_0_expert1_gpu26 -> layer_0_expert_act_gpu26
	layer_0_expert_act_gpu26 -> layer_0_expert2_gpu26
	layer_0_expert1_gpu27 -> layer_0_expert_act_gpu27
	layer_0_expert_act_gpu27 -> layer_0_expert2_gpu27
	layer_0_expert1_gpu28 -> layer_0_expert_act_gpu28
	layer_0_expert_act_gpu28 -> layer_0_expert2_gpu28
	layer_0_expert1_gpu29 -> layer_0_expert_act_gpu29
	layer_0_expert_act_gpu29 -> layer_0_expert2_gpu29
	layer_0_expert1_gpu30 -> layer_0_expert_act_gpu30
	layer_0_expert_act_gpu30 -> layer_0_expert2_gpu30
	layer_0_expert1_gpu31 -> layer_0_expert_act_gpu31
	layer_0_expert_act_gpu31 -> layer_0_expert2_gpu31
	layer_0_expert1_gpu32 -> layer_0_expert_act_gpu32
	layer_0_expert_act_gpu32 -> layer_0_expert2_gpu32
	layer_0_expert1_gpu33 -> layer_0_expert_act_gpu33
	layer_0_expert_act_gpu33 -> layer_0_expert2_gpu33
	layer_0_expert1_gpu34 -> layer_0_expert_act_gpu34
	layer_0_expert_act_gpu34 -> layer_0_expert2_gpu34
	layer_0_expert1_gpu35 -> layer_0_expert_act_gpu35
	layer_0_expert_act_gpu35 -> layer_0_expert2_gpu35
	layer_0_expert1_gpu36 -> layer_0_expert_act_gpu36
	layer_0_expert_act_gpu36 -> layer_0_expert2_gpu36
	layer_0_expert1_gpu37 -> layer_0_expert_act_gpu37
	layer_0_expert_act_gpu37 -> layer_0_expert2_gpu37
	layer_0_expert1_gpu38 -> layer_0_expert_act_gpu38
	layer_0_expert_act_gpu38 -> layer_0_expert2_gpu38
	layer_0_expert1_gpu39 -> layer_0_expert_act_gpu39
	layer_0_expert_act_gpu39 -> layer_0_expert2_gpu39
	layer_0_expert1_gpu40 -> layer_0_expert_act_gpu40
	layer_0_expert_act_gpu40 -> layer_0_expert2_gpu40
	layer_0_expert1_gpu41 -> layer_0_expert_act_gpu41
	layer_0_expert_act_gpu41 -> layer_0_expert2_gpu41
	layer_0_expert1_gpu42 -> layer_0_expert_act_gpu42
	layer_0_expert_act_gpu42 -> layer_0_expert2_gpu42
	layer_0_expert1_gpu43 -> layer_0_expert_act_gpu43
	layer_0_expert_act_gpu43 -> layer_0_expert2_gpu43
	layer_0_expert1_gpu44 -> layer_0_expert_act_gpu44
	layer_0_expert_act_gpu44 -> layer_0_expert2_gpu44
	layer_0_expert1_gpu45 -> layer_0_expert_act_gpu45
	layer_0_expert_act_gpu45 -> layer_0_expert2_gpu45
	layer_0_expert1_gpu46 -> layer_0_expert_act_gpu46
	layer_0_expert_act_gpu46 -> layer_0_expert2_gpu46
	layer_0_expert1_gpu47 -> layer_0_expert_act_gpu47
	layer_0_expert_act_gpu47 -> layer_0_expert2_gpu47
	layer_0_expert1_gpu48 -> layer_0_expert_act_gpu48
	layer_0_expert_act_gpu48 -> layer_0_expert2_gpu48
	layer_0_expert1_gpu49 -> layer_0_expert_act_gpu49
	layer_0_expert_act_gpu49 -> layer_0_expert2_gpu49
	layer_0_expert1_gpu50 -> layer_0_expert_act_gpu50
	layer_0_expert_act_gpu50 -> layer_0_expert2_gpu50
	layer_0_expert1_gpu51 -> layer_0_expert_act_gpu51
	layer_0_expert_act_gpu51 -> layer_0_expert2_gpu51
	layer_0_expert1_gpu52 -> layer_0_expert_act_gpu52
	layer_0_expert_act_gpu52 -> layer_0_expert2_gpu52
	layer_0_expert1_gpu53 -> layer_0_expert_act_gpu53
	layer_0_expert_act_gpu53 -> layer_0_expert2_gpu53
	layer_0_expert1_gpu54 -> layer_0_expert_act_gpu54
	layer_0_expert_act_gpu54 -> layer_0_expert2_gpu54
	layer_0_expert1_gpu55 -> layer_0_expert_act_gpu55
	layer_0_expert_act_gpu55 -> layer_0_expert2_gpu55
	layer_0_expert1_gpu56 -> layer_0_expert_act_gpu56
	layer_0_expert_act_gpu56 -> layer_0_expert2_gpu56
	layer_0_expert1_gpu57 -> layer_0_expert_act_gpu57
	layer_0_expert_act_gpu57 -> layer_0_expert2_gpu57
	layer_0_expert1_gpu58 -> layer_0_expert_act_gpu58
	layer_0_expert_act_gpu58 -> layer_0_expert2_gpu58
	layer_0_expert1_gpu59 -> layer_0_expert_act_gpu59
	layer_0_expert_act_gpu59 -> layer_0_expert2_gpu59
	layer_0_expert1_gpu60 -> layer_0_expert_act_gpu60
	layer_0_expert_act_gpu60 -> layer_0_expert2_gpu60
	layer_0_expert1_gpu61 -> layer_0_expert_act_gpu61
	layer_0_expert_act_gpu61 -> layer_0_expert2_gpu61
	layer_0_expert1_gpu62 -> layer_0_expert_act_gpu62
	layer_0_expert_act_gpu62 -> layer_0_expert2_gpu62
	layer_0_expert1_gpu63 -> layer_0_expert_act_gpu63
	layer_0_expert_act_gpu63 -> layer_0_expert2_gpu63
	layer_0_expert1_gpu64 -> layer_0_expert_act_gpu64
	layer_0_expert_act_gpu64 -> layer_0_expert2_gpu64
	layer_0_expert1_gpu65 -> layer_0_expert_act_gpu65
	layer_0_expert_act_gpu65 -> layer_0_expert2_gpu65
	layer_0_expert1_gpu66 -> layer_0_expert_act_gpu66
	layer_0_expert_act_gpu66 -> layer_0_expert2_gpu66
	layer_0_expert1_gpu67 -> layer_0_expert_act_gpu67
	layer_0_expert_act_gpu67 -> layer_0_expert2_gpu67
	layer_0_expert1_gpu68 -> layer_0_expert_act_gpu68
	layer_0_expert_act_gpu68 -> layer_0_expert2_gpu68
	layer_0_expert1_gpu69 -> layer_0_expert_act_gpu69
	layer_0_expert_act_gpu69 -> layer_0_expert2_gpu69
	layer_0_expert1_gpu70 -> layer_0_expert_act_gpu70
	layer_0_expert_act_gpu70 -> layer_0_expert2_gpu70
	layer_0_expert1_gpu71 -> layer_0_expert_act_gpu71
	layer_0_expert_act_gpu71 -> layer_0_expert2_gpu71
	layer_0_expert1_gpu72 -> layer_0_expert_act_gpu72
	layer_0_expert_act_gpu72 -> layer_0_expert2_gpu72
	layer_0_expert1_gpu73 -> layer_0_expert_act_gpu73
	layer_0_expert_act_gpu73 -> layer_0_expert2_gpu73
	layer_0_expert1_gpu74 -> layer_0_expert_act_gpu74
	layer_0_expert_act_gpu74 -> layer_0_expert2_gpu74
	layer_0_expert1_gpu75 -> layer_0_expert_act_gpu75
	layer_0_expert_act_gpu75 -> layer_0_expert2_gpu75
	layer_0_expert1_gpu76 -> layer_0_expert_act_gpu76
	layer_0_expert_act_gpu76 -> layer_0_expert2_gpu76
	layer_0_expert1_gpu77 -> layer_0_expert_act_gpu77
	layer_0_expert_act_gpu77 -> layer_0_expert2_gpu77
	layer_0_expert1_gpu78 -> layer_0_expert_act_gpu78
	layer_0_expert_act_gpu78 -> layer_0_expert2_gpu78
	layer_0_expert1_gpu79 -> layer_0_expert_act_gpu79
	layer_0_expert_act_gpu79 -> layer_0_expert2_gpu79
	layer_0_expert1_gpu80 -> layer_0_expert_act_gpu80
	layer_0_expert_act_gpu80 -> layer_0_expert2_gpu80
	layer_0_expert1_gpu81 -> layer_0_expert_act_gpu81
	layer_0_expert_act_gpu81 -> layer_0_expert2_gpu81
	layer_0_expert1_gpu82 -> layer_0_expert_act_gpu82
	layer_0_expert_act_gpu82 -> layer_0_expert2_gpu82
	layer_0_expert1_gpu83 -> layer_0_expert_act_gpu83
	layer_0_expert_act_gpu83 -> layer_0_expert2_gpu83
	layer_0_expert1_gpu84 -> layer_0_expert_act_gpu84
	layer_0_expert_act_gpu84 -> layer_0_expert2_gpu84
	layer_0_expert1_gpu85 -> layer_0_expert_act_gpu85
	layer_0_expert_act_gpu85 -> layer_0_expert2_gpu85
	layer_0_expert1_gpu86 -> layer_0_expert_act_gpu86
	layer_0_expert_act_gpu86 -> layer_0_expert2_gpu86
	layer_0_expert1_gpu87 -> layer_0_expert_act_gpu87
	layer_0_expert_act_gpu87 -> layer_0_expert2_gpu87
	layer_0_expert1_gpu88 -> layer_0_expert_act_gpu88
	layer_0_expert_act_gpu88 -> layer_0_expert2_gpu88
	layer_0_expert1_gpu89 -> layer_0_expert_act_gpu89
	layer_0_expert_act_gpu89 -> layer_0_expert2_gpu89
	layer_0_expert1_gpu90 -> layer_0_expert_act_gpu90
	layer_0_expert_act_gpu90 -> layer_0_expert2_gpu90
	layer_0_expert1_gpu91 -> layer_0_expert_act_gpu91
	layer_0_expert_act_gpu91 -> layer_0_expert2_gpu91
	layer_0_expert1_gpu92 -> layer_0_expert_act_gpu92
	layer_0_expert_act_gpu92 -> layer_0_expert2_gpu92
	layer_0_expert1_gpu93 -> layer_0_expert_act_gpu93
	layer_0_expert_act_gpu93 -> layer_0_expert2_gpu93
	layer_0_expert1_gpu94 -> layer_0_expert_act_gpu94
	layer_0_expert_act_gpu94 -> layer_0_expert2_gpu94
	layer_0_expert1_gpu95 -> layer_0_expert_act_gpu95
	layer_0_expert_act_gpu95 -> layer_0_expert2_gpu95
	layer_0_expert1_gpu96 -> layer_0_expert_act_gpu96
	layer_0_expert_act_gpu96 -> layer_0_expert2_gpu96
	layer_0_expert1_gpu97 -> layer_0_expert_act_gpu97
	layer_0_expert_act_gpu97 -> layer_0_expert2_gpu97
	layer_0_expert1_gpu98 -> layer_0_expert_act_gpu98
	layer_0_expert_act_gpu98 -> layer_0_expert2_gpu98
	layer_0_expert1_gpu99 -> layer_0_expert_act_gpu99
	layer_0_expert_act_gpu99 -> layer_0_expert2_gpu99
	layer_0_expert1_gpu100 -> layer_0_expert_act_gpu100
	layer_0_expert_act_gpu100 -> layer_0_expert2_gpu100
	layer_0_expert1_gpu101 -> layer_0_expert_act_gpu101
	layer_0_expert_act_gpu101 -> layer_0_expert2_gpu101
	layer_0_expert1_gpu102 -> layer_0_expert_act_gpu102
	layer_0_expert_act_gpu102 -> layer_0_expert2_gpu102
	layer_0_expert1_gpu103 -> layer_0_expert_act_gpu103
	layer_0_expert_act_gpu103 -> layer_0_expert2_gpu103
	layer_0_expert1_gpu104 -> layer_0_expert_act_gpu104
	layer_0_expert_act_gpu104 -> layer_0_expert2_gpu104
	layer_0_expert1_gpu105 -> layer_0_expert_act_gpu105
	layer_0_expert_act_gpu105 -> layer_0_expert2_gpu105
	layer_0_expert1_gpu106 -> layer_0_expert_act_gpu106
	layer_0_expert_act_gpu106 -> layer_0_expert2_gpu106
	layer_0_expert1_gpu107 -> layer_0_expert_act_gpu107
	layer_0_expert_act_gpu107 -> layer_0_expert2_gpu107
	layer_0_expert1_gpu108 -> layer_0_expert_act_gpu108
	layer_0_expert_act_gpu108 -> layer_0_expert2_gpu108
	layer_0_expert1_gpu109 -> layer_0_expert_act_gpu109
	layer_0_expert_act_gpu109 -> layer_0_expert2_gpu109
	layer_0_expert1_gpu110 -> layer_0_expert_act_gpu110
	layer_0_expert_act_gpu110 -> layer_0_expert2_gpu110
	layer_0_expert1_gpu111 -> layer_0_expert_act_gpu111
	layer_0_expert_act_gpu111 -> layer_0_expert2_gpu111
	layer_0_expert1_gpu112 -> layer_0_expert_act_gpu112
	layer_0_expert_act_gpu112 -> layer_0_expert2_gpu112
	layer_0_expert1_gpu113 -> layer_0_expert_act_gpu113
	layer_0_expert_act_gpu113 -> layer_0_expert2_gpu113
	layer_0_expert1_gpu114 -> layer_0_expert_act_gpu114
	layer_0_expert_act_gpu114 -> layer_0_expert2_gpu114
	layer_0_expert1_gpu115 -> layer_0_expert_act_gpu115
	layer_0_expert_act_gpu115 -> layer_0_expert2_gpu115
	layer_0_expert1_gpu116 -> layer_0_expert_act_gpu116
	layer_0_expert_act_gpu116 -> layer_0_expert2_gpu116
	layer_0_expert1_gpu117 -> layer_0_expert_act_gpu117
	layer_0_expert_act_gpu117 -> layer_0_expert2_gpu117
	layer_0_expert1_gpu118 -> layer_0_expert_act_gpu118
	layer_0_expert_act_gpu118 -> layer_0_expert2_gpu118
	layer_0_expert1_gpu119 -> layer_0_expert_act_gpu119
	layer_0_expert_act_gpu119 -> layer_0_expert2_gpu119
	layer_0_expert1_gpu120 -> layer_0_expert_act_gpu120
	layer_0_expert_act_gpu120 -> layer_0_expert2_gpu120
	layer_0_expert1_gpu121 -> layer_0_expert_act_gpu121
	layer_0_expert_act_gpu121 -> layer_0_expert2_gpu121
	layer_0_expert1_gpu122 -> layer_0_expert_act_gpu122
	layer_0_expert_act_gpu122 -> layer_0_expert2_gpu122
	layer_0_expert1_gpu123 -> layer_0_expert_act_gpu123
	layer_0_expert_act_gpu123 -> layer_0_expert2_gpu123
	layer_0_expert1_gpu124 -> layer_0_expert_act_gpu124
	layer_0_expert_act_gpu124 -> layer_0_expert2_gpu124
	layer_0_expert1_gpu125 -> layer_0_expert_act_gpu125
	layer_0_expert_act_gpu125 -> layer_0_expert2_gpu125
	layer_0_expert1_gpu126 -> layer_0_expert_act_gpu126
	layer_0_expert_act_gpu126 -> layer_0_expert2_gpu126
	layer_0_expert1_gpu127 -> layer_0_expert_act_gpu127
	layer_0_expert_act_gpu127 -> layer_0_expert2_gpu127
	layer_0_expert2_gpu0 -> layer_0_expert_allreduce_group0
	layer_0_expert2_gpu1 -> layer_0_expert_allreduce_group0
	layer_0_expert2_gpu2 -> layer_0_expert_allreduce_group1
	layer_0_expert2_gpu3 -> layer_0_expert_allreduce_group1
	layer_0_expert2_gpu4 -> layer_0_expert_allreduce_group2
	layer_0_expert2_gpu5 -> layer_0_expert_allreduce_group2
	layer_0_expert2_gpu6 -> layer_0_expert_allreduce_group3
	layer_0_expert2_gpu7 -> layer_0_expert_allreduce_group3
	layer_0_expert2_gpu8 -> layer_0_expert_allreduce_group4
	layer_0_expert2_gpu9 -> layer_0_expert_allreduce_group4
	layer_0_expert2_gpu10 -> layer_0_expert_allreduce_group5
	layer_0_expert2_gpu11 -> layer_0_expert_allreduce_group5
	layer_0_expert2_gpu12 -> layer_0_expert_allreduce_group6
	layer_0_expert2_gpu13 -> layer_0_expert_allreduce_group6
	layer_0_expert2_gpu14 -> layer_0_expert_allreduce_group7
	layer_0_expert2_gpu15 -> layer_0_expert_allreduce_group7
	layer_0_expert2_gpu16 -> layer_0_expert_allreduce_group8
	layer_0_expert2_gpu17 -> layer_0_expert_allreduce_group8
	layer_0_expert2_gpu18 -> layer_0_expert_allreduce_group9
	layer_0_expert2_gpu19 -> layer_0_expert_allreduce_group9
	layer_0_expert2_gpu20 -> layer_0_expert_allreduce_group10
	layer_0_expert2_gpu21 -> layer_0_expert_allreduce_group10
	layer_0_expert2_gpu22 -> layer_0_expert_allreduce_group11
	layer_0_expert2_gpu23 -> layer_0_expert_allreduce_group11
	layer_0_expert2_gpu24 -> layer_0_expert_allreduce_group12
	layer_0_expert2_gpu25 -> layer_0_expert_allreduce_group12
	layer_0_expert2_gpu26 -> layer_0_expert_allreduce_group13
	layer_0_expert2_gpu27 -> layer_0_expert_allreduce_group13
	layer_0_expert2_gpu28 -> layer_0_expert_allreduce_group14
	layer_0_expert2_gpu29 -> layer_0_expert_allreduce_group14
	layer_0_expert2_gpu30 -> layer_0_expert_allreduce_group15
	layer_0_expert2_gpu31 -> layer_0_expert_allreduce_group15
	layer_0_expert2_gpu32 -> layer_0_expert_allreduce_group16
	layer_0_expert2_gpu33 -> layer_0_expert_allreduce_group16
	layer_0_expert2_gpu34 -> layer_0_expert_allreduce_group17
	layer_0_expert2_gpu35 -> layer_0_expert_allreduce_group17
	layer_0_expert2_gpu36 -> layer_0_expert_allreduce_group18
	layer_0_expert2_gpu37 -> layer_0_expert_allreduce_group18
	layer_0_expert2_gpu38 -> layer_0_expert_allreduce_group19
	layer_0_expert2_gpu39 -> layer_0_expert_allreduce_group19
	layer_0_expert2_gpu40 -> layer_0_expert_allreduce_group20
	layer_0_expert2_gpu41 -> layer_0_expert_allreduce_group20
	layer_0_expert2_gpu42 -> layer_0_expert_allreduce_group21
	layer_0_expert2_gpu43 -> layer_0_expert_allreduce_group21
	layer_0_expert2_gpu44 -> layer_0_expert_allreduce_group22
	layer_0_expert2_gpu45 -> layer_0_expert_allreduce_group22
	layer_0_expert2_gpu46 -> layer_0_expert_allreduce_group23
	layer_0_expert2_gpu47 -> layer_0_expert_allreduce_group23
	layer_0_expert2_gpu48 -> layer_0_expert_allreduce_group24
	layer_0_expert2_gpu49 -> layer_0_expert_allreduce_group24
	layer_0_expert2_gpu50 -> layer_0_expert_allreduce_group25
	layer_0_expert2_gpu51 -> layer_0_expert_allreduce_group25
	layer_0_expert2_gpu52 -> layer_0_expert_allreduce_group26
	layer_0_expert2_gpu53 -> layer_0_expert_allreduce_group26
	layer_0_expert2_gpu54 -> layer_0_expert_allreduce_group27
	layer_0_expert2_gpu55 -> layer_0_expert_allreduce_group27
	layer_0_expert2_gpu56 -> layer_0_expert_allreduce_group28
	layer_0_expert2_gpu57 -> layer_0_expert_allreduce_group28
	layer_0_expert2_gpu58 -> layer_0_expert_allreduce_group29
	layer_0_expert2_gpu59 -> layer_0_expert_allreduce_group29
	layer_0_expert2_gpu60 -> layer_0_expert_allreduce_group30
	layer_0_expert2_gpu61 -> layer_0_expert_allreduce_group30
	layer_0_expert2_gpu62 -> layer_0_expert_allreduce_group31
	layer_0_expert2_gpu63 -> layer_0_expert_allreduce_group31
	layer_0_expert2_gpu64 -> layer_0_expert_allreduce_group32
	layer_0_expert2_gpu65 -> layer_0_expert_allreduce_group32
	layer_0_expert2_gpu66 -> layer_0_expert_allreduce_group33
	layer_0_expert2_gpu67 -> layer_0_expert_allreduce_group33
	layer_0_expert2_gpu68 -> layer_0_expert_allreduce_group34
	layer_0_expert2_gpu69 -> layer_0_expert_allreduce_group34
	layer_0_expert2_gpu70 -> layer_0_expert_allreduce_group35
	layer_0_expert2_gpu71 -> layer_0_expert_allreduce_group35
	layer_0_expert2_gpu72 -> layer_0_expert_allreduce_group36
	layer_0_expert2_gpu73 -> layer_0_expert_allreduce_group36
	layer_0_expert2_gpu74 -> layer_0_expert_allreduce_group37
	layer_0_expert2_gpu75 -> layer_0_expert_allreduce_group37
	layer_0_expert2_gpu76 -> layer_0_expert_allreduce_group38
	layer_0_expert2_gpu77 -> layer_0_expert_allreduce_group38
	layer_0_expert2_gpu78 -> layer_0_expert_allreduce_group39
	layer_0_expert2_gpu79 -> layer_0_expert_allreduce_group39
	layer_0_expert2_gpu80 -> layer_0_expert_allreduce_group40
	layer_0_expert2_gpu81 -> layer_0_expert_allreduce_group40
	layer_0_expert2_gpu82 -> layer_0_expert_allreduce_group41
	layer_0_expert2_gpu83 -> layer_0_expert_allreduce_group41
	layer_0_expert2_gpu84 -> layer_0_expert_allreduce_group42
	layer_0_expert2_gpu85 -> layer_0_expert_allreduce_group42
	layer_0_expert2_gpu86 -> layer_0_expert_allreduce_group43
	layer_0_expert2_gpu87 -> layer_0_expert_allreduce_group43
	layer_0_expert2_gpu88 -> layer_0_expert_allreduce_group44
	layer_0_expert2_gpu89 -> layer_0_expert_allreduce_group44
	layer_0_expert2_gpu90 -> layer_0_expert_allreduce_group45
	layer_0_expert2_gpu91 -> layer_0_expert_allreduce_group45
	layer_0_expert2_gpu92 -> layer_0_expert_allreduce_group46
	layer_0_expert2_gpu93 -> layer_0_expert_allreduce_group46
	layer_0_expert2_gpu94 -> layer_0_expert_allreduce_group47
	layer_0_expert2_gpu95 -> layer_0_expert_allreduce_group47
	layer_0_expert2_gpu96 -> layer_0_expert_allreduce_group48
	layer_0_expert2_gpu97 -> layer_0_expert_allreduce_group48
	layer_0_expert2_gpu98 -> layer_0_expert_allreduce_group49
	layer_0_expert2_gpu99 -> layer_0_expert_allreduce_group49
	layer_0_expert2_gpu100 -> layer_0_expert_allreduce_group50
	layer_0_expert2_gpu101 -> layer_0_expert_allreduce_group50
	layer_0_expert2_gpu102 -> layer_0_expert_allreduce_group51
	layer_0_expert2_gpu103 -> layer_0_expert_allreduce_group51
	layer_0_expert2_gpu104 -> layer_0_expert_allreduce_group52
	layer_0_expert2_gpu105 -> layer_0_expert_allreduce_group52
	layer_0_expert2_gpu106 -> layer_0_expert_allreduce_group53
	layer_0_expert2_gpu107 -> layer_0_expert_allreduce_group53
	layer_0_expert2_gpu108 -> layer_0_expert_allreduce_group54
	layer_0_expert2_gpu109 -> layer_0_expert_allreduce_group54
	layer_0_expert2_gpu110 -> layer_0_expert_allreduce_group55
	layer_0_expert2_gpu111 -> layer_0_expert_allreduce_group55
	layer_0_expert2_gpu112 -> layer_0_expert_allreduce_group56
	layer_0_expert2_gpu113 -> layer_0_expert_allreduce_group56
	layer_0_expert2_gpu114 -> layer_0_expert_allreduce_group57
	layer_0_expert2_gpu115 -> layer_0_expert_allreduce_group57
	layer_0_expert2_gpu116 -> layer_0_expert_allreduce_group58
	layer_0_expert2_gpu117 -> layer_0_expert_allreduce_group58
	layer_0_expert2_gpu118 -> layer_0_expert_allreduce_group59
	layer_0_expert2_gpu119 -> layer_0_expert_allreduce_group59
	layer_0_expert2_gpu120 -> layer_0_expert_allreduce_group60
	layer_0_expert2_gpu121 -> layer_0_expert_allreduce_group60
	layer_0_expert2_gpu122 -> layer_0_expert_allreduce_group61
	layer_0_expert2_gpu123 -> layer_0_expert_allreduce_group61
	layer_0_expert2_gpu124 -> layer_0_expert_allreduce_group62
	layer_0_expert2_gpu125 -> layer_0_expert_allreduce_group62
	layer_0_expert2_gpu126 -> layer_0_expert_allreduce_group63
	layer_0_expert2_gpu127 -> layer_0_expert_allreduce_group63
	layer_0_expert_allreduce_group0 -> layer_0_aggregate_group0
	layer_0_expert_allreduce_group1 -> layer_0_aggregate_group1
	layer_0_expert_allreduce_group2 -> layer_0_aggregate_group2
	layer_0_expert_allreduce_group3 -> layer_0_aggregate_group3
	layer_0_expert_allreduce_group4 -> layer_0_aggregate_group4
	layer_0_expert_allreduce_group5 -> layer_0_aggregate_group5
	layer_0_expert_allreduce_group6 -> layer_0_aggregate_group6
	layer_0_expert_allreduce_group7 -> layer_0_aggregate_group7
	layer_0_expert_allreduce_group8 -> layer_0_aggregate_group8
	layer_0_expert_allreduce_group9 -> layer_0_aggregate_group9
	layer_0_expert_allreduce_group10 -> layer_0_aggregate_group10
	layer_0_expert_allreduce_group11 -> layer_0_aggregate_group11
	layer_0_expert_allreduce_group12 -> layer_0_aggregate_group12
	layer_0_expert_allreduce_group13 -> layer_0_aggregate_group13
	layer_0_expert_allreduce_group14 -> layer_0_aggregate_group14
	layer_0_expert_allreduce_group15 -> layer_0_aggregate_group15
	layer_0_expert_allreduce_group16 -> layer_0_aggregate_group16
	layer_0_expert_allreduce_group17 -> layer_0_aggregate_group17
	layer_0_expert_allreduce_group18 -> layer_0_aggregate_group18
	layer_0_expert_allreduce_group19 -> layer_0_aggregate_group19
	layer_0_expert_allreduce_group20 -> layer_0_aggregate_group20
	layer_0_expert_allreduce_group21 -> layer_0_aggregate_group21
	layer_0_expert_allreduce_group22 -> layer_0_aggregate_group22
	layer_0_expert_allreduce_group23 -> layer_0_aggregate_group23
	layer_0_expert_allreduce_group24 -> layer_0_aggregate_group24
	layer_0_expert_allreduce_group25 -> layer_0_aggregate_group25
	layer_0_expert_allreduce_group26 -> layer_0_aggregate_group26
	layer_0_expert_allreduce_group27 -> layer_0_aggregate_group27
	layer_0_expert_allreduce_group28 -> layer_0_aggregate_group28
	layer_0_expert_allreduce_group29 -> layer_0_aggregate_group29
	layer_0_expert_allreduce_group30 -> layer_0_aggregate_group30
	layer_0_expert_allreduce_group31 -> layer_0_aggregate_group31
	layer_0_expert_allreduce_group32 -> layer_0_aggregate_group32
	layer_0_expert_allreduce_group33 -> layer_0_aggregate_group33
	layer_0_expert_allreduce_group34 -> layer_0_aggregate_group34
	layer_0_expert_allreduce_group35 -> layer_0_aggregate_group35
	layer_0_expert_allreduce_group36 -> layer_0_aggregate_group36
	layer_0_expert_allreduce_group37 -> layer_0_aggregate_group37
	layer_0_expert_allreduce_group38 -> layer_0_aggregate_group38
	layer_0_expert_allreduce_group39 -> layer_0_aggregate_group39
	layer_0_expert_allreduce_group40 -> layer_0_aggregate_group40
	layer_0_expert_allreduce_group41 -> layer_0_aggregate_group41
	layer_0_expert_allreduce_group42 -> layer_0_aggregate_group42
	layer_0_expert_allreduce_group43 -> layer_0_aggregate_group43
	layer_0_expert_allreduce_group44 -> layer_0_aggregate_group44
	layer_0_expert_allreduce_group45 -> layer_0_aggregate_group45
	layer_0_expert_allreduce_group46 -> layer_0_aggregate_group46
	layer_0_expert_allreduce_group47 -> layer_0_aggregate_group47
	layer_0_expert_allreduce_group48 -> layer_0_aggregate_group48
	layer_0_expert_allreduce_group49 -> layer_0_aggregate_group49
	layer_0_expert_allreduce_group50 -> layer_0_aggregate_group50
	layer_0_expert_allreduce_group51 -> layer_0_aggregate_group51
	layer_0_expert_allreduce_group52 -> layer_0_aggregate_group52
	layer_0_expert_allreduce_group53 -> layer_0_aggregate_group53
	layer_0_expert_allreduce_group54 -> layer_0_aggregate_group54
	layer_0_expert_allreduce_group55 -> layer_0_aggregate_group55
	layer_0_expert_allreduce_group56 -> layer_0_aggregate_group56
	layer_0_expert_allreduce_group57 -> layer_0_aggregate_group57
	layer_0_expert_allreduce_group58 -> layer_0_aggregate_group58
	layer_0_expert_allreduce_group59 -> layer_0_aggregate_group59
	layer_0_expert_allreduce_group60 -> layer_0_aggregate_group60
	layer_0_expert_allreduce_group61 -> layer_0_aggregate_group61
	layer_0_expert_allreduce_group62 -> layer_0_aggregate_group62
	layer_0_expert_allreduce_group63 -> layer_0_aggregate_group63
	layer_0_aggregate_group0 -> layer_0_final_allreduce
	layer_0_aggregate_group1 -> layer_0_final_allreduce
	layer_0_aggregate_group2 -> layer_0_final_allreduce
	layer_0_aggregate_group3 -> layer_0_final_allreduce
	layer_0_aggregate_group4 -> layer_0_final_allreduce
	layer_0_aggregate_group5 -> layer_0_final_allreduce
	layer_0_aggregate_group6 -> layer_0_final_allreduce
	layer_0_aggregate_group7 -> layer_0_final_allreduce
	layer_0_aggregate_group8 -> layer_0_final_allreduce
	layer_0_aggregate_group9 -> layer_0_final_allreduce
	layer_0_aggregate_group10 -> layer_0_final_allreduce
	layer_0_aggregate_group11 -> layer_0_final_allreduce
	layer_0_aggregate_group12 -> layer_0_final_allreduce
	layer_0_aggregate_group13 -> layer_0_final_allreduce
	layer_0_aggregate_group14 -> layer_0_final_allreduce
	layer_0_aggregate_group15 -> layer_0_final_allreduce
	layer_0_aggregate_group16 -> layer_0_final_allreduce
	layer_0_aggregate_group17 -> layer_0_final_allreduce
	layer_0_aggregate_group18 -> layer_0_final_allreduce
	layer_0_aggregate_group19 -> layer_0_final_allreduce
	layer_0_aggregate_group20 -> layer_0_final_allreduce
	layer_0_aggregate_group21 -> layer_0_final_allreduce
	layer_0_aggregate_group22 -> layer_0_final_allreduce
	layer_0_aggregate_group23 -> layer_0_final_allreduce
	layer_0_aggregate_group24 -> layer_0_final_allreduce
	layer_0_aggregate_group25 -> layer_0_final_allreduce
	layer_0_aggregate_group26 -> layer_0_final_allreduce
	layer_0_aggregate_group27 -> layer_0_final_allreduce
	layer_0_aggregate_group28 -> layer_0_final_allreduce
	layer_0_aggregate_group29 -> layer_0_final_allreduce
	layer_0_aggregate_group30 -> layer_0_final_allreduce
	layer_0_aggregate_group31 -> layer_0_final_allreduce
	layer_0_aggregate_group32 -> layer_0_final_allreduce
	layer_0_aggregate_group33 -> layer_0_final_allreduce
	layer_0_aggregate_group34 -> layer_0_final_allreduce
	layer_0_aggregate_group35 -> layer_0_final_allreduce
	layer_0_aggregate_group36 -> layer_0_final_allreduce
	layer_0_aggregate_group37 -> layer_0_final_allreduce
	layer_0_aggregate_group38 -> layer_0_final_allreduce
	layer_0_aggregate_group39 -> layer_0_final_allreduce
	layer_0_aggregate_group40 -> layer_0_final_allreduce
	layer_0_aggregate_group41 -> layer_0_final_allreduce
	layer_0_aggregate_group42 -> layer_0_final_allreduce
	layer_0_aggregate_group43 -> layer_0_final_allreduce
	layer_0_aggregate_group44 -> layer_0_final_allreduce
	layer_0_aggregate_group45 -> layer_0_final_allreduce
	layer_0_aggregate_group46 -> layer_0_final_allreduce
	layer_0_aggregate_group47 -> layer_0_final_allreduce
	layer_0_aggregate_group48 -> layer_0_final_allreduce
	layer_0_aggregate_group49 -> layer_0_final_allreduce
	layer_0_aggregate_group50 -> layer_0_final_allreduce
	layer_0_aggregate_group51 -> layer_0_final_allreduce
	layer_0_aggregate_group52 -> layer_0_final_allreduce
	layer_0_aggregate_group53 -> layer_0_final_allreduce
	layer_0_aggregate_group54 -> layer_0_final_allreduce
	layer_0_aggregate_group55 -> layer_0_final_allreduce
	layer_0_aggregate_group56 -> layer_0_final_allreduce
	layer_0_aggregate_group57 -> layer_0_final_allreduce
	layer_0_aggregate_group58 -> layer_0_final_allreduce
	layer_0_aggregate_group59 -> layer_0_final_allreduce
	layer_0_aggregate_group60 -> layer_0_final_allreduce
	layer_0_aggregate_group61 -> layer_0_final_allreduce
	layer_0_aggregate_group62 -> layer_0_final_allreduce
	layer_0_aggregate_group63 -> layer_0_final_allreduce
	layer_0_final_allreduce -> layer_0_residual2_gpu0
	layer_0_residual1_gpu0 -> layer_0_residual2_gpu0
	layer_0_final_allreduce -> layer_0_residual2_gpu1
	layer_0_residual1_gpu1 -> layer_0_residual2_gpu1
	layer_0_final_allreduce -> layer_0_residual2_gpu2
	layer_0_residual1_gpu2 -> layer_0_residual2_gpu2
	layer_0_final_allreduce -> layer_0_residual2_gpu3
	layer_0_residual1_gpu3 -> layer_0_residual2_gpu3
	layer_0_final_allreduce -> layer_0_residual2_gpu4
	layer_0_residual1_gpu4 -> layer_0_residual2_gpu4
	layer_0_final_allreduce -> layer_0_residual2_gpu5
	layer_0_residual1_gpu5 -> layer_0_residual2_gpu5
	layer_0_final_allreduce -> layer_0_residual2_gpu6
	layer_0_residual1_gpu6 -> layer_0_residual2_gpu6
	layer_0_final_allreduce -> layer_0_residual2_gpu7
	layer_0_residual1_gpu7 -> layer_0_residual2_gpu7
	layer_0_final_allreduce -> layer_0_residual2_gpu8
	layer_0_residual1_gpu8 -> layer_0_residual2_gpu8
	layer_0_final_allreduce -> layer_0_residual2_gpu9
	layer_0_residual1_gpu9 -> layer_0_residual2_gpu9
	layer_0_final_allreduce -> layer_0_residual2_gpu10
	layer_0_residual1_gpu10 -> layer_0_residual2_gpu10
	layer_0_final_allreduce -> layer_0_residual2_gpu11
	layer_0_residual1_gpu11 -> layer_0_residual2_gpu11
	layer_0_final_allreduce -> layer_0_residual2_gpu12
	layer_0_residual1_gpu12 -> layer_0_residual2_gpu12
	layer_0_final_allreduce -> layer_0_residual2_gpu13
	layer_0_residual1_gpu13 -> layer_0_residual2_gpu13
	layer_0_final_allreduce -> layer_0_residual2_gpu14
	layer_0_residual1_gpu14 -> layer_0_residual2_gpu14
	layer_0_final_allreduce -> layer_0_residual2_gpu15
	layer_0_residual1_gpu15 -> layer_0_residual2_gpu15
	layer_0_final_allreduce -> layer_0_residual2_gpu16
	layer_0_residual1_gpu16 -> layer_0_residual2_gpu16
	layer_0_final_allreduce -> layer_0_residual2_gpu17
	layer_0_residual1_gpu17 -> layer_0_residual2_gpu17
	layer_0_final_allreduce -> layer_0_residual2_gpu18
	layer_0_residual1_gpu18 -> layer_0_residual2_gpu18
	layer_0_final_allreduce -> layer_0_residual2_gpu19
	layer_0_residual1_gpu19 -> layer_0_residual2_gpu19
	layer_0_final_allreduce -> layer_0_residual2_gpu20
	layer_0_residual1_gpu20 -> layer_0_residual2_gpu20
	layer_0_final_allreduce -> layer_0_residual2_gpu21
	layer_0_residual1_gpu21 -> layer_0_residual2_gpu21
	layer_0_final_allreduce -> layer_0_residual2_gpu22
	layer_0_residual1_gpu22 -> layer_0_residual2_gpu22
	layer_0_final_allreduce -> layer_0_residual2_gpu23
	layer_0_residual1_gpu23 -> layer_0_residual2_gpu23
	layer_0_final_allreduce -> layer_0_residual2_gpu24
	layer_0_residual1_gpu24 -> layer_0_residual2_gpu24
	layer_0_final_allreduce -> layer_0_residual2_gpu25
	layer_0_residual1_gpu25 -> layer_0_residual2_gpu25
	layer_0_final_allreduce -> layer_0_residual2_gpu26
	layer_0_residual1_gpu26 -> layer_0_residual2_gpu26
	layer_0_final_allreduce -> layer_0_residual2_gpu27
	layer_0_residual1_gpu27 -> layer_0_residual2_gpu27
	layer_0_final_allreduce -> layer_0_residual2_gpu28
	layer_0_residual1_gpu28 -> layer_0_residual2_gpu28
	layer_0_final_allreduce -> layer_0_residual2_gpu29
	layer_0_residual1_gpu29 -> layer_0_residual2_gpu29
	layer_0_final_allreduce -> layer_0_residual2_gpu30
	layer_0_residual1_gpu30 -> layer_0_residual2_gpu30
	layer_0_final_allreduce -> layer_0_residual2_gpu31
	layer_0_residual1_gpu31 -> layer_0_residual2_gpu31
	layer_0_final_allreduce -> layer_0_residual2_gpu32
	layer_0_residual1_gpu32 -> layer_0_residual2_gpu32
	layer_0_final_allreduce -> layer_0_residual2_gpu33
	layer_0_residual1_gpu33 -> layer_0_residual2_gpu33
	layer_0_final_allreduce -> layer_0_residual2_gpu34
	layer_0_residual1_gpu34 -> layer_0_residual2_gpu34
	layer_0_final_allreduce -> layer_0_residual2_gpu35
	layer_0_residual1_gpu35 -> layer_0_residual2_gpu35
	layer_0_final_allreduce -> layer_0_residual2_gpu36
	layer_0_residual1_gpu36 -> layer_0_residual2_gpu36
	layer_0_final_allreduce -> layer_0_residual2_gpu37
	layer_0_residual1_gpu37 -> layer_0_residual2_gpu37
	layer_0_final_allreduce -> layer_0_residual2_gpu38
	layer_0_residual1_gpu38 -> layer_0_residual2_gpu38
	layer_0_final_allreduce -> layer_0_residual2_gpu39
	layer_0_residual1_gpu39 -> layer_0_residual2_gpu39
	layer_0_final_allreduce -> layer_0_residual2_gpu40
	layer_0_residual1_gpu40 -> layer_0_residual2_gpu40
	layer_0_final_allreduce -> layer_0_residual2_gpu41
	layer_0_residual1_gpu41 -> layer_0_residual2_gpu41
	layer_0_final_allreduce -> layer_0_residual2_gpu42
	layer_0_residual1_gpu42 -> layer_0_residual2_gpu42
	layer_0_final_allreduce -> layer_0_residual2_gpu43
	layer_0_residual1_gpu43 -> layer_0_residual2_gpu43
	layer_0_final_allreduce -> layer_0_residual2_gpu44
	layer_0_residual1_gpu44 -> layer_0_residual2_gpu44
	layer_0_final_allreduce -> layer_0_residual2_gpu45
	layer_0_residual1_gpu45 -> layer_0_residual2_gpu45
	layer_0_final_allreduce -> layer_0_residual2_gpu46
	layer_0_residual1_gpu46 -> layer_0_residual2_gpu46
	layer_0_final_allreduce -> layer_0_residual2_gpu47
	layer_0_residual1_gpu47 -> layer_0_residual2_gpu47
	layer_0_final_allreduce -> layer_0_residual2_gpu48
	layer_0_residual1_gpu48 -> layer_0_residual2_gpu48
	layer_0_final_allreduce -> layer_0_residual2_gpu49
	layer_0_residual1_gpu49 -> layer_0_residual2_gpu49
	layer_0_final_allreduce -> layer_0_residual2_gpu50
	layer_0_residual1_gpu50 -> layer_0_residual2_gpu50
	layer_0_final_allreduce -> layer_0_residual2_gpu51
	layer_0_residual1_gpu51 -> layer_0_residual2_gpu51
	layer_0_final_allreduce -> layer_0_residual2_gpu52
	layer_0_residual1_gpu52 -> layer_0_residual2_gpu52
	layer_0_final_allreduce -> layer_0_residual2_gpu53
	layer_0_residual1_gpu53 -> layer_0_residual2_gpu53
	layer_0_final_allreduce -> layer_0_residual2_gpu54
	layer_0_residual1_gpu54 -> layer_0_residual2_gpu54
	layer_0_final_allreduce -> layer_0_residual2_gpu55
	layer_0_residual1_gpu55 -> layer_0_residual2_gpu55
	layer_0_final_allreduce -> layer_0_residual2_gpu56
	layer_0_residual1_gpu56 -> layer_0_residual2_gpu56
	layer_0_final_allreduce -> layer_0_residual2_gpu57
	layer_0_residual1_gpu57 -> layer_0_residual2_gpu57
	layer_0_final_allreduce -> layer_0_residual2_gpu58
	layer_0_residual1_gpu58 -> layer_0_residual2_gpu58
	layer_0_final_allreduce -> layer_0_residual2_gpu59
	layer_0_residual1_gpu59 -> layer_0_residual2_gpu59
	layer_0_final_allreduce -> layer_0_residual2_gpu60
	layer_0_residual1_gpu60 -> layer_0_residual2_gpu60
	layer_0_final_allreduce -> layer_0_residual2_gpu61
	layer_0_residual1_gpu61 -> layer_0_residual2_gpu61
	layer_0_final_allreduce -> layer_0_residual2_gpu62
	layer_0_residual1_gpu62 -> layer_0_residual2_gpu62
	layer_0_final_allreduce -> layer_0_residual2_gpu63
	layer_0_residual1_gpu63 -> layer_0_residual2_gpu63
	layer_0_final_allreduce -> layer_0_residual2_gpu64
	layer_0_residual1_gpu64 -> layer_0_residual2_gpu64
	layer_0_final_allreduce -> layer_0_residual2_gpu65
	layer_0_residual1_gpu65 -> layer_0_residual2_gpu65
	layer_0_final_allreduce -> layer_0_residual2_gpu66
	layer_0_residual1_gpu66 -> layer_0_residual2_gpu66
	layer_0_final_allreduce -> layer_0_residual2_gpu67
	layer_0_residual1_gpu67 -> layer_0_residual2_gpu67
	layer_0_final_allreduce -> layer_0_residual2_gpu68
	layer_0_residual1_gpu68 -> layer_0_residual2_gpu68
	layer_0_final_allreduce -> layer_0_residual2_gpu69
	layer_0_residual1_gpu69 -> layer_0_residual2_gpu69
	layer_0_final_allreduce -> layer_0_residual2_gpu70
	layer_0_residual1_gpu70 -> layer_0_residual2_gpu70
	layer_0_final_allreduce -> layer_0_residual2_gpu71
	layer_0_residual1_gpu71 -> layer_0_residual2_gpu71
	layer_0_final_allreduce -> layer_0_residual2_gpu72
	layer_0_residual1_gpu72 -> layer_0_residual2_gpu72
	layer_0_final_allreduce -> layer_0_residual2_gpu73
	layer_0_residual1_gpu73 -> layer_0_residual2_gpu73
	layer_0_final_allreduce -> layer_0_residual2_gpu74
	layer_0_residual1_gpu74 -> layer_0_residual2_gpu74
	layer_0_final_allreduce -> layer_0_residual2_gpu75
	layer_0_residual1_gpu75 -> layer_0_residual2_gpu75
	layer_0_final_allreduce -> layer_0_residual2_gpu76
	layer_0_residual1_gpu76 -> layer_0_residual2_gpu76
	layer_0_final_allreduce -> layer_0_residual2_gpu77
	layer_0_residual1_gpu77 -> layer_0_residual2_gpu77
	layer_0_final_allreduce -> layer_0_residual2_gpu78
	layer_0_residual1_gpu78 -> layer_0_residual2_gpu78
	layer_0_final_allreduce -> layer_0_residual2_gpu79
	layer_0_residual1_gpu79 -> layer_0_residual2_gpu79
	layer_0_final_allreduce -> layer_0_residual2_gpu80
	layer_0_residual1_gpu80 -> layer_0_residual2_gpu80
	layer_0_final_allreduce -> layer_0_residual2_gpu81
	layer_0_residual1_gpu81 -> layer_0_residual2_gpu81
	layer_0_final_allreduce -> layer_0_residual2_gpu82
	layer_0_residual1_gpu82 -> layer_0_residual2_gpu82
	layer_0_final_allreduce -> layer_0_residual2_gpu83
	layer_0_residual1_gpu83 -> layer_0_residual2_gpu83
	layer_0_final_allreduce -> layer_0_residual2_gpu84
	layer_0_residual1_gpu84 -> layer_0_residual2_gpu84
	layer_0_final_allreduce -> layer_0_residual2_gpu85
	layer_0_residual1_gpu85 -> layer_0_residual2_gpu85
	layer_0_final_allreduce -> layer_0_residual2_gpu86
	layer_0_residual1_gpu86 -> layer_0_residual2_gpu86
	layer_0_final_allreduce -> layer_0_residual2_gpu87
	layer_0_residual1_gpu87 -> layer_0_residual2_gpu87
	layer_0_final_allreduce -> layer_0_residual2_gpu88
	layer_0_residual1_gpu88 -> layer_0_residual2_gpu88
	layer_0_final_allreduce -> layer_0_residual2_gpu89
	layer_0_residual1_gpu89 -> layer_0_residual2_gpu89
	layer_0_final_allreduce -> layer_0_residual2_gpu90
	layer_0_residual1_gpu90 -> layer_0_residual2_gpu90
	layer_0_final_allreduce -> layer_0_residual2_gpu91
	layer_0_residual1_gpu91 -> layer_0_residual2_gpu91
	layer_0_final_allreduce -> layer_0_residual2_gpu92
	layer_0_residual1_gpu92 -> layer_0_residual2_gpu92
	layer_0_final_allreduce -> layer_0_residual2_gpu93
	layer_0_residual1_gpu93 -> layer_0_residual2_gpu93
	layer_0_final_allreduce -> layer_0_residual2_gpu94
	layer_0_residual1_gpu94 -> layer_0_residual2_gpu94
	layer_0_final_allreduce -> layer_0_residual2_gpu95
	layer_0_residual1_gpu95 -> layer_0_residual2_gpu95
	layer_0_final_allreduce -> layer_0_residual2_gpu96
	layer_0_residual1_gpu96 -> layer_0_residual2_gpu96
	layer_0_final_allreduce -> layer_0_residual2_gpu97
	layer_0_residual1_gpu97 -> layer_0_residual2_gpu97
	layer_0_final_allreduce -> layer_0_residual2_gpu98
	layer_0_residual1_gpu98 -> layer_0_residual2_gpu98
	layer_0_final_allreduce -> layer_0_residual2_gpu99
	layer_0_residual1_gpu99 -> layer_0_residual2_gpu99
	layer_0_final_allreduce -> layer_0_residual2_gpu100
	layer_0_residual1_gpu100 -> layer_0_residual2_gpu100
	layer_0_final_allreduce -> layer_0_residual2_gpu101
	layer_0_residual1_gpu101 -> layer_0_residual2_gpu101
	layer_0_final_allreduce -> layer_0_residual2_gpu102
	layer_0_residual1_gpu102 -> layer_0_residual2_gpu102
	layer_0_final_allreduce -> layer_0_residual2_gpu103
	layer_0_residual1_gpu103 -> layer_0_residual2_gpu103
	layer_0_final_allreduce -> layer_0_residual2_gpu104
	layer_0_residual1_gpu104 -> layer_0_residual2_gpu104
	layer_0_final_allreduce -> layer_0_residual2_gpu105
	layer_0_residual1_gpu105 -> layer_0_residual2_gpu105
	layer_0_final_allreduce -> layer_0_residual2_gpu106
	layer_0_residual1_gpu106 -> layer_0_residual2_gpu106
	layer_0_final_allreduce -> layer_0_residual2_gpu107
	layer_0_residual1_gpu107 -> layer_0_residual2_gpu107
	layer_0_final_allreduce -> layer_0_residual2_gpu108
	layer_0_residual1_gpu108 -> layer_0_residual2_gpu108
	layer_0_final_allreduce -> layer_0_residual2_gpu109
	layer_0_residual1_gpu109 -> layer_0_residual2_gpu109
	layer_0_final_allreduce -> layer_0_residual2_gpu110
	layer_0_residual1_gpu110 -> layer_0_residual2_gpu110
	layer_0_final_allreduce -> layer_0_residual2_gpu111
	layer_0_residual1_gpu111 -> layer_0_residual2_gpu111
	layer_0_final_allreduce -> layer_0_residual2_gpu112
	layer_0_residual1_gpu112 -> layer_0_residual2_gpu112
	layer_0_final_allreduce -> layer_0_residual2_gpu113
	layer_0_residual1_gpu113 -> layer_0_residual2_gpu113
	layer_0_final_allreduce -> layer_0_residual2_gpu114
	layer_0_residual1_gpu114 -> layer_0_residual2_gpu114
	layer_0_final_allreduce -> layer_0_residual2_gpu115
	layer_0_residual1_gpu115 -> layer_0_residual2_gpu115
	layer_0_final_allreduce -> layer_0_residual2_gpu116
	layer_0_residual1_gpu116 -> layer_0_residual2_gpu116
	layer_0_final_allreduce -> layer_0_residual2_gpu117
	layer_0_residual1_gpu117 -> layer_0_residual2_gpu117
	layer_0_final_allreduce -> layer_0_residual2_gpu118
	layer_0_residual1_gpu118 -> layer_0_residual2_gpu118
	layer_0_final_allreduce -> layer_0_residual2_gpu119
	layer_0_residual1_gpu119 -> layer_0_residual2_gpu119
	layer_0_final_allreduce -> layer_0_residual2_gpu120
	layer_0_residual1_gpu120 -> layer_0_residual2_gpu120
	layer_0_final_allreduce -> layer_0_residual2_gpu121
	layer_0_residual1_gpu121 -> layer_0_residual2_gpu121
	layer_0_final_allreduce -> layer_0_residual2_gpu122
	layer_0_residual1_gpu122 -> layer_0_residual2_gpu122
	layer_0_final_allreduce -> layer_0_residual2_gpu123
	layer_0_residual1_gpu123 -> layer_0_residual2_gpu123
	layer_0_final_allreduce -> layer_0_residual2_gpu124
	layer_0_residual1_gpu124 -> layer_0_residual2_gpu124
	layer_0_final_allreduce -> layer_0_residual2_gpu125
	layer_0_residual1_gpu125 -> layer_0_residual2_gpu125
	layer_0_final_allreduce -> layer_0_residual2_gpu126
	layer_0_residual1_gpu126 -> layer_0_residual2_gpu126
	layer_0_final_allreduce -> layer_0_residual2_gpu127
	layer_0_residual1_gpu127 -> layer_0_residual2_gpu127
	layer_0_residual2_gpu0 -> layers_1_15_summary
	layers_1_15_summary -> output
}
