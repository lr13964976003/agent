{
  "generated_dag_files": {
    "main_deployment_dag": {
      "dot_file": "../outputs/2025-12-04-15-51-54/moe_deployment_dag.dot",
      "svg_file": "../outputs/2025-12-04-15-51-54/moe_deployment_dag.svg",
      "description": "Complete 128-GPU MoE model deployment DAG with all pipeline stages, expert parallelism, and tensor parallelism"
    },
    "communication_dag": {
      "dot_file": "../outputs/2025-12-04-15-51-54/moe_communication_dag.dot",
      "svg_file": "../outputs/2025-12-04-15-51-54/moe_communication_dag.svg",
      "description": "Communication-focused DAG showing all-reduce, all-gather, and pipeline communication patterns"
    },
    "simplified_dag": {
      "dot_file": "../outputs/2025-12-04-15-51-54/moe_simplified_dag.dot",
      "svg_file": "../outputs/2025-12-04-15-51-54/moe_simplified_dag.svg",
      "description": "Simplified high-level DAG showing major components and communication flows"
    }
  },
  "dag_characteristics": {
    "total_gpus": 128,
    "pipeline_stages": 4,
    "experts_per_layer": 64,
    "tensor_parallelism": 2,
    "expert_parallelism": 64,
    "communication_patterns": ["all-reduce", "all-gather", "pipeline-send", "expert-routing"],
    "node_shapes": {
      "computation": "rectangle",
      "communication": "ellipse", 
      "routing/aggregation": "parallelogram"
    },
    "cycle_check": "passed - no cycles detected",
    "connectivity": "all nodes properly connected with inputs and outputs"
  },
  "meets_requirements": {
    "gpu_boundaries": true,
    "communication_types": true,
    "operator_level_detail": true,
    "input_output_dimensions": true,
    "node_shapes": true,
    "no_cycles": true,
    "proper_connectivity": true
  }
}