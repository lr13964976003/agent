// 128-GPU MoE Model Deployment DAG
digraph MoE_128GPU_Deployment {
	graph [bgcolor=white fontname=Arial fontsize=12 nodesep=0.5 rankdir=TB ranksep=1.0 splines=ortho]
	node [fillcolor=lightblue shape=rectangle style=filled]
	edge [fontname=Arial fontsize=10]
	input [label="Input\nInput: [batch_size=?, seq_len=?]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightgreen shape=ellipse style="filled,bold"]
	subgraph cluster_stage_0 {
		color=blue fillcolor=lightyellow label="Pipeline Stage 0 (Layers 0-3)" style="rounded,filled"
		subgraph cluster_expert_0 {
			color=red fillcolor=lightgray label="Expert 0" style="rounded,filled"
			attn_norm_s0_e0_l0_gpu0 [label="LayerNorm GPU0\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e0_l0_gpu1 [label="LayerNorm GPU1\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e0_l0_gpu0 [label="Attn-Q GPU0\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e0_l0_gpu1 [label="Attn-Q GPU1\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e0_l0_gpu0 [label="Attn-K/V GPU0\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e0_l0_gpu1 [label="Attn-K/V GPU1\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e0_l0_gpu0 [label="Attn-Out GPU0\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e0_l0_gpu1 [label="Attn-Out GPU1\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e0_l0_gpu0 [label="MLP-Gate GPU0\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e0_l0_gpu1 [label="MLP-Gate GPU1\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e0_l0_gpu0 [label="MLP-Up GPU0\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e0_l0_gpu1 [label="MLP-Up GPU1\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e0_l0_gpu0 [label="MLP-Down GPU0\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e0_l0_gpu1 [label="MLP-Down GPU1\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e0_l1_gpu0 [label="LayerNorm GPU0\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e0_l1_gpu1 [label="LayerNorm GPU1\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e0_l1_gpu0 [label="Attn-Q GPU0\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e0_l1_gpu1 [label="Attn-Q GPU1\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e0_l1_gpu0 [label="Attn-K/V GPU0\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e0_l1_gpu1 [label="Attn-K/V GPU1\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e0_l1_gpu0 [label="Attn-Out GPU0\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e0_l1_gpu1 [label="Attn-Out GPU1\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e0_l1_gpu0 [label="MLP-Gate GPU0\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e0_l1_gpu1 [label="MLP-Gate GPU1\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e0_l1_gpu0 [label="MLP-Up GPU0\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e0_l1_gpu1 [label="MLP-Up GPU1\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e0_l1_gpu0 [label="MLP-Down GPU0\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e0_l1_gpu1 [label="MLP-Down GPU1\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e0_l2_gpu0 [label="LayerNorm GPU0\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e0_l2_gpu1 [label="LayerNorm GPU1\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e0_l2_gpu0 [label="Attn-Q GPU0\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e0_l2_gpu1 [label="Attn-Q GPU1\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e0_l2_gpu0 [label="Attn-K/V GPU0\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e0_l2_gpu1 [label="Attn-K/V GPU1\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e0_l2_gpu0 [label="Attn-Out GPU0\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e0_l2_gpu1 [label="Attn-Out GPU1\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e0_l2_gpu0 [label="MLP-Gate GPU0\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e0_l2_gpu1 [label="MLP-Gate GPU1\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e0_l2_gpu0 [label="MLP-Up GPU0\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e0_l2_gpu1 [label="MLP-Up GPU1\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e0_l2_gpu0 [label="MLP-Down GPU0\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e0_l2_gpu1 [label="MLP-Down GPU1\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e0_l3_gpu0 [label="LayerNorm GPU0\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e0_l3_gpu1 [label="LayerNorm GPU1\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e0_l3_gpu0 [label="Attn-Q GPU0\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e0_l3_gpu1 [label="Attn-Q GPU1\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e0_l3_gpu0 [label="Attn-K/V GPU0\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e0_l3_gpu1 [label="Attn-K/V GPU1\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e0_l3_gpu0 [label="Attn-Out GPU0\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e0_l3_gpu1 [label="Attn-Out GPU1\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e0_l3_gpu0 [label="MLP-Gate GPU0\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e0_l3_gpu1 [label="MLP-Gate GPU1\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e0_l3_gpu0 [label="MLP-Up GPU0\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e0_l3_gpu1 [label="MLP-Up GPU1\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e0_l3_gpu0 [label="MLP-Down GPU0\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e0_l3_gpu1 [label="MLP-Down GPU1\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_1 {
			color=red fillcolor=lightgray label="Expert 1" style="rounded,filled"
			attn_norm_s0_e1_l0_gpu2 [label="LayerNorm GPU2\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e1_l0_gpu3 [label="LayerNorm GPU3\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e1_l0_gpu2 [label="Attn-Q GPU2\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e1_l0_gpu3 [label="Attn-Q GPU3\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e1_l0_gpu2 [label="Attn-K/V GPU2\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e1_l0_gpu3 [label="Attn-K/V GPU3\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e1_l0_gpu2 [label="Attn-Out GPU2\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e1_l0_gpu3 [label="Attn-Out GPU3\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e1_l0_gpu2 [label="MLP-Gate GPU2\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e1_l0_gpu3 [label="MLP-Gate GPU3\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e1_l0_gpu2 [label="MLP-Up GPU2\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e1_l0_gpu3 [label="MLP-Up GPU3\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e1_l0_gpu2 [label="MLP-Down GPU2\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e1_l0_gpu3 [label="MLP-Down GPU3\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e1_l1_gpu2 [label="LayerNorm GPU2\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e1_l1_gpu3 [label="LayerNorm GPU3\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e1_l1_gpu2 [label="Attn-Q GPU2\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e1_l1_gpu3 [label="Attn-Q GPU3\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e1_l1_gpu2 [label="Attn-K/V GPU2\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e1_l1_gpu3 [label="Attn-K/V GPU3\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e1_l1_gpu2 [label="Attn-Out GPU2\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e1_l1_gpu3 [label="Attn-Out GPU3\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e1_l1_gpu2 [label="MLP-Gate GPU2\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e1_l1_gpu3 [label="MLP-Gate GPU3\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e1_l1_gpu2 [label="MLP-Up GPU2\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e1_l1_gpu3 [label="MLP-Up GPU3\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e1_l1_gpu2 [label="MLP-Down GPU2\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e1_l1_gpu3 [label="MLP-Down GPU3\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e1_l2_gpu2 [label="LayerNorm GPU2\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e1_l2_gpu3 [label="LayerNorm GPU3\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e1_l2_gpu2 [label="Attn-Q GPU2\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e1_l2_gpu3 [label="Attn-Q GPU3\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e1_l2_gpu2 [label="Attn-K/V GPU2\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e1_l2_gpu3 [label="Attn-K/V GPU3\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e1_l2_gpu2 [label="Attn-Out GPU2\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e1_l2_gpu3 [label="Attn-Out GPU3\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e1_l2_gpu2 [label="MLP-Gate GPU2\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e1_l2_gpu3 [label="MLP-Gate GPU3\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e1_l2_gpu2 [label="MLP-Up GPU2\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e1_l2_gpu3 [label="MLP-Up GPU3\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e1_l2_gpu2 [label="MLP-Down GPU2\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e1_l2_gpu3 [label="MLP-Down GPU3\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e1_l3_gpu2 [label="LayerNorm GPU2\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e1_l3_gpu3 [label="LayerNorm GPU3\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e1_l3_gpu2 [label="Attn-Q GPU2\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e1_l3_gpu3 [label="Attn-Q GPU3\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e1_l3_gpu2 [label="Attn-K/V GPU2\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e1_l3_gpu3 [label="Attn-K/V GPU3\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e1_l3_gpu2 [label="Attn-Out GPU2\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e1_l3_gpu3 [label="Attn-Out GPU3\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e1_l3_gpu2 [label="MLP-Gate GPU2\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e1_l3_gpu3 [label="MLP-Gate GPU3\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e1_l3_gpu2 [label="MLP-Up GPU2\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e1_l3_gpu3 [label="MLP-Up GPU3\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e1_l3_gpu2 [label="MLP-Down GPU2\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e1_l3_gpu3 [label="MLP-Down GPU3\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_2 {
			color=red fillcolor=lightgray label="Expert 2" style="rounded,filled"
			attn_norm_s0_e2_l0_gpu4 [label="LayerNorm GPU4\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e2_l0_gpu5 [label="LayerNorm GPU5\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e2_l0_gpu4 [label="Attn-Q GPU4\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e2_l0_gpu5 [label="Attn-Q GPU5\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e2_l0_gpu4 [label="Attn-K/V GPU4\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e2_l0_gpu5 [label="Attn-K/V GPU5\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e2_l0_gpu4 [label="Attn-Out GPU4\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e2_l0_gpu5 [label="Attn-Out GPU5\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e2_l0_gpu4 [label="MLP-Gate GPU4\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e2_l0_gpu5 [label="MLP-Gate GPU5\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e2_l0_gpu4 [label="MLP-Up GPU4\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e2_l0_gpu5 [label="MLP-Up GPU5\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e2_l0_gpu4 [label="MLP-Down GPU4\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e2_l0_gpu5 [label="MLP-Down GPU5\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e2_l1_gpu4 [label="LayerNorm GPU4\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e2_l1_gpu5 [label="LayerNorm GPU5\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e2_l1_gpu4 [label="Attn-Q GPU4\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e2_l1_gpu5 [label="Attn-Q GPU5\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e2_l1_gpu4 [label="Attn-K/V GPU4\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e2_l1_gpu5 [label="Attn-K/V GPU5\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e2_l1_gpu4 [label="Attn-Out GPU4\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e2_l1_gpu5 [label="Attn-Out GPU5\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e2_l1_gpu4 [label="MLP-Gate GPU4\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e2_l1_gpu5 [label="MLP-Gate GPU5\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e2_l1_gpu4 [label="MLP-Up GPU4\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e2_l1_gpu5 [label="MLP-Up GPU5\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e2_l1_gpu4 [label="MLP-Down GPU4\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e2_l1_gpu5 [label="MLP-Down GPU5\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e2_l2_gpu4 [label="LayerNorm GPU4\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e2_l2_gpu5 [label="LayerNorm GPU5\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e2_l2_gpu4 [label="Attn-Q GPU4\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e2_l2_gpu5 [label="Attn-Q GPU5\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e2_l2_gpu4 [label="Attn-K/V GPU4\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e2_l2_gpu5 [label="Attn-K/V GPU5\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e2_l2_gpu4 [label="Attn-Out GPU4\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e2_l2_gpu5 [label="Attn-Out GPU5\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e2_l2_gpu4 [label="MLP-Gate GPU4\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e2_l2_gpu5 [label="MLP-Gate GPU5\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e2_l2_gpu4 [label="MLP-Up GPU4\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e2_l2_gpu5 [label="MLP-Up GPU5\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e2_l2_gpu4 [label="MLP-Down GPU4\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e2_l2_gpu5 [label="MLP-Down GPU5\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e2_l3_gpu4 [label="LayerNorm GPU4\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e2_l3_gpu5 [label="LayerNorm GPU5\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e2_l3_gpu4 [label="Attn-Q GPU4\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e2_l3_gpu5 [label="Attn-Q GPU5\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e2_l3_gpu4 [label="Attn-K/V GPU4\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e2_l3_gpu5 [label="Attn-K/V GPU5\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e2_l3_gpu4 [label="Attn-Out GPU4\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e2_l3_gpu5 [label="Attn-Out GPU5\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e2_l3_gpu4 [label="MLP-Gate GPU4\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e2_l3_gpu5 [label="MLP-Gate GPU5\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e2_l3_gpu4 [label="MLP-Up GPU4\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e2_l3_gpu5 [label="MLP-Up GPU5\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e2_l3_gpu4 [label="MLP-Down GPU4\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e2_l3_gpu5 [label="MLP-Down GPU5\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_3 {
			color=red fillcolor=lightgray label="Expert 3" style="rounded,filled"
			attn_norm_s0_e3_l0_gpu6 [label="LayerNorm GPU6\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e3_l0_gpu7 [label="LayerNorm GPU7\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e3_l0_gpu6 [label="Attn-Q GPU6\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e3_l0_gpu7 [label="Attn-Q GPU7\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e3_l0_gpu6 [label="Attn-K/V GPU6\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e3_l0_gpu7 [label="Attn-K/V GPU7\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e3_l0_gpu6 [label="Attn-Out GPU6\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e3_l0_gpu7 [label="Attn-Out GPU7\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e3_l0_gpu6 [label="MLP-Gate GPU6\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e3_l0_gpu7 [label="MLP-Gate GPU7\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e3_l0_gpu6 [label="MLP-Up GPU6\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e3_l0_gpu7 [label="MLP-Up GPU7\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e3_l0_gpu6 [label="MLP-Down GPU6\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e3_l0_gpu7 [label="MLP-Down GPU7\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e3_l1_gpu6 [label="LayerNorm GPU6\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e3_l1_gpu7 [label="LayerNorm GPU7\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e3_l1_gpu6 [label="Attn-Q GPU6\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e3_l1_gpu7 [label="Attn-Q GPU7\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e3_l1_gpu6 [label="Attn-K/V GPU6\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e3_l1_gpu7 [label="Attn-K/V GPU7\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e3_l1_gpu6 [label="Attn-Out GPU6\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e3_l1_gpu7 [label="Attn-Out GPU7\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e3_l1_gpu6 [label="MLP-Gate GPU6\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e3_l1_gpu7 [label="MLP-Gate GPU7\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e3_l1_gpu6 [label="MLP-Up GPU6\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e3_l1_gpu7 [label="MLP-Up GPU7\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e3_l1_gpu6 [label="MLP-Down GPU6\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e3_l1_gpu7 [label="MLP-Down GPU7\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e3_l2_gpu6 [label="LayerNorm GPU6\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e3_l2_gpu7 [label="LayerNorm GPU7\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e3_l2_gpu6 [label="Attn-Q GPU6\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e3_l2_gpu7 [label="Attn-Q GPU7\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e3_l2_gpu6 [label="Attn-K/V GPU6\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e3_l2_gpu7 [label="Attn-K/V GPU7\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e3_l2_gpu6 [label="Attn-Out GPU6\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e3_l2_gpu7 [label="Attn-Out GPU7\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e3_l2_gpu6 [label="MLP-Gate GPU6\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e3_l2_gpu7 [label="MLP-Gate GPU7\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e3_l2_gpu6 [label="MLP-Up GPU6\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e3_l2_gpu7 [label="MLP-Up GPU7\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e3_l2_gpu6 [label="MLP-Down GPU6\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e3_l2_gpu7 [label="MLP-Down GPU7\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e3_l3_gpu6 [label="LayerNorm GPU6\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e3_l3_gpu7 [label="LayerNorm GPU7\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e3_l3_gpu6 [label="Attn-Q GPU6\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e3_l3_gpu7 [label="Attn-Q GPU7\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e3_l3_gpu6 [label="Attn-K/V GPU6\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e3_l3_gpu7 [label="Attn-K/V GPU7\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e3_l3_gpu6 [label="Attn-Out GPU6\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e3_l3_gpu7 [label="Attn-Out GPU7\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e3_l3_gpu6 [label="MLP-Gate GPU6\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e3_l3_gpu7 [label="MLP-Gate GPU7\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e3_l3_gpu6 [label="MLP-Up GPU6\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e3_l3_gpu7 [label="MLP-Up GPU7\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e3_l3_gpu6 [label="MLP-Down GPU6\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e3_l3_gpu7 [label="MLP-Down GPU7\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_4 {
			color=red fillcolor=lightgray label="Expert 4" style="rounded,filled"
			attn_norm_s0_e4_l0_gpu8 [label="LayerNorm GPU8\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e4_l0_gpu9 [label="LayerNorm GPU9\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e4_l0_gpu8 [label="Attn-Q GPU8\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e4_l0_gpu9 [label="Attn-Q GPU9\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e4_l0_gpu8 [label="Attn-K/V GPU8\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e4_l0_gpu9 [label="Attn-K/V GPU9\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e4_l0_gpu8 [label="Attn-Out GPU8\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e4_l0_gpu9 [label="Attn-Out GPU9\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e4_l0_gpu8 [label="MLP-Gate GPU8\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e4_l0_gpu9 [label="MLP-Gate GPU9\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e4_l0_gpu8 [label="MLP-Up GPU8\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e4_l0_gpu9 [label="MLP-Up GPU9\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e4_l0_gpu8 [label="MLP-Down GPU8\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e4_l0_gpu9 [label="MLP-Down GPU9\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e4_l1_gpu8 [label="LayerNorm GPU8\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e4_l1_gpu9 [label="LayerNorm GPU9\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e4_l1_gpu8 [label="Attn-Q GPU8\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e4_l1_gpu9 [label="Attn-Q GPU9\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e4_l1_gpu8 [label="Attn-K/V GPU8\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e4_l1_gpu9 [label="Attn-K/V GPU9\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e4_l1_gpu8 [label="Attn-Out GPU8\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e4_l1_gpu9 [label="Attn-Out GPU9\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e4_l1_gpu8 [label="MLP-Gate GPU8\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e4_l1_gpu9 [label="MLP-Gate GPU9\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e4_l1_gpu8 [label="MLP-Up GPU8\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e4_l1_gpu9 [label="MLP-Up GPU9\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e4_l1_gpu8 [label="MLP-Down GPU8\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e4_l1_gpu9 [label="MLP-Down GPU9\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e4_l2_gpu8 [label="LayerNorm GPU8\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e4_l2_gpu9 [label="LayerNorm GPU9\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e4_l2_gpu8 [label="Attn-Q GPU8\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e4_l2_gpu9 [label="Attn-Q GPU9\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e4_l2_gpu8 [label="Attn-K/V GPU8\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e4_l2_gpu9 [label="Attn-K/V GPU9\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e4_l2_gpu8 [label="Attn-Out GPU8\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e4_l2_gpu9 [label="Attn-Out GPU9\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e4_l2_gpu8 [label="MLP-Gate GPU8\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e4_l2_gpu9 [label="MLP-Gate GPU9\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e4_l2_gpu8 [label="MLP-Up GPU8\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e4_l2_gpu9 [label="MLP-Up GPU9\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e4_l2_gpu8 [label="MLP-Down GPU8\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e4_l2_gpu9 [label="MLP-Down GPU9\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e4_l3_gpu8 [label="LayerNorm GPU8\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e4_l3_gpu9 [label="LayerNorm GPU9\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e4_l3_gpu8 [label="Attn-Q GPU8\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e4_l3_gpu9 [label="Attn-Q GPU9\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e4_l3_gpu8 [label="Attn-K/V GPU8\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e4_l3_gpu9 [label="Attn-K/V GPU9\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e4_l3_gpu8 [label="Attn-Out GPU8\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e4_l3_gpu9 [label="Attn-Out GPU9\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e4_l3_gpu8 [label="MLP-Gate GPU8\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e4_l3_gpu9 [label="MLP-Gate GPU9\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e4_l3_gpu8 [label="MLP-Up GPU8\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e4_l3_gpu9 [label="MLP-Up GPU9\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e4_l3_gpu8 [label="MLP-Down GPU8\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e4_l3_gpu9 [label="MLP-Down GPU9\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_5 {
			color=red fillcolor=lightgray label="Expert 5" style="rounded,filled"
			attn_norm_s0_e5_l0_gpu10 [label="LayerNorm GPU10\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e5_l0_gpu11 [label="LayerNorm GPU11\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e5_l0_gpu10 [label="Attn-Q GPU10\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e5_l0_gpu11 [label="Attn-Q GPU11\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e5_l0_gpu10 [label="Attn-K/V GPU10\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e5_l0_gpu11 [label="Attn-K/V GPU11\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e5_l0_gpu10 [label="Attn-Out GPU10\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e5_l0_gpu11 [label="Attn-Out GPU11\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e5_l0_gpu10 [label="MLP-Gate GPU10\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e5_l0_gpu11 [label="MLP-Gate GPU11\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e5_l0_gpu10 [label="MLP-Up GPU10\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e5_l0_gpu11 [label="MLP-Up GPU11\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e5_l0_gpu10 [label="MLP-Down GPU10\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e5_l0_gpu11 [label="MLP-Down GPU11\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e5_l1_gpu10 [label="LayerNorm GPU10\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e5_l1_gpu11 [label="LayerNorm GPU11\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e5_l1_gpu10 [label="Attn-Q GPU10\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e5_l1_gpu11 [label="Attn-Q GPU11\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e5_l1_gpu10 [label="Attn-K/V GPU10\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e5_l1_gpu11 [label="Attn-K/V GPU11\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e5_l1_gpu10 [label="Attn-Out GPU10\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e5_l1_gpu11 [label="Attn-Out GPU11\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e5_l1_gpu10 [label="MLP-Gate GPU10\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e5_l1_gpu11 [label="MLP-Gate GPU11\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e5_l1_gpu10 [label="MLP-Up GPU10\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e5_l1_gpu11 [label="MLP-Up GPU11\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e5_l1_gpu10 [label="MLP-Down GPU10\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e5_l1_gpu11 [label="MLP-Down GPU11\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e5_l2_gpu10 [label="LayerNorm GPU10\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e5_l2_gpu11 [label="LayerNorm GPU11\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e5_l2_gpu10 [label="Attn-Q GPU10\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e5_l2_gpu11 [label="Attn-Q GPU11\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e5_l2_gpu10 [label="Attn-K/V GPU10\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e5_l2_gpu11 [label="Attn-K/V GPU11\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e5_l2_gpu10 [label="Attn-Out GPU10\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e5_l2_gpu11 [label="Attn-Out GPU11\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e5_l2_gpu10 [label="MLP-Gate GPU10\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e5_l2_gpu11 [label="MLP-Gate GPU11\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e5_l2_gpu10 [label="MLP-Up GPU10\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e5_l2_gpu11 [label="MLP-Up GPU11\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e5_l2_gpu10 [label="MLP-Down GPU10\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e5_l2_gpu11 [label="MLP-Down GPU11\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e5_l3_gpu10 [label="LayerNorm GPU10\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e5_l3_gpu11 [label="LayerNorm GPU11\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e5_l3_gpu10 [label="Attn-Q GPU10\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e5_l3_gpu11 [label="Attn-Q GPU11\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e5_l3_gpu10 [label="Attn-K/V GPU10\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e5_l3_gpu11 [label="Attn-K/V GPU11\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e5_l3_gpu10 [label="Attn-Out GPU10\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e5_l3_gpu11 [label="Attn-Out GPU11\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e5_l3_gpu10 [label="MLP-Gate GPU10\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e5_l3_gpu11 [label="MLP-Gate GPU11\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e5_l3_gpu10 [label="MLP-Up GPU10\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e5_l3_gpu11 [label="MLP-Up GPU11\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e5_l3_gpu10 [label="MLP-Down GPU10\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e5_l3_gpu11 [label="MLP-Down GPU11\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_6 {
			color=red fillcolor=lightgray label="Expert 6" style="rounded,filled"
			attn_norm_s0_e6_l0_gpu12 [label="LayerNorm GPU12\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e6_l0_gpu13 [label="LayerNorm GPU13\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e6_l0_gpu12 [label="Attn-Q GPU12\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e6_l0_gpu13 [label="Attn-Q GPU13\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e6_l0_gpu12 [label="Attn-K/V GPU12\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e6_l0_gpu13 [label="Attn-K/V GPU13\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e6_l0_gpu12 [label="Attn-Out GPU12\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e6_l0_gpu13 [label="Attn-Out GPU13\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e6_l0_gpu12 [label="MLP-Gate GPU12\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e6_l0_gpu13 [label="MLP-Gate GPU13\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e6_l0_gpu12 [label="MLP-Up GPU12\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e6_l0_gpu13 [label="MLP-Up GPU13\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e6_l0_gpu12 [label="MLP-Down GPU12\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e6_l0_gpu13 [label="MLP-Down GPU13\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e6_l1_gpu12 [label="LayerNorm GPU12\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e6_l1_gpu13 [label="LayerNorm GPU13\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e6_l1_gpu12 [label="Attn-Q GPU12\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e6_l1_gpu13 [label="Attn-Q GPU13\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e6_l1_gpu12 [label="Attn-K/V GPU12\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e6_l1_gpu13 [label="Attn-K/V GPU13\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e6_l1_gpu12 [label="Attn-Out GPU12\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e6_l1_gpu13 [label="Attn-Out GPU13\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e6_l1_gpu12 [label="MLP-Gate GPU12\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e6_l1_gpu13 [label="MLP-Gate GPU13\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e6_l1_gpu12 [label="MLP-Up GPU12\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e6_l1_gpu13 [label="MLP-Up GPU13\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e6_l1_gpu12 [label="MLP-Down GPU12\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e6_l1_gpu13 [label="MLP-Down GPU13\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e6_l2_gpu12 [label="LayerNorm GPU12\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e6_l2_gpu13 [label="LayerNorm GPU13\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e6_l2_gpu12 [label="Attn-Q GPU12\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e6_l2_gpu13 [label="Attn-Q GPU13\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e6_l2_gpu12 [label="Attn-K/V GPU12\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e6_l2_gpu13 [label="Attn-K/V GPU13\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e6_l2_gpu12 [label="Attn-Out GPU12\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e6_l2_gpu13 [label="Attn-Out GPU13\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e6_l2_gpu12 [label="MLP-Gate GPU12\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e6_l2_gpu13 [label="MLP-Gate GPU13\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e6_l2_gpu12 [label="MLP-Up GPU12\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e6_l2_gpu13 [label="MLP-Up GPU13\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e6_l2_gpu12 [label="MLP-Down GPU12\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e6_l2_gpu13 [label="MLP-Down GPU13\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e6_l3_gpu12 [label="LayerNorm GPU12\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e6_l3_gpu13 [label="LayerNorm GPU13\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e6_l3_gpu12 [label="Attn-Q GPU12\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e6_l3_gpu13 [label="Attn-Q GPU13\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e6_l3_gpu12 [label="Attn-K/V GPU12\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e6_l3_gpu13 [label="Attn-K/V GPU13\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e6_l3_gpu12 [label="Attn-Out GPU12\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e6_l3_gpu13 [label="Attn-Out GPU13\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e6_l3_gpu12 [label="MLP-Gate GPU12\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e6_l3_gpu13 [label="MLP-Gate GPU13\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e6_l3_gpu12 [label="MLP-Up GPU12\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e6_l3_gpu13 [label="MLP-Up GPU13\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e6_l3_gpu12 [label="MLP-Down GPU12\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e6_l3_gpu13 [label="MLP-Down GPU13\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_7 {
			color=red fillcolor=lightgray label="Expert 7" style="rounded,filled"
			attn_norm_s0_e7_l0_gpu14 [label="LayerNorm GPU14\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e7_l0_gpu15 [label="LayerNorm GPU15\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e7_l0_gpu14 [label="Attn-Q GPU14\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e7_l0_gpu15 [label="Attn-Q GPU15\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e7_l0_gpu14 [label="Attn-K/V GPU14\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e7_l0_gpu15 [label="Attn-K/V GPU15\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e7_l0_gpu14 [label="Attn-Out GPU14\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e7_l0_gpu15 [label="Attn-Out GPU15\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e7_l0_gpu14 [label="MLP-Gate GPU14\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e7_l0_gpu15 [label="MLP-Gate GPU15\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e7_l0_gpu14 [label="MLP-Up GPU14\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e7_l0_gpu15 [label="MLP-Up GPU15\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e7_l0_gpu14 [label="MLP-Down GPU14\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e7_l0_gpu15 [label="MLP-Down GPU15\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e7_l1_gpu14 [label="LayerNorm GPU14\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e7_l1_gpu15 [label="LayerNorm GPU15\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e7_l1_gpu14 [label="Attn-Q GPU14\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e7_l1_gpu15 [label="Attn-Q GPU15\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e7_l1_gpu14 [label="Attn-K/V GPU14\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e7_l1_gpu15 [label="Attn-K/V GPU15\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e7_l1_gpu14 [label="Attn-Out GPU14\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e7_l1_gpu15 [label="Attn-Out GPU15\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e7_l1_gpu14 [label="MLP-Gate GPU14\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e7_l1_gpu15 [label="MLP-Gate GPU15\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e7_l1_gpu14 [label="MLP-Up GPU14\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e7_l1_gpu15 [label="MLP-Up GPU15\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e7_l1_gpu14 [label="MLP-Down GPU14\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e7_l1_gpu15 [label="MLP-Down GPU15\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e7_l2_gpu14 [label="LayerNorm GPU14\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e7_l2_gpu15 [label="LayerNorm GPU15\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e7_l2_gpu14 [label="Attn-Q GPU14\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e7_l2_gpu15 [label="Attn-Q GPU15\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e7_l2_gpu14 [label="Attn-K/V GPU14\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e7_l2_gpu15 [label="Attn-K/V GPU15\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e7_l2_gpu14 [label="Attn-Out GPU14\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e7_l2_gpu15 [label="Attn-Out GPU15\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e7_l2_gpu14 [label="MLP-Gate GPU14\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e7_l2_gpu15 [label="MLP-Gate GPU15\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e7_l2_gpu14 [label="MLP-Up GPU14\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e7_l2_gpu15 [label="MLP-Up GPU15\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e7_l2_gpu14 [label="MLP-Down GPU14\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e7_l2_gpu15 [label="MLP-Down GPU15\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e7_l3_gpu14 [label="LayerNorm GPU14\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e7_l3_gpu15 [label="LayerNorm GPU15\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e7_l3_gpu14 [label="Attn-Q GPU14\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e7_l3_gpu15 [label="Attn-Q GPU15\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e7_l3_gpu14 [label="Attn-K/V GPU14\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e7_l3_gpu15 [label="Attn-K/V GPU15\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e7_l3_gpu14 [label="Attn-Out GPU14\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e7_l3_gpu15 [label="Attn-Out GPU15\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e7_l3_gpu14 [label="MLP-Gate GPU14\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e7_l3_gpu15 [label="MLP-Gate GPU15\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e7_l3_gpu14 [label="MLP-Up GPU14\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e7_l3_gpu15 [label="MLP-Up GPU15\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e7_l3_gpu14 [label="MLP-Down GPU14\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e7_l3_gpu15 [label="MLP-Down GPU15\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_8 {
			color=red fillcolor=lightgray label="Expert 8" style="rounded,filled"
			attn_norm_s0_e8_l0_gpu16 [label="LayerNorm GPU16\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e8_l0_gpu17 [label="LayerNorm GPU17\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e8_l0_gpu16 [label="Attn-Q GPU16\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e8_l0_gpu17 [label="Attn-Q GPU17\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e8_l0_gpu16 [label="Attn-K/V GPU16\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e8_l0_gpu17 [label="Attn-K/V GPU17\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e8_l0_gpu16 [label="Attn-Out GPU16\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e8_l0_gpu17 [label="Attn-Out GPU17\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e8_l0_gpu16 [label="MLP-Gate GPU16\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e8_l0_gpu17 [label="MLP-Gate GPU17\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e8_l0_gpu16 [label="MLP-Up GPU16\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e8_l0_gpu17 [label="MLP-Up GPU17\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e8_l0_gpu16 [label="MLP-Down GPU16\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e8_l0_gpu17 [label="MLP-Down GPU17\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e8_l1_gpu16 [label="LayerNorm GPU16\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e8_l1_gpu17 [label="LayerNorm GPU17\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e8_l1_gpu16 [label="Attn-Q GPU16\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e8_l1_gpu17 [label="Attn-Q GPU17\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e8_l1_gpu16 [label="Attn-K/V GPU16\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e8_l1_gpu17 [label="Attn-K/V GPU17\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e8_l1_gpu16 [label="Attn-Out GPU16\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e8_l1_gpu17 [label="Attn-Out GPU17\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e8_l1_gpu16 [label="MLP-Gate GPU16\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e8_l1_gpu17 [label="MLP-Gate GPU17\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e8_l1_gpu16 [label="MLP-Up GPU16\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e8_l1_gpu17 [label="MLP-Up GPU17\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e8_l1_gpu16 [label="MLP-Down GPU16\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e8_l1_gpu17 [label="MLP-Down GPU17\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e8_l2_gpu16 [label="LayerNorm GPU16\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e8_l2_gpu17 [label="LayerNorm GPU17\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e8_l2_gpu16 [label="Attn-Q GPU16\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e8_l2_gpu17 [label="Attn-Q GPU17\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e8_l2_gpu16 [label="Attn-K/V GPU16\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e8_l2_gpu17 [label="Attn-K/V GPU17\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e8_l2_gpu16 [label="Attn-Out GPU16\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e8_l2_gpu17 [label="Attn-Out GPU17\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e8_l2_gpu16 [label="MLP-Gate GPU16\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e8_l2_gpu17 [label="MLP-Gate GPU17\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e8_l2_gpu16 [label="MLP-Up GPU16\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e8_l2_gpu17 [label="MLP-Up GPU17\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e8_l2_gpu16 [label="MLP-Down GPU16\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e8_l2_gpu17 [label="MLP-Down GPU17\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e8_l3_gpu16 [label="LayerNorm GPU16\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e8_l3_gpu17 [label="LayerNorm GPU17\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e8_l3_gpu16 [label="Attn-Q GPU16\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e8_l3_gpu17 [label="Attn-Q GPU17\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e8_l3_gpu16 [label="Attn-K/V GPU16\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e8_l3_gpu17 [label="Attn-K/V GPU17\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e8_l3_gpu16 [label="Attn-Out GPU16\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e8_l3_gpu17 [label="Attn-Out GPU17\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e8_l3_gpu16 [label="MLP-Gate GPU16\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e8_l3_gpu17 [label="MLP-Gate GPU17\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e8_l3_gpu16 [label="MLP-Up GPU16\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e8_l3_gpu17 [label="MLP-Up GPU17\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e8_l3_gpu16 [label="MLP-Down GPU16\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e8_l3_gpu17 [label="MLP-Down GPU17\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_9 {
			color=red fillcolor=lightgray label="Expert 9" style="rounded,filled"
			attn_norm_s0_e9_l0_gpu18 [label="LayerNorm GPU18\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e9_l0_gpu19 [label="LayerNorm GPU19\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e9_l0_gpu18 [label="Attn-Q GPU18\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e9_l0_gpu19 [label="Attn-Q GPU19\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e9_l0_gpu18 [label="Attn-K/V GPU18\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e9_l0_gpu19 [label="Attn-K/V GPU19\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e9_l0_gpu18 [label="Attn-Out GPU18\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e9_l0_gpu19 [label="Attn-Out GPU19\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e9_l0_gpu18 [label="MLP-Gate GPU18\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e9_l0_gpu19 [label="MLP-Gate GPU19\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e9_l0_gpu18 [label="MLP-Up GPU18\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e9_l0_gpu19 [label="MLP-Up GPU19\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e9_l0_gpu18 [label="MLP-Down GPU18\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e9_l0_gpu19 [label="MLP-Down GPU19\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e9_l1_gpu18 [label="LayerNorm GPU18\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e9_l1_gpu19 [label="LayerNorm GPU19\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e9_l1_gpu18 [label="Attn-Q GPU18\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e9_l1_gpu19 [label="Attn-Q GPU19\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e9_l1_gpu18 [label="Attn-K/V GPU18\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e9_l1_gpu19 [label="Attn-K/V GPU19\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e9_l1_gpu18 [label="Attn-Out GPU18\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e9_l1_gpu19 [label="Attn-Out GPU19\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e9_l1_gpu18 [label="MLP-Gate GPU18\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e9_l1_gpu19 [label="MLP-Gate GPU19\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e9_l1_gpu18 [label="MLP-Up GPU18\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e9_l1_gpu19 [label="MLP-Up GPU19\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e9_l1_gpu18 [label="MLP-Down GPU18\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e9_l1_gpu19 [label="MLP-Down GPU19\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e9_l2_gpu18 [label="LayerNorm GPU18\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e9_l2_gpu19 [label="LayerNorm GPU19\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e9_l2_gpu18 [label="Attn-Q GPU18\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e9_l2_gpu19 [label="Attn-Q GPU19\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e9_l2_gpu18 [label="Attn-K/V GPU18\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e9_l2_gpu19 [label="Attn-K/V GPU19\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e9_l2_gpu18 [label="Attn-Out GPU18\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e9_l2_gpu19 [label="Attn-Out GPU19\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e9_l2_gpu18 [label="MLP-Gate GPU18\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e9_l2_gpu19 [label="MLP-Gate GPU19\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e9_l2_gpu18 [label="MLP-Up GPU18\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e9_l2_gpu19 [label="MLP-Up GPU19\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e9_l2_gpu18 [label="MLP-Down GPU18\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e9_l2_gpu19 [label="MLP-Down GPU19\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e9_l3_gpu18 [label="LayerNorm GPU18\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e9_l3_gpu19 [label="LayerNorm GPU19\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e9_l3_gpu18 [label="Attn-Q GPU18\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e9_l3_gpu19 [label="Attn-Q GPU19\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e9_l3_gpu18 [label="Attn-K/V GPU18\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e9_l3_gpu19 [label="Attn-K/V GPU19\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e9_l3_gpu18 [label="Attn-Out GPU18\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e9_l3_gpu19 [label="Attn-Out GPU19\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e9_l3_gpu18 [label="MLP-Gate GPU18\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e9_l3_gpu19 [label="MLP-Gate GPU19\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e9_l3_gpu18 [label="MLP-Up GPU18\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e9_l3_gpu19 [label="MLP-Up GPU19\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e9_l3_gpu18 [label="MLP-Down GPU18\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e9_l3_gpu19 [label="MLP-Down GPU19\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_10 {
			color=red fillcolor=lightgray label="Expert 10" style="rounded,filled"
			attn_norm_s0_e10_l0_gpu20 [label="LayerNorm GPU20\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e10_l0_gpu21 [label="LayerNorm GPU21\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e10_l0_gpu20 [label="Attn-Q GPU20\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e10_l0_gpu21 [label="Attn-Q GPU21\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e10_l0_gpu20 [label="Attn-K/V GPU20\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e10_l0_gpu21 [label="Attn-K/V GPU21\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e10_l0_gpu20 [label="Attn-Out GPU20\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e10_l0_gpu21 [label="Attn-Out GPU21\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e10_l0_gpu20 [label="MLP-Gate GPU20\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e10_l0_gpu21 [label="MLP-Gate GPU21\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e10_l0_gpu20 [label="MLP-Up GPU20\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e10_l0_gpu21 [label="MLP-Up GPU21\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e10_l0_gpu20 [label="MLP-Down GPU20\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e10_l0_gpu21 [label="MLP-Down GPU21\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e10_l1_gpu20 [label="LayerNorm GPU20\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e10_l1_gpu21 [label="LayerNorm GPU21\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e10_l1_gpu20 [label="Attn-Q GPU20\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e10_l1_gpu21 [label="Attn-Q GPU21\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e10_l1_gpu20 [label="Attn-K/V GPU20\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e10_l1_gpu21 [label="Attn-K/V GPU21\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e10_l1_gpu20 [label="Attn-Out GPU20\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e10_l1_gpu21 [label="Attn-Out GPU21\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e10_l1_gpu20 [label="MLP-Gate GPU20\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e10_l1_gpu21 [label="MLP-Gate GPU21\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e10_l1_gpu20 [label="MLP-Up GPU20\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e10_l1_gpu21 [label="MLP-Up GPU21\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e10_l1_gpu20 [label="MLP-Down GPU20\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e10_l1_gpu21 [label="MLP-Down GPU21\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e10_l2_gpu20 [label="LayerNorm GPU20\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e10_l2_gpu21 [label="LayerNorm GPU21\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e10_l2_gpu20 [label="Attn-Q GPU20\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e10_l2_gpu21 [label="Attn-Q GPU21\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e10_l2_gpu20 [label="Attn-K/V GPU20\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e10_l2_gpu21 [label="Attn-K/V GPU21\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e10_l2_gpu20 [label="Attn-Out GPU20\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e10_l2_gpu21 [label="Attn-Out GPU21\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e10_l2_gpu20 [label="MLP-Gate GPU20\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e10_l2_gpu21 [label="MLP-Gate GPU21\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e10_l2_gpu20 [label="MLP-Up GPU20\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e10_l2_gpu21 [label="MLP-Up GPU21\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e10_l2_gpu20 [label="MLP-Down GPU20\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e10_l2_gpu21 [label="MLP-Down GPU21\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e10_l3_gpu20 [label="LayerNorm GPU20\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e10_l3_gpu21 [label="LayerNorm GPU21\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e10_l3_gpu20 [label="Attn-Q GPU20\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e10_l3_gpu21 [label="Attn-Q GPU21\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e10_l3_gpu20 [label="Attn-K/V GPU20\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e10_l3_gpu21 [label="Attn-K/V GPU21\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e10_l3_gpu20 [label="Attn-Out GPU20\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e10_l3_gpu21 [label="Attn-Out GPU21\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e10_l3_gpu20 [label="MLP-Gate GPU20\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e10_l3_gpu21 [label="MLP-Gate GPU21\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e10_l3_gpu20 [label="MLP-Up GPU20\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e10_l3_gpu21 [label="MLP-Up GPU21\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e10_l3_gpu20 [label="MLP-Down GPU20\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e10_l3_gpu21 [label="MLP-Down GPU21\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_11 {
			color=red fillcolor=lightgray label="Expert 11" style="rounded,filled"
			attn_norm_s0_e11_l0_gpu22 [label="LayerNorm GPU22\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e11_l0_gpu23 [label="LayerNorm GPU23\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e11_l0_gpu22 [label="Attn-Q GPU22\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e11_l0_gpu23 [label="Attn-Q GPU23\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e11_l0_gpu22 [label="Attn-K/V GPU22\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e11_l0_gpu23 [label="Attn-K/V GPU23\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e11_l0_gpu22 [label="Attn-Out GPU22\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e11_l0_gpu23 [label="Attn-Out GPU23\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e11_l0_gpu22 [label="MLP-Gate GPU22\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e11_l0_gpu23 [label="MLP-Gate GPU23\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e11_l0_gpu22 [label="MLP-Up GPU22\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e11_l0_gpu23 [label="MLP-Up GPU23\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e11_l0_gpu22 [label="MLP-Down GPU22\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e11_l0_gpu23 [label="MLP-Down GPU23\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e11_l1_gpu22 [label="LayerNorm GPU22\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e11_l1_gpu23 [label="LayerNorm GPU23\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e11_l1_gpu22 [label="Attn-Q GPU22\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e11_l1_gpu23 [label="Attn-Q GPU23\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e11_l1_gpu22 [label="Attn-K/V GPU22\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e11_l1_gpu23 [label="Attn-K/V GPU23\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e11_l1_gpu22 [label="Attn-Out GPU22\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e11_l1_gpu23 [label="Attn-Out GPU23\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e11_l1_gpu22 [label="MLP-Gate GPU22\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e11_l1_gpu23 [label="MLP-Gate GPU23\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e11_l1_gpu22 [label="MLP-Up GPU22\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e11_l1_gpu23 [label="MLP-Up GPU23\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e11_l1_gpu22 [label="MLP-Down GPU22\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e11_l1_gpu23 [label="MLP-Down GPU23\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e11_l2_gpu22 [label="LayerNorm GPU22\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e11_l2_gpu23 [label="LayerNorm GPU23\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e11_l2_gpu22 [label="Attn-Q GPU22\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e11_l2_gpu23 [label="Attn-Q GPU23\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e11_l2_gpu22 [label="Attn-K/V GPU22\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e11_l2_gpu23 [label="Attn-K/V GPU23\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e11_l2_gpu22 [label="Attn-Out GPU22\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e11_l2_gpu23 [label="Attn-Out GPU23\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e11_l2_gpu22 [label="MLP-Gate GPU22\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e11_l2_gpu23 [label="MLP-Gate GPU23\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e11_l2_gpu22 [label="MLP-Up GPU22\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e11_l2_gpu23 [label="MLP-Up GPU23\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e11_l2_gpu22 [label="MLP-Down GPU22\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e11_l2_gpu23 [label="MLP-Down GPU23\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e11_l3_gpu22 [label="LayerNorm GPU22\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e11_l3_gpu23 [label="LayerNorm GPU23\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e11_l3_gpu22 [label="Attn-Q GPU22\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e11_l3_gpu23 [label="Attn-Q GPU23\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e11_l3_gpu22 [label="Attn-K/V GPU22\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e11_l3_gpu23 [label="Attn-K/V GPU23\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e11_l3_gpu22 [label="Attn-Out GPU22\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e11_l3_gpu23 [label="Attn-Out GPU23\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e11_l3_gpu22 [label="MLP-Gate GPU22\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e11_l3_gpu23 [label="MLP-Gate GPU23\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e11_l3_gpu22 [label="MLP-Up GPU22\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e11_l3_gpu23 [label="MLP-Up GPU23\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e11_l3_gpu22 [label="MLP-Down GPU22\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e11_l3_gpu23 [label="MLP-Down GPU23\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_12 {
			color=red fillcolor=lightgray label="Expert 12" style="rounded,filled"
			attn_norm_s0_e12_l0_gpu24 [label="LayerNorm GPU24\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e12_l0_gpu25 [label="LayerNorm GPU25\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e12_l0_gpu24 [label="Attn-Q GPU24\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e12_l0_gpu25 [label="Attn-Q GPU25\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e12_l0_gpu24 [label="Attn-K/V GPU24\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e12_l0_gpu25 [label="Attn-K/V GPU25\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e12_l0_gpu24 [label="Attn-Out GPU24\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e12_l0_gpu25 [label="Attn-Out GPU25\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e12_l0_gpu24 [label="MLP-Gate GPU24\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e12_l0_gpu25 [label="MLP-Gate GPU25\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e12_l0_gpu24 [label="MLP-Up GPU24\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e12_l0_gpu25 [label="MLP-Up GPU25\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e12_l0_gpu24 [label="MLP-Down GPU24\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e12_l0_gpu25 [label="MLP-Down GPU25\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e12_l1_gpu24 [label="LayerNorm GPU24\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e12_l1_gpu25 [label="LayerNorm GPU25\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e12_l1_gpu24 [label="Attn-Q GPU24\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e12_l1_gpu25 [label="Attn-Q GPU25\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e12_l1_gpu24 [label="Attn-K/V GPU24\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e12_l1_gpu25 [label="Attn-K/V GPU25\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e12_l1_gpu24 [label="Attn-Out GPU24\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e12_l1_gpu25 [label="Attn-Out GPU25\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e12_l1_gpu24 [label="MLP-Gate GPU24\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e12_l1_gpu25 [label="MLP-Gate GPU25\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e12_l1_gpu24 [label="MLP-Up GPU24\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e12_l1_gpu25 [label="MLP-Up GPU25\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e12_l1_gpu24 [label="MLP-Down GPU24\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e12_l1_gpu25 [label="MLP-Down GPU25\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e12_l2_gpu24 [label="LayerNorm GPU24\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e12_l2_gpu25 [label="LayerNorm GPU25\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e12_l2_gpu24 [label="Attn-Q GPU24\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e12_l2_gpu25 [label="Attn-Q GPU25\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e12_l2_gpu24 [label="Attn-K/V GPU24\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e12_l2_gpu25 [label="Attn-K/V GPU25\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e12_l2_gpu24 [label="Attn-Out GPU24\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e12_l2_gpu25 [label="Attn-Out GPU25\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e12_l2_gpu24 [label="MLP-Gate GPU24\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e12_l2_gpu25 [label="MLP-Gate GPU25\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e12_l2_gpu24 [label="MLP-Up GPU24\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e12_l2_gpu25 [label="MLP-Up GPU25\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e12_l2_gpu24 [label="MLP-Down GPU24\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e12_l2_gpu25 [label="MLP-Down GPU25\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e12_l3_gpu24 [label="LayerNorm GPU24\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e12_l3_gpu25 [label="LayerNorm GPU25\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e12_l3_gpu24 [label="Attn-Q GPU24\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e12_l3_gpu25 [label="Attn-Q GPU25\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e12_l3_gpu24 [label="Attn-K/V GPU24\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e12_l3_gpu25 [label="Attn-K/V GPU25\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e12_l3_gpu24 [label="Attn-Out GPU24\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e12_l3_gpu25 [label="Attn-Out GPU25\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e12_l3_gpu24 [label="MLP-Gate GPU24\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e12_l3_gpu25 [label="MLP-Gate GPU25\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e12_l3_gpu24 [label="MLP-Up GPU24\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e12_l3_gpu25 [label="MLP-Up GPU25\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e12_l3_gpu24 [label="MLP-Down GPU24\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e12_l3_gpu25 [label="MLP-Down GPU25\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_13 {
			color=red fillcolor=lightgray label="Expert 13" style="rounded,filled"
			attn_norm_s0_e13_l0_gpu26 [label="LayerNorm GPU26\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e13_l0_gpu27 [label="LayerNorm GPU27\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e13_l0_gpu26 [label="Attn-Q GPU26\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e13_l0_gpu27 [label="Attn-Q GPU27\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e13_l0_gpu26 [label="Attn-K/V GPU26\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e13_l0_gpu27 [label="Attn-K/V GPU27\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e13_l0_gpu26 [label="Attn-Out GPU26\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e13_l0_gpu27 [label="Attn-Out GPU27\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e13_l0_gpu26 [label="MLP-Gate GPU26\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e13_l0_gpu27 [label="MLP-Gate GPU27\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e13_l0_gpu26 [label="MLP-Up GPU26\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e13_l0_gpu27 [label="MLP-Up GPU27\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e13_l0_gpu26 [label="MLP-Down GPU26\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e13_l0_gpu27 [label="MLP-Down GPU27\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e13_l1_gpu26 [label="LayerNorm GPU26\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e13_l1_gpu27 [label="LayerNorm GPU27\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e13_l1_gpu26 [label="Attn-Q GPU26\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e13_l1_gpu27 [label="Attn-Q GPU27\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e13_l1_gpu26 [label="Attn-K/V GPU26\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e13_l1_gpu27 [label="Attn-K/V GPU27\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e13_l1_gpu26 [label="Attn-Out GPU26\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e13_l1_gpu27 [label="Attn-Out GPU27\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e13_l1_gpu26 [label="MLP-Gate GPU26\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e13_l1_gpu27 [label="MLP-Gate GPU27\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e13_l1_gpu26 [label="MLP-Up GPU26\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e13_l1_gpu27 [label="MLP-Up GPU27\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e13_l1_gpu26 [label="MLP-Down GPU26\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e13_l1_gpu27 [label="MLP-Down GPU27\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e13_l2_gpu26 [label="LayerNorm GPU26\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e13_l2_gpu27 [label="LayerNorm GPU27\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e13_l2_gpu26 [label="Attn-Q GPU26\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e13_l2_gpu27 [label="Attn-Q GPU27\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e13_l2_gpu26 [label="Attn-K/V GPU26\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e13_l2_gpu27 [label="Attn-K/V GPU27\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e13_l2_gpu26 [label="Attn-Out GPU26\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e13_l2_gpu27 [label="Attn-Out GPU27\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e13_l2_gpu26 [label="MLP-Gate GPU26\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e13_l2_gpu27 [label="MLP-Gate GPU27\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e13_l2_gpu26 [label="MLP-Up GPU26\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e13_l2_gpu27 [label="MLP-Up GPU27\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e13_l2_gpu26 [label="MLP-Down GPU26\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e13_l2_gpu27 [label="MLP-Down GPU27\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e13_l3_gpu26 [label="LayerNorm GPU26\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e13_l3_gpu27 [label="LayerNorm GPU27\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e13_l3_gpu26 [label="Attn-Q GPU26\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e13_l3_gpu27 [label="Attn-Q GPU27\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e13_l3_gpu26 [label="Attn-K/V GPU26\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e13_l3_gpu27 [label="Attn-K/V GPU27\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e13_l3_gpu26 [label="Attn-Out GPU26\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e13_l3_gpu27 [label="Attn-Out GPU27\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e13_l3_gpu26 [label="MLP-Gate GPU26\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e13_l3_gpu27 [label="MLP-Gate GPU27\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e13_l3_gpu26 [label="MLP-Up GPU26\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e13_l3_gpu27 [label="MLP-Up GPU27\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e13_l3_gpu26 [label="MLP-Down GPU26\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e13_l3_gpu27 [label="MLP-Down GPU27\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_14 {
			color=red fillcolor=lightgray label="Expert 14" style="rounded,filled"
			attn_norm_s0_e14_l0_gpu28 [label="LayerNorm GPU28\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e14_l0_gpu29 [label="LayerNorm GPU29\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e14_l0_gpu28 [label="Attn-Q GPU28\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e14_l0_gpu29 [label="Attn-Q GPU29\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e14_l0_gpu28 [label="Attn-K/V GPU28\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e14_l0_gpu29 [label="Attn-K/V GPU29\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e14_l0_gpu28 [label="Attn-Out GPU28\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e14_l0_gpu29 [label="Attn-Out GPU29\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e14_l0_gpu28 [label="MLP-Gate GPU28\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e14_l0_gpu29 [label="MLP-Gate GPU29\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e14_l0_gpu28 [label="MLP-Up GPU28\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e14_l0_gpu29 [label="MLP-Up GPU29\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e14_l0_gpu28 [label="MLP-Down GPU28\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e14_l0_gpu29 [label="MLP-Down GPU29\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e14_l1_gpu28 [label="LayerNorm GPU28\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e14_l1_gpu29 [label="LayerNorm GPU29\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e14_l1_gpu28 [label="Attn-Q GPU28\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e14_l1_gpu29 [label="Attn-Q GPU29\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e14_l1_gpu28 [label="Attn-K/V GPU28\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e14_l1_gpu29 [label="Attn-K/V GPU29\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e14_l1_gpu28 [label="Attn-Out GPU28\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e14_l1_gpu29 [label="Attn-Out GPU29\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e14_l1_gpu28 [label="MLP-Gate GPU28\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e14_l1_gpu29 [label="MLP-Gate GPU29\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e14_l1_gpu28 [label="MLP-Up GPU28\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e14_l1_gpu29 [label="MLP-Up GPU29\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e14_l1_gpu28 [label="MLP-Down GPU28\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e14_l1_gpu29 [label="MLP-Down GPU29\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e14_l2_gpu28 [label="LayerNorm GPU28\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e14_l2_gpu29 [label="LayerNorm GPU29\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e14_l2_gpu28 [label="Attn-Q GPU28\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e14_l2_gpu29 [label="Attn-Q GPU29\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e14_l2_gpu28 [label="Attn-K/V GPU28\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e14_l2_gpu29 [label="Attn-K/V GPU29\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e14_l2_gpu28 [label="Attn-Out GPU28\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e14_l2_gpu29 [label="Attn-Out GPU29\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e14_l2_gpu28 [label="MLP-Gate GPU28\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e14_l2_gpu29 [label="MLP-Gate GPU29\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e14_l2_gpu28 [label="MLP-Up GPU28\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e14_l2_gpu29 [label="MLP-Up GPU29\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e14_l2_gpu28 [label="MLP-Down GPU28\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e14_l2_gpu29 [label="MLP-Down GPU29\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e14_l3_gpu28 [label="LayerNorm GPU28\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e14_l3_gpu29 [label="LayerNorm GPU29\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e14_l3_gpu28 [label="Attn-Q GPU28\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e14_l3_gpu29 [label="Attn-Q GPU29\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e14_l3_gpu28 [label="Attn-K/V GPU28\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e14_l3_gpu29 [label="Attn-K/V GPU29\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e14_l3_gpu28 [label="Attn-Out GPU28\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e14_l3_gpu29 [label="Attn-Out GPU29\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e14_l3_gpu28 [label="MLP-Gate GPU28\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e14_l3_gpu29 [label="MLP-Gate GPU29\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e14_l3_gpu28 [label="MLP-Up GPU28\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e14_l3_gpu29 [label="MLP-Up GPU29\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e14_l3_gpu28 [label="MLP-Down GPU28\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e14_l3_gpu29 [label="MLP-Down GPU29\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_15 {
			color=red fillcolor=lightgray label="Expert 15" style="rounded,filled"
			attn_norm_s0_e15_l0_gpu30 [label="LayerNorm GPU30\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e15_l0_gpu31 [label="LayerNorm GPU31\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e15_l0_gpu30 [label="Attn-Q GPU30\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e15_l0_gpu31 [label="Attn-Q GPU31\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e15_l0_gpu30 [label="Attn-K/V GPU30\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e15_l0_gpu31 [label="Attn-K/V GPU31\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e15_l0_gpu30 [label="Attn-Out GPU30\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e15_l0_gpu31 [label="Attn-Out GPU31\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e15_l0_gpu30 [label="MLP-Gate GPU30\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e15_l0_gpu31 [label="MLP-Gate GPU31\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e15_l0_gpu30 [label="MLP-Up GPU30\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e15_l0_gpu31 [label="MLP-Up GPU31\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e15_l0_gpu30 [label="MLP-Down GPU30\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e15_l0_gpu31 [label="MLP-Down GPU31\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e15_l1_gpu30 [label="LayerNorm GPU30\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e15_l1_gpu31 [label="LayerNorm GPU31\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e15_l1_gpu30 [label="Attn-Q GPU30\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e15_l1_gpu31 [label="Attn-Q GPU31\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e15_l1_gpu30 [label="Attn-K/V GPU30\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e15_l1_gpu31 [label="Attn-K/V GPU31\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e15_l1_gpu30 [label="Attn-Out GPU30\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e15_l1_gpu31 [label="Attn-Out GPU31\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e15_l1_gpu30 [label="MLP-Gate GPU30\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e15_l1_gpu31 [label="MLP-Gate GPU31\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e15_l1_gpu30 [label="MLP-Up GPU30\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e15_l1_gpu31 [label="MLP-Up GPU31\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e15_l1_gpu30 [label="MLP-Down GPU30\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e15_l1_gpu31 [label="MLP-Down GPU31\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e15_l2_gpu30 [label="LayerNorm GPU30\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e15_l2_gpu31 [label="LayerNorm GPU31\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e15_l2_gpu30 [label="Attn-Q GPU30\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e15_l2_gpu31 [label="Attn-Q GPU31\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e15_l2_gpu30 [label="Attn-K/V GPU30\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e15_l2_gpu31 [label="Attn-K/V GPU31\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e15_l2_gpu30 [label="Attn-Out GPU30\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e15_l2_gpu31 [label="Attn-Out GPU31\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e15_l2_gpu30 [label="MLP-Gate GPU30\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e15_l2_gpu31 [label="MLP-Gate GPU31\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e15_l2_gpu30 [label="MLP-Up GPU30\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e15_l2_gpu31 [label="MLP-Up GPU31\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e15_l2_gpu30 [label="MLP-Down GPU30\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e15_l2_gpu31 [label="MLP-Down GPU31\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s0_e15_l3_gpu30 [label="LayerNorm GPU30\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s0_e15_l3_gpu31 [label="LayerNorm GPU31\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s0_e15_l3_gpu30 [label="Attn-Q GPU30\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s0_e15_l3_gpu31 [label="Attn-Q GPU31\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e15_l3_gpu30 [label="Attn-K/V GPU30\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s0_e15_l3_gpu31 [label="Attn-K/V GPU31\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s0_e15_l3_gpu30 [label="Attn-Out GPU30\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s0_e15_l3_gpu31 [label="Attn-Out GPU31\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s0_e15_l3_gpu30 [label="MLP-Gate GPU30\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s0_e15_l3_gpu31 [label="MLP-Gate GPU31\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e15_l3_gpu30 [label="MLP-Up GPU30\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s0_e15_l3_gpu31 [label="MLP-Up GPU31\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s0_e15_l3_gpu30 [label="MLP-Down GPU30\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s0_e15_l3_gpu31 [label="MLP-Down GPU31\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
	}
	subgraph cluster_stage_1 {
		color=blue fillcolor=lightyellow label="Pipeline Stage 1 (Layers 4-7)" style="rounded,filled"
		subgraph cluster_expert_16 {
			color=red fillcolor=lightgray label="Expert 16" style="rounded,filled"
			attn_norm_s1_e16_l0_gpu32 [label="LayerNorm GPU32\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e16_l0_gpu33 [label="LayerNorm GPU33\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e16_l0_gpu32 [label="Attn-Q GPU32\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e16_l0_gpu33 [label="Attn-Q GPU33\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e16_l0_gpu32 [label="Attn-K/V GPU32\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e16_l0_gpu33 [label="Attn-K/V GPU33\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e16_l0_gpu32 [label="Attn-Out GPU32\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e16_l0_gpu33 [label="Attn-Out GPU33\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e16_l0_gpu32 [label="MLP-Gate GPU32\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e16_l0_gpu33 [label="MLP-Gate GPU33\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e16_l0_gpu32 [label="MLP-Up GPU32\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e16_l0_gpu33 [label="MLP-Up GPU33\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e16_l0_gpu32 [label="MLP-Down GPU32\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e16_l0_gpu33 [label="MLP-Down GPU33\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e16_l1_gpu32 [label="LayerNorm GPU32\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e16_l1_gpu33 [label="LayerNorm GPU33\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e16_l1_gpu32 [label="Attn-Q GPU32\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e16_l1_gpu33 [label="Attn-Q GPU33\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e16_l1_gpu32 [label="Attn-K/V GPU32\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e16_l1_gpu33 [label="Attn-K/V GPU33\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e16_l1_gpu32 [label="Attn-Out GPU32\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e16_l1_gpu33 [label="Attn-Out GPU33\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e16_l1_gpu32 [label="MLP-Gate GPU32\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e16_l1_gpu33 [label="MLP-Gate GPU33\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e16_l1_gpu32 [label="MLP-Up GPU32\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e16_l1_gpu33 [label="MLP-Up GPU33\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e16_l1_gpu32 [label="MLP-Down GPU32\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e16_l1_gpu33 [label="MLP-Down GPU33\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e16_l2_gpu32 [label="LayerNorm GPU32\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e16_l2_gpu33 [label="LayerNorm GPU33\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e16_l2_gpu32 [label="Attn-Q GPU32\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e16_l2_gpu33 [label="Attn-Q GPU33\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e16_l2_gpu32 [label="Attn-K/V GPU32\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e16_l2_gpu33 [label="Attn-K/V GPU33\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e16_l2_gpu32 [label="Attn-Out GPU32\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e16_l2_gpu33 [label="Attn-Out GPU33\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e16_l2_gpu32 [label="MLP-Gate GPU32\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e16_l2_gpu33 [label="MLP-Gate GPU33\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e16_l2_gpu32 [label="MLP-Up GPU32\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e16_l2_gpu33 [label="MLP-Up GPU33\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e16_l2_gpu32 [label="MLP-Down GPU32\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e16_l2_gpu33 [label="MLP-Down GPU33\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e16_l3_gpu32 [label="LayerNorm GPU32\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e16_l3_gpu33 [label="LayerNorm GPU33\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e16_l3_gpu32 [label="Attn-Q GPU32\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e16_l3_gpu33 [label="Attn-Q GPU33\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e16_l3_gpu32 [label="Attn-K/V GPU32\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e16_l3_gpu33 [label="Attn-K/V GPU33\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e16_l3_gpu32 [label="Attn-Out GPU32\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e16_l3_gpu33 [label="Attn-Out GPU33\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e16_l3_gpu32 [label="MLP-Gate GPU32\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e16_l3_gpu33 [label="MLP-Gate GPU33\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e16_l3_gpu32 [label="MLP-Up GPU32\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e16_l3_gpu33 [label="MLP-Up GPU33\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e16_l3_gpu32 [label="MLP-Down GPU32\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e16_l3_gpu33 [label="MLP-Down GPU33\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_17 {
			color=red fillcolor=lightgray label="Expert 17" style="rounded,filled"
			attn_norm_s1_e17_l0_gpu34 [label="LayerNorm GPU34\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e17_l0_gpu35 [label="LayerNorm GPU35\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e17_l0_gpu34 [label="Attn-Q GPU34\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e17_l0_gpu35 [label="Attn-Q GPU35\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e17_l0_gpu34 [label="Attn-K/V GPU34\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e17_l0_gpu35 [label="Attn-K/V GPU35\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e17_l0_gpu34 [label="Attn-Out GPU34\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e17_l0_gpu35 [label="Attn-Out GPU35\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e17_l0_gpu34 [label="MLP-Gate GPU34\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e17_l0_gpu35 [label="MLP-Gate GPU35\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e17_l0_gpu34 [label="MLP-Up GPU34\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e17_l0_gpu35 [label="MLP-Up GPU35\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e17_l0_gpu34 [label="MLP-Down GPU34\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e17_l0_gpu35 [label="MLP-Down GPU35\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e17_l1_gpu34 [label="LayerNorm GPU34\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e17_l1_gpu35 [label="LayerNorm GPU35\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e17_l1_gpu34 [label="Attn-Q GPU34\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e17_l1_gpu35 [label="Attn-Q GPU35\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e17_l1_gpu34 [label="Attn-K/V GPU34\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e17_l1_gpu35 [label="Attn-K/V GPU35\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e17_l1_gpu34 [label="Attn-Out GPU34\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e17_l1_gpu35 [label="Attn-Out GPU35\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e17_l1_gpu34 [label="MLP-Gate GPU34\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e17_l1_gpu35 [label="MLP-Gate GPU35\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e17_l1_gpu34 [label="MLP-Up GPU34\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e17_l1_gpu35 [label="MLP-Up GPU35\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e17_l1_gpu34 [label="MLP-Down GPU34\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e17_l1_gpu35 [label="MLP-Down GPU35\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e17_l2_gpu34 [label="LayerNorm GPU34\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e17_l2_gpu35 [label="LayerNorm GPU35\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e17_l2_gpu34 [label="Attn-Q GPU34\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e17_l2_gpu35 [label="Attn-Q GPU35\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e17_l2_gpu34 [label="Attn-K/V GPU34\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e17_l2_gpu35 [label="Attn-K/V GPU35\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e17_l2_gpu34 [label="Attn-Out GPU34\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e17_l2_gpu35 [label="Attn-Out GPU35\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e17_l2_gpu34 [label="MLP-Gate GPU34\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e17_l2_gpu35 [label="MLP-Gate GPU35\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e17_l2_gpu34 [label="MLP-Up GPU34\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e17_l2_gpu35 [label="MLP-Up GPU35\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e17_l2_gpu34 [label="MLP-Down GPU34\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e17_l2_gpu35 [label="MLP-Down GPU35\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e17_l3_gpu34 [label="LayerNorm GPU34\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e17_l3_gpu35 [label="LayerNorm GPU35\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e17_l3_gpu34 [label="Attn-Q GPU34\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e17_l3_gpu35 [label="Attn-Q GPU35\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e17_l3_gpu34 [label="Attn-K/V GPU34\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e17_l3_gpu35 [label="Attn-K/V GPU35\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e17_l3_gpu34 [label="Attn-Out GPU34\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e17_l3_gpu35 [label="Attn-Out GPU35\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e17_l3_gpu34 [label="MLP-Gate GPU34\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e17_l3_gpu35 [label="MLP-Gate GPU35\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e17_l3_gpu34 [label="MLP-Up GPU34\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e17_l3_gpu35 [label="MLP-Up GPU35\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e17_l3_gpu34 [label="MLP-Down GPU34\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e17_l3_gpu35 [label="MLP-Down GPU35\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_18 {
			color=red fillcolor=lightgray label="Expert 18" style="rounded,filled"
			attn_norm_s1_e18_l0_gpu36 [label="LayerNorm GPU36\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e18_l0_gpu37 [label="LayerNorm GPU37\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e18_l0_gpu36 [label="Attn-Q GPU36\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e18_l0_gpu37 [label="Attn-Q GPU37\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e18_l0_gpu36 [label="Attn-K/V GPU36\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e18_l0_gpu37 [label="Attn-K/V GPU37\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e18_l0_gpu36 [label="Attn-Out GPU36\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e18_l0_gpu37 [label="Attn-Out GPU37\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e18_l0_gpu36 [label="MLP-Gate GPU36\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e18_l0_gpu37 [label="MLP-Gate GPU37\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e18_l0_gpu36 [label="MLP-Up GPU36\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e18_l0_gpu37 [label="MLP-Up GPU37\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e18_l0_gpu36 [label="MLP-Down GPU36\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e18_l0_gpu37 [label="MLP-Down GPU37\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e18_l1_gpu36 [label="LayerNorm GPU36\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e18_l1_gpu37 [label="LayerNorm GPU37\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e18_l1_gpu36 [label="Attn-Q GPU36\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e18_l1_gpu37 [label="Attn-Q GPU37\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e18_l1_gpu36 [label="Attn-K/V GPU36\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e18_l1_gpu37 [label="Attn-K/V GPU37\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e18_l1_gpu36 [label="Attn-Out GPU36\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e18_l1_gpu37 [label="Attn-Out GPU37\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e18_l1_gpu36 [label="MLP-Gate GPU36\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e18_l1_gpu37 [label="MLP-Gate GPU37\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e18_l1_gpu36 [label="MLP-Up GPU36\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e18_l1_gpu37 [label="MLP-Up GPU37\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e18_l1_gpu36 [label="MLP-Down GPU36\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e18_l1_gpu37 [label="MLP-Down GPU37\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e18_l2_gpu36 [label="LayerNorm GPU36\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e18_l2_gpu37 [label="LayerNorm GPU37\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e18_l2_gpu36 [label="Attn-Q GPU36\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e18_l2_gpu37 [label="Attn-Q GPU37\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e18_l2_gpu36 [label="Attn-K/V GPU36\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e18_l2_gpu37 [label="Attn-K/V GPU37\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e18_l2_gpu36 [label="Attn-Out GPU36\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e18_l2_gpu37 [label="Attn-Out GPU37\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e18_l2_gpu36 [label="MLP-Gate GPU36\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e18_l2_gpu37 [label="MLP-Gate GPU37\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e18_l2_gpu36 [label="MLP-Up GPU36\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e18_l2_gpu37 [label="MLP-Up GPU37\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e18_l2_gpu36 [label="MLP-Down GPU36\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e18_l2_gpu37 [label="MLP-Down GPU37\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e18_l3_gpu36 [label="LayerNorm GPU36\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e18_l3_gpu37 [label="LayerNorm GPU37\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e18_l3_gpu36 [label="Attn-Q GPU36\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e18_l3_gpu37 [label="Attn-Q GPU37\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e18_l3_gpu36 [label="Attn-K/V GPU36\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e18_l3_gpu37 [label="Attn-K/V GPU37\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e18_l3_gpu36 [label="Attn-Out GPU36\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e18_l3_gpu37 [label="Attn-Out GPU37\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e18_l3_gpu36 [label="MLP-Gate GPU36\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e18_l3_gpu37 [label="MLP-Gate GPU37\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e18_l3_gpu36 [label="MLP-Up GPU36\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e18_l3_gpu37 [label="MLP-Up GPU37\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e18_l3_gpu36 [label="MLP-Down GPU36\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e18_l3_gpu37 [label="MLP-Down GPU37\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_19 {
			color=red fillcolor=lightgray label="Expert 19" style="rounded,filled"
			attn_norm_s1_e19_l0_gpu38 [label="LayerNorm GPU38\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e19_l0_gpu39 [label="LayerNorm GPU39\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e19_l0_gpu38 [label="Attn-Q GPU38\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e19_l0_gpu39 [label="Attn-Q GPU39\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e19_l0_gpu38 [label="Attn-K/V GPU38\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e19_l0_gpu39 [label="Attn-K/V GPU39\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e19_l0_gpu38 [label="Attn-Out GPU38\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e19_l0_gpu39 [label="Attn-Out GPU39\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e19_l0_gpu38 [label="MLP-Gate GPU38\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e19_l0_gpu39 [label="MLP-Gate GPU39\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e19_l0_gpu38 [label="MLP-Up GPU38\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e19_l0_gpu39 [label="MLP-Up GPU39\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e19_l0_gpu38 [label="MLP-Down GPU38\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e19_l0_gpu39 [label="MLP-Down GPU39\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e19_l1_gpu38 [label="LayerNorm GPU38\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e19_l1_gpu39 [label="LayerNorm GPU39\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e19_l1_gpu38 [label="Attn-Q GPU38\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e19_l1_gpu39 [label="Attn-Q GPU39\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e19_l1_gpu38 [label="Attn-K/V GPU38\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e19_l1_gpu39 [label="Attn-K/V GPU39\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e19_l1_gpu38 [label="Attn-Out GPU38\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e19_l1_gpu39 [label="Attn-Out GPU39\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e19_l1_gpu38 [label="MLP-Gate GPU38\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e19_l1_gpu39 [label="MLP-Gate GPU39\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e19_l1_gpu38 [label="MLP-Up GPU38\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e19_l1_gpu39 [label="MLP-Up GPU39\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e19_l1_gpu38 [label="MLP-Down GPU38\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e19_l1_gpu39 [label="MLP-Down GPU39\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e19_l2_gpu38 [label="LayerNorm GPU38\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e19_l2_gpu39 [label="LayerNorm GPU39\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e19_l2_gpu38 [label="Attn-Q GPU38\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e19_l2_gpu39 [label="Attn-Q GPU39\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e19_l2_gpu38 [label="Attn-K/V GPU38\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e19_l2_gpu39 [label="Attn-K/V GPU39\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e19_l2_gpu38 [label="Attn-Out GPU38\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e19_l2_gpu39 [label="Attn-Out GPU39\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e19_l2_gpu38 [label="MLP-Gate GPU38\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e19_l2_gpu39 [label="MLP-Gate GPU39\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e19_l2_gpu38 [label="MLP-Up GPU38\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e19_l2_gpu39 [label="MLP-Up GPU39\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e19_l2_gpu38 [label="MLP-Down GPU38\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e19_l2_gpu39 [label="MLP-Down GPU39\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e19_l3_gpu38 [label="LayerNorm GPU38\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e19_l3_gpu39 [label="LayerNorm GPU39\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e19_l3_gpu38 [label="Attn-Q GPU38\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e19_l3_gpu39 [label="Attn-Q GPU39\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e19_l3_gpu38 [label="Attn-K/V GPU38\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e19_l3_gpu39 [label="Attn-K/V GPU39\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e19_l3_gpu38 [label="Attn-Out GPU38\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e19_l3_gpu39 [label="Attn-Out GPU39\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e19_l3_gpu38 [label="MLP-Gate GPU38\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e19_l3_gpu39 [label="MLP-Gate GPU39\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e19_l3_gpu38 [label="MLP-Up GPU38\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e19_l3_gpu39 [label="MLP-Up GPU39\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e19_l3_gpu38 [label="MLP-Down GPU38\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e19_l3_gpu39 [label="MLP-Down GPU39\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_20 {
			color=red fillcolor=lightgray label="Expert 20" style="rounded,filled"
			attn_norm_s1_e20_l0_gpu40 [label="LayerNorm GPU40\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e20_l0_gpu41 [label="LayerNorm GPU41\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e20_l0_gpu40 [label="Attn-Q GPU40\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e20_l0_gpu41 [label="Attn-Q GPU41\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e20_l0_gpu40 [label="Attn-K/V GPU40\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e20_l0_gpu41 [label="Attn-K/V GPU41\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e20_l0_gpu40 [label="Attn-Out GPU40\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e20_l0_gpu41 [label="Attn-Out GPU41\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e20_l0_gpu40 [label="MLP-Gate GPU40\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e20_l0_gpu41 [label="MLP-Gate GPU41\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e20_l0_gpu40 [label="MLP-Up GPU40\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e20_l0_gpu41 [label="MLP-Up GPU41\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e20_l0_gpu40 [label="MLP-Down GPU40\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e20_l0_gpu41 [label="MLP-Down GPU41\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e20_l1_gpu40 [label="LayerNorm GPU40\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e20_l1_gpu41 [label="LayerNorm GPU41\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e20_l1_gpu40 [label="Attn-Q GPU40\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e20_l1_gpu41 [label="Attn-Q GPU41\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e20_l1_gpu40 [label="Attn-K/V GPU40\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e20_l1_gpu41 [label="Attn-K/V GPU41\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e20_l1_gpu40 [label="Attn-Out GPU40\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e20_l1_gpu41 [label="Attn-Out GPU41\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e20_l1_gpu40 [label="MLP-Gate GPU40\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e20_l1_gpu41 [label="MLP-Gate GPU41\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e20_l1_gpu40 [label="MLP-Up GPU40\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e20_l1_gpu41 [label="MLP-Up GPU41\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e20_l1_gpu40 [label="MLP-Down GPU40\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e20_l1_gpu41 [label="MLP-Down GPU41\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e20_l2_gpu40 [label="LayerNorm GPU40\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e20_l2_gpu41 [label="LayerNorm GPU41\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e20_l2_gpu40 [label="Attn-Q GPU40\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e20_l2_gpu41 [label="Attn-Q GPU41\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e20_l2_gpu40 [label="Attn-K/V GPU40\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e20_l2_gpu41 [label="Attn-K/V GPU41\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e20_l2_gpu40 [label="Attn-Out GPU40\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e20_l2_gpu41 [label="Attn-Out GPU41\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e20_l2_gpu40 [label="MLP-Gate GPU40\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e20_l2_gpu41 [label="MLP-Gate GPU41\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e20_l2_gpu40 [label="MLP-Up GPU40\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e20_l2_gpu41 [label="MLP-Up GPU41\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e20_l2_gpu40 [label="MLP-Down GPU40\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e20_l2_gpu41 [label="MLP-Down GPU41\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e20_l3_gpu40 [label="LayerNorm GPU40\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e20_l3_gpu41 [label="LayerNorm GPU41\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e20_l3_gpu40 [label="Attn-Q GPU40\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e20_l3_gpu41 [label="Attn-Q GPU41\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e20_l3_gpu40 [label="Attn-K/V GPU40\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e20_l3_gpu41 [label="Attn-K/V GPU41\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e20_l3_gpu40 [label="Attn-Out GPU40\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e20_l3_gpu41 [label="Attn-Out GPU41\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e20_l3_gpu40 [label="MLP-Gate GPU40\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e20_l3_gpu41 [label="MLP-Gate GPU41\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e20_l3_gpu40 [label="MLP-Up GPU40\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e20_l3_gpu41 [label="MLP-Up GPU41\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e20_l3_gpu40 [label="MLP-Down GPU40\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e20_l3_gpu41 [label="MLP-Down GPU41\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_21 {
			color=red fillcolor=lightgray label="Expert 21" style="rounded,filled"
			attn_norm_s1_e21_l0_gpu42 [label="LayerNorm GPU42\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e21_l0_gpu43 [label="LayerNorm GPU43\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e21_l0_gpu42 [label="Attn-Q GPU42\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e21_l0_gpu43 [label="Attn-Q GPU43\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e21_l0_gpu42 [label="Attn-K/V GPU42\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e21_l0_gpu43 [label="Attn-K/V GPU43\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e21_l0_gpu42 [label="Attn-Out GPU42\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e21_l0_gpu43 [label="Attn-Out GPU43\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e21_l0_gpu42 [label="MLP-Gate GPU42\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e21_l0_gpu43 [label="MLP-Gate GPU43\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e21_l0_gpu42 [label="MLP-Up GPU42\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e21_l0_gpu43 [label="MLP-Up GPU43\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e21_l0_gpu42 [label="MLP-Down GPU42\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e21_l0_gpu43 [label="MLP-Down GPU43\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e21_l1_gpu42 [label="LayerNorm GPU42\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e21_l1_gpu43 [label="LayerNorm GPU43\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e21_l1_gpu42 [label="Attn-Q GPU42\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e21_l1_gpu43 [label="Attn-Q GPU43\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e21_l1_gpu42 [label="Attn-K/V GPU42\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e21_l1_gpu43 [label="Attn-K/V GPU43\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e21_l1_gpu42 [label="Attn-Out GPU42\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e21_l1_gpu43 [label="Attn-Out GPU43\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e21_l1_gpu42 [label="MLP-Gate GPU42\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e21_l1_gpu43 [label="MLP-Gate GPU43\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e21_l1_gpu42 [label="MLP-Up GPU42\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e21_l1_gpu43 [label="MLP-Up GPU43\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e21_l1_gpu42 [label="MLP-Down GPU42\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e21_l1_gpu43 [label="MLP-Down GPU43\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e21_l2_gpu42 [label="LayerNorm GPU42\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e21_l2_gpu43 [label="LayerNorm GPU43\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e21_l2_gpu42 [label="Attn-Q GPU42\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e21_l2_gpu43 [label="Attn-Q GPU43\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e21_l2_gpu42 [label="Attn-K/V GPU42\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e21_l2_gpu43 [label="Attn-K/V GPU43\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e21_l2_gpu42 [label="Attn-Out GPU42\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e21_l2_gpu43 [label="Attn-Out GPU43\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e21_l2_gpu42 [label="MLP-Gate GPU42\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e21_l2_gpu43 [label="MLP-Gate GPU43\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e21_l2_gpu42 [label="MLP-Up GPU42\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e21_l2_gpu43 [label="MLP-Up GPU43\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e21_l2_gpu42 [label="MLP-Down GPU42\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e21_l2_gpu43 [label="MLP-Down GPU43\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e21_l3_gpu42 [label="LayerNorm GPU42\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e21_l3_gpu43 [label="LayerNorm GPU43\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e21_l3_gpu42 [label="Attn-Q GPU42\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e21_l3_gpu43 [label="Attn-Q GPU43\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e21_l3_gpu42 [label="Attn-K/V GPU42\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e21_l3_gpu43 [label="Attn-K/V GPU43\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e21_l3_gpu42 [label="Attn-Out GPU42\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e21_l3_gpu43 [label="Attn-Out GPU43\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e21_l3_gpu42 [label="MLP-Gate GPU42\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e21_l3_gpu43 [label="MLP-Gate GPU43\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e21_l3_gpu42 [label="MLP-Up GPU42\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e21_l3_gpu43 [label="MLP-Up GPU43\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e21_l3_gpu42 [label="MLP-Down GPU42\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e21_l3_gpu43 [label="MLP-Down GPU43\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_22 {
			color=red fillcolor=lightgray label="Expert 22" style="rounded,filled"
			attn_norm_s1_e22_l0_gpu44 [label="LayerNorm GPU44\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e22_l0_gpu45 [label="LayerNorm GPU45\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e22_l0_gpu44 [label="Attn-Q GPU44\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e22_l0_gpu45 [label="Attn-Q GPU45\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e22_l0_gpu44 [label="Attn-K/V GPU44\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e22_l0_gpu45 [label="Attn-K/V GPU45\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e22_l0_gpu44 [label="Attn-Out GPU44\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e22_l0_gpu45 [label="Attn-Out GPU45\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e22_l0_gpu44 [label="MLP-Gate GPU44\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e22_l0_gpu45 [label="MLP-Gate GPU45\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e22_l0_gpu44 [label="MLP-Up GPU44\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e22_l0_gpu45 [label="MLP-Up GPU45\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e22_l0_gpu44 [label="MLP-Down GPU44\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e22_l0_gpu45 [label="MLP-Down GPU45\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e22_l1_gpu44 [label="LayerNorm GPU44\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e22_l1_gpu45 [label="LayerNorm GPU45\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e22_l1_gpu44 [label="Attn-Q GPU44\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e22_l1_gpu45 [label="Attn-Q GPU45\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e22_l1_gpu44 [label="Attn-K/V GPU44\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e22_l1_gpu45 [label="Attn-K/V GPU45\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e22_l1_gpu44 [label="Attn-Out GPU44\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e22_l1_gpu45 [label="Attn-Out GPU45\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e22_l1_gpu44 [label="MLP-Gate GPU44\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e22_l1_gpu45 [label="MLP-Gate GPU45\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e22_l1_gpu44 [label="MLP-Up GPU44\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e22_l1_gpu45 [label="MLP-Up GPU45\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e22_l1_gpu44 [label="MLP-Down GPU44\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e22_l1_gpu45 [label="MLP-Down GPU45\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e22_l2_gpu44 [label="LayerNorm GPU44\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e22_l2_gpu45 [label="LayerNorm GPU45\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e22_l2_gpu44 [label="Attn-Q GPU44\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e22_l2_gpu45 [label="Attn-Q GPU45\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e22_l2_gpu44 [label="Attn-K/V GPU44\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e22_l2_gpu45 [label="Attn-K/V GPU45\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e22_l2_gpu44 [label="Attn-Out GPU44\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e22_l2_gpu45 [label="Attn-Out GPU45\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e22_l2_gpu44 [label="MLP-Gate GPU44\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e22_l2_gpu45 [label="MLP-Gate GPU45\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e22_l2_gpu44 [label="MLP-Up GPU44\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e22_l2_gpu45 [label="MLP-Up GPU45\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e22_l2_gpu44 [label="MLP-Down GPU44\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e22_l2_gpu45 [label="MLP-Down GPU45\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e22_l3_gpu44 [label="LayerNorm GPU44\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e22_l3_gpu45 [label="LayerNorm GPU45\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e22_l3_gpu44 [label="Attn-Q GPU44\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e22_l3_gpu45 [label="Attn-Q GPU45\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e22_l3_gpu44 [label="Attn-K/V GPU44\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e22_l3_gpu45 [label="Attn-K/V GPU45\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e22_l3_gpu44 [label="Attn-Out GPU44\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e22_l3_gpu45 [label="Attn-Out GPU45\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e22_l3_gpu44 [label="MLP-Gate GPU44\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e22_l3_gpu45 [label="MLP-Gate GPU45\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e22_l3_gpu44 [label="MLP-Up GPU44\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e22_l3_gpu45 [label="MLP-Up GPU45\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e22_l3_gpu44 [label="MLP-Down GPU44\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e22_l3_gpu45 [label="MLP-Down GPU45\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_23 {
			color=red fillcolor=lightgray label="Expert 23" style="rounded,filled"
			attn_norm_s1_e23_l0_gpu46 [label="LayerNorm GPU46\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e23_l0_gpu47 [label="LayerNorm GPU47\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e23_l0_gpu46 [label="Attn-Q GPU46\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e23_l0_gpu47 [label="Attn-Q GPU47\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e23_l0_gpu46 [label="Attn-K/V GPU46\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e23_l0_gpu47 [label="Attn-K/V GPU47\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e23_l0_gpu46 [label="Attn-Out GPU46\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e23_l0_gpu47 [label="Attn-Out GPU47\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e23_l0_gpu46 [label="MLP-Gate GPU46\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e23_l0_gpu47 [label="MLP-Gate GPU47\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e23_l0_gpu46 [label="MLP-Up GPU46\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e23_l0_gpu47 [label="MLP-Up GPU47\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e23_l0_gpu46 [label="MLP-Down GPU46\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e23_l0_gpu47 [label="MLP-Down GPU47\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e23_l1_gpu46 [label="LayerNorm GPU46\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e23_l1_gpu47 [label="LayerNorm GPU47\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e23_l1_gpu46 [label="Attn-Q GPU46\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e23_l1_gpu47 [label="Attn-Q GPU47\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e23_l1_gpu46 [label="Attn-K/V GPU46\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e23_l1_gpu47 [label="Attn-K/V GPU47\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e23_l1_gpu46 [label="Attn-Out GPU46\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e23_l1_gpu47 [label="Attn-Out GPU47\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e23_l1_gpu46 [label="MLP-Gate GPU46\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e23_l1_gpu47 [label="MLP-Gate GPU47\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e23_l1_gpu46 [label="MLP-Up GPU46\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e23_l1_gpu47 [label="MLP-Up GPU47\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e23_l1_gpu46 [label="MLP-Down GPU46\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e23_l1_gpu47 [label="MLP-Down GPU47\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e23_l2_gpu46 [label="LayerNorm GPU46\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e23_l2_gpu47 [label="LayerNorm GPU47\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e23_l2_gpu46 [label="Attn-Q GPU46\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e23_l2_gpu47 [label="Attn-Q GPU47\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e23_l2_gpu46 [label="Attn-K/V GPU46\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e23_l2_gpu47 [label="Attn-K/V GPU47\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e23_l2_gpu46 [label="Attn-Out GPU46\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e23_l2_gpu47 [label="Attn-Out GPU47\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e23_l2_gpu46 [label="MLP-Gate GPU46\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e23_l2_gpu47 [label="MLP-Gate GPU47\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e23_l2_gpu46 [label="MLP-Up GPU46\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e23_l2_gpu47 [label="MLP-Up GPU47\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e23_l2_gpu46 [label="MLP-Down GPU46\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e23_l2_gpu47 [label="MLP-Down GPU47\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e23_l3_gpu46 [label="LayerNorm GPU46\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e23_l3_gpu47 [label="LayerNorm GPU47\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e23_l3_gpu46 [label="Attn-Q GPU46\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e23_l3_gpu47 [label="Attn-Q GPU47\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e23_l3_gpu46 [label="Attn-K/V GPU46\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e23_l3_gpu47 [label="Attn-K/V GPU47\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e23_l3_gpu46 [label="Attn-Out GPU46\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e23_l3_gpu47 [label="Attn-Out GPU47\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e23_l3_gpu46 [label="MLP-Gate GPU46\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e23_l3_gpu47 [label="MLP-Gate GPU47\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e23_l3_gpu46 [label="MLP-Up GPU46\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e23_l3_gpu47 [label="MLP-Up GPU47\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e23_l3_gpu46 [label="MLP-Down GPU46\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e23_l3_gpu47 [label="MLP-Down GPU47\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_24 {
			color=red fillcolor=lightgray label="Expert 24" style="rounded,filled"
			attn_norm_s1_e24_l0_gpu48 [label="LayerNorm GPU48\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e24_l0_gpu49 [label="LayerNorm GPU49\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e24_l0_gpu48 [label="Attn-Q GPU48\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e24_l0_gpu49 [label="Attn-Q GPU49\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e24_l0_gpu48 [label="Attn-K/V GPU48\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e24_l0_gpu49 [label="Attn-K/V GPU49\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e24_l0_gpu48 [label="Attn-Out GPU48\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e24_l0_gpu49 [label="Attn-Out GPU49\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e24_l0_gpu48 [label="MLP-Gate GPU48\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e24_l0_gpu49 [label="MLP-Gate GPU49\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e24_l0_gpu48 [label="MLP-Up GPU48\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e24_l0_gpu49 [label="MLP-Up GPU49\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e24_l0_gpu48 [label="MLP-Down GPU48\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e24_l0_gpu49 [label="MLP-Down GPU49\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e24_l1_gpu48 [label="LayerNorm GPU48\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e24_l1_gpu49 [label="LayerNorm GPU49\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e24_l1_gpu48 [label="Attn-Q GPU48\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e24_l1_gpu49 [label="Attn-Q GPU49\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e24_l1_gpu48 [label="Attn-K/V GPU48\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e24_l1_gpu49 [label="Attn-K/V GPU49\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e24_l1_gpu48 [label="Attn-Out GPU48\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e24_l1_gpu49 [label="Attn-Out GPU49\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e24_l1_gpu48 [label="MLP-Gate GPU48\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e24_l1_gpu49 [label="MLP-Gate GPU49\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e24_l1_gpu48 [label="MLP-Up GPU48\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e24_l1_gpu49 [label="MLP-Up GPU49\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e24_l1_gpu48 [label="MLP-Down GPU48\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e24_l1_gpu49 [label="MLP-Down GPU49\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e24_l2_gpu48 [label="LayerNorm GPU48\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e24_l2_gpu49 [label="LayerNorm GPU49\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e24_l2_gpu48 [label="Attn-Q GPU48\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e24_l2_gpu49 [label="Attn-Q GPU49\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e24_l2_gpu48 [label="Attn-K/V GPU48\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e24_l2_gpu49 [label="Attn-K/V GPU49\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e24_l2_gpu48 [label="Attn-Out GPU48\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e24_l2_gpu49 [label="Attn-Out GPU49\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e24_l2_gpu48 [label="MLP-Gate GPU48\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e24_l2_gpu49 [label="MLP-Gate GPU49\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e24_l2_gpu48 [label="MLP-Up GPU48\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e24_l2_gpu49 [label="MLP-Up GPU49\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e24_l2_gpu48 [label="MLP-Down GPU48\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e24_l2_gpu49 [label="MLP-Down GPU49\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e24_l3_gpu48 [label="LayerNorm GPU48\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e24_l3_gpu49 [label="LayerNorm GPU49\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e24_l3_gpu48 [label="Attn-Q GPU48\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e24_l3_gpu49 [label="Attn-Q GPU49\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e24_l3_gpu48 [label="Attn-K/V GPU48\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e24_l3_gpu49 [label="Attn-K/V GPU49\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e24_l3_gpu48 [label="Attn-Out GPU48\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e24_l3_gpu49 [label="Attn-Out GPU49\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e24_l3_gpu48 [label="MLP-Gate GPU48\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e24_l3_gpu49 [label="MLP-Gate GPU49\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e24_l3_gpu48 [label="MLP-Up GPU48\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e24_l3_gpu49 [label="MLP-Up GPU49\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e24_l3_gpu48 [label="MLP-Down GPU48\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e24_l3_gpu49 [label="MLP-Down GPU49\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_25 {
			color=red fillcolor=lightgray label="Expert 25" style="rounded,filled"
			attn_norm_s1_e25_l0_gpu50 [label="LayerNorm GPU50\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e25_l0_gpu51 [label="LayerNorm GPU51\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e25_l0_gpu50 [label="Attn-Q GPU50\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e25_l0_gpu51 [label="Attn-Q GPU51\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e25_l0_gpu50 [label="Attn-K/V GPU50\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e25_l0_gpu51 [label="Attn-K/V GPU51\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e25_l0_gpu50 [label="Attn-Out GPU50\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e25_l0_gpu51 [label="Attn-Out GPU51\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e25_l0_gpu50 [label="MLP-Gate GPU50\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e25_l0_gpu51 [label="MLP-Gate GPU51\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e25_l0_gpu50 [label="MLP-Up GPU50\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e25_l0_gpu51 [label="MLP-Up GPU51\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e25_l0_gpu50 [label="MLP-Down GPU50\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e25_l0_gpu51 [label="MLP-Down GPU51\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e25_l1_gpu50 [label="LayerNorm GPU50\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e25_l1_gpu51 [label="LayerNorm GPU51\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e25_l1_gpu50 [label="Attn-Q GPU50\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e25_l1_gpu51 [label="Attn-Q GPU51\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e25_l1_gpu50 [label="Attn-K/V GPU50\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e25_l1_gpu51 [label="Attn-K/V GPU51\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e25_l1_gpu50 [label="Attn-Out GPU50\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e25_l1_gpu51 [label="Attn-Out GPU51\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e25_l1_gpu50 [label="MLP-Gate GPU50\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e25_l1_gpu51 [label="MLP-Gate GPU51\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e25_l1_gpu50 [label="MLP-Up GPU50\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e25_l1_gpu51 [label="MLP-Up GPU51\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e25_l1_gpu50 [label="MLP-Down GPU50\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e25_l1_gpu51 [label="MLP-Down GPU51\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e25_l2_gpu50 [label="LayerNorm GPU50\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e25_l2_gpu51 [label="LayerNorm GPU51\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e25_l2_gpu50 [label="Attn-Q GPU50\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e25_l2_gpu51 [label="Attn-Q GPU51\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e25_l2_gpu50 [label="Attn-K/V GPU50\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e25_l2_gpu51 [label="Attn-K/V GPU51\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e25_l2_gpu50 [label="Attn-Out GPU50\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e25_l2_gpu51 [label="Attn-Out GPU51\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e25_l2_gpu50 [label="MLP-Gate GPU50\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e25_l2_gpu51 [label="MLP-Gate GPU51\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e25_l2_gpu50 [label="MLP-Up GPU50\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e25_l2_gpu51 [label="MLP-Up GPU51\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e25_l2_gpu50 [label="MLP-Down GPU50\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e25_l2_gpu51 [label="MLP-Down GPU51\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e25_l3_gpu50 [label="LayerNorm GPU50\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e25_l3_gpu51 [label="LayerNorm GPU51\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e25_l3_gpu50 [label="Attn-Q GPU50\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e25_l3_gpu51 [label="Attn-Q GPU51\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e25_l3_gpu50 [label="Attn-K/V GPU50\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e25_l3_gpu51 [label="Attn-K/V GPU51\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e25_l3_gpu50 [label="Attn-Out GPU50\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e25_l3_gpu51 [label="Attn-Out GPU51\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e25_l3_gpu50 [label="MLP-Gate GPU50\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e25_l3_gpu51 [label="MLP-Gate GPU51\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e25_l3_gpu50 [label="MLP-Up GPU50\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e25_l3_gpu51 [label="MLP-Up GPU51\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e25_l3_gpu50 [label="MLP-Down GPU50\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e25_l3_gpu51 [label="MLP-Down GPU51\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_26 {
			color=red fillcolor=lightgray label="Expert 26" style="rounded,filled"
			attn_norm_s1_e26_l0_gpu52 [label="LayerNorm GPU52\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e26_l0_gpu53 [label="LayerNorm GPU53\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e26_l0_gpu52 [label="Attn-Q GPU52\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e26_l0_gpu53 [label="Attn-Q GPU53\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e26_l0_gpu52 [label="Attn-K/V GPU52\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e26_l0_gpu53 [label="Attn-K/V GPU53\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e26_l0_gpu52 [label="Attn-Out GPU52\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e26_l0_gpu53 [label="Attn-Out GPU53\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e26_l0_gpu52 [label="MLP-Gate GPU52\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e26_l0_gpu53 [label="MLP-Gate GPU53\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e26_l0_gpu52 [label="MLP-Up GPU52\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e26_l0_gpu53 [label="MLP-Up GPU53\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e26_l0_gpu52 [label="MLP-Down GPU52\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e26_l0_gpu53 [label="MLP-Down GPU53\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e26_l1_gpu52 [label="LayerNorm GPU52\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e26_l1_gpu53 [label="LayerNorm GPU53\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e26_l1_gpu52 [label="Attn-Q GPU52\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e26_l1_gpu53 [label="Attn-Q GPU53\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e26_l1_gpu52 [label="Attn-K/V GPU52\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e26_l1_gpu53 [label="Attn-K/V GPU53\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e26_l1_gpu52 [label="Attn-Out GPU52\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e26_l1_gpu53 [label="Attn-Out GPU53\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e26_l1_gpu52 [label="MLP-Gate GPU52\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e26_l1_gpu53 [label="MLP-Gate GPU53\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e26_l1_gpu52 [label="MLP-Up GPU52\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e26_l1_gpu53 [label="MLP-Up GPU53\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e26_l1_gpu52 [label="MLP-Down GPU52\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e26_l1_gpu53 [label="MLP-Down GPU53\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e26_l2_gpu52 [label="LayerNorm GPU52\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e26_l2_gpu53 [label="LayerNorm GPU53\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e26_l2_gpu52 [label="Attn-Q GPU52\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e26_l2_gpu53 [label="Attn-Q GPU53\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e26_l2_gpu52 [label="Attn-K/V GPU52\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e26_l2_gpu53 [label="Attn-K/V GPU53\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e26_l2_gpu52 [label="Attn-Out GPU52\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e26_l2_gpu53 [label="Attn-Out GPU53\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e26_l2_gpu52 [label="MLP-Gate GPU52\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e26_l2_gpu53 [label="MLP-Gate GPU53\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e26_l2_gpu52 [label="MLP-Up GPU52\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e26_l2_gpu53 [label="MLP-Up GPU53\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e26_l2_gpu52 [label="MLP-Down GPU52\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e26_l2_gpu53 [label="MLP-Down GPU53\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e26_l3_gpu52 [label="LayerNorm GPU52\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e26_l3_gpu53 [label="LayerNorm GPU53\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e26_l3_gpu52 [label="Attn-Q GPU52\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e26_l3_gpu53 [label="Attn-Q GPU53\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e26_l3_gpu52 [label="Attn-K/V GPU52\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e26_l3_gpu53 [label="Attn-K/V GPU53\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e26_l3_gpu52 [label="Attn-Out GPU52\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e26_l3_gpu53 [label="Attn-Out GPU53\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e26_l3_gpu52 [label="MLP-Gate GPU52\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e26_l3_gpu53 [label="MLP-Gate GPU53\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e26_l3_gpu52 [label="MLP-Up GPU52\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e26_l3_gpu53 [label="MLP-Up GPU53\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e26_l3_gpu52 [label="MLP-Down GPU52\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e26_l3_gpu53 [label="MLP-Down GPU53\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_27 {
			color=red fillcolor=lightgray label="Expert 27" style="rounded,filled"
			attn_norm_s1_e27_l0_gpu54 [label="LayerNorm GPU54\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e27_l0_gpu55 [label="LayerNorm GPU55\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e27_l0_gpu54 [label="Attn-Q GPU54\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e27_l0_gpu55 [label="Attn-Q GPU55\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e27_l0_gpu54 [label="Attn-K/V GPU54\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e27_l0_gpu55 [label="Attn-K/V GPU55\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e27_l0_gpu54 [label="Attn-Out GPU54\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e27_l0_gpu55 [label="Attn-Out GPU55\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e27_l0_gpu54 [label="MLP-Gate GPU54\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e27_l0_gpu55 [label="MLP-Gate GPU55\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e27_l0_gpu54 [label="MLP-Up GPU54\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e27_l0_gpu55 [label="MLP-Up GPU55\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e27_l0_gpu54 [label="MLP-Down GPU54\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e27_l0_gpu55 [label="MLP-Down GPU55\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e27_l1_gpu54 [label="LayerNorm GPU54\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e27_l1_gpu55 [label="LayerNorm GPU55\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e27_l1_gpu54 [label="Attn-Q GPU54\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e27_l1_gpu55 [label="Attn-Q GPU55\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e27_l1_gpu54 [label="Attn-K/V GPU54\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e27_l1_gpu55 [label="Attn-K/V GPU55\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e27_l1_gpu54 [label="Attn-Out GPU54\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e27_l1_gpu55 [label="Attn-Out GPU55\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e27_l1_gpu54 [label="MLP-Gate GPU54\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e27_l1_gpu55 [label="MLP-Gate GPU55\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e27_l1_gpu54 [label="MLP-Up GPU54\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e27_l1_gpu55 [label="MLP-Up GPU55\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e27_l1_gpu54 [label="MLP-Down GPU54\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e27_l1_gpu55 [label="MLP-Down GPU55\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e27_l2_gpu54 [label="LayerNorm GPU54\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e27_l2_gpu55 [label="LayerNorm GPU55\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e27_l2_gpu54 [label="Attn-Q GPU54\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e27_l2_gpu55 [label="Attn-Q GPU55\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e27_l2_gpu54 [label="Attn-K/V GPU54\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e27_l2_gpu55 [label="Attn-K/V GPU55\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e27_l2_gpu54 [label="Attn-Out GPU54\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e27_l2_gpu55 [label="Attn-Out GPU55\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e27_l2_gpu54 [label="MLP-Gate GPU54\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e27_l2_gpu55 [label="MLP-Gate GPU55\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e27_l2_gpu54 [label="MLP-Up GPU54\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e27_l2_gpu55 [label="MLP-Up GPU55\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e27_l2_gpu54 [label="MLP-Down GPU54\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e27_l2_gpu55 [label="MLP-Down GPU55\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e27_l3_gpu54 [label="LayerNorm GPU54\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e27_l3_gpu55 [label="LayerNorm GPU55\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e27_l3_gpu54 [label="Attn-Q GPU54\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e27_l3_gpu55 [label="Attn-Q GPU55\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e27_l3_gpu54 [label="Attn-K/V GPU54\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e27_l3_gpu55 [label="Attn-K/V GPU55\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e27_l3_gpu54 [label="Attn-Out GPU54\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e27_l3_gpu55 [label="Attn-Out GPU55\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e27_l3_gpu54 [label="MLP-Gate GPU54\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e27_l3_gpu55 [label="MLP-Gate GPU55\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e27_l3_gpu54 [label="MLP-Up GPU54\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e27_l3_gpu55 [label="MLP-Up GPU55\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e27_l3_gpu54 [label="MLP-Down GPU54\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e27_l3_gpu55 [label="MLP-Down GPU55\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_28 {
			color=red fillcolor=lightgray label="Expert 28" style="rounded,filled"
			attn_norm_s1_e28_l0_gpu56 [label="LayerNorm GPU56\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e28_l0_gpu57 [label="LayerNorm GPU57\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e28_l0_gpu56 [label="Attn-Q GPU56\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e28_l0_gpu57 [label="Attn-Q GPU57\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e28_l0_gpu56 [label="Attn-K/V GPU56\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e28_l0_gpu57 [label="Attn-K/V GPU57\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e28_l0_gpu56 [label="Attn-Out GPU56\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e28_l0_gpu57 [label="Attn-Out GPU57\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e28_l0_gpu56 [label="MLP-Gate GPU56\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e28_l0_gpu57 [label="MLP-Gate GPU57\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e28_l0_gpu56 [label="MLP-Up GPU56\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e28_l0_gpu57 [label="MLP-Up GPU57\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e28_l0_gpu56 [label="MLP-Down GPU56\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e28_l0_gpu57 [label="MLP-Down GPU57\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e28_l1_gpu56 [label="LayerNorm GPU56\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e28_l1_gpu57 [label="LayerNorm GPU57\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e28_l1_gpu56 [label="Attn-Q GPU56\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e28_l1_gpu57 [label="Attn-Q GPU57\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e28_l1_gpu56 [label="Attn-K/V GPU56\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e28_l1_gpu57 [label="Attn-K/V GPU57\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e28_l1_gpu56 [label="Attn-Out GPU56\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e28_l1_gpu57 [label="Attn-Out GPU57\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e28_l1_gpu56 [label="MLP-Gate GPU56\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e28_l1_gpu57 [label="MLP-Gate GPU57\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e28_l1_gpu56 [label="MLP-Up GPU56\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e28_l1_gpu57 [label="MLP-Up GPU57\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e28_l1_gpu56 [label="MLP-Down GPU56\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e28_l1_gpu57 [label="MLP-Down GPU57\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e28_l2_gpu56 [label="LayerNorm GPU56\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e28_l2_gpu57 [label="LayerNorm GPU57\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e28_l2_gpu56 [label="Attn-Q GPU56\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e28_l2_gpu57 [label="Attn-Q GPU57\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e28_l2_gpu56 [label="Attn-K/V GPU56\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e28_l2_gpu57 [label="Attn-K/V GPU57\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e28_l2_gpu56 [label="Attn-Out GPU56\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e28_l2_gpu57 [label="Attn-Out GPU57\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e28_l2_gpu56 [label="MLP-Gate GPU56\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e28_l2_gpu57 [label="MLP-Gate GPU57\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e28_l2_gpu56 [label="MLP-Up GPU56\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e28_l2_gpu57 [label="MLP-Up GPU57\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e28_l2_gpu56 [label="MLP-Down GPU56\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e28_l2_gpu57 [label="MLP-Down GPU57\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e28_l3_gpu56 [label="LayerNorm GPU56\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e28_l3_gpu57 [label="LayerNorm GPU57\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e28_l3_gpu56 [label="Attn-Q GPU56\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e28_l3_gpu57 [label="Attn-Q GPU57\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e28_l3_gpu56 [label="Attn-K/V GPU56\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e28_l3_gpu57 [label="Attn-K/V GPU57\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e28_l3_gpu56 [label="Attn-Out GPU56\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e28_l3_gpu57 [label="Attn-Out GPU57\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e28_l3_gpu56 [label="MLP-Gate GPU56\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e28_l3_gpu57 [label="MLP-Gate GPU57\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e28_l3_gpu56 [label="MLP-Up GPU56\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e28_l3_gpu57 [label="MLP-Up GPU57\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e28_l3_gpu56 [label="MLP-Down GPU56\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e28_l3_gpu57 [label="MLP-Down GPU57\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_29 {
			color=red fillcolor=lightgray label="Expert 29" style="rounded,filled"
			attn_norm_s1_e29_l0_gpu58 [label="LayerNorm GPU58\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e29_l0_gpu59 [label="LayerNorm GPU59\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e29_l0_gpu58 [label="Attn-Q GPU58\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e29_l0_gpu59 [label="Attn-Q GPU59\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e29_l0_gpu58 [label="Attn-K/V GPU58\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e29_l0_gpu59 [label="Attn-K/V GPU59\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e29_l0_gpu58 [label="Attn-Out GPU58\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e29_l0_gpu59 [label="Attn-Out GPU59\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e29_l0_gpu58 [label="MLP-Gate GPU58\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e29_l0_gpu59 [label="MLP-Gate GPU59\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e29_l0_gpu58 [label="MLP-Up GPU58\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e29_l0_gpu59 [label="MLP-Up GPU59\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e29_l0_gpu58 [label="MLP-Down GPU58\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e29_l0_gpu59 [label="MLP-Down GPU59\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e29_l1_gpu58 [label="LayerNorm GPU58\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e29_l1_gpu59 [label="LayerNorm GPU59\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e29_l1_gpu58 [label="Attn-Q GPU58\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e29_l1_gpu59 [label="Attn-Q GPU59\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e29_l1_gpu58 [label="Attn-K/V GPU58\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e29_l1_gpu59 [label="Attn-K/V GPU59\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e29_l1_gpu58 [label="Attn-Out GPU58\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e29_l1_gpu59 [label="Attn-Out GPU59\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e29_l1_gpu58 [label="MLP-Gate GPU58\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e29_l1_gpu59 [label="MLP-Gate GPU59\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e29_l1_gpu58 [label="MLP-Up GPU58\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e29_l1_gpu59 [label="MLP-Up GPU59\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e29_l1_gpu58 [label="MLP-Down GPU58\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e29_l1_gpu59 [label="MLP-Down GPU59\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e29_l2_gpu58 [label="LayerNorm GPU58\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e29_l2_gpu59 [label="LayerNorm GPU59\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e29_l2_gpu58 [label="Attn-Q GPU58\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e29_l2_gpu59 [label="Attn-Q GPU59\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e29_l2_gpu58 [label="Attn-K/V GPU58\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e29_l2_gpu59 [label="Attn-K/V GPU59\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e29_l2_gpu58 [label="Attn-Out GPU58\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e29_l2_gpu59 [label="Attn-Out GPU59\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e29_l2_gpu58 [label="MLP-Gate GPU58\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e29_l2_gpu59 [label="MLP-Gate GPU59\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e29_l2_gpu58 [label="MLP-Up GPU58\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e29_l2_gpu59 [label="MLP-Up GPU59\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e29_l2_gpu58 [label="MLP-Down GPU58\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e29_l2_gpu59 [label="MLP-Down GPU59\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e29_l3_gpu58 [label="LayerNorm GPU58\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e29_l3_gpu59 [label="LayerNorm GPU59\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e29_l3_gpu58 [label="Attn-Q GPU58\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e29_l3_gpu59 [label="Attn-Q GPU59\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e29_l3_gpu58 [label="Attn-K/V GPU58\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e29_l3_gpu59 [label="Attn-K/V GPU59\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e29_l3_gpu58 [label="Attn-Out GPU58\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e29_l3_gpu59 [label="Attn-Out GPU59\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e29_l3_gpu58 [label="MLP-Gate GPU58\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e29_l3_gpu59 [label="MLP-Gate GPU59\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e29_l3_gpu58 [label="MLP-Up GPU58\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e29_l3_gpu59 [label="MLP-Up GPU59\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e29_l3_gpu58 [label="MLP-Down GPU58\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e29_l3_gpu59 [label="MLP-Down GPU59\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_30 {
			color=red fillcolor=lightgray label="Expert 30" style="rounded,filled"
			attn_norm_s1_e30_l0_gpu60 [label="LayerNorm GPU60\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e30_l0_gpu61 [label="LayerNorm GPU61\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e30_l0_gpu60 [label="Attn-Q GPU60\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e30_l0_gpu61 [label="Attn-Q GPU61\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e30_l0_gpu60 [label="Attn-K/V GPU60\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e30_l0_gpu61 [label="Attn-K/V GPU61\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e30_l0_gpu60 [label="Attn-Out GPU60\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e30_l0_gpu61 [label="Attn-Out GPU61\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e30_l0_gpu60 [label="MLP-Gate GPU60\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e30_l0_gpu61 [label="MLP-Gate GPU61\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e30_l0_gpu60 [label="MLP-Up GPU60\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e30_l0_gpu61 [label="MLP-Up GPU61\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e30_l0_gpu60 [label="MLP-Down GPU60\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e30_l0_gpu61 [label="MLP-Down GPU61\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e30_l1_gpu60 [label="LayerNorm GPU60\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e30_l1_gpu61 [label="LayerNorm GPU61\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e30_l1_gpu60 [label="Attn-Q GPU60\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e30_l1_gpu61 [label="Attn-Q GPU61\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e30_l1_gpu60 [label="Attn-K/V GPU60\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e30_l1_gpu61 [label="Attn-K/V GPU61\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e30_l1_gpu60 [label="Attn-Out GPU60\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e30_l1_gpu61 [label="Attn-Out GPU61\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e30_l1_gpu60 [label="MLP-Gate GPU60\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e30_l1_gpu61 [label="MLP-Gate GPU61\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e30_l1_gpu60 [label="MLP-Up GPU60\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e30_l1_gpu61 [label="MLP-Up GPU61\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e30_l1_gpu60 [label="MLP-Down GPU60\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e30_l1_gpu61 [label="MLP-Down GPU61\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e30_l2_gpu60 [label="LayerNorm GPU60\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e30_l2_gpu61 [label="LayerNorm GPU61\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e30_l2_gpu60 [label="Attn-Q GPU60\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e30_l2_gpu61 [label="Attn-Q GPU61\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e30_l2_gpu60 [label="Attn-K/V GPU60\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e30_l2_gpu61 [label="Attn-K/V GPU61\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e30_l2_gpu60 [label="Attn-Out GPU60\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e30_l2_gpu61 [label="Attn-Out GPU61\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e30_l2_gpu60 [label="MLP-Gate GPU60\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e30_l2_gpu61 [label="MLP-Gate GPU61\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e30_l2_gpu60 [label="MLP-Up GPU60\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e30_l2_gpu61 [label="MLP-Up GPU61\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e30_l2_gpu60 [label="MLP-Down GPU60\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e30_l2_gpu61 [label="MLP-Down GPU61\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e30_l3_gpu60 [label="LayerNorm GPU60\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e30_l3_gpu61 [label="LayerNorm GPU61\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e30_l3_gpu60 [label="Attn-Q GPU60\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e30_l3_gpu61 [label="Attn-Q GPU61\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e30_l3_gpu60 [label="Attn-K/V GPU60\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e30_l3_gpu61 [label="Attn-K/V GPU61\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e30_l3_gpu60 [label="Attn-Out GPU60\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e30_l3_gpu61 [label="Attn-Out GPU61\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e30_l3_gpu60 [label="MLP-Gate GPU60\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e30_l3_gpu61 [label="MLP-Gate GPU61\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e30_l3_gpu60 [label="MLP-Up GPU60\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e30_l3_gpu61 [label="MLP-Up GPU61\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e30_l3_gpu60 [label="MLP-Down GPU60\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e30_l3_gpu61 [label="MLP-Down GPU61\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_31 {
			color=red fillcolor=lightgray label="Expert 31" style="rounded,filled"
			attn_norm_s1_e31_l0_gpu62 [label="LayerNorm GPU62\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e31_l0_gpu63 [label="LayerNorm GPU63\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e31_l0_gpu62 [label="Attn-Q GPU62\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e31_l0_gpu63 [label="Attn-Q GPU63\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e31_l0_gpu62 [label="Attn-K/V GPU62\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e31_l0_gpu63 [label="Attn-K/V GPU63\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e31_l0_gpu62 [label="Attn-Out GPU62\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e31_l0_gpu63 [label="Attn-Out GPU63\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e31_l0_gpu62 [label="MLP-Gate GPU62\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e31_l0_gpu63 [label="MLP-Gate GPU63\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e31_l0_gpu62 [label="MLP-Up GPU62\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e31_l0_gpu63 [label="MLP-Up GPU63\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e31_l0_gpu62 [label="MLP-Down GPU62\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e31_l0_gpu63 [label="MLP-Down GPU63\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e31_l1_gpu62 [label="LayerNorm GPU62\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e31_l1_gpu63 [label="LayerNorm GPU63\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e31_l1_gpu62 [label="Attn-Q GPU62\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e31_l1_gpu63 [label="Attn-Q GPU63\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e31_l1_gpu62 [label="Attn-K/V GPU62\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e31_l1_gpu63 [label="Attn-K/V GPU63\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e31_l1_gpu62 [label="Attn-Out GPU62\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e31_l1_gpu63 [label="Attn-Out GPU63\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e31_l1_gpu62 [label="MLP-Gate GPU62\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e31_l1_gpu63 [label="MLP-Gate GPU63\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e31_l1_gpu62 [label="MLP-Up GPU62\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e31_l1_gpu63 [label="MLP-Up GPU63\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e31_l1_gpu62 [label="MLP-Down GPU62\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e31_l1_gpu63 [label="MLP-Down GPU63\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e31_l2_gpu62 [label="LayerNorm GPU62\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e31_l2_gpu63 [label="LayerNorm GPU63\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e31_l2_gpu62 [label="Attn-Q GPU62\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e31_l2_gpu63 [label="Attn-Q GPU63\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e31_l2_gpu62 [label="Attn-K/V GPU62\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e31_l2_gpu63 [label="Attn-K/V GPU63\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e31_l2_gpu62 [label="Attn-Out GPU62\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e31_l2_gpu63 [label="Attn-Out GPU63\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e31_l2_gpu62 [label="MLP-Gate GPU62\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e31_l2_gpu63 [label="MLP-Gate GPU63\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e31_l2_gpu62 [label="MLP-Up GPU62\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e31_l2_gpu63 [label="MLP-Up GPU63\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e31_l2_gpu62 [label="MLP-Down GPU62\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e31_l2_gpu63 [label="MLP-Down GPU63\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s1_e31_l3_gpu62 [label="LayerNorm GPU62\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s1_e31_l3_gpu63 [label="LayerNorm GPU63\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s1_e31_l3_gpu62 [label="Attn-Q GPU62\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s1_e31_l3_gpu63 [label="Attn-Q GPU63\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e31_l3_gpu62 [label="Attn-K/V GPU62\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s1_e31_l3_gpu63 [label="Attn-K/V GPU63\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s1_e31_l3_gpu62 [label="Attn-Out GPU62\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s1_e31_l3_gpu63 [label="Attn-Out GPU63\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s1_e31_l3_gpu62 [label="MLP-Gate GPU62\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s1_e31_l3_gpu63 [label="MLP-Gate GPU63\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e31_l3_gpu62 [label="MLP-Up GPU62\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s1_e31_l3_gpu63 [label="MLP-Up GPU63\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s1_e31_l3_gpu62 [label="MLP-Down GPU62\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s1_e31_l3_gpu63 [label="MLP-Down GPU63\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
	}
	subgraph cluster_stage_2 {
		color=blue fillcolor=lightyellow label="Pipeline Stage 2 (Layers 8-11)" style="rounded,filled"
		subgraph cluster_expert_32 {
			color=red fillcolor=lightgray label="Expert 32" style="rounded,filled"
			attn_norm_s2_e32_l0_gpu64 [label="LayerNorm GPU64\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e32_l0_gpu65 [label="LayerNorm GPU65\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e32_l0_gpu64 [label="Attn-Q GPU64\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e32_l0_gpu65 [label="Attn-Q GPU65\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e32_l0_gpu64 [label="Attn-K/V GPU64\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e32_l0_gpu65 [label="Attn-K/V GPU65\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e32_l0_gpu64 [label="Attn-Out GPU64\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e32_l0_gpu65 [label="Attn-Out GPU65\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e32_l0_gpu64 [label="MLP-Gate GPU64\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e32_l0_gpu65 [label="MLP-Gate GPU65\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e32_l0_gpu64 [label="MLP-Up GPU64\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e32_l0_gpu65 [label="MLP-Up GPU65\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e32_l0_gpu64 [label="MLP-Down GPU64\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e32_l0_gpu65 [label="MLP-Down GPU65\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e32_l1_gpu64 [label="LayerNorm GPU64\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e32_l1_gpu65 [label="LayerNorm GPU65\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e32_l1_gpu64 [label="Attn-Q GPU64\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e32_l1_gpu65 [label="Attn-Q GPU65\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e32_l1_gpu64 [label="Attn-K/V GPU64\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e32_l1_gpu65 [label="Attn-K/V GPU65\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e32_l1_gpu64 [label="Attn-Out GPU64\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e32_l1_gpu65 [label="Attn-Out GPU65\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e32_l1_gpu64 [label="MLP-Gate GPU64\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e32_l1_gpu65 [label="MLP-Gate GPU65\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e32_l1_gpu64 [label="MLP-Up GPU64\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e32_l1_gpu65 [label="MLP-Up GPU65\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e32_l1_gpu64 [label="MLP-Down GPU64\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e32_l1_gpu65 [label="MLP-Down GPU65\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e32_l2_gpu64 [label="LayerNorm GPU64\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e32_l2_gpu65 [label="LayerNorm GPU65\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e32_l2_gpu64 [label="Attn-Q GPU64\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e32_l2_gpu65 [label="Attn-Q GPU65\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e32_l2_gpu64 [label="Attn-K/V GPU64\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e32_l2_gpu65 [label="Attn-K/V GPU65\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e32_l2_gpu64 [label="Attn-Out GPU64\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e32_l2_gpu65 [label="Attn-Out GPU65\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e32_l2_gpu64 [label="MLP-Gate GPU64\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e32_l2_gpu65 [label="MLP-Gate GPU65\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e32_l2_gpu64 [label="MLP-Up GPU64\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e32_l2_gpu65 [label="MLP-Up GPU65\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e32_l2_gpu64 [label="MLP-Down GPU64\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e32_l2_gpu65 [label="MLP-Down GPU65\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e32_l3_gpu64 [label="LayerNorm GPU64\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e32_l3_gpu65 [label="LayerNorm GPU65\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e32_l3_gpu64 [label="Attn-Q GPU64\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e32_l3_gpu65 [label="Attn-Q GPU65\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e32_l3_gpu64 [label="Attn-K/V GPU64\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e32_l3_gpu65 [label="Attn-K/V GPU65\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e32_l3_gpu64 [label="Attn-Out GPU64\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e32_l3_gpu65 [label="Attn-Out GPU65\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e32_l3_gpu64 [label="MLP-Gate GPU64\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e32_l3_gpu65 [label="MLP-Gate GPU65\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e32_l3_gpu64 [label="MLP-Up GPU64\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e32_l3_gpu65 [label="MLP-Up GPU65\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e32_l3_gpu64 [label="MLP-Down GPU64\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e32_l3_gpu65 [label="MLP-Down GPU65\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_33 {
			color=red fillcolor=lightgray label="Expert 33" style="rounded,filled"
			attn_norm_s2_e33_l0_gpu66 [label="LayerNorm GPU66\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e33_l0_gpu67 [label="LayerNorm GPU67\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e33_l0_gpu66 [label="Attn-Q GPU66\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e33_l0_gpu67 [label="Attn-Q GPU67\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e33_l0_gpu66 [label="Attn-K/V GPU66\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e33_l0_gpu67 [label="Attn-K/V GPU67\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e33_l0_gpu66 [label="Attn-Out GPU66\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e33_l0_gpu67 [label="Attn-Out GPU67\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e33_l0_gpu66 [label="MLP-Gate GPU66\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e33_l0_gpu67 [label="MLP-Gate GPU67\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e33_l0_gpu66 [label="MLP-Up GPU66\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e33_l0_gpu67 [label="MLP-Up GPU67\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e33_l0_gpu66 [label="MLP-Down GPU66\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e33_l0_gpu67 [label="MLP-Down GPU67\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e33_l1_gpu66 [label="LayerNorm GPU66\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e33_l1_gpu67 [label="LayerNorm GPU67\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e33_l1_gpu66 [label="Attn-Q GPU66\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e33_l1_gpu67 [label="Attn-Q GPU67\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e33_l1_gpu66 [label="Attn-K/V GPU66\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e33_l1_gpu67 [label="Attn-K/V GPU67\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e33_l1_gpu66 [label="Attn-Out GPU66\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e33_l1_gpu67 [label="Attn-Out GPU67\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e33_l1_gpu66 [label="MLP-Gate GPU66\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e33_l1_gpu67 [label="MLP-Gate GPU67\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e33_l1_gpu66 [label="MLP-Up GPU66\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e33_l1_gpu67 [label="MLP-Up GPU67\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e33_l1_gpu66 [label="MLP-Down GPU66\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e33_l1_gpu67 [label="MLP-Down GPU67\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e33_l2_gpu66 [label="LayerNorm GPU66\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e33_l2_gpu67 [label="LayerNorm GPU67\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e33_l2_gpu66 [label="Attn-Q GPU66\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e33_l2_gpu67 [label="Attn-Q GPU67\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e33_l2_gpu66 [label="Attn-K/V GPU66\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e33_l2_gpu67 [label="Attn-K/V GPU67\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e33_l2_gpu66 [label="Attn-Out GPU66\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e33_l2_gpu67 [label="Attn-Out GPU67\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e33_l2_gpu66 [label="MLP-Gate GPU66\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e33_l2_gpu67 [label="MLP-Gate GPU67\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e33_l2_gpu66 [label="MLP-Up GPU66\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e33_l2_gpu67 [label="MLP-Up GPU67\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e33_l2_gpu66 [label="MLP-Down GPU66\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e33_l2_gpu67 [label="MLP-Down GPU67\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e33_l3_gpu66 [label="LayerNorm GPU66\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e33_l3_gpu67 [label="LayerNorm GPU67\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e33_l3_gpu66 [label="Attn-Q GPU66\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e33_l3_gpu67 [label="Attn-Q GPU67\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e33_l3_gpu66 [label="Attn-K/V GPU66\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e33_l3_gpu67 [label="Attn-K/V GPU67\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e33_l3_gpu66 [label="Attn-Out GPU66\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e33_l3_gpu67 [label="Attn-Out GPU67\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e33_l3_gpu66 [label="MLP-Gate GPU66\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e33_l3_gpu67 [label="MLP-Gate GPU67\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e33_l3_gpu66 [label="MLP-Up GPU66\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e33_l3_gpu67 [label="MLP-Up GPU67\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e33_l3_gpu66 [label="MLP-Down GPU66\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e33_l3_gpu67 [label="MLP-Down GPU67\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_34 {
			color=red fillcolor=lightgray label="Expert 34" style="rounded,filled"
			attn_norm_s2_e34_l0_gpu68 [label="LayerNorm GPU68\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e34_l0_gpu69 [label="LayerNorm GPU69\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e34_l0_gpu68 [label="Attn-Q GPU68\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e34_l0_gpu69 [label="Attn-Q GPU69\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e34_l0_gpu68 [label="Attn-K/V GPU68\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e34_l0_gpu69 [label="Attn-K/V GPU69\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e34_l0_gpu68 [label="Attn-Out GPU68\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e34_l0_gpu69 [label="Attn-Out GPU69\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e34_l0_gpu68 [label="MLP-Gate GPU68\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e34_l0_gpu69 [label="MLP-Gate GPU69\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e34_l0_gpu68 [label="MLP-Up GPU68\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e34_l0_gpu69 [label="MLP-Up GPU69\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e34_l0_gpu68 [label="MLP-Down GPU68\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e34_l0_gpu69 [label="MLP-Down GPU69\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e34_l1_gpu68 [label="LayerNorm GPU68\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e34_l1_gpu69 [label="LayerNorm GPU69\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e34_l1_gpu68 [label="Attn-Q GPU68\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e34_l1_gpu69 [label="Attn-Q GPU69\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e34_l1_gpu68 [label="Attn-K/V GPU68\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e34_l1_gpu69 [label="Attn-K/V GPU69\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e34_l1_gpu68 [label="Attn-Out GPU68\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e34_l1_gpu69 [label="Attn-Out GPU69\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e34_l1_gpu68 [label="MLP-Gate GPU68\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e34_l1_gpu69 [label="MLP-Gate GPU69\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e34_l1_gpu68 [label="MLP-Up GPU68\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e34_l1_gpu69 [label="MLP-Up GPU69\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e34_l1_gpu68 [label="MLP-Down GPU68\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e34_l1_gpu69 [label="MLP-Down GPU69\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e34_l2_gpu68 [label="LayerNorm GPU68\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e34_l2_gpu69 [label="LayerNorm GPU69\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e34_l2_gpu68 [label="Attn-Q GPU68\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e34_l2_gpu69 [label="Attn-Q GPU69\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e34_l2_gpu68 [label="Attn-K/V GPU68\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e34_l2_gpu69 [label="Attn-K/V GPU69\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e34_l2_gpu68 [label="Attn-Out GPU68\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e34_l2_gpu69 [label="Attn-Out GPU69\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e34_l2_gpu68 [label="MLP-Gate GPU68\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e34_l2_gpu69 [label="MLP-Gate GPU69\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e34_l2_gpu68 [label="MLP-Up GPU68\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e34_l2_gpu69 [label="MLP-Up GPU69\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e34_l2_gpu68 [label="MLP-Down GPU68\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e34_l2_gpu69 [label="MLP-Down GPU69\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e34_l3_gpu68 [label="LayerNorm GPU68\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e34_l3_gpu69 [label="LayerNorm GPU69\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e34_l3_gpu68 [label="Attn-Q GPU68\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e34_l3_gpu69 [label="Attn-Q GPU69\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e34_l3_gpu68 [label="Attn-K/V GPU68\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e34_l3_gpu69 [label="Attn-K/V GPU69\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e34_l3_gpu68 [label="Attn-Out GPU68\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e34_l3_gpu69 [label="Attn-Out GPU69\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e34_l3_gpu68 [label="MLP-Gate GPU68\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e34_l3_gpu69 [label="MLP-Gate GPU69\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e34_l3_gpu68 [label="MLP-Up GPU68\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e34_l3_gpu69 [label="MLP-Up GPU69\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e34_l3_gpu68 [label="MLP-Down GPU68\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e34_l3_gpu69 [label="MLP-Down GPU69\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_35 {
			color=red fillcolor=lightgray label="Expert 35" style="rounded,filled"
			attn_norm_s2_e35_l0_gpu70 [label="LayerNorm GPU70\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e35_l0_gpu71 [label="LayerNorm GPU71\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e35_l0_gpu70 [label="Attn-Q GPU70\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e35_l0_gpu71 [label="Attn-Q GPU71\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e35_l0_gpu70 [label="Attn-K/V GPU70\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e35_l0_gpu71 [label="Attn-K/V GPU71\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e35_l0_gpu70 [label="Attn-Out GPU70\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e35_l0_gpu71 [label="Attn-Out GPU71\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e35_l0_gpu70 [label="MLP-Gate GPU70\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e35_l0_gpu71 [label="MLP-Gate GPU71\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e35_l0_gpu70 [label="MLP-Up GPU70\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e35_l0_gpu71 [label="MLP-Up GPU71\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e35_l0_gpu70 [label="MLP-Down GPU70\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e35_l0_gpu71 [label="MLP-Down GPU71\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e35_l1_gpu70 [label="LayerNorm GPU70\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e35_l1_gpu71 [label="LayerNorm GPU71\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e35_l1_gpu70 [label="Attn-Q GPU70\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e35_l1_gpu71 [label="Attn-Q GPU71\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e35_l1_gpu70 [label="Attn-K/V GPU70\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e35_l1_gpu71 [label="Attn-K/V GPU71\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e35_l1_gpu70 [label="Attn-Out GPU70\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e35_l1_gpu71 [label="Attn-Out GPU71\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e35_l1_gpu70 [label="MLP-Gate GPU70\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e35_l1_gpu71 [label="MLP-Gate GPU71\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e35_l1_gpu70 [label="MLP-Up GPU70\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e35_l1_gpu71 [label="MLP-Up GPU71\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e35_l1_gpu70 [label="MLP-Down GPU70\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e35_l1_gpu71 [label="MLP-Down GPU71\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e35_l2_gpu70 [label="LayerNorm GPU70\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e35_l2_gpu71 [label="LayerNorm GPU71\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e35_l2_gpu70 [label="Attn-Q GPU70\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e35_l2_gpu71 [label="Attn-Q GPU71\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e35_l2_gpu70 [label="Attn-K/V GPU70\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e35_l2_gpu71 [label="Attn-K/V GPU71\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e35_l2_gpu70 [label="Attn-Out GPU70\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e35_l2_gpu71 [label="Attn-Out GPU71\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e35_l2_gpu70 [label="MLP-Gate GPU70\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e35_l2_gpu71 [label="MLP-Gate GPU71\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e35_l2_gpu70 [label="MLP-Up GPU70\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e35_l2_gpu71 [label="MLP-Up GPU71\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e35_l2_gpu70 [label="MLP-Down GPU70\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e35_l2_gpu71 [label="MLP-Down GPU71\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e35_l3_gpu70 [label="LayerNorm GPU70\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e35_l3_gpu71 [label="LayerNorm GPU71\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e35_l3_gpu70 [label="Attn-Q GPU70\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e35_l3_gpu71 [label="Attn-Q GPU71\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e35_l3_gpu70 [label="Attn-K/V GPU70\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e35_l3_gpu71 [label="Attn-K/V GPU71\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e35_l3_gpu70 [label="Attn-Out GPU70\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e35_l3_gpu71 [label="Attn-Out GPU71\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e35_l3_gpu70 [label="MLP-Gate GPU70\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e35_l3_gpu71 [label="MLP-Gate GPU71\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e35_l3_gpu70 [label="MLP-Up GPU70\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e35_l3_gpu71 [label="MLP-Up GPU71\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e35_l3_gpu70 [label="MLP-Down GPU70\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e35_l3_gpu71 [label="MLP-Down GPU71\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_36 {
			color=red fillcolor=lightgray label="Expert 36" style="rounded,filled"
			attn_norm_s2_e36_l0_gpu72 [label="LayerNorm GPU72\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e36_l0_gpu73 [label="LayerNorm GPU73\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e36_l0_gpu72 [label="Attn-Q GPU72\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e36_l0_gpu73 [label="Attn-Q GPU73\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e36_l0_gpu72 [label="Attn-K/V GPU72\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e36_l0_gpu73 [label="Attn-K/V GPU73\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e36_l0_gpu72 [label="Attn-Out GPU72\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e36_l0_gpu73 [label="Attn-Out GPU73\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e36_l0_gpu72 [label="MLP-Gate GPU72\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e36_l0_gpu73 [label="MLP-Gate GPU73\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e36_l0_gpu72 [label="MLP-Up GPU72\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e36_l0_gpu73 [label="MLP-Up GPU73\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e36_l0_gpu72 [label="MLP-Down GPU72\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e36_l0_gpu73 [label="MLP-Down GPU73\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e36_l1_gpu72 [label="LayerNorm GPU72\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e36_l1_gpu73 [label="LayerNorm GPU73\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e36_l1_gpu72 [label="Attn-Q GPU72\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e36_l1_gpu73 [label="Attn-Q GPU73\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e36_l1_gpu72 [label="Attn-K/V GPU72\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e36_l1_gpu73 [label="Attn-K/V GPU73\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e36_l1_gpu72 [label="Attn-Out GPU72\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e36_l1_gpu73 [label="Attn-Out GPU73\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e36_l1_gpu72 [label="MLP-Gate GPU72\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e36_l1_gpu73 [label="MLP-Gate GPU73\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e36_l1_gpu72 [label="MLP-Up GPU72\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e36_l1_gpu73 [label="MLP-Up GPU73\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e36_l1_gpu72 [label="MLP-Down GPU72\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e36_l1_gpu73 [label="MLP-Down GPU73\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e36_l2_gpu72 [label="LayerNorm GPU72\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e36_l2_gpu73 [label="LayerNorm GPU73\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e36_l2_gpu72 [label="Attn-Q GPU72\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e36_l2_gpu73 [label="Attn-Q GPU73\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e36_l2_gpu72 [label="Attn-K/V GPU72\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e36_l2_gpu73 [label="Attn-K/V GPU73\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e36_l2_gpu72 [label="Attn-Out GPU72\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e36_l2_gpu73 [label="Attn-Out GPU73\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e36_l2_gpu72 [label="MLP-Gate GPU72\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e36_l2_gpu73 [label="MLP-Gate GPU73\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e36_l2_gpu72 [label="MLP-Up GPU72\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e36_l2_gpu73 [label="MLP-Up GPU73\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e36_l2_gpu72 [label="MLP-Down GPU72\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e36_l2_gpu73 [label="MLP-Down GPU73\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e36_l3_gpu72 [label="LayerNorm GPU72\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e36_l3_gpu73 [label="LayerNorm GPU73\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e36_l3_gpu72 [label="Attn-Q GPU72\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e36_l3_gpu73 [label="Attn-Q GPU73\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e36_l3_gpu72 [label="Attn-K/V GPU72\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e36_l3_gpu73 [label="Attn-K/V GPU73\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e36_l3_gpu72 [label="Attn-Out GPU72\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e36_l3_gpu73 [label="Attn-Out GPU73\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e36_l3_gpu72 [label="MLP-Gate GPU72\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e36_l3_gpu73 [label="MLP-Gate GPU73\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e36_l3_gpu72 [label="MLP-Up GPU72\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e36_l3_gpu73 [label="MLP-Up GPU73\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e36_l3_gpu72 [label="MLP-Down GPU72\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e36_l3_gpu73 [label="MLP-Down GPU73\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_37 {
			color=red fillcolor=lightgray label="Expert 37" style="rounded,filled"
			attn_norm_s2_e37_l0_gpu74 [label="LayerNorm GPU74\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e37_l0_gpu75 [label="LayerNorm GPU75\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e37_l0_gpu74 [label="Attn-Q GPU74\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e37_l0_gpu75 [label="Attn-Q GPU75\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e37_l0_gpu74 [label="Attn-K/V GPU74\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e37_l0_gpu75 [label="Attn-K/V GPU75\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e37_l0_gpu74 [label="Attn-Out GPU74\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e37_l0_gpu75 [label="Attn-Out GPU75\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e37_l0_gpu74 [label="MLP-Gate GPU74\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e37_l0_gpu75 [label="MLP-Gate GPU75\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e37_l0_gpu74 [label="MLP-Up GPU74\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e37_l0_gpu75 [label="MLP-Up GPU75\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e37_l0_gpu74 [label="MLP-Down GPU74\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e37_l0_gpu75 [label="MLP-Down GPU75\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e37_l1_gpu74 [label="LayerNorm GPU74\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e37_l1_gpu75 [label="LayerNorm GPU75\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e37_l1_gpu74 [label="Attn-Q GPU74\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e37_l1_gpu75 [label="Attn-Q GPU75\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e37_l1_gpu74 [label="Attn-K/V GPU74\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e37_l1_gpu75 [label="Attn-K/V GPU75\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e37_l1_gpu74 [label="Attn-Out GPU74\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e37_l1_gpu75 [label="Attn-Out GPU75\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e37_l1_gpu74 [label="MLP-Gate GPU74\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e37_l1_gpu75 [label="MLP-Gate GPU75\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e37_l1_gpu74 [label="MLP-Up GPU74\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e37_l1_gpu75 [label="MLP-Up GPU75\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e37_l1_gpu74 [label="MLP-Down GPU74\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e37_l1_gpu75 [label="MLP-Down GPU75\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e37_l2_gpu74 [label="LayerNorm GPU74\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e37_l2_gpu75 [label="LayerNorm GPU75\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e37_l2_gpu74 [label="Attn-Q GPU74\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e37_l2_gpu75 [label="Attn-Q GPU75\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e37_l2_gpu74 [label="Attn-K/V GPU74\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e37_l2_gpu75 [label="Attn-K/V GPU75\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e37_l2_gpu74 [label="Attn-Out GPU74\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e37_l2_gpu75 [label="Attn-Out GPU75\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e37_l2_gpu74 [label="MLP-Gate GPU74\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e37_l2_gpu75 [label="MLP-Gate GPU75\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e37_l2_gpu74 [label="MLP-Up GPU74\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e37_l2_gpu75 [label="MLP-Up GPU75\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e37_l2_gpu74 [label="MLP-Down GPU74\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e37_l2_gpu75 [label="MLP-Down GPU75\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e37_l3_gpu74 [label="LayerNorm GPU74\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e37_l3_gpu75 [label="LayerNorm GPU75\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e37_l3_gpu74 [label="Attn-Q GPU74\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e37_l3_gpu75 [label="Attn-Q GPU75\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e37_l3_gpu74 [label="Attn-K/V GPU74\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e37_l3_gpu75 [label="Attn-K/V GPU75\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e37_l3_gpu74 [label="Attn-Out GPU74\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e37_l3_gpu75 [label="Attn-Out GPU75\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e37_l3_gpu74 [label="MLP-Gate GPU74\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e37_l3_gpu75 [label="MLP-Gate GPU75\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e37_l3_gpu74 [label="MLP-Up GPU74\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e37_l3_gpu75 [label="MLP-Up GPU75\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e37_l3_gpu74 [label="MLP-Down GPU74\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e37_l3_gpu75 [label="MLP-Down GPU75\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_38 {
			color=red fillcolor=lightgray label="Expert 38" style="rounded,filled"
			attn_norm_s2_e38_l0_gpu76 [label="LayerNorm GPU76\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e38_l0_gpu77 [label="LayerNorm GPU77\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e38_l0_gpu76 [label="Attn-Q GPU76\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e38_l0_gpu77 [label="Attn-Q GPU77\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e38_l0_gpu76 [label="Attn-K/V GPU76\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e38_l0_gpu77 [label="Attn-K/V GPU77\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e38_l0_gpu76 [label="Attn-Out GPU76\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e38_l0_gpu77 [label="Attn-Out GPU77\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e38_l0_gpu76 [label="MLP-Gate GPU76\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e38_l0_gpu77 [label="MLP-Gate GPU77\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e38_l0_gpu76 [label="MLP-Up GPU76\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e38_l0_gpu77 [label="MLP-Up GPU77\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e38_l0_gpu76 [label="MLP-Down GPU76\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e38_l0_gpu77 [label="MLP-Down GPU77\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e38_l1_gpu76 [label="LayerNorm GPU76\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e38_l1_gpu77 [label="LayerNorm GPU77\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e38_l1_gpu76 [label="Attn-Q GPU76\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e38_l1_gpu77 [label="Attn-Q GPU77\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e38_l1_gpu76 [label="Attn-K/V GPU76\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e38_l1_gpu77 [label="Attn-K/V GPU77\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e38_l1_gpu76 [label="Attn-Out GPU76\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e38_l1_gpu77 [label="Attn-Out GPU77\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e38_l1_gpu76 [label="MLP-Gate GPU76\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e38_l1_gpu77 [label="MLP-Gate GPU77\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e38_l1_gpu76 [label="MLP-Up GPU76\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e38_l1_gpu77 [label="MLP-Up GPU77\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e38_l1_gpu76 [label="MLP-Down GPU76\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e38_l1_gpu77 [label="MLP-Down GPU77\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e38_l2_gpu76 [label="LayerNorm GPU76\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e38_l2_gpu77 [label="LayerNorm GPU77\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e38_l2_gpu76 [label="Attn-Q GPU76\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e38_l2_gpu77 [label="Attn-Q GPU77\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e38_l2_gpu76 [label="Attn-K/V GPU76\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e38_l2_gpu77 [label="Attn-K/V GPU77\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e38_l2_gpu76 [label="Attn-Out GPU76\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e38_l2_gpu77 [label="Attn-Out GPU77\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e38_l2_gpu76 [label="MLP-Gate GPU76\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e38_l2_gpu77 [label="MLP-Gate GPU77\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e38_l2_gpu76 [label="MLP-Up GPU76\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e38_l2_gpu77 [label="MLP-Up GPU77\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e38_l2_gpu76 [label="MLP-Down GPU76\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e38_l2_gpu77 [label="MLP-Down GPU77\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e38_l3_gpu76 [label="LayerNorm GPU76\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e38_l3_gpu77 [label="LayerNorm GPU77\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e38_l3_gpu76 [label="Attn-Q GPU76\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e38_l3_gpu77 [label="Attn-Q GPU77\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e38_l3_gpu76 [label="Attn-K/V GPU76\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e38_l3_gpu77 [label="Attn-K/V GPU77\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e38_l3_gpu76 [label="Attn-Out GPU76\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e38_l3_gpu77 [label="Attn-Out GPU77\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e38_l3_gpu76 [label="MLP-Gate GPU76\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e38_l3_gpu77 [label="MLP-Gate GPU77\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e38_l3_gpu76 [label="MLP-Up GPU76\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e38_l3_gpu77 [label="MLP-Up GPU77\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e38_l3_gpu76 [label="MLP-Down GPU76\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e38_l3_gpu77 [label="MLP-Down GPU77\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_39 {
			color=red fillcolor=lightgray label="Expert 39" style="rounded,filled"
			attn_norm_s2_e39_l0_gpu78 [label="LayerNorm GPU78\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e39_l0_gpu79 [label="LayerNorm GPU79\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e39_l0_gpu78 [label="Attn-Q GPU78\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e39_l0_gpu79 [label="Attn-Q GPU79\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e39_l0_gpu78 [label="Attn-K/V GPU78\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e39_l0_gpu79 [label="Attn-K/V GPU79\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e39_l0_gpu78 [label="Attn-Out GPU78\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e39_l0_gpu79 [label="Attn-Out GPU79\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e39_l0_gpu78 [label="MLP-Gate GPU78\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e39_l0_gpu79 [label="MLP-Gate GPU79\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e39_l0_gpu78 [label="MLP-Up GPU78\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e39_l0_gpu79 [label="MLP-Up GPU79\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e39_l0_gpu78 [label="MLP-Down GPU78\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e39_l0_gpu79 [label="MLP-Down GPU79\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e39_l1_gpu78 [label="LayerNorm GPU78\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e39_l1_gpu79 [label="LayerNorm GPU79\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e39_l1_gpu78 [label="Attn-Q GPU78\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e39_l1_gpu79 [label="Attn-Q GPU79\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e39_l1_gpu78 [label="Attn-K/V GPU78\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e39_l1_gpu79 [label="Attn-K/V GPU79\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e39_l1_gpu78 [label="Attn-Out GPU78\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e39_l1_gpu79 [label="Attn-Out GPU79\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e39_l1_gpu78 [label="MLP-Gate GPU78\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e39_l1_gpu79 [label="MLP-Gate GPU79\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e39_l1_gpu78 [label="MLP-Up GPU78\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e39_l1_gpu79 [label="MLP-Up GPU79\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e39_l1_gpu78 [label="MLP-Down GPU78\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e39_l1_gpu79 [label="MLP-Down GPU79\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e39_l2_gpu78 [label="LayerNorm GPU78\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e39_l2_gpu79 [label="LayerNorm GPU79\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e39_l2_gpu78 [label="Attn-Q GPU78\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e39_l2_gpu79 [label="Attn-Q GPU79\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e39_l2_gpu78 [label="Attn-K/V GPU78\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e39_l2_gpu79 [label="Attn-K/V GPU79\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e39_l2_gpu78 [label="Attn-Out GPU78\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e39_l2_gpu79 [label="Attn-Out GPU79\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e39_l2_gpu78 [label="MLP-Gate GPU78\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e39_l2_gpu79 [label="MLP-Gate GPU79\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e39_l2_gpu78 [label="MLP-Up GPU78\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e39_l2_gpu79 [label="MLP-Up GPU79\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e39_l2_gpu78 [label="MLP-Down GPU78\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e39_l2_gpu79 [label="MLP-Down GPU79\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e39_l3_gpu78 [label="LayerNorm GPU78\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e39_l3_gpu79 [label="LayerNorm GPU79\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e39_l3_gpu78 [label="Attn-Q GPU78\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e39_l3_gpu79 [label="Attn-Q GPU79\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e39_l3_gpu78 [label="Attn-K/V GPU78\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e39_l3_gpu79 [label="Attn-K/V GPU79\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e39_l3_gpu78 [label="Attn-Out GPU78\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e39_l3_gpu79 [label="Attn-Out GPU79\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e39_l3_gpu78 [label="MLP-Gate GPU78\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e39_l3_gpu79 [label="MLP-Gate GPU79\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e39_l3_gpu78 [label="MLP-Up GPU78\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e39_l3_gpu79 [label="MLP-Up GPU79\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e39_l3_gpu78 [label="MLP-Down GPU78\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e39_l3_gpu79 [label="MLP-Down GPU79\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_40 {
			color=red fillcolor=lightgray label="Expert 40" style="rounded,filled"
			attn_norm_s2_e40_l0_gpu80 [label="LayerNorm GPU80\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e40_l0_gpu81 [label="LayerNorm GPU81\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e40_l0_gpu80 [label="Attn-Q GPU80\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e40_l0_gpu81 [label="Attn-Q GPU81\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e40_l0_gpu80 [label="Attn-K/V GPU80\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e40_l0_gpu81 [label="Attn-K/V GPU81\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e40_l0_gpu80 [label="Attn-Out GPU80\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e40_l0_gpu81 [label="Attn-Out GPU81\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e40_l0_gpu80 [label="MLP-Gate GPU80\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e40_l0_gpu81 [label="MLP-Gate GPU81\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e40_l0_gpu80 [label="MLP-Up GPU80\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e40_l0_gpu81 [label="MLP-Up GPU81\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e40_l0_gpu80 [label="MLP-Down GPU80\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e40_l0_gpu81 [label="MLP-Down GPU81\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e40_l1_gpu80 [label="LayerNorm GPU80\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e40_l1_gpu81 [label="LayerNorm GPU81\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e40_l1_gpu80 [label="Attn-Q GPU80\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e40_l1_gpu81 [label="Attn-Q GPU81\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e40_l1_gpu80 [label="Attn-K/V GPU80\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e40_l1_gpu81 [label="Attn-K/V GPU81\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e40_l1_gpu80 [label="Attn-Out GPU80\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e40_l1_gpu81 [label="Attn-Out GPU81\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e40_l1_gpu80 [label="MLP-Gate GPU80\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e40_l1_gpu81 [label="MLP-Gate GPU81\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e40_l1_gpu80 [label="MLP-Up GPU80\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e40_l1_gpu81 [label="MLP-Up GPU81\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e40_l1_gpu80 [label="MLP-Down GPU80\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e40_l1_gpu81 [label="MLP-Down GPU81\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e40_l2_gpu80 [label="LayerNorm GPU80\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e40_l2_gpu81 [label="LayerNorm GPU81\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e40_l2_gpu80 [label="Attn-Q GPU80\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e40_l2_gpu81 [label="Attn-Q GPU81\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e40_l2_gpu80 [label="Attn-K/V GPU80\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e40_l2_gpu81 [label="Attn-K/V GPU81\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e40_l2_gpu80 [label="Attn-Out GPU80\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e40_l2_gpu81 [label="Attn-Out GPU81\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e40_l2_gpu80 [label="MLP-Gate GPU80\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e40_l2_gpu81 [label="MLP-Gate GPU81\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e40_l2_gpu80 [label="MLP-Up GPU80\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e40_l2_gpu81 [label="MLP-Up GPU81\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e40_l2_gpu80 [label="MLP-Down GPU80\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e40_l2_gpu81 [label="MLP-Down GPU81\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e40_l3_gpu80 [label="LayerNorm GPU80\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e40_l3_gpu81 [label="LayerNorm GPU81\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e40_l3_gpu80 [label="Attn-Q GPU80\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e40_l3_gpu81 [label="Attn-Q GPU81\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e40_l3_gpu80 [label="Attn-K/V GPU80\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e40_l3_gpu81 [label="Attn-K/V GPU81\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e40_l3_gpu80 [label="Attn-Out GPU80\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e40_l3_gpu81 [label="Attn-Out GPU81\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e40_l3_gpu80 [label="MLP-Gate GPU80\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e40_l3_gpu81 [label="MLP-Gate GPU81\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e40_l3_gpu80 [label="MLP-Up GPU80\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e40_l3_gpu81 [label="MLP-Up GPU81\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e40_l3_gpu80 [label="MLP-Down GPU80\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e40_l3_gpu81 [label="MLP-Down GPU81\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_41 {
			color=red fillcolor=lightgray label="Expert 41" style="rounded,filled"
			attn_norm_s2_e41_l0_gpu82 [label="LayerNorm GPU82\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e41_l0_gpu83 [label="LayerNorm GPU83\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e41_l0_gpu82 [label="Attn-Q GPU82\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e41_l0_gpu83 [label="Attn-Q GPU83\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e41_l0_gpu82 [label="Attn-K/V GPU82\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e41_l0_gpu83 [label="Attn-K/V GPU83\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e41_l0_gpu82 [label="Attn-Out GPU82\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e41_l0_gpu83 [label="Attn-Out GPU83\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e41_l0_gpu82 [label="MLP-Gate GPU82\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e41_l0_gpu83 [label="MLP-Gate GPU83\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e41_l0_gpu82 [label="MLP-Up GPU82\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e41_l0_gpu83 [label="MLP-Up GPU83\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e41_l0_gpu82 [label="MLP-Down GPU82\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e41_l0_gpu83 [label="MLP-Down GPU83\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e41_l1_gpu82 [label="LayerNorm GPU82\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e41_l1_gpu83 [label="LayerNorm GPU83\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e41_l1_gpu82 [label="Attn-Q GPU82\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e41_l1_gpu83 [label="Attn-Q GPU83\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e41_l1_gpu82 [label="Attn-K/V GPU82\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e41_l1_gpu83 [label="Attn-K/V GPU83\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e41_l1_gpu82 [label="Attn-Out GPU82\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e41_l1_gpu83 [label="Attn-Out GPU83\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e41_l1_gpu82 [label="MLP-Gate GPU82\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e41_l1_gpu83 [label="MLP-Gate GPU83\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e41_l1_gpu82 [label="MLP-Up GPU82\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e41_l1_gpu83 [label="MLP-Up GPU83\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e41_l1_gpu82 [label="MLP-Down GPU82\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e41_l1_gpu83 [label="MLP-Down GPU83\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e41_l2_gpu82 [label="LayerNorm GPU82\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e41_l2_gpu83 [label="LayerNorm GPU83\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e41_l2_gpu82 [label="Attn-Q GPU82\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e41_l2_gpu83 [label="Attn-Q GPU83\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e41_l2_gpu82 [label="Attn-K/V GPU82\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e41_l2_gpu83 [label="Attn-K/V GPU83\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e41_l2_gpu82 [label="Attn-Out GPU82\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e41_l2_gpu83 [label="Attn-Out GPU83\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e41_l2_gpu82 [label="MLP-Gate GPU82\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e41_l2_gpu83 [label="MLP-Gate GPU83\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e41_l2_gpu82 [label="MLP-Up GPU82\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e41_l2_gpu83 [label="MLP-Up GPU83\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e41_l2_gpu82 [label="MLP-Down GPU82\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e41_l2_gpu83 [label="MLP-Down GPU83\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e41_l3_gpu82 [label="LayerNorm GPU82\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e41_l3_gpu83 [label="LayerNorm GPU83\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e41_l3_gpu82 [label="Attn-Q GPU82\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e41_l3_gpu83 [label="Attn-Q GPU83\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e41_l3_gpu82 [label="Attn-K/V GPU82\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e41_l3_gpu83 [label="Attn-K/V GPU83\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e41_l3_gpu82 [label="Attn-Out GPU82\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e41_l3_gpu83 [label="Attn-Out GPU83\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e41_l3_gpu82 [label="MLP-Gate GPU82\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e41_l3_gpu83 [label="MLP-Gate GPU83\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e41_l3_gpu82 [label="MLP-Up GPU82\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e41_l3_gpu83 [label="MLP-Up GPU83\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e41_l3_gpu82 [label="MLP-Down GPU82\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e41_l3_gpu83 [label="MLP-Down GPU83\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_42 {
			color=red fillcolor=lightgray label="Expert 42" style="rounded,filled"
			attn_norm_s2_e42_l0_gpu84 [label="LayerNorm GPU84\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e42_l0_gpu85 [label="LayerNorm GPU85\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e42_l0_gpu84 [label="Attn-Q GPU84\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e42_l0_gpu85 [label="Attn-Q GPU85\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e42_l0_gpu84 [label="Attn-K/V GPU84\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e42_l0_gpu85 [label="Attn-K/V GPU85\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e42_l0_gpu84 [label="Attn-Out GPU84\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e42_l0_gpu85 [label="Attn-Out GPU85\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e42_l0_gpu84 [label="MLP-Gate GPU84\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e42_l0_gpu85 [label="MLP-Gate GPU85\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e42_l0_gpu84 [label="MLP-Up GPU84\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e42_l0_gpu85 [label="MLP-Up GPU85\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e42_l0_gpu84 [label="MLP-Down GPU84\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e42_l0_gpu85 [label="MLP-Down GPU85\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e42_l1_gpu84 [label="LayerNorm GPU84\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e42_l1_gpu85 [label="LayerNorm GPU85\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e42_l1_gpu84 [label="Attn-Q GPU84\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e42_l1_gpu85 [label="Attn-Q GPU85\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e42_l1_gpu84 [label="Attn-K/V GPU84\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e42_l1_gpu85 [label="Attn-K/V GPU85\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e42_l1_gpu84 [label="Attn-Out GPU84\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e42_l1_gpu85 [label="Attn-Out GPU85\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e42_l1_gpu84 [label="MLP-Gate GPU84\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e42_l1_gpu85 [label="MLP-Gate GPU85\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e42_l1_gpu84 [label="MLP-Up GPU84\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e42_l1_gpu85 [label="MLP-Up GPU85\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e42_l1_gpu84 [label="MLP-Down GPU84\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e42_l1_gpu85 [label="MLP-Down GPU85\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e42_l2_gpu84 [label="LayerNorm GPU84\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e42_l2_gpu85 [label="LayerNorm GPU85\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e42_l2_gpu84 [label="Attn-Q GPU84\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e42_l2_gpu85 [label="Attn-Q GPU85\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e42_l2_gpu84 [label="Attn-K/V GPU84\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e42_l2_gpu85 [label="Attn-K/V GPU85\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e42_l2_gpu84 [label="Attn-Out GPU84\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e42_l2_gpu85 [label="Attn-Out GPU85\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e42_l2_gpu84 [label="MLP-Gate GPU84\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e42_l2_gpu85 [label="MLP-Gate GPU85\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e42_l2_gpu84 [label="MLP-Up GPU84\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e42_l2_gpu85 [label="MLP-Up GPU85\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e42_l2_gpu84 [label="MLP-Down GPU84\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e42_l2_gpu85 [label="MLP-Down GPU85\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e42_l3_gpu84 [label="LayerNorm GPU84\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e42_l3_gpu85 [label="LayerNorm GPU85\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e42_l3_gpu84 [label="Attn-Q GPU84\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e42_l3_gpu85 [label="Attn-Q GPU85\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e42_l3_gpu84 [label="Attn-K/V GPU84\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e42_l3_gpu85 [label="Attn-K/V GPU85\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e42_l3_gpu84 [label="Attn-Out GPU84\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e42_l3_gpu85 [label="Attn-Out GPU85\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e42_l3_gpu84 [label="MLP-Gate GPU84\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e42_l3_gpu85 [label="MLP-Gate GPU85\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e42_l3_gpu84 [label="MLP-Up GPU84\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e42_l3_gpu85 [label="MLP-Up GPU85\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e42_l3_gpu84 [label="MLP-Down GPU84\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e42_l3_gpu85 [label="MLP-Down GPU85\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_43 {
			color=red fillcolor=lightgray label="Expert 43" style="rounded,filled"
			attn_norm_s2_e43_l0_gpu86 [label="LayerNorm GPU86\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e43_l0_gpu87 [label="LayerNorm GPU87\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e43_l0_gpu86 [label="Attn-Q GPU86\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e43_l0_gpu87 [label="Attn-Q GPU87\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e43_l0_gpu86 [label="Attn-K/V GPU86\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e43_l0_gpu87 [label="Attn-K/V GPU87\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e43_l0_gpu86 [label="Attn-Out GPU86\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e43_l0_gpu87 [label="Attn-Out GPU87\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e43_l0_gpu86 [label="MLP-Gate GPU86\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e43_l0_gpu87 [label="MLP-Gate GPU87\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e43_l0_gpu86 [label="MLP-Up GPU86\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e43_l0_gpu87 [label="MLP-Up GPU87\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e43_l0_gpu86 [label="MLP-Down GPU86\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e43_l0_gpu87 [label="MLP-Down GPU87\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e43_l1_gpu86 [label="LayerNorm GPU86\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e43_l1_gpu87 [label="LayerNorm GPU87\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e43_l1_gpu86 [label="Attn-Q GPU86\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e43_l1_gpu87 [label="Attn-Q GPU87\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e43_l1_gpu86 [label="Attn-K/V GPU86\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e43_l1_gpu87 [label="Attn-K/V GPU87\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e43_l1_gpu86 [label="Attn-Out GPU86\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e43_l1_gpu87 [label="Attn-Out GPU87\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e43_l1_gpu86 [label="MLP-Gate GPU86\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e43_l1_gpu87 [label="MLP-Gate GPU87\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e43_l1_gpu86 [label="MLP-Up GPU86\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e43_l1_gpu87 [label="MLP-Up GPU87\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e43_l1_gpu86 [label="MLP-Down GPU86\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e43_l1_gpu87 [label="MLP-Down GPU87\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e43_l2_gpu86 [label="LayerNorm GPU86\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e43_l2_gpu87 [label="LayerNorm GPU87\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e43_l2_gpu86 [label="Attn-Q GPU86\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e43_l2_gpu87 [label="Attn-Q GPU87\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e43_l2_gpu86 [label="Attn-K/V GPU86\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e43_l2_gpu87 [label="Attn-K/V GPU87\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e43_l2_gpu86 [label="Attn-Out GPU86\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e43_l2_gpu87 [label="Attn-Out GPU87\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e43_l2_gpu86 [label="MLP-Gate GPU86\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e43_l2_gpu87 [label="MLP-Gate GPU87\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e43_l2_gpu86 [label="MLP-Up GPU86\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e43_l2_gpu87 [label="MLP-Up GPU87\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e43_l2_gpu86 [label="MLP-Down GPU86\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e43_l2_gpu87 [label="MLP-Down GPU87\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e43_l3_gpu86 [label="LayerNorm GPU86\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e43_l3_gpu87 [label="LayerNorm GPU87\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e43_l3_gpu86 [label="Attn-Q GPU86\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e43_l3_gpu87 [label="Attn-Q GPU87\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e43_l3_gpu86 [label="Attn-K/V GPU86\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e43_l3_gpu87 [label="Attn-K/V GPU87\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e43_l3_gpu86 [label="Attn-Out GPU86\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e43_l3_gpu87 [label="Attn-Out GPU87\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e43_l3_gpu86 [label="MLP-Gate GPU86\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e43_l3_gpu87 [label="MLP-Gate GPU87\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e43_l3_gpu86 [label="MLP-Up GPU86\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e43_l3_gpu87 [label="MLP-Up GPU87\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e43_l3_gpu86 [label="MLP-Down GPU86\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e43_l3_gpu87 [label="MLP-Down GPU87\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_44 {
			color=red fillcolor=lightgray label="Expert 44" style="rounded,filled"
			attn_norm_s2_e44_l0_gpu88 [label="LayerNorm GPU88\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e44_l0_gpu89 [label="LayerNorm GPU89\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e44_l0_gpu88 [label="Attn-Q GPU88\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e44_l0_gpu89 [label="Attn-Q GPU89\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e44_l0_gpu88 [label="Attn-K/V GPU88\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e44_l0_gpu89 [label="Attn-K/V GPU89\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e44_l0_gpu88 [label="Attn-Out GPU88\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e44_l0_gpu89 [label="Attn-Out GPU89\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e44_l0_gpu88 [label="MLP-Gate GPU88\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e44_l0_gpu89 [label="MLP-Gate GPU89\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e44_l0_gpu88 [label="MLP-Up GPU88\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e44_l0_gpu89 [label="MLP-Up GPU89\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e44_l0_gpu88 [label="MLP-Down GPU88\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e44_l0_gpu89 [label="MLP-Down GPU89\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e44_l1_gpu88 [label="LayerNorm GPU88\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e44_l1_gpu89 [label="LayerNorm GPU89\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e44_l1_gpu88 [label="Attn-Q GPU88\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e44_l1_gpu89 [label="Attn-Q GPU89\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e44_l1_gpu88 [label="Attn-K/V GPU88\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e44_l1_gpu89 [label="Attn-K/V GPU89\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e44_l1_gpu88 [label="Attn-Out GPU88\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e44_l1_gpu89 [label="Attn-Out GPU89\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e44_l1_gpu88 [label="MLP-Gate GPU88\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e44_l1_gpu89 [label="MLP-Gate GPU89\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e44_l1_gpu88 [label="MLP-Up GPU88\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e44_l1_gpu89 [label="MLP-Up GPU89\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e44_l1_gpu88 [label="MLP-Down GPU88\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e44_l1_gpu89 [label="MLP-Down GPU89\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e44_l2_gpu88 [label="LayerNorm GPU88\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e44_l2_gpu89 [label="LayerNorm GPU89\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e44_l2_gpu88 [label="Attn-Q GPU88\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e44_l2_gpu89 [label="Attn-Q GPU89\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e44_l2_gpu88 [label="Attn-K/V GPU88\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e44_l2_gpu89 [label="Attn-K/V GPU89\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e44_l2_gpu88 [label="Attn-Out GPU88\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e44_l2_gpu89 [label="Attn-Out GPU89\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e44_l2_gpu88 [label="MLP-Gate GPU88\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e44_l2_gpu89 [label="MLP-Gate GPU89\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e44_l2_gpu88 [label="MLP-Up GPU88\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e44_l2_gpu89 [label="MLP-Up GPU89\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e44_l2_gpu88 [label="MLP-Down GPU88\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e44_l2_gpu89 [label="MLP-Down GPU89\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e44_l3_gpu88 [label="LayerNorm GPU88\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e44_l3_gpu89 [label="LayerNorm GPU89\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e44_l3_gpu88 [label="Attn-Q GPU88\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e44_l3_gpu89 [label="Attn-Q GPU89\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e44_l3_gpu88 [label="Attn-K/V GPU88\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e44_l3_gpu89 [label="Attn-K/V GPU89\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e44_l3_gpu88 [label="Attn-Out GPU88\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e44_l3_gpu89 [label="Attn-Out GPU89\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e44_l3_gpu88 [label="MLP-Gate GPU88\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e44_l3_gpu89 [label="MLP-Gate GPU89\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e44_l3_gpu88 [label="MLP-Up GPU88\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e44_l3_gpu89 [label="MLP-Up GPU89\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e44_l3_gpu88 [label="MLP-Down GPU88\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e44_l3_gpu89 [label="MLP-Down GPU89\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_45 {
			color=red fillcolor=lightgray label="Expert 45" style="rounded,filled"
			attn_norm_s2_e45_l0_gpu90 [label="LayerNorm GPU90\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e45_l0_gpu91 [label="LayerNorm GPU91\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e45_l0_gpu90 [label="Attn-Q GPU90\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e45_l0_gpu91 [label="Attn-Q GPU91\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e45_l0_gpu90 [label="Attn-K/V GPU90\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e45_l0_gpu91 [label="Attn-K/V GPU91\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e45_l0_gpu90 [label="Attn-Out GPU90\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e45_l0_gpu91 [label="Attn-Out GPU91\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e45_l0_gpu90 [label="MLP-Gate GPU90\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e45_l0_gpu91 [label="MLP-Gate GPU91\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e45_l0_gpu90 [label="MLP-Up GPU90\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e45_l0_gpu91 [label="MLP-Up GPU91\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e45_l0_gpu90 [label="MLP-Down GPU90\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e45_l0_gpu91 [label="MLP-Down GPU91\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e45_l1_gpu90 [label="LayerNorm GPU90\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e45_l1_gpu91 [label="LayerNorm GPU91\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e45_l1_gpu90 [label="Attn-Q GPU90\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e45_l1_gpu91 [label="Attn-Q GPU91\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e45_l1_gpu90 [label="Attn-K/V GPU90\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e45_l1_gpu91 [label="Attn-K/V GPU91\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e45_l1_gpu90 [label="Attn-Out GPU90\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e45_l1_gpu91 [label="Attn-Out GPU91\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e45_l1_gpu90 [label="MLP-Gate GPU90\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e45_l1_gpu91 [label="MLP-Gate GPU91\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e45_l1_gpu90 [label="MLP-Up GPU90\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e45_l1_gpu91 [label="MLP-Up GPU91\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e45_l1_gpu90 [label="MLP-Down GPU90\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e45_l1_gpu91 [label="MLP-Down GPU91\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e45_l2_gpu90 [label="LayerNorm GPU90\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e45_l2_gpu91 [label="LayerNorm GPU91\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e45_l2_gpu90 [label="Attn-Q GPU90\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e45_l2_gpu91 [label="Attn-Q GPU91\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e45_l2_gpu90 [label="Attn-K/V GPU90\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e45_l2_gpu91 [label="Attn-K/V GPU91\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e45_l2_gpu90 [label="Attn-Out GPU90\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e45_l2_gpu91 [label="Attn-Out GPU91\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e45_l2_gpu90 [label="MLP-Gate GPU90\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e45_l2_gpu91 [label="MLP-Gate GPU91\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e45_l2_gpu90 [label="MLP-Up GPU90\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e45_l2_gpu91 [label="MLP-Up GPU91\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e45_l2_gpu90 [label="MLP-Down GPU90\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e45_l2_gpu91 [label="MLP-Down GPU91\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e45_l3_gpu90 [label="LayerNorm GPU90\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e45_l3_gpu91 [label="LayerNorm GPU91\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e45_l3_gpu90 [label="Attn-Q GPU90\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e45_l3_gpu91 [label="Attn-Q GPU91\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e45_l3_gpu90 [label="Attn-K/V GPU90\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e45_l3_gpu91 [label="Attn-K/V GPU91\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e45_l3_gpu90 [label="Attn-Out GPU90\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e45_l3_gpu91 [label="Attn-Out GPU91\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e45_l3_gpu90 [label="MLP-Gate GPU90\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e45_l3_gpu91 [label="MLP-Gate GPU91\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e45_l3_gpu90 [label="MLP-Up GPU90\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e45_l3_gpu91 [label="MLP-Up GPU91\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e45_l3_gpu90 [label="MLP-Down GPU90\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e45_l3_gpu91 [label="MLP-Down GPU91\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_46 {
			color=red fillcolor=lightgray label="Expert 46" style="rounded,filled"
			attn_norm_s2_e46_l0_gpu92 [label="LayerNorm GPU92\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e46_l0_gpu93 [label="LayerNorm GPU93\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e46_l0_gpu92 [label="Attn-Q GPU92\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e46_l0_gpu93 [label="Attn-Q GPU93\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e46_l0_gpu92 [label="Attn-K/V GPU92\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e46_l0_gpu93 [label="Attn-K/V GPU93\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e46_l0_gpu92 [label="Attn-Out GPU92\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e46_l0_gpu93 [label="Attn-Out GPU93\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e46_l0_gpu92 [label="MLP-Gate GPU92\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e46_l0_gpu93 [label="MLP-Gate GPU93\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e46_l0_gpu92 [label="MLP-Up GPU92\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e46_l0_gpu93 [label="MLP-Up GPU93\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e46_l0_gpu92 [label="MLP-Down GPU92\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e46_l0_gpu93 [label="MLP-Down GPU93\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e46_l1_gpu92 [label="LayerNorm GPU92\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e46_l1_gpu93 [label="LayerNorm GPU93\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e46_l1_gpu92 [label="Attn-Q GPU92\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e46_l1_gpu93 [label="Attn-Q GPU93\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e46_l1_gpu92 [label="Attn-K/V GPU92\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e46_l1_gpu93 [label="Attn-K/V GPU93\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e46_l1_gpu92 [label="Attn-Out GPU92\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e46_l1_gpu93 [label="Attn-Out GPU93\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e46_l1_gpu92 [label="MLP-Gate GPU92\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e46_l1_gpu93 [label="MLP-Gate GPU93\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e46_l1_gpu92 [label="MLP-Up GPU92\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e46_l1_gpu93 [label="MLP-Up GPU93\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e46_l1_gpu92 [label="MLP-Down GPU92\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e46_l1_gpu93 [label="MLP-Down GPU93\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e46_l2_gpu92 [label="LayerNorm GPU92\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e46_l2_gpu93 [label="LayerNorm GPU93\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e46_l2_gpu92 [label="Attn-Q GPU92\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e46_l2_gpu93 [label="Attn-Q GPU93\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e46_l2_gpu92 [label="Attn-K/V GPU92\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e46_l2_gpu93 [label="Attn-K/V GPU93\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e46_l2_gpu92 [label="Attn-Out GPU92\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e46_l2_gpu93 [label="Attn-Out GPU93\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e46_l2_gpu92 [label="MLP-Gate GPU92\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e46_l2_gpu93 [label="MLP-Gate GPU93\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e46_l2_gpu92 [label="MLP-Up GPU92\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e46_l2_gpu93 [label="MLP-Up GPU93\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e46_l2_gpu92 [label="MLP-Down GPU92\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e46_l2_gpu93 [label="MLP-Down GPU93\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e46_l3_gpu92 [label="LayerNorm GPU92\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e46_l3_gpu93 [label="LayerNorm GPU93\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e46_l3_gpu92 [label="Attn-Q GPU92\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e46_l3_gpu93 [label="Attn-Q GPU93\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e46_l3_gpu92 [label="Attn-K/V GPU92\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e46_l3_gpu93 [label="Attn-K/V GPU93\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e46_l3_gpu92 [label="Attn-Out GPU92\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e46_l3_gpu93 [label="Attn-Out GPU93\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e46_l3_gpu92 [label="MLP-Gate GPU92\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e46_l3_gpu93 [label="MLP-Gate GPU93\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e46_l3_gpu92 [label="MLP-Up GPU92\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e46_l3_gpu93 [label="MLP-Up GPU93\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e46_l3_gpu92 [label="MLP-Down GPU92\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e46_l3_gpu93 [label="MLP-Down GPU93\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_47 {
			color=red fillcolor=lightgray label="Expert 47" style="rounded,filled"
			attn_norm_s2_e47_l0_gpu94 [label="LayerNorm GPU94\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e47_l0_gpu95 [label="LayerNorm GPU95\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e47_l0_gpu94 [label="Attn-Q GPU94\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e47_l0_gpu95 [label="Attn-Q GPU95\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e47_l0_gpu94 [label="Attn-K/V GPU94\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e47_l0_gpu95 [label="Attn-K/V GPU95\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e47_l0_gpu94 [label="Attn-Out GPU94\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e47_l0_gpu95 [label="Attn-Out GPU95\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e47_l0_gpu94 [label="MLP-Gate GPU94\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e47_l0_gpu95 [label="MLP-Gate GPU95\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e47_l0_gpu94 [label="MLP-Up GPU94\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e47_l0_gpu95 [label="MLP-Up GPU95\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e47_l0_gpu94 [label="MLP-Down GPU94\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e47_l0_gpu95 [label="MLP-Down GPU95\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e47_l1_gpu94 [label="LayerNorm GPU94\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e47_l1_gpu95 [label="LayerNorm GPU95\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e47_l1_gpu94 [label="Attn-Q GPU94\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e47_l1_gpu95 [label="Attn-Q GPU95\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e47_l1_gpu94 [label="Attn-K/V GPU94\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e47_l1_gpu95 [label="Attn-K/V GPU95\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e47_l1_gpu94 [label="Attn-Out GPU94\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e47_l1_gpu95 [label="Attn-Out GPU95\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e47_l1_gpu94 [label="MLP-Gate GPU94\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e47_l1_gpu95 [label="MLP-Gate GPU95\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e47_l1_gpu94 [label="MLP-Up GPU94\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e47_l1_gpu95 [label="MLP-Up GPU95\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e47_l1_gpu94 [label="MLP-Down GPU94\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e47_l1_gpu95 [label="MLP-Down GPU95\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e47_l2_gpu94 [label="LayerNorm GPU94\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e47_l2_gpu95 [label="LayerNorm GPU95\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e47_l2_gpu94 [label="Attn-Q GPU94\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e47_l2_gpu95 [label="Attn-Q GPU95\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e47_l2_gpu94 [label="Attn-K/V GPU94\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e47_l2_gpu95 [label="Attn-K/V GPU95\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e47_l2_gpu94 [label="Attn-Out GPU94\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e47_l2_gpu95 [label="Attn-Out GPU95\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e47_l2_gpu94 [label="MLP-Gate GPU94\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e47_l2_gpu95 [label="MLP-Gate GPU95\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e47_l2_gpu94 [label="MLP-Up GPU94\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e47_l2_gpu95 [label="MLP-Up GPU95\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e47_l2_gpu94 [label="MLP-Down GPU94\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e47_l2_gpu95 [label="MLP-Down GPU95\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s2_e47_l3_gpu94 [label="LayerNorm GPU94\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s2_e47_l3_gpu95 [label="LayerNorm GPU95\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s2_e47_l3_gpu94 [label="Attn-Q GPU94\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s2_e47_l3_gpu95 [label="Attn-Q GPU95\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e47_l3_gpu94 [label="Attn-K/V GPU94\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s2_e47_l3_gpu95 [label="Attn-K/V GPU95\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s2_e47_l3_gpu94 [label="Attn-Out GPU94\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s2_e47_l3_gpu95 [label="Attn-Out GPU95\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s2_e47_l3_gpu94 [label="MLP-Gate GPU94\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s2_e47_l3_gpu95 [label="MLP-Gate GPU95\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e47_l3_gpu94 [label="MLP-Up GPU94\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s2_e47_l3_gpu95 [label="MLP-Up GPU95\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s2_e47_l3_gpu94 [label="MLP-Down GPU94\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s2_e47_l3_gpu95 [label="MLP-Down GPU95\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
	}
	subgraph cluster_stage_3 {
		color=blue fillcolor=lightyellow label="Pipeline Stage 3 (Layers 12-15)" style="rounded,filled"
		subgraph cluster_expert_48 {
			color=red fillcolor=lightgray label="Expert 48" style="rounded,filled"
			attn_norm_s3_e48_l0_gpu96 [label="LayerNorm GPU96\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e48_l0_gpu97 [label="LayerNorm GPU97\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e48_l0_gpu96 [label="Attn-Q GPU96\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e48_l0_gpu97 [label="Attn-Q GPU97\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e48_l0_gpu96 [label="Attn-K/V GPU96\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e48_l0_gpu97 [label="Attn-K/V GPU97\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e48_l0_gpu96 [label="Attn-Out GPU96\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e48_l0_gpu97 [label="Attn-Out GPU97\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e48_l0_gpu96 [label="MLP-Gate GPU96\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e48_l0_gpu97 [label="MLP-Gate GPU97\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e48_l0_gpu96 [label="MLP-Up GPU96\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e48_l0_gpu97 [label="MLP-Up GPU97\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e48_l0_gpu96 [label="MLP-Down GPU96\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e48_l0_gpu97 [label="MLP-Down GPU97\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e48_l1_gpu96 [label="LayerNorm GPU96\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e48_l1_gpu97 [label="LayerNorm GPU97\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e48_l1_gpu96 [label="Attn-Q GPU96\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e48_l1_gpu97 [label="Attn-Q GPU97\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e48_l1_gpu96 [label="Attn-K/V GPU96\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e48_l1_gpu97 [label="Attn-K/V GPU97\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e48_l1_gpu96 [label="Attn-Out GPU96\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e48_l1_gpu97 [label="Attn-Out GPU97\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e48_l1_gpu96 [label="MLP-Gate GPU96\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e48_l1_gpu97 [label="MLP-Gate GPU97\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e48_l1_gpu96 [label="MLP-Up GPU96\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e48_l1_gpu97 [label="MLP-Up GPU97\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e48_l1_gpu96 [label="MLP-Down GPU96\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e48_l1_gpu97 [label="MLP-Down GPU97\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e48_l2_gpu96 [label="LayerNorm GPU96\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e48_l2_gpu97 [label="LayerNorm GPU97\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e48_l2_gpu96 [label="Attn-Q GPU96\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e48_l2_gpu97 [label="Attn-Q GPU97\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e48_l2_gpu96 [label="Attn-K/V GPU96\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e48_l2_gpu97 [label="Attn-K/V GPU97\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e48_l2_gpu96 [label="Attn-Out GPU96\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e48_l2_gpu97 [label="Attn-Out GPU97\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e48_l2_gpu96 [label="MLP-Gate GPU96\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e48_l2_gpu97 [label="MLP-Gate GPU97\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e48_l2_gpu96 [label="MLP-Up GPU96\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e48_l2_gpu97 [label="MLP-Up GPU97\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e48_l2_gpu96 [label="MLP-Down GPU96\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e48_l2_gpu97 [label="MLP-Down GPU97\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e48_l3_gpu96 [label="LayerNorm GPU96\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e48_l3_gpu97 [label="LayerNorm GPU97\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e48_l3_gpu96 [label="Attn-Q GPU96\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e48_l3_gpu97 [label="Attn-Q GPU97\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e48_l3_gpu96 [label="Attn-K/V GPU96\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e48_l3_gpu97 [label="Attn-K/V GPU97\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e48_l3_gpu96 [label="Attn-Out GPU96\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e48_l3_gpu97 [label="Attn-Out GPU97\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e48_l3_gpu96 [label="MLP-Gate GPU96\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e48_l3_gpu97 [label="MLP-Gate GPU97\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e48_l3_gpu96 [label="MLP-Up GPU96\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e48_l3_gpu97 [label="MLP-Up GPU97\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e48_l3_gpu96 [label="MLP-Down GPU96\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e48_l3_gpu97 [label="MLP-Down GPU97\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_49 {
			color=red fillcolor=lightgray label="Expert 49" style="rounded,filled"
			attn_norm_s3_e49_l0_gpu98 [label="LayerNorm GPU98\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e49_l0_gpu99 [label="LayerNorm GPU99\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e49_l0_gpu98 [label="Attn-Q GPU98\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e49_l0_gpu99 [label="Attn-Q GPU99\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e49_l0_gpu98 [label="Attn-K/V GPU98\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e49_l0_gpu99 [label="Attn-K/V GPU99\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e49_l0_gpu98 [label="Attn-Out GPU98\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e49_l0_gpu99 [label="Attn-Out GPU99\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e49_l0_gpu98 [label="MLP-Gate GPU98\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e49_l0_gpu99 [label="MLP-Gate GPU99\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e49_l0_gpu98 [label="MLP-Up GPU98\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e49_l0_gpu99 [label="MLP-Up GPU99\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e49_l0_gpu98 [label="MLP-Down GPU98\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e49_l0_gpu99 [label="MLP-Down GPU99\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e49_l1_gpu98 [label="LayerNorm GPU98\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e49_l1_gpu99 [label="LayerNorm GPU99\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e49_l1_gpu98 [label="Attn-Q GPU98\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e49_l1_gpu99 [label="Attn-Q GPU99\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e49_l1_gpu98 [label="Attn-K/V GPU98\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e49_l1_gpu99 [label="Attn-K/V GPU99\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e49_l1_gpu98 [label="Attn-Out GPU98\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e49_l1_gpu99 [label="Attn-Out GPU99\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e49_l1_gpu98 [label="MLP-Gate GPU98\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e49_l1_gpu99 [label="MLP-Gate GPU99\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e49_l1_gpu98 [label="MLP-Up GPU98\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e49_l1_gpu99 [label="MLP-Up GPU99\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e49_l1_gpu98 [label="MLP-Down GPU98\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e49_l1_gpu99 [label="MLP-Down GPU99\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e49_l2_gpu98 [label="LayerNorm GPU98\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e49_l2_gpu99 [label="LayerNorm GPU99\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e49_l2_gpu98 [label="Attn-Q GPU98\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e49_l2_gpu99 [label="Attn-Q GPU99\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e49_l2_gpu98 [label="Attn-K/V GPU98\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e49_l2_gpu99 [label="Attn-K/V GPU99\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e49_l2_gpu98 [label="Attn-Out GPU98\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e49_l2_gpu99 [label="Attn-Out GPU99\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e49_l2_gpu98 [label="MLP-Gate GPU98\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e49_l2_gpu99 [label="MLP-Gate GPU99\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e49_l2_gpu98 [label="MLP-Up GPU98\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e49_l2_gpu99 [label="MLP-Up GPU99\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e49_l2_gpu98 [label="MLP-Down GPU98\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e49_l2_gpu99 [label="MLP-Down GPU99\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e49_l3_gpu98 [label="LayerNorm GPU98\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e49_l3_gpu99 [label="LayerNorm GPU99\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e49_l3_gpu98 [label="Attn-Q GPU98\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e49_l3_gpu99 [label="Attn-Q GPU99\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e49_l3_gpu98 [label="Attn-K/V GPU98\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e49_l3_gpu99 [label="Attn-K/V GPU99\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e49_l3_gpu98 [label="Attn-Out GPU98\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e49_l3_gpu99 [label="Attn-Out GPU99\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e49_l3_gpu98 [label="MLP-Gate GPU98\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e49_l3_gpu99 [label="MLP-Gate GPU99\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e49_l3_gpu98 [label="MLP-Up GPU98\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e49_l3_gpu99 [label="MLP-Up GPU99\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e49_l3_gpu98 [label="MLP-Down GPU98\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e49_l3_gpu99 [label="MLP-Down GPU99\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_50 {
			color=red fillcolor=lightgray label="Expert 50" style="rounded,filled"
			attn_norm_s3_e50_l0_gpu100 [label="LayerNorm GPU100\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e50_l0_gpu101 [label="LayerNorm GPU101\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e50_l0_gpu100 [label="Attn-Q GPU100\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e50_l0_gpu101 [label="Attn-Q GPU101\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e50_l0_gpu100 [label="Attn-K/V GPU100\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e50_l0_gpu101 [label="Attn-K/V GPU101\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e50_l0_gpu100 [label="Attn-Out GPU100\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e50_l0_gpu101 [label="Attn-Out GPU101\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e50_l0_gpu100 [label="MLP-Gate GPU100\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e50_l0_gpu101 [label="MLP-Gate GPU101\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e50_l0_gpu100 [label="MLP-Up GPU100\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e50_l0_gpu101 [label="MLP-Up GPU101\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e50_l0_gpu100 [label="MLP-Down GPU100\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e50_l0_gpu101 [label="MLP-Down GPU101\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e50_l1_gpu100 [label="LayerNorm GPU100\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e50_l1_gpu101 [label="LayerNorm GPU101\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e50_l1_gpu100 [label="Attn-Q GPU100\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e50_l1_gpu101 [label="Attn-Q GPU101\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e50_l1_gpu100 [label="Attn-K/V GPU100\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e50_l1_gpu101 [label="Attn-K/V GPU101\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e50_l1_gpu100 [label="Attn-Out GPU100\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e50_l1_gpu101 [label="Attn-Out GPU101\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e50_l1_gpu100 [label="MLP-Gate GPU100\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e50_l1_gpu101 [label="MLP-Gate GPU101\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e50_l1_gpu100 [label="MLP-Up GPU100\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e50_l1_gpu101 [label="MLP-Up GPU101\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e50_l1_gpu100 [label="MLP-Down GPU100\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e50_l1_gpu101 [label="MLP-Down GPU101\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e50_l2_gpu100 [label="LayerNorm GPU100\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e50_l2_gpu101 [label="LayerNorm GPU101\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e50_l2_gpu100 [label="Attn-Q GPU100\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e50_l2_gpu101 [label="Attn-Q GPU101\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e50_l2_gpu100 [label="Attn-K/V GPU100\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e50_l2_gpu101 [label="Attn-K/V GPU101\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e50_l2_gpu100 [label="Attn-Out GPU100\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e50_l2_gpu101 [label="Attn-Out GPU101\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e50_l2_gpu100 [label="MLP-Gate GPU100\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e50_l2_gpu101 [label="MLP-Gate GPU101\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e50_l2_gpu100 [label="MLP-Up GPU100\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e50_l2_gpu101 [label="MLP-Up GPU101\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e50_l2_gpu100 [label="MLP-Down GPU100\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e50_l2_gpu101 [label="MLP-Down GPU101\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e50_l3_gpu100 [label="LayerNorm GPU100\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e50_l3_gpu101 [label="LayerNorm GPU101\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e50_l3_gpu100 [label="Attn-Q GPU100\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e50_l3_gpu101 [label="Attn-Q GPU101\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e50_l3_gpu100 [label="Attn-K/V GPU100\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e50_l3_gpu101 [label="Attn-K/V GPU101\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e50_l3_gpu100 [label="Attn-Out GPU100\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e50_l3_gpu101 [label="Attn-Out GPU101\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e50_l3_gpu100 [label="MLP-Gate GPU100\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e50_l3_gpu101 [label="MLP-Gate GPU101\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e50_l3_gpu100 [label="MLP-Up GPU100\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e50_l3_gpu101 [label="MLP-Up GPU101\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e50_l3_gpu100 [label="MLP-Down GPU100\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e50_l3_gpu101 [label="MLP-Down GPU101\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_51 {
			color=red fillcolor=lightgray label="Expert 51" style="rounded,filled"
			attn_norm_s3_e51_l0_gpu102 [label="LayerNorm GPU102\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e51_l0_gpu103 [label="LayerNorm GPU103\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e51_l0_gpu102 [label="Attn-Q GPU102\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e51_l0_gpu103 [label="Attn-Q GPU103\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e51_l0_gpu102 [label="Attn-K/V GPU102\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e51_l0_gpu103 [label="Attn-K/V GPU103\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e51_l0_gpu102 [label="Attn-Out GPU102\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e51_l0_gpu103 [label="Attn-Out GPU103\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e51_l0_gpu102 [label="MLP-Gate GPU102\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e51_l0_gpu103 [label="MLP-Gate GPU103\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e51_l0_gpu102 [label="MLP-Up GPU102\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e51_l0_gpu103 [label="MLP-Up GPU103\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e51_l0_gpu102 [label="MLP-Down GPU102\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e51_l0_gpu103 [label="MLP-Down GPU103\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e51_l1_gpu102 [label="LayerNorm GPU102\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e51_l1_gpu103 [label="LayerNorm GPU103\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e51_l1_gpu102 [label="Attn-Q GPU102\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e51_l1_gpu103 [label="Attn-Q GPU103\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e51_l1_gpu102 [label="Attn-K/V GPU102\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e51_l1_gpu103 [label="Attn-K/V GPU103\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e51_l1_gpu102 [label="Attn-Out GPU102\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e51_l1_gpu103 [label="Attn-Out GPU103\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e51_l1_gpu102 [label="MLP-Gate GPU102\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e51_l1_gpu103 [label="MLP-Gate GPU103\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e51_l1_gpu102 [label="MLP-Up GPU102\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e51_l1_gpu103 [label="MLP-Up GPU103\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e51_l1_gpu102 [label="MLP-Down GPU102\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e51_l1_gpu103 [label="MLP-Down GPU103\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e51_l2_gpu102 [label="LayerNorm GPU102\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e51_l2_gpu103 [label="LayerNorm GPU103\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e51_l2_gpu102 [label="Attn-Q GPU102\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e51_l2_gpu103 [label="Attn-Q GPU103\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e51_l2_gpu102 [label="Attn-K/V GPU102\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e51_l2_gpu103 [label="Attn-K/V GPU103\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e51_l2_gpu102 [label="Attn-Out GPU102\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e51_l2_gpu103 [label="Attn-Out GPU103\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e51_l2_gpu102 [label="MLP-Gate GPU102\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e51_l2_gpu103 [label="MLP-Gate GPU103\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e51_l2_gpu102 [label="MLP-Up GPU102\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e51_l2_gpu103 [label="MLP-Up GPU103\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e51_l2_gpu102 [label="MLP-Down GPU102\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e51_l2_gpu103 [label="MLP-Down GPU103\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e51_l3_gpu102 [label="LayerNorm GPU102\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e51_l3_gpu103 [label="LayerNorm GPU103\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e51_l3_gpu102 [label="Attn-Q GPU102\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e51_l3_gpu103 [label="Attn-Q GPU103\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e51_l3_gpu102 [label="Attn-K/V GPU102\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e51_l3_gpu103 [label="Attn-K/V GPU103\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e51_l3_gpu102 [label="Attn-Out GPU102\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e51_l3_gpu103 [label="Attn-Out GPU103\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e51_l3_gpu102 [label="MLP-Gate GPU102\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e51_l3_gpu103 [label="MLP-Gate GPU103\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e51_l3_gpu102 [label="MLP-Up GPU102\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e51_l3_gpu103 [label="MLP-Up GPU103\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e51_l3_gpu102 [label="MLP-Down GPU102\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e51_l3_gpu103 [label="MLP-Down GPU103\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_52 {
			color=red fillcolor=lightgray label="Expert 52" style="rounded,filled"
			attn_norm_s3_e52_l0_gpu104 [label="LayerNorm GPU104\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e52_l0_gpu105 [label="LayerNorm GPU105\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e52_l0_gpu104 [label="Attn-Q GPU104\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e52_l0_gpu105 [label="Attn-Q GPU105\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e52_l0_gpu104 [label="Attn-K/V GPU104\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e52_l0_gpu105 [label="Attn-K/V GPU105\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e52_l0_gpu104 [label="Attn-Out GPU104\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e52_l0_gpu105 [label="Attn-Out GPU105\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e52_l0_gpu104 [label="MLP-Gate GPU104\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e52_l0_gpu105 [label="MLP-Gate GPU105\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e52_l0_gpu104 [label="MLP-Up GPU104\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e52_l0_gpu105 [label="MLP-Up GPU105\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e52_l0_gpu104 [label="MLP-Down GPU104\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e52_l0_gpu105 [label="MLP-Down GPU105\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e52_l1_gpu104 [label="LayerNorm GPU104\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e52_l1_gpu105 [label="LayerNorm GPU105\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e52_l1_gpu104 [label="Attn-Q GPU104\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e52_l1_gpu105 [label="Attn-Q GPU105\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e52_l1_gpu104 [label="Attn-K/V GPU104\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e52_l1_gpu105 [label="Attn-K/V GPU105\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e52_l1_gpu104 [label="Attn-Out GPU104\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e52_l1_gpu105 [label="Attn-Out GPU105\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e52_l1_gpu104 [label="MLP-Gate GPU104\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e52_l1_gpu105 [label="MLP-Gate GPU105\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e52_l1_gpu104 [label="MLP-Up GPU104\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e52_l1_gpu105 [label="MLP-Up GPU105\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e52_l1_gpu104 [label="MLP-Down GPU104\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e52_l1_gpu105 [label="MLP-Down GPU105\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e52_l2_gpu104 [label="LayerNorm GPU104\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e52_l2_gpu105 [label="LayerNorm GPU105\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e52_l2_gpu104 [label="Attn-Q GPU104\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e52_l2_gpu105 [label="Attn-Q GPU105\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e52_l2_gpu104 [label="Attn-K/V GPU104\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e52_l2_gpu105 [label="Attn-K/V GPU105\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e52_l2_gpu104 [label="Attn-Out GPU104\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e52_l2_gpu105 [label="Attn-Out GPU105\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e52_l2_gpu104 [label="MLP-Gate GPU104\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e52_l2_gpu105 [label="MLP-Gate GPU105\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e52_l2_gpu104 [label="MLP-Up GPU104\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e52_l2_gpu105 [label="MLP-Up GPU105\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e52_l2_gpu104 [label="MLP-Down GPU104\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e52_l2_gpu105 [label="MLP-Down GPU105\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e52_l3_gpu104 [label="LayerNorm GPU104\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e52_l3_gpu105 [label="LayerNorm GPU105\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e52_l3_gpu104 [label="Attn-Q GPU104\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e52_l3_gpu105 [label="Attn-Q GPU105\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e52_l3_gpu104 [label="Attn-K/V GPU104\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e52_l3_gpu105 [label="Attn-K/V GPU105\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e52_l3_gpu104 [label="Attn-Out GPU104\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e52_l3_gpu105 [label="Attn-Out GPU105\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e52_l3_gpu104 [label="MLP-Gate GPU104\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e52_l3_gpu105 [label="MLP-Gate GPU105\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e52_l3_gpu104 [label="MLP-Up GPU104\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e52_l3_gpu105 [label="MLP-Up GPU105\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e52_l3_gpu104 [label="MLP-Down GPU104\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e52_l3_gpu105 [label="MLP-Down GPU105\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_53 {
			color=red fillcolor=lightgray label="Expert 53" style="rounded,filled"
			attn_norm_s3_e53_l0_gpu106 [label="LayerNorm GPU106\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e53_l0_gpu107 [label="LayerNorm GPU107\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e53_l0_gpu106 [label="Attn-Q GPU106\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e53_l0_gpu107 [label="Attn-Q GPU107\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e53_l0_gpu106 [label="Attn-K/V GPU106\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e53_l0_gpu107 [label="Attn-K/V GPU107\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e53_l0_gpu106 [label="Attn-Out GPU106\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e53_l0_gpu107 [label="Attn-Out GPU107\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e53_l0_gpu106 [label="MLP-Gate GPU106\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e53_l0_gpu107 [label="MLP-Gate GPU107\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e53_l0_gpu106 [label="MLP-Up GPU106\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e53_l0_gpu107 [label="MLP-Up GPU107\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e53_l0_gpu106 [label="MLP-Down GPU106\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e53_l0_gpu107 [label="MLP-Down GPU107\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e53_l1_gpu106 [label="LayerNorm GPU106\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e53_l1_gpu107 [label="LayerNorm GPU107\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e53_l1_gpu106 [label="Attn-Q GPU106\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e53_l1_gpu107 [label="Attn-Q GPU107\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e53_l1_gpu106 [label="Attn-K/V GPU106\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e53_l1_gpu107 [label="Attn-K/V GPU107\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e53_l1_gpu106 [label="Attn-Out GPU106\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e53_l1_gpu107 [label="Attn-Out GPU107\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e53_l1_gpu106 [label="MLP-Gate GPU106\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e53_l1_gpu107 [label="MLP-Gate GPU107\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e53_l1_gpu106 [label="MLP-Up GPU106\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e53_l1_gpu107 [label="MLP-Up GPU107\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e53_l1_gpu106 [label="MLP-Down GPU106\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e53_l1_gpu107 [label="MLP-Down GPU107\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e53_l2_gpu106 [label="LayerNorm GPU106\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e53_l2_gpu107 [label="LayerNorm GPU107\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e53_l2_gpu106 [label="Attn-Q GPU106\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e53_l2_gpu107 [label="Attn-Q GPU107\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e53_l2_gpu106 [label="Attn-K/V GPU106\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e53_l2_gpu107 [label="Attn-K/V GPU107\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e53_l2_gpu106 [label="Attn-Out GPU106\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e53_l2_gpu107 [label="Attn-Out GPU107\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e53_l2_gpu106 [label="MLP-Gate GPU106\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e53_l2_gpu107 [label="MLP-Gate GPU107\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e53_l2_gpu106 [label="MLP-Up GPU106\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e53_l2_gpu107 [label="MLP-Up GPU107\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e53_l2_gpu106 [label="MLP-Down GPU106\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e53_l2_gpu107 [label="MLP-Down GPU107\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e53_l3_gpu106 [label="LayerNorm GPU106\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e53_l3_gpu107 [label="LayerNorm GPU107\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e53_l3_gpu106 [label="Attn-Q GPU106\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e53_l3_gpu107 [label="Attn-Q GPU107\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e53_l3_gpu106 [label="Attn-K/V GPU106\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e53_l3_gpu107 [label="Attn-K/V GPU107\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e53_l3_gpu106 [label="Attn-Out GPU106\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e53_l3_gpu107 [label="Attn-Out GPU107\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e53_l3_gpu106 [label="MLP-Gate GPU106\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e53_l3_gpu107 [label="MLP-Gate GPU107\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e53_l3_gpu106 [label="MLP-Up GPU106\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e53_l3_gpu107 [label="MLP-Up GPU107\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e53_l3_gpu106 [label="MLP-Down GPU106\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e53_l3_gpu107 [label="MLP-Down GPU107\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_54 {
			color=red fillcolor=lightgray label="Expert 54" style="rounded,filled"
			attn_norm_s3_e54_l0_gpu108 [label="LayerNorm GPU108\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e54_l0_gpu109 [label="LayerNorm GPU109\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e54_l0_gpu108 [label="Attn-Q GPU108\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e54_l0_gpu109 [label="Attn-Q GPU109\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e54_l0_gpu108 [label="Attn-K/V GPU108\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e54_l0_gpu109 [label="Attn-K/V GPU109\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e54_l0_gpu108 [label="Attn-Out GPU108\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e54_l0_gpu109 [label="Attn-Out GPU109\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e54_l0_gpu108 [label="MLP-Gate GPU108\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e54_l0_gpu109 [label="MLP-Gate GPU109\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e54_l0_gpu108 [label="MLP-Up GPU108\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e54_l0_gpu109 [label="MLP-Up GPU109\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e54_l0_gpu108 [label="MLP-Down GPU108\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e54_l0_gpu109 [label="MLP-Down GPU109\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e54_l1_gpu108 [label="LayerNorm GPU108\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e54_l1_gpu109 [label="LayerNorm GPU109\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e54_l1_gpu108 [label="Attn-Q GPU108\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e54_l1_gpu109 [label="Attn-Q GPU109\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e54_l1_gpu108 [label="Attn-K/V GPU108\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e54_l1_gpu109 [label="Attn-K/V GPU109\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e54_l1_gpu108 [label="Attn-Out GPU108\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e54_l1_gpu109 [label="Attn-Out GPU109\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e54_l1_gpu108 [label="MLP-Gate GPU108\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e54_l1_gpu109 [label="MLP-Gate GPU109\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e54_l1_gpu108 [label="MLP-Up GPU108\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e54_l1_gpu109 [label="MLP-Up GPU109\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e54_l1_gpu108 [label="MLP-Down GPU108\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e54_l1_gpu109 [label="MLP-Down GPU109\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e54_l2_gpu108 [label="LayerNorm GPU108\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e54_l2_gpu109 [label="LayerNorm GPU109\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e54_l2_gpu108 [label="Attn-Q GPU108\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e54_l2_gpu109 [label="Attn-Q GPU109\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e54_l2_gpu108 [label="Attn-K/V GPU108\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e54_l2_gpu109 [label="Attn-K/V GPU109\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e54_l2_gpu108 [label="Attn-Out GPU108\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e54_l2_gpu109 [label="Attn-Out GPU109\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e54_l2_gpu108 [label="MLP-Gate GPU108\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e54_l2_gpu109 [label="MLP-Gate GPU109\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e54_l2_gpu108 [label="MLP-Up GPU108\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e54_l2_gpu109 [label="MLP-Up GPU109\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e54_l2_gpu108 [label="MLP-Down GPU108\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e54_l2_gpu109 [label="MLP-Down GPU109\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e54_l3_gpu108 [label="LayerNorm GPU108\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e54_l3_gpu109 [label="LayerNorm GPU109\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e54_l3_gpu108 [label="Attn-Q GPU108\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e54_l3_gpu109 [label="Attn-Q GPU109\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e54_l3_gpu108 [label="Attn-K/V GPU108\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e54_l3_gpu109 [label="Attn-K/V GPU109\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e54_l3_gpu108 [label="Attn-Out GPU108\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e54_l3_gpu109 [label="Attn-Out GPU109\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e54_l3_gpu108 [label="MLP-Gate GPU108\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e54_l3_gpu109 [label="MLP-Gate GPU109\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e54_l3_gpu108 [label="MLP-Up GPU108\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e54_l3_gpu109 [label="MLP-Up GPU109\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e54_l3_gpu108 [label="MLP-Down GPU108\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e54_l3_gpu109 [label="MLP-Down GPU109\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_55 {
			color=red fillcolor=lightgray label="Expert 55" style="rounded,filled"
			attn_norm_s3_e55_l0_gpu110 [label="LayerNorm GPU110\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e55_l0_gpu111 [label="LayerNorm GPU111\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e55_l0_gpu110 [label="Attn-Q GPU110\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e55_l0_gpu111 [label="Attn-Q GPU111\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e55_l0_gpu110 [label="Attn-K/V GPU110\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e55_l0_gpu111 [label="Attn-K/V GPU111\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e55_l0_gpu110 [label="Attn-Out GPU110\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e55_l0_gpu111 [label="Attn-Out GPU111\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e55_l0_gpu110 [label="MLP-Gate GPU110\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e55_l0_gpu111 [label="MLP-Gate GPU111\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e55_l0_gpu110 [label="MLP-Up GPU110\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e55_l0_gpu111 [label="MLP-Up GPU111\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e55_l0_gpu110 [label="MLP-Down GPU110\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e55_l0_gpu111 [label="MLP-Down GPU111\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e55_l1_gpu110 [label="LayerNorm GPU110\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e55_l1_gpu111 [label="LayerNorm GPU111\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e55_l1_gpu110 [label="Attn-Q GPU110\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e55_l1_gpu111 [label="Attn-Q GPU111\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e55_l1_gpu110 [label="Attn-K/V GPU110\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e55_l1_gpu111 [label="Attn-K/V GPU111\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e55_l1_gpu110 [label="Attn-Out GPU110\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e55_l1_gpu111 [label="Attn-Out GPU111\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e55_l1_gpu110 [label="MLP-Gate GPU110\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e55_l1_gpu111 [label="MLP-Gate GPU111\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e55_l1_gpu110 [label="MLP-Up GPU110\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e55_l1_gpu111 [label="MLP-Up GPU111\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e55_l1_gpu110 [label="MLP-Down GPU110\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e55_l1_gpu111 [label="MLP-Down GPU111\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e55_l2_gpu110 [label="LayerNorm GPU110\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e55_l2_gpu111 [label="LayerNorm GPU111\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e55_l2_gpu110 [label="Attn-Q GPU110\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e55_l2_gpu111 [label="Attn-Q GPU111\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e55_l2_gpu110 [label="Attn-K/V GPU110\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e55_l2_gpu111 [label="Attn-K/V GPU111\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e55_l2_gpu110 [label="Attn-Out GPU110\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e55_l2_gpu111 [label="Attn-Out GPU111\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e55_l2_gpu110 [label="MLP-Gate GPU110\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e55_l2_gpu111 [label="MLP-Gate GPU111\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e55_l2_gpu110 [label="MLP-Up GPU110\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e55_l2_gpu111 [label="MLP-Up GPU111\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e55_l2_gpu110 [label="MLP-Down GPU110\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e55_l2_gpu111 [label="MLP-Down GPU111\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e55_l3_gpu110 [label="LayerNorm GPU110\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e55_l3_gpu111 [label="LayerNorm GPU111\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e55_l3_gpu110 [label="Attn-Q GPU110\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e55_l3_gpu111 [label="Attn-Q GPU111\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e55_l3_gpu110 [label="Attn-K/V GPU110\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e55_l3_gpu111 [label="Attn-K/V GPU111\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e55_l3_gpu110 [label="Attn-Out GPU110\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e55_l3_gpu111 [label="Attn-Out GPU111\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e55_l3_gpu110 [label="MLP-Gate GPU110\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e55_l3_gpu111 [label="MLP-Gate GPU111\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e55_l3_gpu110 [label="MLP-Up GPU110\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e55_l3_gpu111 [label="MLP-Up GPU111\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e55_l3_gpu110 [label="MLP-Down GPU110\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e55_l3_gpu111 [label="MLP-Down GPU111\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_56 {
			color=red fillcolor=lightgray label="Expert 56" style="rounded,filled"
			attn_norm_s3_e56_l0_gpu112 [label="LayerNorm GPU112\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e56_l0_gpu113 [label="LayerNorm GPU113\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e56_l0_gpu112 [label="Attn-Q GPU112\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e56_l0_gpu113 [label="Attn-Q GPU113\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e56_l0_gpu112 [label="Attn-K/V GPU112\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e56_l0_gpu113 [label="Attn-K/V GPU113\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e56_l0_gpu112 [label="Attn-Out GPU112\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e56_l0_gpu113 [label="Attn-Out GPU113\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e56_l0_gpu112 [label="MLP-Gate GPU112\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e56_l0_gpu113 [label="MLP-Gate GPU113\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e56_l0_gpu112 [label="MLP-Up GPU112\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e56_l0_gpu113 [label="MLP-Up GPU113\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e56_l0_gpu112 [label="MLP-Down GPU112\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e56_l0_gpu113 [label="MLP-Down GPU113\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e56_l1_gpu112 [label="LayerNorm GPU112\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e56_l1_gpu113 [label="LayerNorm GPU113\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e56_l1_gpu112 [label="Attn-Q GPU112\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e56_l1_gpu113 [label="Attn-Q GPU113\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e56_l1_gpu112 [label="Attn-K/V GPU112\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e56_l1_gpu113 [label="Attn-K/V GPU113\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e56_l1_gpu112 [label="Attn-Out GPU112\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e56_l1_gpu113 [label="Attn-Out GPU113\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e56_l1_gpu112 [label="MLP-Gate GPU112\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e56_l1_gpu113 [label="MLP-Gate GPU113\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e56_l1_gpu112 [label="MLP-Up GPU112\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e56_l1_gpu113 [label="MLP-Up GPU113\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e56_l1_gpu112 [label="MLP-Down GPU112\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e56_l1_gpu113 [label="MLP-Down GPU113\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e56_l2_gpu112 [label="LayerNorm GPU112\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e56_l2_gpu113 [label="LayerNorm GPU113\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e56_l2_gpu112 [label="Attn-Q GPU112\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e56_l2_gpu113 [label="Attn-Q GPU113\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e56_l2_gpu112 [label="Attn-K/V GPU112\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e56_l2_gpu113 [label="Attn-K/V GPU113\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e56_l2_gpu112 [label="Attn-Out GPU112\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e56_l2_gpu113 [label="Attn-Out GPU113\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e56_l2_gpu112 [label="MLP-Gate GPU112\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e56_l2_gpu113 [label="MLP-Gate GPU113\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e56_l2_gpu112 [label="MLP-Up GPU112\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e56_l2_gpu113 [label="MLP-Up GPU113\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e56_l2_gpu112 [label="MLP-Down GPU112\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e56_l2_gpu113 [label="MLP-Down GPU113\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e56_l3_gpu112 [label="LayerNorm GPU112\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e56_l3_gpu113 [label="LayerNorm GPU113\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e56_l3_gpu112 [label="Attn-Q GPU112\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e56_l3_gpu113 [label="Attn-Q GPU113\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e56_l3_gpu112 [label="Attn-K/V GPU112\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e56_l3_gpu113 [label="Attn-K/V GPU113\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e56_l3_gpu112 [label="Attn-Out GPU112\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e56_l3_gpu113 [label="Attn-Out GPU113\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e56_l3_gpu112 [label="MLP-Gate GPU112\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e56_l3_gpu113 [label="MLP-Gate GPU113\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e56_l3_gpu112 [label="MLP-Up GPU112\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e56_l3_gpu113 [label="MLP-Up GPU113\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e56_l3_gpu112 [label="MLP-Down GPU112\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e56_l3_gpu113 [label="MLP-Down GPU113\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_57 {
			color=red fillcolor=lightgray label="Expert 57" style="rounded,filled"
			attn_norm_s3_e57_l0_gpu114 [label="LayerNorm GPU114\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e57_l0_gpu115 [label="LayerNorm GPU115\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e57_l0_gpu114 [label="Attn-Q GPU114\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e57_l0_gpu115 [label="Attn-Q GPU115\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e57_l0_gpu114 [label="Attn-K/V GPU114\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e57_l0_gpu115 [label="Attn-K/V GPU115\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e57_l0_gpu114 [label="Attn-Out GPU114\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e57_l0_gpu115 [label="Attn-Out GPU115\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e57_l0_gpu114 [label="MLP-Gate GPU114\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e57_l0_gpu115 [label="MLP-Gate GPU115\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e57_l0_gpu114 [label="MLP-Up GPU114\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e57_l0_gpu115 [label="MLP-Up GPU115\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e57_l0_gpu114 [label="MLP-Down GPU114\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e57_l0_gpu115 [label="MLP-Down GPU115\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e57_l1_gpu114 [label="LayerNorm GPU114\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e57_l1_gpu115 [label="LayerNorm GPU115\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e57_l1_gpu114 [label="Attn-Q GPU114\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e57_l1_gpu115 [label="Attn-Q GPU115\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e57_l1_gpu114 [label="Attn-K/V GPU114\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e57_l1_gpu115 [label="Attn-K/V GPU115\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e57_l1_gpu114 [label="Attn-Out GPU114\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e57_l1_gpu115 [label="Attn-Out GPU115\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e57_l1_gpu114 [label="MLP-Gate GPU114\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e57_l1_gpu115 [label="MLP-Gate GPU115\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e57_l1_gpu114 [label="MLP-Up GPU114\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e57_l1_gpu115 [label="MLP-Up GPU115\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e57_l1_gpu114 [label="MLP-Down GPU114\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e57_l1_gpu115 [label="MLP-Down GPU115\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e57_l2_gpu114 [label="LayerNorm GPU114\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e57_l2_gpu115 [label="LayerNorm GPU115\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e57_l2_gpu114 [label="Attn-Q GPU114\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e57_l2_gpu115 [label="Attn-Q GPU115\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e57_l2_gpu114 [label="Attn-K/V GPU114\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e57_l2_gpu115 [label="Attn-K/V GPU115\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e57_l2_gpu114 [label="Attn-Out GPU114\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e57_l2_gpu115 [label="Attn-Out GPU115\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e57_l2_gpu114 [label="MLP-Gate GPU114\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e57_l2_gpu115 [label="MLP-Gate GPU115\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e57_l2_gpu114 [label="MLP-Up GPU114\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e57_l2_gpu115 [label="MLP-Up GPU115\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e57_l2_gpu114 [label="MLP-Down GPU114\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e57_l2_gpu115 [label="MLP-Down GPU115\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e57_l3_gpu114 [label="LayerNorm GPU114\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e57_l3_gpu115 [label="LayerNorm GPU115\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e57_l3_gpu114 [label="Attn-Q GPU114\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e57_l3_gpu115 [label="Attn-Q GPU115\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e57_l3_gpu114 [label="Attn-K/V GPU114\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e57_l3_gpu115 [label="Attn-K/V GPU115\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e57_l3_gpu114 [label="Attn-Out GPU114\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e57_l3_gpu115 [label="Attn-Out GPU115\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e57_l3_gpu114 [label="MLP-Gate GPU114\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e57_l3_gpu115 [label="MLP-Gate GPU115\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e57_l3_gpu114 [label="MLP-Up GPU114\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e57_l3_gpu115 [label="MLP-Up GPU115\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e57_l3_gpu114 [label="MLP-Down GPU114\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e57_l3_gpu115 [label="MLP-Down GPU115\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_58 {
			color=red fillcolor=lightgray label="Expert 58" style="rounded,filled"
			attn_norm_s3_e58_l0_gpu116 [label="LayerNorm GPU116\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e58_l0_gpu117 [label="LayerNorm GPU117\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e58_l0_gpu116 [label="Attn-Q GPU116\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e58_l0_gpu117 [label="Attn-Q GPU117\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e58_l0_gpu116 [label="Attn-K/V GPU116\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e58_l0_gpu117 [label="Attn-K/V GPU117\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e58_l0_gpu116 [label="Attn-Out GPU116\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e58_l0_gpu117 [label="Attn-Out GPU117\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e58_l0_gpu116 [label="MLP-Gate GPU116\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e58_l0_gpu117 [label="MLP-Gate GPU117\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e58_l0_gpu116 [label="MLP-Up GPU116\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e58_l0_gpu117 [label="MLP-Up GPU117\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e58_l0_gpu116 [label="MLP-Down GPU116\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e58_l0_gpu117 [label="MLP-Down GPU117\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e58_l1_gpu116 [label="LayerNorm GPU116\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e58_l1_gpu117 [label="LayerNorm GPU117\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e58_l1_gpu116 [label="Attn-Q GPU116\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e58_l1_gpu117 [label="Attn-Q GPU117\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e58_l1_gpu116 [label="Attn-K/V GPU116\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e58_l1_gpu117 [label="Attn-K/V GPU117\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e58_l1_gpu116 [label="Attn-Out GPU116\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e58_l1_gpu117 [label="Attn-Out GPU117\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e58_l1_gpu116 [label="MLP-Gate GPU116\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e58_l1_gpu117 [label="MLP-Gate GPU117\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e58_l1_gpu116 [label="MLP-Up GPU116\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e58_l1_gpu117 [label="MLP-Up GPU117\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e58_l1_gpu116 [label="MLP-Down GPU116\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e58_l1_gpu117 [label="MLP-Down GPU117\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e58_l2_gpu116 [label="LayerNorm GPU116\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e58_l2_gpu117 [label="LayerNorm GPU117\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e58_l2_gpu116 [label="Attn-Q GPU116\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e58_l2_gpu117 [label="Attn-Q GPU117\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e58_l2_gpu116 [label="Attn-K/V GPU116\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e58_l2_gpu117 [label="Attn-K/V GPU117\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e58_l2_gpu116 [label="Attn-Out GPU116\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e58_l2_gpu117 [label="Attn-Out GPU117\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e58_l2_gpu116 [label="MLP-Gate GPU116\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e58_l2_gpu117 [label="MLP-Gate GPU117\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e58_l2_gpu116 [label="MLP-Up GPU116\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e58_l2_gpu117 [label="MLP-Up GPU117\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e58_l2_gpu116 [label="MLP-Down GPU116\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e58_l2_gpu117 [label="MLP-Down GPU117\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e58_l3_gpu116 [label="LayerNorm GPU116\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e58_l3_gpu117 [label="LayerNorm GPU117\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e58_l3_gpu116 [label="Attn-Q GPU116\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e58_l3_gpu117 [label="Attn-Q GPU117\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e58_l3_gpu116 [label="Attn-K/V GPU116\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e58_l3_gpu117 [label="Attn-K/V GPU117\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e58_l3_gpu116 [label="Attn-Out GPU116\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e58_l3_gpu117 [label="Attn-Out GPU117\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e58_l3_gpu116 [label="MLP-Gate GPU116\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e58_l3_gpu117 [label="MLP-Gate GPU117\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e58_l3_gpu116 [label="MLP-Up GPU116\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e58_l3_gpu117 [label="MLP-Up GPU117\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e58_l3_gpu116 [label="MLP-Down GPU116\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e58_l3_gpu117 [label="MLP-Down GPU117\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_59 {
			color=red fillcolor=lightgray label="Expert 59" style="rounded,filled"
			attn_norm_s3_e59_l0_gpu118 [label="LayerNorm GPU118\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e59_l0_gpu119 [label="LayerNorm GPU119\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e59_l0_gpu118 [label="Attn-Q GPU118\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e59_l0_gpu119 [label="Attn-Q GPU119\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e59_l0_gpu118 [label="Attn-K/V GPU118\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e59_l0_gpu119 [label="Attn-K/V GPU119\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e59_l0_gpu118 [label="Attn-Out GPU118\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e59_l0_gpu119 [label="Attn-Out GPU119\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e59_l0_gpu118 [label="MLP-Gate GPU118\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e59_l0_gpu119 [label="MLP-Gate GPU119\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e59_l0_gpu118 [label="MLP-Up GPU118\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e59_l0_gpu119 [label="MLP-Up GPU119\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e59_l0_gpu118 [label="MLP-Down GPU118\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e59_l0_gpu119 [label="MLP-Down GPU119\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e59_l1_gpu118 [label="LayerNorm GPU118\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e59_l1_gpu119 [label="LayerNorm GPU119\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e59_l1_gpu118 [label="Attn-Q GPU118\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e59_l1_gpu119 [label="Attn-Q GPU119\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e59_l1_gpu118 [label="Attn-K/V GPU118\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e59_l1_gpu119 [label="Attn-K/V GPU119\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e59_l1_gpu118 [label="Attn-Out GPU118\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e59_l1_gpu119 [label="Attn-Out GPU119\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e59_l1_gpu118 [label="MLP-Gate GPU118\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e59_l1_gpu119 [label="MLP-Gate GPU119\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e59_l1_gpu118 [label="MLP-Up GPU118\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e59_l1_gpu119 [label="MLP-Up GPU119\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e59_l1_gpu118 [label="MLP-Down GPU118\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e59_l1_gpu119 [label="MLP-Down GPU119\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e59_l2_gpu118 [label="LayerNorm GPU118\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e59_l2_gpu119 [label="LayerNorm GPU119\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e59_l2_gpu118 [label="Attn-Q GPU118\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e59_l2_gpu119 [label="Attn-Q GPU119\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e59_l2_gpu118 [label="Attn-K/V GPU118\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e59_l2_gpu119 [label="Attn-K/V GPU119\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e59_l2_gpu118 [label="Attn-Out GPU118\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e59_l2_gpu119 [label="Attn-Out GPU119\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e59_l2_gpu118 [label="MLP-Gate GPU118\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e59_l2_gpu119 [label="MLP-Gate GPU119\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e59_l2_gpu118 [label="MLP-Up GPU118\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e59_l2_gpu119 [label="MLP-Up GPU119\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e59_l2_gpu118 [label="MLP-Down GPU118\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e59_l2_gpu119 [label="MLP-Down GPU119\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e59_l3_gpu118 [label="LayerNorm GPU118\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e59_l3_gpu119 [label="LayerNorm GPU119\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e59_l3_gpu118 [label="Attn-Q GPU118\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e59_l3_gpu119 [label="Attn-Q GPU119\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e59_l3_gpu118 [label="Attn-K/V GPU118\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e59_l3_gpu119 [label="Attn-K/V GPU119\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e59_l3_gpu118 [label="Attn-Out GPU118\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e59_l3_gpu119 [label="Attn-Out GPU119\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e59_l3_gpu118 [label="MLP-Gate GPU118\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e59_l3_gpu119 [label="MLP-Gate GPU119\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e59_l3_gpu118 [label="MLP-Up GPU118\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e59_l3_gpu119 [label="MLP-Up GPU119\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e59_l3_gpu118 [label="MLP-Down GPU118\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e59_l3_gpu119 [label="MLP-Down GPU119\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_60 {
			color=red fillcolor=lightgray label="Expert 60" style="rounded,filled"
			attn_norm_s3_e60_l0_gpu120 [label="LayerNorm GPU120\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e60_l0_gpu121 [label="LayerNorm GPU121\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e60_l0_gpu120 [label="Attn-Q GPU120\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e60_l0_gpu121 [label="Attn-Q GPU121\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e60_l0_gpu120 [label="Attn-K/V GPU120\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e60_l0_gpu121 [label="Attn-K/V GPU121\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e60_l0_gpu120 [label="Attn-Out GPU120\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e60_l0_gpu121 [label="Attn-Out GPU121\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e60_l0_gpu120 [label="MLP-Gate GPU120\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e60_l0_gpu121 [label="MLP-Gate GPU121\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e60_l0_gpu120 [label="MLP-Up GPU120\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e60_l0_gpu121 [label="MLP-Up GPU121\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e60_l0_gpu120 [label="MLP-Down GPU120\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e60_l0_gpu121 [label="MLP-Down GPU121\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e60_l1_gpu120 [label="LayerNorm GPU120\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e60_l1_gpu121 [label="LayerNorm GPU121\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e60_l1_gpu120 [label="Attn-Q GPU120\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e60_l1_gpu121 [label="Attn-Q GPU121\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e60_l1_gpu120 [label="Attn-K/V GPU120\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e60_l1_gpu121 [label="Attn-K/V GPU121\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e60_l1_gpu120 [label="Attn-Out GPU120\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e60_l1_gpu121 [label="Attn-Out GPU121\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e60_l1_gpu120 [label="MLP-Gate GPU120\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e60_l1_gpu121 [label="MLP-Gate GPU121\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e60_l1_gpu120 [label="MLP-Up GPU120\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e60_l1_gpu121 [label="MLP-Up GPU121\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e60_l1_gpu120 [label="MLP-Down GPU120\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e60_l1_gpu121 [label="MLP-Down GPU121\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e60_l2_gpu120 [label="LayerNorm GPU120\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e60_l2_gpu121 [label="LayerNorm GPU121\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e60_l2_gpu120 [label="Attn-Q GPU120\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e60_l2_gpu121 [label="Attn-Q GPU121\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e60_l2_gpu120 [label="Attn-K/V GPU120\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e60_l2_gpu121 [label="Attn-K/V GPU121\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e60_l2_gpu120 [label="Attn-Out GPU120\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e60_l2_gpu121 [label="Attn-Out GPU121\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e60_l2_gpu120 [label="MLP-Gate GPU120\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e60_l2_gpu121 [label="MLP-Gate GPU121\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e60_l2_gpu120 [label="MLP-Up GPU120\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e60_l2_gpu121 [label="MLP-Up GPU121\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e60_l2_gpu120 [label="MLP-Down GPU120\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e60_l2_gpu121 [label="MLP-Down GPU121\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e60_l3_gpu120 [label="LayerNorm GPU120\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e60_l3_gpu121 [label="LayerNorm GPU121\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e60_l3_gpu120 [label="Attn-Q GPU120\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e60_l3_gpu121 [label="Attn-Q GPU121\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e60_l3_gpu120 [label="Attn-K/V GPU120\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e60_l3_gpu121 [label="Attn-K/V GPU121\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e60_l3_gpu120 [label="Attn-Out GPU120\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e60_l3_gpu121 [label="Attn-Out GPU121\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e60_l3_gpu120 [label="MLP-Gate GPU120\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e60_l3_gpu121 [label="MLP-Gate GPU121\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e60_l3_gpu120 [label="MLP-Up GPU120\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e60_l3_gpu121 [label="MLP-Up GPU121\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e60_l3_gpu120 [label="MLP-Down GPU120\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e60_l3_gpu121 [label="MLP-Down GPU121\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_61 {
			color=red fillcolor=lightgray label="Expert 61" style="rounded,filled"
			attn_norm_s3_e61_l0_gpu122 [label="LayerNorm GPU122\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e61_l0_gpu123 [label="LayerNorm GPU123\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e61_l0_gpu122 [label="Attn-Q GPU122\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e61_l0_gpu123 [label="Attn-Q GPU123\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e61_l0_gpu122 [label="Attn-K/V GPU122\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e61_l0_gpu123 [label="Attn-K/V GPU123\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e61_l0_gpu122 [label="Attn-Out GPU122\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e61_l0_gpu123 [label="Attn-Out GPU123\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e61_l0_gpu122 [label="MLP-Gate GPU122\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e61_l0_gpu123 [label="MLP-Gate GPU123\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e61_l0_gpu122 [label="MLP-Up GPU122\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e61_l0_gpu123 [label="MLP-Up GPU123\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e61_l0_gpu122 [label="MLP-Down GPU122\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e61_l0_gpu123 [label="MLP-Down GPU123\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e61_l1_gpu122 [label="LayerNorm GPU122\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e61_l1_gpu123 [label="LayerNorm GPU123\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e61_l1_gpu122 [label="Attn-Q GPU122\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e61_l1_gpu123 [label="Attn-Q GPU123\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e61_l1_gpu122 [label="Attn-K/V GPU122\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e61_l1_gpu123 [label="Attn-K/V GPU123\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e61_l1_gpu122 [label="Attn-Out GPU122\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e61_l1_gpu123 [label="Attn-Out GPU123\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e61_l1_gpu122 [label="MLP-Gate GPU122\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e61_l1_gpu123 [label="MLP-Gate GPU123\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e61_l1_gpu122 [label="MLP-Up GPU122\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e61_l1_gpu123 [label="MLP-Up GPU123\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e61_l1_gpu122 [label="MLP-Down GPU122\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e61_l1_gpu123 [label="MLP-Down GPU123\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e61_l2_gpu122 [label="LayerNorm GPU122\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e61_l2_gpu123 [label="LayerNorm GPU123\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e61_l2_gpu122 [label="Attn-Q GPU122\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e61_l2_gpu123 [label="Attn-Q GPU123\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e61_l2_gpu122 [label="Attn-K/V GPU122\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e61_l2_gpu123 [label="Attn-K/V GPU123\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e61_l2_gpu122 [label="Attn-Out GPU122\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e61_l2_gpu123 [label="Attn-Out GPU123\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e61_l2_gpu122 [label="MLP-Gate GPU122\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e61_l2_gpu123 [label="MLP-Gate GPU123\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e61_l2_gpu122 [label="MLP-Up GPU122\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e61_l2_gpu123 [label="MLP-Up GPU123\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e61_l2_gpu122 [label="MLP-Down GPU122\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e61_l2_gpu123 [label="MLP-Down GPU123\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e61_l3_gpu122 [label="LayerNorm GPU122\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e61_l3_gpu123 [label="LayerNorm GPU123\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e61_l3_gpu122 [label="Attn-Q GPU122\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e61_l3_gpu123 [label="Attn-Q GPU123\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e61_l3_gpu122 [label="Attn-K/V GPU122\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e61_l3_gpu123 [label="Attn-K/V GPU123\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e61_l3_gpu122 [label="Attn-Out GPU122\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e61_l3_gpu123 [label="Attn-Out GPU123\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e61_l3_gpu122 [label="MLP-Gate GPU122\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e61_l3_gpu123 [label="MLP-Gate GPU123\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e61_l3_gpu122 [label="MLP-Up GPU122\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e61_l3_gpu123 [label="MLP-Up GPU123\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e61_l3_gpu122 [label="MLP-Down GPU122\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e61_l3_gpu123 [label="MLP-Down GPU123\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_62 {
			color=red fillcolor=lightgray label="Expert 62" style="rounded,filled"
			attn_norm_s3_e62_l0_gpu124 [label="LayerNorm GPU124\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e62_l0_gpu125 [label="LayerNorm GPU125\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e62_l0_gpu124 [label="Attn-Q GPU124\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e62_l0_gpu125 [label="Attn-Q GPU125\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e62_l0_gpu124 [label="Attn-K/V GPU124\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e62_l0_gpu125 [label="Attn-K/V GPU125\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e62_l0_gpu124 [label="Attn-Out GPU124\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e62_l0_gpu125 [label="Attn-Out GPU125\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e62_l0_gpu124 [label="MLP-Gate GPU124\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e62_l0_gpu125 [label="MLP-Gate GPU125\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e62_l0_gpu124 [label="MLP-Up GPU124\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e62_l0_gpu125 [label="MLP-Up GPU125\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e62_l0_gpu124 [label="MLP-Down GPU124\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e62_l0_gpu125 [label="MLP-Down GPU125\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e62_l1_gpu124 [label="LayerNorm GPU124\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e62_l1_gpu125 [label="LayerNorm GPU125\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e62_l1_gpu124 [label="Attn-Q GPU124\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e62_l1_gpu125 [label="Attn-Q GPU125\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e62_l1_gpu124 [label="Attn-K/V GPU124\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e62_l1_gpu125 [label="Attn-K/V GPU125\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e62_l1_gpu124 [label="Attn-Out GPU124\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e62_l1_gpu125 [label="Attn-Out GPU125\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e62_l1_gpu124 [label="MLP-Gate GPU124\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e62_l1_gpu125 [label="MLP-Gate GPU125\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e62_l1_gpu124 [label="MLP-Up GPU124\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e62_l1_gpu125 [label="MLP-Up GPU125\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e62_l1_gpu124 [label="MLP-Down GPU124\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e62_l1_gpu125 [label="MLP-Down GPU125\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e62_l2_gpu124 [label="LayerNorm GPU124\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e62_l2_gpu125 [label="LayerNorm GPU125\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e62_l2_gpu124 [label="Attn-Q GPU124\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e62_l2_gpu125 [label="Attn-Q GPU125\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e62_l2_gpu124 [label="Attn-K/V GPU124\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e62_l2_gpu125 [label="Attn-K/V GPU125\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e62_l2_gpu124 [label="Attn-Out GPU124\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e62_l2_gpu125 [label="Attn-Out GPU125\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e62_l2_gpu124 [label="MLP-Gate GPU124\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e62_l2_gpu125 [label="MLP-Gate GPU125\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e62_l2_gpu124 [label="MLP-Up GPU124\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e62_l2_gpu125 [label="MLP-Up GPU125\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e62_l2_gpu124 [label="MLP-Down GPU124\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e62_l2_gpu125 [label="MLP-Down GPU125\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e62_l3_gpu124 [label="LayerNorm GPU124\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e62_l3_gpu125 [label="LayerNorm GPU125\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e62_l3_gpu124 [label="Attn-Q GPU124\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e62_l3_gpu125 [label="Attn-Q GPU125\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e62_l3_gpu124 [label="Attn-K/V GPU124\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e62_l3_gpu125 [label="Attn-K/V GPU125\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e62_l3_gpu124 [label="Attn-Out GPU124\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e62_l3_gpu125 [label="Attn-Out GPU125\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e62_l3_gpu124 [label="MLP-Gate GPU124\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e62_l3_gpu125 [label="MLP-Gate GPU125\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e62_l3_gpu124 [label="MLP-Up GPU124\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e62_l3_gpu125 [label="MLP-Up GPU125\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e62_l3_gpu124 [label="MLP-Down GPU124\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e62_l3_gpu125 [label="MLP-Down GPU125\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
		subgraph cluster_expert_63 {
			color=red fillcolor=lightgray label="Expert 63" style="rounded,filled"
			attn_norm_s3_e63_l0_gpu126 [label="LayerNorm GPU126\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e63_l0_gpu127 [label="LayerNorm GPU127\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e63_l0_gpu126 [label="Attn-Q GPU126\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e63_l0_gpu127 [label="Attn-Q GPU127\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e63_l0_gpu126 [label="Attn-K/V GPU126\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e63_l0_gpu127 [label="Attn-K/V GPU127\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e63_l0_gpu126 [label="Attn-Out GPU126\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e63_l0_gpu127 [label="Attn-Out GPU127\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e63_l0_gpu126 [label="MLP-Gate GPU126\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e63_l0_gpu127 [label="MLP-Gate GPU127\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e63_l0_gpu126 [label="MLP-Up GPU126\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e63_l0_gpu127 [label="MLP-Up GPU127\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e63_l0_gpu126 [label="MLP-Down GPU126\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e63_l0_gpu127 [label="MLP-Down GPU127\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e63_l1_gpu126 [label="LayerNorm GPU126\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e63_l1_gpu127 [label="LayerNorm GPU127\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e63_l1_gpu126 [label="Attn-Q GPU126\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e63_l1_gpu127 [label="Attn-Q GPU127\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e63_l1_gpu126 [label="Attn-K/V GPU126\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e63_l1_gpu127 [label="Attn-K/V GPU127\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e63_l1_gpu126 [label="Attn-Out GPU126\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e63_l1_gpu127 [label="Attn-Out GPU127\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e63_l1_gpu126 [label="MLP-Gate GPU126\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e63_l1_gpu127 [label="MLP-Gate GPU127\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e63_l1_gpu126 [label="MLP-Up GPU126\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e63_l1_gpu127 [label="MLP-Up GPU127\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e63_l1_gpu126 [label="MLP-Down GPU126\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e63_l1_gpu127 [label="MLP-Down GPU127\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e63_l2_gpu126 [label="LayerNorm GPU126\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e63_l2_gpu127 [label="LayerNorm GPU127\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e63_l2_gpu126 [label="Attn-Q GPU126\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e63_l2_gpu127 [label="Attn-Q GPU127\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e63_l2_gpu126 [label="Attn-K/V GPU126\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e63_l2_gpu127 [label="Attn-K/V GPU127\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e63_l2_gpu126 [label="Attn-Out GPU126\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e63_l2_gpu127 [label="Attn-Out GPU127\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e63_l2_gpu126 [label="MLP-Gate GPU126\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e63_l2_gpu127 [label="MLP-Gate GPU127\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e63_l2_gpu126 [label="MLP-Up GPU126\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e63_l2_gpu127 [label="MLP-Up GPU127\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e63_l2_gpu126 [label="MLP-Down GPU126\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e63_l2_gpu127 [label="MLP-Down GPU127\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			attn_norm_s3_e63_l3_gpu126 [label="LayerNorm GPU126\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_norm_s3_e63_l3_gpu127 [label="LayerNorm GPU127\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=lightblue]
			attn_q_s3_e63_l3_gpu126 [label="Attn-Q GPU126\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_q_s3_e63_l3_gpu127 [label="Attn-Q GPU127\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e63_l3_gpu126 [label="Attn-K/V GPU126\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_k_s3_e63_l3_gpu127 [label="Attn-K/V GPU127\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, heads=16, d_k=128]" fillcolor=lightcoral]
			attn_out_s3_e63_l3_gpu126 [label="Attn-Out GPU126\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			attn_out_s3_e63_l3_gpu127 [label="Attn-Out GPU127\nInput: [batch_size=?, seq_len=?, heads=16, d_k=128]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcoral]
			mlp_gate_s3_e63_l3_gpu126 [label="MLP-Gate GPU126\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_gate_s3_e63_l3_gpu127 [label="MLP-Gate GPU127\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e63_l3_gpu126 [label="MLP-Up GPU126\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_up_s3_e63_l3_gpu127 [label="MLP-Up GPU127\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, ffn_size=8192]" fillcolor=lightcyan]
			mlp_down_s3_e63_l3_gpu126 [label="MLP-Down GPU126\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
			mlp_down_s3_e63_l3_gpu127 [label="MLP-Down GPU127\nInput: [batch_size=?, seq_len=?, ffn_size=8192]\nOutput: [batch_size=?, seq_len=?, hidden_size=2048]" fillcolor=lightcyan]
		}
	}
	attn_allreduce_s0_e0_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e0_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e0_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e0_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e0_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e0_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e0_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e0_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e1_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e1_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e1_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e1_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e1_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e1_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e1_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e1_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e2_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e2_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e2_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e2_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e2_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e2_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e2_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e2_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e3_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e3_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e3_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e3_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e3_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e3_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e3_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e3_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e4_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e4_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e4_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e4_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e4_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e4_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e4_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e4_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e5_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e5_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e5_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e5_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e5_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e5_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e5_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e5_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e6_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e6_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e6_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e6_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e6_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e6_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e6_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e6_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e7_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e7_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e7_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e7_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e7_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e7_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e7_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e7_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e8_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e8_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e8_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e8_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e8_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e8_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e8_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e8_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e9_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e9_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e9_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e9_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e9_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e9_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e9_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e9_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e10_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e10_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e10_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e10_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e10_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e10_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e10_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e10_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e11_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e11_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e11_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e11_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e11_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e11_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e11_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e11_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e12_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e12_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e12_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e12_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e12_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e12_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e12_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e12_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e13_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e13_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e13_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e13_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e13_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e13_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e13_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e13_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e14_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e14_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e14_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e14_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e14_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e14_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e14_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e14_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e15_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e15_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e15_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e15_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e15_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e15_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s0_e15_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s0_e15_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e16_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e16_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e16_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e16_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e16_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e16_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e16_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e16_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e17_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e17_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e17_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e17_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e17_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e17_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e17_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e17_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e18_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e18_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e18_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e18_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e18_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e18_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e18_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e18_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e19_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e19_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e19_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e19_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e19_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e19_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e19_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e19_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e20_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e20_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e20_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e20_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e20_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e20_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e20_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e20_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e21_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e21_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e21_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e21_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e21_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e21_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e21_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e21_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e22_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e22_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e22_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e22_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e22_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e22_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e22_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e22_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e23_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e23_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e23_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e23_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e23_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e23_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e23_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e23_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e24_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e24_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e24_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e24_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e24_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e24_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e24_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e24_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e25_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e25_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e25_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e25_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e25_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e25_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e25_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e25_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e26_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e26_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e26_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e26_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e26_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e26_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e26_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e26_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e27_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e27_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e27_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e27_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e27_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e27_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e27_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e27_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e28_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e28_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e28_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e28_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e28_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e28_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e28_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e28_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e29_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e29_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e29_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e29_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e29_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e29_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e29_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e29_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e30_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e30_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e30_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e30_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e30_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e30_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e30_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e30_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e31_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e31_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e31_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e31_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e31_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e31_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s1_e31_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s1_e31_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e32_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e32_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e32_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e32_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e32_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e32_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e32_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e32_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e33_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e33_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e33_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e33_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e33_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e33_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e33_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e33_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e34_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e34_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e34_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e34_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e34_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e34_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e34_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e34_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e35_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e35_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e35_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e35_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e35_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e35_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e35_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e35_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e36_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e36_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e36_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e36_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e36_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e36_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e36_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e36_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e37_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e37_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e37_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e37_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e37_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e37_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e37_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e37_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e38_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e38_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e38_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e38_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e38_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e38_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e38_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e38_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e39_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e39_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e39_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e39_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e39_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e39_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e39_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e39_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e40_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e40_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e40_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e40_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e40_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e40_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e40_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e40_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e41_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e41_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e41_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e41_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e41_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e41_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e41_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e41_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e42_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e42_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e42_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e42_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e42_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e42_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e42_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e42_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e43_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e43_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e43_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e43_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e43_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e43_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e43_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e43_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e44_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e44_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e44_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e44_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e44_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e44_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e44_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e44_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e45_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e45_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e45_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e45_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e45_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e45_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e45_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e45_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e46_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e46_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e46_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e46_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e46_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e46_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e46_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e46_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e47_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e47_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e47_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e47_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e47_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e47_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s2_e47_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s2_e47_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e48_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e48_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e48_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e48_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e48_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e48_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e48_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e48_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e49_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e49_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e49_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e49_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e49_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e49_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e49_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e49_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e50_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e50_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e50_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e50_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e50_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e50_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e50_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e50_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e51_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e51_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e51_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e51_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e51_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e51_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e51_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e51_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e52_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e52_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e52_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e52_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e52_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e52_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e52_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e52_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e53_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e53_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e53_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e53_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e53_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e53_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e53_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e53_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e54_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e54_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e54_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e54_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e54_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e54_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e54_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e54_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e55_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e55_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e55_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e55_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e55_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e55_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e55_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e55_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e56_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e56_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e56_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e56_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e56_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e56_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e56_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e56_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e57_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e57_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e57_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e57_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e57_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e57_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e57_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e57_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e58_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e58_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e58_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e58_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e58_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e58_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e58_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e58_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e59_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e59_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e59_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e59_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e59_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e59_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e59_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e59_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e60_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e60_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e60_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e60_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e60_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e60_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e60_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e60_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e61_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e61_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e61_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e61_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e61_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e61_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e61_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e61_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e62_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e62_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e62_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e62_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e62_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e62_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e62_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e62_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e63_l0 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e63_l0 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e63_l1 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e63_l1 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e63_l2 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e63_l2 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	attn_allreduce_s3_e63_l3 [label="All-Reduce Attn\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	mlp_allreduce_s3_e63_l3 [label="All-Reduce MLP\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, hidden_size=4096]" fillcolor=yellow shape=ellipse style="filled,dashed"]
	moe_gate [label="MoE Gate\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, num_experts=64]" fillcolor=orange shape=parallelogram style="filled,dashed"]
	expert_select [label="Expert Selection\nInput: [batch_size=?, seq_len=?, num_experts=64]\nOutput: [batch_size=?, seq_len=?, selected_experts=2]" fillcolor=orange shape=parallelogram style="filled,dashed"]
	input -> attn_norm_s0_e0_l0_gpu0 [style=solid]
	input -> attn_norm_s0_e0_l0_gpu1 [style=solid]
	input -> attn_norm_s0_e1_l0_gpu2 [style=solid]
	input -> attn_norm_s0_e1_l0_gpu3 [style=solid]
	input -> attn_norm_s0_e2_l0_gpu4 [style=solid]
	input -> attn_norm_s0_e2_l0_gpu5 [style=solid]
	input -> attn_norm_s0_e3_l0_gpu6 [style=solid]
	input -> attn_norm_s0_e3_l0_gpu7 [style=solid]
	input -> attn_norm_s0_e4_l0_gpu8 [style=solid]
	input -> attn_norm_s0_e4_l0_gpu9 [style=solid]
	input -> attn_norm_s0_e5_l0_gpu10 [style=solid]
	input -> attn_norm_s0_e5_l0_gpu11 [style=solid]
	input -> attn_norm_s0_e6_l0_gpu12 [style=solid]
	input -> attn_norm_s0_e6_l0_gpu13 [style=solid]
	input -> attn_norm_s0_e7_l0_gpu14 [style=solid]
	input -> attn_norm_s0_e7_l0_gpu15 [style=solid]
	input -> attn_norm_s0_e8_l0_gpu16 [style=solid]
	input -> attn_norm_s0_e8_l0_gpu17 [style=solid]
	input -> attn_norm_s0_e9_l0_gpu18 [style=solid]
	input -> attn_norm_s0_e9_l0_gpu19 [style=solid]
	input -> attn_norm_s0_e10_l0_gpu20 [style=solid]
	input -> attn_norm_s0_e10_l0_gpu21 [style=solid]
	input -> attn_norm_s0_e11_l0_gpu22 [style=solid]
	input -> attn_norm_s0_e11_l0_gpu23 [style=solid]
	input -> attn_norm_s0_e12_l0_gpu24 [style=solid]
	input -> attn_norm_s0_e12_l0_gpu25 [style=solid]
	input -> attn_norm_s0_e13_l0_gpu26 [style=solid]
	input -> attn_norm_s0_e13_l0_gpu27 [style=solid]
	input -> attn_norm_s0_e14_l0_gpu28 [style=solid]
	input -> attn_norm_s0_e14_l0_gpu29 [style=solid]
	input -> attn_norm_s0_e15_l0_gpu30 [style=solid]
	input -> attn_norm_s0_e15_l0_gpu31 [style=solid]
	output [label="Output\nInput: [batch_size=?, seq_len=?, hidden_size=4096]\nOutput: [batch_size=?, seq_len=?, vocab_size=50000]" fillcolor=lightgreen shape=ellipse style="filled,bold"]
}
