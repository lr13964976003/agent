// Original Proposed Layer-wise Dense Model DAG
digraph {
	bgcolor=white rankdir=TB splines=ortho
	node [fillcolor=lightblue shape=ellipse style=filled]
	node [fillcolor=lightgreen shape=box style=filled]
	node [fillcolor=lightyellow shape=parallelogram style=filled]
	input [label="Input
(batch_size=128, seq_len=10000, hidden_size=4096)" fillcolor=lightcoral shape=box]
	layer1 [label="Layer 1
GPU 0
(Cache: 15.36GB)" fillcolor=lightgreen shape=box]
	transfer_l1_l2 [label="Transfer
Layer1→Layer2" fillcolor=lightblue shape=ellipse]
	input -> layer1
	layer1 -> transfer_l1_l2
	layer2 [label="Layer 2
GPU 1
(Cache: 15.36GB)" fillcolor=lightgreen shape=box]
	transfer_l2_l3 [label="Transfer
Layer2→Layer3" fillcolor=lightblue shape=ellipse]
	transfer_l1_l2 -> layer2
	layer2 -> transfer_l2_l3
	layer3 [label="Layer 3
GPU 2
(Cache: 15.36GB)" fillcolor=lightgreen shape=box]
	transfer_l3_l4 [label="Transfer
Layer3→Layer4" fillcolor=lightblue shape=ellipse]
	transfer_l2_l3 -> layer3
	layer3 -> transfer_l3_l4
	layer4 [label="Layer 4
GPU 3
(Cache: 15.36GB)" fillcolor=lightgreen shape=box]
	transfer_l3_l4 -> layer4
	output [label="Output
(batch_size=128, seq_len=10000, hidden_size=4096)" fillcolor=lightcoral shape=box]
	layer4 -> output
	perf [label="Performance:
TPS: 15,360 (+20% vs baseline)
Cache Utilization: 98.8%
GPUs Used: 4/16" fillcolor=lightgray fontcolor=black shape=note]
}
