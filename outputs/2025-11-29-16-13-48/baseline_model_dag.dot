// Baseline Dense Model DAG (TP=8, PP=2)
digraph {
	bgcolor=white rankdir=TB splines=ortho
	node [fillcolor=lightblue shape=ellipse style=filled]
	node [fillcolor=lightgreen shape=box style=filled]
	node [fillcolor=lightyellow shape=parallelogram style=filled]
	input [label="Input
(batch_size=128, seq_len=10000, hidden_size=4096)" fillcolor=lightcoral shape=box]
	subgraph cluster_stage1 {
		bgcolor=lightblue fontcolor=black label="Pipeline Stage 1 (TP=8)" style="rounded,dashed"
		split_input_s1 [label="Split Input
Column-wise" fillcolor=lightyellow shape=parallelogram]
		layer1_gpu0 [label="Layer 1
GPU 0
(TP shard)" fillcolor=lightgreen shape=box]
		layer1_gpu1 [label="Layer 1
GPU 1
(TP shard)" fillcolor=lightgreen shape=box]
		layer1_gpu2 [label="Layer 1
GPU 2
(TP shard)" fillcolor=lightgreen shape=box]
		layer1_gpu3 [label="Layer 1
GPU 3
(TP shard)" fillcolor=lightgreen shape=box]
		layer1_gpu4 [label="Layer 1
GPU 4
(TP shard)" fillcolor=lightgreen shape=box]
		layer1_gpu5 [label="Layer 1
GPU 5
(TP shard)" fillcolor=lightgreen shape=box]
		layer1_gpu6 [label="Layer 1
GPU 6
(TP shard)" fillcolor=lightgreen shape=box]
		layer1_gpu7 [label="Layer 1
GPU 7
(TP shard)" fillcolor=lightgreen shape=box]
		ar_layer1 [label="All-Reduce
Layer 1 Output" fillcolor=lightblue shape=ellipse]
		layer2_gpu0 [label="Layer 2
GPU 0
(TP shard)" fillcolor=lightgreen shape=box]
		layer2_gpu1 [label="Layer 2
GPU 1
(TP shard)" fillcolor=lightgreen shape=box]
		layer2_gpu2 [label="Layer 2
GPU 2
(TP shard)" fillcolor=lightgreen shape=box]
		layer2_gpu3 [label="Layer 2
GPU 3
(TP shard)" fillcolor=lightgreen shape=box]
		layer2_gpu4 [label="Layer 2
GPU 4
(TP shard)" fillcolor=lightgreen shape=box]
		layer2_gpu5 [label="Layer 2
GPU 5
(TP shard)" fillcolor=lightgreen shape=box]
		layer2_gpu6 [label="Layer 2
GPU 6
(TP shard)" fillcolor=lightgreen shape=box]
		layer2_gpu7 [label="Layer 2
GPU 7
(TP shard)" fillcolor=lightgreen shape=box]
		ar_layer2 [label="All-Reduce
Layer 2 Output" fillcolor=lightblue shape=ellipse]
		split_input_s1 -> layer1_gpu0 [style=dashed]
		split_input_s1 -> layer1_gpu1 [style=dashed]
		split_input_s1 -> layer1_gpu2 [style=dashed]
		split_input_s1 -> layer1_gpu3 [style=dashed]
		split_input_s1 -> layer1_gpu4 [style=dashed]
		split_input_s1 -> layer1_gpu5 [style=dashed]
		split_input_s1 -> layer1_gpu6 [style=dashed]
		split_input_s1 -> layer1_gpu7 [style=dashed]
		layer1_gpu0 -> ar_layer1
		ar_layer1 -> layer2_gpu0
		layer2_gpu0 -> ar_layer2
		layer1_gpu1 -> ar_layer1
		ar_layer1 -> layer2_gpu1
		layer2_gpu1 -> ar_layer2
		layer1_gpu2 -> ar_layer1
		ar_layer1 -> layer2_gpu2
		layer2_gpu2 -> ar_layer2
		layer1_gpu3 -> ar_layer1
		ar_layer1 -> layer2_gpu3
		layer2_gpu3 -> ar_layer2
		layer1_gpu4 -> ar_layer1
		ar_layer1 -> layer2_gpu4
		layer2_gpu4 -> ar_layer2
		layer1_gpu5 -> ar_layer1
		ar_layer1 -> layer2_gpu5
		layer2_gpu5 -> ar_layer2
		layer1_gpu6 -> ar_layer1
		ar_layer1 -> layer2_gpu6
		layer2_gpu6 -> ar_layer2
		layer1_gpu7 -> ar_layer1
		ar_layer1 -> layer2_gpu7
		layer2_gpu7 -> ar_layer2
	}
	subgraph cluster_stage2 {
		bgcolor=lightpink fontcolor=black label="Pipeline Stage 2 (TP=8)" style="rounded,dashed"
		transfer_s1_s2 [label="Transfer
Stage1â†’Stage2" fillcolor=lightblue shape=ellipse]
		split_input_s2 [label="Split Input
Column-wise" fillcolor=lightyellow shape=parallelogram]
		layer3_gpu8 [label="Layer 3
GPU 8
(TP shard)" fillcolor=lightgreen shape=box]
		layer3_gpu9 [label="Layer 3
GPU 9
(TP shard)" fillcolor=lightgreen shape=box]
		layer3_gpu10 [label="Layer 3
GPU 10
(TP shard)" fillcolor=lightgreen shape=box]
		layer3_gpu11 [label="Layer 3
GPU 11
(TP shard)" fillcolor=lightgreen shape=box]
		layer3_gpu12 [label="Layer 3
GPU 12
(TP shard)" fillcolor=lightgreen shape=box]
		layer3_gpu13 [label="Layer 3
GPU 13
(TP shard)" fillcolor=lightgreen shape=box]
		layer3_gpu14 [label="Layer 3
GPU 14
(TP shard)" fillcolor=lightgreen shape=box]
		layer3_gpu15 [label="Layer 3
GPU 15
(TP shard)" fillcolor=lightgreen shape=box]
		ar_layer3 [label="All-Reduce
Layer 3 Output" fillcolor=lightblue shape=ellipse]
		layer4_gpu8 [label="Layer 4
GPU 8
(TP shard)" fillcolor=lightgreen shape=box]
		layer4_gpu9 [label="Layer 4
GPU 9
(TP shard)" fillcolor=lightgreen shape=box]
		layer4_gpu10 [label="Layer 4
GPU 10
(TP shard)" fillcolor=lightgreen shape=box]
		layer4_gpu11 [label="Layer 4
GPU 11
(TP shard)" fillcolor=lightgreen shape=box]
		layer4_gpu12 [label="Layer 4
GPU 12
(TP shard)" fillcolor=lightgreen shape=box]
		layer4_gpu13 [label="Layer 4
GPU 13
(TP shard)" fillcolor=lightgreen shape=box]
		layer4_gpu14 [label="Layer 4
GPU 14
(TP shard)" fillcolor=lightgreen shape=box]
		layer4_gpu15 [label="Layer 4
GPU 15
(TP shard)" fillcolor=lightgreen shape=box]
		ar_layer4 [label="All-Reduce
Layer 4 Output" fillcolor=lightblue shape=ellipse]
		transfer_s1_s2 -> split_input_s2
		split_input_s2 -> layer3_gpu8 [style=dashed]
		split_input_s2 -> layer3_gpu9 [style=dashed]
		split_input_s2 -> layer3_gpu10 [style=dashed]
		split_input_s2 -> layer3_gpu11 [style=dashed]
		split_input_s2 -> layer3_gpu12 [style=dashed]
		split_input_s2 -> layer3_gpu13 [style=dashed]
		split_input_s2 -> layer3_gpu14 [style=dashed]
		split_input_s2 -> layer3_gpu15 [style=dashed]
		layer3_gpu8 -> ar_layer3
		ar_layer3 -> layer4_gpu8
		layer4_gpu8 -> ar_layer4
		layer3_gpu9 -> ar_layer3
		ar_layer3 -> layer4_gpu9
		layer4_gpu9 -> ar_layer4
		layer3_gpu10 -> ar_layer3
		ar_layer3 -> layer4_gpu10
		layer4_gpu10 -> ar_layer4
		layer3_gpu11 -> ar_layer3
		ar_layer3 -> layer4_gpu11
		layer4_gpu11 -> ar_layer4
		layer3_gpu12 -> ar_layer3
		ar_layer3 -> layer4_gpu12
		layer4_gpu12 -> ar_layer4
		layer3_gpu13 -> ar_layer3
		ar_layer3 -> layer4_gpu13
		layer4_gpu13 -> ar_layer4
		layer3_gpu14 -> ar_layer3
		ar_layer3 -> layer4_gpu14
		layer4_gpu14 -> ar_layer4
		layer3_gpu15 -> ar_layer3
		ar_layer3 -> layer4_gpu15
		layer4_gpu15 -> ar_layer4
	}
	input -> split_input_s1
	ar_layer2 -> transfer_s1_s2
	output [label="Output
(batch_size=128, seq_len=10000, hidden_size=4096)" fillcolor=lightcoral shape=box]
	ar_layer4 -> output
}
