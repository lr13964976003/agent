// EP16_TP4_PP2_Hybrid_MoE_DAG
digraph {
	bgcolor=white rankdir=TB
	node [fontname=Arial fontsize=10]
	edge [fontname=Arial fontsize=8]
	node [fillcolor=lightblue shape=rectangle style=filled]
	node [fillcolor=lightgreen shape=ellipse style=filled]
	node [fillcolor=lightyellow shape=parallelogram style=filled]
	input [label="Input\n[batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgray shape=hexagon]
	layer_0_ep0_tp0_sa_qkv [label="Self-Attn QKV\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep0_tp0_sa_attn [label="Self-Attn Compute\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep0_tp0_sa_out [label="Self-Attn Output\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep0_tp0_sa_qkv -> layer_0_ep0_tp0_sa_attn
	layer_0_ep0_tp0_sa_attn -> layer_0_ep0_tp0_sa_out
	layer_0_ep0_tp1_sa_qkv [label="Self-Attn QKV\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep0_tp1_sa_attn [label="Self-Attn Compute\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep0_tp1_sa_out [label="Self-Attn Output\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep0_tp1_sa_qkv -> layer_0_ep0_tp1_sa_attn
	layer_0_ep0_tp1_sa_attn -> layer_0_ep0_tp1_sa_out
	layer_0_ep0_tp2_sa_qkv [label="Self-Attn QKV\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep0_tp2_sa_attn [label="Self-Attn Compute\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep0_tp2_sa_out [label="Self-Attn Output\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep0_tp2_sa_qkv -> layer_0_ep0_tp2_sa_attn
	layer_0_ep0_tp2_sa_attn -> layer_0_ep0_tp2_sa_out
	layer_0_ep0_tp3_sa_qkv [label="Self-Attn QKV\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep0_tp3_sa_attn [label="Self-Attn Compute\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep0_tp3_sa_out [label="Self-Attn Output\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep0_tp3_sa_qkv -> layer_0_ep0_tp3_sa_attn
	layer_0_ep0_tp3_sa_attn -> layer_0_ep0_tp3_sa_out
	layer_0_ep1_tp0_sa_qkv [label="Self-Attn QKV\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep1_tp0_sa_attn [label="Self-Attn Compute\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep1_tp0_sa_out [label="Self-Attn Output\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep1_tp0_sa_qkv -> layer_0_ep1_tp0_sa_attn
	layer_0_ep1_tp0_sa_attn -> layer_0_ep1_tp0_sa_out
	layer_0_ep1_tp1_sa_qkv [label="Self-Attn QKV\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep1_tp1_sa_attn [label="Self-Attn Compute\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep1_tp1_sa_out [label="Self-Attn Output\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep1_tp1_sa_qkv -> layer_0_ep1_tp1_sa_attn
	layer_0_ep1_tp1_sa_attn -> layer_0_ep1_tp1_sa_out
	layer_0_ep1_tp2_sa_qkv [label="Self-Attn QKV\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep1_tp2_sa_attn [label="Self-Attn Compute\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep1_tp2_sa_out [label="Self-Attn Output\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep1_tp2_sa_qkv -> layer_0_ep1_tp2_sa_attn
	layer_0_ep1_tp2_sa_attn -> layer_0_ep1_tp2_sa_out
	layer_0_ep1_tp3_sa_qkv [label="Self-Attn QKV\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep1_tp3_sa_attn [label="Self-Attn Compute\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep1_tp3_sa_out [label="Self-Attn Output\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep1_tp3_sa_qkv -> layer_0_ep1_tp3_sa_attn
	layer_0_ep1_tp3_sa_attn -> layer_0_ep1_tp3_sa_out
	layer_0_ep2_tp0_sa_qkv [label="Self-Attn QKV\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep2_tp0_sa_attn [label="Self-Attn Compute\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep2_tp0_sa_out [label="Self-Attn Output\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep2_tp0_sa_qkv -> layer_0_ep2_tp0_sa_attn
	layer_0_ep2_tp0_sa_attn -> layer_0_ep2_tp0_sa_out
	layer_0_ep2_tp1_sa_qkv [label="Self-Attn QKV\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep2_tp1_sa_attn [label="Self-Attn Compute\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep2_tp1_sa_out [label="Self-Attn Output\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep2_tp1_sa_qkv -> layer_0_ep2_tp1_sa_attn
	layer_0_ep2_tp1_sa_attn -> layer_0_ep2_tp1_sa_out
	layer_0_ep2_tp2_sa_qkv [label="Self-Attn QKV\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep2_tp2_sa_attn [label="Self-Attn Compute\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep2_tp2_sa_out [label="Self-Attn Output\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep2_tp2_sa_qkv -> layer_0_ep2_tp2_sa_attn
	layer_0_ep2_tp2_sa_attn -> layer_0_ep2_tp2_sa_out
	layer_0_ep2_tp3_sa_qkv [label="Self-Attn QKV\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep2_tp3_sa_attn [label="Self-Attn Compute\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep2_tp3_sa_out [label="Self-Attn Output\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep2_tp3_sa_qkv -> layer_0_ep2_tp3_sa_attn
	layer_0_ep2_tp3_sa_attn -> layer_0_ep2_tp3_sa_out
	layer_0_ep3_tp0_sa_qkv [label="Self-Attn QKV\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep3_tp0_sa_attn [label="Self-Attn Compute\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep3_tp0_sa_out [label="Self-Attn Output\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep3_tp0_sa_qkv -> layer_0_ep3_tp0_sa_attn
	layer_0_ep3_tp0_sa_attn -> layer_0_ep3_tp0_sa_out
	layer_0_ep3_tp1_sa_qkv [label="Self-Attn QKV\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep3_tp1_sa_attn [label="Self-Attn Compute\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep3_tp1_sa_out [label="Self-Attn Output\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep3_tp1_sa_qkv -> layer_0_ep3_tp1_sa_attn
	layer_0_ep3_tp1_sa_attn -> layer_0_ep3_tp1_sa_out
	layer_0_ep3_tp2_sa_qkv [label="Self-Attn QKV\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep3_tp2_sa_attn [label="Self-Attn Compute\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep3_tp2_sa_out [label="Self-Attn Output\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep3_tp2_sa_qkv -> layer_0_ep3_tp2_sa_attn
	layer_0_ep3_tp2_sa_attn -> layer_0_ep3_tp2_sa_out
	layer_0_ep3_tp3_sa_qkv [label="Self-Attn QKV\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep3_tp3_sa_attn [label="Self-Attn Compute\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep3_tp3_sa_out [label="Self-Attn Output\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep3_tp3_sa_qkv -> layer_0_ep3_tp3_sa_attn
	layer_0_ep3_tp3_sa_attn -> layer_0_ep3_tp3_sa_out
	layer_0_ep4_tp0_sa_qkv [label="Self-Attn QKV\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep4_tp0_sa_attn [label="Self-Attn Compute\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep4_tp0_sa_out [label="Self-Attn Output\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep4_tp0_sa_qkv -> layer_0_ep4_tp0_sa_attn
	layer_0_ep4_tp0_sa_attn -> layer_0_ep4_tp0_sa_out
	layer_0_ep4_tp1_sa_qkv [label="Self-Attn QKV\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep4_tp1_sa_attn [label="Self-Attn Compute\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep4_tp1_sa_out [label="Self-Attn Output\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep4_tp1_sa_qkv -> layer_0_ep4_tp1_sa_attn
	layer_0_ep4_tp1_sa_attn -> layer_0_ep4_tp1_sa_out
	layer_0_ep4_tp2_sa_qkv [label="Self-Attn QKV\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep4_tp2_sa_attn [label="Self-Attn Compute\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep4_tp2_sa_out [label="Self-Attn Output\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep4_tp2_sa_qkv -> layer_0_ep4_tp2_sa_attn
	layer_0_ep4_tp2_sa_attn -> layer_0_ep4_tp2_sa_out
	layer_0_ep4_tp3_sa_qkv [label="Self-Attn QKV\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep4_tp3_sa_attn [label="Self-Attn Compute\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep4_tp3_sa_out [label="Self-Attn Output\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep4_tp3_sa_qkv -> layer_0_ep4_tp3_sa_attn
	layer_0_ep4_tp3_sa_attn -> layer_0_ep4_tp3_sa_out
	layer_0_ep5_tp0_sa_qkv [label="Self-Attn QKV\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep5_tp0_sa_attn [label="Self-Attn Compute\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep5_tp0_sa_out [label="Self-Attn Output\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep5_tp0_sa_qkv -> layer_0_ep5_tp0_sa_attn
	layer_0_ep5_tp0_sa_attn -> layer_0_ep5_tp0_sa_out
	layer_0_ep5_tp1_sa_qkv [label="Self-Attn QKV\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep5_tp1_sa_attn [label="Self-Attn Compute\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep5_tp1_sa_out [label="Self-Attn Output\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep5_tp1_sa_qkv -> layer_0_ep5_tp1_sa_attn
	layer_0_ep5_tp1_sa_attn -> layer_0_ep5_tp1_sa_out
	layer_0_ep5_tp2_sa_qkv [label="Self-Attn QKV\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep5_tp2_sa_attn [label="Self-Attn Compute\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep5_tp2_sa_out [label="Self-Attn Output\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep5_tp2_sa_qkv -> layer_0_ep5_tp2_sa_attn
	layer_0_ep5_tp2_sa_attn -> layer_0_ep5_tp2_sa_out
	layer_0_ep5_tp3_sa_qkv [label="Self-Attn QKV\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep5_tp3_sa_attn [label="Self-Attn Compute\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep5_tp3_sa_out [label="Self-Attn Output\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep5_tp3_sa_qkv -> layer_0_ep5_tp3_sa_attn
	layer_0_ep5_tp3_sa_attn -> layer_0_ep5_tp3_sa_out
	layer_0_ep6_tp0_sa_qkv [label="Self-Attn QKV\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep6_tp0_sa_attn [label="Self-Attn Compute\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep6_tp0_sa_out [label="Self-Attn Output\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep6_tp0_sa_qkv -> layer_0_ep6_tp0_sa_attn
	layer_0_ep6_tp0_sa_attn -> layer_0_ep6_tp0_sa_out
	layer_0_ep6_tp1_sa_qkv [label="Self-Attn QKV\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep6_tp1_sa_attn [label="Self-Attn Compute\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep6_tp1_sa_out [label="Self-Attn Output\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep6_tp1_sa_qkv -> layer_0_ep6_tp1_sa_attn
	layer_0_ep6_tp1_sa_attn -> layer_0_ep6_tp1_sa_out
	layer_0_ep6_tp2_sa_qkv [label="Self-Attn QKV\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep6_tp2_sa_attn [label="Self-Attn Compute\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep6_tp2_sa_out [label="Self-Attn Output\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep6_tp2_sa_qkv -> layer_0_ep6_tp2_sa_attn
	layer_0_ep6_tp2_sa_attn -> layer_0_ep6_tp2_sa_out
	layer_0_ep6_tp3_sa_qkv [label="Self-Attn QKV\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep6_tp3_sa_attn [label="Self-Attn Compute\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep6_tp3_sa_out [label="Self-Attn Output\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep6_tp3_sa_qkv -> layer_0_ep6_tp3_sa_attn
	layer_0_ep6_tp3_sa_attn -> layer_0_ep6_tp3_sa_out
	layer_0_ep7_tp0_sa_qkv [label="Self-Attn QKV\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep7_tp0_sa_attn [label="Self-Attn Compute\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep7_tp0_sa_out [label="Self-Attn Output\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep7_tp0_sa_qkv -> layer_0_ep7_tp0_sa_attn
	layer_0_ep7_tp0_sa_attn -> layer_0_ep7_tp0_sa_out
	layer_0_ep7_tp1_sa_qkv [label="Self-Attn QKV\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep7_tp1_sa_attn [label="Self-Attn Compute\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep7_tp1_sa_out [label="Self-Attn Output\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep7_tp1_sa_qkv -> layer_0_ep7_tp1_sa_attn
	layer_0_ep7_tp1_sa_attn -> layer_0_ep7_tp1_sa_out
	layer_0_ep7_tp2_sa_qkv [label="Self-Attn QKV\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep7_tp2_sa_attn [label="Self-Attn Compute\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep7_tp2_sa_out [label="Self-Attn Output\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep7_tp2_sa_qkv -> layer_0_ep7_tp2_sa_attn
	layer_0_ep7_tp2_sa_attn -> layer_0_ep7_tp2_sa_out
	layer_0_ep7_tp3_sa_qkv [label="Self-Attn QKV\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep7_tp3_sa_attn [label="Self-Attn Compute\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep7_tp3_sa_out [label="Self-Attn Output\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep7_tp3_sa_qkv -> layer_0_ep7_tp3_sa_attn
	layer_0_ep7_tp3_sa_attn -> layer_0_ep7_tp3_sa_out
	layer_0_ep8_tp0_sa_qkv [label="Self-Attn QKV\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep8_tp0_sa_attn [label="Self-Attn Compute\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep8_tp0_sa_out [label="Self-Attn Output\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep8_tp0_sa_qkv -> layer_0_ep8_tp0_sa_attn
	layer_0_ep8_tp0_sa_attn -> layer_0_ep8_tp0_sa_out
	layer_0_ep8_tp1_sa_qkv [label="Self-Attn QKV\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep8_tp1_sa_attn [label="Self-Attn Compute\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep8_tp1_sa_out [label="Self-Attn Output\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep8_tp1_sa_qkv -> layer_0_ep8_tp1_sa_attn
	layer_0_ep8_tp1_sa_attn -> layer_0_ep8_tp1_sa_out
	layer_0_ep8_tp2_sa_qkv [label="Self-Attn QKV\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep8_tp2_sa_attn [label="Self-Attn Compute\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep8_tp2_sa_out [label="Self-Attn Output\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep8_tp2_sa_qkv -> layer_0_ep8_tp2_sa_attn
	layer_0_ep8_tp2_sa_attn -> layer_0_ep8_tp2_sa_out
	layer_0_ep8_tp3_sa_qkv [label="Self-Attn QKV\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep8_tp3_sa_attn [label="Self-Attn Compute\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep8_tp3_sa_out [label="Self-Attn Output\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep8_tp3_sa_qkv -> layer_0_ep8_tp3_sa_attn
	layer_0_ep8_tp3_sa_attn -> layer_0_ep8_tp3_sa_out
	layer_0_ep9_tp0_sa_qkv [label="Self-Attn QKV\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep9_tp0_sa_attn [label="Self-Attn Compute\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep9_tp0_sa_out [label="Self-Attn Output\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep9_tp0_sa_qkv -> layer_0_ep9_tp0_sa_attn
	layer_0_ep9_tp0_sa_attn -> layer_0_ep9_tp0_sa_out
	layer_0_ep9_tp1_sa_qkv [label="Self-Attn QKV\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep9_tp1_sa_attn [label="Self-Attn Compute\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep9_tp1_sa_out [label="Self-Attn Output\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep9_tp1_sa_qkv -> layer_0_ep9_tp1_sa_attn
	layer_0_ep9_tp1_sa_attn -> layer_0_ep9_tp1_sa_out
	layer_0_ep9_tp2_sa_qkv [label="Self-Attn QKV\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep9_tp2_sa_attn [label="Self-Attn Compute\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep9_tp2_sa_out [label="Self-Attn Output\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep9_tp2_sa_qkv -> layer_0_ep9_tp2_sa_attn
	layer_0_ep9_tp2_sa_attn -> layer_0_ep9_tp2_sa_out
	layer_0_ep9_tp3_sa_qkv [label="Self-Attn QKV\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep9_tp3_sa_attn [label="Self-Attn Compute\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep9_tp3_sa_out [label="Self-Attn Output\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep9_tp3_sa_qkv -> layer_0_ep9_tp3_sa_attn
	layer_0_ep9_tp3_sa_attn -> layer_0_ep9_tp3_sa_out
	layer_0_ep10_tp0_sa_qkv [label="Self-Attn QKV\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep10_tp0_sa_attn [label="Self-Attn Compute\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep10_tp0_sa_out [label="Self-Attn Output\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep10_tp0_sa_qkv -> layer_0_ep10_tp0_sa_attn
	layer_0_ep10_tp0_sa_attn -> layer_0_ep10_tp0_sa_out
	layer_0_ep10_tp1_sa_qkv [label="Self-Attn QKV\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep10_tp1_sa_attn [label="Self-Attn Compute\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep10_tp1_sa_out [label="Self-Attn Output\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep10_tp1_sa_qkv -> layer_0_ep10_tp1_sa_attn
	layer_0_ep10_tp1_sa_attn -> layer_0_ep10_tp1_sa_out
	layer_0_ep10_tp2_sa_qkv [label="Self-Attn QKV\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep10_tp2_sa_attn [label="Self-Attn Compute\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep10_tp2_sa_out [label="Self-Attn Output\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep10_tp2_sa_qkv -> layer_0_ep10_tp2_sa_attn
	layer_0_ep10_tp2_sa_attn -> layer_0_ep10_tp2_sa_out
	layer_0_ep10_tp3_sa_qkv [label="Self-Attn QKV\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep10_tp3_sa_attn [label="Self-Attn Compute\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep10_tp3_sa_out [label="Self-Attn Output\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep10_tp3_sa_qkv -> layer_0_ep10_tp3_sa_attn
	layer_0_ep10_tp3_sa_attn -> layer_0_ep10_tp3_sa_out
	layer_0_ep11_tp0_sa_qkv [label="Self-Attn QKV\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep11_tp0_sa_attn [label="Self-Attn Compute\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep11_tp0_sa_out [label="Self-Attn Output\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep11_tp0_sa_qkv -> layer_0_ep11_tp0_sa_attn
	layer_0_ep11_tp0_sa_attn -> layer_0_ep11_tp0_sa_out
	layer_0_ep11_tp1_sa_qkv [label="Self-Attn QKV\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep11_tp1_sa_attn [label="Self-Attn Compute\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep11_tp1_sa_out [label="Self-Attn Output\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep11_tp1_sa_qkv -> layer_0_ep11_tp1_sa_attn
	layer_0_ep11_tp1_sa_attn -> layer_0_ep11_tp1_sa_out
	layer_0_ep11_tp2_sa_qkv [label="Self-Attn QKV\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep11_tp2_sa_attn [label="Self-Attn Compute\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep11_tp2_sa_out [label="Self-Attn Output\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep11_tp2_sa_qkv -> layer_0_ep11_tp2_sa_attn
	layer_0_ep11_tp2_sa_attn -> layer_0_ep11_tp2_sa_out
	layer_0_ep11_tp3_sa_qkv [label="Self-Attn QKV\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep11_tp3_sa_attn [label="Self-Attn Compute\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep11_tp3_sa_out [label="Self-Attn Output\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep11_tp3_sa_qkv -> layer_0_ep11_tp3_sa_attn
	layer_0_ep11_tp3_sa_attn -> layer_0_ep11_tp3_sa_out
	layer_0_ep12_tp0_sa_qkv [label="Self-Attn QKV\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep12_tp0_sa_attn [label="Self-Attn Compute\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep12_tp0_sa_out [label="Self-Attn Output\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep12_tp0_sa_qkv -> layer_0_ep12_tp0_sa_attn
	layer_0_ep12_tp0_sa_attn -> layer_0_ep12_tp0_sa_out
	layer_0_ep12_tp1_sa_qkv [label="Self-Attn QKV\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep12_tp1_sa_attn [label="Self-Attn Compute\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep12_tp1_sa_out [label="Self-Attn Output\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep12_tp1_sa_qkv -> layer_0_ep12_tp1_sa_attn
	layer_0_ep12_tp1_sa_attn -> layer_0_ep12_tp1_sa_out
	layer_0_ep12_tp2_sa_qkv [label="Self-Attn QKV\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep12_tp2_sa_attn [label="Self-Attn Compute\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep12_tp2_sa_out [label="Self-Attn Output\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep12_tp2_sa_qkv -> layer_0_ep12_tp2_sa_attn
	layer_0_ep12_tp2_sa_attn -> layer_0_ep12_tp2_sa_out
	layer_0_ep12_tp3_sa_qkv [label="Self-Attn QKV\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep12_tp3_sa_attn [label="Self-Attn Compute\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep12_tp3_sa_out [label="Self-Attn Output\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep12_tp3_sa_qkv -> layer_0_ep12_tp3_sa_attn
	layer_0_ep12_tp3_sa_attn -> layer_0_ep12_tp3_sa_out
	layer_0_ep13_tp0_sa_qkv [label="Self-Attn QKV\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep13_tp0_sa_attn [label="Self-Attn Compute\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep13_tp0_sa_out [label="Self-Attn Output\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep13_tp0_sa_qkv -> layer_0_ep13_tp0_sa_attn
	layer_0_ep13_tp0_sa_attn -> layer_0_ep13_tp0_sa_out
	layer_0_ep13_tp1_sa_qkv [label="Self-Attn QKV\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep13_tp1_sa_attn [label="Self-Attn Compute\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep13_tp1_sa_out [label="Self-Attn Output\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep13_tp1_sa_qkv -> layer_0_ep13_tp1_sa_attn
	layer_0_ep13_tp1_sa_attn -> layer_0_ep13_tp1_sa_out
	layer_0_ep13_tp2_sa_qkv [label="Self-Attn QKV\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep13_tp2_sa_attn [label="Self-Attn Compute\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep13_tp2_sa_out [label="Self-Attn Output\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep13_tp2_sa_qkv -> layer_0_ep13_tp2_sa_attn
	layer_0_ep13_tp2_sa_attn -> layer_0_ep13_tp2_sa_out
	layer_0_ep13_tp3_sa_qkv [label="Self-Attn QKV\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep13_tp3_sa_attn [label="Self-Attn Compute\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep13_tp3_sa_out [label="Self-Attn Output\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep13_tp3_sa_qkv -> layer_0_ep13_tp3_sa_attn
	layer_0_ep13_tp3_sa_attn -> layer_0_ep13_tp3_sa_out
	layer_0_ep14_tp0_sa_qkv [label="Self-Attn QKV\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep14_tp0_sa_attn [label="Self-Attn Compute\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep14_tp0_sa_out [label="Self-Attn Output\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep14_tp0_sa_qkv -> layer_0_ep14_tp0_sa_attn
	layer_0_ep14_tp0_sa_attn -> layer_0_ep14_tp0_sa_out
	layer_0_ep14_tp1_sa_qkv [label="Self-Attn QKV\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep14_tp1_sa_attn [label="Self-Attn Compute\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep14_tp1_sa_out [label="Self-Attn Output\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep14_tp1_sa_qkv -> layer_0_ep14_tp1_sa_attn
	layer_0_ep14_tp1_sa_attn -> layer_0_ep14_tp1_sa_out
	layer_0_ep14_tp2_sa_qkv [label="Self-Attn QKV\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep14_tp2_sa_attn [label="Self-Attn Compute\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep14_tp2_sa_out [label="Self-Attn Output\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep14_tp2_sa_qkv -> layer_0_ep14_tp2_sa_attn
	layer_0_ep14_tp2_sa_attn -> layer_0_ep14_tp2_sa_out
	layer_0_ep14_tp3_sa_qkv [label="Self-Attn QKV\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep14_tp3_sa_attn [label="Self-Attn Compute\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep14_tp3_sa_out [label="Self-Attn Output\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep14_tp3_sa_qkv -> layer_0_ep14_tp3_sa_attn
	layer_0_ep14_tp3_sa_attn -> layer_0_ep14_tp3_sa_out
	layer_0_ep15_tp0_sa_qkv [label="Self-Attn QKV\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep15_tp0_sa_attn [label="Self-Attn Compute\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep15_tp0_sa_out [label="Self-Attn Output\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep15_tp0_sa_qkv -> layer_0_ep15_tp0_sa_attn
	layer_0_ep15_tp0_sa_attn -> layer_0_ep15_tp0_sa_out
	layer_0_ep15_tp1_sa_qkv [label="Self-Attn QKV\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep15_tp1_sa_attn [label="Self-Attn Compute\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep15_tp1_sa_out [label="Self-Attn Output\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep15_tp1_sa_qkv -> layer_0_ep15_tp1_sa_attn
	layer_0_ep15_tp1_sa_attn -> layer_0_ep15_tp1_sa_out
	layer_0_ep15_tp2_sa_qkv [label="Self-Attn QKV\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep15_tp2_sa_attn [label="Self-Attn Compute\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep15_tp2_sa_out [label="Self-Attn Output\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep15_tp2_sa_qkv -> layer_0_ep15_tp2_sa_attn
	layer_0_ep15_tp2_sa_attn -> layer_0_ep15_tp2_sa_out
	layer_0_ep15_tp3_sa_qkv [label="Self-Attn QKV\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep15_tp3_sa_attn [label="Self-Attn Compute\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep15_tp3_sa_out [label="Self-Attn Output\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep15_tp3_sa_qkv -> layer_0_ep15_tp3_sa_attn
	layer_0_ep15_tp3_sa_attn -> layer_0_ep15_tp3_sa_out
	layer_0_ep0_tp_allreduce [label="TP All-Reduce\nEP-Group-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_0_ep0_tp0_sa_out -> layer_0_ep0_tp_allreduce
	layer_0_ep0_tp1_sa_out -> layer_0_ep0_tp_allreduce
	layer_0_ep0_tp2_sa_out -> layer_0_ep0_tp_allreduce
	layer_0_ep0_tp3_sa_out -> layer_0_ep0_tp_allreduce
	layer_0_ep1_tp_allreduce [label="TP All-Reduce\nEP-Group-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_0_ep1_tp0_sa_out -> layer_0_ep1_tp_allreduce
	layer_0_ep1_tp1_sa_out -> layer_0_ep1_tp_allreduce
	layer_0_ep1_tp2_sa_out -> layer_0_ep1_tp_allreduce
	layer_0_ep1_tp3_sa_out -> layer_0_ep1_tp_allreduce
	layer_0_ep2_tp_allreduce [label="TP All-Reduce\nEP-Group-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_0_ep2_tp0_sa_out -> layer_0_ep2_tp_allreduce
	layer_0_ep2_tp1_sa_out -> layer_0_ep2_tp_allreduce
	layer_0_ep2_tp2_sa_out -> layer_0_ep2_tp_allreduce
	layer_0_ep2_tp3_sa_out -> layer_0_ep2_tp_allreduce
	layer_0_ep3_tp_allreduce [label="TP All-Reduce\nEP-Group-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_0_ep3_tp0_sa_out -> layer_0_ep3_tp_allreduce
	layer_0_ep3_tp1_sa_out -> layer_0_ep3_tp_allreduce
	layer_0_ep3_tp2_sa_out -> layer_0_ep3_tp_allreduce
	layer_0_ep3_tp3_sa_out -> layer_0_ep3_tp_allreduce
	layer_0_ep4_tp_allreduce [label="TP All-Reduce\nEP-Group-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_0_ep4_tp0_sa_out -> layer_0_ep4_tp_allreduce
	layer_0_ep4_tp1_sa_out -> layer_0_ep4_tp_allreduce
	layer_0_ep4_tp2_sa_out -> layer_0_ep4_tp_allreduce
	layer_0_ep4_tp3_sa_out -> layer_0_ep4_tp_allreduce
	layer_0_ep5_tp_allreduce [label="TP All-Reduce\nEP-Group-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_0_ep5_tp0_sa_out -> layer_0_ep5_tp_allreduce
	layer_0_ep5_tp1_sa_out -> layer_0_ep5_tp_allreduce
	layer_0_ep5_tp2_sa_out -> layer_0_ep5_tp_allreduce
	layer_0_ep5_tp3_sa_out -> layer_0_ep5_tp_allreduce
	layer_0_ep6_tp_allreduce [label="TP All-Reduce\nEP-Group-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_0_ep6_tp0_sa_out -> layer_0_ep6_tp_allreduce
	layer_0_ep6_tp1_sa_out -> layer_0_ep6_tp_allreduce
	layer_0_ep6_tp2_sa_out -> layer_0_ep6_tp_allreduce
	layer_0_ep6_tp3_sa_out -> layer_0_ep6_tp_allreduce
	layer_0_ep7_tp_allreduce [label="TP All-Reduce\nEP-Group-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_0_ep7_tp0_sa_out -> layer_0_ep7_tp_allreduce
	layer_0_ep7_tp1_sa_out -> layer_0_ep7_tp_allreduce
	layer_0_ep7_tp2_sa_out -> layer_0_ep7_tp_allreduce
	layer_0_ep7_tp3_sa_out -> layer_0_ep7_tp_allreduce
	layer_0_ep8_tp_allreduce [label="TP All-Reduce\nEP-Group-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_0_ep8_tp0_sa_out -> layer_0_ep8_tp_allreduce
	layer_0_ep8_tp1_sa_out -> layer_0_ep8_tp_allreduce
	layer_0_ep8_tp2_sa_out -> layer_0_ep8_tp_allreduce
	layer_0_ep8_tp3_sa_out -> layer_0_ep8_tp_allreduce
	layer_0_ep9_tp_allreduce [label="TP All-Reduce\nEP-Group-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_0_ep9_tp0_sa_out -> layer_0_ep9_tp_allreduce
	layer_0_ep9_tp1_sa_out -> layer_0_ep9_tp_allreduce
	layer_0_ep9_tp2_sa_out -> layer_0_ep9_tp_allreduce
	layer_0_ep9_tp3_sa_out -> layer_0_ep9_tp_allreduce
	layer_0_ep10_tp_allreduce [label="TP All-Reduce\nEP-Group-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_0_ep10_tp0_sa_out -> layer_0_ep10_tp_allreduce
	layer_0_ep10_tp1_sa_out -> layer_0_ep10_tp_allreduce
	layer_0_ep10_tp2_sa_out -> layer_0_ep10_tp_allreduce
	layer_0_ep10_tp3_sa_out -> layer_0_ep10_tp_allreduce
	layer_0_ep11_tp_allreduce [label="TP All-Reduce\nEP-Group-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_0_ep11_tp0_sa_out -> layer_0_ep11_tp_allreduce
	layer_0_ep11_tp1_sa_out -> layer_0_ep11_tp_allreduce
	layer_0_ep11_tp2_sa_out -> layer_0_ep11_tp_allreduce
	layer_0_ep11_tp3_sa_out -> layer_0_ep11_tp_allreduce
	layer_0_ep12_tp_allreduce [label="TP All-Reduce\nEP-Group-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_0_ep12_tp0_sa_out -> layer_0_ep12_tp_allreduce
	layer_0_ep12_tp1_sa_out -> layer_0_ep12_tp_allreduce
	layer_0_ep12_tp2_sa_out -> layer_0_ep12_tp_allreduce
	layer_0_ep12_tp3_sa_out -> layer_0_ep12_tp_allreduce
	layer_0_ep13_tp_allreduce [label="TP All-Reduce\nEP-Group-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_0_ep13_tp0_sa_out -> layer_0_ep13_tp_allreduce
	layer_0_ep13_tp1_sa_out -> layer_0_ep13_tp_allreduce
	layer_0_ep13_tp2_sa_out -> layer_0_ep13_tp_allreduce
	layer_0_ep13_tp3_sa_out -> layer_0_ep13_tp_allreduce
	layer_0_ep14_tp_allreduce [label="TP All-Reduce\nEP-Group-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_0_ep14_tp0_sa_out -> layer_0_ep14_tp_allreduce
	layer_0_ep14_tp1_sa_out -> layer_0_ep14_tp_allreduce
	layer_0_ep14_tp2_sa_out -> layer_0_ep14_tp_allreduce
	layer_0_ep14_tp3_sa_out -> layer_0_ep14_tp_allreduce
	layer_0_ep15_tp_allreduce [label="TP All-Reduce\nEP-Group-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_0_ep15_tp0_sa_out -> layer_0_ep15_tp_allreduce
	layer_0_ep15_tp1_sa_out -> layer_0_ep15_tp_allreduce
	layer_0_ep15_tp2_sa_out -> layer_0_ep15_tp_allreduce
	layer_0_ep15_tp3_sa_out -> layer_0_ep15_tp_allreduce
	layer_0_ep0_gate [label="MoE Gate\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_0_ep0_expert_0 [label="Expert-0\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep0_gate -> layer_0_ep0_expert_0 [label="select tokens" style=dashed]
	layer_0_ep0_expert_1 [label="Expert-1\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep0_gate -> layer_0_ep0_expert_1 [label="select tokens" style=dashed]
	layer_0_ep0_expert_2 [label="Expert-2\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep0_gate -> layer_0_ep0_expert_2 [label="select tokens" style=dashed]
	layer_0_ep0_expert_3 [label="Expert-3\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep0_gate -> layer_0_ep0_expert_3 [label="select tokens" style=dashed]
	layer_0_ep0_expert_aggr [label="Expert Aggregation\nEP-Group-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_0_ep0_expert_0 -> layer_0_ep0_expert_aggr
	layer_0_ep0_expert_1 -> layer_0_ep0_expert_aggr
	layer_0_ep0_expert_2 -> layer_0_ep0_expert_aggr
	layer_0_ep0_expert_3 -> layer_0_ep0_expert_aggr
	layer_0_ep1_gate [label="MoE Gate\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_0_ep1_expert_0 [label="Expert-0\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep1_gate -> layer_0_ep1_expert_0 [label="select tokens" style=dashed]
	layer_0_ep1_expert_1 [label="Expert-1\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep1_gate -> layer_0_ep1_expert_1 [label="select tokens" style=dashed]
	layer_0_ep1_expert_2 [label="Expert-2\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep1_gate -> layer_0_ep1_expert_2 [label="select tokens" style=dashed]
	layer_0_ep1_expert_3 [label="Expert-3\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep1_gate -> layer_0_ep1_expert_3 [label="select tokens" style=dashed]
	layer_0_ep1_expert_aggr [label="Expert Aggregation\nEP-Group-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_0_ep1_expert_0 -> layer_0_ep1_expert_aggr
	layer_0_ep1_expert_1 -> layer_0_ep1_expert_aggr
	layer_0_ep1_expert_2 -> layer_0_ep1_expert_aggr
	layer_0_ep1_expert_3 -> layer_0_ep1_expert_aggr
	layer_0_ep2_gate [label="MoE Gate\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_0_ep2_expert_0 [label="Expert-0\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep2_gate -> layer_0_ep2_expert_0 [label="select tokens" style=dashed]
	layer_0_ep2_expert_1 [label="Expert-1\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep2_gate -> layer_0_ep2_expert_1 [label="select tokens" style=dashed]
	layer_0_ep2_expert_2 [label="Expert-2\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep2_gate -> layer_0_ep2_expert_2 [label="select tokens" style=dashed]
	layer_0_ep2_expert_3 [label="Expert-3\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep2_gate -> layer_0_ep2_expert_3 [label="select tokens" style=dashed]
	layer_0_ep2_expert_aggr [label="Expert Aggregation\nEP-Group-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_0_ep2_expert_0 -> layer_0_ep2_expert_aggr
	layer_0_ep2_expert_1 -> layer_0_ep2_expert_aggr
	layer_0_ep2_expert_2 -> layer_0_ep2_expert_aggr
	layer_0_ep2_expert_3 -> layer_0_ep2_expert_aggr
	layer_0_ep3_gate [label="MoE Gate\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_0_ep3_expert_0 [label="Expert-0\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep3_gate -> layer_0_ep3_expert_0 [label="select tokens" style=dashed]
	layer_0_ep3_expert_1 [label="Expert-1\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep3_gate -> layer_0_ep3_expert_1 [label="select tokens" style=dashed]
	layer_0_ep3_expert_2 [label="Expert-2\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep3_gate -> layer_0_ep3_expert_2 [label="select tokens" style=dashed]
	layer_0_ep3_expert_3 [label="Expert-3\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep3_gate -> layer_0_ep3_expert_3 [label="select tokens" style=dashed]
	layer_0_ep3_expert_aggr [label="Expert Aggregation\nEP-Group-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_0_ep3_expert_0 -> layer_0_ep3_expert_aggr
	layer_0_ep3_expert_1 -> layer_0_ep3_expert_aggr
	layer_0_ep3_expert_2 -> layer_0_ep3_expert_aggr
	layer_0_ep3_expert_3 -> layer_0_ep3_expert_aggr
	layer_0_ep4_gate [label="MoE Gate\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_0_ep4_expert_0 [label="Expert-0\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep4_gate -> layer_0_ep4_expert_0 [label="select tokens" style=dashed]
	layer_0_ep4_expert_1 [label="Expert-1\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep4_gate -> layer_0_ep4_expert_1 [label="select tokens" style=dashed]
	layer_0_ep4_expert_2 [label="Expert-2\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep4_gate -> layer_0_ep4_expert_2 [label="select tokens" style=dashed]
	layer_0_ep4_expert_3 [label="Expert-3\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep4_gate -> layer_0_ep4_expert_3 [label="select tokens" style=dashed]
	layer_0_ep4_expert_aggr [label="Expert Aggregation\nEP-Group-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_0_ep4_expert_0 -> layer_0_ep4_expert_aggr
	layer_0_ep4_expert_1 -> layer_0_ep4_expert_aggr
	layer_0_ep4_expert_2 -> layer_0_ep4_expert_aggr
	layer_0_ep4_expert_3 -> layer_0_ep4_expert_aggr
	layer_0_ep5_gate [label="MoE Gate\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_0_ep5_expert_0 [label="Expert-0\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep5_gate -> layer_0_ep5_expert_0 [label="select tokens" style=dashed]
	layer_0_ep5_expert_1 [label="Expert-1\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep5_gate -> layer_0_ep5_expert_1 [label="select tokens" style=dashed]
	layer_0_ep5_expert_2 [label="Expert-2\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep5_gate -> layer_0_ep5_expert_2 [label="select tokens" style=dashed]
	layer_0_ep5_expert_3 [label="Expert-3\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep5_gate -> layer_0_ep5_expert_3 [label="select tokens" style=dashed]
	layer_0_ep5_expert_aggr [label="Expert Aggregation\nEP-Group-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_0_ep5_expert_0 -> layer_0_ep5_expert_aggr
	layer_0_ep5_expert_1 -> layer_0_ep5_expert_aggr
	layer_0_ep5_expert_2 -> layer_0_ep5_expert_aggr
	layer_0_ep5_expert_3 -> layer_0_ep5_expert_aggr
	layer_0_ep6_gate [label="MoE Gate\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_0_ep6_expert_0 [label="Expert-0\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep6_gate -> layer_0_ep6_expert_0 [label="select tokens" style=dashed]
	layer_0_ep6_expert_1 [label="Expert-1\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep6_gate -> layer_0_ep6_expert_1 [label="select tokens" style=dashed]
	layer_0_ep6_expert_2 [label="Expert-2\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep6_gate -> layer_0_ep6_expert_2 [label="select tokens" style=dashed]
	layer_0_ep6_expert_3 [label="Expert-3\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep6_gate -> layer_0_ep6_expert_3 [label="select tokens" style=dashed]
	layer_0_ep6_expert_aggr [label="Expert Aggregation\nEP-Group-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_0_ep6_expert_0 -> layer_0_ep6_expert_aggr
	layer_0_ep6_expert_1 -> layer_0_ep6_expert_aggr
	layer_0_ep6_expert_2 -> layer_0_ep6_expert_aggr
	layer_0_ep6_expert_3 -> layer_0_ep6_expert_aggr
	layer_0_ep7_gate [label="MoE Gate\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_0_ep7_expert_0 [label="Expert-0\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep7_gate -> layer_0_ep7_expert_0 [label="select tokens" style=dashed]
	layer_0_ep7_expert_1 [label="Expert-1\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep7_gate -> layer_0_ep7_expert_1 [label="select tokens" style=dashed]
	layer_0_ep7_expert_2 [label="Expert-2\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep7_gate -> layer_0_ep7_expert_2 [label="select tokens" style=dashed]
	layer_0_ep7_expert_3 [label="Expert-3\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep7_gate -> layer_0_ep7_expert_3 [label="select tokens" style=dashed]
	layer_0_ep7_expert_aggr [label="Expert Aggregation\nEP-Group-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_0_ep7_expert_0 -> layer_0_ep7_expert_aggr
	layer_0_ep7_expert_1 -> layer_0_ep7_expert_aggr
	layer_0_ep7_expert_2 -> layer_0_ep7_expert_aggr
	layer_0_ep7_expert_3 -> layer_0_ep7_expert_aggr
	layer_0_ep8_gate [label="MoE Gate\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_0_ep8_expert_0 [label="Expert-0\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep8_gate -> layer_0_ep8_expert_0 [label="select tokens" style=dashed]
	layer_0_ep8_expert_1 [label="Expert-1\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep8_gate -> layer_0_ep8_expert_1 [label="select tokens" style=dashed]
	layer_0_ep8_expert_2 [label="Expert-2\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep8_gate -> layer_0_ep8_expert_2 [label="select tokens" style=dashed]
	layer_0_ep8_expert_3 [label="Expert-3\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep8_gate -> layer_0_ep8_expert_3 [label="select tokens" style=dashed]
	layer_0_ep8_expert_aggr [label="Expert Aggregation\nEP-Group-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_0_ep8_expert_0 -> layer_0_ep8_expert_aggr
	layer_0_ep8_expert_1 -> layer_0_ep8_expert_aggr
	layer_0_ep8_expert_2 -> layer_0_ep8_expert_aggr
	layer_0_ep8_expert_3 -> layer_0_ep8_expert_aggr
	layer_0_ep9_gate [label="MoE Gate\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_0_ep9_expert_0 [label="Expert-0\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep9_gate -> layer_0_ep9_expert_0 [label="select tokens" style=dashed]
	layer_0_ep9_expert_1 [label="Expert-1\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep9_gate -> layer_0_ep9_expert_1 [label="select tokens" style=dashed]
	layer_0_ep9_expert_2 [label="Expert-2\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep9_gate -> layer_0_ep9_expert_2 [label="select tokens" style=dashed]
	layer_0_ep9_expert_3 [label="Expert-3\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep9_gate -> layer_0_ep9_expert_3 [label="select tokens" style=dashed]
	layer_0_ep9_expert_aggr [label="Expert Aggregation\nEP-Group-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_0_ep9_expert_0 -> layer_0_ep9_expert_aggr
	layer_0_ep9_expert_1 -> layer_0_ep9_expert_aggr
	layer_0_ep9_expert_2 -> layer_0_ep9_expert_aggr
	layer_0_ep9_expert_3 -> layer_0_ep9_expert_aggr
	layer_0_ep10_gate [label="MoE Gate\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_0_ep10_expert_0 [label="Expert-0\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep10_gate -> layer_0_ep10_expert_0 [label="select tokens" style=dashed]
	layer_0_ep10_expert_1 [label="Expert-1\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep10_gate -> layer_0_ep10_expert_1 [label="select tokens" style=dashed]
	layer_0_ep10_expert_2 [label="Expert-2\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep10_gate -> layer_0_ep10_expert_2 [label="select tokens" style=dashed]
	layer_0_ep10_expert_3 [label="Expert-3\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep10_gate -> layer_0_ep10_expert_3 [label="select tokens" style=dashed]
	layer_0_ep10_expert_aggr [label="Expert Aggregation\nEP-Group-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_0_ep10_expert_0 -> layer_0_ep10_expert_aggr
	layer_0_ep10_expert_1 -> layer_0_ep10_expert_aggr
	layer_0_ep10_expert_2 -> layer_0_ep10_expert_aggr
	layer_0_ep10_expert_3 -> layer_0_ep10_expert_aggr
	layer_0_ep11_gate [label="MoE Gate\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_0_ep11_expert_0 [label="Expert-0\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep11_gate -> layer_0_ep11_expert_0 [label="select tokens" style=dashed]
	layer_0_ep11_expert_1 [label="Expert-1\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep11_gate -> layer_0_ep11_expert_1 [label="select tokens" style=dashed]
	layer_0_ep11_expert_2 [label="Expert-2\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep11_gate -> layer_0_ep11_expert_2 [label="select tokens" style=dashed]
	layer_0_ep11_expert_3 [label="Expert-3\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep11_gate -> layer_0_ep11_expert_3 [label="select tokens" style=dashed]
	layer_0_ep11_expert_aggr [label="Expert Aggregation\nEP-Group-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_0_ep11_expert_0 -> layer_0_ep11_expert_aggr
	layer_0_ep11_expert_1 -> layer_0_ep11_expert_aggr
	layer_0_ep11_expert_2 -> layer_0_ep11_expert_aggr
	layer_0_ep11_expert_3 -> layer_0_ep11_expert_aggr
	layer_0_ep12_gate [label="MoE Gate\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_0_ep12_expert_0 [label="Expert-0\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep12_gate -> layer_0_ep12_expert_0 [label="select tokens" style=dashed]
	layer_0_ep12_expert_1 [label="Expert-1\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep12_gate -> layer_0_ep12_expert_1 [label="select tokens" style=dashed]
	layer_0_ep12_expert_2 [label="Expert-2\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep12_gate -> layer_0_ep12_expert_2 [label="select tokens" style=dashed]
	layer_0_ep12_expert_3 [label="Expert-3\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep12_gate -> layer_0_ep12_expert_3 [label="select tokens" style=dashed]
	layer_0_ep12_expert_aggr [label="Expert Aggregation\nEP-Group-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_0_ep12_expert_0 -> layer_0_ep12_expert_aggr
	layer_0_ep12_expert_1 -> layer_0_ep12_expert_aggr
	layer_0_ep12_expert_2 -> layer_0_ep12_expert_aggr
	layer_0_ep12_expert_3 -> layer_0_ep12_expert_aggr
	layer_0_ep13_gate [label="MoE Gate\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_0_ep13_expert_0 [label="Expert-0\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep13_gate -> layer_0_ep13_expert_0 [label="select tokens" style=dashed]
	layer_0_ep13_expert_1 [label="Expert-1\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep13_gate -> layer_0_ep13_expert_1 [label="select tokens" style=dashed]
	layer_0_ep13_expert_2 [label="Expert-2\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep13_gate -> layer_0_ep13_expert_2 [label="select tokens" style=dashed]
	layer_0_ep13_expert_3 [label="Expert-3\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep13_gate -> layer_0_ep13_expert_3 [label="select tokens" style=dashed]
	layer_0_ep13_expert_aggr [label="Expert Aggregation\nEP-Group-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_0_ep13_expert_0 -> layer_0_ep13_expert_aggr
	layer_0_ep13_expert_1 -> layer_0_ep13_expert_aggr
	layer_0_ep13_expert_2 -> layer_0_ep13_expert_aggr
	layer_0_ep13_expert_3 -> layer_0_ep13_expert_aggr
	layer_0_ep14_gate [label="MoE Gate\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_0_ep14_expert_0 [label="Expert-0\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep14_gate -> layer_0_ep14_expert_0 [label="select tokens" style=dashed]
	layer_0_ep14_expert_1 [label="Expert-1\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep14_gate -> layer_0_ep14_expert_1 [label="select tokens" style=dashed]
	layer_0_ep14_expert_2 [label="Expert-2\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep14_gate -> layer_0_ep14_expert_2 [label="select tokens" style=dashed]
	layer_0_ep14_expert_3 [label="Expert-3\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep14_gate -> layer_0_ep14_expert_3 [label="select tokens" style=dashed]
	layer_0_ep14_expert_aggr [label="Expert Aggregation\nEP-Group-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_0_ep14_expert_0 -> layer_0_ep14_expert_aggr
	layer_0_ep14_expert_1 -> layer_0_ep14_expert_aggr
	layer_0_ep14_expert_2 -> layer_0_ep14_expert_aggr
	layer_0_ep14_expert_3 -> layer_0_ep14_expert_aggr
	layer_0_ep15_gate [label="MoE Gate\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_0_ep15_expert_0 [label="Expert-0\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep15_gate -> layer_0_ep15_expert_0 [label="select tokens" style=dashed]
	layer_0_ep15_expert_1 [label="Expert-1\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep15_gate -> layer_0_ep15_expert_1 [label="select tokens" style=dashed]
	layer_0_ep15_expert_2 [label="Expert-2\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep15_gate -> layer_0_ep15_expert_2 [label="select tokens" style=dashed]
	layer_0_ep15_expert_3 [label="Expert-3\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_0_ep15_gate -> layer_0_ep15_expert_3 [label="select tokens" style=dashed]
	layer_0_ep15_expert_aggr [label="Expert Aggregation\nEP-Group-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_0_ep15_expert_0 -> layer_0_ep15_expert_aggr
	layer_0_ep15_expert_1 -> layer_0_ep15_expert_aggr
	layer_0_ep15_expert_2 -> layer_0_ep15_expert_aggr
	layer_0_ep15_expert_3 -> layer_0_ep15_expert_aggr
	layer_0_to_1_ep0_pp [label="Pipeline Stage Transfer\nEP-Group-0\nLayer-0 to Layer-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_0_ep0_expert_aggr -> layer_0_to_1_ep0_pp
	layer_0_to_1_ep1_pp [label="Pipeline Stage Transfer\nEP-Group-1\nLayer-0 to Layer-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_0_ep1_expert_aggr -> layer_0_to_1_ep1_pp
	layer_0_to_1_ep2_pp [label="Pipeline Stage Transfer\nEP-Group-2\nLayer-0 to Layer-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_0_ep2_expert_aggr -> layer_0_to_1_ep2_pp
	layer_0_to_1_ep3_pp [label="Pipeline Stage Transfer\nEP-Group-3\nLayer-0 to Layer-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_0_ep3_expert_aggr -> layer_0_to_1_ep3_pp
	layer_0_to_1_ep4_pp [label="Pipeline Stage Transfer\nEP-Group-4\nLayer-0 to Layer-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_0_ep4_expert_aggr -> layer_0_to_1_ep4_pp
	layer_0_to_1_ep5_pp [label="Pipeline Stage Transfer\nEP-Group-5\nLayer-0 to Layer-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_0_ep5_expert_aggr -> layer_0_to_1_ep5_pp
	layer_0_to_1_ep6_pp [label="Pipeline Stage Transfer\nEP-Group-6\nLayer-0 to Layer-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_0_ep6_expert_aggr -> layer_0_to_1_ep6_pp
	layer_0_to_1_ep7_pp [label="Pipeline Stage Transfer\nEP-Group-7\nLayer-0 to Layer-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_0_ep7_expert_aggr -> layer_0_to_1_ep7_pp
	layer_0_to_1_ep8_pp [label="Pipeline Stage Transfer\nEP-Group-8\nLayer-0 to Layer-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_0_ep8_expert_aggr -> layer_0_to_1_ep8_pp
	layer_0_to_1_ep9_pp [label="Pipeline Stage Transfer\nEP-Group-9\nLayer-0 to Layer-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_0_ep9_expert_aggr -> layer_0_to_1_ep9_pp
	layer_0_to_1_ep10_pp [label="Pipeline Stage Transfer\nEP-Group-10\nLayer-0 to Layer-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_0_ep10_expert_aggr -> layer_0_to_1_ep10_pp
	layer_0_to_1_ep11_pp [label="Pipeline Stage Transfer\nEP-Group-11\nLayer-0 to Layer-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_0_ep11_expert_aggr -> layer_0_to_1_ep11_pp
	layer_0_to_1_ep12_pp [label="Pipeline Stage Transfer\nEP-Group-12\nLayer-0 to Layer-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_0_ep12_expert_aggr -> layer_0_to_1_ep12_pp
	layer_0_to_1_ep13_pp [label="Pipeline Stage Transfer\nEP-Group-13\nLayer-0 to Layer-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_0_ep13_expert_aggr -> layer_0_to_1_ep13_pp
	layer_0_to_1_ep14_pp [label="Pipeline Stage Transfer\nEP-Group-14\nLayer-0 to Layer-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_0_ep14_expert_aggr -> layer_0_to_1_ep14_pp
	layer_0_to_1_ep15_pp [label="Pipeline Stage Transfer\nEP-Group-15\nLayer-0 to Layer-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_0_ep15_expert_aggr -> layer_0_to_1_ep15_pp
	layer_1_ep0_tp0_sa_qkv [label="Self-Attn QKV\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep0_tp0_sa_attn [label="Self-Attn Compute\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep0_tp0_sa_out [label="Self-Attn Output\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep0_tp0_sa_qkv -> layer_1_ep0_tp0_sa_attn
	layer_1_ep0_tp0_sa_attn -> layer_1_ep0_tp0_sa_out
	layer_1_ep0_tp1_sa_qkv [label="Self-Attn QKV\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep0_tp1_sa_attn [label="Self-Attn Compute\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep0_tp1_sa_out [label="Self-Attn Output\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep0_tp1_sa_qkv -> layer_1_ep0_tp1_sa_attn
	layer_1_ep0_tp1_sa_attn -> layer_1_ep0_tp1_sa_out
	layer_1_ep0_tp2_sa_qkv [label="Self-Attn QKV\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep0_tp2_sa_attn [label="Self-Attn Compute\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep0_tp2_sa_out [label="Self-Attn Output\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep0_tp2_sa_qkv -> layer_1_ep0_tp2_sa_attn
	layer_1_ep0_tp2_sa_attn -> layer_1_ep0_tp2_sa_out
	layer_1_ep0_tp3_sa_qkv [label="Self-Attn QKV\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep0_tp3_sa_attn [label="Self-Attn Compute\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep0_tp3_sa_out [label="Self-Attn Output\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep0_tp3_sa_qkv -> layer_1_ep0_tp3_sa_attn
	layer_1_ep0_tp3_sa_attn -> layer_1_ep0_tp3_sa_out
	layer_1_ep1_tp0_sa_qkv [label="Self-Attn QKV\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep1_tp0_sa_attn [label="Self-Attn Compute\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep1_tp0_sa_out [label="Self-Attn Output\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep1_tp0_sa_qkv -> layer_1_ep1_tp0_sa_attn
	layer_1_ep1_tp0_sa_attn -> layer_1_ep1_tp0_sa_out
	layer_1_ep1_tp1_sa_qkv [label="Self-Attn QKV\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep1_tp1_sa_attn [label="Self-Attn Compute\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep1_tp1_sa_out [label="Self-Attn Output\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep1_tp1_sa_qkv -> layer_1_ep1_tp1_sa_attn
	layer_1_ep1_tp1_sa_attn -> layer_1_ep1_tp1_sa_out
	layer_1_ep1_tp2_sa_qkv [label="Self-Attn QKV\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep1_tp2_sa_attn [label="Self-Attn Compute\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep1_tp2_sa_out [label="Self-Attn Output\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep1_tp2_sa_qkv -> layer_1_ep1_tp2_sa_attn
	layer_1_ep1_tp2_sa_attn -> layer_1_ep1_tp2_sa_out
	layer_1_ep1_tp3_sa_qkv [label="Self-Attn QKV\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep1_tp3_sa_attn [label="Self-Attn Compute\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep1_tp3_sa_out [label="Self-Attn Output\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep1_tp3_sa_qkv -> layer_1_ep1_tp3_sa_attn
	layer_1_ep1_tp3_sa_attn -> layer_1_ep1_tp3_sa_out
	layer_1_ep2_tp0_sa_qkv [label="Self-Attn QKV\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep2_tp0_sa_attn [label="Self-Attn Compute\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep2_tp0_sa_out [label="Self-Attn Output\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep2_tp0_sa_qkv -> layer_1_ep2_tp0_sa_attn
	layer_1_ep2_tp0_sa_attn -> layer_1_ep2_tp0_sa_out
	layer_1_ep2_tp1_sa_qkv [label="Self-Attn QKV\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep2_tp1_sa_attn [label="Self-Attn Compute\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep2_tp1_sa_out [label="Self-Attn Output\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep2_tp1_sa_qkv -> layer_1_ep2_tp1_sa_attn
	layer_1_ep2_tp1_sa_attn -> layer_1_ep2_tp1_sa_out
	layer_1_ep2_tp2_sa_qkv [label="Self-Attn QKV\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep2_tp2_sa_attn [label="Self-Attn Compute\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep2_tp2_sa_out [label="Self-Attn Output\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep2_tp2_sa_qkv -> layer_1_ep2_tp2_sa_attn
	layer_1_ep2_tp2_sa_attn -> layer_1_ep2_tp2_sa_out
	layer_1_ep2_tp3_sa_qkv [label="Self-Attn QKV\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep2_tp3_sa_attn [label="Self-Attn Compute\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep2_tp3_sa_out [label="Self-Attn Output\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep2_tp3_sa_qkv -> layer_1_ep2_tp3_sa_attn
	layer_1_ep2_tp3_sa_attn -> layer_1_ep2_tp3_sa_out
	layer_1_ep3_tp0_sa_qkv [label="Self-Attn QKV\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep3_tp0_sa_attn [label="Self-Attn Compute\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep3_tp0_sa_out [label="Self-Attn Output\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep3_tp0_sa_qkv -> layer_1_ep3_tp0_sa_attn
	layer_1_ep3_tp0_sa_attn -> layer_1_ep3_tp0_sa_out
	layer_1_ep3_tp1_sa_qkv [label="Self-Attn QKV\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep3_tp1_sa_attn [label="Self-Attn Compute\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep3_tp1_sa_out [label="Self-Attn Output\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep3_tp1_sa_qkv -> layer_1_ep3_tp1_sa_attn
	layer_1_ep3_tp1_sa_attn -> layer_1_ep3_tp1_sa_out
	layer_1_ep3_tp2_sa_qkv [label="Self-Attn QKV\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep3_tp2_sa_attn [label="Self-Attn Compute\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep3_tp2_sa_out [label="Self-Attn Output\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep3_tp2_sa_qkv -> layer_1_ep3_tp2_sa_attn
	layer_1_ep3_tp2_sa_attn -> layer_1_ep3_tp2_sa_out
	layer_1_ep3_tp3_sa_qkv [label="Self-Attn QKV\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep3_tp3_sa_attn [label="Self-Attn Compute\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep3_tp3_sa_out [label="Self-Attn Output\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep3_tp3_sa_qkv -> layer_1_ep3_tp3_sa_attn
	layer_1_ep3_tp3_sa_attn -> layer_1_ep3_tp3_sa_out
	layer_1_ep4_tp0_sa_qkv [label="Self-Attn QKV\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep4_tp0_sa_attn [label="Self-Attn Compute\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep4_tp0_sa_out [label="Self-Attn Output\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep4_tp0_sa_qkv -> layer_1_ep4_tp0_sa_attn
	layer_1_ep4_tp0_sa_attn -> layer_1_ep4_tp0_sa_out
	layer_1_ep4_tp1_sa_qkv [label="Self-Attn QKV\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep4_tp1_sa_attn [label="Self-Attn Compute\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep4_tp1_sa_out [label="Self-Attn Output\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep4_tp1_sa_qkv -> layer_1_ep4_tp1_sa_attn
	layer_1_ep4_tp1_sa_attn -> layer_1_ep4_tp1_sa_out
	layer_1_ep4_tp2_sa_qkv [label="Self-Attn QKV\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep4_tp2_sa_attn [label="Self-Attn Compute\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep4_tp2_sa_out [label="Self-Attn Output\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep4_tp2_sa_qkv -> layer_1_ep4_tp2_sa_attn
	layer_1_ep4_tp2_sa_attn -> layer_1_ep4_tp2_sa_out
	layer_1_ep4_tp3_sa_qkv [label="Self-Attn QKV\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep4_tp3_sa_attn [label="Self-Attn Compute\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep4_tp3_sa_out [label="Self-Attn Output\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep4_tp3_sa_qkv -> layer_1_ep4_tp3_sa_attn
	layer_1_ep4_tp3_sa_attn -> layer_1_ep4_tp3_sa_out
	layer_1_ep5_tp0_sa_qkv [label="Self-Attn QKV\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep5_tp0_sa_attn [label="Self-Attn Compute\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep5_tp0_sa_out [label="Self-Attn Output\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep5_tp0_sa_qkv -> layer_1_ep5_tp0_sa_attn
	layer_1_ep5_tp0_sa_attn -> layer_1_ep5_tp0_sa_out
	layer_1_ep5_tp1_sa_qkv [label="Self-Attn QKV\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep5_tp1_sa_attn [label="Self-Attn Compute\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep5_tp1_sa_out [label="Self-Attn Output\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep5_tp1_sa_qkv -> layer_1_ep5_tp1_sa_attn
	layer_1_ep5_tp1_sa_attn -> layer_1_ep5_tp1_sa_out
	layer_1_ep5_tp2_sa_qkv [label="Self-Attn QKV\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep5_tp2_sa_attn [label="Self-Attn Compute\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep5_tp2_sa_out [label="Self-Attn Output\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep5_tp2_sa_qkv -> layer_1_ep5_tp2_sa_attn
	layer_1_ep5_tp2_sa_attn -> layer_1_ep5_tp2_sa_out
	layer_1_ep5_tp3_sa_qkv [label="Self-Attn QKV\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep5_tp3_sa_attn [label="Self-Attn Compute\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep5_tp3_sa_out [label="Self-Attn Output\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep5_tp3_sa_qkv -> layer_1_ep5_tp3_sa_attn
	layer_1_ep5_tp3_sa_attn -> layer_1_ep5_tp3_sa_out
	layer_1_ep6_tp0_sa_qkv [label="Self-Attn QKV\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep6_tp0_sa_attn [label="Self-Attn Compute\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep6_tp0_sa_out [label="Self-Attn Output\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep6_tp0_sa_qkv -> layer_1_ep6_tp0_sa_attn
	layer_1_ep6_tp0_sa_attn -> layer_1_ep6_tp0_sa_out
	layer_1_ep6_tp1_sa_qkv [label="Self-Attn QKV\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep6_tp1_sa_attn [label="Self-Attn Compute\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep6_tp1_sa_out [label="Self-Attn Output\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep6_tp1_sa_qkv -> layer_1_ep6_tp1_sa_attn
	layer_1_ep6_tp1_sa_attn -> layer_1_ep6_tp1_sa_out
	layer_1_ep6_tp2_sa_qkv [label="Self-Attn QKV\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep6_tp2_sa_attn [label="Self-Attn Compute\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep6_tp2_sa_out [label="Self-Attn Output\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep6_tp2_sa_qkv -> layer_1_ep6_tp2_sa_attn
	layer_1_ep6_tp2_sa_attn -> layer_1_ep6_tp2_sa_out
	layer_1_ep6_tp3_sa_qkv [label="Self-Attn QKV\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep6_tp3_sa_attn [label="Self-Attn Compute\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep6_tp3_sa_out [label="Self-Attn Output\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep6_tp3_sa_qkv -> layer_1_ep6_tp3_sa_attn
	layer_1_ep6_tp3_sa_attn -> layer_1_ep6_tp3_sa_out
	layer_1_ep7_tp0_sa_qkv [label="Self-Attn QKV\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep7_tp0_sa_attn [label="Self-Attn Compute\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep7_tp0_sa_out [label="Self-Attn Output\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep7_tp0_sa_qkv -> layer_1_ep7_tp0_sa_attn
	layer_1_ep7_tp0_sa_attn -> layer_1_ep7_tp0_sa_out
	layer_1_ep7_tp1_sa_qkv [label="Self-Attn QKV\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep7_tp1_sa_attn [label="Self-Attn Compute\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep7_tp1_sa_out [label="Self-Attn Output\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep7_tp1_sa_qkv -> layer_1_ep7_tp1_sa_attn
	layer_1_ep7_tp1_sa_attn -> layer_1_ep7_tp1_sa_out
	layer_1_ep7_tp2_sa_qkv [label="Self-Attn QKV\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep7_tp2_sa_attn [label="Self-Attn Compute\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep7_tp2_sa_out [label="Self-Attn Output\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep7_tp2_sa_qkv -> layer_1_ep7_tp2_sa_attn
	layer_1_ep7_tp2_sa_attn -> layer_1_ep7_tp2_sa_out
	layer_1_ep7_tp3_sa_qkv [label="Self-Attn QKV\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep7_tp3_sa_attn [label="Self-Attn Compute\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep7_tp3_sa_out [label="Self-Attn Output\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep7_tp3_sa_qkv -> layer_1_ep7_tp3_sa_attn
	layer_1_ep7_tp3_sa_attn -> layer_1_ep7_tp3_sa_out
	layer_1_ep8_tp0_sa_qkv [label="Self-Attn QKV\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep8_tp0_sa_attn [label="Self-Attn Compute\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep8_tp0_sa_out [label="Self-Attn Output\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep8_tp0_sa_qkv -> layer_1_ep8_tp0_sa_attn
	layer_1_ep8_tp0_sa_attn -> layer_1_ep8_tp0_sa_out
	layer_1_ep8_tp1_sa_qkv [label="Self-Attn QKV\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep8_tp1_sa_attn [label="Self-Attn Compute\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep8_tp1_sa_out [label="Self-Attn Output\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep8_tp1_sa_qkv -> layer_1_ep8_tp1_sa_attn
	layer_1_ep8_tp1_sa_attn -> layer_1_ep8_tp1_sa_out
	layer_1_ep8_tp2_sa_qkv [label="Self-Attn QKV\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep8_tp2_sa_attn [label="Self-Attn Compute\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep8_tp2_sa_out [label="Self-Attn Output\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep8_tp2_sa_qkv -> layer_1_ep8_tp2_sa_attn
	layer_1_ep8_tp2_sa_attn -> layer_1_ep8_tp2_sa_out
	layer_1_ep8_tp3_sa_qkv [label="Self-Attn QKV\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep8_tp3_sa_attn [label="Self-Attn Compute\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep8_tp3_sa_out [label="Self-Attn Output\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep8_tp3_sa_qkv -> layer_1_ep8_tp3_sa_attn
	layer_1_ep8_tp3_sa_attn -> layer_1_ep8_tp3_sa_out
	layer_1_ep9_tp0_sa_qkv [label="Self-Attn QKV\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep9_tp0_sa_attn [label="Self-Attn Compute\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep9_tp0_sa_out [label="Self-Attn Output\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep9_tp0_sa_qkv -> layer_1_ep9_tp0_sa_attn
	layer_1_ep9_tp0_sa_attn -> layer_1_ep9_tp0_sa_out
	layer_1_ep9_tp1_sa_qkv [label="Self-Attn QKV\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep9_tp1_sa_attn [label="Self-Attn Compute\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep9_tp1_sa_out [label="Self-Attn Output\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep9_tp1_sa_qkv -> layer_1_ep9_tp1_sa_attn
	layer_1_ep9_tp1_sa_attn -> layer_1_ep9_tp1_sa_out
	layer_1_ep9_tp2_sa_qkv [label="Self-Attn QKV\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep9_tp2_sa_attn [label="Self-Attn Compute\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep9_tp2_sa_out [label="Self-Attn Output\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep9_tp2_sa_qkv -> layer_1_ep9_tp2_sa_attn
	layer_1_ep9_tp2_sa_attn -> layer_1_ep9_tp2_sa_out
	layer_1_ep9_tp3_sa_qkv [label="Self-Attn QKV\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep9_tp3_sa_attn [label="Self-Attn Compute\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep9_tp3_sa_out [label="Self-Attn Output\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep9_tp3_sa_qkv -> layer_1_ep9_tp3_sa_attn
	layer_1_ep9_tp3_sa_attn -> layer_1_ep9_tp3_sa_out
	layer_1_ep10_tp0_sa_qkv [label="Self-Attn QKV\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep10_tp0_sa_attn [label="Self-Attn Compute\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep10_tp0_sa_out [label="Self-Attn Output\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep10_tp0_sa_qkv -> layer_1_ep10_tp0_sa_attn
	layer_1_ep10_tp0_sa_attn -> layer_1_ep10_tp0_sa_out
	layer_1_ep10_tp1_sa_qkv [label="Self-Attn QKV\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep10_tp1_sa_attn [label="Self-Attn Compute\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep10_tp1_sa_out [label="Self-Attn Output\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep10_tp1_sa_qkv -> layer_1_ep10_tp1_sa_attn
	layer_1_ep10_tp1_sa_attn -> layer_1_ep10_tp1_sa_out
	layer_1_ep10_tp2_sa_qkv [label="Self-Attn QKV\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep10_tp2_sa_attn [label="Self-Attn Compute\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep10_tp2_sa_out [label="Self-Attn Output\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep10_tp2_sa_qkv -> layer_1_ep10_tp2_sa_attn
	layer_1_ep10_tp2_sa_attn -> layer_1_ep10_tp2_sa_out
	layer_1_ep10_tp3_sa_qkv [label="Self-Attn QKV\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep10_tp3_sa_attn [label="Self-Attn Compute\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep10_tp3_sa_out [label="Self-Attn Output\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep10_tp3_sa_qkv -> layer_1_ep10_tp3_sa_attn
	layer_1_ep10_tp3_sa_attn -> layer_1_ep10_tp3_sa_out
	layer_1_ep11_tp0_sa_qkv [label="Self-Attn QKV\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep11_tp0_sa_attn [label="Self-Attn Compute\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep11_tp0_sa_out [label="Self-Attn Output\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep11_tp0_sa_qkv -> layer_1_ep11_tp0_sa_attn
	layer_1_ep11_tp0_sa_attn -> layer_1_ep11_tp0_sa_out
	layer_1_ep11_tp1_sa_qkv [label="Self-Attn QKV\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep11_tp1_sa_attn [label="Self-Attn Compute\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep11_tp1_sa_out [label="Self-Attn Output\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep11_tp1_sa_qkv -> layer_1_ep11_tp1_sa_attn
	layer_1_ep11_tp1_sa_attn -> layer_1_ep11_tp1_sa_out
	layer_1_ep11_tp2_sa_qkv [label="Self-Attn QKV\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep11_tp2_sa_attn [label="Self-Attn Compute\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep11_tp2_sa_out [label="Self-Attn Output\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep11_tp2_sa_qkv -> layer_1_ep11_tp2_sa_attn
	layer_1_ep11_tp2_sa_attn -> layer_1_ep11_tp2_sa_out
	layer_1_ep11_tp3_sa_qkv [label="Self-Attn QKV\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep11_tp3_sa_attn [label="Self-Attn Compute\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep11_tp3_sa_out [label="Self-Attn Output\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep11_tp3_sa_qkv -> layer_1_ep11_tp3_sa_attn
	layer_1_ep11_tp3_sa_attn -> layer_1_ep11_tp3_sa_out
	layer_1_ep12_tp0_sa_qkv [label="Self-Attn QKV\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep12_tp0_sa_attn [label="Self-Attn Compute\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep12_tp0_sa_out [label="Self-Attn Output\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep12_tp0_sa_qkv -> layer_1_ep12_tp0_sa_attn
	layer_1_ep12_tp0_sa_attn -> layer_1_ep12_tp0_sa_out
	layer_1_ep12_tp1_sa_qkv [label="Self-Attn QKV\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep12_tp1_sa_attn [label="Self-Attn Compute\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep12_tp1_sa_out [label="Self-Attn Output\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep12_tp1_sa_qkv -> layer_1_ep12_tp1_sa_attn
	layer_1_ep12_tp1_sa_attn -> layer_1_ep12_tp1_sa_out
	layer_1_ep12_tp2_sa_qkv [label="Self-Attn QKV\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep12_tp2_sa_attn [label="Self-Attn Compute\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep12_tp2_sa_out [label="Self-Attn Output\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep12_tp2_sa_qkv -> layer_1_ep12_tp2_sa_attn
	layer_1_ep12_tp2_sa_attn -> layer_1_ep12_tp2_sa_out
	layer_1_ep12_tp3_sa_qkv [label="Self-Attn QKV\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep12_tp3_sa_attn [label="Self-Attn Compute\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep12_tp3_sa_out [label="Self-Attn Output\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep12_tp3_sa_qkv -> layer_1_ep12_tp3_sa_attn
	layer_1_ep12_tp3_sa_attn -> layer_1_ep12_tp3_sa_out
	layer_1_ep13_tp0_sa_qkv [label="Self-Attn QKV\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep13_tp0_sa_attn [label="Self-Attn Compute\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep13_tp0_sa_out [label="Self-Attn Output\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep13_tp0_sa_qkv -> layer_1_ep13_tp0_sa_attn
	layer_1_ep13_tp0_sa_attn -> layer_1_ep13_tp0_sa_out
	layer_1_ep13_tp1_sa_qkv [label="Self-Attn QKV\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep13_tp1_sa_attn [label="Self-Attn Compute\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep13_tp1_sa_out [label="Self-Attn Output\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep13_tp1_sa_qkv -> layer_1_ep13_tp1_sa_attn
	layer_1_ep13_tp1_sa_attn -> layer_1_ep13_tp1_sa_out
	layer_1_ep13_tp2_sa_qkv [label="Self-Attn QKV\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep13_tp2_sa_attn [label="Self-Attn Compute\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep13_tp2_sa_out [label="Self-Attn Output\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep13_tp2_sa_qkv -> layer_1_ep13_tp2_sa_attn
	layer_1_ep13_tp2_sa_attn -> layer_1_ep13_tp2_sa_out
	layer_1_ep13_tp3_sa_qkv [label="Self-Attn QKV\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep13_tp3_sa_attn [label="Self-Attn Compute\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep13_tp3_sa_out [label="Self-Attn Output\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep13_tp3_sa_qkv -> layer_1_ep13_tp3_sa_attn
	layer_1_ep13_tp3_sa_attn -> layer_1_ep13_tp3_sa_out
	layer_1_ep14_tp0_sa_qkv [label="Self-Attn QKV\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep14_tp0_sa_attn [label="Self-Attn Compute\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep14_tp0_sa_out [label="Self-Attn Output\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep14_tp0_sa_qkv -> layer_1_ep14_tp0_sa_attn
	layer_1_ep14_tp0_sa_attn -> layer_1_ep14_tp0_sa_out
	layer_1_ep14_tp1_sa_qkv [label="Self-Attn QKV\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep14_tp1_sa_attn [label="Self-Attn Compute\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep14_tp1_sa_out [label="Self-Attn Output\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep14_tp1_sa_qkv -> layer_1_ep14_tp1_sa_attn
	layer_1_ep14_tp1_sa_attn -> layer_1_ep14_tp1_sa_out
	layer_1_ep14_tp2_sa_qkv [label="Self-Attn QKV\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep14_tp2_sa_attn [label="Self-Attn Compute\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep14_tp2_sa_out [label="Self-Attn Output\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep14_tp2_sa_qkv -> layer_1_ep14_tp2_sa_attn
	layer_1_ep14_tp2_sa_attn -> layer_1_ep14_tp2_sa_out
	layer_1_ep14_tp3_sa_qkv [label="Self-Attn QKV\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep14_tp3_sa_attn [label="Self-Attn Compute\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep14_tp3_sa_out [label="Self-Attn Output\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep14_tp3_sa_qkv -> layer_1_ep14_tp3_sa_attn
	layer_1_ep14_tp3_sa_attn -> layer_1_ep14_tp3_sa_out
	layer_1_ep15_tp0_sa_qkv [label="Self-Attn QKV\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep15_tp0_sa_attn [label="Self-Attn Compute\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep15_tp0_sa_out [label="Self-Attn Output\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep15_tp0_sa_qkv -> layer_1_ep15_tp0_sa_attn
	layer_1_ep15_tp0_sa_attn -> layer_1_ep15_tp0_sa_out
	layer_1_ep15_tp1_sa_qkv [label="Self-Attn QKV\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep15_tp1_sa_attn [label="Self-Attn Compute\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep15_tp1_sa_out [label="Self-Attn Output\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep15_tp1_sa_qkv -> layer_1_ep15_tp1_sa_attn
	layer_1_ep15_tp1_sa_attn -> layer_1_ep15_tp1_sa_out
	layer_1_ep15_tp2_sa_qkv [label="Self-Attn QKV\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep15_tp2_sa_attn [label="Self-Attn Compute\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep15_tp2_sa_out [label="Self-Attn Output\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep15_tp2_sa_qkv -> layer_1_ep15_tp2_sa_attn
	layer_1_ep15_tp2_sa_attn -> layer_1_ep15_tp2_sa_out
	layer_1_ep15_tp3_sa_qkv [label="Self-Attn QKV\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep15_tp3_sa_attn [label="Self-Attn Compute\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep15_tp3_sa_out [label="Self-Attn Output\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep15_tp3_sa_qkv -> layer_1_ep15_tp3_sa_attn
	layer_1_ep15_tp3_sa_attn -> layer_1_ep15_tp3_sa_out
	layer_1_ep0_tp_allreduce [label="TP All-Reduce\nEP-Group-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_1_ep0_tp0_sa_out -> layer_1_ep0_tp_allreduce
	layer_1_ep0_tp1_sa_out -> layer_1_ep0_tp_allreduce
	layer_1_ep0_tp2_sa_out -> layer_1_ep0_tp_allreduce
	layer_1_ep0_tp3_sa_out -> layer_1_ep0_tp_allreduce
	layer_1_ep1_tp_allreduce [label="TP All-Reduce\nEP-Group-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_1_ep1_tp0_sa_out -> layer_1_ep1_tp_allreduce
	layer_1_ep1_tp1_sa_out -> layer_1_ep1_tp_allreduce
	layer_1_ep1_tp2_sa_out -> layer_1_ep1_tp_allreduce
	layer_1_ep1_tp3_sa_out -> layer_1_ep1_tp_allreduce
	layer_1_ep2_tp_allreduce [label="TP All-Reduce\nEP-Group-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_1_ep2_tp0_sa_out -> layer_1_ep2_tp_allreduce
	layer_1_ep2_tp1_sa_out -> layer_1_ep2_tp_allreduce
	layer_1_ep2_tp2_sa_out -> layer_1_ep2_tp_allreduce
	layer_1_ep2_tp3_sa_out -> layer_1_ep2_tp_allreduce
	layer_1_ep3_tp_allreduce [label="TP All-Reduce\nEP-Group-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_1_ep3_tp0_sa_out -> layer_1_ep3_tp_allreduce
	layer_1_ep3_tp1_sa_out -> layer_1_ep3_tp_allreduce
	layer_1_ep3_tp2_sa_out -> layer_1_ep3_tp_allreduce
	layer_1_ep3_tp3_sa_out -> layer_1_ep3_tp_allreduce
	layer_1_ep4_tp_allreduce [label="TP All-Reduce\nEP-Group-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_1_ep4_tp0_sa_out -> layer_1_ep4_tp_allreduce
	layer_1_ep4_tp1_sa_out -> layer_1_ep4_tp_allreduce
	layer_1_ep4_tp2_sa_out -> layer_1_ep4_tp_allreduce
	layer_1_ep4_tp3_sa_out -> layer_1_ep4_tp_allreduce
	layer_1_ep5_tp_allreduce [label="TP All-Reduce\nEP-Group-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_1_ep5_tp0_sa_out -> layer_1_ep5_tp_allreduce
	layer_1_ep5_tp1_sa_out -> layer_1_ep5_tp_allreduce
	layer_1_ep5_tp2_sa_out -> layer_1_ep5_tp_allreduce
	layer_1_ep5_tp3_sa_out -> layer_1_ep5_tp_allreduce
	layer_1_ep6_tp_allreduce [label="TP All-Reduce\nEP-Group-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_1_ep6_tp0_sa_out -> layer_1_ep6_tp_allreduce
	layer_1_ep6_tp1_sa_out -> layer_1_ep6_tp_allreduce
	layer_1_ep6_tp2_sa_out -> layer_1_ep6_tp_allreduce
	layer_1_ep6_tp3_sa_out -> layer_1_ep6_tp_allreduce
	layer_1_ep7_tp_allreduce [label="TP All-Reduce\nEP-Group-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_1_ep7_tp0_sa_out -> layer_1_ep7_tp_allreduce
	layer_1_ep7_tp1_sa_out -> layer_1_ep7_tp_allreduce
	layer_1_ep7_tp2_sa_out -> layer_1_ep7_tp_allreduce
	layer_1_ep7_tp3_sa_out -> layer_1_ep7_tp_allreduce
	layer_1_ep8_tp_allreduce [label="TP All-Reduce\nEP-Group-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_1_ep8_tp0_sa_out -> layer_1_ep8_tp_allreduce
	layer_1_ep8_tp1_sa_out -> layer_1_ep8_tp_allreduce
	layer_1_ep8_tp2_sa_out -> layer_1_ep8_tp_allreduce
	layer_1_ep8_tp3_sa_out -> layer_1_ep8_tp_allreduce
	layer_1_ep9_tp_allreduce [label="TP All-Reduce\nEP-Group-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_1_ep9_tp0_sa_out -> layer_1_ep9_tp_allreduce
	layer_1_ep9_tp1_sa_out -> layer_1_ep9_tp_allreduce
	layer_1_ep9_tp2_sa_out -> layer_1_ep9_tp_allreduce
	layer_1_ep9_tp3_sa_out -> layer_1_ep9_tp_allreduce
	layer_1_ep10_tp_allreduce [label="TP All-Reduce\nEP-Group-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_1_ep10_tp0_sa_out -> layer_1_ep10_tp_allreduce
	layer_1_ep10_tp1_sa_out -> layer_1_ep10_tp_allreduce
	layer_1_ep10_tp2_sa_out -> layer_1_ep10_tp_allreduce
	layer_1_ep10_tp3_sa_out -> layer_1_ep10_tp_allreduce
	layer_1_ep11_tp_allreduce [label="TP All-Reduce\nEP-Group-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_1_ep11_tp0_sa_out -> layer_1_ep11_tp_allreduce
	layer_1_ep11_tp1_sa_out -> layer_1_ep11_tp_allreduce
	layer_1_ep11_tp2_sa_out -> layer_1_ep11_tp_allreduce
	layer_1_ep11_tp3_sa_out -> layer_1_ep11_tp_allreduce
	layer_1_ep12_tp_allreduce [label="TP All-Reduce\nEP-Group-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_1_ep12_tp0_sa_out -> layer_1_ep12_tp_allreduce
	layer_1_ep12_tp1_sa_out -> layer_1_ep12_tp_allreduce
	layer_1_ep12_tp2_sa_out -> layer_1_ep12_tp_allreduce
	layer_1_ep12_tp3_sa_out -> layer_1_ep12_tp_allreduce
	layer_1_ep13_tp_allreduce [label="TP All-Reduce\nEP-Group-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_1_ep13_tp0_sa_out -> layer_1_ep13_tp_allreduce
	layer_1_ep13_tp1_sa_out -> layer_1_ep13_tp_allreduce
	layer_1_ep13_tp2_sa_out -> layer_1_ep13_tp_allreduce
	layer_1_ep13_tp3_sa_out -> layer_1_ep13_tp_allreduce
	layer_1_ep14_tp_allreduce [label="TP All-Reduce\nEP-Group-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_1_ep14_tp0_sa_out -> layer_1_ep14_tp_allreduce
	layer_1_ep14_tp1_sa_out -> layer_1_ep14_tp_allreduce
	layer_1_ep14_tp2_sa_out -> layer_1_ep14_tp_allreduce
	layer_1_ep14_tp3_sa_out -> layer_1_ep14_tp_allreduce
	layer_1_ep15_tp_allreduce [label="TP All-Reduce\nEP-Group-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_1_ep15_tp0_sa_out -> layer_1_ep15_tp_allreduce
	layer_1_ep15_tp1_sa_out -> layer_1_ep15_tp_allreduce
	layer_1_ep15_tp2_sa_out -> layer_1_ep15_tp_allreduce
	layer_1_ep15_tp3_sa_out -> layer_1_ep15_tp_allreduce
	layer_1_ep0_gate [label="MoE Gate\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_1_ep0_expert_0 [label="Expert-0\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep0_gate -> layer_1_ep0_expert_0 [label="select tokens" style=dashed]
	layer_1_ep0_expert_1 [label="Expert-1\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep0_gate -> layer_1_ep0_expert_1 [label="select tokens" style=dashed]
	layer_1_ep0_expert_2 [label="Expert-2\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep0_gate -> layer_1_ep0_expert_2 [label="select tokens" style=dashed]
	layer_1_ep0_expert_3 [label="Expert-3\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep0_gate -> layer_1_ep0_expert_3 [label="select tokens" style=dashed]
	layer_1_ep0_expert_aggr [label="Expert Aggregation\nEP-Group-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_1_ep0_expert_0 -> layer_1_ep0_expert_aggr
	layer_1_ep0_expert_1 -> layer_1_ep0_expert_aggr
	layer_1_ep0_expert_2 -> layer_1_ep0_expert_aggr
	layer_1_ep0_expert_3 -> layer_1_ep0_expert_aggr
	layer_1_ep1_gate [label="MoE Gate\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_1_ep1_expert_0 [label="Expert-0\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep1_gate -> layer_1_ep1_expert_0 [label="select tokens" style=dashed]
	layer_1_ep1_expert_1 [label="Expert-1\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep1_gate -> layer_1_ep1_expert_1 [label="select tokens" style=dashed]
	layer_1_ep1_expert_2 [label="Expert-2\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep1_gate -> layer_1_ep1_expert_2 [label="select tokens" style=dashed]
	layer_1_ep1_expert_3 [label="Expert-3\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep1_gate -> layer_1_ep1_expert_3 [label="select tokens" style=dashed]
	layer_1_ep1_expert_aggr [label="Expert Aggregation\nEP-Group-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_1_ep1_expert_0 -> layer_1_ep1_expert_aggr
	layer_1_ep1_expert_1 -> layer_1_ep1_expert_aggr
	layer_1_ep1_expert_2 -> layer_1_ep1_expert_aggr
	layer_1_ep1_expert_3 -> layer_1_ep1_expert_aggr
	layer_1_ep2_gate [label="MoE Gate\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_1_ep2_expert_0 [label="Expert-0\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep2_gate -> layer_1_ep2_expert_0 [label="select tokens" style=dashed]
	layer_1_ep2_expert_1 [label="Expert-1\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep2_gate -> layer_1_ep2_expert_1 [label="select tokens" style=dashed]
	layer_1_ep2_expert_2 [label="Expert-2\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep2_gate -> layer_1_ep2_expert_2 [label="select tokens" style=dashed]
	layer_1_ep2_expert_3 [label="Expert-3\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep2_gate -> layer_1_ep2_expert_3 [label="select tokens" style=dashed]
	layer_1_ep2_expert_aggr [label="Expert Aggregation\nEP-Group-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_1_ep2_expert_0 -> layer_1_ep2_expert_aggr
	layer_1_ep2_expert_1 -> layer_1_ep2_expert_aggr
	layer_1_ep2_expert_2 -> layer_1_ep2_expert_aggr
	layer_1_ep2_expert_3 -> layer_1_ep2_expert_aggr
	layer_1_ep3_gate [label="MoE Gate\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_1_ep3_expert_0 [label="Expert-0\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep3_gate -> layer_1_ep3_expert_0 [label="select tokens" style=dashed]
	layer_1_ep3_expert_1 [label="Expert-1\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep3_gate -> layer_1_ep3_expert_1 [label="select tokens" style=dashed]
	layer_1_ep3_expert_2 [label="Expert-2\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep3_gate -> layer_1_ep3_expert_2 [label="select tokens" style=dashed]
	layer_1_ep3_expert_3 [label="Expert-3\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep3_gate -> layer_1_ep3_expert_3 [label="select tokens" style=dashed]
	layer_1_ep3_expert_aggr [label="Expert Aggregation\nEP-Group-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_1_ep3_expert_0 -> layer_1_ep3_expert_aggr
	layer_1_ep3_expert_1 -> layer_1_ep3_expert_aggr
	layer_1_ep3_expert_2 -> layer_1_ep3_expert_aggr
	layer_1_ep3_expert_3 -> layer_1_ep3_expert_aggr
	layer_1_ep4_gate [label="MoE Gate\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_1_ep4_expert_0 [label="Expert-0\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep4_gate -> layer_1_ep4_expert_0 [label="select tokens" style=dashed]
	layer_1_ep4_expert_1 [label="Expert-1\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep4_gate -> layer_1_ep4_expert_1 [label="select tokens" style=dashed]
	layer_1_ep4_expert_2 [label="Expert-2\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep4_gate -> layer_1_ep4_expert_2 [label="select tokens" style=dashed]
	layer_1_ep4_expert_3 [label="Expert-3\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep4_gate -> layer_1_ep4_expert_3 [label="select tokens" style=dashed]
	layer_1_ep4_expert_aggr [label="Expert Aggregation\nEP-Group-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_1_ep4_expert_0 -> layer_1_ep4_expert_aggr
	layer_1_ep4_expert_1 -> layer_1_ep4_expert_aggr
	layer_1_ep4_expert_2 -> layer_1_ep4_expert_aggr
	layer_1_ep4_expert_3 -> layer_1_ep4_expert_aggr
	layer_1_ep5_gate [label="MoE Gate\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_1_ep5_expert_0 [label="Expert-0\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep5_gate -> layer_1_ep5_expert_0 [label="select tokens" style=dashed]
	layer_1_ep5_expert_1 [label="Expert-1\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep5_gate -> layer_1_ep5_expert_1 [label="select tokens" style=dashed]
	layer_1_ep5_expert_2 [label="Expert-2\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep5_gate -> layer_1_ep5_expert_2 [label="select tokens" style=dashed]
	layer_1_ep5_expert_3 [label="Expert-3\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep5_gate -> layer_1_ep5_expert_3 [label="select tokens" style=dashed]
	layer_1_ep5_expert_aggr [label="Expert Aggregation\nEP-Group-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_1_ep5_expert_0 -> layer_1_ep5_expert_aggr
	layer_1_ep5_expert_1 -> layer_1_ep5_expert_aggr
	layer_1_ep5_expert_2 -> layer_1_ep5_expert_aggr
	layer_1_ep5_expert_3 -> layer_1_ep5_expert_aggr
	layer_1_ep6_gate [label="MoE Gate\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_1_ep6_expert_0 [label="Expert-0\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep6_gate -> layer_1_ep6_expert_0 [label="select tokens" style=dashed]
	layer_1_ep6_expert_1 [label="Expert-1\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep6_gate -> layer_1_ep6_expert_1 [label="select tokens" style=dashed]
	layer_1_ep6_expert_2 [label="Expert-2\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep6_gate -> layer_1_ep6_expert_2 [label="select tokens" style=dashed]
	layer_1_ep6_expert_3 [label="Expert-3\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep6_gate -> layer_1_ep6_expert_3 [label="select tokens" style=dashed]
	layer_1_ep6_expert_aggr [label="Expert Aggregation\nEP-Group-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_1_ep6_expert_0 -> layer_1_ep6_expert_aggr
	layer_1_ep6_expert_1 -> layer_1_ep6_expert_aggr
	layer_1_ep6_expert_2 -> layer_1_ep6_expert_aggr
	layer_1_ep6_expert_3 -> layer_1_ep6_expert_aggr
	layer_1_ep7_gate [label="MoE Gate\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_1_ep7_expert_0 [label="Expert-0\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep7_gate -> layer_1_ep7_expert_0 [label="select tokens" style=dashed]
	layer_1_ep7_expert_1 [label="Expert-1\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep7_gate -> layer_1_ep7_expert_1 [label="select tokens" style=dashed]
	layer_1_ep7_expert_2 [label="Expert-2\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep7_gate -> layer_1_ep7_expert_2 [label="select tokens" style=dashed]
	layer_1_ep7_expert_3 [label="Expert-3\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep7_gate -> layer_1_ep7_expert_3 [label="select tokens" style=dashed]
	layer_1_ep7_expert_aggr [label="Expert Aggregation\nEP-Group-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_1_ep7_expert_0 -> layer_1_ep7_expert_aggr
	layer_1_ep7_expert_1 -> layer_1_ep7_expert_aggr
	layer_1_ep7_expert_2 -> layer_1_ep7_expert_aggr
	layer_1_ep7_expert_3 -> layer_1_ep7_expert_aggr
	layer_1_ep8_gate [label="MoE Gate\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_1_ep8_expert_0 [label="Expert-0\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep8_gate -> layer_1_ep8_expert_0 [label="select tokens" style=dashed]
	layer_1_ep8_expert_1 [label="Expert-1\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep8_gate -> layer_1_ep8_expert_1 [label="select tokens" style=dashed]
	layer_1_ep8_expert_2 [label="Expert-2\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep8_gate -> layer_1_ep8_expert_2 [label="select tokens" style=dashed]
	layer_1_ep8_expert_3 [label="Expert-3\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep8_gate -> layer_1_ep8_expert_3 [label="select tokens" style=dashed]
	layer_1_ep8_expert_aggr [label="Expert Aggregation\nEP-Group-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_1_ep8_expert_0 -> layer_1_ep8_expert_aggr
	layer_1_ep8_expert_1 -> layer_1_ep8_expert_aggr
	layer_1_ep8_expert_2 -> layer_1_ep8_expert_aggr
	layer_1_ep8_expert_3 -> layer_1_ep8_expert_aggr
	layer_1_ep9_gate [label="MoE Gate\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_1_ep9_expert_0 [label="Expert-0\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep9_gate -> layer_1_ep9_expert_0 [label="select tokens" style=dashed]
	layer_1_ep9_expert_1 [label="Expert-1\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep9_gate -> layer_1_ep9_expert_1 [label="select tokens" style=dashed]
	layer_1_ep9_expert_2 [label="Expert-2\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep9_gate -> layer_1_ep9_expert_2 [label="select tokens" style=dashed]
	layer_1_ep9_expert_3 [label="Expert-3\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep9_gate -> layer_1_ep9_expert_3 [label="select tokens" style=dashed]
	layer_1_ep9_expert_aggr [label="Expert Aggregation\nEP-Group-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_1_ep9_expert_0 -> layer_1_ep9_expert_aggr
	layer_1_ep9_expert_1 -> layer_1_ep9_expert_aggr
	layer_1_ep9_expert_2 -> layer_1_ep9_expert_aggr
	layer_1_ep9_expert_3 -> layer_1_ep9_expert_aggr
	layer_1_ep10_gate [label="MoE Gate\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_1_ep10_expert_0 [label="Expert-0\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep10_gate -> layer_1_ep10_expert_0 [label="select tokens" style=dashed]
	layer_1_ep10_expert_1 [label="Expert-1\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep10_gate -> layer_1_ep10_expert_1 [label="select tokens" style=dashed]
	layer_1_ep10_expert_2 [label="Expert-2\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep10_gate -> layer_1_ep10_expert_2 [label="select tokens" style=dashed]
	layer_1_ep10_expert_3 [label="Expert-3\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep10_gate -> layer_1_ep10_expert_3 [label="select tokens" style=dashed]
	layer_1_ep10_expert_aggr [label="Expert Aggregation\nEP-Group-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_1_ep10_expert_0 -> layer_1_ep10_expert_aggr
	layer_1_ep10_expert_1 -> layer_1_ep10_expert_aggr
	layer_1_ep10_expert_2 -> layer_1_ep10_expert_aggr
	layer_1_ep10_expert_3 -> layer_1_ep10_expert_aggr
	layer_1_ep11_gate [label="MoE Gate\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_1_ep11_expert_0 [label="Expert-0\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep11_gate -> layer_1_ep11_expert_0 [label="select tokens" style=dashed]
	layer_1_ep11_expert_1 [label="Expert-1\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep11_gate -> layer_1_ep11_expert_1 [label="select tokens" style=dashed]
	layer_1_ep11_expert_2 [label="Expert-2\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep11_gate -> layer_1_ep11_expert_2 [label="select tokens" style=dashed]
	layer_1_ep11_expert_3 [label="Expert-3\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep11_gate -> layer_1_ep11_expert_3 [label="select tokens" style=dashed]
	layer_1_ep11_expert_aggr [label="Expert Aggregation\nEP-Group-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_1_ep11_expert_0 -> layer_1_ep11_expert_aggr
	layer_1_ep11_expert_1 -> layer_1_ep11_expert_aggr
	layer_1_ep11_expert_2 -> layer_1_ep11_expert_aggr
	layer_1_ep11_expert_3 -> layer_1_ep11_expert_aggr
	layer_1_ep12_gate [label="MoE Gate\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_1_ep12_expert_0 [label="Expert-0\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep12_gate -> layer_1_ep12_expert_0 [label="select tokens" style=dashed]
	layer_1_ep12_expert_1 [label="Expert-1\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep12_gate -> layer_1_ep12_expert_1 [label="select tokens" style=dashed]
	layer_1_ep12_expert_2 [label="Expert-2\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep12_gate -> layer_1_ep12_expert_2 [label="select tokens" style=dashed]
	layer_1_ep12_expert_3 [label="Expert-3\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep12_gate -> layer_1_ep12_expert_3 [label="select tokens" style=dashed]
	layer_1_ep12_expert_aggr [label="Expert Aggregation\nEP-Group-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_1_ep12_expert_0 -> layer_1_ep12_expert_aggr
	layer_1_ep12_expert_1 -> layer_1_ep12_expert_aggr
	layer_1_ep12_expert_2 -> layer_1_ep12_expert_aggr
	layer_1_ep12_expert_3 -> layer_1_ep12_expert_aggr
	layer_1_ep13_gate [label="MoE Gate\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_1_ep13_expert_0 [label="Expert-0\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep13_gate -> layer_1_ep13_expert_0 [label="select tokens" style=dashed]
	layer_1_ep13_expert_1 [label="Expert-1\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep13_gate -> layer_1_ep13_expert_1 [label="select tokens" style=dashed]
	layer_1_ep13_expert_2 [label="Expert-2\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep13_gate -> layer_1_ep13_expert_2 [label="select tokens" style=dashed]
	layer_1_ep13_expert_3 [label="Expert-3\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep13_gate -> layer_1_ep13_expert_3 [label="select tokens" style=dashed]
	layer_1_ep13_expert_aggr [label="Expert Aggregation\nEP-Group-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_1_ep13_expert_0 -> layer_1_ep13_expert_aggr
	layer_1_ep13_expert_1 -> layer_1_ep13_expert_aggr
	layer_1_ep13_expert_2 -> layer_1_ep13_expert_aggr
	layer_1_ep13_expert_3 -> layer_1_ep13_expert_aggr
	layer_1_ep14_gate [label="MoE Gate\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_1_ep14_expert_0 [label="Expert-0\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep14_gate -> layer_1_ep14_expert_0 [label="select tokens" style=dashed]
	layer_1_ep14_expert_1 [label="Expert-1\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep14_gate -> layer_1_ep14_expert_1 [label="select tokens" style=dashed]
	layer_1_ep14_expert_2 [label="Expert-2\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep14_gate -> layer_1_ep14_expert_2 [label="select tokens" style=dashed]
	layer_1_ep14_expert_3 [label="Expert-3\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep14_gate -> layer_1_ep14_expert_3 [label="select tokens" style=dashed]
	layer_1_ep14_expert_aggr [label="Expert Aggregation\nEP-Group-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_1_ep14_expert_0 -> layer_1_ep14_expert_aggr
	layer_1_ep14_expert_1 -> layer_1_ep14_expert_aggr
	layer_1_ep14_expert_2 -> layer_1_ep14_expert_aggr
	layer_1_ep14_expert_3 -> layer_1_ep14_expert_aggr
	layer_1_ep15_gate [label="MoE Gate\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_1_ep15_expert_0 [label="Expert-0\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep15_gate -> layer_1_ep15_expert_0 [label="select tokens" style=dashed]
	layer_1_ep15_expert_1 [label="Expert-1\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep15_gate -> layer_1_ep15_expert_1 [label="select tokens" style=dashed]
	layer_1_ep15_expert_2 [label="Expert-2\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep15_gate -> layer_1_ep15_expert_2 [label="select tokens" style=dashed]
	layer_1_ep15_expert_3 [label="Expert-3\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_1_ep15_gate -> layer_1_ep15_expert_3 [label="select tokens" style=dashed]
	layer_1_ep15_expert_aggr [label="Expert Aggregation\nEP-Group-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_1_ep15_expert_0 -> layer_1_ep15_expert_aggr
	layer_1_ep15_expert_1 -> layer_1_ep15_expert_aggr
	layer_1_ep15_expert_2 -> layer_1_ep15_expert_aggr
	layer_1_ep15_expert_3 -> layer_1_ep15_expert_aggr
	layer_1_to_2_ep0_pp [label="Pipeline Stage Transfer\nEP-Group-0\nLayer-1 to Layer-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_1_ep0_expert_aggr -> layer_1_to_2_ep0_pp
	layer_1_to_2_ep1_pp [label="Pipeline Stage Transfer\nEP-Group-1\nLayer-1 to Layer-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_1_ep1_expert_aggr -> layer_1_to_2_ep1_pp
	layer_1_to_2_ep2_pp [label="Pipeline Stage Transfer\nEP-Group-2\nLayer-1 to Layer-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_1_ep2_expert_aggr -> layer_1_to_2_ep2_pp
	layer_1_to_2_ep3_pp [label="Pipeline Stage Transfer\nEP-Group-3\nLayer-1 to Layer-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_1_ep3_expert_aggr -> layer_1_to_2_ep3_pp
	layer_1_to_2_ep4_pp [label="Pipeline Stage Transfer\nEP-Group-4\nLayer-1 to Layer-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_1_ep4_expert_aggr -> layer_1_to_2_ep4_pp
	layer_1_to_2_ep5_pp [label="Pipeline Stage Transfer\nEP-Group-5\nLayer-1 to Layer-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_1_ep5_expert_aggr -> layer_1_to_2_ep5_pp
	layer_1_to_2_ep6_pp [label="Pipeline Stage Transfer\nEP-Group-6\nLayer-1 to Layer-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_1_ep6_expert_aggr -> layer_1_to_2_ep6_pp
	layer_1_to_2_ep7_pp [label="Pipeline Stage Transfer\nEP-Group-7\nLayer-1 to Layer-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_1_ep7_expert_aggr -> layer_1_to_2_ep7_pp
	layer_1_to_2_ep8_pp [label="Pipeline Stage Transfer\nEP-Group-8\nLayer-1 to Layer-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_1_ep8_expert_aggr -> layer_1_to_2_ep8_pp
	layer_1_to_2_ep9_pp [label="Pipeline Stage Transfer\nEP-Group-9\nLayer-1 to Layer-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_1_ep9_expert_aggr -> layer_1_to_2_ep9_pp
	layer_1_to_2_ep10_pp [label="Pipeline Stage Transfer\nEP-Group-10\nLayer-1 to Layer-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_1_ep10_expert_aggr -> layer_1_to_2_ep10_pp
	layer_1_to_2_ep11_pp [label="Pipeline Stage Transfer\nEP-Group-11\nLayer-1 to Layer-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_1_ep11_expert_aggr -> layer_1_to_2_ep11_pp
	layer_1_to_2_ep12_pp [label="Pipeline Stage Transfer\nEP-Group-12\nLayer-1 to Layer-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_1_ep12_expert_aggr -> layer_1_to_2_ep12_pp
	layer_1_to_2_ep13_pp [label="Pipeline Stage Transfer\nEP-Group-13\nLayer-1 to Layer-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_1_ep13_expert_aggr -> layer_1_to_2_ep13_pp
	layer_1_to_2_ep14_pp [label="Pipeline Stage Transfer\nEP-Group-14\nLayer-1 to Layer-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_1_ep14_expert_aggr -> layer_1_to_2_ep14_pp
	layer_1_to_2_ep15_pp [label="Pipeline Stage Transfer\nEP-Group-15\nLayer-1 to Layer-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_1_ep15_expert_aggr -> layer_1_to_2_ep15_pp
	layer_2_ep0_tp0_sa_qkv [label="Self-Attn QKV\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep0_tp0_sa_attn [label="Self-Attn Compute\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep0_tp0_sa_out [label="Self-Attn Output\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep0_tp0_sa_qkv -> layer_2_ep0_tp0_sa_attn
	layer_2_ep0_tp0_sa_attn -> layer_2_ep0_tp0_sa_out
	layer_2_ep0_tp1_sa_qkv [label="Self-Attn QKV\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep0_tp1_sa_attn [label="Self-Attn Compute\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep0_tp1_sa_out [label="Self-Attn Output\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep0_tp1_sa_qkv -> layer_2_ep0_tp1_sa_attn
	layer_2_ep0_tp1_sa_attn -> layer_2_ep0_tp1_sa_out
	layer_2_ep0_tp2_sa_qkv [label="Self-Attn QKV\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep0_tp2_sa_attn [label="Self-Attn Compute\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep0_tp2_sa_out [label="Self-Attn Output\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep0_tp2_sa_qkv -> layer_2_ep0_tp2_sa_attn
	layer_2_ep0_tp2_sa_attn -> layer_2_ep0_tp2_sa_out
	layer_2_ep0_tp3_sa_qkv [label="Self-Attn QKV\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep0_tp3_sa_attn [label="Self-Attn Compute\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep0_tp3_sa_out [label="Self-Attn Output\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep0_tp3_sa_qkv -> layer_2_ep0_tp3_sa_attn
	layer_2_ep0_tp3_sa_attn -> layer_2_ep0_tp3_sa_out
	layer_2_ep1_tp0_sa_qkv [label="Self-Attn QKV\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep1_tp0_sa_attn [label="Self-Attn Compute\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep1_tp0_sa_out [label="Self-Attn Output\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep1_tp0_sa_qkv -> layer_2_ep1_tp0_sa_attn
	layer_2_ep1_tp0_sa_attn -> layer_2_ep1_tp0_sa_out
	layer_2_ep1_tp1_sa_qkv [label="Self-Attn QKV\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep1_tp1_sa_attn [label="Self-Attn Compute\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep1_tp1_sa_out [label="Self-Attn Output\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep1_tp1_sa_qkv -> layer_2_ep1_tp1_sa_attn
	layer_2_ep1_tp1_sa_attn -> layer_2_ep1_tp1_sa_out
	layer_2_ep1_tp2_sa_qkv [label="Self-Attn QKV\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep1_tp2_sa_attn [label="Self-Attn Compute\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep1_tp2_sa_out [label="Self-Attn Output\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep1_tp2_sa_qkv -> layer_2_ep1_tp2_sa_attn
	layer_2_ep1_tp2_sa_attn -> layer_2_ep1_tp2_sa_out
	layer_2_ep1_tp3_sa_qkv [label="Self-Attn QKV\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep1_tp3_sa_attn [label="Self-Attn Compute\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep1_tp3_sa_out [label="Self-Attn Output\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep1_tp3_sa_qkv -> layer_2_ep1_tp3_sa_attn
	layer_2_ep1_tp3_sa_attn -> layer_2_ep1_tp3_sa_out
	layer_2_ep2_tp0_sa_qkv [label="Self-Attn QKV\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep2_tp0_sa_attn [label="Self-Attn Compute\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep2_tp0_sa_out [label="Self-Attn Output\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep2_tp0_sa_qkv -> layer_2_ep2_tp0_sa_attn
	layer_2_ep2_tp0_sa_attn -> layer_2_ep2_tp0_sa_out
	layer_2_ep2_tp1_sa_qkv [label="Self-Attn QKV\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep2_tp1_sa_attn [label="Self-Attn Compute\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep2_tp1_sa_out [label="Self-Attn Output\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep2_tp1_sa_qkv -> layer_2_ep2_tp1_sa_attn
	layer_2_ep2_tp1_sa_attn -> layer_2_ep2_tp1_sa_out
	layer_2_ep2_tp2_sa_qkv [label="Self-Attn QKV\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep2_tp2_sa_attn [label="Self-Attn Compute\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep2_tp2_sa_out [label="Self-Attn Output\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep2_tp2_sa_qkv -> layer_2_ep2_tp2_sa_attn
	layer_2_ep2_tp2_sa_attn -> layer_2_ep2_tp2_sa_out
	layer_2_ep2_tp3_sa_qkv [label="Self-Attn QKV\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep2_tp3_sa_attn [label="Self-Attn Compute\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep2_tp3_sa_out [label="Self-Attn Output\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep2_tp3_sa_qkv -> layer_2_ep2_tp3_sa_attn
	layer_2_ep2_tp3_sa_attn -> layer_2_ep2_tp3_sa_out
	layer_2_ep3_tp0_sa_qkv [label="Self-Attn QKV\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep3_tp0_sa_attn [label="Self-Attn Compute\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep3_tp0_sa_out [label="Self-Attn Output\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep3_tp0_sa_qkv -> layer_2_ep3_tp0_sa_attn
	layer_2_ep3_tp0_sa_attn -> layer_2_ep3_tp0_sa_out
	layer_2_ep3_tp1_sa_qkv [label="Self-Attn QKV\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep3_tp1_sa_attn [label="Self-Attn Compute\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep3_tp1_sa_out [label="Self-Attn Output\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep3_tp1_sa_qkv -> layer_2_ep3_tp1_sa_attn
	layer_2_ep3_tp1_sa_attn -> layer_2_ep3_tp1_sa_out
	layer_2_ep3_tp2_sa_qkv [label="Self-Attn QKV\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep3_tp2_sa_attn [label="Self-Attn Compute\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep3_tp2_sa_out [label="Self-Attn Output\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep3_tp2_sa_qkv -> layer_2_ep3_tp2_sa_attn
	layer_2_ep3_tp2_sa_attn -> layer_2_ep3_tp2_sa_out
	layer_2_ep3_tp3_sa_qkv [label="Self-Attn QKV\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep3_tp3_sa_attn [label="Self-Attn Compute\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep3_tp3_sa_out [label="Self-Attn Output\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep3_tp3_sa_qkv -> layer_2_ep3_tp3_sa_attn
	layer_2_ep3_tp3_sa_attn -> layer_2_ep3_tp3_sa_out
	layer_2_ep4_tp0_sa_qkv [label="Self-Attn QKV\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep4_tp0_sa_attn [label="Self-Attn Compute\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep4_tp0_sa_out [label="Self-Attn Output\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep4_tp0_sa_qkv -> layer_2_ep4_tp0_sa_attn
	layer_2_ep4_tp0_sa_attn -> layer_2_ep4_tp0_sa_out
	layer_2_ep4_tp1_sa_qkv [label="Self-Attn QKV\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep4_tp1_sa_attn [label="Self-Attn Compute\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep4_tp1_sa_out [label="Self-Attn Output\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep4_tp1_sa_qkv -> layer_2_ep4_tp1_sa_attn
	layer_2_ep4_tp1_sa_attn -> layer_2_ep4_tp1_sa_out
	layer_2_ep4_tp2_sa_qkv [label="Self-Attn QKV\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep4_tp2_sa_attn [label="Self-Attn Compute\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep4_tp2_sa_out [label="Self-Attn Output\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep4_tp2_sa_qkv -> layer_2_ep4_tp2_sa_attn
	layer_2_ep4_tp2_sa_attn -> layer_2_ep4_tp2_sa_out
	layer_2_ep4_tp3_sa_qkv [label="Self-Attn QKV\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep4_tp3_sa_attn [label="Self-Attn Compute\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep4_tp3_sa_out [label="Self-Attn Output\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep4_tp3_sa_qkv -> layer_2_ep4_tp3_sa_attn
	layer_2_ep4_tp3_sa_attn -> layer_2_ep4_tp3_sa_out
	layer_2_ep5_tp0_sa_qkv [label="Self-Attn QKV\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep5_tp0_sa_attn [label="Self-Attn Compute\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep5_tp0_sa_out [label="Self-Attn Output\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep5_tp0_sa_qkv -> layer_2_ep5_tp0_sa_attn
	layer_2_ep5_tp0_sa_attn -> layer_2_ep5_tp0_sa_out
	layer_2_ep5_tp1_sa_qkv [label="Self-Attn QKV\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep5_tp1_sa_attn [label="Self-Attn Compute\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep5_tp1_sa_out [label="Self-Attn Output\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep5_tp1_sa_qkv -> layer_2_ep5_tp1_sa_attn
	layer_2_ep5_tp1_sa_attn -> layer_2_ep5_tp1_sa_out
	layer_2_ep5_tp2_sa_qkv [label="Self-Attn QKV\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep5_tp2_sa_attn [label="Self-Attn Compute\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep5_tp2_sa_out [label="Self-Attn Output\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep5_tp2_sa_qkv -> layer_2_ep5_tp2_sa_attn
	layer_2_ep5_tp2_sa_attn -> layer_2_ep5_tp2_sa_out
	layer_2_ep5_tp3_sa_qkv [label="Self-Attn QKV\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep5_tp3_sa_attn [label="Self-Attn Compute\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep5_tp3_sa_out [label="Self-Attn Output\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep5_tp3_sa_qkv -> layer_2_ep5_tp3_sa_attn
	layer_2_ep5_tp3_sa_attn -> layer_2_ep5_tp3_sa_out
	layer_2_ep6_tp0_sa_qkv [label="Self-Attn QKV\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep6_tp0_sa_attn [label="Self-Attn Compute\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep6_tp0_sa_out [label="Self-Attn Output\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep6_tp0_sa_qkv -> layer_2_ep6_tp0_sa_attn
	layer_2_ep6_tp0_sa_attn -> layer_2_ep6_tp0_sa_out
	layer_2_ep6_tp1_sa_qkv [label="Self-Attn QKV\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep6_tp1_sa_attn [label="Self-Attn Compute\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep6_tp1_sa_out [label="Self-Attn Output\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep6_tp1_sa_qkv -> layer_2_ep6_tp1_sa_attn
	layer_2_ep6_tp1_sa_attn -> layer_2_ep6_tp1_sa_out
	layer_2_ep6_tp2_sa_qkv [label="Self-Attn QKV\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep6_tp2_sa_attn [label="Self-Attn Compute\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep6_tp2_sa_out [label="Self-Attn Output\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep6_tp2_sa_qkv -> layer_2_ep6_tp2_sa_attn
	layer_2_ep6_tp2_sa_attn -> layer_2_ep6_tp2_sa_out
	layer_2_ep6_tp3_sa_qkv [label="Self-Attn QKV\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep6_tp3_sa_attn [label="Self-Attn Compute\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep6_tp3_sa_out [label="Self-Attn Output\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep6_tp3_sa_qkv -> layer_2_ep6_tp3_sa_attn
	layer_2_ep6_tp3_sa_attn -> layer_2_ep6_tp3_sa_out
	layer_2_ep7_tp0_sa_qkv [label="Self-Attn QKV\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep7_tp0_sa_attn [label="Self-Attn Compute\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep7_tp0_sa_out [label="Self-Attn Output\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep7_tp0_sa_qkv -> layer_2_ep7_tp0_sa_attn
	layer_2_ep7_tp0_sa_attn -> layer_2_ep7_tp0_sa_out
	layer_2_ep7_tp1_sa_qkv [label="Self-Attn QKV\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep7_tp1_sa_attn [label="Self-Attn Compute\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep7_tp1_sa_out [label="Self-Attn Output\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep7_tp1_sa_qkv -> layer_2_ep7_tp1_sa_attn
	layer_2_ep7_tp1_sa_attn -> layer_2_ep7_tp1_sa_out
	layer_2_ep7_tp2_sa_qkv [label="Self-Attn QKV\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep7_tp2_sa_attn [label="Self-Attn Compute\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep7_tp2_sa_out [label="Self-Attn Output\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep7_tp2_sa_qkv -> layer_2_ep7_tp2_sa_attn
	layer_2_ep7_tp2_sa_attn -> layer_2_ep7_tp2_sa_out
	layer_2_ep7_tp3_sa_qkv [label="Self-Attn QKV\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep7_tp3_sa_attn [label="Self-Attn Compute\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep7_tp3_sa_out [label="Self-Attn Output\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep7_tp3_sa_qkv -> layer_2_ep7_tp3_sa_attn
	layer_2_ep7_tp3_sa_attn -> layer_2_ep7_tp3_sa_out
	layer_2_ep8_tp0_sa_qkv [label="Self-Attn QKV\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep8_tp0_sa_attn [label="Self-Attn Compute\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep8_tp0_sa_out [label="Self-Attn Output\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep8_tp0_sa_qkv -> layer_2_ep8_tp0_sa_attn
	layer_2_ep8_tp0_sa_attn -> layer_2_ep8_tp0_sa_out
	layer_2_ep8_tp1_sa_qkv [label="Self-Attn QKV\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep8_tp1_sa_attn [label="Self-Attn Compute\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep8_tp1_sa_out [label="Self-Attn Output\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep8_tp1_sa_qkv -> layer_2_ep8_tp1_sa_attn
	layer_2_ep8_tp1_sa_attn -> layer_2_ep8_tp1_sa_out
	layer_2_ep8_tp2_sa_qkv [label="Self-Attn QKV\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep8_tp2_sa_attn [label="Self-Attn Compute\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep8_tp2_sa_out [label="Self-Attn Output\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep8_tp2_sa_qkv -> layer_2_ep8_tp2_sa_attn
	layer_2_ep8_tp2_sa_attn -> layer_2_ep8_tp2_sa_out
	layer_2_ep8_tp3_sa_qkv [label="Self-Attn QKV\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep8_tp3_sa_attn [label="Self-Attn Compute\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep8_tp3_sa_out [label="Self-Attn Output\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep8_tp3_sa_qkv -> layer_2_ep8_tp3_sa_attn
	layer_2_ep8_tp3_sa_attn -> layer_2_ep8_tp3_sa_out
	layer_2_ep9_tp0_sa_qkv [label="Self-Attn QKV\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep9_tp0_sa_attn [label="Self-Attn Compute\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep9_tp0_sa_out [label="Self-Attn Output\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep9_tp0_sa_qkv -> layer_2_ep9_tp0_sa_attn
	layer_2_ep9_tp0_sa_attn -> layer_2_ep9_tp0_sa_out
	layer_2_ep9_tp1_sa_qkv [label="Self-Attn QKV\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep9_tp1_sa_attn [label="Self-Attn Compute\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep9_tp1_sa_out [label="Self-Attn Output\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep9_tp1_sa_qkv -> layer_2_ep9_tp1_sa_attn
	layer_2_ep9_tp1_sa_attn -> layer_2_ep9_tp1_sa_out
	layer_2_ep9_tp2_sa_qkv [label="Self-Attn QKV\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep9_tp2_sa_attn [label="Self-Attn Compute\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep9_tp2_sa_out [label="Self-Attn Output\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep9_tp2_sa_qkv -> layer_2_ep9_tp2_sa_attn
	layer_2_ep9_tp2_sa_attn -> layer_2_ep9_tp2_sa_out
	layer_2_ep9_tp3_sa_qkv [label="Self-Attn QKV\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep9_tp3_sa_attn [label="Self-Attn Compute\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep9_tp3_sa_out [label="Self-Attn Output\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep9_tp3_sa_qkv -> layer_2_ep9_tp3_sa_attn
	layer_2_ep9_tp3_sa_attn -> layer_2_ep9_tp3_sa_out
	layer_2_ep10_tp0_sa_qkv [label="Self-Attn QKV\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep10_tp0_sa_attn [label="Self-Attn Compute\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep10_tp0_sa_out [label="Self-Attn Output\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep10_tp0_sa_qkv -> layer_2_ep10_tp0_sa_attn
	layer_2_ep10_tp0_sa_attn -> layer_2_ep10_tp0_sa_out
	layer_2_ep10_tp1_sa_qkv [label="Self-Attn QKV\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep10_tp1_sa_attn [label="Self-Attn Compute\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep10_tp1_sa_out [label="Self-Attn Output\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep10_tp1_sa_qkv -> layer_2_ep10_tp1_sa_attn
	layer_2_ep10_tp1_sa_attn -> layer_2_ep10_tp1_sa_out
	layer_2_ep10_tp2_sa_qkv [label="Self-Attn QKV\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep10_tp2_sa_attn [label="Self-Attn Compute\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep10_tp2_sa_out [label="Self-Attn Output\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep10_tp2_sa_qkv -> layer_2_ep10_tp2_sa_attn
	layer_2_ep10_tp2_sa_attn -> layer_2_ep10_tp2_sa_out
	layer_2_ep10_tp3_sa_qkv [label="Self-Attn QKV\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep10_tp3_sa_attn [label="Self-Attn Compute\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep10_tp3_sa_out [label="Self-Attn Output\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep10_tp3_sa_qkv -> layer_2_ep10_tp3_sa_attn
	layer_2_ep10_tp3_sa_attn -> layer_2_ep10_tp3_sa_out
	layer_2_ep11_tp0_sa_qkv [label="Self-Attn QKV\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep11_tp0_sa_attn [label="Self-Attn Compute\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep11_tp0_sa_out [label="Self-Attn Output\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep11_tp0_sa_qkv -> layer_2_ep11_tp0_sa_attn
	layer_2_ep11_tp0_sa_attn -> layer_2_ep11_tp0_sa_out
	layer_2_ep11_tp1_sa_qkv [label="Self-Attn QKV\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep11_tp1_sa_attn [label="Self-Attn Compute\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep11_tp1_sa_out [label="Self-Attn Output\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep11_tp1_sa_qkv -> layer_2_ep11_tp1_sa_attn
	layer_2_ep11_tp1_sa_attn -> layer_2_ep11_tp1_sa_out
	layer_2_ep11_tp2_sa_qkv [label="Self-Attn QKV\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep11_tp2_sa_attn [label="Self-Attn Compute\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep11_tp2_sa_out [label="Self-Attn Output\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep11_tp2_sa_qkv -> layer_2_ep11_tp2_sa_attn
	layer_2_ep11_tp2_sa_attn -> layer_2_ep11_tp2_sa_out
	layer_2_ep11_tp3_sa_qkv [label="Self-Attn QKV\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep11_tp3_sa_attn [label="Self-Attn Compute\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep11_tp3_sa_out [label="Self-Attn Output\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep11_tp3_sa_qkv -> layer_2_ep11_tp3_sa_attn
	layer_2_ep11_tp3_sa_attn -> layer_2_ep11_tp3_sa_out
	layer_2_ep12_tp0_sa_qkv [label="Self-Attn QKV\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep12_tp0_sa_attn [label="Self-Attn Compute\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep12_tp0_sa_out [label="Self-Attn Output\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep12_tp0_sa_qkv -> layer_2_ep12_tp0_sa_attn
	layer_2_ep12_tp0_sa_attn -> layer_2_ep12_tp0_sa_out
	layer_2_ep12_tp1_sa_qkv [label="Self-Attn QKV\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep12_tp1_sa_attn [label="Self-Attn Compute\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep12_tp1_sa_out [label="Self-Attn Output\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep12_tp1_sa_qkv -> layer_2_ep12_tp1_sa_attn
	layer_2_ep12_tp1_sa_attn -> layer_2_ep12_tp1_sa_out
	layer_2_ep12_tp2_sa_qkv [label="Self-Attn QKV\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep12_tp2_sa_attn [label="Self-Attn Compute\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep12_tp2_sa_out [label="Self-Attn Output\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep12_tp2_sa_qkv -> layer_2_ep12_tp2_sa_attn
	layer_2_ep12_tp2_sa_attn -> layer_2_ep12_tp2_sa_out
	layer_2_ep12_tp3_sa_qkv [label="Self-Attn QKV\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep12_tp3_sa_attn [label="Self-Attn Compute\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep12_tp3_sa_out [label="Self-Attn Output\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep12_tp3_sa_qkv -> layer_2_ep12_tp3_sa_attn
	layer_2_ep12_tp3_sa_attn -> layer_2_ep12_tp3_sa_out
	layer_2_ep13_tp0_sa_qkv [label="Self-Attn QKV\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep13_tp0_sa_attn [label="Self-Attn Compute\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep13_tp0_sa_out [label="Self-Attn Output\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep13_tp0_sa_qkv -> layer_2_ep13_tp0_sa_attn
	layer_2_ep13_tp0_sa_attn -> layer_2_ep13_tp0_sa_out
	layer_2_ep13_tp1_sa_qkv [label="Self-Attn QKV\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep13_tp1_sa_attn [label="Self-Attn Compute\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep13_tp1_sa_out [label="Self-Attn Output\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep13_tp1_sa_qkv -> layer_2_ep13_tp1_sa_attn
	layer_2_ep13_tp1_sa_attn -> layer_2_ep13_tp1_sa_out
	layer_2_ep13_tp2_sa_qkv [label="Self-Attn QKV\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep13_tp2_sa_attn [label="Self-Attn Compute\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep13_tp2_sa_out [label="Self-Attn Output\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep13_tp2_sa_qkv -> layer_2_ep13_tp2_sa_attn
	layer_2_ep13_tp2_sa_attn -> layer_2_ep13_tp2_sa_out
	layer_2_ep13_tp3_sa_qkv [label="Self-Attn QKV\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep13_tp3_sa_attn [label="Self-Attn Compute\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep13_tp3_sa_out [label="Self-Attn Output\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep13_tp3_sa_qkv -> layer_2_ep13_tp3_sa_attn
	layer_2_ep13_tp3_sa_attn -> layer_2_ep13_tp3_sa_out
	layer_2_ep14_tp0_sa_qkv [label="Self-Attn QKV\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep14_tp0_sa_attn [label="Self-Attn Compute\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep14_tp0_sa_out [label="Self-Attn Output\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep14_tp0_sa_qkv -> layer_2_ep14_tp0_sa_attn
	layer_2_ep14_tp0_sa_attn -> layer_2_ep14_tp0_sa_out
	layer_2_ep14_tp1_sa_qkv [label="Self-Attn QKV\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep14_tp1_sa_attn [label="Self-Attn Compute\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep14_tp1_sa_out [label="Self-Attn Output\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep14_tp1_sa_qkv -> layer_2_ep14_tp1_sa_attn
	layer_2_ep14_tp1_sa_attn -> layer_2_ep14_tp1_sa_out
	layer_2_ep14_tp2_sa_qkv [label="Self-Attn QKV\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep14_tp2_sa_attn [label="Self-Attn Compute\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep14_tp2_sa_out [label="Self-Attn Output\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep14_tp2_sa_qkv -> layer_2_ep14_tp2_sa_attn
	layer_2_ep14_tp2_sa_attn -> layer_2_ep14_tp2_sa_out
	layer_2_ep14_tp3_sa_qkv [label="Self-Attn QKV\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep14_tp3_sa_attn [label="Self-Attn Compute\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep14_tp3_sa_out [label="Self-Attn Output\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep14_tp3_sa_qkv -> layer_2_ep14_tp3_sa_attn
	layer_2_ep14_tp3_sa_attn -> layer_2_ep14_tp3_sa_out
	layer_2_ep15_tp0_sa_qkv [label="Self-Attn QKV\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep15_tp0_sa_attn [label="Self-Attn Compute\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep15_tp0_sa_out [label="Self-Attn Output\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep15_tp0_sa_qkv -> layer_2_ep15_tp0_sa_attn
	layer_2_ep15_tp0_sa_attn -> layer_2_ep15_tp0_sa_out
	layer_2_ep15_tp1_sa_qkv [label="Self-Attn QKV\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep15_tp1_sa_attn [label="Self-Attn Compute\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep15_tp1_sa_out [label="Self-Attn Output\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep15_tp1_sa_qkv -> layer_2_ep15_tp1_sa_attn
	layer_2_ep15_tp1_sa_attn -> layer_2_ep15_tp1_sa_out
	layer_2_ep15_tp2_sa_qkv [label="Self-Attn QKV\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep15_tp2_sa_attn [label="Self-Attn Compute\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep15_tp2_sa_out [label="Self-Attn Output\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep15_tp2_sa_qkv -> layer_2_ep15_tp2_sa_attn
	layer_2_ep15_tp2_sa_attn -> layer_2_ep15_tp2_sa_out
	layer_2_ep15_tp3_sa_qkv [label="Self-Attn QKV\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep15_tp3_sa_attn [label="Self-Attn Compute\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep15_tp3_sa_out [label="Self-Attn Output\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep15_tp3_sa_qkv -> layer_2_ep15_tp3_sa_attn
	layer_2_ep15_tp3_sa_attn -> layer_2_ep15_tp3_sa_out
	layer_2_ep0_tp_allreduce [label="TP All-Reduce\nEP-Group-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_2_ep0_tp0_sa_out -> layer_2_ep0_tp_allreduce
	layer_2_ep0_tp1_sa_out -> layer_2_ep0_tp_allreduce
	layer_2_ep0_tp2_sa_out -> layer_2_ep0_tp_allreduce
	layer_2_ep0_tp3_sa_out -> layer_2_ep0_tp_allreduce
	layer_2_ep1_tp_allreduce [label="TP All-Reduce\nEP-Group-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_2_ep1_tp0_sa_out -> layer_2_ep1_tp_allreduce
	layer_2_ep1_tp1_sa_out -> layer_2_ep1_tp_allreduce
	layer_2_ep1_tp2_sa_out -> layer_2_ep1_tp_allreduce
	layer_2_ep1_tp3_sa_out -> layer_2_ep1_tp_allreduce
	layer_2_ep2_tp_allreduce [label="TP All-Reduce\nEP-Group-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_2_ep2_tp0_sa_out -> layer_2_ep2_tp_allreduce
	layer_2_ep2_tp1_sa_out -> layer_2_ep2_tp_allreduce
	layer_2_ep2_tp2_sa_out -> layer_2_ep2_tp_allreduce
	layer_2_ep2_tp3_sa_out -> layer_2_ep2_tp_allreduce
	layer_2_ep3_tp_allreduce [label="TP All-Reduce\nEP-Group-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_2_ep3_tp0_sa_out -> layer_2_ep3_tp_allreduce
	layer_2_ep3_tp1_sa_out -> layer_2_ep3_tp_allreduce
	layer_2_ep3_tp2_sa_out -> layer_2_ep3_tp_allreduce
	layer_2_ep3_tp3_sa_out -> layer_2_ep3_tp_allreduce
	layer_2_ep4_tp_allreduce [label="TP All-Reduce\nEP-Group-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_2_ep4_tp0_sa_out -> layer_2_ep4_tp_allreduce
	layer_2_ep4_tp1_sa_out -> layer_2_ep4_tp_allreduce
	layer_2_ep4_tp2_sa_out -> layer_2_ep4_tp_allreduce
	layer_2_ep4_tp3_sa_out -> layer_2_ep4_tp_allreduce
	layer_2_ep5_tp_allreduce [label="TP All-Reduce\nEP-Group-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_2_ep5_tp0_sa_out -> layer_2_ep5_tp_allreduce
	layer_2_ep5_tp1_sa_out -> layer_2_ep5_tp_allreduce
	layer_2_ep5_tp2_sa_out -> layer_2_ep5_tp_allreduce
	layer_2_ep5_tp3_sa_out -> layer_2_ep5_tp_allreduce
	layer_2_ep6_tp_allreduce [label="TP All-Reduce\nEP-Group-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_2_ep6_tp0_sa_out -> layer_2_ep6_tp_allreduce
	layer_2_ep6_tp1_sa_out -> layer_2_ep6_tp_allreduce
	layer_2_ep6_tp2_sa_out -> layer_2_ep6_tp_allreduce
	layer_2_ep6_tp3_sa_out -> layer_2_ep6_tp_allreduce
	layer_2_ep7_tp_allreduce [label="TP All-Reduce\nEP-Group-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_2_ep7_tp0_sa_out -> layer_2_ep7_tp_allreduce
	layer_2_ep7_tp1_sa_out -> layer_2_ep7_tp_allreduce
	layer_2_ep7_tp2_sa_out -> layer_2_ep7_tp_allreduce
	layer_2_ep7_tp3_sa_out -> layer_2_ep7_tp_allreduce
	layer_2_ep8_tp_allreduce [label="TP All-Reduce\nEP-Group-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_2_ep8_tp0_sa_out -> layer_2_ep8_tp_allreduce
	layer_2_ep8_tp1_sa_out -> layer_2_ep8_tp_allreduce
	layer_2_ep8_tp2_sa_out -> layer_2_ep8_tp_allreduce
	layer_2_ep8_tp3_sa_out -> layer_2_ep8_tp_allreduce
	layer_2_ep9_tp_allreduce [label="TP All-Reduce\nEP-Group-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_2_ep9_tp0_sa_out -> layer_2_ep9_tp_allreduce
	layer_2_ep9_tp1_sa_out -> layer_2_ep9_tp_allreduce
	layer_2_ep9_tp2_sa_out -> layer_2_ep9_tp_allreduce
	layer_2_ep9_tp3_sa_out -> layer_2_ep9_tp_allreduce
	layer_2_ep10_tp_allreduce [label="TP All-Reduce\nEP-Group-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_2_ep10_tp0_sa_out -> layer_2_ep10_tp_allreduce
	layer_2_ep10_tp1_sa_out -> layer_2_ep10_tp_allreduce
	layer_2_ep10_tp2_sa_out -> layer_2_ep10_tp_allreduce
	layer_2_ep10_tp3_sa_out -> layer_2_ep10_tp_allreduce
	layer_2_ep11_tp_allreduce [label="TP All-Reduce\nEP-Group-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_2_ep11_tp0_sa_out -> layer_2_ep11_tp_allreduce
	layer_2_ep11_tp1_sa_out -> layer_2_ep11_tp_allreduce
	layer_2_ep11_tp2_sa_out -> layer_2_ep11_tp_allreduce
	layer_2_ep11_tp3_sa_out -> layer_2_ep11_tp_allreduce
	layer_2_ep12_tp_allreduce [label="TP All-Reduce\nEP-Group-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_2_ep12_tp0_sa_out -> layer_2_ep12_tp_allreduce
	layer_2_ep12_tp1_sa_out -> layer_2_ep12_tp_allreduce
	layer_2_ep12_tp2_sa_out -> layer_2_ep12_tp_allreduce
	layer_2_ep12_tp3_sa_out -> layer_2_ep12_tp_allreduce
	layer_2_ep13_tp_allreduce [label="TP All-Reduce\nEP-Group-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_2_ep13_tp0_sa_out -> layer_2_ep13_tp_allreduce
	layer_2_ep13_tp1_sa_out -> layer_2_ep13_tp_allreduce
	layer_2_ep13_tp2_sa_out -> layer_2_ep13_tp_allreduce
	layer_2_ep13_tp3_sa_out -> layer_2_ep13_tp_allreduce
	layer_2_ep14_tp_allreduce [label="TP All-Reduce\nEP-Group-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_2_ep14_tp0_sa_out -> layer_2_ep14_tp_allreduce
	layer_2_ep14_tp1_sa_out -> layer_2_ep14_tp_allreduce
	layer_2_ep14_tp2_sa_out -> layer_2_ep14_tp_allreduce
	layer_2_ep14_tp3_sa_out -> layer_2_ep14_tp_allreduce
	layer_2_ep15_tp_allreduce [label="TP All-Reduce\nEP-Group-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_2_ep15_tp0_sa_out -> layer_2_ep15_tp_allreduce
	layer_2_ep15_tp1_sa_out -> layer_2_ep15_tp_allreduce
	layer_2_ep15_tp2_sa_out -> layer_2_ep15_tp_allreduce
	layer_2_ep15_tp3_sa_out -> layer_2_ep15_tp_allreduce
	layer_2_ep0_gate [label="MoE Gate\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_2_ep0_expert_0 [label="Expert-0\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep0_gate -> layer_2_ep0_expert_0 [label="select tokens" style=dashed]
	layer_2_ep0_expert_1 [label="Expert-1\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep0_gate -> layer_2_ep0_expert_1 [label="select tokens" style=dashed]
	layer_2_ep0_expert_2 [label="Expert-2\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep0_gate -> layer_2_ep0_expert_2 [label="select tokens" style=dashed]
	layer_2_ep0_expert_3 [label="Expert-3\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep0_gate -> layer_2_ep0_expert_3 [label="select tokens" style=dashed]
	layer_2_ep0_expert_aggr [label="Expert Aggregation\nEP-Group-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_2_ep0_expert_0 -> layer_2_ep0_expert_aggr
	layer_2_ep0_expert_1 -> layer_2_ep0_expert_aggr
	layer_2_ep0_expert_2 -> layer_2_ep0_expert_aggr
	layer_2_ep0_expert_3 -> layer_2_ep0_expert_aggr
	layer_2_ep1_gate [label="MoE Gate\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_2_ep1_expert_0 [label="Expert-0\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep1_gate -> layer_2_ep1_expert_0 [label="select tokens" style=dashed]
	layer_2_ep1_expert_1 [label="Expert-1\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep1_gate -> layer_2_ep1_expert_1 [label="select tokens" style=dashed]
	layer_2_ep1_expert_2 [label="Expert-2\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep1_gate -> layer_2_ep1_expert_2 [label="select tokens" style=dashed]
	layer_2_ep1_expert_3 [label="Expert-3\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep1_gate -> layer_2_ep1_expert_3 [label="select tokens" style=dashed]
	layer_2_ep1_expert_aggr [label="Expert Aggregation\nEP-Group-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_2_ep1_expert_0 -> layer_2_ep1_expert_aggr
	layer_2_ep1_expert_1 -> layer_2_ep1_expert_aggr
	layer_2_ep1_expert_2 -> layer_2_ep1_expert_aggr
	layer_2_ep1_expert_3 -> layer_2_ep1_expert_aggr
	layer_2_ep2_gate [label="MoE Gate\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_2_ep2_expert_0 [label="Expert-0\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep2_gate -> layer_2_ep2_expert_0 [label="select tokens" style=dashed]
	layer_2_ep2_expert_1 [label="Expert-1\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep2_gate -> layer_2_ep2_expert_1 [label="select tokens" style=dashed]
	layer_2_ep2_expert_2 [label="Expert-2\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep2_gate -> layer_2_ep2_expert_2 [label="select tokens" style=dashed]
	layer_2_ep2_expert_3 [label="Expert-3\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep2_gate -> layer_2_ep2_expert_3 [label="select tokens" style=dashed]
	layer_2_ep2_expert_aggr [label="Expert Aggregation\nEP-Group-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_2_ep2_expert_0 -> layer_2_ep2_expert_aggr
	layer_2_ep2_expert_1 -> layer_2_ep2_expert_aggr
	layer_2_ep2_expert_2 -> layer_2_ep2_expert_aggr
	layer_2_ep2_expert_3 -> layer_2_ep2_expert_aggr
	layer_2_ep3_gate [label="MoE Gate\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_2_ep3_expert_0 [label="Expert-0\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep3_gate -> layer_2_ep3_expert_0 [label="select tokens" style=dashed]
	layer_2_ep3_expert_1 [label="Expert-1\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep3_gate -> layer_2_ep3_expert_1 [label="select tokens" style=dashed]
	layer_2_ep3_expert_2 [label="Expert-2\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep3_gate -> layer_2_ep3_expert_2 [label="select tokens" style=dashed]
	layer_2_ep3_expert_3 [label="Expert-3\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep3_gate -> layer_2_ep3_expert_3 [label="select tokens" style=dashed]
	layer_2_ep3_expert_aggr [label="Expert Aggregation\nEP-Group-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_2_ep3_expert_0 -> layer_2_ep3_expert_aggr
	layer_2_ep3_expert_1 -> layer_2_ep3_expert_aggr
	layer_2_ep3_expert_2 -> layer_2_ep3_expert_aggr
	layer_2_ep3_expert_3 -> layer_2_ep3_expert_aggr
	layer_2_ep4_gate [label="MoE Gate\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_2_ep4_expert_0 [label="Expert-0\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep4_gate -> layer_2_ep4_expert_0 [label="select tokens" style=dashed]
	layer_2_ep4_expert_1 [label="Expert-1\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep4_gate -> layer_2_ep4_expert_1 [label="select tokens" style=dashed]
	layer_2_ep4_expert_2 [label="Expert-2\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep4_gate -> layer_2_ep4_expert_2 [label="select tokens" style=dashed]
	layer_2_ep4_expert_3 [label="Expert-3\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep4_gate -> layer_2_ep4_expert_3 [label="select tokens" style=dashed]
	layer_2_ep4_expert_aggr [label="Expert Aggregation\nEP-Group-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_2_ep4_expert_0 -> layer_2_ep4_expert_aggr
	layer_2_ep4_expert_1 -> layer_2_ep4_expert_aggr
	layer_2_ep4_expert_2 -> layer_2_ep4_expert_aggr
	layer_2_ep4_expert_3 -> layer_2_ep4_expert_aggr
	layer_2_ep5_gate [label="MoE Gate\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_2_ep5_expert_0 [label="Expert-0\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep5_gate -> layer_2_ep5_expert_0 [label="select tokens" style=dashed]
	layer_2_ep5_expert_1 [label="Expert-1\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep5_gate -> layer_2_ep5_expert_1 [label="select tokens" style=dashed]
	layer_2_ep5_expert_2 [label="Expert-2\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep5_gate -> layer_2_ep5_expert_2 [label="select tokens" style=dashed]
	layer_2_ep5_expert_3 [label="Expert-3\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep5_gate -> layer_2_ep5_expert_3 [label="select tokens" style=dashed]
	layer_2_ep5_expert_aggr [label="Expert Aggregation\nEP-Group-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_2_ep5_expert_0 -> layer_2_ep5_expert_aggr
	layer_2_ep5_expert_1 -> layer_2_ep5_expert_aggr
	layer_2_ep5_expert_2 -> layer_2_ep5_expert_aggr
	layer_2_ep5_expert_3 -> layer_2_ep5_expert_aggr
	layer_2_ep6_gate [label="MoE Gate\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_2_ep6_expert_0 [label="Expert-0\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep6_gate -> layer_2_ep6_expert_0 [label="select tokens" style=dashed]
	layer_2_ep6_expert_1 [label="Expert-1\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep6_gate -> layer_2_ep6_expert_1 [label="select tokens" style=dashed]
	layer_2_ep6_expert_2 [label="Expert-2\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep6_gate -> layer_2_ep6_expert_2 [label="select tokens" style=dashed]
	layer_2_ep6_expert_3 [label="Expert-3\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep6_gate -> layer_2_ep6_expert_3 [label="select tokens" style=dashed]
	layer_2_ep6_expert_aggr [label="Expert Aggregation\nEP-Group-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_2_ep6_expert_0 -> layer_2_ep6_expert_aggr
	layer_2_ep6_expert_1 -> layer_2_ep6_expert_aggr
	layer_2_ep6_expert_2 -> layer_2_ep6_expert_aggr
	layer_2_ep6_expert_3 -> layer_2_ep6_expert_aggr
	layer_2_ep7_gate [label="MoE Gate\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_2_ep7_expert_0 [label="Expert-0\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep7_gate -> layer_2_ep7_expert_0 [label="select tokens" style=dashed]
	layer_2_ep7_expert_1 [label="Expert-1\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep7_gate -> layer_2_ep7_expert_1 [label="select tokens" style=dashed]
	layer_2_ep7_expert_2 [label="Expert-2\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep7_gate -> layer_2_ep7_expert_2 [label="select tokens" style=dashed]
	layer_2_ep7_expert_3 [label="Expert-3\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep7_gate -> layer_2_ep7_expert_3 [label="select tokens" style=dashed]
	layer_2_ep7_expert_aggr [label="Expert Aggregation\nEP-Group-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_2_ep7_expert_0 -> layer_2_ep7_expert_aggr
	layer_2_ep7_expert_1 -> layer_2_ep7_expert_aggr
	layer_2_ep7_expert_2 -> layer_2_ep7_expert_aggr
	layer_2_ep7_expert_3 -> layer_2_ep7_expert_aggr
	layer_2_ep8_gate [label="MoE Gate\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_2_ep8_expert_0 [label="Expert-0\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep8_gate -> layer_2_ep8_expert_0 [label="select tokens" style=dashed]
	layer_2_ep8_expert_1 [label="Expert-1\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep8_gate -> layer_2_ep8_expert_1 [label="select tokens" style=dashed]
	layer_2_ep8_expert_2 [label="Expert-2\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep8_gate -> layer_2_ep8_expert_2 [label="select tokens" style=dashed]
	layer_2_ep8_expert_3 [label="Expert-3\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep8_gate -> layer_2_ep8_expert_3 [label="select tokens" style=dashed]
	layer_2_ep8_expert_aggr [label="Expert Aggregation\nEP-Group-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_2_ep8_expert_0 -> layer_2_ep8_expert_aggr
	layer_2_ep8_expert_1 -> layer_2_ep8_expert_aggr
	layer_2_ep8_expert_2 -> layer_2_ep8_expert_aggr
	layer_2_ep8_expert_3 -> layer_2_ep8_expert_aggr
	layer_2_ep9_gate [label="MoE Gate\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_2_ep9_expert_0 [label="Expert-0\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep9_gate -> layer_2_ep9_expert_0 [label="select tokens" style=dashed]
	layer_2_ep9_expert_1 [label="Expert-1\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep9_gate -> layer_2_ep9_expert_1 [label="select tokens" style=dashed]
	layer_2_ep9_expert_2 [label="Expert-2\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep9_gate -> layer_2_ep9_expert_2 [label="select tokens" style=dashed]
	layer_2_ep9_expert_3 [label="Expert-3\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep9_gate -> layer_2_ep9_expert_3 [label="select tokens" style=dashed]
	layer_2_ep9_expert_aggr [label="Expert Aggregation\nEP-Group-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_2_ep9_expert_0 -> layer_2_ep9_expert_aggr
	layer_2_ep9_expert_1 -> layer_2_ep9_expert_aggr
	layer_2_ep9_expert_2 -> layer_2_ep9_expert_aggr
	layer_2_ep9_expert_3 -> layer_2_ep9_expert_aggr
	layer_2_ep10_gate [label="MoE Gate\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_2_ep10_expert_0 [label="Expert-0\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep10_gate -> layer_2_ep10_expert_0 [label="select tokens" style=dashed]
	layer_2_ep10_expert_1 [label="Expert-1\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep10_gate -> layer_2_ep10_expert_1 [label="select tokens" style=dashed]
	layer_2_ep10_expert_2 [label="Expert-2\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep10_gate -> layer_2_ep10_expert_2 [label="select tokens" style=dashed]
	layer_2_ep10_expert_3 [label="Expert-3\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep10_gate -> layer_2_ep10_expert_3 [label="select tokens" style=dashed]
	layer_2_ep10_expert_aggr [label="Expert Aggregation\nEP-Group-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_2_ep10_expert_0 -> layer_2_ep10_expert_aggr
	layer_2_ep10_expert_1 -> layer_2_ep10_expert_aggr
	layer_2_ep10_expert_2 -> layer_2_ep10_expert_aggr
	layer_2_ep10_expert_3 -> layer_2_ep10_expert_aggr
	layer_2_ep11_gate [label="MoE Gate\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_2_ep11_expert_0 [label="Expert-0\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep11_gate -> layer_2_ep11_expert_0 [label="select tokens" style=dashed]
	layer_2_ep11_expert_1 [label="Expert-1\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep11_gate -> layer_2_ep11_expert_1 [label="select tokens" style=dashed]
	layer_2_ep11_expert_2 [label="Expert-2\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep11_gate -> layer_2_ep11_expert_2 [label="select tokens" style=dashed]
	layer_2_ep11_expert_3 [label="Expert-3\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep11_gate -> layer_2_ep11_expert_3 [label="select tokens" style=dashed]
	layer_2_ep11_expert_aggr [label="Expert Aggregation\nEP-Group-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_2_ep11_expert_0 -> layer_2_ep11_expert_aggr
	layer_2_ep11_expert_1 -> layer_2_ep11_expert_aggr
	layer_2_ep11_expert_2 -> layer_2_ep11_expert_aggr
	layer_2_ep11_expert_3 -> layer_2_ep11_expert_aggr
	layer_2_ep12_gate [label="MoE Gate\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_2_ep12_expert_0 [label="Expert-0\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep12_gate -> layer_2_ep12_expert_0 [label="select tokens" style=dashed]
	layer_2_ep12_expert_1 [label="Expert-1\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep12_gate -> layer_2_ep12_expert_1 [label="select tokens" style=dashed]
	layer_2_ep12_expert_2 [label="Expert-2\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep12_gate -> layer_2_ep12_expert_2 [label="select tokens" style=dashed]
	layer_2_ep12_expert_3 [label="Expert-3\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep12_gate -> layer_2_ep12_expert_3 [label="select tokens" style=dashed]
	layer_2_ep12_expert_aggr [label="Expert Aggregation\nEP-Group-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_2_ep12_expert_0 -> layer_2_ep12_expert_aggr
	layer_2_ep12_expert_1 -> layer_2_ep12_expert_aggr
	layer_2_ep12_expert_2 -> layer_2_ep12_expert_aggr
	layer_2_ep12_expert_3 -> layer_2_ep12_expert_aggr
	layer_2_ep13_gate [label="MoE Gate\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_2_ep13_expert_0 [label="Expert-0\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep13_gate -> layer_2_ep13_expert_0 [label="select tokens" style=dashed]
	layer_2_ep13_expert_1 [label="Expert-1\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep13_gate -> layer_2_ep13_expert_1 [label="select tokens" style=dashed]
	layer_2_ep13_expert_2 [label="Expert-2\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep13_gate -> layer_2_ep13_expert_2 [label="select tokens" style=dashed]
	layer_2_ep13_expert_3 [label="Expert-3\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep13_gate -> layer_2_ep13_expert_3 [label="select tokens" style=dashed]
	layer_2_ep13_expert_aggr [label="Expert Aggregation\nEP-Group-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_2_ep13_expert_0 -> layer_2_ep13_expert_aggr
	layer_2_ep13_expert_1 -> layer_2_ep13_expert_aggr
	layer_2_ep13_expert_2 -> layer_2_ep13_expert_aggr
	layer_2_ep13_expert_3 -> layer_2_ep13_expert_aggr
	layer_2_ep14_gate [label="MoE Gate\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_2_ep14_expert_0 [label="Expert-0\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep14_gate -> layer_2_ep14_expert_0 [label="select tokens" style=dashed]
	layer_2_ep14_expert_1 [label="Expert-1\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep14_gate -> layer_2_ep14_expert_1 [label="select tokens" style=dashed]
	layer_2_ep14_expert_2 [label="Expert-2\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep14_gate -> layer_2_ep14_expert_2 [label="select tokens" style=dashed]
	layer_2_ep14_expert_3 [label="Expert-3\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep14_gate -> layer_2_ep14_expert_3 [label="select tokens" style=dashed]
	layer_2_ep14_expert_aggr [label="Expert Aggregation\nEP-Group-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_2_ep14_expert_0 -> layer_2_ep14_expert_aggr
	layer_2_ep14_expert_1 -> layer_2_ep14_expert_aggr
	layer_2_ep14_expert_2 -> layer_2_ep14_expert_aggr
	layer_2_ep14_expert_3 -> layer_2_ep14_expert_aggr
	layer_2_ep15_gate [label="MoE Gate\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_2_ep15_expert_0 [label="Expert-0\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep15_gate -> layer_2_ep15_expert_0 [label="select tokens" style=dashed]
	layer_2_ep15_expert_1 [label="Expert-1\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep15_gate -> layer_2_ep15_expert_1 [label="select tokens" style=dashed]
	layer_2_ep15_expert_2 [label="Expert-2\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep15_gate -> layer_2_ep15_expert_2 [label="select tokens" style=dashed]
	layer_2_ep15_expert_3 [label="Expert-3\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_2_ep15_gate -> layer_2_ep15_expert_3 [label="select tokens" style=dashed]
	layer_2_ep15_expert_aggr [label="Expert Aggregation\nEP-Group-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_2_ep15_expert_0 -> layer_2_ep15_expert_aggr
	layer_2_ep15_expert_1 -> layer_2_ep15_expert_aggr
	layer_2_ep15_expert_2 -> layer_2_ep15_expert_aggr
	layer_2_ep15_expert_3 -> layer_2_ep15_expert_aggr
	layer_2_to_3_ep0_pp [label="Pipeline Stage Transfer\nEP-Group-0\nLayer-2 to Layer-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_2_ep0_expert_aggr -> layer_2_to_3_ep0_pp
	layer_2_to_3_ep1_pp [label="Pipeline Stage Transfer\nEP-Group-1\nLayer-2 to Layer-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_2_ep1_expert_aggr -> layer_2_to_3_ep1_pp
	layer_2_to_3_ep2_pp [label="Pipeline Stage Transfer\nEP-Group-2\nLayer-2 to Layer-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_2_ep2_expert_aggr -> layer_2_to_3_ep2_pp
	layer_2_to_3_ep3_pp [label="Pipeline Stage Transfer\nEP-Group-3\nLayer-2 to Layer-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_2_ep3_expert_aggr -> layer_2_to_3_ep3_pp
	layer_2_to_3_ep4_pp [label="Pipeline Stage Transfer\nEP-Group-4\nLayer-2 to Layer-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_2_ep4_expert_aggr -> layer_2_to_3_ep4_pp
	layer_2_to_3_ep5_pp [label="Pipeline Stage Transfer\nEP-Group-5\nLayer-2 to Layer-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_2_ep5_expert_aggr -> layer_2_to_3_ep5_pp
	layer_2_to_3_ep6_pp [label="Pipeline Stage Transfer\nEP-Group-6\nLayer-2 to Layer-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_2_ep6_expert_aggr -> layer_2_to_3_ep6_pp
	layer_2_to_3_ep7_pp [label="Pipeline Stage Transfer\nEP-Group-7\nLayer-2 to Layer-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_2_ep7_expert_aggr -> layer_2_to_3_ep7_pp
	layer_2_to_3_ep8_pp [label="Pipeline Stage Transfer\nEP-Group-8\nLayer-2 to Layer-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_2_ep8_expert_aggr -> layer_2_to_3_ep8_pp
	layer_2_to_3_ep9_pp [label="Pipeline Stage Transfer\nEP-Group-9\nLayer-2 to Layer-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_2_ep9_expert_aggr -> layer_2_to_3_ep9_pp
	layer_2_to_3_ep10_pp [label="Pipeline Stage Transfer\nEP-Group-10\nLayer-2 to Layer-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_2_ep10_expert_aggr -> layer_2_to_3_ep10_pp
	layer_2_to_3_ep11_pp [label="Pipeline Stage Transfer\nEP-Group-11\nLayer-2 to Layer-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_2_ep11_expert_aggr -> layer_2_to_3_ep11_pp
	layer_2_to_3_ep12_pp [label="Pipeline Stage Transfer\nEP-Group-12\nLayer-2 to Layer-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_2_ep12_expert_aggr -> layer_2_to_3_ep12_pp
	layer_2_to_3_ep13_pp [label="Pipeline Stage Transfer\nEP-Group-13\nLayer-2 to Layer-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_2_ep13_expert_aggr -> layer_2_to_3_ep13_pp
	layer_2_to_3_ep14_pp [label="Pipeline Stage Transfer\nEP-Group-14\nLayer-2 to Layer-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_2_ep14_expert_aggr -> layer_2_to_3_ep14_pp
	layer_2_to_3_ep15_pp [label="Pipeline Stage Transfer\nEP-Group-15\nLayer-2 to Layer-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_2_ep15_expert_aggr -> layer_2_to_3_ep15_pp
	layer_3_ep0_tp0_sa_qkv [label="Self-Attn QKV\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep0_tp0_sa_attn [label="Self-Attn Compute\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep0_tp0_sa_out [label="Self-Attn Output\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep0_tp0_sa_qkv -> layer_3_ep0_tp0_sa_attn
	layer_3_ep0_tp0_sa_attn -> layer_3_ep0_tp0_sa_out
	layer_3_ep0_tp1_sa_qkv [label="Self-Attn QKV\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep0_tp1_sa_attn [label="Self-Attn Compute\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep0_tp1_sa_out [label="Self-Attn Output\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep0_tp1_sa_qkv -> layer_3_ep0_tp1_sa_attn
	layer_3_ep0_tp1_sa_attn -> layer_3_ep0_tp1_sa_out
	layer_3_ep0_tp2_sa_qkv [label="Self-Attn QKV\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep0_tp2_sa_attn [label="Self-Attn Compute\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep0_tp2_sa_out [label="Self-Attn Output\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep0_tp2_sa_qkv -> layer_3_ep0_tp2_sa_attn
	layer_3_ep0_tp2_sa_attn -> layer_3_ep0_tp2_sa_out
	layer_3_ep0_tp3_sa_qkv [label="Self-Attn QKV\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep0_tp3_sa_attn [label="Self-Attn Compute\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep0_tp3_sa_out [label="Self-Attn Output\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep0_tp3_sa_qkv -> layer_3_ep0_tp3_sa_attn
	layer_3_ep0_tp3_sa_attn -> layer_3_ep0_tp3_sa_out
	layer_3_ep1_tp0_sa_qkv [label="Self-Attn QKV\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep1_tp0_sa_attn [label="Self-Attn Compute\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep1_tp0_sa_out [label="Self-Attn Output\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep1_tp0_sa_qkv -> layer_3_ep1_tp0_sa_attn
	layer_3_ep1_tp0_sa_attn -> layer_3_ep1_tp0_sa_out
	layer_3_ep1_tp1_sa_qkv [label="Self-Attn QKV\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep1_tp1_sa_attn [label="Self-Attn Compute\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep1_tp1_sa_out [label="Self-Attn Output\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep1_tp1_sa_qkv -> layer_3_ep1_tp1_sa_attn
	layer_3_ep1_tp1_sa_attn -> layer_3_ep1_tp1_sa_out
	layer_3_ep1_tp2_sa_qkv [label="Self-Attn QKV\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep1_tp2_sa_attn [label="Self-Attn Compute\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep1_tp2_sa_out [label="Self-Attn Output\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep1_tp2_sa_qkv -> layer_3_ep1_tp2_sa_attn
	layer_3_ep1_tp2_sa_attn -> layer_3_ep1_tp2_sa_out
	layer_3_ep1_tp3_sa_qkv [label="Self-Attn QKV\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep1_tp3_sa_attn [label="Self-Attn Compute\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep1_tp3_sa_out [label="Self-Attn Output\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep1_tp3_sa_qkv -> layer_3_ep1_tp3_sa_attn
	layer_3_ep1_tp3_sa_attn -> layer_3_ep1_tp3_sa_out
	layer_3_ep2_tp0_sa_qkv [label="Self-Attn QKV\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep2_tp0_sa_attn [label="Self-Attn Compute\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep2_tp0_sa_out [label="Self-Attn Output\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep2_tp0_sa_qkv -> layer_3_ep2_tp0_sa_attn
	layer_3_ep2_tp0_sa_attn -> layer_3_ep2_tp0_sa_out
	layer_3_ep2_tp1_sa_qkv [label="Self-Attn QKV\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep2_tp1_sa_attn [label="Self-Attn Compute\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep2_tp1_sa_out [label="Self-Attn Output\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep2_tp1_sa_qkv -> layer_3_ep2_tp1_sa_attn
	layer_3_ep2_tp1_sa_attn -> layer_3_ep2_tp1_sa_out
	layer_3_ep2_tp2_sa_qkv [label="Self-Attn QKV\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep2_tp2_sa_attn [label="Self-Attn Compute\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep2_tp2_sa_out [label="Self-Attn Output\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep2_tp2_sa_qkv -> layer_3_ep2_tp2_sa_attn
	layer_3_ep2_tp2_sa_attn -> layer_3_ep2_tp2_sa_out
	layer_3_ep2_tp3_sa_qkv [label="Self-Attn QKV\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep2_tp3_sa_attn [label="Self-Attn Compute\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep2_tp3_sa_out [label="Self-Attn Output\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep2_tp3_sa_qkv -> layer_3_ep2_tp3_sa_attn
	layer_3_ep2_tp3_sa_attn -> layer_3_ep2_tp3_sa_out
	layer_3_ep3_tp0_sa_qkv [label="Self-Attn QKV\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep3_tp0_sa_attn [label="Self-Attn Compute\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep3_tp0_sa_out [label="Self-Attn Output\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep3_tp0_sa_qkv -> layer_3_ep3_tp0_sa_attn
	layer_3_ep3_tp0_sa_attn -> layer_3_ep3_tp0_sa_out
	layer_3_ep3_tp1_sa_qkv [label="Self-Attn QKV\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep3_tp1_sa_attn [label="Self-Attn Compute\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep3_tp1_sa_out [label="Self-Attn Output\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep3_tp1_sa_qkv -> layer_3_ep3_tp1_sa_attn
	layer_3_ep3_tp1_sa_attn -> layer_3_ep3_tp1_sa_out
	layer_3_ep3_tp2_sa_qkv [label="Self-Attn QKV\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep3_tp2_sa_attn [label="Self-Attn Compute\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep3_tp2_sa_out [label="Self-Attn Output\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep3_tp2_sa_qkv -> layer_3_ep3_tp2_sa_attn
	layer_3_ep3_tp2_sa_attn -> layer_3_ep3_tp2_sa_out
	layer_3_ep3_tp3_sa_qkv [label="Self-Attn QKV\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep3_tp3_sa_attn [label="Self-Attn Compute\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep3_tp3_sa_out [label="Self-Attn Output\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep3_tp3_sa_qkv -> layer_3_ep3_tp3_sa_attn
	layer_3_ep3_tp3_sa_attn -> layer_3_ep3_tp3_sa_out
	layer_3_ep4_tp0_sa_qkv [label="Self-Attn QKV\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep4_tp0_sa_attn [label="Self-Attn Compute\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep4_tp0_sa_out [label="Self-Attn Output\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep4_tp0_sa_qkv -> layer_3_ep4_tp0_sa_attn
	layer_3_ep4_tp0_sa_attn -> layer_3_ep4_tp0_sa_out
	layer_3_ep4_tp1_sa_qkv [label="Self-Attn QKV\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep4_tp1_sa_attn [label="Self-Attn Compute\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep4_tp1_sa_out [label="Self-Attn Output\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep4_tp1_sa_qkv -> layer_3_ep4_tp1_sa_attn
	layer_3_ep4_tp1_sa_attn -> layer_3_ep4_tp1_sa_out
	layer_3_ep4_tp2_sa_qkv [label="Self-Attn QKV\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep4_tp2_sa_attn [label="Self-Attn Compute\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep4_tp2_sa_out [label="Self-Attn Output\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep4_tp2_sa_qkv -> layer_3_ep4_tp2_sa_attn
	layer_3_ep4_tp2_sa_attn -> layer_3_ep4_tp2_sa_out
	layer_3_ep4_tp3_sa_qkv [label="Self-Attn QKV\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep4_tp3_sa_attn [label="Self-Attn Compute\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep4_tp3_sa_out [label="Self-Attn Output\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep4_tp3_sa_qkv -> layer_3_ep4_tp3_sa_attn
	layer_3_ep4_tp3_sa_attn -> layer_3_ep4_tp3_sa_out
	layer_3_ep5_tp0_sa_qkv [label="Self-Attn QKV\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep5_tp0_sa_attn [label="Self-Attn Compute\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep5_tp0_sa_out [label="Self-Attn Output\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep5_tp0_sa_qkv -> layer_3_ep5_tp0_sa_attn
	layer_3_ep5_tp0_sa_attn -> layer_3_ep5_tp0_sa_out
	layer_3_ep5_tp1_sa_qkv [label="Self-Attn QKV\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep5_tp1_sa_attn [label="Self-Attn Compute\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep5_tp1_sa_out [label="Self-Attn Output\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep5_tp1_sa_qkv -> layer_3_ep5_tp1_sa_attn
	layer_3_ep5_tp1_sa_attn -> layer_3_ep5_tp1_sa_out
	layer_3_ep5_tp2_sa_qkv [label="Self-Attn QKV\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep5_tp2_sa_attn [label="Self-Attn Compute\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep5_tp2_sa_out [label="Self-Attn Output\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep5_tp2_sa_qkv -> layer_3_ep5_tp2_sa_attn
	layer_3_ep5_tp2_sa_attn -> layer_3_ep5_tp2_sa_out
	layer_3_ep5_tp3_sa_qkv [label="Self-Attn QKV\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep5_tp3_sa_attn [label="Self-Attn Compute\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep5_tp3_sa_out [label="Self-Attn Output\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep5_tp3_sa_qkv -> layer_3_ep5_tp3_sa_attn
	layer_3_ep5_tp3_sa_attn -> layer_3_ep5_tp3_sa_out
	layer_3_ep6_tp0_sa_qkv [label="Self-Attn QKV\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep6_tp0_sa_attn [label="Self-Attn Compute\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep6_tp0_sa_out [label="Self-Attn Output\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep6_tp0_sa_qkv -> layer_3_ep6_tp0_sa_attn
	layer_3_ep6_tp0_sa_attn -> layer_3_ep6_tp0_sa_out
	layer_3_ep6_tp1_sa_qkv [label="Self-Attn QKV\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep6_tp1_sa_attn [label="Self-Attn Compute\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep6_tp1_sa_out [label="Self-Attn Output\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep6_tp1_sa_qkv -> layer_3_ep6_tp1_sa_attn
	layer_3_ep6_tp1_sa_attn -> layer_3_ep6_tp1_sa_out
	layer_3_ep6_tp2_sa_qkv [label="Self-Attn QKV\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep6_tp2_sa_attn [label="Self-Attn Compute\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep6_tp2_sa_out [label="Self-Attn Output\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep6_tp2_sa_qkv -> layer_3_ep6_tp2_sa_attn
	layer_3_ep6_tp2_sa_attn -> layer_3_ep6_tp2_sa_out
	layer_3_ep6_tp3_sa_qkv [label="Self-Attn QKV\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep6_tp3_sa_attn [label="Self-Attn Compute\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep6_tp3_sa_out [label="Self-Attn Output\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep6_tp3_sa_qkv -> layer_3_ep6_tp3_sa_attn
	layer_3_ep6_tp3_sa_attn -> layer_3_ep6_tp3_sa_out
	layer_3_ep7_tp0_sa_qkv [label="Self-Attn QKV\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep7_tp0_sa_attn [label="Self-Attn Compute\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep7_tp0_sa_out [label="Self-Attn Output\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep7_tp0_sa_qkv -> layer_3_ep7_tp0_sa_attn
	layer_3_ep7_tp0_sa_attn -> layer_3_ep7_tp0_sa_out
	layer_3_ep7_tp1_sa_qkv [label="Self-Attn QKV\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep7_tp1_sa_attn [label="Self-Attn Compute\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep7_tp1_sa_out [label="Self-Attn Output\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep7_tp1_sa_qkv -> layer_3_ep7_tp1_sa_attn
	layer_3_ep7_tp1_sa_attn -> layer_3_ep7_tp1_sa_out
	layer_3_ep7_tp2_sa_qkv [label="Self-Attn QKV\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep7_tp2_sa_attn [label="Self-Attn Compute\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep7_tp2_sa_out [label="Self-Attn Output\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep7_tp2_sa_qkv -> layer_3_ep7_tp2_sa_attn
	layer_3_ep7_tp2_sa_attn -> layer_3_ep7_tp2_sa_out
	layer_3_ep7_tp3_sa_qkv [label="Self-Attn QKV\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep7_tp3_sa_attn [label="Self-Attn Compute\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep7_tp3_sa_out [label="Self-Attn Output\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep7_tp3_sa_qkv -> layer_3_ep7_tp3_sa_attn
	layer_3_ep7_tp3_sa_attn -> layer_3_ep7_tp3_sa_out
	layer_3_ep8_tp0_sa_qkv [label="Self-Attn QKV\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep8_tp0_sa_attn [label="Self-Attn Compute\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep8_tp0_sa_out [label="Self-Attn Output\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep8_tp0_sa_qkv -> layer_3_ep8_tp0_sa_attn
	layer_3_ep8_tp0_sa_attn -> layer_3_ep8_tp0_sa_out
	layer_3_ep8_tp1_sa_qkv [label="Self-Attn QKV\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep8_tp1_sa_attn [label="Self-Attn Compute\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep8_tp1_sa_out [label="Self-Attn Output\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep8_tp1_sa_qkv -> layer_3_ep8_tp1_sa_attn
	layer_3_ep8_tp1_sa_attn -> layer_3_ep8_tp1_sa_out
	layer_3_ep8_tp2_sa_qkv [label="Self-Attn QKV\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep8_tp2_sa_attn [label="Self-Attn Compute\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep8_tp2_sa_out [label="Self-Attn Output\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep8_tp2_sa_qkv -> layer_3_ep8_tp2_sa_attn
	layer_3_ep8_tp2_sa_attn -> layer_3_ep8_tp2_sa_out
	layer_3_ep8_tp3_sa_qkv [label="Self-Attn QKV\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep8_tp3_sa_attn [label="Self-Attn Compute\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep8_tp3_sa_out [label="Self-Attn Output\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep8_tp3_sa_qkv -> layer_3_ep8_tp3_sa_attn
	layer_3_ep8_tp3_sa_attn -> layer_3_ep8_tp3_sa_out
	layer_3_ep9_tp0_sa_qkv [label="Self-Attn QKV\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep9_tp0_sa_attn [label="Self-Attn Compute\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep9_tp0_sa_out [label="Self-Attn Output\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep9_tp0_sa_qkv -> layer_3_ep9_tp0_sa_attn
	layer_3_ep9_tp0_sa_attn -> layer_3_ep9_tp0_sa_out
	layer_3_ep9_tp1_sa_qkv [label="Self-Attn QKV\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep9_tp1_sa_attn [label="Self-Attn Compute\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep9_tp1_sa_out [label="Self-Attn Output\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep9_tp1_sa_qkv -> layer_3_ep9_tp1_sa_attn
	layer_3_ep9_tp1_sa_attn -> layer_3_ep9_tp1_sa_out
	layer_3_ep9_tp2_sa_qkv [label="Self-Attn QKV\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep9_tp2_sa_attn [label="Self-Attn Compute\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep9_tp2_sa_out [label="Self-Attn Output\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep9_tp2_sa_qkv -> layer_3_ep9_tp2_sa_attn
	layer_3_ep9_tp2_sa_attn -> layer_3_ep9_tp2_sa_out
	layer_3_ep9_tp3_sa_qkv [label="Self-Attn QKV\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep9_tp3_sa_attn [label="Self-Attn Compute\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep9_tp3_sa_out [label="Self-Attn Output\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep9_tp3_sa_qkv -> layer_3_ep9_tp3_sa_attn
	layer_3_ep9_tp3_sa_attn -> layer_3_ep9_tp3_sa_out
	layer_3_ep10_tp0_sa_qkv [label="Self-Attn QKV\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep10_tp0_sa_attn [label="Self-Attn Compute\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep10_tp0_sa_out [label="Self-Attn Output\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep10_tp0_sa_qkv -> layer_3_ep10_tp0_sa_attn
	layer_3_ep10_tp0_sa_attn -> layer_3_ep10_tp0_sa_out
	layer_3_ep10_tp1_sa_qkv [label="Self-Attn QKV\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep10_tp1_sa_attn [label="Self-Attn Compute\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep10_tp1_sa_out [label="Self-Attn Output\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep10_tp1_sa_qkv -> layer_3_ep10_tp1_sa_attn
	layer_3_ep10_tp1_sa_attn -> layer_3_ep10_tp1_sa_out
	layer_3_ep10_tp2_sa_qkv [label="Self-Attn QKV\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep10_tp2_sa_attn [label="Self-Attn Compute\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep10_tp2_sa_out [label="Self-Attn Output\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep10_tp2_sa_qkv -> layer_3_ep10_tp2_sa_attn
	layer_3_ep10_tp2_sa_attn -> layer_3_ep10_tp2_sa_out
	layer_3_ep10_tp3_sa_qkv [label="Self-Attn QKV\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep10_tp3_sa_attn [label="Self-Attn Compute\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep10_tp3_sa_out [label="Self-Attn Output\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep10_tp3_sa_qkv -> layer_3_ep10_tp3_sa_attn
	layer_3_ep10_tp3_sa_attn -> layer_3_ep10_tp3_sa_out
	layer_3_ep11_tp0_sa_qkv [label="Self-Attn QKV\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep11_tp0_sa_attn [label="Self-Attn Compute\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep11_tp0_sa_out [label="Self-Attn Output\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep11_tp0_sa_qkv -> layer_3_ep11_tp0_sa_attn
	layer_3_ep11_tp0_sa_attn -> layer_3_ep11_tp0_sa_out
	layer_3_ep11_tp1_sa_qkv [label="Self-Attn QKV\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep11_tp1_sa_attn [label="Self-Attn Compute\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep11_tp1_sa_out [label="Self-Attn Output\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep11_tp1_sa_qkv -> layer_3_ep11_tp1_sa_attn
	layer_3_ep11_tp1_sa_attn -> layer_3_ep11_tp1_sa_out
	layer_3_ep11_tp2_sa_qkv [label="Self-Attn QKV\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep11_tp2_sa_attn [label="Self-Attn Compute\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep11_tp2_sa_out [label="Self-Attn Output\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep11_tp2_sa_qkv -> layer_3_ep11_tp2_sa_attn
	layer_3_ep11_tp2_sa_attn -> layer_3_ep11_tp2_sa_out
	layer_3_ep11_tp3_sa_qkv [label="Self-Attn QKV\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep11_tp3_sa_attn [label="Self-Attn Compute\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep11_tp3_sa_out [label="Self-Attn Output\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep11_tp3_sa_qkv -> layer_3_ep11_tp3_sa_attn
	layer_3_ep11_tp3_sa_attn -> layer_3_ep11_tp3_sa_out
	layer_3_ep12_tp0_sa_qkv [label="Self-Attn QKV\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep12_tp0_sa_attn [label="Self-Attn Compute\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep12_tp0_sa_out [label="Self-Attn Output\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep12_tp0_sa_qkv -> layer_3_ep12_tp0_sa_attn
	layer_3_ep12_tp0_sa_attn -> layer_3_ep12_tp0_sa_out
	layer_3_ep12_tp1_sa_qkv [label="Self-Attn QKV\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep12_tp1_sa_attn [label="Self-Attn Compute\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep12_tp1_sa_out [label="Self-Attn Output\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep12_tp1_sa_qkv -> layer_3_ep12_tp1_sa_attn
	layer_3_ep12_tp1_sa_attn -> layer_3_ep12_tp1_sa_out
	layer_3_ep12_tp2_sa_qkv [label="Self-Attn QKV\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep12_tp2_sa_attn [label="Self-Attn Compute\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep12_tp2_sa_out [label="Self-Attn Output\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep12_tp2_sa_qkv -> layer_3_ep12_tp2_sa_attn
	layer_3_ep12_tp2_sa_attn -> layer_3_ep12_tp2_sa_out
	layer_3_ep12_tp3_sa_qkv [label="Self-Attn QKV\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep12_tp3_sa_attn [label="Self-Attn Compute\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep12_tp3_sa_out [label="Self-Attn Output\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep12_tp3_sa_qkv -> layer_3_ep12_tp3_sa_attn
	layer_3_ep12_tp3_sa_attn -> layer_3_ep12_tp3_sa_out
	layer_3_ep13_tp0_sa_qkv [label="Self-Attn QKV\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep13_tp0_sa_attn [label="Self-Attn Compute\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep13_tp0_sa_out [label="Self-Attn Output\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep13_tp0_sa_qkv -> layer_3_ep13_tp0_sa_attn
	layer_3_ep13_tp0_sa_attn -> layer_3_ep13_tp0_sa_out
	layer_3_ep13_tp1_sa_qkv [label="Self-Attn QKV\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep13_tp1_sa_attn [label="Self-Attn Compute\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep13_tp1_sa_out [label="Self-Attn Output\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep13_tp1_sa_qkv -> layer_3_ep13_tp1_sa_attn
	layer_3_ep13_tp1_sa_attn -> layer_3_ep13_tp1_sa_out
	layer_3_ep13_tp2_sa_qkv [label="Self-Attn QKV\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep13_tp2_sa_attn [label="Self-Attn Compute\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep13_tp2_sa_out [label="Self-Attn Output\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep13_tp2_sa_qkv -> layer_3_ep13_tp2_sa_attn
	layer_3_ep13_tp2_sa_attn -> layer_3_ep13_tp2_sa_out
	layer_3_ep13_tp3_sa_qkv [label="Self-Attn QKV\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep13_tp3_sa_attn [label="Self-Attn Compute\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep13_tp3_sa_out [label="Self-Attn Output\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep13_tp3_sa_qkv -> layer_3_ep13_tp3_sa_attn
	layer_3_ep13_tp3_sa_attn -> layer_3_ep13_tp3_sa_out
	layer_3_ep14_tp0_sa_qkv [label="Self-Attn QKV\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep14_tp0_sa_attn [label="Self-Attn Compute\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep14_tp0_sa_out [label="Self-Attn Output\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep14_tp0_sa_qkv -> layer_3_ep14_tp0_sa_attn
	layer_3_ep14_tp0_sa_attn -> layer_3_ep14_tp0_sa_out
	layer_3_ep14_tp1_sa_qkv [label="Self-Attn QKV\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep14_tp1_sa_attn [label="Self-Attn Compute\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep14_tp1_sa_out [label="Self-Attn Output\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep14_tp1_sa_qkv -> layer_3_ep14_tp1_sa_attn
	layer_3_ep14_tp1_sa_attn -> layer_3_ep14_tp1_sa_out
	layer_3_ep14_tp2_sa_qkv [label="Self-Attn QKV\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep14_tp2_sa_attn [label="Self-Attn Compute\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep14_tp2_sa_out [label="Self-Attn Output\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep14_tp2_sa_qkv -> layer_3_ep14_tp2_sa_attn
	layer_3_ep14_tp2_sa_attn -> layer_3_ep14_tp2_sa_out
	layer_3_ep14_tp3_sa_qkv [label="Self-Attn QKV\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep14_tp3_sa_attn [label="Self-Attn Compute\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep14_tp3_sa_out [label="Self-Attn Output\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep14_tp3_sa_qkv -> layer_3_ep14_tp3_sa_attn
	layer_3_ep14_tp3_sa_attn -> layer_3_ep14_tp3_sa_out
	layer_3_ep15_tp0_sa_qkv [label="Self-Attn QKV\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep15_tp0_sa_attn [label="Self-Attn Compute\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep15_tp0_sa_out [label="Self-Attn Output\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep15_tp0_sa_qkv -> layer_3_ep15_tp0_sa_attn
	layer_3_ep15_tp0_sa_attn -> layer_3_ep15_tp0_sa_out
	layer_3_ep15_tp1_sa_qkv [label="Self-Attn QKV\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep15_tp1_sa_attn [label="Self-Attn Compute\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep15_tp1_sa_out [label="Self-Attn Output\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep15_tp1_sa_qkv -> layer_3_ep15_tp1_sa_attn
	layer_3_ep15_tp1_sa_attn -> layer_3_ep15_tp1_sa_out
	layer_3_ep15_tp2_sa_qkv [label="Self-Attn QKV\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep15_tp2_sa_attn [label="Self-Attn Compute\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep15_tp2_sa_out [label="Self-Attn Output\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep15_tp2_sa_qkv -> layer_3_ep15_tp2_sa_attn
	layer_3_ep15_tp2_sa_attn -> layer_3_ep15_tp2_sa_out
	layer_3_ep15_tp3_sa_qkv [label="Self-Attn QKV\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep15_tp3_sa_attn [label="Self-Attn Compute\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep15_tp3_sa_out [label="Self-Attn Output\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep15_tp3_sa_qkv -> layer_3_ep15_tp3_sa_attn
	layer_3_ep15_tp3_sa_attn -> layer_3_ep15_tp3_sa_out
	layer_3_ep0_tp_allreduce [label="TP All-Reduce\nEP-Group-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_3_ep0_tp0_sa_out -> layer_3_ep0_tp_allreduce
	layer_3_ep0_tp1_sa_out -> layer_3_ep0_tp_allreduce
	layer_3_ep0_tp2_sa_out -> layer_3_ep0_tp_allreduce
	layer_3_ep0_tp3_sa_out -> layer_3_ep0_tp_allreduce
	layer_3_ep1_tp_allreduce [label="TP All-Reduce\nEP-Group-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_3_ep1_tp0_sa_out -> layer_3_ep1_tp_allreduce
	layer_3_ep1_tp1_sa_out -> layer_3_ep1_tp_allreduce
	layer_3_ep1_tp2_sa_out -> layer_3_ep1_tp_allreduce
	layer_3_ep1_tp3_sa_out -> layer_3_ep1_tp_allreduce
	layer_3_ep2_tp_allreduce [label="TP All-Reduce\nEP-Group-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_3_ep2_tp0_sa_out -> layer_3_ep2_tp_allreduce
	layer_3_ep2_tp1_sa_out -> layer_3_ep2_tp_allreduce
	layer_3_ep2_tp2_sa_out -> layer_3_ep2_tp_allreduce
	layer_3_ep2_tp3_sa_out -> layer_3_ep2_tp_allreduce
	layer_3_ep3_tp_allreduce [label="TP All-Reduce\nEP-Group-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_3_ep3_tp0_sa_out -> layer_3_ep3_tp_allreduce
	layer_3_ep3_tp1_sa_out -> layer_3_ep3_tp_allreduce
	layer_3_ep3_tp2_sa_out -> layer_3_ep3_tp_allreduce
	layer_3_ep3_tp3_sa_out -> layer_3_ep3_tp_allreduce
	layer_3_ep4_tp_allreduce [label="TP All-Reduce\nEP-Group-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_3_ep4_tp0_sa_out -> layer_3_ep4_tp_allreduce
	layer_3_ep4_tp1_sa_out -> layer_3_ep4_tp_allreduce
	layer_3_ep4_tp2_sa_out -> layer_3_ep4_tp_allreduce
	layer_3_ep4_tp3_sa_out -> layer_3_ep4_tp_allreduce
	layer_3_ep5_tp_allreduce [label="TP All-Reduce\nEP-Group-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_3_ep5_tp0_sa_out -> layer_3_ep5_tp_allreduce
	layer_3_ep5_tp1_sa_out -> layer_3_ep5_tp_allreduce
	layer_3_ep5_tp2_sa_out -> layer_3_ep5_tp_allreduce
	layer_3_ep5_tp3_sa_out -> layer_3_ep5_tp_allreduce
	layer_3_ep6_tp_allreduce [label="TP All-Reduce\nEP-Group-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_3_ep6_tp0_sa_out -> layer_3_ep6_tp_allreduce
	layer_3_ep6_tp1_sa_out -> layer_3_ep6_tp_allreduce
	layer_3_ep6_tp2_sa_out -> layer_3_ep6_tp_allreduce
	layer_3_ep6_tp3_sa_out -> layer_3_ep6_tp_allreduce
	layer_3_ep7_tp_allreduce [label="TP All-Reduce\nEP-Group-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_3_ep7_tp0_sa_out -> layer_3_ep7_tp_allreduce
	layer_3_ep7_tp1_sa_out -> layer_3_ep7_tp_allreduce
	layer_3_ep7_tp2_sa_out -> layer_3_ep7_tp_allreduce
	layer_3_ep7_tp3_sa_out -> layer_3_ep7_tp_allreduce
	layer_3_ep8_tp_allreduce [label="TP All-Reduce\nEP-Group-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_3_ep8_tp0_sa_out -> layer_3_ep8_tp_allreduce
	layer_3_ep8_tp1_sa_out -> layer_3_ep8_tp_allreduce
	layer_3_ep8_tp2_sa_out -> layer_3_ep8_tp_allreduce
	layer_3_ep8_tp3_sa_out -> layer_3_ep8_tp_allreduce
	layer_3_ep9_tp_allreduce [label="TP All-Reduce\nEP-Group-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_3_ep9_tp0_sa_out -> layer_3_ep9_tp_allreduce
	layer_3_ep9_tp1_sa_out -> layer_3_ep9_tp_allreduce
	layer_3_ep9_tp2_sa_out -> layer_3_ep9_tp_allreduce
	layer_3_ep9_tp3_sa_out -> layer_3_ep9_tp_allreduce
	layer_3_ep10_tp_allreduce [label="TP All-Reduce\nEP-Group-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_3_ep10_tp0_sa_out -> layer_3_ep10_tp_allreduce
	layer_3_ep10_tp1_sa_out -> layer_3_ep10_tp_allreduce
	layer_3_ep10_tp2_sa_out -> layer_3_ep10_tp_allreduce
	layer_3_ep10_tp3_sa_out -> layer_3_ep10_tp_allreduce
	layer_3_ep11_tp_allreduce [label="TP All-Reduce\nEP-Group-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_3_ep11_tp0_sa_out -> layer_3_ep11_tp_allreduce
	layer_3_ep11_tp1_sa_out -> layer_3_ep11_tp_allreduce
	layer_3_ep11_tp2_sa_out -> layer_3_ep11_tp_allreduce
	layer_3_ep11_tp3_sa_out -> layer_3_ep11_tp_allreduce
	layer_3_ep12_tp_allreduce [label="TP All-Reduce\nEP-Group-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_3_ep12_tp0_sa_out -> layer_3_ep12_tp_allreduce
	layer_3_ep12_tp1_sa_out -> layer_3_ep12_tp_allreduce
	layer_3_ep12_tp2_sa_out -> layer_3_ep12_tp_allreduce
	layer_3_ep12_tp3_sa_out -> layer_3_ep12_tp_allreduce
	layer_3_ep13_tp_allreduce [label="TP All-Reduce\nEP-Group-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_3_ep13_tp0_sa_out -> layer_3_ep13_tp_allreduce
	layer_3_ep13_tp1_sa_out -> layer_3_ep13_tp_allreduce
	layer_3_ep13_tp2_sa_out -> layer_3_ep13_tp_allreduce
	layer_3_ep13_tp3_sa_out -> layer_3_ep13_tp_allreduce
	layer_3_ep14_tp_allreduce [label="TP All-Reduce\nEP-Group-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_3_ep14_tp0_sa_out -> layer_3_ep14_tp_allreduce
	layer_3_ep14_tp1_sa_out -> layer_3_ep14_tp_allreduce
	layer_3_ep14_tp2_sa_out -> layer_3_ep14_tp_allreduce
	layer_3_ep14_tp3_sa_out -> layer_3_ep14_tp_allreduce
	layer_3_ep15_tp_allreduce [label="TP All-Reduce\nEP-Group-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_3_ep15_tp0_sa_out -> layer_3_ep15_tp_allreduce
	layer_3_ep15_tp1_sa_out -> layer_3_ep15_tp_allreduce
	layer_3_ep15_tp2_sa_out -> layer_3_ep15_tp_allreduce
	layer_3_ep15_tp3_sa_out -> layer_3_ep15_tp_allreduce
	layer_3_ep0_gate [label="MoE Gate\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_3_ep0_expert_0 [label="Expert-0\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep0_gate -> layer_3_ep0_expert_0 [label="select tokens" style=dashed]
	layer_3_ep0_expert_1 [label="Expert-1\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep0_gate -> layer_3_ep0_expert_1 [label="select tokens" style=dashed]
	layer_3_ep0_expert_2 [label="Expert-2\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep0_gate -> layer_3_ep0_expert_2 [label="select tokens" style=dashed]
	layer_3_ep0_expert_3 [label="Expert-3\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep0_gate -> layer_3_ep0_expert_3 [label="select tokens" style=dashed]
	layer_3_ep0_expert_aggr [label="Expert Aggregation\nEP-Group-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_3_ep0_expert_0 -> layer_3_ep0_expert_aggr
	layer_3_ep0_expert_1 -> layer_3_ep0_expert_aggr
	layer_3_ep0_expert_2 -> layer_3_ep0_expert_aggr
	layer_3_ep0_expert_3 -> layer_3_ep0_expert_aggr
	layer_3_ep1_gate [label="MoE Gate\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_3_ep1_expert_0 [label="Expert-0\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep1_gate -> layer_3_ep1_expert_0 [label="select tokens" style=dashed]
	layer_3_ep1_expert_1 [label="Expert-1\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep1_gate -> layer_3_ep1_expert_1 [label="select tokens" style=dashed]
	layer_3_ep1_expert_2 [label="Expert-2\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep1_gate -> layer_3_ep1_expert_2 [label="select tokens" style=dashed]
	layer_3_ep1_expert_3 [label="Expert-3\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep1_gate -> layer_3_ep1_expert_3 [label="select tokens" style=dashed]
	layer_3_ep1_expert_aggr [label="Expert Aggregation\nEP-Group-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_3_ep1_expert_0 -> layer_3_ep1_expert_aggr
	layer_3_ep1_expert_1 -> layer_3_ep1_expert_aggr
	layer_3_ep1_expert_2 -> layer_3_ep1_expert_aggr
	layer_3_ep1_expert_3 -> layer_3_ep1_expert_aggr
	layer_3_ep2_gate [label="MoE Gate\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_3_ep2_expert_0 [label="Expert-0\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep2_gate -> layer_3_ep2_expert_0 [label="select tokens" style=dashed]
	layer_3_ep2_expert_1 [label="Expert-1\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep2_gate -> layer_3_ep2_expert_1 [label="select tokens" style=dashed]
	layer_3_ep2_expert_2 [label="Expert-2\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep2_gate -> layer_3_ep2_expert_2 [label="select tokens" style=dashed]
	layer_3_ep2_expert_3 [label="Expert-3\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep2_gate -> layer_3_ep2_expert_3 [label="select tokens" style=dashed]
	layer_3_ep2_expert_aggr [label="Expert Aggregation\nEP-Group-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_3_ep2_expert_0 -> layer_3_ep2_expert_aggr
	layer_3_ep2_expert_1 -> layer_3_ep2_expert_aggr
	layer_3_ep2_expert_2 -> layer_3_ep2_expert_aggr
	layer_3_ep2_expert_3 -> layer_3_ep2_expert_aggr
	layer_3_ep3_gate [label="MoE Gate\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_3_ep3_expert_0 [label="Expert-0\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep3_gate -> layer_3_ep3_expert_0 [label="select tokens" style=dashed]
	layer_3_ep3_expert_1 [label="Expert-1\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep3_gate -> layer_3_ep3_expert_1 [label="select tokens" style=dashed]
	layer_3_ep3_expert_2 [label="Expert-2\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep3_gate -> layer_3_ep3_expert_2 [label="select tokens" style=dashed]
	layer_3_ep3_expert_3 [label="Expert-3\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep3_gate -> layer_3_ep3_expert_3 [label="select tokens" style=dashed]
	layer_3_ep3_expert_aggr [label="Expert Aggregation\nEP-Group-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_3_ep3_expert_0 -> layer_3_ep3_expert_aggr
	layer_3_ep3_expert_1 -> layer_3_ep3_expert_aggr
	layer_3_ep3_expert_2 -> layer_3_ep3_expert_aggr
	layer_3_ep3_expert_3 -> layer_3_ep3_expert_aggr
	layer_3_ep4_gate [label="MoE Gate\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_3_ep4_expert_0 [label="Expert-0\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep4_gate -> layer_3_ep4_expert_0 [label="select tokens" style=dashed]
	layer_3_ep4_expert_1 [label="Expert-1\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep4_gate -> layer_3_ep4_expert_1 [label="select tokens" style=dashed]
	layer_3_ep4_expert_2 [label="Expert-2\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep4_gate -> layer_3_ep4_expert_2 [label="select tokens" style=dashed]
	layer_3_ep4_expert_3 [label="Expert-3\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep4_gate -> layer_3_ep4_expert_3 [label="select tokens" style=dashed]
	layer_3_ep4_expert_aggr [label="Expert Aggregation\nEP-Group-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_3_ep4_expert_0 -> layer_3_ep4_expert_aggr
	layer_3_ep4_expert_1 -> layer_3_ep4_expert_aggr
	layer_3_ep4_expert_2 -> layer_3_ep4_expert_aggr
	layer_3_ep4_expert_3 -> layer_3_ep4_expert_aggr
	layer_3_ep5_gate [label="MoE Gate\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_3_ep5_expert_0 [label="Expert-0\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep5_gate -> layer_3_ep5_expert_0 [label="select tokens" style=dashed]
	layer_3_ep5_expert_1 [label="Expert-1\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep5_gate -> layer_3_ep5_expert_1 [label="select tokens" style=dashed]
	layer_3_ep5_expert_2 [label="Expert-2\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep5_gate -> layer_3_ep5_expert_2 [label="select tokens" style=dashed]
	layer_3_ep5_expert_3 [label="Expert-3\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep5_gate -> layer_3_ep5_expert_3 [label="select tokens" style=dashed]
	layer_3_ep5_expert_aggr [label="Expert Aggregation\nEP-Group-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_3_ep5_expert_0 -> layer_3_ep5_expert_aggr
	layer_3_ep5_expert_1 -> layer_3_ep5_expert_aggr
	layer_3_ep5_expert_2 -> layer_3_ep5_expert_aggr
	layer_3_ep5_expert_3 -> layer_3_ep5_expert_aggr
	layer_3_ep6_gate [label="MoE Gate\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_3_ep6_expert_0 [label="Expert-0\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep6_gate -> layer_3_ep6_expert_0 [label="select tokens" style=dashed]
	layer_3_ep6_expert_1 [label="Expert-1\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep6_gate -> layer_3_ep6_expert_1 [label="select tokens" style=dashed]
	layer_3_ep6_expert_2 [label="Expert-2\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep6_gate -> layer_3_ep6_expert_2 [label="select tokens" style=dashed]
	layer_3_ep6_expert_3 [label="Expert-3\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep6_gate -> layer_3_ep6_expert_3 [label="select tokens" style=dashed]
	layer_3_ep6_expert_aggr [label="Expert Aggregation\nEP-Group-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_3_ep6_expert_0 -> layer_3_ep6_expert_aggr
	layer_3_ep6_expert_1 -> layer_3_ep6_expert_aggr
	layer_3_ep6_expert_2 -> layer_3_ep6_expert_aggr
	layer_3_ep6_expert_3 -> layer_3_ep6_expert_aggr
	layer_3_ep7_gate [label="MoE Gate\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_3_ep7_expert_0 [label="Expert-0\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep7_gate -> layer_3_ep7_expert_0 [label="select tokens" style=dashed]
	layer_3_ep7_expert_1 [label="Expert-1\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep7_gate -> layer_3_ep7_expert_1 [label="select tokens" style=dashed]
	layer_3_ep7_expert_2 [label="Expert-2\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep7_gate -> layer_3_ep7_expert_2 [label="select tokens" style=dashed]
	layer_3_ep7_expert_3 [label="Expert-3\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep7_gate -> layer_3_ep7_expert_3 [label="select tokens" style=dashed]
	layer_3_ep7_expert_aggr [label="Expert Aggregation\nEP-Group-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_3_ep7_expert_0 -> layer_3_ep7_expert_aggr
	layer_3_ep7_expert_1 -> layer_3_ep7_expert_aggr
	layer_3_ep7_expert_2 -> layer_3_ep7_expert_aggr
	layer_3_ep7_expert_3 -> layer_3_ep7_expert_aggr
	layer_3_ep8_gate [label="MoE Gate\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_3_ep8_expert_0 [label="Expert-0\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep8_gate -> layer_3_ep8_expert_0 [label="select tokens" style=dashed]
	layer_3_ep8_expert_1 [label="Expert-1\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep8_gate -> layer_3_ep8_expert_1 [label="select tokens" style=dashed]
	layer_3_ep8_expert_2 [label="Expert-2\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep8_gate -> layer_3_ep8_expert_2 [label="select tokens" style=dashed]
	layer_3_ep8_expert_3 [label="Expert-3\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep8_gate -> layer_3_ep8_expert_3 [label="select tokens" style=dashed]
	layer_3_ep8_expert_aggr [label="Expert Aggregation\nEP-Group-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_3_ep8_expert_0 -> layer_3_ep8_expert_aggr
	layer_3_ep8_expert_1 -> layer_3_ep8_expert_aggr
	layer_3_ep8_expert_2 -> layer_3_ep8_expert_aggr
	layer_3_ep8_expert_3 -> layer_3_ep8_expert_aggr
	layer_3_ep9_gate [label="MoE Gate\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_3_ep9_expert_0 [label="Expert-0\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep9_gate -> layer_3_ep9_expert_0 [label="select tokens" style=dashed]
	layer_3_ep9_expert_1 [label="Expert-1\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep9_gate -> layer_3_ep9_expert_1 [label="select tokens" style=dashed]
	layer_3_ep9_expert_2 [label="Expert-2\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep9_gate -> layer_3_ep9_expert_2 [label="select tokens" style=dashed]
	layer_3_ep9_expert_3 [label="Expert-3\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep9_gate -> layer_3_ep9_expert_3 [label="select tokens" style=dashed]
	layer_3_ep9_expert_aggr [label="Expert Aggregation\nEP-Group-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_3_ep9_expert_0 -> layer_3_ep9_expert_aggr
	layer_3_ep9_expert_1 -> layer_3_ep9_expert_aggr
	layer_3_ep9_expert_2 -> layer_3_ep9_expert_aggr
	layer_3_ep9_expert_3 -> layer_3_ep9_expert_aggr
	layer_3_ep10_gate [label="MoE Gate\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_3_ep10_expert_0 [label="Expert-0\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep10_gate -> layer_3_ep10_expert_0 [label="select tokens" style=dashed]
	layer_3_ep10_expert_1 [label="Expert-1\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep10_gate -> layer_3_ep10_expert_1 [label="select tokens" style=dashed]
	layer_3_ep10_expert_2 [label="Expert-2\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep10_gate -> layer_3_ep10_expert_2 [label="select tokens" style=dashed]
	layer_3_ep10_expert_3 [label="Expert-3\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep10_gate -> layer_3_ep10_expert_3 [label="select tokens" style=dashed]
	layer_3_ep10_expert_aggr [label="Expert Aggregation\nEP-Group-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_3_ep10_expert_0 -> layer_3_ep10_expert_aggr
	layer_3_ep10_expert_1 -> layer_3_ep10_expert_aggr
	layer_3_ep10_expert_2 -> layer_3_ep10_expert_aggr
	layer_3_ep10_expert_3 -> layer_3_ep10_expert_aggr
	layer_3_ep11_gate [label="MoE Gate\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_3_ep11_expert_0 [label="Expert-0\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep11_gate -> layer_3_ep11_expert_0 [label="select tokens" style=dashed]
	layer_3_ep11_expert_1 [label="Expert-1\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep11_gate -> layer_3_ep11_expert_1 [label="select tokens" style=dashed]
	layer_3_ep11_expert_2 [label="Expert-2\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep11_gate -> layer_3_ep11_expert_2 [label="select tokens" style=dashed]
	layer_3_ep11_expert_3 [label="Expert-3\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep11_gate -> layer_3_ep11_expert_3 [label="select tokens" style=dashed]
	layer_3_ep11_expert_aggr [label="Expert Aggregation\nEP-Group-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_3_ep11_expert_0 -> layer_3_ep11_expert_aggr
	layer_3_ep11_expert_1 -> layer_3_ep11_expert_aggr
	layer_3_ep11_expert_2 -> layer_3_ep11_expert_aggr
	layer_3_ep11_expert_3 -> layer_3_ep11_expert_aggr
	layer_3_ep12_gate [label="MoE Gate\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_3_ep12_expert_0 [label="Expert-0\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep12_gate -> layer_3_ep12_expert_0 [label="select tokens" style=dashed]
	layer_3_ep12_expert_1 [label="Expert-1\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep12_gate -> layer_3_ep12_expert_1 [label="select tokens" style=dashed]
	layer_3_ep12_expert_2 [label="Expert-2\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep12_gate -> layer_3_ep12_expert_2 [label="select tokens" style=dashed]
	layer_3_ep12_expert_3 [label="Expert-3\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep12_gate -> layer_3_ep12_expert_3 [label="select tokens" style=dashed]
	layer_3_ep12_expert_aggr [label="Expert Aggregation\nEP-Group-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_3_ep12_expert_0 -> layer_3_ep12_expert_aggr
	layer_3_ep12_expert_1 -> layer_3_ep12_expert_aggr
	layer_3_ep12_expert_2 -> layer_3_ep12_expert_aggr
	layer_3_ep12_expert_3 -> layer_3_ep12_expert_aggr
	layer_3_ep13_gate [label="MoE Gate\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_3_ep13_expert_0 [label="Expert-0\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep13_gate -> layer_3_ep13_expert_0 [label="select tokens" style=dashed]
	layer_3_ep13_expert_1 [label="Expert-1\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep13_gate -> layer_3_ep13_expert_1 [label="select tokens" style=dashed]
	layer_3_ep13_expert_2 [label="Expert-2\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep13_gate -> layer_3_ep13_expert_2 [label="select tokens" style=dashed]
	layer_3_ep13_expert_3 [label="Expert-3\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep13_gate -> layer_3_ep13_expert_3 [label="select tokens" style=dashed]
	layer_3_ep13_expert_aggr [label="Expert Aggregation\nEP-Group-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_3_ep13_expert_0 -> layer_3_ep13_expert_aggr
	layer_3_ep13_expert_1 -> layer_3_ep13_expert_aggr
	layer_3_ep13_expert_2 -> layer_3_ep13_expert_aggr
	layer_3_ep13_expert_3 -> layer_3_ep13_expert_aggr
	layer_3_ep14_gate [label="MoE Gate\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_3_ep14_expert_0 [label="Expert-0\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep14_gate -> layer_3_ep14_expert_0 [label="select tokens" style=dashed]
	layer_3_ep14_expert_1 [label="Expert-1\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep14_gate -> layer_3_ep14_expert_1 [label="select tokens" style=dashed]
	layer_3_ep14_expert_2 [label="Expert-2\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep14_gate -> layer_3_ep14_expert_2 [label="select tokens" style=dashed]
	layer_3_ep14_expert_3 [label="Expert-3\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep14_gate -> layer_3_ep14_expert_3 [label="select tokens" style=dashed]
	layer_3_ep14_expert_aggr [label="Expert Aggregation\nEP-Group-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_3_ep14_expert_0 -> layer_3_ep14_expert_aggr
	layer_3_ep14_expert_1 -> layer_3_ep14_expert_aggr
	layer_3_ep14_expert_2 -> layer_3_ep14_expert_aggr
	layer_3_ep14_expert_3 -> layer_3_ep14_expert_aggr
	layer_3_ep15_gate [label="MoE Gate\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_3_ep15_expert_0 [label="Expert-0\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep15_gate -> layer_3_ep15_expert_0 [label="select tokens" style=dashed]
	layer_3_ep15_expert_1 [label="Expert-1\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep15_gate -> layer_3_ep15_expert_1 [label="select tokens" style=dashed]
	layer_3_ep15_expert_2 [label="Expert-2\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep15_gate -> layer_3_ep15_expert_2 [label="select tokens" style=dashed]
	layer_3_ep15_expert_3 [label="Expert-3\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_3_ep15_gate -> layer_3_ep15_expert_3 [label="select tokens" style=dashed]
	layer_3_ep15_expert_aggr [label="Expert Aggregation\nEP-Group-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_3_ep15_expert_0 -> layer_3_ep15_expert_aggr
	layer_3_ep15_expert_1 -> layer_3_ep15_expert_aggr
	layer_3_ep15_expert_2 -> layer_3_ep15_expert_aggr
	layer_3_ep15_expert_3 -> layer_3_ep15_expert_aggr
	layer_3_to_4_ep0_pp [label="Pipeline Stage Transfer\nEP-Group-0\nLayer-3 to Layer-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_3_ep0_expert_aggr -> layer_3_to_4_ep0_pp
	layer_3_to_4_ep1_pp [label="Pipeline Stage Transfer\nEP-Group-1\nLayer-3 to Layer-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_3_ep1_expert_aggr -> layer_3_to_4_ep1_pp
	layer_3_to_4_ep2_pp [label="Pipeline Stage Transfer\nEP-Group-2\nLayer-3 to Layer-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_3_ep2_expert_aggr -> layer_3_to_4_ep2_pp
	layer_3_to_4_ep3_pp [label="Pipeline Stage Transfer\nEP-Group-3\nLayer-3 to Layer-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_3_ep3_expert_aggr -> layer_3_to_4_ep3_pp
	layer_3_to_4_ep4_pp [label="Pipeline Stage Transfer\nEP-Group-4\nLayer-3 to Layer-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_3_ep4_expert_aggr -> layer_3_to_4_ep4_pp
	layer_3_to_4_ep5_pp [label="Pipeline Stage Transfer\nEP-Group-5\nLayer-3 to Layer-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_3_ep5_expert_aggr -> layer_3_to_4_ep5_pp
	layer_3_to_4_ep6_pp [label="Pipeline Stage Transfer\nEP-Group-6\nLayer-3 to Layer-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_3_ep6_expert_aggr -> layer_3_to_4_ep6_pp
	layer_3_to_4_ep7_pp [label="Pipeline Stage Transfer\nEP-Group-7\nLayer-3 to Layer-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_3_ep7_expert_aggr -> layer_3_to_4_ep7_pp
	layer_3_to_4_ep8_pp [label="Pipeline Stage Transfer\nEP-Group-8\nLayer-3 to Layer-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_3_ep8_expert_aggr -> layer_3_to_4_ep8_pp
	layer_3_to_4_ep9_pp [label="Pipeline Stage Transfer\nEP-Group-9\nLayer-3 to Layer-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_3_ep9_expert_aggr -> layer_3_to_4_ep9_pp
	layer_3_to_4_ep10_pp [label="Pipeline Stage Transfer\nEP-Group-10\nLayer-3 to Layer-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_3_ep10_expert_aggr -> layer_3_to_4_ep10_pp
	layer_3_to_4_ep11_pp [label="Pipeline Stage Transfer\nEP-Group-11\nLayer-3 to Layer-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_3_ep11_expert_aggr -> layer_3_to_4_ep11_pp
	layer_3_to_4_ep12_pp [label="Pipeline Stage Transfer\nEP-Group-12\nLayer-3 to Layer-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_3_ep12_expert_aggr -> layer_3_to_4_ep12_pp
	layer_3_to_4_ep13_pp [label="Pipeline Stage Transfer\nEP-Group-13\nLayer-3 to Layer-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_3_ep13_expert_aggr -> layer_3_to_4_ep13_pp
	layer_3_to_4_ep14_pp [label="Pipeline Stage Transfer\nEP-Group-14\nLayer-3 to Layer-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_3_ep14_expert_aggr -> layer_3_to_4_ep14_pp
	layer_3_to_4_ep15_pp [label="Pipeline Stage Transfer\nEP-Group-15\nLayer-3 to Layer-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_3_ep15_expert_aggr -> layer_3_to_4_ep15_pp
	layer_4_ep0_tp0_sa_qkv [label="Self-Attn QKV\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep0_tp0_sa_attn [label="Self-Attn Compute\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep0_tp0_sa_out [label="Self-Attn Output\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep0_tp0_sa_qkv -> layer_4_ep0_tp0_sa_attn
	layer_4_ep0_tp0_sa_attn -> layer_4_ep0_tp0_sa_out
	layer_4_ep0_tp1_sa_qkv [label="Self-Attn QKV\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep0_tp1_sa_attn [label="Self-Attn Compute\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep0_tp1_sa_out [label="Self-Attn Output\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep0_tp1_sa_qkv -> layer_4_ep0_tp1_sa_attn
	layer_4_ep0_tp1_sa_attn -> layer_4_ep0_tp1_sa_out
	layer_4_ep0_tp2_sa_qkv [label="Self-Attn QKV\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep0_tp2_sa_attn [label="Self-Attn Compute\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep0_tp2_sa_out [label="Self-Attn Output\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep0_tp2_sa_qkv -> layer_4_ep0_tp2_sa_attn
	layer_4_ep0_tp2_sa_attn -> layer_4_ep0_tp2_sa_out
	layer_4_ep0_tp3_sa_qkv [label="Self-Attn QKV\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep0_tp3_sa_attn [label="Self-Attn Compute\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep0_tp3_sa_out [label="Self-Attn Output\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep0_tp3_sa_qkv -> layer_4_ep0_tp3_sa_attn
	layer_4_ep0_tp3_sa_attn -> layer_4_ep0_tp3_sa_out
	layer_4_ep1_tp0_sa_qkv [label="Self-Attn QKV\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep1_tp0_sa_attn [label="Self-Attn Compute\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep1_tp0_sa_out [label="Self-Attn Output\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep1_tp0_sa_qkv -> layer_4_ep1_tp0_sa_attn
	layer_4_ep1_tp0_sa_attn -> layer_4_ep1_tp0_sa_out
	layer_4_ep1_tp1_sa_qkv [label="Self-Attn QKV\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep1_tp1_sa_attn [label="Self-Attn Compute\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep1_tp1_sa_out [label="Self-Attn Output\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep1_tp1_sa_qkv -> layer_4_ep1_tp1_sa_attn
	layer_4_ep1_tp1_sa_attn -> layer_4_ep1_tp1_sa_out
	layer_4_ep1_tp2_sa_qkv [label="Self-Attn QKV\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep1_tp2_sa_attn [label="Self-Attn Compute\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep1_tp2_sa_out [label="Self-Attn Output\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep1_tp2_sa_qkv -> layer_4_ep1_tp2_sa_attn
	layer_4_ep1_tp2_sa_attn -> layer_4_ep1_tp2_sa_out
	layer_4_ep1_tp3_sa_qkv [label="Self-Attn QKV\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep1_tp3_sa_attn [label="Self-Attn Compute\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep1_tp3_sa_out [label="Self-Attn Output\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep1_tp3_sa_qkv -> layer_4_ep1_tp3_sa_attn
	layer_4_ep1_tp3_sa_attn -> layer_4_ep1_tp3_sa_out
	layer_4_ep2_tp0_sa_qkv [label="Self-Attn QKV\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep2_tp0_sa_attn [label="Self-Attn Compute\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep2_tp0_sa_out [label="Self-Attn Output\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep2_tp0_sa_qkv -> layer_4_ep2_tp0_sa_attn
	layer_4_ep2_tp0_sa_attn -> layer_4_ep2_tp0_sa_out
	layer_4_ep2_tp1_sa_qkv [label="Self-Attn QKV\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep2_tp1_sa_attn [label="Self-Attn Compute\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep2_tp1_sa_out [label="Self-Attn Output\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep2_tp1_sa_qkv -> layer_4_ep2_tp1_sa_attn
	layer_4_ep2_tp1_sa_attn -> layer_4_ep2_tp1_sa_out
	layer_4_ep2_tp2_sa_qkv [label="Self-Attn QKV\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep2_tp2_sa_attn [label="Self-Attn Compute\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep2_tp2_sa_out [label="Self-Attn Output\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep2_tp2_sa_qkv -> layer_4_ep2_tp2_sa_attn
	layer_4_ep2_tp2_sa_attn -> layer_4_ep2_tp2_sa_out
	layer_4_ep2_tp3_sa_qkv [label="Self-Attn QKV\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep2_tp3_sa_attn [label="Self-Attn Compute\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep2_tp3_sa_out [label="Self-Attn Output\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep2_tp3_sa_qkv -> layer_4_ep2_tp3_sa_attn
	layer_4_ep2_tp3_sa_attn -> layer_4_ep2_tp3_sa_out
	layer_4_ep3_tp0_sa_qkv [label="Self-Attn QKV\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep3_tp0_sa_attn [label="Self-Attn Compute\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep3_tp0_sa_out [label="Self-Attn Output\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep3_tp0_sa_qkv -> layer_4_ep3_tp0_sa_attn
	layer_4_ep3_tp0_sa_attn -> layer_4_ep3_tp0_sa_out
	layer_4_ep3_tp1_sa_qkv [label="Self-Attn QKV\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep3_tp1_sa_attn [label="Self-Attn Compute\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep3_tp1_sa_out [label="Self-Attn Output\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep3_tp1_sa_qkv -> layer_4_ep3_tp1_sa_attn
	layer_4_ep3_tp1_sa_attn -> layer_4_ep3_tp1_sa_out
	layer_4_ep3_tp2_sa_qkv [label="Self-Attn QKV\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep3_tp2_sa_attn [label="Self-Attn Compute\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep3_tp2_sa_out [label="Self-Attn Output\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep3_tp2_sa_qkv -> layer_4_ep3_tp2_sa_attn
	layer_4_ep3_tp2_sa_attn -> layer_4_ep3_tp2_sa_out
	layer_4_ep3_tp3_sa_qkv [label="Self-Attn QKV\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep3_tp3_sa_attn [label="Self-Attn Compute\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep3_tp3_sa_out [label="Self-Attn Output\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep3_tp3_sa_qkv -> layer_4_ep3_tp3_sa_attn
	layer_4_ep3_tp3_sa_attn -> layer_4_ep3_tp3_sa_out
	layer_4_ep4_tp0_sa_qkv [label="Self-Attn QKV\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep4_tp0_sa_attn [label="Self-Attn Compute\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep4_tp0_sa_out [label="Self-Attn Output\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep4_tp0_sa_qkv -> layer_4_ep4_tp0_sa_attn
	layer_4_ep4_tp0_sa_attn -> layer_4_ep4_tp0_sa_out
	layer_4_ep4_tp1_sa_qkv [label="Self-Attn QKV\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep4_tp1_sa_attn [label="Self-Attn Compute\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep4_tp1_sa_out [label="Self-Attn Output\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep4_tp1_sa_qkv -> layer_4_ep4_tp1_sa_attn
	layer_4_ep4_tp1_sa_attn -> layer_4_ep4_tp1_sa_out
	layer_4_ep4_tp2_sa_qkv [label="Self-Attn QKV\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep4_tp2_sa_attn [label="Self-Attn Compute\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep4_tp2_sa_out [label="Self-Attn Output\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep4_tp2_sa_qkv -> layer_4_ep4_tp2_sa_attn
	layer_4_ep4_tp2_sa_attn -> layer_4_ep4_tp2_sa_out
	layer_4_ep4_tp3_sa_qkv [label="Self-Attn QKV\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep4_tp3_sa_attn [label="Self-Attn Compute\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep4_tp3_sa_out [label="Self-Attn Output\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep4_tp3_sa_qkv -> layer_4_ep4_tp3_sa_attn
	layer_4_ep4_tp3_sa_attn -> layer_4_ep4_tp3_sa_out
	layer_4_ep5_tp0_sa_qkv [label="Self-Attn QKV\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep5_tp0_sa_attn [label="Self-Attn Compute\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep5_tp0_sa_out [label="Self-Attn Output\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep5_tp0_sa_qkv -> layer_4_ep5_tp0_sa_attn
	layer_4_ep5_tp0_sa_attn -> layer_4_ep5_tp0_sa_out
	layer_4_ep5_tp1_sa_qkv [label="Self-Attn QKV\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep5_tp1_sa_attn [label="Self-Attn Compute\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep5_tp1_sa_out [label="Self-Attn Output\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep5_tp1_sa_qkv -> layer_4_ep5_tp1_sa_attn
	layer_4_ep5_tp1_sa_attn -> layer_4_ep5_tp1_sa_out
	layer_4_ep5_tp2_sa_qkv [label="Self-Attn QKV\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep5_tp2_sa_attn [label="Self-Attn Compute\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep5_tp2_sa_out [label="Self-Attn Output\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep5_tp2_sa_qkv -> layer_4_ep5_tp2_sa_attn
	layer_4_ep5_tp2_sa_attn -> layer_4_ep5_tp2_sa_out
	layer_4_ep5_tp3_sa_qkv [label="Self-Attn QKV\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep5_tp3_sa_attn [label="Self-Attn Compute\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep5_tp3_sa_out [label="Self-Attn Output\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep5_tp3_sa_qkv -> layer_4_ep5_tp3_sa_attn
	layer_4_ep5_tp3_sa_attn -> layer_4_ep5_tp3_sa_out
	layer_4_ep6_tp0_sa_qkv [label="Self-Attn QKV\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep6_tp0_sa_attn [label="Self-Attn Compute\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep6_tp0_sa_out [label="Self-Attn Output\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep6_tp0_sa_qkv -> layer_4_ep6_tp0_sa_attn
	layer_4_ep6_tp0_sa_attn -> layer_4_ep6_tp0_sa_out
	layer_4_ep6_tp1_sa_qkv [label="Self-Attn QKV\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep6_tp1_sa_attn [label="Self-Attn Compute\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep6_tp1_sa_out [label="Self-Attn Output\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep6_tp1_sa_qkv -> layer_4_ep6_tp1_sa_attn
	layer_4_ep6_tp1_sa_attn -> layer_4_ep6_tp1_sa_out
	layer_4_ep6_tp2_sa_qkv [label="Self-Attn QKV\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep6_tp2_sa_attn [label="Self-Attn Compute\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep6_tp2_sa_out [label="Self-Attn Output\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep6_tp2_sa_qkv -> layer_4_ep6_tp2_sa_attn
	layer_4_ep6_tp2_sa_attn -> layer_4_ep6_tp2_sa_out
	layer_4_ep6_tp3_sa_qkv [label="Self-Attn QKV\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep6_tp3_sa_attn [label="Self-Attn Compute\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep6_tp3_sa_out [label="Self-Attn Output\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep6_tp3_sa_qkv -> layer_4_ep6_tp3_sa_attn
	layer_4_ep6_tp3_sa_attn -> layer_4_ep6_tp3_sa_out
	layer_4_ep7_tp0_sa_qkv [label="Self-Attn QKV\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep7_tp0_sa_attn [label="Self-Attn Compute\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep7_tp0_sa_out [label="Self-Attn Output\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep7_tp0_sa_qkv -> layer_4_ep7_tp0_sa_attn
	layer_4_ep7_tp0_sa_attn -> layer_4_ep7_tp0_sa_out
	layer_4_ep7_tp1_sa_qkv [label="Self-Attn QKV\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep7_tp1_sa_attn [label="Self-Attn Compute\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep7_tp1_sa_out [label="Self-Attn Output\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep7_tp1_sa_qkv -> layer_4_ep7_tp1_sa_attn
	layer_4_ep7_tp1_sa_attn -> layer_4_ep7_tp1_sa_out
	layer_4_ep7_tp2_sa_qkv [label="Self-Attn QKV\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep7_tp2_sa_attn [label="Self-Attn Compute\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep7_tp2_sa_out [label="Self-Attn Output\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep7_tp2_sa_qkv -> layer_4_ep7_tp2_sa_attn
	layer_4_ep7_tp2_sa_attn -> layer_4_ep7_tp2_sa_out
	layer_4_ep7_tp3_sa_qkv [label="Self-Attn QKV\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep7_tp3_sa_attn [label="Self-Attn Compute\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep7_tp3_sa_out [label="Self-Attn Output\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep7_tp3_sa_qkv -> layer_4_ep7_tp3_sa_attn
	layer_4_ep7_tp3_sa_attn -> layer_4_ep7_tp3_sa_out
	layer_4_ep8_tp0_sa_qkv [label="Self-Attn QKV\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep8_tp0_sa_attn [label="Self-Attn Compute\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep8_tp0_sa_out [label="Self-Attn Output\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep8_tp0_sa_qkv -> layer_4_ep8_tp0_sa_attn
	layer_4_ep8_tp0_sa_attn -> layer_4_ep8_tp0_sa_out
	layer_4_ep8_tp1_sa_qkv [label="Self-Attn QKV\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep8_tp1_sa_attn [label="Self-Attn Compute\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep8_tp1_sa_out [label="Self-Attn Output\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep8_tp1_sa_qkv -> layer_4_ep8_tp1_sa_attn
	layer_4_ep8_tp1_sa_attn -> layer_4_ep8_tp1_sa_out
	layer_4_ep8_tp2_sa_qkv [label="Self-Attn QKV\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep8_tp2_sa_attn [label="Self-Attn Compute\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep8_tp2_sa_out [label="Self-Attn Output\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep8_tp2_sa_qkv -> layer_4_ep8_tp2_sa_attn
	layer_4_ep8_tp2_sa_attn -> layer_4_ep8_tp2_sa_out
	layer_4_ep8_tp3_sa_qkv [label="Self-Attn QKV\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep8_tp3_sa_attn [label="Self-Attn Compute\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep8_tp3_sa_out [label="Self-Attn Output\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep8_tp3_sa_qkv -> layer_4_ep8_tp3_sa_attn
	layer_4_ep8_tp3_sa_attn -> layer_4_ep8_tp3_sa_out
	layer_4_ep9_tp0_sa_qkv [label="Self-Attn QKV\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep9_tp0_sa_attn [label="Self-Attn Compute\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep9_tp0_sa_out [label="Self-Attn Output\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep9_tp0_sa_qkv -> layer_4_ep9_tp0_sa_attn
	layer_4_ep9_tp0_sa_attn -> layer_4_ep9_tp0_sa_out
	layer_4_ep9_tp1_sa_qkv [label="Self-Attn QKV\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep9_tp1_sa_attn [label="Self-Attn Compute\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep9_tp1_sa_out [label="Self-Attn Output\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep9_tp1_sa_qkv -> layer_4_ep9_tp1_sa_attn
	layer_4_ep9_tp1_sa_attn -> layer_4_ep9_tp1_sa_out
	layer_4_ep9_tp2_sa_qkv [label="Self-Attn QKV\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep9_tp2_sa_attn [label="Self-Attn Compute\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep9_tp2_sa_out [label="Self-Attn Output\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep9_tp2_sa_qkv -> layer_4_ep9_tp2_sa_attn
	layer_4_ep9_tp2_sa_attn -> layer_4_ep9_tp2_sa_out
	layer_4_ep9_tp3_sa_qkv [label="Self-Attn QKV\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep9_tp3_sa_attn [label="Self-Attn Compute\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep9_tp3_sa_out [label="Self-Attn Output\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep9_tp3_sa_qkv -> layer_4_ep9_tp3_sa_attn
	layer_4_ep9_tp3_sa_attn -> layer_4_ep9_tp3_sa_out
	layer_4_ep10_tp0_sa_qkv [label="Self-Attn QKV\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep10_tp0_sa_attn [label="Self-Attn Compute\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep10_tp0_sa_out [label="Self-Attn Output\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep10_tp0_sa_qkv -> layer_4_ep10_tp0_sa_attn
	layer_4_ep10_tp0_sa_attn -> layer_4_ep10_tp0_sa_out
	layer_4_ep10_tp1_sa_qkv [label="Self-Attn QKV\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep10_tp1_sa_attn [label="Self-Attn Compute\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep10_tp1_sa_out [label="Self-Attn Output\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep10_tp1_sa_qkv -> layer_4_ep10_tp1_sa_attn
	layer_4_ep10_tp1_sa_attn -> layer_4_ep10_tp1_sa_out
	layer_4_ep10_tp2_sa_qkv [label="Self-Attn QKV\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep10_tp2_sa_attn [label="Self-Attn Compute\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep10_tp2_sa_out [label="Self-Attn Output\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep10_tp2_sa_qkv -> layer_4_ep10_tp2_sa_attn
	layer_4_ep10_tp2_sa_attn -> layer_4_ep10_tp2_sa_out
	layer_4_ep10_tp3_sa_qkv [label="Self-Attn QKV\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep10_tp3_sa_attn [label="Self-Attn Compute\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep10_tp3_sa_out [label="Self-Attn Output\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep10_tp3_sa_qkv -> layer_4_ep10_tp3_sa_attn
	layer_4_ep10_tp3_sa_attn -> layer_4_ep10_tp3_sa_out
	layer_4_ep11_tp0_sa_qkv [label="Self-Attn QKV\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep11_tp0_sa_attn [label="Self-Attn Compute\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep11_tp0_sa_out [label="Self-Attn Output\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep11_tp0_sa_qkv -> layer_4_ep11_tp0_sa_attn
	layer_4_ep11_tp0_sa_attn -> layer_4_ep11_tp0_sa_out
	layer_4_ep11_tp1_sa_qkv [label="Self-Attn QKV\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep11_tp1_sa_attn [label="Self-Attn Compute\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep11_tp1_sa_out [label="Self-Attn Output\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep11_tp1_sa_qkv -> layer_4_ep11_tp1_sa_attn
	layer_4_ep11_tp1_sa_attn -> layer_4_ep11_tp1_sa_out
	layer_4_ep11_tp2_sa_qkv [label="Self-Attn QKV\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep11_tp2_sa_attn [label="Self-Attn Compute\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep11_tp2_sa_out [label="Self-Attn Output\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep11_tp2_sa_qkv -> layer_4_ep11_tp2_sa_attn
	layer_4_ep11_tp2_sa_attn -> layer_4_ep11_tp2_sa_out
	layer_4_ep11_tp3_sa_qkv [label="Self-Attn QKV\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep11_tp3_sa_attn [label="Self-Attn Compute\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep11_tp3_sa_out [label="Self-Attn Output\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep11_tp3_sa_qkv -> layer_4_ep11_tp3_sa_attn
	layer_4_ep11_tp3_sa_attn -> layer_4_ep11_tp3_sa_out
	layer_4_ep12_tp0_sa_qkv [label="Self-Attn QKV\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep12_tp0_sa_attn [label="Self-Attn Compute\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep12_tp0_sa_out [label="Self-Attn Output\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep12_tp0_sa_qkv -> layer_4_ep12_tp0_sa_attn
	layer_4_ep12_tp0_sa_attn -> layer_4_ep12_tp0_sa_out
	layer_4_ep12_tp1_sa_qkv [label="Self-Attn QKV\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep12_tp1_sa_attn [label="Self-Attn Compute\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep12_tp1_sa_out [label="Self-Attn Output\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep12_tp1_sa_qkv -> layer_4_ep12_tp1_sa_attn
	layer_4_ep12_tp1_sa_attn -> layer_4_ep12_tp1_sa_out
	layer_4_ep12_tp2_sa_qkv [label="Self-Attn QKV\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep12_tp2_sa_attn [label="Self-Attn Compute\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep12_tp2_sa_out [label="Self-Attn Output\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep12_tp2_sa_qkv -> layer_4_ep12_tp2_sa_attn
	layer_4_ep12_tp2_sa_attn -> layer_4_ep12_tp2_sa_out
	layer_4_ep12_tp3_sa_qkv [label="Self-Attn QKV\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep12_tp3_sa_attn [label="Self-Attn Compute\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep12_tp3_sa_out [label="Self-Attn Output\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep12_tp3_sa_qkv -> layer_4_ep12_tp3_sa_attn
	layer_4_ep12_tp3_sa_attn -> layer_4_ep12_tp3_sa_out
	layer_4_ep13_tp0_sa_qkv [label="Self-Attn QKV\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep13_tp0_sa_attn [label="Self-Attn Compute\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep13_tp0_sa_out [label="Self-Attn Output\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep13_tp0_sa_qkv -> layer_4_ep13_tp0_sa_attn
	layer_4_ep13_tp0_sa_attn -> layer_4_ep13_tp0_sa_out
	layer_4_ep13_tp1_sa_qkv [label="Self-Attn QKV\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep13_tp1_sa_attn [label="Self-Attn Compute\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep13_tp1_sa_out [label="Self-Attn Output\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep13_tp1_sa_qkv -> layer_4_ep13_tp1_sa_attn
	layer_4_ep13_tp1_sa_attn -> layer_4_ep13_tp1_sa_out
	layer_4_ep13_tp2_sa_qkv [label="Self-Attn QKV\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep13_tp2_sa_attn [label="Self-Attn Compute\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep13_tp2_sa_out [label="Self-Attn Output\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep13_tp2_sa_qkv -> layer_4_ep13_tp2_sa_attn
	layer_4_ep13_tp2_sa_attn -> layer_4_ep13_tp2_sa_out
	layer_4_ep13_tp3_sa_qkv [label="Self-Attn QKV\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep13_tp3_sa_attn [label="Self-Attn Compute\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep13_tp3_sa_out [label="Self-Attn Output\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep13_tp3_sa_qkv -> layer_4_ep13_tp3_sa_attn
	layer_4_ep13_tp3_sa_attn -> layer_4_ep13_tp3_sa_out
	layer_4_ep14_tp0_sa_qkv [label="Self-Attn QKV\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep14_tp0_sa_attn [label="Self-Attn Compute\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep14_tp0_sa_out [label="Self-Attn Output\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep14_tp0_sa_qkv -> layer_4_ep14_tp0_sa_attn
	layer_4_ep14_tp0_sa_attn -> layer_4_ep14_tp0_sa_out
	layer_4_ep14_tp1_sa_qkv [label="Self-Attn QKV\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep14_tp1_sa_attn [label="Self-Attn Compute\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep14_tp1_sa_out [label="Self-Attn Output\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep14_tp1_sa_qkv -> layer_4_ep14_tp1_sa_attn
	layer_4_ep14_tp1_sa_attn -> layer_4_ep14_tp1_sa_out
	layer_4_ep14_tp2_sa_qkv [label="Self-Attn QKV\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep14_tp2_sa_attn [label="Self-Attn Compute\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep14_tp2_sa_out [label="Self-Attn Output\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep14_tp2_sa_qkv -> layer_4_ep14_tp2_sa_attn
	layer_4_ep14_tp2_sa_attn -> layer_4_ep14_tp2_sa_out
	layer_4_ep14_tp3_sa_qkv [label="Self-Attn QKV\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep14_tp3_sa_attn [label="Self-Attn Compute\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep14_tp3_sa_out [label="Self-Attn Output\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep14_tp3_sa_qkv -> layer_4_ep14_tp3_sa_attn
	layer_4_ep14_tp3_sa_attn -> layer_4_ep14_tp3_sa_out
	layer_4_ep15_tp0_sa_qkv [label="Self-Attn QKV\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep15_tp0_sa_attn [label="Self-Attn Compute\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep15_tp0_sa_out [label="Self-Attn Output\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep15_tp0_sa_qkv -> layer_4_ep15_tp0_sa_attn
	layer_4_ep15_tp0_sa_attn -> layer_4_ep15_tp0_sa_out
	layer_4_ep15_tp1_sa_qkv [label="Self-Attn QKV\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep15_tp1_sa_attn [label="Self-Attn Compute\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep15_tp1_sa_out [label="Self-Attn Output\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep15_tp1_sa_qkv -> layer_4_ep15_tp1_sa_attn
	layer_4_ep15_tp1_sa_attn -> layer_4_ep15_tp1_sa_out
	layer_4_ep15_tp2_sa_qkv [label="Self-Attn QKV\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep15_tp2_sa_attn [label="Self-Attn Compute\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep15_tp2_sa_out [label="Self-Attn Output\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep15_tp2_sa_qkv -> layer_4_ep15_tp2_sa_attn
	layer_4_ep15_tp2_sa_attn -> layer_4_ep15_tp2_sa_out
	layer_4_ep15_tp3_sa_qkv [label="Self-Attn QKV\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep15_tp3_sa_attn [label="Self-Attn Compute\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep15_tp3_sa_out [label="Self-Attn Output\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep15_tp3_sa_qkv -> layer_4_ep15_tp3_sa_attn
	layer_4_ep15_tp3_sa_attn -> layer_4_ep15_tp3_sa_out
	layer_4_ep0_tp_allreduce [label="TP All-Reduce\nEP-Group-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_4_ep0_tp0_sa_out -> layer_4_ep0_tp_allreduce
	layer_4_ep0_tp1_sa_out -> layer_4_ep0_tp_allreduce
	layer_4_ep0_tp2_sa_out -> layer_4_ep0_tp_allreduce
	layer_4_ep0_tp3_sa_out -> layer_4_ep0_tp_allreduce
	layer_4_ep1_tp_allreduce [label="TP All-Reduce\nEP-Group-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_4_ep1_tp0_sa_out -> layer_4_ep1_tp_allreduce
	layer_4_ep1_tp1_sa_out -> layer_4_ep1_tp_allreduce
	layer_4_ep1_tp2_sa_out -> layer_4_ep1_tp_allreduce
	layer_4_ep1_tp3_sa_out -> layer_4_ep1_tp_allreduce
	layer_4_ep2_tp_allreduce [label="TP All-Reduce\nEP-Group-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_4_ep2_tp0_sa_out -> layer_4_ep2_tp_allreduce
	layer_4_ep2_tp1_sa_out -> layer_4_ep2_tp_allreduce
	layer_4_ep2_tp2_sa_out -> layer_4_ep2_tp_allreduce
	layer_4_ep2_tp3_sa_out -> layer_4_ep2_tp_allreduce
	layer_4_ep3_tp_allreduce [label="TP All-Reduce\nEP-Group-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_4_ep3_tp0_sa_out -> layer_4_ep3_tp_allreduce
	layer_4_ep3_tp1_sa_out -> layer_4_ep3_tp_allreduce
	layer_4_ep3_tp2_sa_out -> layer_4_ep3_tp_allreduce
	layer_4_ep3_tp3_sa_out -> layer_4_ep3_tp_allreduce
	layer_4_ep4_tp_allreduce [label="TP All-Reduce\nEP-Group-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_4_ep4_tp0_sa_out -> layer_4_ep4_tp_allreduce
	layer_4_ep4_tp1_sa_out -> layer_4_ep4_tp_allreduce
	layer_4_ep4_tp2_sa_out -> layer_4_ep4_tp_allreduce
	layer_4_ep4_tp3_sa_out -> layer_4_ep4_tp_allreduce
	layer_4_ep5_tp_allreduce [label="TP All-Reduce\nEP-Group-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_4_ep5_tp0_sa_out -> layer_4_ep5_tp_allreduce
	layer_4_ep5_tp1_sa_out -> layer_4_ep5_tp_allreduce
	layer_4_ep5_tp2_sa_out -> layer_4_ep5_tp_allreduce
	layer_4_ep5_tp3_sa_out -> layer_4_ep5_tp_allreduce
	layer_4_ep6_tp_allreduce [label="TP All-Reduce\nEP-Group-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_4_ep6_tp0_sa_out -> layer_4_ep6_tp_allreduce
	layer_4_ep6_tp1_sa_out -> layer_4_ep6_tp_allreduce
	layer_4_ep6_tp2_sa_out -> layer_4_ep6_tp_allreduce
	layer_4_ep6_tp3_sa_out -> layer_4_ep6_tp_allreduce
	layer_4_ep7_tp_allreduce [label="TP All-Reduce\nEP-Group-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_4_ep7_tp0_sa_out -> layer_4_ep7_tp_allreduce
	layer_4_ep7_tp1_sa_out -> layer_4_ep7_tp_allreduce
	layer_4_ep7_tp2_sa_out -> layer_4_ep7_tp_allreduce
	layer_4_ep7_tp3_sa_out -> layer_4_ep7_tp_allreduce
	layer_4_ep8_tp_allreduce [label="TP All-Reduce\nEP-Group-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_4_ep8_tp0_sa_out -> layer_4_ep8_tp_allreduce
	layer_4_ep8_tp1_sa_out -> layer_4_ep8_tp_allreduce
	layer_4_ep8_tp2_sa_out -> layer_4_ep8_tp_allreduce
	layer_4_ep8_tp3_sa_out -> layer_4_ep8_tp_allreduce
	layer_4_ep9_tp_allreduce [label="TP All-Reduce\nEP-Group-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_4_ep9_tp0_sa_out -> layer_4_ep9_tp_allreduce
	layer_4_ep9_tp1_sa_out -> layer_4_ep9_tp_allreduce
	layer_4_ep9_tp2_sa_out -> layer_4_ep9_tp_allreduce
	layer_4_ep9_tp3_sa_out -> layer_4_ep9_tp_allreduce
	layer_4_ep10_tp_allreduce [label="TP All-Reduce\nEP-Group-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_4_ep10_tp0_sa_out -> layer_4_ep10_tp_allreduce
	layer_4_ep10_tp1_sa_out -> layer_4_ep10_tp_allreduce
	layer_4_ep10_tp2_sa_out -> layer_4_ep10_tp_allreduce
	layer_4_ep10_tp3_sa_out -> layer_4_ep10_tp_allreduce
	layer_4_ep11_tp_allreduce [label="TP All-Reduce\nEP-Group-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_4_ep11_tp0_sa_out -> layer_4_ep11_tp_allreduce
	layer_4_ep11_tp1_sa_out -> layer_4_ep11_tp_allreduce
	layer_4_ep11_tp2_sa_out -> layer_4_ep11_tp_allreduce
	layer_4_ep11_tp3_sa_out -> layer_4_ep11_tp_allreduce
	layer_4_ep12_tp_allreduce [label="TP All-Reduce\nEP-Group-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_4_ep12_tp0_sa_out -> layer_4_ep12_tp_allreduce
	layer_4_ep12_tp1_sa_out -> layer_4_ep12_tp_allreduce
	layer_4_ep12_tp2_sa_out -> layer_4_ep12_tp_allreduce
	layer_4_ep12_tp3_sa_out -> layer_4_ep12_tp_allreduce
	layer_4_ep13_tp_allreduce [label="TP All-Reduce\nEP-Group-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_4_ep13_tp0_sa_out -> layer_4_ep13_tp_allreduce
	layer_4_ep13_tp1_sa_out -> layer_4_ep13_tp_allreduce
	layer_4_ep13_tp2_sa_out -> layer_4_ep13_tp_allreduce
	layer_4_ep13_tp3_sa_out -> layer_4_ep13_tp_allreduce
	layer_4_ep14_tp_allreduce [label="TP All-Reduce\nEP-Group-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_4_ep14_tp0_sa_out -> layer_4_ep14_tp_allreduce
	layer_4_ep14_tp1_sa_out -> layer_4_ep14_tp_allreduce
	layer_4_ep14_tp2_sa_out -> layer_4_ep14_tp_allreduce
	layer_4_ep14_tp3_sa_out -> layer_4_ep14_tp_allreduce
	layer_4_ep15_tp_allreduce [label="TP All-Reduce\nEP-Group-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_4_ep15_tp0_sa_out -> layer_4_ep15_tp_allreduce
	layer_4_ep15_tp1_sa_out -> layer_4_ep15_tp_allreduce
	layer_4_ep15_tp2_sa_out -> layer_4_ep15_tp_allreduce
	layer_4_ep15_tp3_sa_out -> layer_4_ep15_tp_allreduce
	layer_4_ep0_gate [label="MoE Gate\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_4_ep0_expert_0 [label="Expert-0\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep0_gate -> layer_4_ep0_expert_0 [label="select tokens" style=dashed]
	layer_4_ep0_expert_1 [label="Expert-1\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep0_gate -> layer_4_ep0_expert_1 [label="select tokens" style=dashed]
	layer_4_ep0_expert_2 [label="Expert-2\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep0_gate -> layer_4_ep0_expert_2 [label="select tokens" style=dashed]
	layer_4_ep0_expert_3 [label="Expert-3\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep0_gate -> layer_4_ep0_expert_3 [label="select tokens" style=dashed]
	layer_4_ep0_expert_aggr [label="Expert Aggregation\nEP-Group-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_4_ep0_expert_0 -> layer_4_ep0_expert_aggr
	layer_4_ep0_expert_1 -> layer_4_ep0_expert_aggr
	layer_4_ep0_expert_2 -> layer_4_ep0_expert_aggr
	layer_4_ep0_expert_3 -> layer_4_ep0_expert_aggr
	layer_4_ep1_gate [label="MoE Gate\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_4_ep1_expert_0 [label="Expert-0\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep1_gate -> layer_4_ep1_expert_0 [label="select tokens" style=dashed]
	layer_4_ep1_expert_1 [label="Expert-1\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep1_gate -> layer_4_ep1_expert_1 [label="select tokens" style=dashed]
	layer_4_ep1_expert_2 [label="Expert-2\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep1_gate -> layer_4_ep1_expert_2 [label="select tokens" style=dashed]
	layer_4_ep1_expert_3 [label="Expert-3\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep1_gate -> layer_4_ep1_expert_3 [label="select tokens" style=dashed]
	layer_4_ep1_expert_aggr [label="Expert Aggregation\nEP-Group-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_4_ep1_expert_0 -> layer_4_ep1_expert_aggr
	layer_4_ep1_expert_1 -> layer_4_ep1_expert_aggr
	layer_4_ep1_expert_2 -> layer_4_ep1_expert_aggr
	layer_4_ep1_expert_3 -> layer_4_ep1_expert_aggr
	layer_4_ep2_gate [label="MoE Gate\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_4_ep2_expert_0 [label="Expert-0\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep2_gate -> layer_4_ep2_expert_0 [label="select tokens" style=dashed]
	layer_4_ep2_expert_1 [label="Expert-1\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep2_gate -> layer_4_ep2_expert_1 [label="select tokens" style=dashed]
	layer_4_ep2_expert_2 [label="Expert-2\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep2_gate -> layer_4_ep2_expert_2 [label="select tokens" style=dashed]
	layer_4_ep2_expert_3 [label="Expert-3\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep2_gate -> layer_4_ep2_expert_3 [label="select tokens" style=dashed]
	layer_4_ep2_expert_aggr [label="Expert Aggregation\nEP-Group-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_4_ep2_expert_0 -> layer_4_ep2_expert_aggr
	layer_4_ep2_expert_1 -> layer_4_ep2_expert_aggr
	layer_4_ep2_expert_2 -> layer_4_ep2_expert_aggr
	layer_4_ep2_expert_3 -> layer_4_ep2_expert_aggr
	layer_4_ep3_gate [label="MoE Gate\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_4_ep3_expert_0 [label="Expert-0\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep3_gate -> layer_4_ep3_expert_0 [label="select tokens" style=dashed]
	layer_4_ep3_expert_1 [label="Expert-1\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep3_gate -> layer_4_ep3_expert_1 [label="select tokens" style=dashed]
	layer_4_ep3_expert_2 [label="Expert-2\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep3_gate -> layer_4_ep3_expert_2 [label="select tokens" style=dashed]
	layer_4_ep3_expert_3 [label="Expert-3\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep3_gate -> layer_4_ep3_expert_3 [label="select tokens" style=dashed]
	layer_4_ep3_expert_aggr [label="Expert Aggregation\nEP-Group-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_4_ep3_expert_0 -> layer_4_ep3_expert_aggr
	layer_4_ep3_expert_1 -> layer_4_ep3_expert_aggr
	layer_4_ep3_expert_2 -> layer_4_ep3_expert_aggr
	layer_4_ep3_expert_3 -> layer_4_ep3_expert_aggr
	layer_4_ep4_gate [label="MoE Gate\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_4_ep4_expert_0 [label="Expert-0\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep4_gate -> layer_4_ep4_expert_0 [label="select tokens" style=dashed]
	layer_4_ep4_expert_1 [label="Expert-1\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep4_gate -> layer_4_ep4_expert_1 [label="select tokens" style=dashed]
	layer_4_ep4_expert_2 [label="Expert-2\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep4_gate -> layer_4_ep4_expert_2 [label="select tokens" style=dashed]
	layer_4_ep4_expert_3 [label="Expert-3\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep4_gate -> layer_4_ep4_expert_3 [label="select tokens" style=dashed]
	layer_4_ep4_expert_aggr [label="Expert Aggregation\nEP-Group-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_4_ep4_expert_0 -> layer_4_ep4_expert_aggr
	layer_4_ep4_expert_1 -> layer_4_ep4_expert_aggr
	layer_4_ep4_expert_2 -> layer_4_ep4_expert_aggr
	layer_4_ep4_expert_3 -> layer_4_ep4_expert_aggr
	layer_4_ep5_gate [label="MoE Gate\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_4_ep5_expert_0 [label="Expert-0\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep5_gate -> layer_4_ep5_expert_0 [label="select tokens" style=dashed]
	layer_4_ep5_expert_1 [label="Expert-1\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep5_gate -> layer_4_ep5_expert_1 [label="select tokens" style=dashed]
	layer_4_ep5_expert_2 [label="Expert-2\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep5_gate -> layer_4_ep5_expert_2 [label="select tokens" style=dashed]
	layer_4_ep5_expert_3 [label="Expert-3\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep5_gate -> layer_4_ep5_expert_3 [label="select tokens" style=dashed]
	layer_4_ep5_expert_aggr [label="Expert Aggregation\nEP-Group-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_4_ep5_expert_0 -> layer_4_ep5_expert_aggr
	layer_4_ep5_expert_1 -> layer_4_ep5_expert_aggr
	layer_4_ep5_expert_2 -> layer_4_ep5_expert_aggr
	layer_4_ep5_expert_3 -> layer_4_ep5_expert_aggr
	layer_4_ep6_gate [label="MoE Gate\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_4_ep6_expert_0 [label="Expert-0\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep6_gate -> layer_4_ep6_expert_0 [label="select tokens" style=dashed]
	layer_4_ep6_expert_1 [label="Expert-1\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep6_gate -> layer_4_ep6_expert_1 [label="select tokens" style=dashed]
	layer_4_ep6_expert_2 [label="Expert-2\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep6_gate -> layer_4_ep6_expert_2 [label="select tokens" style=dashed]
	layer_4_ep6_expert_3 [label="Expert-3\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep6_gate -> layer_4_ep6_expert_3 [label="select tokens" style=dashed]
	layer_4_ep6_expert_aggr [label="Expert Aggregation\nEP-Group-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_4_ep6_expert_0 -> layer_4_ep6_expert_aggr
	layer_4_ep6_expert_1 -> layer_4_ep6_expert_aggr
	layer_4_ep6_expert_2 -> layer_4_ep6_expert_aggr
	layer_4_ep6_expert_3 -> layer_4_ep6_expert_aggr
	layer_4_ep7_gate [label="MoE Gate\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_4_ep7_expert_0 [label="Expert-0\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep7_gate -> layer_4_ep7_expert_0 [label="select tokens" style=dashed]
	layer_4_ep7_expert_1 [label="Expert-1\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep7_gate -> layer_4_ep7_expert_1 [label="select tokens" style=dashed]
	layer_4_ep7_expert_2 [label="Expert-2\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep7_gate -> layer_4_ep7_expert_2 [label="select tokens" style=dashed]
	layer_4_ep7_expert_3 [label="Expert-3\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep7_gate -> layer_4_ep7_expert_3 [label="select tokens" style=dashed]
	layer_4_ep7_expert_aggr [label="Expert Aggregation\nEP-Group-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_4_ep7_expert_0 -> layer_4_ep7_expert_aggr
	layer_4_ep7_expert_1 -> layer_4_ep7_expert_aggr
	layer_4_ep7_expert_2 -> layer_4_ep7_expert_aggr
	layer_4_ep7_expert_3 -> layer_4_ep7_expert_aggr
	layer_4_ep8_gate [label="MoE Gate\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_4_ep8_expert_0 [label="Expert-0\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep8_gate -> layer_4_ep8_expert_0 [label="select tokens" style=dashed]
	layer_4_ep8_expert_1 [label="Expert-1\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep8_gate -> layer_4_ep8_expert_1 [label="select tokens" style=dashed]
	layer_4_ep8_expert_2 [label="Expert-2\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep8_gate -> layer_4_ep8_expert_2 [label="select tokens" style=dashed]
	layer_4_ep8_expert_3 [label="Expert-3\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep8_gate -> layer_4_ep8_expert_3 [label="select tokens" style=dashed]
	layer_4_ep8_expert_aggr [label="Expert Aggregation\nEP-Group-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_4_ep8_expert_0 -> layer_4_ep8_expert_aggr
	layer_4_ep8_expert_1 -> layer_4_ep8_expert_aggr
	layer_4_ep8_expert_2 -> layer_4_ep8_expert_aggr
	layer_4_ep8_expert_3 -> layer_4_ep8_expert_aggr
	layer_4_ep9_gate [label="MoE Gate\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_4_ep9_expert_0 [label="Expert-0\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep9_gate -> layer_4_ep9_expert_0 [label="select tokens" style=dashed]
	layer_4_ep9_expert_1 [label="Expert-1\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep9_gate -> layer_4_ep9_expert_1 [label="select tokens" style=dashed]
	layer_4_ep9_expert_2 [label="Expert-2\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep9_gate -> layer_4_ep9_expert_2 [label="select tokens" style=dashed]
	layer_4_ep9_expert_3 [label="Expert-3\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep9_gate -> layer_4_ep9_expert_3 [label="select tokens" style=dashed]
	layer_4_ep9_expert_aggr [label="Expert Aggregation\nEP-Group-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_4_ep9_expert_0 -> layer_4_ep9_expert_aggr
	layer_4_ep9_expert_1 -> layer_4_ep9_expert_aggr
	layer_4_ep9_expert_2 -> layer_4_ep9_expert_aggr
	layer_4_ep9_expert_3 -> layer_4_ep9_expert_aggr
	layer_4_ep10_gate [label="MoE Gate\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_4_ep10_expert_0 [label="Expert-0\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep10_gate -> layer_4_ep10_expert_0 [label="select tokens" style=dashed]
	layer_4_ep10_expert_1 [label="Expert-1\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep10_gate -> layer_4_ep10_expert_1 [label="select tokens" style=dashed]
	layer_4_ep10_expert_2 [label="Expert-2\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep10_gate -> layer_4_ep10_expert_2 [label="select tokens" style=dashed]
	layer_4_ep10_expert_3 [label="Expert-3\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep10_gate -> layer_4_ep10_expert_3 [label="select tokens" style=dashed]
	layer_4_ep10_expert_aggr [label="Expert Aggregation\nEP-Group-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_4_ep10_expert_0 -> layer_4_ep10_expert_aggr
	layer_4_ep10_expert_1 -> layer_4_ep10_expert_aggr
	layer_4_ep10_expert_2 -> layer_4_ep10_expert_aggr
	layer_4_ep10_expert_3 -> layer_4_ep10_expert_aggr
	layer_4_ep11_gate [label="MoE Gate\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_4_ep11_expert_0 [label="Expert-0\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep11_gate -> layer_4_ep11_expert_0 [label="select tokens" style=dashed]
	layer_4_ep11_expert_1 [label="Expert-1\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep11_gate -> layer_4_ep11_expert_1 [label="select tokens" style=dashed]
	layer_4_ep11_expert_2 [label="Expert-2\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep11_gate -> layer_4_ep11_expert_2 [label="select tokens" style=dashed]
	layer_4_ep11_expert_3 [label="Expert-3\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep11_gate -> layer_4_ep11_expert_3 [label="select tokens" style=dashed]
	layer_4_ep11_expert_aggr [label="Expert Aggregation\nEP-Group-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_4_ep11_expert_0 -> layer_4_ep11_expert_aggr
	layer_4_ep11_expert_1 -> layer_4_ep11_expert_aggr
	layer_4_ep11_expert_2 -> layer_4_ep11_expert_aggr
	layer_4_ep11_expert_3 -> layer_4_ep11_expert_aggr
	layer_4_ep12_gate [label="MoE Gate\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_4_ep12_expert_0 [label="Expert-0\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep12_gate -> layer_4_ep12_expert_0 [label="select tokens" style=dashed]
	layer_4_ep12_expert_1 [label="Expert-1\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep12_gate -> layer_4_ep12_expert_1 [label="select tokens" style=dashed]
	layer_4_ep12_expert_2 [label="Expert-2\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep12_gate -> layer_4_ep12_expert_2 [label="select tokens" style=dashed]
	layer_4_ep12_expert_3 [label="Expert-3\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep12_gate -> layer_4_ep12_expert_3 [label="select tokens" style=dashed]
	layer_4_ep12_expert_aggr [label="Expert Aggregation\nEP-Group-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_4_ep12_expert_0 -> layer_4_ep12_expert_aggr
	layer_4_ep12_expert_1 -> layer_4_ep12_expert_aggr
	layer_4_ep12_expert_2 -> layer_4_ep12_expert_aggr
	layer_4_ep12_expert_3 -> layer_4_ep12_expert_aggr
	layer_4_ep13_gate [label="MoE Gate\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_4_ep13_expert_0 [label="Expert-0\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep13_gate -> layer_4_ep13_expert_0 [label="select tokens" style=dashed]
	layer_4_ep13_expert_1 [label="Expert-1\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep13_gate -> layer_4_ep13_expert_1 [label="select tokens" style=dashed]
	layer_4_ep13_expert_2 [label="Expert-2\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep13_gate -> layer_4_ep13_expert_2 [label="select tokens" style=dashed]
	layer_4_ep13_expert_3 [label="Expert-3\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep13_gate -> layer_4_ep13_expert_3 [label="select tokens" style=dashed]
	layer_4_ep13_expert_aggr [label="Expert Aggregation\nEP-Group-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_4_ep13_expert_0 -> layer_4_ep13_expert_aggr
	layer_4_ep13_expert_1 -> layer_4_ep13_expert_aggr
	layer_4_ep13_expert_2 -> layer_4_ep13_expert_aggr
	layer_4_ep13_expert_3 -> layer_4_ep13_expert_aggr
	layer_4_ep14_gate [label="MoE Gate\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_4_ep14_expert_0 [label="Expert-0\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep14_gate -> layer_4_ep14_expert_0 [label="select tokens" style=dashed]
	layer_4_ep14_expert_1 [label="Expert-1\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep14_gate -> layer_4_ep14_expert_1 [label="select tokens" style=dashed]
	layer_4_ep14_expert_2 [label="Expert-2\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep14_gate -> layer_4_ep14_expert_2 [label="select tokens" style=dashed]
	layer_4_ep14_expert_3 [label="Expert-3\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep14_gate -> layer_4_ep14_expert_3 [label="select tokens" style=dashed]
	layer_4_ep14_expert_aggr [label="Expert Aggregation\nEP-Group-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_4_ep14_expert_0 -> layer_4_ep14_expert_aggr
	layer_4_ep14_expert_1 -> layer_4_ep14_expert_aggr
	layer_4_ep14_expert_2 -> layer_4_ep14_expert_aggr
	layer_4_ep14_expert_3 -> layer_4_ep14_expert_aggr
	layer_4_ep15_gate [label="MoE Gate\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_4_ep15_expert_0 [label="Expert-0\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep15_gate -> layer_4_ep15_expert_0 [label="select tokens" style=dashed]
	layer_4_ep15_expert_1 [label="Expert-1\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep15_gate -> layer_4_ep15_expert_1 [label="select tokens" style=dashed]
	layer_4_ep15_expert_2 [label="Expert-2\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep15_gate -> layer_4_ep15_expert_2 [label="select tokens" style=dashed]
	layer_4_ep15_expert_3 [label="Expert-3\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_4_ep15_gate -> layer_4_ep15_expert_3 [label="select tokens" style=dashed]
	layer_4_ep15_expert_aggr [label="Expert Aggregation\nEP-Group-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_4_ep15_expert_0 -> layer_4_ep15_expert_aggr
	layer_4_ep15_expert_1 -> layer_4_ep15_expert_aggr
	layer_4_ep15_expert_2 -> layer_4_ep15_expert_aggr
	layer_4_ep15_expert_3 -> layer_4_ep15_expert_aggr
	layer_4_to_5_ep0_pp [label="Pipeline Stage Transfer\nEP-Group-0\nLayer-4 to Layer-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_4_ep0_expert_aggr -> layer_4_to_5_ep0_pp
	layer_4_to_5_ep1_pp [label="Pipeline Stage Transfer\nEP-Group-1\nLayer-4 to Layer-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_4_ep1_expert_aggr -> layer_4_to_5_ep1_pp
	layer_4_to_5_ep2_pp [label="Pipeline Stage Transfer\nEP-Group-2\nLayer-4 to Layer-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_4_ep2_expert_aggr -> layer_4_to_5_ep2_pp
	layer_4_to_5_ep3_pp [label="Pipeline Stage Transfer\nEP-Group-3\nLayer-4 to Layer-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_4_ep3_expert_aggr -> layer_4_to_5_ep3_pp
	layer_4_to_5_ep4_pp [label="Pipeline Stage Transfer\nEP-Group-4\nLayer-4 to Layer-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_4_ep4_expert_aggr -> layer_4_to_5_ep4_pp
	layer_4_to_5_ep5_pp [label="Pipeline Stage Transfer\nEP-Group-5\nLayer-4 to Layer-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_4_ep5_expert_aggr -> layer_4_to_5_ep5_pp
	layer_4_to_5_ep6_pp [label="Pipeline Stage Transfer\nEP-Group-6\nLayer-4 to Layer-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_4_ep6_expert_aggr -> layer_4_to_5_ep6_pp
	layer_4_to_5_ep7_pp [label="Pipeline Stage Transfer\nEP-Group-7\nLayer-4 to Layer-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_4_ep7_expert_aggr -> layer_4_to_5_ep7_pp
	layer_4_to_5_ep8_pp [label="Pipeline Stage Transfer\nEP-Group-8\nLayer-4 to Layer-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_4_ep8_expert_aggr -> layer_4_to_5_ep8_pp
	layer_4_to_5_ep9_pp [label="Pipeline Stage Transfer\nEP-Group-9\nLayer-4 to Layer-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_4_ep9_expert_aggr -> layer_4_to_5_ep9_pp
	layer_4_to_5_ep10_pp [label="Pipeline Stage Transfer\nEP-Group-10\nLayer-4 to Layer-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_4_ep10_expert_aggr -> layer_4_to_5_ep10_pp
	layer_4_to_5_ep11_pp [label="Pipeline Stage Transfer\nEP-Group-11\nLayer-4 to Layer-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_4_ep11_expert_aggr -> layer_4_to_5_ep11_pp
	layer_4_to_5_ep12_pp [label="Pipeline Stage Transfer\nEP-Group-12\nLayer-4 to Layer-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_4_ep12_expert_aggr -> layer_4_to_5_ep12_pp
	layer_4_to_5_ep13_pp [label="Pipeline Stage Transfer\nEP-Group-13\nLayer-4 to Layer-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_4_ep13_expert_aggr -> layer_4_to_5_ep13_pp
	layer_4_to_5_ep14_pp [label="Pipeline Stage Transfer\nEP-Group-14\nLayer-4 to Layer-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_4_ep14_expert_aggr -> layer_4_to_5_ep14_pp
	layer_4_to_5_ep15_pp [label="Pipeline Stage Transfer\nEP-Group-15\nLayer-4 to Layer-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_4_ep15_expert_aggr -> layer_4_to_5_ep15_pp
	layer_5_ep0_tp0_sa_qkv [label="Self-Attn QKV\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep0_tp0_sa_attn [label="Self-Attn Compute\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep0_tp0_sa_out [label="Self-Attn Output\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep0_tp0_sa_qkv -> layer_5_ep0_tp0_sa_attn
	layer_5_ep0_tp0_sa_attn -> layer_5_ep0_tp0_sa_out
	layer_5_ep0_tp1_sa_qkv [label="Self-Attn QKV\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep0_tp1_sa_attn [label="Self-Attn Compute\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep0_tp1_sa_out [label="Self-Attn Output\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep0_tp1_sa_qkv -> layer_5_ep0_tp1_sa_attn
	layer_5_ep0_tp1_sa_attn -> layer_5_ep0_tp1_sa_out
	layer_5_ep0_tp2_sa_qkv [label="Self-Attn QKV\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep0_tp2_sa_attn [label="Self-Attn Compute\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep0_tp2_sa_out [label="Self-Attn Output\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep0_tp2_sa_qkv -> layer_5_ep0_tp2_sa_attn
	layer_5_ep0_tp2_sa_attn -> layer_5_ep0_tp2_sa_out
	layer_5_ep0_tp3_sa_qkv [label="Self-Attn QKV\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep0_tp3_sa_attn [label="Self-Attn Compute\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep0_tp3_sa_out [label="Self-Attn Output\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep0_tp3_sa_qkv -> layer_5_ep0_tp3_sa_attn
	layer_5_ep0_tp3_sa_attn -> layer_5_ep0_tp3_sa_out
	layer_5_ep1_tp0_sa_qkv [label="Self-Attn QKV\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep1_tp0_sa_attn [label="Self-Attn Compute\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep1_tp0_sa_out [label="Self-Attn Output\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep1_tp0_sa_qkv -> layer_5_ep1_tp0_sa_attn
	layer_5_ep1_tp0_sa_attn -> layer_5_ep1_tp0_sa_out
	layer_5_ep1_tp1_sa_qkv [label="Self-Attn QKV\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep1_tp1_sa_attn [label="Self-Attn Compute\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep1_tp1_sa_out [label="Self-Attn Output\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep1_tp1_sa_qkv -> layer_5_ep1_tp1_sa_attn
	layer_5_ep1_tp1_sa_attn -> layer_5_ep1_tp1_sa_out
	layer_5_ep1_tp2_sa_qkv [label="Self-Attn QKV\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep1_tp2_sa_attn [label="Self-Attn Compute\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep1_tp2_sa_out [label="Self-Attn Output\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep1_tp2_sa_qkv -> layer_5_ep1_tp2_sa_attn
	layer_5_ep1_tp2_sa_attn -> layer_5_ep1_tp2_sa_out
	layer_5_ep1_tp3_sa_qkv [label="Self-Attn QKV\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep1_tp3_sa_attn [label="Self-Attn Compute\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep1_tp3_sa_out [label="Self-Attn Output\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep1_tp3_sa_qkv -> layer_5_ep1_tp3_sa_attn
	layer_5_ep1_tp3_sa_attn -> layer_5_ep1_tp3_sa_out
	layer_5_ep2_tp0_sa_qkv [label="Self-Attn QKV\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep2_tp0_sa_attn [label="Self-Attn Compute\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep2_tp0_sa_out [label="Self-Attn Output\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep2_tp0_sa_qkv -> layer_5_ep2_tp0_sa_attn
	layer_5_ep2_tp0_sa_attn -> layer_5_ep2_tp0_sa_out
	layer_5_ep2_tp1_sa_qkv [label="Self-Attn QKV\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep2_tp1_sa_attn [label="Self-Attn Compute\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep2_tp1_sa_out [label="Self-Attn Output\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep2_tp1_sa_qkv -> layer_5_ep2_tp1_sa_attn
	layer_5_ep2_tp1_sa_attn -> layer_5_ep2_tp1_sa_out
	layer_5_ep2_tp2_sa_qkv [label="Self-Attn QKV\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep2_tp2_sa_attn [label="Self-Attn Compute\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep2_tp2_sa_out [label="Self-Attn Output\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep2_tp2_sa_qkv -> layer_5_ep2_tp2_sa_attn
	layer_5_ep2_tp2_sa_attn -> layer_5_ep2_tp2_sa_out
	layer_5_ep2_tp3_sa_qkv [label="Self-Attn QKV\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep2_tp3_sa_attn [label="Self-Attn Compute\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep2_tp3_sa_out [label="Self-Attn Output\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep2_tp3_sa_qkv -> layer_5_ep2_tp3_sa_attn
	layer_5_ep2_tp3_sa_attn -> layer_5_ep2_tp3_sa_out
	layer_5_ep3_tp0_sa_qkv [label="Self-Attn QKV\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep3_tp0_sa_attn [label="Self-Attn Compute\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep3_tp0_sa_out [label="Self-Attn Output\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep3_tp0_sa_qkv -> layer_5_ep3_tp0_sa_attn
	layer_5_ep3_tp0_sa_attn -> layer_5_ep3_tp0_sa_out
	layer_5_ep3_tp1_sa_qkv [label="Self-Attn QKV\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep3_tp1_sa_attn [label="Self-Attn Compute\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep3_tp1_sa_out [label="Self-Attn Output\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep3_tp1_sa_qkv -> layer_5_ep3_tp1_sa_attn
	layer_5_ep3_tp1_sa_attn -> layer_5_ep3_tp1_sa_out
	layer_5_ep3_tp2_sa_qkv [label="Self-Attn QKV\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep3_tp2_sa_attn [label="Self-Attn Compute\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep3_tp2_sa_out [label="Self-Attn Output\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep3_tp2_sa_qkv -> layer_5_ep3_tp2_sa_attn
	layer_5_ep3_tp2_sa_attn -> layer_5_ep3_tp2_sa_out
	layer_5_ep3_tp3_sa_qkv [label="Self-Attn QKV\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep3_tp3_sa_attn [label="Self-Attn Compute\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep3_tp3_sa_out [label="Self-Attn Output\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep3_tp3_sa_qkv -> layer_5_ep3_tp3_sa_attn
	layer_5_ep3_tp3_sa_attn -> layer_5_ep3_tp3_sa_out
	layer_5_ep4_tp0_sa_qkv [label="Self-Attn QKV\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep4_tp0_sa_attn [label="Self-Attn Compute\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep4_tp0_sa_out [label="Self-Attn Output\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep4_tp0_sa_qkv -> layer_5_ep4_tp0_sa_attn
	layer_5_ep4_tp0_sa_attn -> layer_5_ep4_tp0_sa_out
	layer_5_ep4_tp1_sa_qkv [label="Self-Attn QKV\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep4_tp1_sa_attn [label="Self-Attn Compute\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep4_tp1_sa_out [label="Self-Attn Output\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep4_tp1_sa_qkv -> layer_5_ep4_tp1_sa_attn
	layer_5_ep4_tp1_sa_attn -> layer_5_ep4_tp1_sa_out
	layer_5_ep4_tp2_sa_qkv [label="Self-Attn QKV\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep4_tp2_sa_attn [label="Self-Attn Compute\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep4_tp2_sa_out [label="Self-Attn Output\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep4_tp2_sa_qkv -> layer_5_ep4_tp2_sa_attn
	layer_5_ep4_tp2_sa_attn -> layer_5_ep4_tp2_sa_out
	layer_5_ep4_tp3_sa_qkv [label="Self-Attn QKV\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep4_tp3_sa_attn [label="Self-Attn Compute\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep4_tp3_sa_out [label="Self-Attn Output\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep4_tp3_sa_qkv -> layer_5_ep4_tp3_sa_attn
	layer_5_ep4_tp3_sa_attn -> layer_5_ep4_tp3_sa_out
	layer_5_ep5_tp0_sa_qkv [label="Self-Attn QKV\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep5_tp0_sa_attn [label="Self-Attn Compute\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep5_tp0_sa_out [label="Self-Attn Output\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep5_tp0_sa_qkv -> layer_5_ep5_tp0_sa_attn
	layer_5_ep5_tp0_sa_attn -> layer_5_ep5_tp0_sa_out
	layer_5_ep5_tp1_sa_qkv [label="Self-Attn QKV\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep5_tp1_sa_attn [label="Self-Attn Compute\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep5_tp1_sa_out [label="Self-Attn Output\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep5_tp1_sa_qkv -> layer_5_ep5_tp1_sa_attn
	layer_5_ep5_tp1_sa_attn -> layer_5_ep5_tp1_sa_out
	layer_5_ep5_tp2_sa_qkv [label="Self-Attn QKV\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep5_tp2_sa_attn [label="Self-Attn Compute\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep5_tp2_sa_out [label="Self-Attn Output\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep5_tp2_sa_qkv -> layer_5_ep5_tp2_sa_attn
	layer_5_ep5_tp2_sa_attn -> layer_5_ep5_tp2_sa_out
	layer_5_ep5_tp3_sa_qkv [label="Self-Attn QKV\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep5_tp3_sa_attn [label="Self-Attn Compute\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep5_tp3_sa_out [label="Self-Attn Output\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep5_tp3_sa_qkv -> layer_5_ep5_tp3_sa_attn
	layer_5_ep5_tp3_sa_attn -> layer_5_ep5_tp3_sa_out
	layer_5_ep6_tp0_sa_qkv [label="Self-Attn QKV\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep6_tp0_sa_attn [label="Self-Attn Compute\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep6_tp0_sa_out [label="Self-Attn Output\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep6_tp0_sa_qkv -> layer_5_ep6_tp0_sa_attn
	layer_5_ep6_tp0_sa_attn -> layer_5_ep6_tp0_sa_out
	layer_5_ep6_tp1_sa_qkv [label="Self-Attn QKV\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep6_tp1_sa_attn [label="Self-Attn Compute\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep6_tp1_sa_out [label="Self-Attn Output\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep6_tp1_sa_qkv -> layer_5_ep6_tp1_sa_attn
	layer_5_ep6_tp1_sa_attn -> layer_5_ep6_tp1_sa_out
	layer_5_ep6_tp2_sa_qkv [label="Self-Attn QKV\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep6_tp2_sa_attn [label="Self-Attn Compute\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep6_tp2_sa_out [label="Self-Attn Output\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep6_tp2_sa_qkv -> layer_5_ep6_tp2_sa_attn
	layer_5_ep6_tp2_sa_attn -> layer_5_ep6_tp2_sa_out
	layer_5_ep6_tp3_sa_qkv [label="Self-Attn QKV\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep6_tp3_sa_attn [label="Self-Attn Compute\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep6_tp3_sa_out [label="Self-Attn Output\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep6_tp3_sa_qkv -> layer_5_ep6_tp3_sa_attn
	layer_5_ep6_tp3_sa_attn -> layer_5_ep6_tp3_sa_out
	layer_5_ep7_tp0_sa_qkv [label="Self-Attn QKV\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep7_tp0_sa_attn [label="Self-Attn Compute\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep7_tp0_sa_out [label="Self-Attn Output\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep7_tp0_sa_qkv -> layer_5_ep7_tp0_sa_attn
	layer_5_ep7_tp0_sa_attn -> layer_5_ep7_tp0_sa_out
	layer_5_ep7_tp1_sa_qkv [label="Self-Attn QKV\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep7_tp1_sa_attn [label="Self-Attn Compute\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep7_tp1_sa_out [label="Self-Attn Output\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep7_tp1_sa_qkv -> layer_5_ep7_tp1_sa_attn
	layer_5_ep7_tp1_sa_attn -> layer_5_ep7_tp1_sa_out
	layer_5_ep7_tp2_sa_qkv [label="Self-Attn QKV\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep7_tp2_sa_attn [label="Self-Attn Compute\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep7_tp2_sa_out [label="Self-Attn Output\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep7_tp2_sa_qkv -> layer_5_ep7_tp2_sa_attn
	layer_5_ep7_tp2_sa_attn -> layer_5_ep7_tp2_sa_out
	layer_5_ep7_tp3_sa_qkv [label="Self-Attn QKV\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep7_tp3_sa_attn [label="Self-Attn Compute\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep7_tp3_sa_out [label="Self-Attn Output\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep7_tp3_sa_qkv -> layer_5_ep7_tp3_sa_attn
	layer_5_ep7_tp3_sa_attn -> layer_5_ep7_tp3_sa_out
	layer_5_ep8_tp0_sa_qkv [label="Self-Attn QKV\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep8_tp0_sa_attn [label="Self-Attn Compute\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep8_tp0_sa_out [label="Self-Attn Output\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep8_tp0_sa_qkv -> layer_5_ep8_tp0_sa_attn
	layer_5_ep8_tp0_sa_attn -> layer_5_ep8_tp0_sa_out
	layer_5_ep8_tp1_sa_qkv [label="Self-Attn QKV\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep8_tp1_sa_attn [label="Self-Attn Compute\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep8_tp1_sa_out [label="Self-Attn Output\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep8_tp1_sa_qkv -> layer_5_ep8_tp1_sa_attn
	layer_5_ep8_tp1_sa_attn -> layer_5_ep8_tp1_sa_out
	layer_5_ep8_tp2_sa_qkv [label="Self-Attn QKV\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep8_tp2_sa_attn [label="Self-Attn Compute\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep8_tp2_sa_out [label="Self-Attn Output\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep8_tp2_sa_qkv -> layer_5_ep8_tp2_sa_attn
	layer_5_ep8_tp2_sa_attn -> layer_5_ep8_tp2_sa_out
	layer_5_ep8_tp3_sa_qkv [label="Self-Attn QKV\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep8_tp3_sa_attn [label="Self-Attn Compute\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep8_tp3_sa_out [label="Self-Attn Output\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep8_tp3_sa_qkv -> layer_5_ep8_tp3_sa_attn
	layer_5_ep8_tp3_sa_attn -> layer_5_ep8_tp3_sa_out
	layer_5_ep9_tp0_sa_qkv [label="Self-Attn QKV\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep9_tp0_sa_attn [label="Self-Attn Compute\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep9_tp0_sa_out [label="Self-Attn Output\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep9_tp0_sa_qkv -> layer_5_ep9_tp0_sa_attn
	layer_5_ep9_tp0_sa_attn -> layer_5_ep9_tp0_sa_out
	layer_5_ep9_tp1_sa_qkv [label="Self-Attn QKV\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep9_tp1_sa_attn [label="Self-Attn Compute\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep9_tp1_sa_out [label="Self-Attn Output\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep9_tp1_sa_qkv -> layer_5_ep9_tp1_sa_attn
	layer_5_ep9_tp1_sa_attn -> layer_5_ep9_tp1_sa_out
	layer_5_ep9_tp2_sa_qkv [label="Self-Attn QKV\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep9_tp2_sa_attn [label="Self-Attn Compute\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep9_tp2_sa_out [label="Self-Attn Output\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep9_tp2_sa_qkv -> layer_5_ep9_tp2_sa_attn
	layer_5_ep9_tp2_sa_attn -> layer_5_ep9_tp2_sa_out
	layer_5_ep9_tp3_sa_qkv [label="Self-Attn QKV\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep9_tp3_sa_attn [label="Self-Attn Compute\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep9_tp3_sa_out [label="Self-Attn Output\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep9_tp3_sa_qkv -> layer_5_ep9_tp3_sa_attn
	layer_5_ep9_tp3_sa_attn -> layer_5_ep9_tp3_sa_out
	layer_5_ep10_tp0_sa_qkv [label="Self-Attn QKV\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep10_tp0_sa_attn [label="Self-Attn Compute\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep10_tp0_sa_out [label="Self-Attn Output\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep10_tp0_sa_qkv -> layer_5_ep10_tp0_sa_attn
	layer_5_ep10_tp0_sa_attn -> layer_5_ep10_tp0_sa_out
	layer_5_ep10_tp1_sa_qkv [label="Self-Attn QKV\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep10_tp1_sa_attn [label="Self-Attn Compute\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep10_tp1_sa_out [label="Self-Attn Output\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep10_tp1_sa_qkv -> layer_5_ep10_tp1_sa_attn
	layer_5_ep10_tp1_sa_attn -> layer_5_ep10_tp1_sa_out
	layer_5_ep10_tp2_sa_qkv [label="Self-Attn QKV\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep10_tp2_sa_attn [label="Self-Attn Compute\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep10_tp2_sa_out [label="Self-Attn Output\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep10_tp2_sa_qkv -> layer_5_ep10_tp2_sa_attn
	layer_5_ep10_tp2_sa_attn -> layer_5_ep10_tp2_sa_out
	layer_5_ep10_tp3_sa_qkv [label="Self-Attn QKV\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep10_tp3_sa_attn [label="Self-Attn Compute\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep10_tp3_sa_out [label="Self-Attn Output\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep10_tp3_sa_qkv -> layer_5_ep10_tp3_sa_attn
	layer_5_ep10_tp3_sa_attn -> layer_5_ep10_tp3_sa_out
	layer_5_ep11_tp0_sa_qkv [label="Self-Attn QKV\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep11_tp0_sa_attn [label="Self-Attn Compute\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep11_tp0_sa_out [label="Self-Attn Output\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep11_tp0_sa_qkv -> layer_5_ep11_tp0_sa_attn
	layer_5_ep11_tp0_sa_attn -> layer_5_ep11_tp0_sa_out
	layer_5_ep11_tp1_sa_qkv [label="Self-Attn QKV\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep11_tp1_sa_attn [label="Self-Attn Compute\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep11_tp1_sa_out [label="Self-Attn Output\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep11_tp1_sa_qkv -> layer_5_ep11_tp1_sa_attn
	layer_5_ep11_tp1_sa_attn -> layer_5_ep11_tp1_sa_out
	layer_5_ep11_tp2_sa_qkv [label="Self-Attn QKV\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep11_tp2_sa_attn [label="Self-Attn Compute\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep11_tp2_sa_out [label="Self-Attn Output\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep11_tp2_sa_qkv -> layer_5_ep11_tp2_sa_attn
	layer_5_ep11_tp2_sa_attn -> layer_5_ep11_tp2_sa_out
	layer_5_ep11_tp3_sa_qkv [label="Self-Attn QKV\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep11_tp3_sa_attn [label="Self-Attn Compute\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep11_tp3_sa_out [label="Self-Attn Output\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep11_tp3_sa_qkv -> layer_5_ep11_tp3_sa_attn
	layer_5_ep11_tp3_sa_attn -> layer_5_ep11_tp3_sa_out
	layer_5_ep12_tp0_sa_qkv [label="Self-Attn QKV\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep12_tp0_sa_attn [label="Self-Attn Compute\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep12_tp0_sa_out [label="Self-Attn Output\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep12_tp0_sa_qkv -> layer_5_ep12_tp0_sa_attn
	layer_5_ep12_tp0_sa_attn -> layer_5_ep12_tp0_sa_out
	layer_5_ep12_tp1_sa_qkv [label="Self-Attn QKV\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep12_tp1_sa_attn [label="Self-Attn Compute\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep12_tp1_sa_out [label="Self-Attn Output\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep12_tp1_sa_qkv -> layer_5_ep12_tp1_sa_attn
	layer_5_ep12_tp1_sa_attn -> layer_5_ep12_tp1_sa_out
	layer_5_ep12_tp2_sa_qkv [label="Self-Attn QKV\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep12_tp2_sa_attn [label="Self-Attn Compute\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep12_tp2_sa_out [label="Self-Attn Output\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep12_tp2_sa_qkv -> layer_5_ep12_tp2_sa_attn
	layer_5_ep12_tp2_sa_attn -> layer_5_ep12_tp2_sa_out
	layer_5_ep12_tp3_sa_qkv [label="Self-Attn QKV\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep12_tp3_sa_attn [label="Self-Attn Compute\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep12_tp3_sa_out [label="Self-Attn Output\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep12_tp3_sa_qkv -> layer_5_ep12_tp3_sa_attn
	layer_5_ep12_tp3_sa_attn -> layer_5_ep12_tp3_sa_out
	layer_5_ep13_tp0_sa_qkv [label="Self-Attn QKV\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep13_tp0_sa_attn [label="Self-Attn Compute\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep13_tp0_sa_out [label="Self-Attn Output\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep13_tp0_sa_qkv -> layer_5_ep13_tp0_sa_attn
	layer_5_ep13_tp0_sa_attn -> layer_5_ep13_tp0_sa_out
	layer_5_ep13_tp1_sa_qkv [label="Self-Attn QKV\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep13_tp1_sa_attn [label="Self-Attn Compute\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep13_tp1_sa_out [label="Self-Attn Output\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep13_tp1_sa_qkv -> layer_5_ep13_tp1_sa_attn
	layer_5_ep13_tp1_sa_attn -> layer_5_ep13_tp1_sa_out
	layer_5_ep13_tp2_sa_qkv [label="Self-Attn QKV\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep13_tp2_sa_attn [label="Self-Attn Compute\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep13_tp2_sa_out [label="Self-Attn Output\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep13_tp2_sa_qkv -> layer_5_ep13_tp2_sa_attn
	layer_5_ep13_tp2_sa_attn -> layer_5_ep13_tp2_sa_out
	layer_5_ep13_tp3_sa_qkv [label="Self-Attn QKV\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep13_tp3_sa_attn [label="Self-Attn Compute\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep13_tp3_sa_out [label="Self-Attn Output\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep13_tp3_sa_qkv -> layer_5_ep13_tp3_sa_attn
	layer_5_ep13_tp3_sa_attn -> layer_5_ep13_tp3_sa_out
	layer_5_ep14_tp0_sa_qkv [label="Self-Attn QKV\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep14_tp0_sa_attn [label="Self-Attn Compute\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep14_tp0_sa_out [label="Self-Attn Output\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep14_tp0_sa_qkv -> layer_5_ep14_tp0_sa_attn
	layer_5_ep14_tp0_sa_attn -> layer_5_ep14_tp0_sa_out
	layer_5_ep14_tp1_sa_qkv [label="Self-Attn QKV\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep14_tp1_sa_attn [label="Self-Attn Compute\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep14_tp1_sa_out [label="Self-Attn Output\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep14_tp1_sa_qkv -> layer_5_ep14_tp1_sa_attn
	layer_5_ep14_tp1_sa_attn -> layer_5_ep14_tp1_sa_out
	layer_5_ep14_tp2_sa_qkv [label="Self-Attn QKV\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep14_tp2_sa_attn [label="Self-Attn Compute\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep14_tp2_sa_out [label="Self-Attn Output\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep14_tp2_sa_qkv -> layer_5_ep14_tp2_sa_attn
	layer_5_ep14_tp2_sa_attn -> layer_5_ep14_tp2_sa_out
	layer_5_ep14_tp3_sa_qkv [label="Self-Attn QKV\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep14_tp3_sa_attn [label="Self-Attn Compute\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep14_tp3_sa_out [label="Self-Attn Output\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep14_tp3_sa_qkv -> layer_5_ep14_tp3_sa_attn
	layer_5_ep14_tp3_sa_attn -> layer_5_ep14_tp3_sa_out
	layer_5_ep15_tp0_sa_qkv [label="Self-Attn QKV\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep15_tp0_sa_attn [label="Self-Attn Compute\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep15_tp0_sa_out [label="Self-Attn Output\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep15_tp0_sa_qkv -> layer_5_ep15_tp0_sa_attn
	layer_5_ep15_tp0_sa_attn -> layer_5_ep15_tp0_sa_out
	layer_5_ep15_tp1_sa_qkv [label="Self-Attn QKV\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep15_tp1_sa_attn [label="Self-Attn Compute\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep15_tp1_sa_out [label="Self-Attn Output\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep15_tp1_sa_qkv -> layer_5_ep15_tp1_sa_attn
	layer_5_ep15_tp1_sa_attn -> layer_5_ep15_tp1_sa_out
	layer_5_ep15_tp2_sa_qkv [label="Self-Attn QKV\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep15_tp2_sa_attn [label="Self-Attn Compute\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep15_tp2_sa_out [label="Self-Attn Output\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep15_tp2_sa_qkv -> layer_5_ep15_tp2_sa_attn
	layer_5_ep15_tp2_sa_attn -> layer_5_ep15_tp2_sa_out
	layer_5_ep15_tp3_sa_qkv [label="Self-Attn QKV\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep15_tp3_sa_attn [label="Self-Attn Compute\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep15_tp3_sa_out [label="Self-Attn Output\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep15_tp3_sa_qkv -> layer_5_ep15_tp3_sa_attn
	layer_5_ep15_tp3_sa_attn -> layer_5_ep15_tp3_sa_out
	layer_5_ep0_tp_allreduce [label="TP All-Reduce\nEP-Group-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_5_ep0_tp0_sa_out -> layer_5_ep0_tp_allreduce
	layer_5_ep0_tp1_sa_out -> layer_5_ep0_tp_allreduce
	layer_5_ep0_tp2_sa_out -> layer_5_ep0_tp_allreduce
	layer_5_ep0_tp3_sa_out -> layer_5_ep0_tp_allreduce
	layer_5_ep1_tp_allreduce [label="TP All-Reduce\nEP-Group-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_5_ep1_tp0_sa_out -> layer_5_ep1_tp_allreduce
	layer_5_ep1_tp1_sa_out -> layer_5_ep1_tp_allreduce
	layer_5_ep1_tp2_sa_out -> layer_5_ep1_tp_allreduce
	layer_5_ep1_tp3_sa_out -> layer_5_ep1_tp_allreduce
	layer_5_ep2_tp_allreduce [label="TP All-Reduce\nEP-Group-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_5_ep2_tp0_sa_out -> layer_5_ep2_tp_allreduce
	layer_5_ep2_tp1_sa_out -> layer_5_ep2_tp_allreduce
	layer_5_ep2_tp2_sa_out -> layer_5_ep2_tp_allreduce
	layer_5_ep2_tp3_sa_out -> layer_5_ep2_tp_allreduce
	layer_5_ep3_tp_allreduce [label="TP All-Reduce\nEP-Group-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_5_ep3_tp0_sa_out -> layer_5_ep3_tp_allreduce
	layer_5_ep3_tp1_sa_out -> layer_5_ep3_tp_allreduce
	layer_5_ep3_tp2_sa_out -> layer_5_ep3_tp_allreduce
	layer_5_ep3_tp3_sa_out -> layer_5_ep3_tp_allreduce
	layer_5_ep4_tp_allreduce [label="TP All-Reduce\nEP-Group-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_5_ep4_tp0_sa_out -> layer_5_ep4_tp_allreduce
	layer_5_ep4_tp1_sa_out -> layer_5_ep4_tp_allreduce
	layer_5_ep4_tp2_sa_out -> layer_5_ep4_tp_allreduce
	layer_5_ep4_tp3_sa_out -> layer_5_ep4_tp_allreduce
	layer_5_ep5_tp_allreduce [label="TP All-Reduce\nEP-Group-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_5_ep5_tp0_sa_out -> layer_5_ep5_tp_allreduce
	layer_5_ep5_tp1_sa_out -> layer_5_ep5_tp_allreduce
	layer_5_ep5_tp2_sa_out -> layer_5_ep5_tp_allreduce
	layer_5_ep5_tp3_sa_out -> layer_5_ep5_tp_allreduce
	layer_5_ep6_tp_allreduce [label="TP All-Reduce\nEP-Group-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_5_ep6_tp0_sa_out -> layer_5_ep6_tp_allreduce
	layer_5_ep6_tp1_sa_out -> layer_5_ep6_tp_allreduce
	layer_5_ep6_tp2_sa_out -> layer_5_ep6_tp_allreduce
	layer_5_ep6_tp3_sa_out -> layer_5_ep6_tp_allreduce
	layer_5_ep7_tp_allreduce [label="TP All-Reduce\nEP-Group-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_5_ep7_tp0_sa_out -> layer_5_ep7_tp_allreduce
	layer_5_ep7_tp1_sa_out -> layer_5_ep7_tp_allreduce
	layer_5_ep7_tp2_sa_out -> layer_5_ep7_tp_allreduce
	layer_5_ep7_tp3_sa_out -> layer_5_ep7_tp_allreduce
	layer_5_ep8_tp_allreduce [label="TP All-Reduce\nEP-Group-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_5_ep8_tp0_sa_out -> layer_5_ep8_tp_allreduce
	layer_5_ep8_tp1_sa_out -> layer_5_ep8_tp_allreduce
	layer_5_ep8_tp2_sa_out -> layer_5_ep8_tp_allreduce
	layer_5_ep8_tp3_sa_out -> layer_5_ep8_tp_allreduce
	layer_5_ep9_tp_allreduce [label="TP All-Reduce\nEP-Group-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_5_ep9_tp0_sa_out -> layer_5_ep9_tp_allreduce
	layer_5_ep9_tp1_sa_out -> layer_5_ep9_tp_allreduce
	layer_5_ep9_tp2_sa_out -> layer_5_ep9_tp_allreduce
	layer_5_ep9_tp3_sa_out -> layer_5_ep9_tp_allreduce
	layer_5_ep10_tp_allreduce [label="TP All-Reduce\nEP-Group-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_5_ep10_tp0_sa_out -> layer_5_ep10_tp_allreduce
	layer_5_ep10_tp1_sa_out -> layer_5_ep10_tp_allreduce
	layer_5_ep10_tp2_sa_out -> layer_5_ep10_tp_allreduce
	layer_5_ep10_tp3_sa_out -> layer_5_ep10_tp_allreduce
	layer_5_ep11_tp_allreduce [label="TP All-Reduce\nEP-Group-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_5_ep11_tp0_sa_out -> layer_5_ep11_tp_allreduce
	layer_5_ep11_tp1_sa_out -> layer_5_ep11_tp_allreduce
	layer_5_ep11_tp2_sa_out -> layer_5_ep11_tp_allreduce
	layer_5_ep11_tp3_sa_out -> layer_5_ep11_tp_allreduce
	layer_5_ep12_tp_allreduce [label="TP All-Reduce\nEP-Group-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_5_ep12_tp0_sa_out -> layer_5_ep12_tp_allreduce
	layer_5_ep12_tp1_sa_out -> layer_5_ep12_tp_allreduce
	layer_5_ep12_tp2_sa_out -> layer_5_ep12_tp_allreduce
	layer_5_ep12_tp3_sa_out -> layer_5_ep12_tp_allreduce
	layer_5_ep13_tp_allreduce [label="TP All-Reduce\nEP-Group-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_5_ep13_tp0_sa_out -> layer_5_ep13_tp_allreduce
	layer_5_ep13_tp1_sa_out -> layer_5_ep13_tp_allreduce
	layer_5_ep13_tp2_sa_out -> layer_5_ep13_tp_allreduce
	layer_5_ep13_tp3_sa_out -> layer_5_ep13_tp_allreduce
	layer_5_ep14_tp_allreduce [label="TP All-Reduce\nEP-Group-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_5_ep14_tp0_sa_out -> layer_5_ep14_tp_allreduce
	layer_5_ep14_tp1_sa_out -> layer_5_ep14_tp_allreduce
	layer_5_ep14_tp2_sa_out -> layer_5_ep14_tp_allreduce
	layer_5_ep14_tp3_sa_out -> layer_5_ep14_tp_allreduce
	layer_5_ep15_tp_allreduce [label="TP All-Reduce\nEP-Group-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_5_ep15_tp0_sa_out -> layer_5_ep15_tp_allreduce
	layer_5_ep15_tp1_sa_out -> layer_5_ep15_tp_allreduce
	layer_5_ep15_tp2_sa_out -> layer_5_ep15_tp_allreduce
	layer_5_ep15_tp3_sa_out -> layer_5_ep15_tp_allreduce
	layer_5_ep0_gate [label="MoE Gate\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_5_ep0_expert_0 [label="Expert-0\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep0_gate -> layer_5_ep0_expert_0 [label="select tokens" style=dashed]
	layer_5_ep0_expert_1 [label="Expert-1\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep0_gate -> layer_5_ep0_expert_1 [label="select tokens" style=dashed]
	layer_5_ep0_expert_2 [label="Expert-2\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep0_gate -> layer_5_ep0_expert_2 [label="select tokens" style=dashed]
	layer_5_ep0_expert_3 [label="Expert-3\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep0_gate -> layer_5_ep0_expert_3 [label="select tokens" style=dashed]
	layer_5_ep0_expert_aggr [label="Expert Aggregation\nEP-Group-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_5_ep0_expert_0 -> layer_5_ep0_expert_aggr
	layer_5_ep0_expert_1 -> layer_5_ep0_expert_aggr
	layer_5_ep0_expert_2 -> layer_5_ep0_expert_aggr
	layer_5_ep0_expert_3 -> layer_5_ep0_expert_aggr
	layer_5_ep1_gate [label="MoE Gate\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_5_ep1_expert_0 [label="Expert-0\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep1_gate -> layer_5_ep1_expert_0 [label="select tokens" style=dashed]
	layer_5_ep1_expert_1 [label="Expert-1\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep1_gate -> layer_5_ep1_expert_1 [label="select tokens" style=dashed]
	layer_5_ep1_expert_2 [label="Expert-2\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep1_gate -> layer_5_ep1_expert_2 [label="select tokens" style=dashed]
	layer_5_ep1_expert_3 [label="Expert-3\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep1_gate -> layer_5_ep1_expert_3 [label="select tokens" style=dashed]
	layer_5_ep1_expert_aggr [label="Expert Aggregation\nEP-Group-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_5_ep1_expert_0 -> layer_5_ep1_expert_aggr
	layer_5_ep1_expert_1 -> layer_5_ep1_expert_aggr
	layer_5_ep1_expert_2 -> layer_5_ep1_expert_aggr
	layer_5_ep1_expert_3 -> layer_5_ep1_expert_aggr
	layer_5_ep2_gate [label="MoE Gate\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_5_ep2_expert_0 [label="Expert-0\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep2_gate -> layer_5_ep2_expert_0 [label="select tokens" style=dashed]
	layer_5_ep2_expert_1 [label="Expert-1\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep2_gate -> layer_5_ep2_expert_1 [label="select tokens" style=dashed]
	layer_5_ep2_expert_2 [label="Expert-2\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep2_gate -> layer_5_ep2_expert_2 [label="select tokens" style=dashed]
	layer_5_ep2_expert_3 [label="Expert-3\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep2_gate -> layer_5_ep2_expert_3 [label="select tokens" style=dashed]
	layer_5_ep2_expert_aggr [label="Expert Aggregation\nEP-Group-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_5_ep2_expert_0 -> layer_5_ep2_expert_aggr
	layer_5_ep2_expert_1 -> layer_5_ep2_expert_aggr
	layer_5_ep2_expert_2 -> layer_5_ep2_expert_aggr
	layer_5_ep2_expert_3 -> layer_5_ep2_expert_aggr
	layer_5_ep3_gate [label="MoE Gate\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_5_ep3_expert_0 [label="Expert-0\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep3_gate -> layer_5_ep3_expert_0 [label="select tokens" style=dashed]
	layer_5_ep3_expert_1 [label="Expert-1\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep3_gate -> layer_5_ep3_expert_1 [label="select tokens" style=dashed]
	layer_5_ep3_expert_2 [label="Expert-2\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep3_gate -> layer_5_ep3_expert_2 [label="select tokens" style=dashed]
	layer_5_ep3_expert_3 [label="Expert-3\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep3_gate -> layer_5_ep3_expert_3 [label="select tokens" style=dashed]
	layer_5_ep3_expert_aggr [label="Expert Aggregation\nEP-Group-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_5_ep3_expert_0 -> layer_5_ep3_expert_aggr
	layer_5_ep3_expert_1 -> layer_5_ep3_expert_aggr
	layer_5_ep3_expert_2 -> layer_5_ep3_expert_aggr
	layer_5_ep3_expert_3 -> layer_5_ep3_expert_aggr
	layer_5_ep4_gate [label="MoE Gate\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_5_ep4_expert_0 [label="Expert-0\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep4_gate -> layer_5_ep4_expert_0 [label="select tokens" style=dashed]
	layer_5_ep4_expert_1 [label="Expert-1\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep4_gate -> layer_5_ep4_expert_1 [label="select tokens" style=dashed]
	layer_5_ep4_expert_2 [label="Expert-2\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep4_gate -> layer_5_ep4_expert_2 [label="select tokens" style=dashed]
	layer_5_ep4_expert_3 [label="Expert-3\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep4_gate -> layer_5_ep4_expert_3 [label="select tokens" style=dashed]
	layer_5_ep4_expert_aggr [label="Expert Aggregation\nEP-Group-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_5_ep4_expert_0 -> layer_5_ep4_expert_aggr
	layer_5_ep4_expert_1 -> layer_5_ep4_expert_aggr
	layer_5_ep4_expert_2 -> layer_5_ep4_expert_aggr
	layer_5_ep4_expert_3 -> layer_5_ep4_expert_aggr
	layer_5_ep5_gate [label="MoE Gate\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_5_ep5_expert_0 [label="Expert-0\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep5_gate -> layer_5_ep5_expert_0 [label="select tokens" style=dashed]
	layer_5_ep5_expert_1 [label="Expert-1\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep5_gate -> layer_5_ep5_expert_1 [label="select tokens" style=dashed]
	layer_5_ep5_expert_2 [label="Expert-2\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep5_gate -> layer_5_ep5_expert_2 [label="select tokens" style=dashed]
	layer_5_ep5_expert_3 [label="Expert-3\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep5_gate -> layer_5_ep5_expert_3 [label="select tokens" style=dashed]
	layer_5_ep5_expert_aggr [label="Expert Aggregation\nEP-Group-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_5_ep5_expert_0 -> layer_5_ep5_expert_aggr
	layer_5_ep5_expert_1 -> layer_5_ep5_expert_aggr
	layer_5_ep5_expert_2 -> layer_5_ep5_expert_aggr
	layer_5_ep5_expert_3 -> layer_5_ep5_expert_aggr
	layer_5_ep6_gate [label="MoE Gate\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_5_ep6_expert_0 [label="Expert-0\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep6_gate -> layer_5_ep6_expert_0 [label="select tokens" style=dashed]
	layer_5_ep6_expert_1 [label="Expert-1\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep6_gate -> layer_5_ep6_expert_1 [label="select tokens" style=dashed]
	layer_5_ep6_expert_2 [label="Expert-2\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep6_gate -> layer_5_ep6_expert_2 [label="select tokens" style=dashed]
	layer_5_ep6_expert_3 [label="Expert-3\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep6_gate -> layer_5_ep6_expert_3 [label="select tokens" style=dashed]
	layer_5_ep6_expert_aggr [label="Expert Aggregation\nEP-Group-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_5_ep6_expert_0 -> layer_5_ep6_expert_aggr
	layer_5_ep6_expert_1 -> layer_5_ep6_expert_aggr
	layer_5_ep6_expert_2 -> layer_5_ep6_expert_aggr
	layer_5_ep6_expert_3 -> layer_5_ep6_expert_aggr
	layer_5_ep7_gate [label="MoE Gate\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_5_ep7_expert_0 [label="Expert-0\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep7_gate -> layer_5_ep7_expert_0 [label="select tokens" style=dashed]
	layer_5_ep7_expert_1 [label="Expert-1\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep7_gate -> layer_5_ep7_expert_1 [label="select tokens" style=dashed]
	layer_5_ep7_expert_2 [label="Expert-2\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep7_gate -> layer_5_ep7_expert_2 [label="select tokens" style=dashed]
	layer_5_ep7_expert_3 [label="Expert-3\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep7_gate -> layer_5_ep7_expert_3 [label="select tokens" style=dashed]
	layer_5_ep7_expert_aggr [label="Expert Aggregation\nEP-Group-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_5_ep7_expert_0 -> layer_5_ep7_expert_aggr
	layer_5_ep7_expert_1 -> layer_5_ep7_expert_aggr
	layer_5_ep7_expert_2 -> layer_5_ep7_expert_aggr
	layer_5_ep7_expert_3 -> layer_5_ep7_expert_aggr
	layer_5_ep8_gate [label="MoE Gate\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_5_ep8_expert_0 [label="Expert-0\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep8_gate -> layer_5_ep8_expert_0 [label="select tokens" style=dashed]
	layer_5_ep8_expert_1 [label="Expert-1\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep8_gate -> layer_5_ep8_expert_1 [label="select tokens" style=dashed]
	layer_5_ep8_expert_2 [label="Expert-2\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep8_gate -> layer_5_ep8_expert_2 [label="select tokens" style=dashed]
	layer_5_ep8_expert_3 [label="Expert-3\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep8_gate -> layer_5_ep8_expert_3 [label="select tokens" style=dashed]
	layer_5_ep8_expert_aggr [label="Expert Aggregation\nEP-Group-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_5_ep8_expert_0 -> layer_5_ep8_expert_aggr
	layer_5_ep8_expert_1 -> layer_5_ep8_expert_aggr
	layer_5_ep8_expert_2 -> layer_5_ep8_expert_aggr
	layer_5_ep8_expert_3 -> layer_5_ep8_expert_aggr
	layer_5_ep9_gate [label="MoE Gate\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_5_ep9_expert_0 [label="Expert-0\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep9_gate -> layer_5_ep9_expert_0 [label="select tokens" style=dashed]
	layer_5_ep9_expert_1 [label="Expert-1\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep9_gate -> layer_5_ep9_expert_1 [label="select tokens" style=dashed]
	layer_5_ep9_expert_2 [label="Expert-2\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep9_gate -> layer_5_ep9_expert_2 [label="select tokens" style=dashed]
	layer_5_ep9_expert_3 [label="Expert-3\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep9_gate -> layer_5_ep9_expert_3 [label="select tokens" style=dashed]
	layer_5_ep9_expert_aggr [label="Expert Aggregation\nEP-Group-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_5_ep9_expert_0 -> layer_5_ep9_expert_aggr
	layer_5_ep9_expert_1 -> layer_5_ep9_expert_aggr
	layer_5_ep9_expert_2 -> layer_5_ep9_expert_aggr
	layer_5_ep9_expert_3 -> layer_5_ep9_expert_aggr
	layer_5_ep10_gate [label="MoE Gate\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_5_ep10_expert_0 [label="Expert-0\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep10_gate -> layer_5_ep10_expert_0 [label="select tokens" style=dashed]
	layer_5_ep10_expert_1 [label="Expert-1\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep10_gate -> layer_5_ep10_expert_1 [label="select tokens" style=dashed]
	layer_5_ep10_expert_2 [label="Expert-2\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep10_gate -> layer_5_ep10_expert_2 [label="select tokens" style=dashed]
	layer_5_ep10_expert_3 [label="Expert-3\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep10_gate -> layer_5_ep10_expert_3 [label="select tokens" style=dashed]
	layer_5_ep10_expert_aggr [label="Expert Aggregation\nEP-Group-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_5_ep10_expert_0 -> layer_5_ep10_expert_aggr
	layer_5_ep10_expert_1 -> layer_5_ep10_expert_aggr
	layer_5_ep10_expert_2 -> layer_5_ep10_expert_aggr
	layer_5_ep10_expert_3 -> layer_5_ep10_expert_aggr
	layer_5_ep11_gate [label="MoE Gate\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_5_ep11_expert_0 [label="Expert-0\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep11_gate -> layer_5_ep11_expert_0 [label="select tokens" style=dashed]
	layer_5_ep11_expert_1 [label="Expert-1\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep11_gate -> layer_5_ep11_expert_1 [label="select tokens" style=dashed]
	layer_5_ep11_expert_2 [label="Expert-2\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep11_gate -> layer_5_ep11_expert_2 [label="select tokens" style=dashed]
	layer_5_ep11_expert_3 [label="Expert-3\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep11_gate -> layer_5_ep11_expert_3 [label="select tokens" style=dashed]
	layer_5_ep11_expert_aggr [label="Expert Aggregation\nEP-Group-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_5_ep11_expert_0 -> layer_5_ep11_expert_aggr
	layer_5_ep11_expert_1 -> layer_5_ep11_expert_aggr
	layer_5_ep11_expert_2 -> layer_5_ep11_expert_aggr
	layer_5_ep11_expert_3 -> layer_5_ep11_expert_aggr
	layer_5_ep12_gate [label="MoE Gate\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_5_ep12_expert_0 [label="Expert-0\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep12_gate -> layer_5_ep12_expert_0 [label="select tokens" style=dashed]
	layer_5_ep12_expert_1 [label="Expert-1\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep12_gate -> layer_5_ep12_expert_1 [label="select tokens" style=dashed]
	layer_5_ep12_expert_2 [label="Expert-2\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep12_gate -> layer_5_ep12_expert_2 [label="select tokens" style=dashed]
	layer_5_ep12_expert_3 [label="Expert-3\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep12_gate -> layer_5_ep12_expert_3 [label="select tokens" style=dashed]
	layer_5_ep12_expert_aggr [label="Expert Aggregation\nEP-Group-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_5_ep12_expert_0 -> layer_5_ep12_expert_aggr
	layer_5_ep12_expert_1 -> layer_5_ep12_expert_aggr
	layer_5_ep12_expert_2 -> layer_5_ep12_expert_aggr
	layer_5_ep12_expert_3 -> layer_5_ep12_expert_aggr
	layer_5_ep13_gate [label="MoE Gate\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_5_ep13_expert_0 [label="Expert-0\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep13_gate -> layer_5_ep13_expert_0 [label="select tokens" style=dashed]
	layer_5_ep13_expert_1 [label="Expert-1\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep13_gate -> layer_5_ep13_expert_1 [label="select tokens" style=dashed]
	layer_5_ep13_expert_2 [label="Expert-2\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep13_gate -> layer_5_ep13_expert_2 [label="select tokens" style=dashed]
	layer_5_ep13_expert_3 [label="Expert-3\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep13_gate -> layer_5_ep13_expert_3 [label="select tokens" style=dashed]
	layer_5_ep13_expert_aggr [label="Expert Aggregation\nEP-Group-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_5_ep13_expert_0 -> layer_5_ep13_expert_aggr
	layer_5_ep13_expert_1 -> layer_5_ep13_expert_aggr
	layer_5_ep13_expert_2 -> layer_5_ep13_expert_aggr
	layer_5_ep13_expert_3 -> layer_5_ep13_expert_aggr
	layer_5_ep14_gate [label="MoE Gate\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_5_ep14_expert_0 [label="Expert-0\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep14_gate -> layer_5_ep14_expert_0 [label="select tokens" style=dashed]
	layer_5_ep14_expert_1 [label="Expert-1\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep14_gate -> layer_5_ep14_expert_1 [label="select tokens" style=dashed]
	layer_5_ep14_expert_2 [label="Expert-2\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep14_gate -> layer_5_ep14_expert_2 [label="select tokens" style=dashed]
	layer_5_ep14_expert_3 [label="Expert-3\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep14_gate -> layer_5_ep14_expert_3 [label="select tokens" style=dashed]
	layer_5_ep14_expert_aggr [label="Expert Aggregation\nEP-Group-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_5_ep14_expert_0 -> layer_5_ep14_expert_aggr
	layer_5_ep14_expert_1 -> layer_5_ep14_expert_aggr
	layer_5_ep14_expert_2 -> layer_5_ep14_expert_aggr
	layer_5_ep14_expert_3 -> layer_5_ep14_expert_aggr
	layer_5_ep15_gate [label="MoE Gate\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_5_ep15_expert_0 [label="Expert-0\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep15_gate -> layer_5_ep15_expert_0 [label="select tokens" style=dashed]
	layer_5_ep15_expert_1 [label="Expert-1\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep15_gate -> layer_5_ep15_expert_1 [label="select tokens" style=dashed]
	layer_5_ep15_expert_2 [label="Expert-2\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep15_gate -> layer_5_ep15_expert_2 [label="select tokens" style=dashed]
	layer_5_ep15_expert_3 [label="Expert-3\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_5_ep15_gate -> layer_5_ep15_expert_3 [label="select tokens" style=dashed]
	layer_5_ep15_expert_aggr [label="Expert Aggregation\nEP-Group-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_5_ep15_expert_0 -> layer_5_ep15_expert_aggr
	layer_5_ep15_expert_1 -> layer_5_ep15_expert_aggr
	layer_5_ep15_expert_2 -> layer_5_ep15_expert_aggr
	layer_5_ep15_expert_3 -> layer_5_ep15_expert_aggr
	layer_5_to_6_ep0_pp [label="Pipeline Stage Transfer\nEP-Group-0\nLayer-5 to Layer-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_5_ep0_expert_aggr -> layer_5_to_6_ep0_pp
	layer_5_to_6_ep1_pp [label="Pipeline Stage Transfer\nEP-Group-1\nLayer-5 to Layer-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_5_ep1_expert_aggr -> layer_5_to_6_ep1_pp
	layer_5_to_6_ep2_pp [label="Pipeline Stage Transfer\nEP-Group-2\nLayer-5 to Layer-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_5_ep2_expert_aggr -> layer_5_to_6_ep2_pp
	layer_5_to_6_ep3_pp [label="Pipeline Stage Transfer\nEP-Group-3\nLayer-5 to Layer-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_5_ep3_expert_aggr -> layer_5_to_6_ep3_pp
	layer_5_to_6_ep4_pp [label="Pipeline Stage Transfer\nEP-Group-4\nLayer-5 to Layer-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_5_ep4_expert_aggr -> layer_5_to_6_ep4_pp
	layer_5_to_6_ep5_pp [label="Pipeline Stage Transfer\nEP-Group-5\nLayer-5 to Layer-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_5_ep5_expert_aggr -> layer_5_to_6_ep5_pp
	layer_5_to_6_ep6_pp [label="Pipeline Stage Transfer\nEP-Group-6\nLayer-5 to Layer-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_5_ep6_expert_aggr -> layer_5_to_6_ep6_pp
	layer_5_to_6_ep7_pp [label="Pipeline Stage Transfer\nEP-Group-7\nLayer-5 to Layer-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_5_ep7_expert_aggr -> layer_5_to_6_ep7_pp
	layer_5_to_6_ep8_pp [label="Pipeline Stage Transfer\nEP-Group-8\nLayer-5 to Layer-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_5_ep8_expert_aggr -> layer_5_to_6_ep8_pp
	layer_5_to_6_ep9_pp [label="Pipeline Stage Transfer\nEP-Group-9\nLayer-5 to Layer-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_5_ep9_expert_aggr -> layer_5_to_6_ep9_pp
	layer_5_to_6_ep10_pp [label="Pipeline Stage Transfer\nEP-Group-10\nLayer-5 to Layer-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_5_ep10_expert_aggr -> layer_5_to_6_ep10_pp
	layer_5_to_6_ep11_pp [label="Pipeline Stage Transfer\nEP-Group-11\nLayer-5 to Layer-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_5_ep11_expert_aggr -> layer_5_to_6_ep11_pp
	layer_5_to_6_ep12_pp [label="Pipeline Stage Transfer\nEP-Group-12\nLayer-5 to Layer-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_5_ep12_expert_aggr -> layer_5_to_6_ep12_pp
	layer_5_to_6_ep13_pp [label="Pipeline Stage Transfer\nEP-Group-13\nLayer-5 to Layer-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_5_ep13_expert_aggr -> layer_5_to_6_ep13_pp
	layer_5_to_6_ep14_pp [label="Pipeline Stage Transfer\nEP-Group-14\nLayer-5 to Layer-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_5_ep14_expert_aggr -> layer_5_to_6_ep14_pp
	layer_5_to_6_ep15_pp [label="Pipeline Stage Transfer\nEP-Group-15\nLayer-5 to Layer-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_5_ep15_expert_aggr -> layer_5_to_6_ep15_pp
	layer_6_ep0_tp0_sa_qkv [label="Self-Attn QKV\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep0_tp0_sa_attn [label="Self-Attn Compute\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep0_tp0_sa_out [label="Self-Attn Output\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep0_tp0_sa_qkv -> layer_6_ep0_tp0_sa_attn
	layer_6_ep0_tp0_sa_attn -> layer_6_ep0_tp0_sa_out
	layer_6_ep0_tp1_sa_qkv [label="Self-Attn QKV\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep0_tp1_sa_attn [label="Self-Attn Compute\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep0_tp1_sa_out [label="Self-Attn Output\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep0_tp1_sa_qkv -> layer_6_ep0_tp1_sa_attn
	layer_6_ep0_tp1_sa_attn -> layer_6_ep0_tp1_sa_out
	layer_6_ep0_tp2_sa_qkv [label="Self-Attn QKV\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep0_tp2_sa_attn [label="Self-Attn Compute\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep0_tp2_sa_out [label="Self-Attn Output\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep0_tp2_sa_qkv -> layer_6_ep0_tp2_sa_attn
	layer_6_ep0_tp2_sa_attn -> layer_6_ep0_tp2_sa_out
	layer_6_ep0_tp3_sa_qkv [label="Self-Attn QKV\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep0_tp3_sa_attn [label="Self-Attn Compute\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep0_tp3_sa_out [label="Self-Attn Output\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep0_tp3_sa_qkv -> layer_6_ep0_tp3_sa_attn
	layer_6_ep0_tp3_sa_attn -> layer_6_ep0_tp3_sa_out
	layer_6_ep1_tp0_sa_qkv [label="Self-Attn QKV\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep1_tp0_sa_attn [label="Self-Attn Compute\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep1_tp0_sa_out [label="Self-Attn Output\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep1_tp0_sa_qkv -> layer_6_ep1_tp0_sa_attn
	layer_6_ep1_tp0_sa_attn -> layer_6_ep1_tp0_sa_out
	layer_6_ep1_tp1_sa_qkv [label="Self-Attn QKV\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep1_tp1_sa_attn [label="Self-Attn Compute\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep1_tp1_sa_out [label="Self-Attn Output\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep1_tp1_sa_qkv -> layer_6_ep1_tp1_sa_attn
	layer_6_ep1_tp1_sa_attn -> layer_6_ep1_tp1_sa_out
	layer_6_ep1_tp2_sa_qkv [label="Self-Attn QKV\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep1_tp2_sa_attn [label="Self-Attn Compute\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep1_tp2_sa_out [label="Self-Attn Output\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep1_tp2_sa_qkv -> layer_6_ep1_tp2_sa_attn
	layer_6_ep1_tp2_sa_attn -> layer_6_ep1_tp2_sa_out
	layer_6_ep1_tp3_sa_qkv [label="Self-Attn QKV\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep1_tp3_sa_attn [label="Self-Attn Compute\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep1_tp3_sa_out [label="Self-Attn Output\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep1_tp3_sa_qkv -> layer_6_ep1_tp3_sa_attn
	layer_6_ep1_tp3_sa_attn -> layer_6_ep1_tp3_sa_out
	layer_6_ep2_tp0_sa_qkv [label="Self-Attn QKV\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep2_tp0_sa_attn [label="Self-Attn Compute\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep2_tp0_sa_out [label="Self-Attn Output\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep2_tp0_sa_qkv -> layer_6_ep2_tp0_sa_attn
	layer_6_ep2_tp0_sa_attn -> layer_6_ep2_tp0_sa_out
	layer_6_ep2_tp1_sa_qkv [label="Self-Attn QKV\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep2_tp1_sa_attn [label="Self-Attn Compute\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep2_tp1_sa_out [label="Self-Attn Output\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep2_tp1_sa_qkv -> layer_6_ep2_tp1_sa_attn
	layer_6_ep2_tp1_sa_attn -> layer_6_ep2_tp1_sa_out
	layer_6_ep2_tp2_sa_qkv [label="Self-Attn QKV\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep2_tp2_sa_attn [label="Self-Attn Compute\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep2_tp2_sa_out [label="Self-Attn Output\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep2_tp2_sa_qkv -> layer_6_ep2_tp2_sa_attn
	layer_6_ep2_tp2_sa_attn -> layer_6_ep2_tp2_sa_out
	layer_6_ep2_tp3_sa_qkv [label="Self-Attn QKV\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep2_tp3_sa_attn [label="Self-Attn Compute\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep2_tp3_sa_out [label="Self-Attn Output\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep2_tp3_sa_qkv -> layer_6_ep2_tp3_sa_attn
	layer_6_ep2_tp3_sa_attn -> layer_6_ep2_tp3_sa_out
	layer_6_ep3_tp0_sa_qkv [label="Self-Attn QKV\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep3_tp0_sa_attn [label="Self-Attn Compute\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep3_tp0_sa_out [label="Self-Attn Output\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep3_tp0_sa_qkv -> layer_6_ep3_tp0_sa_attn
	layer_6_ep3_tp0_sa_attn -> layer_6_ep3_tp0_sa_out
	layer_6_ep3_tp1_sa_qkv [label="Self-Attn QKV\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep3_tp1_sa_attn [label="Self-Attn Compute\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep3_tp1_sa_out [label="Self-Attn Output\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep3_tp1_sa_qkv -> layer_6_ep3_tp1_sa_attn
	layer_6_ep3_tp1_sa_attn -> layer_6_ep3_tp1_sa_out
	layer_6_ep3_tp2_sa_qkv [label="Self-Attn QKV\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep3_tp2_sa_attn [label="Self-Attn Compute\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep3_tp2_sa_out [label="Self-Attn Output\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep3_tp2_sa_qkv -> layer_6_ep3_tp2_sa_attn
	layer_6_ep3_tp2_sa_attn -> layer_6_ep3_tp2_sa_out
	layer_6_ep3_tp3_sa_qkv [label="Self-Attn QKV\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep3_tp3_sa_attn [label="Self-Attn Compute\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep3_tp3_sa_out [label="Self-Attn Output\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep3_tp3_sa_qkv -> layer_6_ep3_tp3_sa_attn
	layer_6_ep3_tp3_sa_attn -> layer_6_ep3_tp3_sa_out
	layer_6_ep4_tp0_sa_qkv [label="Self-Attn QKV\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep4_tp0_sa_attn [label="Self-Attn Compute\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep4_tp0_sa_out [label="Self-Attn Output\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep4_tp0_sa_qkv -> layer_6_ep4_tp0_sa_attn
	layer_6_ep4_tp0_sa_attn -> layer_6_ep4_tp0_sa_out
	layer_6_ep4_tp1_sa_qkv [label="Self-Attn QKV\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep4_tp1_sa_attn [label="Self-Attn Compute\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep4_tp1_sa_out [label="Self-Attn Output\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep4_tp1_sa_qkv -> layer_6_ep4_tp1_sa_attn
	layer_6_ep4_tp1_sa_attn -> layer_6_ep4_tp1_sa_out
	layer_6_ep4_tp2_sa_qkv [label="Self-Attn QKV\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep4_tp2_sa_attn [label="Self-Attn Compute\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep4_tp2_sa_out [label="Self-Attn Output\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep4_tp2_sa_qkv -> layer_6_ep4_tp2_sa_attn
	layer_6_ep4_tp2_sa_attn -> layer_6_ep4_tp2_sa_out
	layer_6_ep4_tp3_sa_qkv [label="Self-Attn QKV\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep4_tp3_sa_attn [label="Self-Attn Compute\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep4_tp3_sa_out [label="Self-Attn Output\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep4_tp3_sa_qkv -> layer_6_ep4_tp3_sa_attn
	layer_6_ep4_tp3_sa_attn -> layer_6_ep4_tp3_sa_out
	layer_6_ep5_tp0_sa_qkv [label="Self-Attn QKV\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep5_tp0_sa_attn [label="Self-Attn Compute\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep5_tp0_sa_out [label="Self-Attn Output\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep5_tp0_sa_qkv -> layer_6_ep5_tp0_sa_attn
	layer_6_ep5_tp0_sa_attn -> layer_6_ep5_tp0_sa_out
	layer_6_ep5_tp1_sa_qkv [label="Self-Attn QKV\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep5_tp1_sa_attn [label="Self-Attn Compute\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep5_tp1_sa_out [label="Self-Attn Output\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep5_tp1_sa_qkv -> layer_6_ep5_tp1_sa_attn
	layer_6_ep5_tp1_sa_attn -> layer_6_ep5_tp1_sa_out
	layer_6_ep5_tp2_sa_qkv [label="Self-Attn QKV\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep5_tp2_sa_attn [label="Self-Attn Compute\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep5_tp2_sa_out [label="Self-Attn Output\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep5_tp2_sa_qkv -> layer_6_ep5_tp2_sa_attn
	layer_6_ep5_tp2_sa_attn -> layer_6_ep5_tp2_sa_out
	layer_6_ep5_tp3_sa_qkv [label="Self-Attn QKV\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep5_tp3_sa_attn [label="Self-Attn Compute\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep5_tp3_sa_out [label="Self-Attn Output\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep5_tp3_sa_qkv -> layer_6_ep5_tp3_sa_attn
	layer_6_ep5_tp3_sa_attn -> layer_6_ep5_tp3_sa_out
	layer_6_ep6_tp0_sa_qkv [label="Self-Attn QKV\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep6_tp0_sa_attn [label="Self-Attn Compute\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep6_tp0_sa_out [label="Self-Attn Output\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep6_tp0_sa_qkv -> layer_6_ep6_tp0_sa_attn
	layer_6_ep6_tp0_sa_attn -> layer_6_ep6_tp0_sa_out
	layer_6_ep6_tp1_sa_qkv [label="Self-Attn QKV\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep6_tp1_sa_attn [label="Self-Attn Compute\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep6_tp1_sa_out [label="Self-Attn Output\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep6_tp1_sa_qkv -> layer_6_ep6_tp1_sa_attn
	layer_6_ep6_tp1_sa_attn -> layer_6_ep6_tp1_sa_out
	layer_6_ep6_tp2_sa_qkv [label="Self-Attn QKV\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep6_tp2_sa_attn [label="Self-Attn Compute\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep6_tp2_sa_out [label="Self-Attn Output\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep6_tp2_sa_qkv -> layer_6_ep6_tp2_sa_attn
	layer_6_ep6_tp2_sa_attn -> layer_6_ep6_tp2_sa_out
	layer_6_ep6_tp3_sa_qkv [label="Self-Attn QKV\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep6_tp3_sa_attn [label="Self-Attn Compute\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep6_tp3_sa_out [label="Self-Attn Output\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep6_tp3_sa_qkv -> layer_6_ep6_tp3_sa_attn
	layer_6_ep6_tp3_sa_attn -> layer_6_ep6_tp3_sa_out
	layer_6_ep7_tp0_sa_qkv [label="Self-Attn QKV\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep7_tp0_sa_attn [label="Self-Attn Compute\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep7_tp0_sa_out [label="Self-Attn Output\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep7_tp0_sa_qkv -> layer_6_ep7_tp0_sa_attn
	layer_6_ep7_tp0_sa_attn -> layer_6_ep7_tp0_sa_out
	layer_6_ep7_tp1_sa_qkv [label="Self-Attn QKV\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep7_tp1_sa_attn [label="Self-Attn Compute\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep7_tp1_sa_out [label="Self-Attn Output\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep7_tp1_sa_qkv -> layer_6_ep7_tp1_sa_attn
	layer_6_ep7_tp1_sa_attn -> layer_6_ep7_tp1_sa_out
	layer_6_ep7_tp2_sa_qkv [label="Self-Attn QKV\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep7_tp2_sa_attn [label="Self-Attn Compute\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep7_tp2_sa_out [label="Self-Attn Output\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep7_tp2_sa_qkv -> layer_6_ep7_tp2_sa_attn
	layer_6_ep7_tp2_sa_attn -> layer_6_ep7_tp2_sa_out
	layer_6_ep7_tp3_sa_qkv [label="Self-Attn QKV\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep7_tp3_sa_attn [label="Self-Attn Compute\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep7_tp3_sa_out [label="Self-Attn Output\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep7_tp3_sa_qkv -> layer_6_ep7_tp3_sa_attn
	layer_6_ep7_tp3_sa_attn -> layer_6_ep7_tp3_sa_out
	layer_6_ep8_tp0_sa_qkv [label="Self-Attn QKV\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep8_tp0_sa_attn [label="Self-Attn Compute\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep8_tp0_sa_out [label="Self-Attn Output\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep8_tp0_sa_qkv -> layer_6_ep8_tp0_sa_attn
	layer_6_ep8_tp0_sa_attn -> layer_6_ep8_tp0_sa_out
	layer_6_ep8_tp1_sa_qkv [label="Self-Attn QKV\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep8_tp1_sa_attn [label="Self-Attn Compute\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep8_tp1_sa_out [label="Self-Attn Output\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep8_tp1_sa_qkv -> layer_6_ep8_tp1_sa_attn
	layer_6_ep8_tp1_sa_attn -> layer_6_ep8_tp1_sa_out
	layer_6_ep8_tp2_sa_qkv [label="Self-Attn QKV\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep8_tp2_sa_attn [label="Self-Attn Compute\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep8_tp2_sa_out [label="Self-Attn Output\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep8_tp2_sa_qkv -> layer_6_ep8_tp2_sa_attn
	layer_6_ep8_tp2_sa_attn -> layer_6_ep8_tp2_sa_out
	layer_6_ep8_tp3_sa_qkv [label="Self-Attn QKV\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep8_tp3_sa_attn [label="Self-Attn Compute\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep8_tp3_sa_out [label="Self-Attn Output\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep8_tp3_sa_qkv -> layer_6_ep8_tp3_sa_attn
	layer_6_ep8_tp3_sa_attn -> layer_6_ep8_tp3_sa_out
	layer_6_ep9_tp0_sa_qkv [label="Self-Attn QKV\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep9_tp0_sa_attn [label="Self-Attn Compute\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep9_tp0_sa_out [label="Self-Attn Output\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep9_tp0_sa_qkv -> layer_6_ep9_tp0_sa_attn
	layer_6_ep9_tp0_sa_attn -> layer_6_ep9_tp0_sa_out
	layer_6_ep9_tp1_sa_qkv [label="Self-Attn QKV\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep9_tp1_sa_attn [label="Self-Attn Compute\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep9_tp1_sa_out [label="Self-Attn Output\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep9_tp1_sa_qkv -> layer_6_ep9_tp1_sa_attn
	layer_6_ep9_tp1_sa_attn -> layer_6_ep9_tp1_sa_out
	layer_6_ep9_tp2_sa_qkv [label="Self-Attn QKV\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep9_tp2_sa_attn [label="Self-Attn Compute\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep9_tp2_sa_out [label="Self-Attn Output\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep9_tp2_sa_qkv -> layer_6_ep9_tp2_sa_attn
	layer_6_ep9_tp2_sa_attn -> layer_6_ep9_tp2_sa_out
	layer_6_ep9_tp3_sa_qkv [label="Self-Attn QKV\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep9_tp3_sa_attn [label="Self-Attn Compute\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep9_tp3_sa_out [label="Self-Attn Output\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep9_tp3_sa_qkv -> layer_6_ep9_tp3_sa_attn
	layer_6_ep9_tp3_sa_attn -> layer_6_ep9_tp3_sa_out
	layer_6_ep10_tp0_sa_qkv [label="Self-Attn QKV\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep10_tp0_sa_attn [label="Self-Attn Compute\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep10_tp0_sa_out [label="Self-Attn Output\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep10_tp0_sa_qkv -> layer_6_ep10_tp0_sa_attn
	layer_6_ep10_tp0_sa_attn -> layer_6_ep10_tp0_sa_out
	layer_6_ep10_tp1_sa_qkv [label="Self-Attn QKV\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep10_tp1_sa_attn [label="Self-Attn Compute\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep10_tp1_sa_out [label="Self-Attn Output\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep10_tp1_sa_qkv -> layer_6_ep10_tp1_sa_attn
	layer_6_ep10_tp1_sa_attn -> layer_6_ep10_tp1_sa_out
	layer_6_ep10_tp2_sa_qkv [label="Self-Attn QKV\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep10_tp2_sa_attn [label="Self-Attn Compute\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep10_tp2_sa_out [label="Self-Attn Output\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep10_tp2_sa_qkv -> layer_6_ep10_tp2_sa_attn
	layer_6_ep10_tp2_sa_attn -> layer_6_ep10_tp2_sa_out
	layer_6_ep10_tp3_sa_qkv [label="Self-Attn QKV\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep10_tp3_sa_attn [label="Self-Attn Compute\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep10_tp3_sa_out [label="Self-Attn Output\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep10_tp3_sa_qkv -> layer_6_ep10_tp3_sa_attn
	layer_6_ep10_tp3_sa_attn -> layer_6_ep10_tp3_sa_out
	layer_6_ep11_tp0_sa_qkv [label="Self-Attn QKV\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep11_tp0_sa_attn [label="Self-Attn Compute\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep11_tp0_sa_out [label="Self-Attn Output\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep11_tp0_sa_qkv -> layer_6_ep11_tp0_sa_attn
	layer_6_ep11_tp0_sa_attn -> layer_6_ep11_tp0_sa_out
	layer_6_ep11_tp1_sa_qkv [label="Self-Attn QKV\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep11_tp1_sa_attn [label="Self-Attn Compute\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep11_tp1_sa_out [label="Self-Attn Output\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep11_tp1_sa_qkv -> layer_6_ep11_tp1_sa_attn
	layer_6_ep11_tp1_sa_attn -> layer_6_ep11_tp1_sa_out
	layer_6_ep11_tp2_sa_qkv [label="Self-Attn QKV\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep11_tp2_sa_attn [label="Self-Attn Compute\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep11_tp2_sa_out [label="Self-Attn Output\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep11_tp2_sa_qkv -> layer_6_ep11_tp2_sa_attn
	layer_6_ep11_tp2_sa_attn -> layer_6_ep11_tp2_sa_out
	layer_6_ep11_tp3_sa_qkv [label="Self-Attn QKV\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep11_tp3_sa_attn [label="Self-Attn Compute\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep11_tp3_sa_out [label="Self-Attn Output\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep11_tp3_sa_qkv -> layer_6_ep11_tp3_sa_attn
	layer_6_ep11_tp3_sa_attn -> layer_6_ep11_tp3_sa_out
	layer_6_ep12_tp0_sa_qkv [label="Self-Attn QKV\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep12_tp0_sa_attn [label="Self-Attn Compute\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep12_tp0_sa_out [label="Self-Attn Output\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep12_tp0_sa_qkv -> layer_6_ep12_tp0_sa_attn
	layer_6_ep12_tp0_sa_attn -> layer_6_ep12_tp0_sa_out
	layer_6_ep12_tp1_sa_qkv [label="Self-Attn QKV\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep12_tp1_sa_attn [label="Self-Attn Compute\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep12_tp1_sa_out [label="Self-Attn Output\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep12_tp1_sa_qkv -> layer_6_ep12_tp1_sa_attn
	layer_6_ep12_tp1_sa_attn -> layer_6_ep12_tp1_sa_out
	layer_6_ep12_tp2_sa_qkv [label="Self-Attn QKV\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep12_tp2_sa_attn [label="Self-Attn Compute\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep12_tp2_sa_out [label="Self-Attn Output\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep12_tp2_sa_qkv -> layer_6_ep12_tp2_sa_attn
	layer_6_ep12_tp2_sa_attn -> layer_6_ep12_tp2_sa_out
	layer_6_ep12_tp3_sa_qkv [label="Self-Attn QKV\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep12_tp3_sa_attn [label="Self-Attn Compute\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep12_tp3_sa_out [label="Self-Attn Output\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep12_tp3_sa_qkv -> layer_6_ep12_tp3_sa_attn
	layer_6_ep12_tp3_sa_attn -> layer_6_ep12_tp3_sa_out
	layer_6_ep13_tp0_sa_qkv [label="Self-Attn QKV\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep13_tp0_sa_attn [label="Self-Attn Compute\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep13_tp0_sa_out [label="Self-Attn Output\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep13_tp0_sa_qkv -> layer_6_ep13_tp0_sa_attn
	layer_6_ep13_tp0_sa_attn -> layer_6_ep13_tp0_sa_out
	layer_6_ep13_tp1_sa_qkv [label="Self-Attn QKV\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep13_tp1_sa_attn [label="Self-Attn Compute\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep13_tp1_sa_out [label="Self-Attn Output\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep13_tp1_sa_qkv -> layer_6_ep13_tp1_sa_attn
	layer_6_ep13_tp1_sa_attn -> layer_6_ep13_tp1_sa_out
	layer_6_ep13_tp2_sa_qkv [label="Self-Attn QKV\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep13_tp2_sa_attn [label="Self-Attn Compute\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep13_tp2_sa_out [label="Self-Attn Output\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep13_tp2_sa_qkv -> layer_6_ep13_tp2_sa_attn
	layer_6_ep13_tp2_sa_attn -> layer_6_ep13_tp2_sa_out
	layer_6_ep13_tp3_sa_qkv [label="Self-Attn QKV\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep13_tp3_sa_attn [label="Self-Attn Compute\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep13_tp3_sa_out [label="Self-Attn Output\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep13_tp3_sa_qkv -> layer_6_ep13_tp3_sa_attn
	layer_6_ep13_tp3_sa_attn -> layer_6_ep13_tp3_sa_out
	layer_6_ep14_tp0_sa_qkv [label="Self-Attn QKV\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep14_tp0_sa_attn [label="Self-Attn Compute\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep14_tp0_sa_out [label="Self-Attn Output\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep14_tp0_sa_qkv -> layer_6_ep14_tp0_sa_attn
	layer_6_ep14_tp0_sa_attn -> layer_6_ep14_tp0_sa_out
	layer_6_ep14_tp1_sa_qkv [label="Self-Attn QKV\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep14_tp1_sa_attn [label="Self-Attn Compute\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep14_tp1_sa_out [label="Self-Attn Output\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep14_tp1_sa_qkv -> layer_6_ep14_tp1_sa_attn
	layer_6_ep14_tp1_sa_attn -> layer_6_ep14_tp1_sa_out
	layer_6_ep14_tp2_sa_qkv [label="Self-Attn QKV\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep14_tp2_sa_attn [label="Self-Attn Compute\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep14_tp2_sa_out [label="Self-Attn Output\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep14_tp2_sa_qkv -> layer_6_ep14_tp2_sa_attn
	layer_6_ep14_tp2_sa_attn -> layer_6_ep14_tp2_sa_out
	layer_6_ep14_tp3_sa_qkv [label="Self-Attn QKV\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep14_tp3_sa_attn [label="Self-Attn Compute\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep14_tp3_sa_out [label="Self-Attn Output\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep14_tp3_sa_qkv -> layer_6_ep14_tp3_sa_attn
	layer_6_ep14_tp3_sa_attn -> layer_6_ep14_tp3_sa_out
	layer_6_ep15_tp0_sa_qkv [label="Self-Attn QKV\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep15_tp0_sa_attn [label="Self-Attn Compute\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep15_tp0_sa_out [label="Self-Attn Output\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep15_tp0_sa_qkv -> layer_6_ep15_tp0_sa_attn
	layer_6_ep15_tp0_sa_attn -> layer_6_ep15_tp0_sa_out
	layer_6_ep15_tp1_sa_qkv [label="Self-Attn QKV\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep15_tp1_sa_attn [label="Self-Attn Compute\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep15_tp1_sa_out [label="Self-Attn Output\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep15_tp1_sa_qkv -> layer_6_ep15_tp1_sa_attn
	layer_6_ep15_tp1_sa_attn -> layer_6_ep15_tp1_sa_out
	layer_6_ep15_tp2_sa_qkv [label="Self-Attn QKV\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep15_tp2_sa_attn [label="Self-Attn Compute\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep15_tp2_sa_out [label="Self-Attn Output\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep15_tp2_sa_qkv -> layer_6_ep15_tp2_sa_attn
	layer_6_ep15_tp2_sa_attn -> layer_6_ep15_tp2_sa_out
	layer_6_ep15_tp3_sa_qkv [label="Self-Attn QKV\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep15_tp3_sa_attn [label="Self-Attn Compute\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep15_tp3_sa_out [label="Self-Attn Output\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep15_tp3_sa_qkv -> layer_6_ep15_tp3_sa_attn
	layer_6_ep15_tp3_sa_attn -> layer_6_ep15_tp3_sa_out
	layer_6_ep0_tp_allreduce [label="TP All-Reduce\nEP-Group-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_6_ep0_tp0_sa_out -> layer_6_ep0_tp_allreduce
	layer_6_ep0_tp1_sa_out -> layer_6_ep0_tp_allreduce
	layer_6_ep0_tp2_sa_out -> layer_6_ep0_tp_allreduce
	layer_6_ep0_tp3_sa_out -> layer_6_ep0_tp_allreduce
	layer_6_ep1_tp_allreduce [label="TP All-Reduce\nEP-Group-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_6_ep1_tp0_sa_out -> layer_6_ep1_tp_allreduce
	layer_6_ep1_tp1_sa_out -> layer_6_ep1_tp_allreduce
	layer_6_ep1_tp2_sa_out -> layer_6_ep1_tp_allreduce
	layer_6_ep1_tp3_sa_out -> layer_6_ep1_tp_allreduce
	layer_6_ep2_tp_allreduce [label="TP All-Reduce\nEP-Group-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_6_ep2_tp0_sa_out -> layer_6_ep2_tp_allreduce
	layer_6_ep2_tp1_sa_out -> layer_6_ep2_tp_allreduce
	layer_6_ep2_tp2_sa_out -> layer_6_ep2_tp_allreduce
	layer_6_ep2_tp3_sa_out -> layer_6_ep2_tp_allreduce
	layer_6_ep3_tp_allreduce [label="TP All-Reduce\nEP-Group-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_6_ep3_tp0_sa_out -> layer_6_ep3_tp_allreduce
	layer_6_ep3_tp1_sa_out -> layer_6_ep3_tp_allreduce
	layer_6_ep3_tp2_sa_out -> layer_6_ep3_tp_allreduce
	layer_6_ep3_tp3_sa_out -> layer_6_ep3_tp_allreduce
	layer_6_ep4_tp_allreduce [label="TP All-Reduce\nEP-Group-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_6_ep4_tp0_sa_out -> layer_6_ep4_tp_allreduce
	layer_6_ep4_tp1_sa_out -> layer_6_ep4_tp_allreduce
	layer_6_ep4_tp2_sa_out -> layer_6_ep4_tp_allreduce
	layer_6_ep4_tp3_sa_out -> layer_6_ep4_tp_allreduce
	layer_6_ep5_tp_allreduce [label="TP All-Reduce\nEP-Group-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_6_ep5_tp0_sa_out -> layer_6_ep5_tp_allreduce
	layer_6_ep5_tp1_sa_out -> layer_6_ep5_tp_allreduce
	layer_6_ep5_tp2_sa_out -> layer_6_ep5_tp_allreduce
	layer_6_ep5_tp3_sa_out -> layer_6_ep5_tp_allreduce
	layer_6_ep6_tp_allreduce [label="TP All-Reduce\nEP-Group-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_6_ep6_tp0_sa_out -> layer_6_ep6_tp_allreduce
	layer_6_ep6_tp1_sa_out -> layer_6_ep6_tp_allreduce
	layer_6_ep6_tp2_sa_out -> layer_6_ep6_tp_allreduce
	layer_6_ep6_tp3_sa_out -> layer_6_ep6_tp_allreduce
	layer_6_ep7_tp_allreduce [label="TP All-Reduce\nEP-Group-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_6_ep7_tp0_sa_out -> layer_6_ep7_tp_allreduce
	layer_6_ep7_tp1_sa_out -> layer_6_ep7_tp_allreduce
	layer_6_ep7_tp2_sa_out -> layer_6_ep7_tp_allreduce
	layer_6_ep7_tp3_sa_out -> layer_6_ep7_tp_allreduce
	layer_6_ep8_tp_allreduce [label="TP All-Reduce\nEP-Group-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_6_ep8_tp0_sa_out -> layer_6_ep8_tp_allreduce
	layer_6_ep8_tp1_sa_out -> layer_6_ep8_tp_allreduce
	layer_6_ep8_tp2_sa_out -> layer_6_ep8_tp_allreduce
	layer_6_ep8_tp3_sa_out -> layer_6_ep8_tp_allreduce
	layer_6_ep9_tp_allreduce [label="TP All-Reduce\nEP-Group-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_6_ep9_tp0_sa_out -> layer_6_ep9_tp_allreduce
	layer_6_ep9_tp1_sa_out -> layer_6_ep9_tp_allreduce
	layer_6_ep9_tp2_sa_out -> layer_6_ep9_tp_allreduce
	layer_6_ep9_tp3_sa_out -> layer_6_ep9_tp_allreduce
	layer_6_ep10_tp_allreduce [label="TP All-Reduce\nEP-Group-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_6_ep10_tp0_sa_out -> layer_6_ep10_tp_allreduce
	layer_6_ep10_tp1_sa_out -> layer_6_ep10_tp_allreduce
	layer_6_ep10_tp2_sa_out -> layer_6_ep10_tp_allreduce
	layer_6_ep10_tp3_sa_out -> layer_6_ep10_tp_allreduce
	layer_6_ep11_tp_allreduce [label="TP All-Reduce\nEP-Group-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_6_ep11_tp0_sa_out -> layer_6_ep11_tp_allreduce
	layer_6_ep11_tp1_sa_out -> layer_6_ep11_tp_allreduce
	layer_6_ep11_tp2_sa_out -> layer_6_ep11_tp_allreduce
	layer_6_ep11_tp3_sa_out -> layer_6_ep11_tp_allreduce
	layer_6_ep12_tp_allreduce [label="TP All-Reduce\nEP-Group-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_6_ep12_tp0_sa_out -> layer_6_ep12_tp_allreduce
	layer_6_ep12_tp1_sa_out -> layer_6_ep12_tp_allreduce
	layer_6_ep12_tp2_sa_out -> layer_6_ep12_tp_allreduce
	layer_6_ep12_tp3_sa_out -> layer_6_ep12_tp_allreduce
	layer_6_ep13_tp_allreduce [label="TP All-Reduce\nEP-Group-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_6_ep13_tp0_sa_out -> layer_6_ep13_tp_allreduce
	layer_6_ep13_tp1_sa_out -> layer_6_ep13_tp_allreduce
	layer_6_ep13_tp2_sa_out -> layer_6_ep13_tp_allreduce
	layer_6_ep13_tp3_sa_out -> layer_6_ep13_tp_allreduce
	layer_6_ep14_tp_allreduce [label="TP All-Reduce\nEP-Group-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_6_ep14_tp0_sa_out -> layer_6_ep14_tp_allreduce
	layer_6_ep14_tp1_sa_out -> layer_6_ep14_tp_allreduce
	layer_6_ep14_tp2_sa_out -> layer_6_ep14_tp_allreduce
	layer_6_ep14_tp3_sa_out -> layer_6_ep14_tp_allreduce
	layer_6_ep15_tp_allreduce [label="TP All-Reduce\nEP-Group-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_6_ep15_tp0_sa_out -> layer_6_ep15_tp_allreduce
	layer_6_ep15_tp1_sa_out -> layer_6_ep15_tp_allreduce
	layer_6_ep15_tp2_sa_out -> layer_6_ep15_tp_allreduce
	layer_6_ep15_tp3_sa_out -> layer_6_ep15_tp_allreduce
	layer_6_ep0_gate [label="MoE Gate\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_6_ep0_expert_0 [label="Expert-0\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep0_gate -> layer_6_ep0_expert_0 [label="select tokens" style=dashed]
	layer_6_ep0_expert_1 [label="Expert-1\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep0_gate -> layer_6_ep0_expert_1 [label="select tokens" style=dashed]
	layer_6_ep0_expert_2 [label="Expert-2\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep0_gate -> layer_6_ep0_expert_2 [label="select tokens" style=dashed]
	layer_6_ep0_expert_3 [label="Expert-3\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep0_gate -> layer_6_ep0_expert_3 [label="select tokens" style=dashed]
	layer_6_ep0_expert_aggr [label="Expert Aggregation\nEP-Group-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_6_ep0_expert_0 -> layer_6_ep0_expert_aggr
	layer_6_ep0_expert_1 -> layer_6_ep0_expert_aggr
	layer_6_ep0_expert_2 -> layer_6_ep0_expert_aggr
	layer_6_ep0_expert_3 -> layer_6_ep0_expert_aggr
	layer_6_ep1_gate [label="MoE Gate\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_6_ep1_expert_0 [label="Expert-0\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep1_gate -> layer_6_ep1_expert_0 [label="select tokens" style=dashed]
	layer_6_ep1_expert_1 [label="Expert-1\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep1_gate -> layer_6_ep1_expert_1 [label="select tokens" style=dashed]
	layer_6_ep1_expert_2 [label="Expert-2\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep1_gate -> layer_6_ep1_expert_2 [label="select tokens" style=dashed]
	layer_6_ep1_expert_3 [label="Expert-3\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep1_gate -> layer_6_ep1_expert_3 [label="select tokens" style=dashed]
	layer_6_ep1_expert_aggr [label="Expert Aggregation\nEP-Group-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_6_ep1_expert_0 -> layer_6_ep1_expert_aggr
	layer_6_ep1_expert_1 -> layer_6_ep1_expert_aggr
	layer_6_ep1_expert_2 -> layer_6_ep1_expert_aggr
	layer_6_ep1_expert_3 -> layer_6_ep1_expert_aggr
	layer_6_ep2_gate [label="MoE Gate\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_6_ep2_expert_0 [label="Expert-0\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep2_gate -> layer_6_ep2_expert_0 [label="select tokens" style=dashed]
	layer_6_ep2_expert_1 [label="Expert-1\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep2_gate -> layer_6_ep2_expert_1 [label="select tokens" style=dashed]
	layer_6_ep2_expert_2 [label="Expert-2\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep2_gate -> layer_6_ep2_expert_2 [label="select tokens" style=dashed]
	layer_6_ep2_expert_3 [label="Expert-3\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep2_gate -> layer_6_ep2_expert_3 [label="select tokens" style=dashed]
	layer_6_ep2_expert_aggr [label="Expert Aggregation\nEP-Group-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_6_ep2_expert_0 -> layer_6_ep2_expert_aggr
	layer_6_ep2_expert_1 -> layer_6_ep2_expert_aggr
	layer_6_ep2_expert_2 -> layer_6_ep2_expert_aggr
	layer_6_ep2_expert_3 -> layer_6_ep2_expert_aggr
	layer_6_ep3_gate [label="MoE Gate\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_6_ep3_expert_0 [label="Expert-0\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep3_gate -> layer_6_ep3_expert_0 [label="select tokens" style=dashed]
	layer_6_ep3_expert_1 [label="Expert-1\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep3_gate -> layer_6_ep3_expert_1 [label="select tokens" style=dashed]
	layer_6_ep3_expert_2 [label="Expert-2\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep3_gate -> layer_6_ep3_expert_2 [label="select tokens" style=dashed]
	layer_6_ep3_expert_3 [label="Expert-3\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep3_gate -> layer_6_ep3_expert_3 [label="select tokens" style=dashed]
	layer_6_ep3_expert_aggr [label="Expert Aggregation\nEP-Group-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_6_ep3_expert_0 -> layer_6_ep3_expert_aggr
	layer_6_ep3_expert_1 -> layer_6_ep3_expert_aggr
	layer_6_ep3_expert_2 -> layer_6_ep3_expert_aggr
	layer_6_ep3_expert_3 -> layer_6_ep3_expert_aggr
	layer_6_ep4_gate [label="MoE Gate\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_6_ep4_expert_0 [label="Expert-0\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep4_gate -> layer_6_ep4_expert_0 [label="select tokens" style=dashed]
	layer_6_ep4_expert_1 [label="Expert-1\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep4_gate -> layer_6_ep4_expert_1 [label="select tokens" style=dashed]
	layer_6_ep4_expert_2 [label="Expert-2\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep4_gate -> layer_6_ep4_expert_2 [label="select tokens" style=dashed]
	layer_6_ep4_expert_3 [label="Expert-3\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep4_gate -> layer_6_ep4_expert_3 [label="select tokens" style=dashed]
	layer_6_ep4_expert_aggr [label="Expert Aggregation\nEP-Group-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_6_ep4_expert_0 -> layer_6_ep4_expert_aggr
	layer_6_ep4_expert_1 -> layer_6_ep4_expert_aggr
	layer_6_ep4_expert_2 -> layer_6_ep4_expert_aggr
	layer_6_ep4_expert_3 -> layer_6_ep4_expert_aggr
	layer_6_ep5_gate [label="MoE Gate\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_6_ep5_expert_0 [label="Expert-0\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep5_gate -> layer_6_ep5_expert_0 [label="select tokens" style=dashed]
	layer_6_ep5_expert_1 [label="Expert-1\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep5_gate -> layer_6_ep5_expert_1 [label="select tokens" style=dashed]
	layer_6_ep5_expert_2 [label="Expert-2\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep5_gate -> layer_6_ep5_expert_2 [label="select tokens" style=dashed]
	layer_6_ep5_expert_3 [label="Expert-3\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep5_gate -> layer_6_ep5_expert_3 [label="select tokens" style=dashed]
	layer_6_ep5_expert_aggr [label="Expert Aggregation\nEP-Group-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_6_ep5_expert_0 -> layer_6_ep5_expert_aggr
	layer_6_ep5_expert_1 -> layer_6_ep5_expert_aggr
	layer_6_ep5_expert_2 -> layer_6_ep5_expert_aggr
	layer_6_ep5_expert_3 -> layer_6_ep5_expert_aggr
	layer_6_ep6_gate [label="MoE Gate\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_6_ep6_expert_0 [label="Expert-0\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep6_gate -> layer_6_ep6_expert_0 [label="select tokens" style=dashed]
	layer_6_ep6_expert_1 [label="Expert-1\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep6_gate -> layer_6_ep6_expert_1 [label="select tokens" style=dashed]
	layer_6_ep6_expert_2 [label="Expert-2\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep6_gate -> layer_6_ep6_expert_2 [label="select tokens" style=dashed]
	layer_6_ep6_expert_3 [label="Expert-3\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep6_gate -> layer_6_ep6_expert_3 [label="select tokens" style=dashed]
	layer_6_ep6_expert_aggr [label="Expert Aggregation\nEP-Group-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_6_ep6_expert_0 -> layer_6_ep6_expert_aggr
	layer_6_ep6_expert_1 -> layer_6_ep6_expert_aggr
	layer_6_ep6_expert_2 -> layer_6_ep6_expert_aggr
	layer_6_ep6_expert_3 -> layer_6_ep6_expert_aggr
	layer_6_ep7_gate [label="MoE Gate\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_6_ep7_expert_0 [label="Expert-0\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep7_gate -> layer_6_ep7_expert_0 [label="select tokens" style=dashed]
	layer_6_ep7_expert_1 [label="Expert-1\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep7_gate -> layer_6_ep7_expert_1 [label="select tokens" style=dashed]
	layer_6_ep7_expert_2 [label="Expert-2\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep7_gate -> layer_6_ep7_expert_2 [label="select tokens" style=dashed]
	layer_6_ep7_expert_3 [label="Expert-3\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep7_gate -> layer_6_ep7_expert_3 [label="select tokens" style=dashed]
	layer_6_ep7_expert_aggr [label="Expert Aggregation\nEP-Group-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_6_ep7_expert_0 -> layer_6_ep7_expert_aggr
	layer_6_ep7_expert_1 -> layer_6_ep7_expert_aggr
	layer_6_ep7_expert_2 -> layer_6_ep7_expert_aggr
	layer_6_ep7_expert_3 -> layer_6_ep7_expert_aggr
	layer_6_ep8_gate [label="MoE Gate\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_6_ep8_expert_0 [label="Expert-0\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep8_gate -> layer_6_ep8_expert_0 [label="select tokens" style=dashed]
	layer_6_ep8_expert_1 [label="Expert-1\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep8_gate -> layer_6_ep8_expert_1 [label="select tokens" style=dashed]
	layer_6_ep8_expert_2 [label="Expert-2\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep8_gate -> layer_6_ep8_expert_2 [label="select tokens" style=dashed]
	layer_6_ep8_expert_3 [label="Expert-3\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep8_gate -> layer_6_ep8_expert_3 [label="select tokens" style=dashed]
	layer_6_ep8_expert_aggr [label="Expert Aggregation\nEP-Group-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_6_ep8_expert_0 -> layer_6_ep8_expert_aggr
	layer_6_ep8_expert_1 -> layer_6_ep8_expert_aggr
	layer_6_ep8_expert_2 -> layer_6_ep8_expert_aggr
	layer_6_ep8_expert_3 -> layer_6_ep8_expert_aggr
	layer_6_ep9_gate [label="MoE Gate\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_6_ep9_expert_0 [label="Expert-0\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep9_gate -> layer_6_ep9_expert_0 [label="select tokens" style=dashed]
	layer_6_ep9_expert_1 [label="Expert-1\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep9_gate -> layer_6_ep9_expert_1 [label="select tokens" style=dashed]
	layer_6_ep9_expert_2 [label="Expert-2\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep9_gate -> layer_6_ep9_expert_2 [label="select tokens" style=dashed]
	layer_6_ep9_expert_3 [label="Expert-3\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep9_gate -> layer_6_ep9_expert_3 [label="select tokens" style=dashed]
	layer_6_ep9_expert_aggr [label="Expert Aggregation\nEP-Group-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_6_ep9_expert_0 -> layer_6_ep9_expert_aggr
	layer_6_ep9_expert_1 -> layer_6_ep9_expert_aggr
	layer_6_ep9_expert_2 -> layer_6_ep9_expert_aggr
	layer_6_ep9_expert_3 -> layer_6_ep9_expert_aggr
	layer_6_ep10_gate [label="MoE Gate\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_6_ep10_expert_0 [label="Expert-0\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep10_gate -> layer_6_ep10_expert_0 [label="select tokens" style=dashed]
	layer_6_ep10_expert_1 [label="Expert-1\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep10_gate -> layer_6_ep10_expert_1 [label="select tokens" style=dashed]
	layer_6_ep10_expert_2 [label="Expert-2\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep10_gate -> layer_6_ep10_expert_2 [label="select tokens" style=dashed]
	layer_6_ep10_expert_3 [label="Expert-3\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep10_gate -> layer_6_ep10_expert_3 [label="select tokens" style=dashed]
	layer_6_ep10_expert_aggr [label="Expert Aggregation\nEP-Group-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_6_ep10_expert_0 -> layer_6_ep10_expert_aggr
	layer_6_ep10_expert_1 -> layer_6_ep10_expert_aggr
	layer_6_ep10_expert_2 -> layer_6_ep10_expert_aggr
	layer_6_ep10_expert_3 -> layer_6_ep10_expert_aggr
	layer_6_ep11_gate [label="MoE Gate\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_6_ep11_expert_0 [label="Expert-0\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep11_gate -> layer_6_ep11_expert_0 [label="select tokens" style=dashed]
	layer_6_ep11_expert_1 [label="Expert-1\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep11_gate -> layer_6_ep11_expert_1 [label="select tokens" style=dashed]
	layer_6_ep11_expert_2 [label="Expert-2\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep11_gate -> layer_6_ep11_expert_2 [label="select tokens" style=dashed]
	layer_6_ep11_expert_3 [label="Expert-3\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep11_gate -> layer_6_ep11_expert_3 [label="select tokens" style=dashed]
	layer_6_ep11_expert_aggr [label="Expert Aggregation\nEP-Group-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_6_ep11_expert_0 -> layer_6_ep11_expert_aggr
	layer_6_ep11_expert_1 -> layer_6_ep11_expert_aggr
	layer_6_ep11_expert_2 -> layer_6_ep11_expert_aggr
	layer_6_ep11_expert_3 -> layer_6_ep11_expert_aggr
	layer_6_ep12_gate [label="MoE Gate\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_6_ep12_expert_0 [label="Expert-0\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep12_gate -> layer_6_ep12_expert_0 [label="select tokens" style=dashed]
	layer_6_ep12_expert_1 [label="Expert-1\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep12_gate -> layer_6_ep12_expert_1 [label="select tokens" style=dashed]
	layer_6_ep12_expert_2 [label="Expert-2\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep12_gate -> layer_6_ep12_expert_2 [label="select tokens" style=dashed]
	layer_6_ep12_expert_3 [label="Expert-3\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep12_gate -> layer_6_ep12_expert_3 [label="select tokens" style=dashed]
	layer_6_ep12_expert_aggr [label="Expert Aggregation\nEP-Group-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_6_ep12_expert_0 -> layer_6_ep12_expert_aggr
	layer_6_ep12_expert_1 -> layer_6_ep12_expert_aggr
	layer_6_ep12_expert_2 -> layer_6_ep12_expert_aggr
	layer_6_ep12_expert_3 -> layer_6_ep12_expert_aggr
	layer_6_ep13_gate [label="MoE Gate\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_6_ep13_expert_0 [label="Expert-0\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep13_gate -> layer_6_ep13_expert_0 [label="select tokens" style=dashed]
	layer_6_ep13_expert_1 [label="Expert-1\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep13_gate -> layer_6_ep13_expert_1 [label="select tokens" style=dashed]
	layer_6_ep13_expert_2 [label="Expert-2\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep13_gate -> layer_6_ep13_expert_2 [label="select tokens" style=dashed]
	layer_6_ep13_expert_3 [label="Expert-3\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep13_gate -> layer_6_ep13_expert_3 [label="select tokens" style=dashed]
	layer_6_ep13_expert_aggr [label="Expert Aggregation\nEP-Group-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_6_ep13_expert_0 -> layer_6_ep13_expert_aggr
	layer_6_ep13_expert_1 -> layer_6_ep13_expert_aggr
	layer_6_ep13_expert_2 -> layer_6_ep13_expert_aggr
	layer_6_ep13_expert_3 -> layer_6_ep13_expert_aggr
	layer_6_ep14_gate [label="MoE Gate\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_6_ep14_expert_0 [label="Expert-0\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep14_gate -> layer_6_ep14_expert_0 [label="select tokens" style=dashed]
	layer_6_ep14_expert_1 [label="Expert-1\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep14_gate -> layer_6_ep14_expert_1 [label="select tokens" style=dashed]
	layer_6_ep14_expert_2 [label="Expert-2\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep14_gate -> layer_6_ep14_expert_2 [label="select tokens" style=dashed]
	layer_6_ep14_expert_3 [label="Expert-3\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep14_gate -> layer_6_ep14_expert_3 [label="select tokens" style=dashed]
	layer_6_ep14_expert_aggr [label="Expert Aggregation\nEP-Group-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_6_ep14_expert_0 -> layer_6_ep14_expert_aggr
	layer_6_ep14_expert_1 -> layer_6_ep14_expert_aggr
	layer_6_ep14_expert_2 -> layer_6_ep14_expert_aggr
	layer_6_ep14_expert_3 -> layer_6_ep14_expert_aggr
	layer_6_ep15_gate [label="MoE Gate\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_6_ep15_expert_0 [label="Expert-0\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep15_gate -> layer_6_ep15_expert_0 [label="select tokens" style=dashed]
	layer_6_ep15_expert_1 [label="Expert-1\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep15_gate -> layer_6_ep15_expert_1 [label="select tokens" style=dashed]
	layer_6_ep15_expert_2 [label="Expert-2\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep15_gate -> layer_6_ep15_expert_2 [label="select tokens" style=dashed]
	layer_6_ep15_expert_3 [label="Expert-3\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_6_ep15_gate -> layer_6_ep15_expert_3 [label="select tokens" style=dashed]
	layer_6_ep15_expert_aggr [label="Expert Aggregation\nEP-Group-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_6_ep15_expert_0 -> layer_6_ep15_expert_aggr
	layer_6_ep15_expert_1 -> layer_6_ep15_expert_aggr
	layer_6_ep15_expert_2 -> layer_6_ep15_expert_aggr
	layer_6_ep15_expert_3 -> layer_6_ep15_expert_aggr
	layer_6_to_7_ep0_pp [label="Pipeline Stage Transfer\nEP-Group-0\nLayer-6 to Layer-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_6_ep0_expert_aggr -> layer_6_to_7_ep0_pp
	layer_6_to_7_ep1_pp [label="Pipeline Stage Transfer\nEP-Group-1\nLayer-6 to Layer-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_6_ep1_expert_aggr -> layer_6_to_7_ep1_pp
	layer_6_to_7_ep2_pp [label="Pipeline Stage Transfer\nEP-Group-2\nLayer-6 to Layer-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_6_ep2_expert_aggr -> layer_6_to_7_ep2_pp
	layer_6_to_7_ep3_pp [label="Pipeline Stage Transfer\nEP-Group-3\nLayer-6 to Layer-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_6_ep3_expert_aggr -> layer_6_to_7_ep3_pp
	layer_6_to_7_ep4_pp [label="Pipeline Stage Transfer\nEP-Group-4\nLayer-6 to Layer-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_6_ep4_expert_aggr -> layer_6_to_7_ep4_pp
	layer_6_to_7_ep5_pp [label="Pipeline Stage Transfer\nEP-Group-5\nLayer-6 to Layer-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_6_ep5_expert_aggr -> layer_6_to_7_ep5_pp
	layer_6_to_7_ep6_pp [label="Pipeline Stage Transfer\nEP-Group-6\nLayer-6 to Layer-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_6_ep6_expert_aggr -> layer_6_to_7_ep6_pp
	layer_6_to_7_ep7_pp [label="Pipeline Stage Transfer\nEP-Group-7\nLayer-6 to Layer-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_6_ep7_expert_aggr -> layer_6_to_7_ep7_pp
	layer_6_to_7_ep8_pp [label="Pipeline Stage Transfer\nEP-Group-8\nLayer-6 to Layer-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_6_ep8_expert_aggr -> layer_6_to_7_ep8_pp
	layer_6_to_7_ep9_pp [label="Pipeline Stage Transfer\nEP-Group-9\nLayer-6 to Layer-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_6_ep9_expert_aggr -> layer_6_to_7_ep9_pp
	layer_6_to_7_ep10_pp [label="Pipeline Stage Transfer\nEP-Group-10\nLayer-6 to Layer-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_6_ep10_expert_aggr -> layer_6_to_7_ep10_pp
	layer_6_to_7_ep11_pp [label="Pipeline Stage Transfer\nEP-Group-11\nLayer-6 to Layer-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_6_ep11_expert_aggr -> layer_6_to_7_ep11_pp
	layer_6_to_7_ep12_pp [label="Pipeline Stage Transfer\nEP-Group-12\nLayer-6 to Layer-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_6_ep12_expert_aggr -> layer_6_to_7_ep12_pp
	layer_6_to_7_ep13_pp [label="Pipeline Stage Transfer\nEP-Group-13\nLayer-6 to Layer-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_6_ep13_expert_aggr -> layer_6_to_7_ep13_pp
	layer_6_to_7_ep14_pp [label="Pipeline Stage Transfer\nEP-Group-14\nLayer-6 to Layer-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_6_ep14_expert_aggr -> layer_6_to_7_ep14_pp
	layer_6_to_7_ep15_pp [label="Pipeline Stage Transfer\nEP-Group-15\nLayer-6 to Layer-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_6_ep15_expert_aggr -> layer_6_to_7_ep15_pp
	layer_7_ep0_tp0_sa_qkv [label="Self-Attn QKV\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep0_tp0_sa_attn [label="Self-Attn Compute\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep0_tp0_sa_out [label="Self-Attn Output\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep0_tp0_sa_qkv -> layer_7_ep0_tp0_sa_attn
	layer_7_ep0_tp0_sa_attn -> layer_7_ep0_tp0_sa_out
	layer_7_ep0_tp1_sa_qkv [label="Self-Attn QKV\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep0_tp1_sa_attn [label="Self-Attn Compute\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep0_tp1_sa_out [label="Self-Attn Output\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep0_tp1_sa_qkv -> layer_7_ep0_tp1_sa_attn
	layer_7_ep0_tp1_sa_attn -> layer_7_ep0_tp1_sa_out
	layer_7_ep0_tp2_sa_qkv [label="Self-Attn QKV\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep0_tp2_sa_attn [label="Self-Attn Compute\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep0_tp2_sa_out [label="Self-Attn Output\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep0_tp2_sa_qkv -> layer_7_ep0_tp2_sa_attn
	layer_7_ep0_tp2_sa_attn -> layer_7_ep0_tp2_sa_out
	layer_7_ep0_tp3_sa_qkv [label="Self-Attn QKV\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep0_tp3_sa_attn [label="Self-Attn Compute\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep0_tp3_sa_out [label="Self-Attn Output\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep0_tp3_sa_qkv -> layer_7_ep0_tp3_sa_attn
	layer_7_ep0_tp3_sa_attn -> layer_7_ep0_tp3_sa_out
	layer_7_ep1_tp0_sa_qkv [label="Self-Attn QKV\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep1_tp0_sa_attn [label="Self-Attn Compute\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep1_tp0_sa_out [label="Self-Attn Output\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep1_tp0_sa_qkv -> layer_7_ep1_tp0_sa_attn
	layer_7_ep1_tp0_sa_attn -> layer_7_ep1_tp0_sa_out
	layer_7_ep1_tp1_sa_qkv [label="Self-Attn QKV\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep1_tp1_sa_attn [label="Self-Attn Compute\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep1_tp1_sa_out [label="Self-Attn Output\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep1_tp1_sa_qkv -> layer_7_ep1_tp1_sa_attn
	layer_7_ep1_tp1_sa_attn -> layer_7_ep1_tp1_sa_out
	layer_7_ep1_tp2_sa_qkv [label="Self-Attn QKV\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep1_tp2_sa_attn [label="Self-Attn Compute\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep1_tp2_sa_out [label="Self-Attn Output\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep1_tp2_sa_qkv -> layer_7_ep1_tp2_sa_attn
	layer_7_ep1_tp2_sa_attn -> layer_7_ep1_tp2_sa_out
	layer_7_ep1_tp3_sa_qkv [label="Self-Attn QKV\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep1_tp3_sa_attn [label="Self-Attn Compute\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep1_tp3_sa_out [label="Self-Attn Output\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep1_tp3_sa_qkv -> layer_7_ep1_tp3_sa_attn
	layer_7_ep1_tp3_sa_attn -> layer_7_ep1_tp3_sa_out
	layer_7_ep2_tp0_sa_qkv [label="Self-Attn QKV\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep2_tp0_sa_attn [label="Self-Attn Compute\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep2_tp0_sa_out [label="Self-Attn Output\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep2_tp0_sa_qkv -> layer_7_ep2_tp0_sa_attn
	layer_7_ep2_tp0_sa_attn -> layer_7_ep2_tp0_sa_out
	layer_7_ep2_tp1_sa_qkv [label="Self-Attn QKV\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep2_tp1_sa_attn [label="Self-Attn Compute\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep2_tp1_sa_out [label="Self-Attn Output\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep2_tp1_sa_qkv -> layer_7_ep2_tp1_sa_attn
	layer_7_ep2_tp1_sa_attn -> layer_7_ep2_tp1_sa_out
	layer_7_ep2_tp2_sa_qkv [label="Self-Attn QKV\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep2_tp2_sa_attn [label="Self-Attn Compute\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep2_tp2_sa_out [label="Self-Attn Output\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep2_tp2_sa_qkv -> layer_7_ep2_tp2_sa_attn
	layer_7_ep2_tp2_sa_attn -> layer_7_ep2_tp2_sa_out
	layer_7_ep2_tp3_sa_qkv [label="Self-Attn QKV\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep2_tp3_sa_attn [label="Self-Attn Compute\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep2_tp3_sa_out [label="Self-Attn Output\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep2_tp3_sa_qkv -> layer_7_ep2_tp3_sa_attn
	layer_7_ep2_tp3_sa_attn -> layer_7_ep2_tp3_sa_out
	layer_7_ep3_tp0_sa_qkv [label="Self-Attn QKV\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep3_tp0_sa_attn [label="Self-Attn Compute\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep3_tp0_sa_out [label="Self-Attn Output\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep3_tp0_sa_qkv -> layer_7_ep3_tp0_sa_attn
	layer_7_ep3_tp0_sa_attn -> layer_7_ep3_tp0_sa_out
	layer_7_ep3_tp1_sa_qkv [label="Self-Attn QKV\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep3_tp1_sa_attn [label="Self-Attn Compute\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep3_tp1_sa_out [label="Self-Attn Output\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep3_tp1_sa_qkv -> layer_7_ep3_tp1_sa_attn
	layer_7_ep3_tp1_sa_attn -> layer_7_ep3_tp1_sa_out
	layer_7_ep3_tp2_sa_qkv [label="Self-Attn QKV\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep3_tp2_sa_attn [label="Self-Attn Compute\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep3_tp2_sa_out [label="Self-Attn Output\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep3_tp2_sa_qkv -> layer_7_ep3_tp2_sa_attn
	layer_7_ep3_tp2_sa_attn -> layer_7_ep3_tp2_sa_out
	layer_7_ep3_tp3_sa_qkv [label="Self-Attn QKV\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep3_tp3_sa_attn [label="Self-Attn Compute\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep3_tp3_sa_out [label="Self-Attn Output\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep3_tp3_sa_qkv -> layer_7_ep3_tp3_sa_attn
	layer_7_ep3_tp3_sa_attn -> layer_7_ep3_tp3_sa_out
	layer_7_ep4_tp0_sa_qkv [label="Self-Attn QKV\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep4_tp0_sa_attn [label="Self-Attn Compute\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep4_tp0_sa_out [label="Self-Attn Output\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep4_tp0_sa_qkv -> layer_7_ep4_tp0_sa_attn
	layer_7_ep4_tp0_sa_attn -> layer_7_ep4_tp0_sa_out
	layer_7_ep4_tp1_sa_qkv [label="Self-Attn QKV\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep4_tp1_sa_attn [label="Self-Attn Compute\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep4_tp1_sa_out [label="Self-Attn Output\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep4_tp1_sa_qkv -> layer_7_ep4_tp1_sa_attn
	layer_7_ep4_tp1_sa_attn -> layer_7_ep4_tp1_sa_out
	layer_7_ep4_tp2_sa_qkv [label="Self-Attn QKV\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep4_tp2_sa_attn [label="Self-Attn Compute\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep4_tp2_sa_out [label="Self-Attn Output\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep4_tp2_sa_qkv -> layer_7_ep4_tp2_sa_attn
	layer_7_ep4_tp2_sa_attn -> layer_7_ep4_tp2_sa_out
	layer_7_ep4_tp3_sa_qkv [label="Self-Attn QKV\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep4_tp3_sa_attn [label="Self-Attn Compute\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep4_tp3_sa_out [label="Self-Attn Output\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep4_tp3_sa_qkv -> layer_7_ep4_tp3_sa_attn
	layer_7_ep4_tp3_sa_attn -> layer_7_ep4_tp3_sa_out
	layer_7_ep5_tp0_sa_qkv [label="Self-Attn QKV\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep5_tp0_sa_attn [label="Self-Attn Compute\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep5_tp0_sa_out [label="Self-Attn Output\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep5_tp0_sa_qkv -> layer_7_ep5_tp0_sa_attn
	layer_7_ep5_tp0_sa_attn -> layer_7_ep5_tp0_sa_out
	layer_7_ep5_tp1_sa_qkv [label="Self-Attn QKV\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep5_tp1_sa_attn [label="Self-Attn Compute\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep5_tp1_sa_out [label="Self-Attn Output\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep5_tp1_sa_qkv -> layer_7_ep5_tp1_sa_attn
	layer_7_ep5_tp1_sa_attn -> layer_7_ep5_tp1_sa_out
	layer_7_ep5_tp2_sa_qkv [label="Self-Attn QKV\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep5_tp2_sa_attn [label="Self-Attn Compute\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep5_tp2_sa_out [label="Self-Attn Output\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep5_tp2_sa_qkv -> layer_7_ep5_tp2_sa_attn
	layer_7_ep5_tp2_sa_attn -> layer_7_ep5_tp2_sa_out
	layer_7_ep5_tp3_sa_qkv [label="Self-Attn QKV\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep5_tp3_sa_attn [label="Self-Attn Compute\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep5_tp3_sa_out [label="Self-Attn Output\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep5_tp3_sa_qkv -> layer_7_ep5_tp3_sa_attn
	layer_7_ep5_tp3_sa_attn -> layer_7_ep5_tp3_sa_out
	layer_7_ep6_tp0_sa_qkv [label="Self-Attn QKV\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep6_tp0_sa_attn [label="Self-Attn Compute\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep6_tp0_sa_out [label="Self-Attn Output\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep6_tp0_sa_qkv -> layer_7_ep6_tp0_sa_attn
	layer_7_ep6_tp0_sa_attn -> layer_7_ep6_tp0_sa_out
	layer_7_ep6_tp1_sa_qkv [label="Self-Attn QKV\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep6_tp1_sa_attn [label="Self-Attn Compute\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep6_tp1_sa_out [label="Self-Attn Output\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep6_tp1_sa_qkv -> layer_7_ep6_tp1_sa_attn
	layer_7_ep6_tp1_sa_attn -> layer_7_ep6_tp1_sa_out
	layer_7_ep6_tp2_sa_qkv [label="Self-Attn QKV\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep6_tp2_sa_attn [label="Self-Attn Compute\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep6_tp2_sa_out [label="Self-Attn Output\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep6_tp2_sa_qkv -> layer_7_ep6_tp2_sa_attn
	layer_7_ep6_tp2_sa_attn -> layer_7_ep6_tp2_sa_out
	layer_7_ep6_tp3_sa_qkv [label="Self-Attn QKV\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep6_tp3_sa_attn [label="Self-Attn Compute\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep6_tp3_sa_out [label="Self-Attn Output\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep6_tp3_sa_qkv -> layer_7_ep6_tp3_sa_attn
	layer_7_ep6_tp3_sa_attn -> layer_7_ep6_tp3_sa_out
	layer_7_ep7_tp0_sa_qkv [label="Self-Attn QKV\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep7_tp0_sa_attn [label="Self-Attn Compute\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep7_tp0_sa_out [label="Self-Attn Output\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep7_tp0_sa_qkv -> layer_7_ep7_tp0_sa_attn
	layer_7_ep7_tp0_sa_attn -> layer_7_ep7_tp0_sa_out
	layer_7_ep7_tp1_sa_qkv [label="Self-Attn QKV\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep7_tp1_sa_attn [label="Self-Attn Compute\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep7_tp1_sa_out [label="Self-Attn Output\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep7_tp1_sa_qkv -> layer_7_ep7_tp1_sa_attn
	layer_7_ep7_tp1_sa_attn -> layer_7_ep7_tp1_sa_out
	layer_7_ep7_tp2_sa_qkv [label="Self-Attn QKV\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep7_tp2_sa_attn [label="Self-Attn Compute\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep7_tp2_sa_out [label="Self-Attn Output\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep7_tp2_sa_qkv -> layer_7_ep7_tp2_sa_attn
	layer_7_ep7_tp2_sa_attn -> layer_7_ep7_tp2_sa_out
	layer_7_ep7_tp3_sa_qkv [label="Self-Attn QKV\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep7_tp3_sa_attn [label="Self-Attn Compute\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep7_tp3_sa_out [label="Self-Attn Output\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep7_tp3_sa_qkv -> layer_7_ep7_tp3_sa_attn
	layer_7_ep7_tp3_sa_attn -> layer_7_ep7_tp3_sa_out
	layer_7_ep8_tp0_sa_qkv [label="Self-Attn QKV\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep8_tp0_sa_attn [label="Self-Attn Compute\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep8_tp0_sa_out [label="Self-Attn Output\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep8_tp0_sa_qkv -> layer_7_ep8_tp0_sa_attn
	layer_7_ep8_tp0_sa_attn -> layer_7_ep8_tp0_sa_out
	layer_7_ep8_tp1_sa_qkv [label="Self-Attn QKV\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep8_tp1_sa_attn [label="Self-Attn Compute\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep8_tp1_sa_out [label="Self-Attn Output\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep8_tp1_sa_qkv -> layer_7_ep8_tp1_sa_attn
	layer_7_ep8_tp1_sa_attn -> layer_7_ep8_tp1_sa_out
	layer_7_ep8_tp2_sa_qkv [label="Self-Attn QKV\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep8_tp2_sa_attn [label="Self-Attn Compute\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep8_tp2_sa_out [label="Self-Attn Output\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep8_tp2_sa_qkv -> layer_7_ep8_tp2_sa_attn
	layer_7_ep8_tp2_sa_attn -> layer_7_ep8_tp2_sa_out
	layer_7_ep8_tp3_sa_qkv [label="Self-Attn QKV\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep8_tp3_sa_attn [label="Self-Attn Compute\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep8_tp3_sa_out [label="Self-Attn Output\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep8_tp3_sa_qkv -> layer_7_ep8_tp3_sa_attn
	layer_7_ep8_tp3_sa_attn -> layer_7_ep8_tp3_sa_out
	layer_7_ep9_tp0_sa_qkv [label="Self-Attn QKV\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep9_tp0_sa_attn [label="Self-Attn Compute\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep9_tp0_sa_out [label="Self-Attn Output\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep9_tp0_sa_qkv -> layer_7_ep9_tp0_sa_attn
	layer_7_ep9_tp0_sa_attn -> layer_7_ep9_tp0_sa_out
	layer_7_ep9_tp1_sa_qkv [label="Self-Attn QKV\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep9_tp1_sa_attn [label="Self-Attn Compute\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep9_tp1_sa_out [label="Self-Attn Output\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep9_tp1_sa_qkv -> layer_7_ep9_tp1_sa_attn
	layer_7_ep9_tp1_sa_attn -> layer_7_ep9_tp1_sa_out
	layer_7_ep9_tp2_sa_qkv [label="Self-Attn QKV\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep9_tp2_sa_attn [label="Self-Attn Compute\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep9_tp2_sa_out [label="Self-Attn Output\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep9_tp2_sa_qkv -> layer_7_ep9_tp2_sa_attn
	layer_7_ep9_tp2_sa_attn -> layer_7_ep9_tp2_sa_out
	layer_7_ep9_tp3_sa_qkv [label="Self-Attn QKV\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep9_tp3_sa_attn [label="Self-Attn Compute\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep9_tp3_sa_out [label="Self-Attn Output\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep9_tp3_sa_qkv -> layer_7_ep9_tp3_sa_attn
	layer_7_ep9_tp3_sa_attn -> layer_7_ep9_tp3_sa_out
	layer_7_ep10_tp0_sa_qkv [label="Self-Attn QKV\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep10_tp0_sa_attn [label="Self-Attn Compute\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep10_tp0_sa_out [label="Self-Attn Output\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep10_tp0_sa_qkv -> layer_7_ep10_tp0_sa_attn
	layer_7_ep10_tp0_sa_attn -> layer_7_ep10_tp0_sa_out
	layer_7_ep10_tp1_sa_qkv [label="Self-Attn QKV\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep10_tp1_sa_attn [label="Self-Attn Compute\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep10_tp1_sa_out [label="Self-Attn Output\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep10_tp1_sa_qkv -> layer_7_ep10_tp1_sa_attn
	layer_7_ep10_tp1_sa_attn -> layer_7_ep10_tp1_sa_out
	layer_7_ep10_tp2_sa_qkv [label="Self-Attn QKV\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep10_tp2_sa_attn [label="Self-Attn Compute\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep10_tp2_sa_out [label="Self-Attn Output\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep10_tp2_sa_qkv -> layer_7_ep10_tp2_sa_attn
	layer_7_ep10_tp2_sa_attn -> layer_7_ep10_tp2_sa_out
	layer_7_ep10_tp3_sa_qkv [label="Self-Attn QKV\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep10_tp3_sa_attn [label="Self-Attn Compute\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep10_tp3_sa_out [label="Self-Attn Output\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep10_tp3_sa_qkv -> layer_7_ep10_tp3_sa_attn
	layer_7_ep10_tp3_sa_attn -> layer_7_ep10_tp3_sa_out
	layer_7_ep11_tp0_sa_qkv [label="Self-Attn QKV\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep11_tp0_sa_attn [label="Self-Attn Compute\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep11_tp0_sa_out [label="Self-Attn Output\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep11_tp0_sa_qkv -> layer_7_ep11_tp0_sa_attn
	layer_7_ep11_tp0_sa_attn -> layer_7_ep11_tp0_sa_out
	layer_7_ep11_tp1_sa_qkv [label="Self-Attn QKV\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep11_tp1_sa_attn [label="Self-Attn Compute\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep11_tp1_sa_out [label="Self-Attn Output\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep11_tp1_sa_qkv -> layer_7_ep11_tp1_sa_attn
	layer_7_ep11_tp1_sa_attn -> layer_7_ep11_tp1_sa_out
	layer_7_ep11_tp2_sa_qkv [label="Self-Attn QKV\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep11_tp2_sa_attn [label="Self-Attn Compute\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep11_tp2_sa_out [label="Self-Attn Output\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep11_tp2_sa_qkv -> layer_7_ep11_tp2_sa_attn
	layer_7_ep11_tp2_sa_attn -> layer_7_ep11_tp2_sa_out
	layer_7_ep11_tp3_sa_qkv [label="Self-Attn QKV\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep11_tp3_sa_attn [label="Self-Attn Compute\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep11_tp3_sa_out [label="Self-Attn Output\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep11_tp3_sa_qkv -> layer_7_ep11_tp3_sa_attn
	layer_7_ep11_tp3_sa_attn -> layer_7_ep11_tp3_sa_out
	layer_7_ep12_tp0_sa_qkv [label="Self-Attn QKV\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep12_tp0_sa_attn [label="Self-Attn Compute\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep12_tp0_sa_out [label="Self-Attn Output\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep12_tp0_sa_qkv -> layer_7_ep12_tp0_sa_attn
	layer_7_ep12_tp0_sa_attn -> layer_7_ep12_tp0_sa_out
	layer_7_ep12_tp1_sa_qkv [label="Self-Attn QKV\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep12_tp1_sa_attn [label="Self-Attn Compute\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep12_tp1_sa_out [label="Self-Attn Output\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep12_tp1_sa_qkv -> layer_7_ep12_tp1_sa_attn
	layer_7_ep12_tp1_sa_attn -> layer_7_ep12_tp1_sa_out
	layer_7_ep12_tp2_sa_qkv [label="Self-Attn QKV\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep12_tp2_sa_attn [label="Self-Attn Compute\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep12_tp2_sa_out [label="Self-Attn Output\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep12_tp2_sa_qkv -> layer_7_ep12_tp2_sa_attn
	layer_7_ep12_tp2_sa_attn -> layer_7_ep12_tp2_sa_out
	layer_7_ep12_tp3_sa_qkv [label="Self-Attn QKV\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep12_tp3_sa_attn [label="Self-Attn Compute\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep12_tp3_sa_out [label="Self-Attn Output\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep12_tp3_sa_qkv -> layer_7_ep12_tp3_sa_attn
	layer_7_ep12_tp3_sa_attn -> layer_7_ep12_tp3_sa_out
	layer_7_ep13_tp0_sa_qkv [label="Self-Attn QKV\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep13_tp0_sa_attn [label="Self-Attn Compute\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep13_tp0_sa_out [label="Self-Attn Output\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep13_tp0_sa_qkv -> layer_7_ep13_tp0_sa_attn
	layer_7_ep13_tp0_sa_attn -> layer_7_ep13_tp0_sa_out
	layer_7_ep13_tp1_sa_qkv [label="Self-Attn QKV\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep13_tp1_sa_attn [label="Self-Attn Compute\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep13_tp1_sa_out [label="Self-Attn Output\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep13_tp1_sa_qkv -> layer_7_ep13_tp1_sa_attn
	layer_7_ep13_tp1_sa_attn -> layer_7_ep13_tp1_sa_out
	layer_7_ep13_tp2_sa_qkv [label="Self-Attn QKV\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep13_tp2_sa_attn [label="Self-Attn Compute\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep13_tp2_sa_out [label="Self-Attn Output\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep13_tp2_sa_qkv -> layer_7_ep13_tp2_sa_attn
	layer_7_ep13_tp2_sa_attn -> layer_7_ep13_tp2_sa_out
	layer_7_ep13_tp3_sa_qkv [label="Self-Attn QKV\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep13_tp3_sa_attn [label="Self-Attn Compute\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep13_tp3_sa_out [label="Self-Attn Output\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep13_tp3_sa_qkv -> layer_7_ep13_tp3_sa_attn
	layer_7_ep13_tp3_sa_attn -> layer_7_ep13_tp3_sa_out
	layer_7_ep14_tp0_sa_qkv [label="Self-Attn QKV\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep14_tp0_sa_attn [label="Self-Attn Compute\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep14_tp0_sa_out [label="Self-Attn Output\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep14_tp0_sa_qkv -> layer_7_ep14_tp0_sa_attn
	layer_7_ep14_tp0_sa_attn -> layer_7_ep14_tp0_sa_out
	layer_7_ep14_tp1_sa_qkv [label="Self-Attn QKV\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep14_tp1_sa_attn [label="Self-Attn Compute\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep14_tp1_sa_out [label="Self-Attn Output\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep14_tp1_sa_qkv -> layer_7_ep14_tp1_sa_attn
	layer_7_ep14_tp1_sa_attn -> layer_7_ep14_tp1_sa_out
	layer_7_ep14_tp2_sa_qkv [label="Self-Attn QKV\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep14_tp2_sa_attn [label="Self-Attn Compute\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep14_tp2_sa_out [label="Self-Attn Output\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep14_tp2_sa_qkv -> layer_7_ep14_tp2_sa_attn
	layer_7_ep14_tp2_sa_attn -> layer_7_ep14_tp2_sa_out
	layer_7_ep14_tp3_sa_qkv [label="Self-Attn QKV\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep14_tp3_sa_attn [label="Self-Attn Compute\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep14_tp3_sa_out [label="Self-Attn Output\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep14_tp3_sa_qkv -> layer_7_ep14_tp3_sa_attn
	layer_7_ep14_tp3_sa_attn -> layer_7_ep14_tp3_sa_out
	layer_7_ep15_tp0_sa_qkv [label="Self-Attn QKV\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep15_tp0_sa_attn [label="Self-Attn Compute\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep15_tp0_sa_out [label="Self-Attn Output\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep15_tp0_sa_qkv -> layer_7_ep15_tp0_sa_attn
	layer_7_ep15_tp0_sa_attn -> layer_7_ep15_tp0_sa_out
	layer_7_ep15_tp1_sa_qkv [label="Self-Attn QKV\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep15_tp1_sa_attn [label="Self-Attn Compute\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep15_tp1_sa_out [label="Self-Attn Output\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep15_tp1_sa_qkv -> layer_7_ep15_tp1_sa_attn
	layer_7_ep15_tp1_sa_attn -> layer_7_ep15_tp1_sa_out
	layer_7_ep15_tp2_sa_qkv [label="Self-Attn QKV\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep15_tp2_sa_attn [label="Self-Attn Compute\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep15_tp2_sa_out [label="Self-Attn Output\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep15_tp2_sa_qkv -> layer_7_ep15_tp2_sa_attn
	layer_7_ep15_tp2_sa_attn -> layer_7_ep15_tp2_sa_out
	layer_7_ep15_tp3_sa_qkv [label="Self-Attn QKV\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep15_tp3_sa_attn [label="Self-Attn Compute\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep15_tp3_sa_out [label="Self-Attn Output\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep15_tp3_sa_qkv -> layer_7_ep15_tp3_sa_attn
	layer_7_ep15_tp3_sa_attn -> layer_7_ep15_tp3_sa_out
	layer_7_ep0_tp_allreduce [label="TP All-Reduce\nEP-Group-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_7_ep0_tp0_sa_out -> layer_7_ep0_tp_allreduce
	layer_7_ep0_tp1_sa_out -> layer_7_ep0_tp_allreduce
	layer_7_ep0_tp2_sa_out -> layer_7_ep0_tp_allreduce
	layer_7_ep0_tp3_sa_out -> layer_7_ep0_tp_allreduce
	layer_7_ep1_tp_allreduce [label="TP All-Reduce\nEP-Group-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_7_ep1_tp0_sa_out -> layer_7_ep1_tp_allreduce
	layer_7_ep1_tp1_sa_out -> layer_7_ep1_tp_allreduce
	layer_7_ep1_tp2_sa_out -> layer_7_ep1_tp_allreduce
	layer_7_ep1_tp3_sa_out -> layer_7_ep1_tp_allreduce
	layer_7_ep2_tp_allreduce [label="TP All-Reduce\nEP-Group-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_7_ep2_tp0_sa_out -> layer_7_ep2_tp_allreduce
	layer_7_ep2_tp1_sa_out -> layer_7_ep2_tp_allreduce
	layer_7_ep2_tp2_sa_out -> layer_7_ep2_tp_allreduce
	layer_7_ep2_tp3_sa_out -> layer_7_ep2_tp_allreduce
	layer_7_ep3_tp_allreduce [label="TP All-Reduce\nEP-Group-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_7_ep3_tp0_sa_out -> layer_7_ep3_tp_allreduce
	layer_7_ep3_tp1_sa_out -> layer_7_ep3_tp_allreduce
	layer_7_ep3_tp2_sa_out -> layer_7_ep3_tp_allreduce
	layer_7_ep3_tp3_sa_out -> layer_7_ep3_tp_allreduce
	layer_7_ep4_tp_allreduce [label="TP All-Reduce\nEP-Group-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_7_ep4_tp0_sa_out -> layer_7_ep4_tp_allreduce
	layer_7_ep4_tp1_sa_out -> layer_7_ep4_tp_allreduce
	layer_7_ep4_tp2_sa_out -> layer_7_ep4_tp_allreduce
	layer_7_ep4_tp3_sa_out -> layer_7_ep4_tp_allreduce
	layer_7_ep5_tp_allreduce [label="TP All-Reduce\nEP-Group-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_7_ep5_tp0_sa_out -> layer_7_ep5_tp_allreduce
	layer_7_ep5_tp1_sa_out -> layer_7_ep5_tp_allreduce
	layer_7_ep5_tp2_sa_out -> layer_7_ep5_tp_allreduce
	layer_7_ep5_tp3_sa_out -> layer_7_ep5_tp_allreduce
	layer_7_ep6_tp_allreduce [label="TP All-Reduce\nEP-Group-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_7_ep6_tp0_sa_out -> layer_7_ep6_tp_allreduce
	layer_7_ep6_tp1_sa_out -> layer_7_ep6_tp_allreduce
	layer_7_ep6_tp2_sa_out -> layer_7_ep6_tp_allreduce
	layer_7_ep6_tp3_sa_out -> layer_7_ep6_tp_allreduce
	layer_7_ep7_tp_allreduce [label="TP All-Reduce\nEP-Group-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_7_ep7_tp0_sa_out -> layer_7_ep7_tp_allreduce
	layer_7_ep7_tp1_sa_out -> layer_7_ep7_tp_allreduce
	layer_7_ep7_tp2_sa_out -> layer_7_ep7_tp_allreduce
	layer_7_ep7_tp3_sa_out -> layer_7_ep7_tp_allreduce
	layer_7_ep8_tp_allreduce [label="TP All-Reduce\nEP-Group-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_7_ep8_tp0_sa_out -> layer_7_ep8_tp_allreduce
	layer_7_ep8_tp1_sa_out -> layer_7_ep8_tp_allreduce
	layer_7_ep8_tp2_sa_out -> layer_7_ep8_tp_allreduce
	layer_7_ep8_tp3_sa_out -> layer_7_ep8_tp_allreduce
	layer_7_ep9_tp_allreduce [label="TP All-Reduce\nEP-Group-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_7_ep9_tp0_sa_out -> layer_7_ep9_tp_allreduce
	layer_7_ep9_tp1_sa_out -> layer_7_ep9_tp_allreduce
	layer_7_ep9_tp2_sa_out -> layer_7_ep9_tp_allreduce
	layer_7_ep9_tp3_sa_out -> layer_7_ep9_tp_allreduce
	layer_7_ep10_tp_allreduce [label="TP All-Reduce\nEP-Group-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_7_ep10_tp0_sa_out -> layer_7_ep10_tp_allreduce
	layer_7_ep10_tp1_sa_out -> layer_7_ep10_tp_allreduce
	layer_7_ep10_tp2_sa_out -> layer_7_ep10_tp_allreduce
	layer_7_ep10_tp3_sa_out -> layer_7_ep10_tp_allreduce
	layer_7_ep11_tp_allreduce [label="TP All-Reduce\nEP-Group-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_7_ep11_tp0_sa_out -> layer_7_ep11_tp_allreduce
	layer_7_ep11_tp1_sa_out -> layer_7_ep11_tp_allreduce
	layer_7_ep11_tp2_sa_out -> layer_7_ep11_tp_allreduce
	layer_7_ep11_tp3_sa_out -> layer_7_ep11_tp_allreduce
	layer_7_ep12_tp_allreduce [label="TP All-Reduce\nEP-Group-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_7_ep12_tp0_sa_out -> layer_7_ep12_tp_allreduce
	layer_7_ep12_tp1_sa_out -> layer_7_ep12_tp_allreduce
	layer_7_ep12_tp2_sa_out -> layer_7_ep12_tp_allreduce
	layer_7_ep12_tp3_sa_out -> layer_7_ep12_tp_allreduce
	layer_7_ep13_tp_allreduce [label="TP All-Reduce\nEP-Group-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_7_ep13_tp0_sa_out -> layer_7_ep13_tp_allreduce
	layer_7_ep13_tp1_sa_out -> layer_7_ep13_tp_allreduce
	layer_7_ep13_tp2_sa_out -> layer_7_ep13_tp_allreduce
	layer_7_ep13_tp3_sa_out -> layer_7_ep13_tp_allreduce
	layer_7_ep14_tp_allreduce [label="TP All-Reduce\nEP-Group-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_7_ep14_tp0_sa_out -> layer_7_ep14_tp_allreduce
	layer_7_ep14_tp1_sa_out -> layer_7_ep14_tp_allreduce
	layer_7_ep14_tp2_sa_out -> layer_7_ep14_tp_allreduce
	layer_7_ep14_tp3_sa_out -> layer_7_ep14_tp_allreduce
	layer_7_ep15_tp_allreduce [label="TP All-Reduce\nEP-Group-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_7_ep15_tp0_sa_out -> layer_7_ep15_tp_allreduce
	layer_7_ep15_tp1_sa_out -> layer_7_ep15_tp_allreduce
	layer_7_ep15_tp2_sa_out -> layer_7_ep15_tp_allreduce
	layer_7_ep15_tp3_sa_out -> layer_7_ep15_tp_allreduce
	layer_7_ep0_gate [label="MoE Gate\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_7_ep0_expert_0 [label="Expert-0\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep0_gate -> layer_7_ep0_expert_0 [label="select tokens" style=dashed]
	layer_7_ep0_expert_1 [label="Expert-1\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep0_gate -> layer_7_ep0_expert_1 [label="select tokens" style=dashed]
	layer_7_ep0_expert_2 [label="Expert-2\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep0_gate -> layer_7_ep0_expert_2 [label="select tokens" style=dashed]
	layer_7_ep0_expert_3 [label="Expert-3\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep0_gate -> layer_7_ep0_expert_3 [label="select tokens" style=dashed]
	layer_7_ep0_expert_aggr [label="Expert Aggregation\nEP-Group-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_7_ep0_expert_0 -> layer_7_ep0_expert_aggr
	layer_7_ep0_expert_1 -> layer_7_ep0_expert_aggr
	layer_7_ep0_expert_2 -> layer_7_ep0_expert_aggr
	layer_7_ep0_expert_3 -> layer_7_ep0_expert_aggr
	layer_7_ep1_gate [label="MoE Gate\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_7_ep1_expert_0 [label="Expert-0\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep1_gate -> layer_7_ep1_expert_0 [label="select tokens" style=dashed]
	layer_7_ep1_expert_1 [label="Expert-1\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep1_gate -> layer_7_ep1_expert_1 [label="select tokens" style=dashed]
	layer_7_ep1_expert_2 [label="Expert-2\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep1_gate -> layer_7_ep1_expert_2 [label="select tokens" style=dashed]
	layer_7_ep1_expert_3 [label="Expert-3\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep1_gate -> layer_7_ep1_expert_3 [label="select tokens" style=dashed]
	layer_7_ep1_expert_aggr [label="Expert Aggregation\nEP-Group-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_7_ep1_expert_0 -> layer_7_ep1_expert_aggr
	layer_7_ep1_expert_1 -> layer_7_ep1_expert_aggr
	layer_7_ep1_expert_2 -> layer_7_ep1_expert_aggr
	layer_7_ep1_expert_3 -> layer_7_ep1_expert_aggr
	layer_7_ep2_gate [label="MoE Gate\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_7_ep2_expert_0 [label="Expert-0\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep2_gate -> layer_7_ep2_expert_0 [label="select tokens" style=dashed]
	layer_7_ep2_expert_1 [label="Expert-1\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep2_gate -> layer_7_ep2_expert_1 [label="select tokens" style=dashed]
	layer_7_ep2_expert_2 [label="Expert-2\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep2_gate -> layer_7_ep2_expert_2 [label="select tokens" style=dashed]
	layer_7_ep2_expert_3 [label="Expert-3\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep2_gate -> layer_7_ep2_expert_3 [label="select tokens" style=dashed]
	layer_7_ep2_expert_aggr [label="Expert Aggregation\nEP-Group-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_7_ep2_expert_0 -> layer_7_ep2_expert_aggr
	layer_7_ep2_expert_1 -> layer_7_ep2_expert_aggr
	layer_7_ep2_expert_2 -> layer_7_ep2_expert_aggr
	layer_7_ep2_expert_3 -> layer_7_ep2_expert_aggr
	layer_7_ep3_gate [label="MoE Gate\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_7_ep3_expert_0 [label="Expert-0\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep3_gate -> layer_7_ep3_expert_0 [label="select tokens" style=dashed]
	layer_7_ep3_expert_1 [label="Expert-1\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep3_gate -> layer_7_ep3_expert_1 [label="select tokens" style=dashed]
	layer_7_ep3_expert_2 [label="Expert-2\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep3_gate -> layer_7_ep3_expert_2 [label="select tokens" style=dashed]
	layer_7_ep3_expert_3 [label="Expert-3\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep3_gate -> layer_7_ep3_expert_3 [label="select tokens" style=dashed]
	layer_7_ep3_expert_aggr [label="Expert Aggregation\nEP-Group-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_7_ep3_expert_0 -> layer_7_ep3_expert_aggr
	layer_7_ep3_expert_1 -> layer_7_ep3_expert_aggr
	layer_7_ep3_expert_2 -> layer_7_ep3_expert_aggr
	layer_7_ep3_expert_3 -> layer_7_ep3_expert_aggr
	layer_7_ep4_gate [label="MoE Gate\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_7_ep4_expert_0 [label="Expert-0\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep4_gate -> layer_7_ep4_expert_0 [label="select tokens" style=dashed]
	layer_7_ep4_expert_1 [label="Expert-1\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep4_gate -> layer_7_ep4_expert_1 [label="select tokens" style=dashed]
	layer_7_ep4_expert_2 [label="Expert-2\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep4_gate -> layer_7_ep4_expert_2 [label="select tokens" style=dashed]
	layer_7_ep4_expert_3 [label="Expert-3\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep4_gate -> layer_7_ep4_expert_3 [label="select tokens" style=dashed]
	layer_7_ep4_expert_aggr [label="Expert Aggregation\nEP-Group-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_7_ep4_expert_0 -> layer_7_ep4_expert_aggr
	layer_7_ep4_expert_1 -> layer_7_ep4_expert_aggr
	layer_7_ep4_expert_2 -> layer_7_ep4_expert_aggr
	layer_7_ep4_expert_3 -> layer_7_ep4_expert_aggr
	layer_7_ep5_gate [label="MoE Gate\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_7_ep5_expert_0 [label="Expert-0\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep5_gate -> layer_7_ep5_expert_0 [label="select tokens" style=dashed]
	layer_7_ep5_expert_1 [label="Expert-1\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep5_gate -> layer_7_ep5_expert_1 [label="select tokens" style=dashed]
	layer_7_ep5_expert_2 [label="Expert-2\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep5_gate -> layer_7_ep5_expert_2 [label="select tokens" style=dashed]
	layer_7_ep5_expert_3 [label="Expert-3\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep5_gate -> layer_7_ep5_expert_3 [label="select tokens" style=dashed]
	layer_7_ep5_expert_aggr [label="Expert Aggregation\nEP-Group-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_7_ep5_expert_0 -> layer_7_ep5_expert_aggr
	layer_7_ep5_expert_1 -> layer_7_ep5_expert_aggr
	layer_7_ep5_expert_2 -> layer_7_ep5_expert_aggr
	layer_7_ep5_expert_3 -> layer_7_ep5_expert_aggr
	layer_7_ep6_gate [label="MoE Gate\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_7_ep6_expert_0 [label="Expert-0\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep6_gate -> layer_7_ep6_expert_0 [label="select tokens" style=dashed]
	layer_7_ep6_expert_1 [label="Expert-1\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep6_gate -> layer_7_ep6_expert_1 [label="select tokens" style=dashed]
	layer_7_ep6_expert_2 [label="Expert-2\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep6_gate -> layer_7_ep6_expert_2 [label="select tokens" style=dashed]
	layer_7_ep6_expert_3 [label="Expert-3\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep6_gate -> layer_7_ep6_expert_3 [label="select tokens" style=dashed]
	layer_7_ep6_expert_aggr [label="Expert Aggregation\nEP-Group-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_7_ep6_expert_0 -> layer_7_ep6_expert_aggr
	layer_7_ep6_expert_1 -> layer_7_ep6_expert_aggr
	layer_7_ep6_expert_2 -> layer_7_ep6_expert_aggr
	layer_7_ep6_expert_3 -> layer_7_ep6_expert_aggr
	layer_7_ep7_gate [label="MoE Gate\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_7_ep7_expert_0 [label="Expert-0\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep7_gate -> layer_7_ep7_expert_0 [label="select tokens" style=dashed]
	layer_7_ep7_expert_1 [label="Expert-1\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep7_gate -> layer_7_ep7_expert_1 [label="select tokens" style=dashed]
	layer_7_ep7_expert_2 [label="Expert-2\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep7_gate -> layer_7_ep7_expert_2 [label="select tokens" style=dashed]
	layer_7_ep7_expert_3 [label="Expert-3\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep7_gate -> layer_7_ep7_expert_3 [label="select tokens" style=dashed]
	layer_7_ep7_expert_aggr [label="Expert Aggregation\nEP-Group-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_7_ep7_expert_0 -> layer_7_ep7_expert_aggr
	layer_7_ep7_expert_1 -> layer_7_ep7_expert_aggr
	layer_7_ep7_expert_2 -> layer_7_ep7_expert_aggr
	layer_7_ep7_expert_3 -> layer_7_ep7_expert_aggr
	layer_7_ep8_gate [label="MoE Gate\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_7_ep8_expert_0 [label="Expert-0\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep8_gate -> layer_7_ep8_expert_0 [label="select tokens" style=dashed]
	layer_7_ep8_expert_1 [label="Expert-1\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep8_gate -> layer_7_ep8_expert_1 [label="select tokens" style=dashed]
	layer_7_ep8_expert_2 [label="Expert-2\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep8_gate -> layer_7_ep8_expert_2 [label="select tokens" style=dashed]
	layer_7_ep8_expert_3 [label="Expert-3\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep8_gate -> layer_7_ep8_expert_3 [label="select tokens" style=dashed]
	layer_7_ep8_expert_aggr [label="Expert Aggregation\nEP-Group-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_7_ep8_expert_0 -> layer_7_ep8_expert_aggr
	layer_7_ep8_expert_1 -> layer_7_ep8_expert_aggr
	layer_7_ep8_expert_2 -> layer_7_ep8_expert_aggr
	layer_7_ep8_expert_3 -> layer_7_ep8_expert_aggr
	layer_7_ep9_gate [label="MoE Gate\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_7_ep9_expert_0 [label="Expert-0\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep9_gate -> layer_7_ep9_expert_0 [label="select tokens" style=dashed]
	layer_7_ep9_expert_1 [label="Expert-1\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep9_gate -> layer_7_ep9_expert_1 [label="select tokens" style=dashed]
	layer_7_ep9_expert_2 [label="Expert-2\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep9_gate -> layer_7_ep9_expert_2 [label="select tokens" style=dashed]
	layer_7_ep9_expert_3 [label="Expert-3\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep9_gate -> layer_7_ep9_expert_3 [label="select tokens" style=dashed]
	layer_7_ep9_expert_aggr [label="Expert Aggregation\nEP-Group-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_7_ep9_expert_0 -> layer_7_ep9_expert_aggr
	layer_7_ep9_expert_1 -> layer_7_ep9_expert_aggr
	layer_7_ep9_expert_2 -> layer_7_ep9_expert_aggr
	layer_7_ep9_expert_3 -> layer_7_ep9_expert_aggr
	layer_7_ep10_gate [label="MoE Gate\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_7_ep10_expert_0 [label="Expert-0\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep10_gate -> layer_7_ep10_expert_0 [label="select tokens" style=dashed]
	layer_7_ep10_expert_1 [label="Expert-1\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep10_gate -> layer_7_ep10_expert_1 [label="select tokens" style=dashed]
	layer_7_ep10_expert_2 [label="Expert-2\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep10_gate -> layer_7_ep10_expert_2 [label="select tokens" style=dashed]
	layer_7_ep10_expert_3 [label="Expert-3\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep10_gate -> layer_7_ep10_expert_3 [label="select tokens" style=dashed]
	layer_7_ep10_expert_aggr [label="Expert Aggregation\nEP-Group-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_7_ep10_expert_0 -> layer_7_ep10_expert_aggr
	layer_7_ep10_expert_1 -> layer_7_ep10_expert_aggr
	layer_7_ep10_expert_2 -> layer_7_ep10_expert_aggr
	layer_7_ep10_expert_3 -> layer_7_ep10_expert_aggr
	layer_7_ep11_gate [label="MoE Gate\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_7_ep11_expert_0 [label="Expert-0\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep11_gate -> layer_7_ep11_expert_0 [label="select tokens" style=dashed]
	layer_7_ep11_expert_1 [label="Expert-1\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep11_gate -> layer_7_ep11_expert_1 [label="select tokens" style=dashed]
	layer_7_ep11_expert_2 [label="Expert-2\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep11_gate -> layer_7_ep11_expert_2 [label="select tokens" style=dashed]
	layer_7_ep11_expert_3 [label="Expert-3\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep11_gate -> layer_7_ep11_expert_3 [label="select tokens" style=dashed]
	layer_7_ep11_expert_aggr [label="Expert Aggregation\nEP-Group-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_7_ep11_expert_0 -> layer_7_ep11_expert_aggr
	layer_7_ep11_expert_1 -> layer_7_ep11_expert_aggr
	layer_7_ep11_expert_2 -> layer_7_ep11_expert_aggr
	layer_7_ep11_expert_3 -> layer_7_ep11_expert_aggr
	layer_7_ep12_gate [label="MoE Gate\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_7_ep12_expert_0 [label="Expert-0\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep12_gate -> layer_7_ep12_expert_0 [label="select tokens" style=dashed]
	layer_7_ep12_expert_1 [label="Expert-1\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep12_gate -> layer_7_ep12_expert_1 [label="select tokens" style=dashed]
	layer_7_ep12_expert_2 [label="Expert-2\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep12_gate -> layer_7_ep12_expert_2 [label="select tokens" style=dashed]
	layer_7_ep12_expert_3 [label="Expert-3\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep12_gate -> layer_7_ep12_expert_3 [label="select tokens" style=dashed]
	layer_7_ep12_expert_aggr [label="Expert Aggregation\nEP-Group-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_7_ep12_expert_0 -> layer_7_ep12_expert_aggr
	layer_7_ep12_expert_1 -> layer_7_ep12_expert_aggr
	layer_7_ep12_expert_2 -> layer_7_ep12_expert_aggr
	layer_7_ep12_expert_3 -> layer_7_ep12_expert_aggr
	layer_7_ep13_gate [label="MoE Gate\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_7_ep13_expert_0 [label="Expert-0\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep13_gate -> layer_7_ep13_expert_0 [label="select tokens" style=dashed]
	layer_7_ep13_expert_1 [label="Expert-1\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep13_gate -> layer_7_ep13_expert_1 [label="select tokens" style=dashed]
	layer_7_ep13_expert_2 [label="Expert-2\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep13_gate -> layer_7_ep13_expert_2 [label="select tokens" style=dashed]
	layer_7_ep13_expert_3 [label="Expert-3\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep13_gate -> layer_7_ep13_expert_3 [label="select tokens" style=dashed]
	layer_7_ep13_expert_aggr [label="Expert Aggregation\nEP-Group-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_7_ep13_expert_0 -> layer_7_ep13_expert_aggr
	layer_7_ep13_expert_1 -> layer_7_ep13_expert_aggr
	layer_7_ep13_expert_2 -> layer_7_ep13_expert_aggr
	layer_7_ep13_expert_3 -> layer_7_ep13_expert_aggr
	layer_7_ep14_gate [label="MoE Gate\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_7_ep14_expert_0 [label="Expert-0\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep14_gate -> layer_7_ep14_expert_0 [label="select tokens" style=dashed]
	layer_7_ep14_expert_1 [label="Expert-1\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep14_gate -> layer_7_ep14_expert_1 [label="select tokens" style=dashed]
	layer_7_ep14_expert_2 [label="Expert-2\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep14_gate -> layer_7_ep14_expert_2 [label="select tokens" style=dashed]
	layer_7_ep14_expert_3 [label="Expert-3\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep14_gate -> layer_7_ep14_expert_3 [label="select tokens" style=dashed]
	layer_7_ep14_expert_aggr [label="Expert Aggregation\nEP-Group-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_7_ep14_expert_0 -> layer_7_ep14_expert_aggr
	layer_7_ep14_expert_1 -> layer_7_ep14_expert_aggr
	layer_7_ep14_expert_2 -> layer_7_ep14_expert_aggr
	layer_7_ep14_expert_3 -> layer_7_ep14_expert_aggr
	layer_7_ep15_gate [label="MoE Gate\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_7_ep15_expert_0 [label="Expert-0\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep15_gate -> layer_7_ep15_expert_0 [label="select tokens" style=dashed]
	layer_7_ep15_expert_1 [label="Expert-1\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep15_gate -> layer_7_ep15_expert_1 [label="select tokens" style=dashed]
	layer_7_ep15_expert_2 [label="Expert-2\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep15_gate -> layer_7_ep15_expert_2 [label="select tokens" style=dashed]
	layer_7_ep15_expert_3 [label="Expert-3\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_7_ep15_gate -> layer_7_ep15_expert_3 [label="select tokens" style=dashed]
	layer_7_ep15_expert_aggr [label="Expert Aggregation\nEP-Group-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_7_ep15_expert_0 -> layer_7_ep15_expert_aggr
	layer_7_ep15_expert_1 -> layer_7_ep15_expert_aggr
	layer_7_ep15_expert_2 -> layer_7_ep15_expert_aggr
	layer_7_ep15_expert_3 -> layer_7_ep15_expert_aggr
	layer_7_to_8_ep0_pp [label="Pipeline Stage Transfer\nEP-Group-0\nLayer-7 to Layer-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_7_ep0_expert_aggr -> layer_7_to_8_ep0_pp
	layer_7_to_8_ep1_pp [label="Pipeline Stage Transfer\nEP-Group-1\nLayer-7 to Layer-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_7_ep1_expert_aggr -> layer_7_to_8_ep1_pp
	layer_7_to_8_ep2_pp [label="Pipeline Stage Transfer\nEP-Group-2\nLayer-7 to Layer-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_7_ep2_expert_aggr -> layer_7_to_8_ep2_pp
	layer_7_to_8_ep3_pp [label="Pipeline Stage Transfer\nEP-Group-3\nLayer-7 to Layer-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_7_ep3_expert_aggr -> layer_7_to_8_ep3_pp
	layer_7_to_8_ep4_pp [label="Pipeline Stage Transfer\nEP-Group-4\nLayer-7 to Layer-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_7_ep4_expert_aggr -> layer_7_to_8_ep4_pp
	layer_7_to_8_ep5_pp [label="Pipeline Stage Transfer\nEP-Group-5\nLayer-7 to Layer-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_7_ep5_expert_aggr -> layer_7_to_8_ep5_pp
	layer_7_to_8_ep6_pp [label="Pipeline Stage Transfer\nEP-Group-6\nLayer-7 to Layer-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_7_ep6_expert_aggr -> layer_7_to_8_ep6_pp
	layer_7_to_8_ep7_pp [label="Pipeline Stage Transfer\nEP-Group-7\nLayer-7 to Layer-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_7_ep7_expert_aggr -> layer_7_to_8_ep7_pp
	layer_7_to_8_ep8_pp [label="Pipeline Stage Transfer\nEP-Group-8\nLayer-7 to Layer-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_7_ep8_expert_aggr -> layer_7_to_8_ep8_pp
	layer_7_to_8_ep9_pp [label="Pipeline Stage Transfer\nEP-Group-9\nLayer-7 to Layer-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_7_ep9_expert_aggr -> layer_7_to_8_ep9_pp
	layer_7_to_8_ep10_pp [label="Pipeline Stage Transfer\nEP-Group-10\nLayer-7 to Layer-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_7_ep10_expert_aggr -> layer_7_to_8_ep10_pp
	layer_7_to_8_ep11_pp [label="Pipeline Stage Transfer\nEP-Group-11\nLayer-7 to Layer-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_7_ep11_expert_aggr -> layer_7_to_8_ep11_pp
	layer_7_to_8_ep12_pp [label="Pipeline Stage Transfer\nEP-Group-12\nLayer-7 to Layer-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_7_ep12_expert_aggr -> layer_7_to_8_ep12_pp
	layer_7_to_8_ep13_pp [label="Pipeline Stage Transfer\nEP-Group-13\nLayer-7 to Layer-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_7_ep13_expert_aggr -> layer_7_to_8_ep13_pp
	layer_7_to_8_ep14_pp [label="Pipeline Stage Transfer\nEP-Group-14\nLayer-7 to Layer-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_7_ep14_expert_aggr -> layer_7_to_8_ep14_pp
	layer_7_to_8_ep15_pp [label="Pipeline Stage Transfer\nEP-Group-15\nLayer-7 to Layer-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_7_ep15_expert_aggr -> layer_7_to_8_ep15_pp
	layer_8_ep0_tp0_sa_qkv [label="Self-Attn QKV\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep0_tp0_sa_attn [label="Self-Attn Compute\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep0_tp0_sa_out [label="Self-Attn Output\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep0_tp0_sa_qkv -> layer_8_ep0_tp0_sa_attn
	layer_8_ep0_tp0_sa_attn -> layer_8_ep0_tp0_sa_out
	layer_8_ep0_tp1_sa_qkv [label="Self-Attn QKV\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep0_tp1_sa_attn [label="Self-Attn Compute\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep0_tp1_sa_out [label="Self-Attn Output\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep0_tp1_sa_qkv -> layer_8_ep0_tp1_sa_attn
	layer_8_ep0_tp1_sa_attn -> layer_8_ep0_tp1_sa_out
	layer_8_ep0_tp2_sa_qkv [label="Self-Attn QKV\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep0_tp2_sa_attn [label="Self-Attn Compute\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep0_tp2_sa_out [label="Self-Attn Output\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep0_tp2_sa_qkv -> layer_8_ep0_tp2_sa_attn
	layer_8_ep0_tp2_sa_attn -> layer_8_ep0_tp2_sa_out
	layer_8_ep0_tp3_sa_qkv [label="Self-Attn QKV\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep0_tp3_sa_attn [label="Self-Attn Compute\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep0_tp3_sa_out [label="Self-Attn Output\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep0_tp3_sa_qkv -> layer_8_ep0_tp3_sa_attn
	layer_8_ep0_tp3_sa_attn -> layer_8_ep0_tp3_sa_out
	layer_8_ep1_tp0_sa_qkv [label="Self-Attn QKV\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep1_tp0_sa_attn [label="Self-Attn Compute\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep1_tp0_sa_out [label="Self-Attn Output\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep1_tp0_sa_qkv -> layer_8_ep1_tp0_sa_attn
	layer_8_ep1_tp0_sa_attn -> layer_8_ep1_tp0_sa_out
	layer_8_ep1_tp1_sa_qkv [label="Self-Attn QKV\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep1_tp1_sa_attn [label="Self-Attn Compute\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep1_tp1_sa_out [label="Self-Attn Output\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep1_tp1_sa_qkv -> layer_8_ep1_tp1_sa_attn
	layer_8_ep1_tp1_sa_attn -> layer_8_ep1_tp1_sa_out
	layer_8_ep1_tp2_sa_qkv [label="Self-Attn QKV\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep1_tp2_sa_attn [label="Self-Attn Compute\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep1_tp2_sa_out [label="Self-Attn Output\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep1_tp2_sa_qkv -> layer_8_ep1_tp2_sa_attn
	layer_8_ep1_tp2_sa_attn -> layer_8_ep1_tp2_sa_out
	layer_8_ep1_tp3_sa_qkv [label="Self-Attn QKV\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep1_tp3_sa_attn [label="Self-Attn Compute\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep1_tp3_sa_out [label="Self-Attn Output\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep1_tp3_sa_qkv -> layer_8_ep1_tp3_sa_attn
	layer_8_ep1_tp3_sa_attn -> layer_8_ep1_tp3_sa_out
	layer_8_ep2_tp0_sa_qkv [label="Self-Attn QKV\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep2_tp0_sa_attn [label="Self-Attn Compute\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep2_tp0_sa_out [label="Self-Attn Output\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep2_tp0_sa_qkv -> layer_8_ep2_tp0_sa_attn
	layer_8_ep2_tp0_sa_attn -> layer_8_ep2_tp0_sa_out
	layer_8_ep2_tp1_sa_qkv [label="Self-Attn QKV\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep2_tp1_sa_attn [label="Self-Attn Compute\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep2_tp1_sa_out [label="Self-Attn Output\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep2_tp1_sa_qkv -> layer_8_ep2_tp1_sa_attn
	layer_8_ep2_tp1_sa_attn -> layer_8_ep2_tp1_sa_out
	layer_8_ep2_tp2_sa_qkv [label="Self-Attn QKV\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep2_tp2_sa_attn [label="Self-Attn Compute\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep2_tp2_sa_out [label="Self-Attn Output\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep2_tp2_sa_qkv -> layer_8_ep2_tp2_sa_attn
	layer_8_ep2_tp2_sa_attn -> layer_8_ep2_tp2_sa_out
	layer_8_ep2_tp3_sa_qkv [label="Self-Attn QKV\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep2_tp3_sa_attn [label="Self-Attn Compute\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep2_tp3_sa_out [label="Self-Attn Output\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep2_tp3_sa_qkv -> layer_8_ep2_tp3_sa_attn
	layer_8_ep2_tp3_sa_attn -> layer_8_ep2_tp3_sa_out
	layer_8_ep3_tp0_sa_qkv [label="Self-Attn QKV\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep3_tp0_sa_attn [label="Self-Attn Compute\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep3_tp0_sa_out [label="Self-Attn Output\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep3_tp0_sa_qkv -> layer_8_ep3_tp0_sa_attn
	layer_8_ep3_tp0_sa_attn -> layer_8_ep3_tp0_sa_out
	layer_8_ep3_tp1_sa_qkv [label="Self-Attn QKV\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep3_tp1_sa_attn [label="Self-Attn Compute\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep3_tp1_sa_out [label="Self-Attn Output\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep3_tp1_sa_qkv -> layer_8_ep3_tp1_sa_attn
	layer_8_ep3_tp1_sa_attn -> layer_8_ep3_tp1_sa_out
	layer_8_ep3_tp2_sa_qkv [label="Self-Attn QKV\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep3_tp2_sa_attn [label="Self-Attn Compute\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep3_tp2_sa_out [label="Self-Attn Output\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep3_tp2_sa_qkv -> layer_8_ep3_tp2_sa_attn
	layer_8_ep3_tp2_sa_attn -> layer_8_ep3_tp2_sa_out
	layer_8_ep3_tp3_sa_qkv [label="Self-Attn QKV\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep3_tp3_sa_attn [label="Self-Attn Compute\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep3_tp3_sa_out [label="Self-Attn Output\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep3_tp3_sa_qkv -> layer_8_ep3_tp3_sa_attn
	layer_8_ep3_tp3_sa_attn -> layer_8_ep3_tp3_sa_out
	layer_8_ep4_tp0_sa_qkv [label="Self-Attn QKV\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep4_tp0_sa_attn [label="Self-Attn Compute\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep4_tp0_sa_out [label="Self-Attn Output\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep4_tp0_sa_qkv -> layer_8_ep4_tp0_sa_attn
	layer_8_ep4_tp0_sa_attn -> layer_8_ep4_tp0_sa_out
	layer_8_ep4_tp1_sa_qkv [label="Self-Attn QKV\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep4_tp1_sa_attn [label="Self-Attn Compute\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep4_tp1_sa_out [label="Self-Attn Output\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep4_tp1_sa_qkv -> layer_8_ep4_tp1_sa_attn
	layer_8_ep4_tp1_sa_attn -> layer_8_ep4_tp1_sa_out
	layer_8_ep4_tp2_sa_qkv [label="Self-Attn QKV\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep4_tp2_sa_attn [label="Self-Attn Compute\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep4_tp2_sa_out [label="Self-Attn Output\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep4_tp2_sa_qkv -> layer_8_ep4_tp2_sa_attn
	layer_8_ep4_tp2_sa_attn -> layer_8_ep4_tp2_sa_out
	layer_8_ep4_tp3_sa_qkv [label="Self-Attn QKV\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep4_tp3_sa_attn [label="Self-Attn Compute\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep4_tp3_sa_out [label="Self-Attn Output\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep4_tp3_sa_qkv -> layer_8_ep4_tp3_sa_attn
	layer_8_ep4_tp3_sa_attn -> layer_8_ep4_tp3_sa_out
	layer_8_ep5_tp0_sa_qkv [label="Self-Attn QKV\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep5_tp0_sa_attn [label="Self-Attn Compute\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep5_tp0_sa_out [label="Self-Attn Output\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep5_tp0_sa_qkv -> layer_8_ep5_tp0_sa_attn
	layer_8_ep5_tp0_sa_attn -> layer_8_ep5_tp0_sa_out
	layer_8_ep5_tp1_sa_qkv [label="Self-Attn QKV\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep5_tp1_sa_attn [label="Self-Attn Compute\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep5_tp1_sa_out [label="Self-Attn Output\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep5_tp1_sa_qkv -> layer_8_ep5_tp1_sa_attn
	layer_8_ep5_tp1_sa_attn -> layer_8_ep5_tp1_sa_out
	layer_8_ep5_tp2_sa_qkv [label="Self-Attn QKV\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep5_tp2_sa_attn [label="Self-Attn Compute\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep5_tp2_sa_out [label="Self-Attn Output\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep5_tp2_sa_qkv -> layer_8_ep5_tp2_sa_attn
	layer_8_ep5_tp2_sa_attn -> layer_8_ep5_tp2_sa_out
	layer_8_ep5_tp3_sa_qkv [label="Self-Attn QKV\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep5_tp3_sa_attn [label="Self-Attn Compute\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep5_tp3_sa_out [label="Self-Attn Output\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep5_tp3_sa_qkv -> layer_8_ep5_tp3_sa_attn
	layer_8_ep5_tp3_sa_attn -> layer_8_ep5_tp3_sa_out
	layer_8_ep6_tp0_sa_qkv [label="Self-Attn QKV\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep6_tp0_sa_attn [label="Self-Attn Compute\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep6_tp0_sa_out [label="Self-Attn Output\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep6_tp0_sa_qkv -> layer_8_ep6_tp0_sa_attn
	layer_8_ep6_tp0_sa_attn -> layer_8_ep6_tp0_sa_out
	layer_8_ep6_tp1_sa_qkv [label="Self-Attn QKV\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep6_tp1_sa_attn [label="Self-Attn Compute\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep6_tp1_sa_out [label="Self-Attn Output\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep6_tp1_sa_qkv -> layer_8_ep6_tp1_sa_attn
	layer_8_ep6_tp1_sa_attn -> layer_8_ep6_tp1_sa_out
	layer_8_ep6_tp2_sa_qkv [label="Self-Attn QKV\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep6_tp2_sa_attn [label="Self-Attn Compute\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep6_tp2_sa_out [label="Self-Attn Output\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep6_tp2_sa_qkv -> layer_8_ep6_tp2_sa_attn
	layer_8_ep6_tp2_sa_attn -> layer_8_ep6_tp2_sa_out
	layer_8_ep6_tp3_sa_qkv [label="Self-Attn QKV\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep6_tp3_sa_attn [label="Self-Attn Compute\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep6_tp3_sa_out [label="Self-Attn Output\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep6_tp3_sa_qkv -> layer_8_ep6_tp3_sa_attn
	layer_8_ep6_tp3_sa_attn -> layer_8_ep6_tp3_sa_out
	layer_8_ep7_tp0_sa_qkv [label="Self-Attn QKV\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep7_tp0_sa_attn [label="Self-Attn Compute\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep7_tp0_sa_out [label="Self-Attn Output\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep7_tp0_sa_qkv -> layer_8_ep7_tp0_sa_attn
	layer_8_ep7_tp0_sa_attn -> layer_8_ep7_tp0_sa_out
	layer_8_ep7_tp1_sa_qkv [label="Self-Attn QKV\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep7_tp1_sa_attn [label="Self-Attn Compute\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep7_tp1_sa_out [label="Self-Attn Output\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep7_tp1_sa_qkv -> layer_8_ep7_tp1_sa_attn
	layer_8_ep7_tp1_sa_attn -> layer_8_ep7_tp1_sa_out
	layer_8_ep7_tp2_sa_qkv [label="Self-Attn QKV\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep7_tp2_sa_attn [label="Self-Attn Compute\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep7_tp2_sa_out [label="Self-Attn Output\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep7_tp2_sa_qkv -> layer_8_ep7_tp2_sa_attn
	layer_8_ep7_tp2_sa_attn -> layer_8_ep7_tp2_sa_out
	layer_8_ep7_tp3_sa_qkv [label="Self-Attn QKV\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep7_tp3_sa_attn [label="Self-Attn Compute\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep7_tp3_sa_out [label="Self-Attn Output\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep7_tp3_sa_qkv -> layer_8_ep7_tp3_sa_attn
	layer_8_ep7_tp3_sa_attn -> layer_8_ep7_tp3_sa_out
	layer_8_ep8_tp0_sa_qkv [label="Self-Attn QKV\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep8_tp0_sa_attn [label="Self-Attn Compute\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep8_tp0_sa_out [label="Self-Attn Output\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep8_tp0_sa_qkv -> layer_8_ep8_tp0_sa_attn
	layer_8_ep8_tp0_sa_attn -> layer_8_ep8_tp0_sa_out
	layer_8_ep8_tp1_sa_qkv [label="Self-Attn QKV\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep8_tp1_sa_attn [label="Self-Attn Compute\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep8_tp1_sa_out [label="Self-Attn Output\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep8_tp1_sa_qkv -> layer_8_ep8_tp1_sa_attn
	layer_8_ep8_tp1_sa_attn -> layer_8_ep8_tp1_sa_out
	layer_8_ep8_tp2_sa_qkv [label="Self-Attn QKV\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep8_tp2_sa_attn [label="Self-Attn Compute\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep8_tp2_sa_out [label="Self-Attn Output\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep8_tp2_sa_qkv -> layer_8_ep8_tp2_sa_attn
	layer_8_ep8_tp2_sa_attn -> layer_8_ep8_tp2_sa_out
	layer_8_ep8_tp3_sa_qkv [label="Self-Attn QKV\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep8_tp3_sa_attn [label="Self-Attn Compute\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep8_tp3_sa_out [label="Self-Attn Output\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep8_tp3_sa_qkv -> layer_8_ep8_tp3_sa_attn
	layer_8_ep8_tp3_sa_attn -> layer_8_ep8_tp3_sa_out
	layer_8_ep9_tp0_sa_qkv [label="Self-Attn QKV\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep9_tp0_sa_attn [label="Self-Attn Compute\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep9_tp0_sa_out [label="Self-Attn Output\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep9_tp0_sa_qkv -> layer_8_ep9_tp0_sa_attn
	layer_8_ep9_tp0_sa_attn -> layer_8_ep9_tp0_sa_out
	layer_8_ep9_tp1_sa_qkv [label="Self-Attn QKV\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep9_tp1_sa_attn [label="Self-Attn Compute\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep9_tp1_sa_out [label="Self-Attn Output\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep9_tp1_sa_qkv -> layer_8_ep9_tp1_sa_attn
	layer_8_ep9_tp1_sa_attn -> layer_8_ep9_tp1_sa_out
	layer_8_ep9_tp2_sa_qkv [label="Self-Attn QKV\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep9_tp2_sa_attn [label="Self-Attn Compute\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep9_tp2_sa_out [label="Self-Attn Output\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep9_tp2_sa_qkv -> layer_8_ep9_tp2_sa_attn
	layer_8_ep9_tp2_sa_attn -> layer_8_ep9_tp2_sa_out
	layer_8_ep9_tp3_sa_qkv [label="Self-Attn QKV\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep9_tp3_sa_attn [label="Self-Attn Compute\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep9_tp3_sa_out [label="Self-Attn Output\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep9_tp3_sa_qkv -> layer_8_ep9_tp3_sa_attn
	layer_8_ep9_tp3_sa_attn -> layer_8_ep9_tp3_sa_out
	layer_8_ep10_tp0_sa_qkv [label="Self-Attn QKV\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep10_tp0_sa_attn [label="Self-Attn Compute\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep10_tp0_sa_out [label="Self-Attn Output\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep10_tp0_sa_qkv -> layer_8_ep10_tp0_sa_attn
	layer_8_ep10_tp0_sa_attn -> layer_8_ep10_tp0_sa_out
	layer_8_ep10_tp1_sa_qkv [label="Self-Attn QKV\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep10_tp1_sa_attn [label="Self-Attn Compute\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep10_tp1_sa_out [label="Self-Attn Output\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep10_tp1_sa_qkv -> layer_8_ep10_tp1_sa_attn
	layer_8_ep10_tp1_sa_attn -> layer_8_ep10_tp1_sa_out
	layer_8_ep10_tp2_sa_qkv [label="Self-Attn QKV\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep10_tp2_sa_attn [label="Self-Attn Compute\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep10_tp2_sa_out [label="Self-Attn Output\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep10_tp2_sa_qkv -> layer_8_ep10_tp2_sa_attn
	layer_8_ep10_tp2_sa_attn -> layer_8_ep10_tp2_sa_out
	layer_8_ep10_tp3_sa_qkv [label="Self-Attn QKV\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep10_tp3_sa_attn [label="Self-Attn Compute\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep10_tp3_sa_out [label="Self-Attn Output\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep10_tp3_sa_qkv -> layer_8_ep10_tp3_sa_attn
	layer_8_ep10_tp3_sa_attn -> layer_8_ep10_tp3_sa_out
	layer_8_ep11_tp0_sa_qkv [label="Self-Attn QKV\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep11_tp0_sa_attn [label="Self-Attn Compute\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep11_tp0_sa_out [label="Self-Attn Output\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep11_tp0_sa_qkv -> layer_8_ep11_tp0_sa_attn
	layer_8_ep11_tp0_sa_attn -> layer_8_ep11_tp0_sa_out
	layer_8_ep11_tp1_sa_qkv [label="Self-Attn QKV\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep11_tp1_sa_attn [label="Self-Attn Compute\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep11_tp1_sa_out [label="Self-Attn Output\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep11_tp1_sa_qkv -> layer_8_ep11_tp1_sa_attn
	layer_8_ep11_tp1_sa_attn -> layer_8_ep11_tp1_sa_out
	layer_8_ep11_tp2_sa_qkv [label="Self-Attn QKV\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep11_tp2_sa_attn [label="Self-Attn Compute\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep11_tp2_sa_out [label="Self-Attn Output\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep11_tp2_sa_qkv -> layer_8_ep11_tp2_sa_attn
	layer_8_ep11_tp2_sa_attn -> layer_8_ep11_tp2_sa_out
	layer_8_ep11_tp3_sa_qkv [label="Self-Attn QKV\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep11_tp3_sa_attn [label="Self-Attn Compute\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep11_tp3_sa_out [label="Self-Attn Output\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep11_tp3_sa_qkv -> layer_8_ep11_tp3_sa_attn
	layer_8_ep11_tp3_sa_attn -> layer_8_ep11_tp3_sa_out
	layer_8_ep12_tp0_sa_qkv [label="Self-Attn QKV\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep12_tp0_sa_attn [label="Self-Attn Compute\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep12_tp0_sa_out [label="Self-Attn Output\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep12_tp0_sa_qkv -> layer_8_ep12_tp0_sa_attn
	layer_8_ep12_tp0_sa_attn -> layer_8_ep12_tp0_sa_out
	layer_8_ep12_tp1_sa_qkv [label="Self-Attn QKV\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep12_tp1_sa_attn [label="Self-Attn Compute\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep12_tp1_sa_out [label="Self-Attn Output\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep12_tp1_sa_qkv -> layer_8_ep12_tp1_sa_attn
	layer_8_ep12_tp1_sa_attn -> layer_8_ep12_tp1_sa_out
	layer_8_ep12_tp2_sa_qkv [label="Self-Attn QKV\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep12_tp2_sa_attn [label="Self-Attn Compute\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep12_tp2_sa_out [label="Self-Attn Output\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep12_tp2_sa_qkv -> layer_8_ep12_tp2_sa_attn
	layer_8_ep12_tp2_sa_attn -> layer_8_ep12_tp2_sa_out
	layer_8_ep12_tp3_sa_qkv [label="Self-Attn QKV\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep12_tp3_sa_attn [label="Self-Attn Compute\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep12_tp3_sa_out [label="Self-Attn Output\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep12_tp3_sa_qkv -> layer_8_ep12_tp3_sa_attn
	layer_8_ep12_tp3_sa_attn -> layer_8_ep12_tp3_sa_out
	layer_8_ep13_tp0_sa_qkv [label="Self-Attn QKV\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep13_tp0_sa_attn [label="Self-Attn Compute\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep13_tp0_sa_out [label="Self-Attn Output\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep13_tp0_sa_qkv -> layer_8_ep13_tp0_sa_attn
	layer_8_ep13_tp0_sa_attn -> layer_8_ep13_tp0_sa_out
	layer_8_ep13_tp1_sa_qkv [label="Self-Attn QKV\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep13_tp1_sa_attn [label="Self-Attn Compute\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep13_tp1_sa_out [label="Self-Attn Output\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep13_tp1_sa_qkv -> layer_8_ep13_tp1_sa_attn
	layer_8_ep13_tp1_sa_attn -> layer_8_ep13_tp1_sa_out
	layer_8_ep13_tp2_sa_qkv [label="Self-Attn QKV\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep13_tp2_sa_attn [label="Self-Attn Compute\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep13_tp2_sa_out [label="Self-Attn Output\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep13_tp2_sa_qkv -> layer_8_ep13_tp2_sa_attn
	layer_8_ep13_tp2_sa_attn -> layer_8_ep13_tp2_sa_out
	layer_8_ep13_tp3_sa_qkv [label="Self-Attn QKV\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep13_tp3_sa_attn [label="Self-Attn Compute\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep13_tp3_sa_out [label="Self-Attn Output\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep13_tp3_sa_qkv -> layer_8_ep13_tp3_sa_attn
	layer_8_ep13_tp3_sa_attn -> layer_8_ep13_tp3_sa_out
	layer_8_ep14_tp0_sa_qkv [label="Self-Attn QKV\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep14_tp0_sa_attn [label="Self-Attn Compute\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep14_tp0_sa_out [label="Self-Attn Output\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep14_tp0_sa_qkv -> layer_8_ep14_tp0_sa_attn
	layer_8_ep14_tp0_sa_attn -> layer_8_ep14_tp0_sa_out
	layer_8_ep14_tp1_sa_qkv [label="Self-Attn QKV\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep14_tp1_sa_attn [label="Self-Attn Compute\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep14_tp1_sa_out [label="Self-Attn Output\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep14_tp1_sa_qkv -> layer_8_ep14_tp1_sa_attn
	layer_8_ep14_tp1_sa_attn -> layer_8_ep14_tp1_sa_out
	layer_8_ep14_tp2_sa_qkv [label="Self-Attn QKV\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep14_tp2_sa_attn [label="Self-Attn Compute\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep14_tp2_sa_out [label="Self-Attn Output\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep14_tp2_sa_qkv -> layer_8_ep14_tp2_sa_attn
	layer_8_ep14_tp2_sa_attn -> layer_8_ep14_tp2_sa_out
	layer_8_ep14_tp3_sa_qkv [label="Self-Attn QKV\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep14_tp3_sa_attn [label="Self-Attn Compute\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep14_tp3_sa_out [label="Self-Attn Output\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep14_tp3_sa_qkv -> layer_8_ep14_tp3_sa_attn
	layer_8_ep14_tp3_sa_attn -> layer_8_ep14_tp3_sa_out
	layer_8_ep15_tp0_sa_qkv [label="Self-Attn QKV\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep15_tp0_sa_attn [label="Self-Attn Compute\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep15_tp0_sa_out [label="Self-Attn Output\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep15_tp0_sa_qkv -> layer_8_ep15_tp0_sa_attn
	layer_8_ep15_tp0_sa_attn -> layer_8_ep15_tp0_sa_out
	layer_8_ep15_tp1_sa_qkv [label="Self-Attn QKV\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep15_tp1_sa_attn [label="Self-Attn Compute\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep15_tp1_sa_out [label="Self-Attn Output\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep15_tp1_sa_qkv -> layer_8_ep15_tp1_sa_attn
	layer_8_ep15_tp1_sa_attn -> layer_8_ep15_tp1_sa_out
	layer_8_ep15_tp2_sa_qkv [label="Self-Attn QKV\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep15_tp2_sa_attn [label="Self-Attn Compute\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep15_tp2_sa_out [label="Self-Attn Output\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep15_tp2_sa_qkv -> layer_8_ep15_tp2_sa_attn
	layer_8_ep15_tp2_sa_attn -> layer_8_ep15_tp2_sa_out
	layer_8_ep15_tp3_sa_qkv [label="Self-Attn QKV\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep15_tp3_sa_attn [label="Self-Attn Compute\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep15_tp3_sa_out [label="Self-Attn Output\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep15_tp3_sa_qkv -> layer_8_ep15_tp3_sa_attn
	layer_8_ep15_tp3_sa_attn -> layer_8_ep15_tp3_sa_out
	layer_8_ep0_tp_allreduce [label="TP All-Reduce\nEP-Group-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_8_ep0_tp0_sa_out -> layer_8_ep0_tp_allreduce
	layer_8_ep0_tp1_sa_out -> layer_8_ep0_tp_allreduce
	layer_8_ep0_tp2_sa_out -> layer_8_ep0_tp_allreduce
	layer_8_ep0_tp3_sa_out -> layer_8_ep0_tp_allreduce
	layer_8_ep1_tp_allreduce [label="TP All-Reduce\nEP-Group-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_8_ep1_tp0_sa_out -> layer_8_ep1_tp_allreduce
	layer_8_ep1_tp1_sa_out -> layer_8_ep1_tp_allreduce
	layer_8_ep1_tp2_sa_out -> layer_8_ep1_tp_allreduce
	layer_8_ep1_tp3_sa_out -> layer_8_ep1_tp_allreduce
	layer_8_ep2_tp_allreduce [label="TP All-Reduce\nEP-Group-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_8_ep2_tp0_sa_out -> layer_8_ep2_tp_allreduce
	layer_8_ep2_tp1_sa_out -> layer_8_ep2_tp_allreduce
	layer_8_ep2_tp2_sa_out -> layer_8_ep2_tp_allreduce
	layer_8_ep2_tp3_sa_out -> layer_8_ep2_tp_allreduce
	layer_8_ep3_tp_allreduce [label="TP All-Reduce\nEP-Group-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_8_ep3_tp0_sa_out -> layer_8_ep3_tp_allreduce
	layer_8_ep3_tp1_sa_out -> layer_8_ep3_tp_allreduce
	layer_8_ep3_tp2_sa_out -> layer_8_ep3_tp_allreduce
	layer_8_ep3_tp3_sa_out -> layer_8_ep3_tp_allreduce
	layer_8_ep4_tp_allreduce [label="TP All-Reduce\nEP-Group-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_8_ep4_tp0_sa_out -> layer_8_ep4_tp_allreduce
	layer_8_ep4_tp1_sa_out -> layer_8_ep4_tp_allreduce
	layer_8_ep4_tp2_sa_out -> layer_8_ep4_tp_allreduce
	layer_8_ep4_tp3_sa_out -> layer_8_ep4_tp_allreduce
	layer_8_ep5_tp_allreduce [label="TP All-Reduce\nEP-Group-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_8_ep5_tp0_sa_out -> layer_8_ep5_tp_allreduce
	layer_8_ep5_tp1_sa_out -> layer_8_ep5_tp_allreduce
	layer_8_ep5_tp2_sa_out -> layer_8_ep5_tp_allreduce
	layer_8_ep5_tp3_sa_out -> layer_8_ep5_tp_allreduce
	layer_8_ep6_tp_allreduce [label="TP All-Reduce\nEP-Group-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_8_ep6_tp0_sa_out -> layer_8_ep6_tp_allreduce
	layer_8_ep6_tp1_sa_out -> layer_8_ep6_tp_allreduce
	layer_8_ep6_tp2_sa_out -> layer_8_ep6_tp_allreduce
	layer_8_ep6_tp3_sa_out -> layer_8_ep6_tp_allreduce
	layer_8_ep7_tp_allreduce [label="TP All-Reduce\nEP-Group-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_8_ep7_tp0_sa_out -> layer_8_ep7_tp_allreduce
	layer_8_ep7_tp1_sa_out -> layer_8_ep7_tp_allreduce
	layer_8_ep7_tp2_sa_out -> layer_8_ep7_tp_allreduce
	layer_8_ep7_tp3_sa_out -> layer_8_ep7_tp_allreduce
	layer_8_ep8_tp_allreduce [label="TP All-Reduce\nEP-Group-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_8_ep8_tp0_sa_out -> layer_8_ep8_tp_allreduce
	layer_8_ep8_tp1_sa_out -> layer_8_ep8_tp_allreduce
	layer_8_ep8_tp2_sa_out -> layer_8_ep8_tp_allreduce
	layer_8_ep8_tp3_sa_out -> layer_8_ep8_tp_allreduce
	layer_8_ep9_tp_allreduce [label="TP All-Reduce\nEP-Group-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_8_ep9_tp0_sa_out -> layer_8_ep9_tp_allreduce
	layer_8_ep9_tp1_sa_out -> layer_8_ep9_tp_allreduce
	layer_8_ep9_tp2_sa_out -> layer_8_ep9_tp_allreduce
	layer_8_ep9_tp3_sa_out -> layer_8_ep9_tp_allreduce
	layer_8_ep10_tp_allreduce [label="TP All-Reduce\nEP-Group-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_8_ep10_tp0_sa_out -> layer_8_ep10_tp_allreduce
	layer_8_ep10_tp1_sa_out -> layer_8_ep10_tp_allreduce
	layer_8_ep10_tp2_sa_out -> layer_8_ep10_tp_allreduce
	layer_8_ep10_tp3_sa_out -> layer_8_ep10_tp_allreduce
	layer_8_ep11_tp_allreduce [label="TP All-Reduce\nEP-Group-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_8_ep11_tp0_sa_out -> layer_8_ep11_tp_allreduce
	layer_8_ep11_tp1_sa_out -> layer_8_ep11_tp_allreduce
	layer_8_ep11_tp2_sa_out -> layer_8_ep11_tp_allreduce
	layer_8_ep11_tp3_sa_out -> layer_8_ep11_tp_allreduce
	layer_8_ep12_tp_allreduce [label="TP All-Reduce\nEP-Group-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_8_ep12_tp0_sa_out -> layer_8_ep12_tp_allreduce
	layer_8_ep12_tp1_sa_out -> layer_8_ep12_tp_allreduce
	layer_8_ep12_tp2_sa_out -> layer_8_ep12_tp_allreduce
	layer_8_ep12_tp3_sa_out -> layer_8_ep12_tp_allreduce
	layer_8_ep13_tp_allreduce [label="TP All-Reduce\nEP-Group-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_8_ep13_tp0_sa_out -> layer_8_ep13_tp_allreduce
	layer_8_ep13_tp1_sa_out -> layer_8_ep13_tp_allreduce
	layer_8_ep13_tp2_sa_out -> layer_8_ep13_tp_allreduce
	layer_8_ep13_tp3_sa_out -> layer_8_ep13_tp_allreduce
	layer_8_ep14_tp_allreduce [label="TP All-Reduce\nEP-Group-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_8_ep14_tp0_sa_out -> layer_8_ep14_tp_allreduce
	layer_8_ep14_tp1_sa_out -> layer_8_ep14_tp_allreduce
	layer_8_ep14_tp2_sa_out -> layer_8_ep14_tp_allreduce
	layer_8_ep14_tp3_sa_out -> layer_8_ep14_tp_allreduce
	layer_8_ep15_tp_allreduce [label="TP All-Reduce\nEP-Group-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_8_ep15_tp0_sa_out -> layer_8_ep15_tp_allreduce
	layer_8_ep15_tp1_sa_out -> layer_8_ep15_tp_allreduce
	layer_8_ep15_tp2_sa_out -> layer_8_ep15_tp_allreduce
	layer_8_ep15_tp3_sa_out -> layer_8_ep15_tp_allreduce
	layer_8_ep0_gate [label="MoE Gate\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_8_ep0_expert_0 [label="Expert-0\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep0_gate -> layer_8_ep0_expert_0 [label="select tokens" style=dashed]
	layer_8_ep0_expert_1 [label="Expert-1\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep0_gate -> layer_8_ep0_expert_1 [label="select tokens" style=dashed]
	layer_8_ep0_expert_2 [label="Expert-2\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep0_gate -> layer_8_ep0_expert_2 [label="select tokens" style=dashed]
	layer_8_ep0_expert_3 [label="Expert-3\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep0_gate -> layer_8_ep0_expert_3 [label="select tokens" style=dashed]
	layer_8_ep0_expert_aggr [label="Expert Aggregation\nEP-Group-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_8_ep0_expert_0 -> layer_8_ep0_expert_aggr
	layer_8_ep0_expert_1 -> layer_8_ep0_expert_aggr
	layer_8_ep0_expert_2 -> layer_8_ep0_expert_aggr
	layer_8_ep0_expert_3 -> layer_8_ep0_expert_aggr
	layer_8_ep1_gate [label="MoE Gate\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_8_ep1_expert_0 [label="Expert-0\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep1_gate -> layer_8_ep1_expert_0 [label="select tokens" style=dashed]
	layer_8_ep1_expert_1 [label="Expert-1\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep1_gate -> layer_8_ep1_expert_1 [label="select tokens" style=dashed]
	layer_8_ep1_expert_2 [label="Expert-2\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep1_gate -> layer_8_ep1_expert_2 [label="select tokens" style=dashed]
	layer_8_ep1_expert_3 [label="Expert-3\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep1_gate -> layer_8_ep1_expert_3 [label="select tokens" style=dashed]
	layer_8_ep1_expert_aggr [label="Expert Aggregation\nEP-Group-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_8_ep1_expert_0 -> layer_8_ep1_expert_aggr
	layer_8_ep1_expert_1 -> layer_8_ep1_expert_aggr
	layer_8_ep1_expert_2 -> layer_8_ep1_expert_aggr
	layer_8_ep1_expert_3 -> layer_8_ep1_expert_aggr
	layer_8_ep2_gate [label="MoE Gate\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_8_ep2_expert_0 [label="Expert-0\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep2_gate -> layer_8_ep2_expert_0 [label="select tokens" style=dashed]
	layer_8_ep2_expert_1 [label="Expert-1\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep2_gate -> layer_8_ep2_expert_1 [label="select tokens" style=dashed]
	layer_8_ep2_expert_2 [label="Expert-2\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep2_gate -> layer_8_ep2_expert_2 [label="select tokens" style=dashed]
	layer_8_ep2_expert_3 [label="Expert-3\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep2_gate -> layer_8_ep2_expert_3 [label="select tokens" style=dashed]
	layer_8_ep2_expert_aggr [label="Expert Aggregation\nEP-Group-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_8_ep2_expert_0 -> layer_8_ep2_expert_aggr
	layer_8_ep2_expert_1 -> layer_8_ep2_expert_aggr
	layer_8_ep2_expert_2 -> layer_8_ep2_expert_aggr
	layer_8_ep2_expert_3 -> layer_8_ep2_expert_aggr
	layer_8_ep3_gate [label="MoE Gate\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_8_ep3_expert_0 [label="Expert-0\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep3_gate -> layer_8_ep3_expert_0 [label="select tokens" style=dashed]
	layer_8_ep3_expert_1 [label="Expert-1\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep3_gate -> layer_8_ep3_expert_1 [label="select tokens" style=dashed]
	layer_8_ep3_expert_2 [label="Expert-2\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep3_gate -> layer_8_ep3_expert_2 [label="select tokens" style=dashed]
	layer_8_ep3_expert_3 [label="Expert-3\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep3_gate -> layer_8_ep3_expert_3 [label="select tokens" style=dashed]
	layer_8_ep3_expert_aggr [label="Expert Aggregation\nEP-Group-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_8_ep3_expert_0 -> layer_8_ep3_expert_aggr
	layer_8_ep3_expert_1 -> layer_8_ep3_expert_aggr
	layer_8_ep3_expert_2 -> layer_8_ep3_expert_aggr
	layer_8_ep3_expert_3 -> layer_8_ep3_expert_aggr
	layer_8_ep4_gate [label="MoE Gate\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_8_ep4_expert_0 [label="Expert-0\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep4_gate -> layer_8_ep4_expert_0 [label="select tokens" style=dashed]
	layer_8_ep4_expert_1 [label="Expert-1\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep4_gate -> layer_8_ep4_expert_1 [label="select tokens" style=dashed]
	layer_8_ep4_expert_2 [label="Expert-2\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep4_gate -> layer_8_ep4_expert_2 [label="select tokens" style=dashed]
	layer_8_ep4_expert_3 [label="Expert-3\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep4_gate -> layer_8_ep4_expert_3 [label="select tokens" style=dashed]
	layer_8_ep4_expert_aggr [label="Expert Aggregation\nEP-Group-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_8_ep4_expert_0 -> layer_8_ep4_expert_aggr
	layer_8_ep4_expert_1 -> layer_8_ep4_expert_aggr
	layer_8_ep4_expert_2 -> layer_8_ep4_expert_aggr
	layer_8_ep4_expert_3 -> layer_8_ep4_expert_aggr
	layer_8_ep5_gate [label="MoE Gate\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_8_ep5_expert_0 [label="Expert-0\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep5_gate -> layer_8_ep5_expert_0 [label="select tokens" style=dashed]
	layer_8_ep5_expert_1 [label="Expert-1\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep5_gate -> layer_8_ep5_expert_1 [label="select tokens" style=dashed]
	layer_8_ep5_expert_2 [label="Expert-2\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep5_gate -> layer_8_ep5_expert_2 [label="select tokens" style=dashed]
	layer_8_ep5_expert_3 [label="Expert-3\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep5_gate -> layer_8_ep5_expert_3 [label="select tokens" style=dashed]
	layer_8_ep5_expert_aggr [label="Expert Aggregation\nEP-Group-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_8_ep5_expert_0 -> layer_8_ep5_expert_aggr
	layer_8_ep5_expert_1 -> layer_8_ep5_expert_aggr
	layer_8_ep5_expert_2 -> layer_8_ep5_expert_aggr
	layer_8_ep5_expert_3 -> layer_8_ep5_expert_aggr
	layer_8_ep6_gate [label="MoE Gate\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_8_ep6_expert_0 [label="Expert-0\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep6_gate -> layer_8_ep6_expert_0 [label="select tokens" style=dashed]
	layer_8_ep6_expert_1 [label="Expert-1\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep6_gate -> layer_8_ep6_expert_1 [label="select tokens" style=dashed]
	layer_8_ep6_expert_2 [label="Expert-2\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep6_gate -> layer_8_ep6_expert_2 [label="select tokens" style=dashed]
	layer_8_ep6_expert_3 [label="Expert-3\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep6_gate -> layer_8_ep6_expert_3 [label="select tokens" style=dashed]
	layer_8_ep6_expert_aggr [label="Expert Aggregation\nEP-Group-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_8_ep6_expert_0 -> layer_8_ep6_expert_aggr
	layer_8_ep6_expert_1 -> layer_8_ep6_expert_aggr
	layer_8_ep6_expert_2 -> layer_8_ep6_expert_aggr
	layer_8_ep6_expert_3 -> layer_8_ep6_expert_aggr
	layer_8_ep7_gate [label="MoE Gate\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_8_ep7_expert_0 [label="Expert-0\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep7_gate -> layer_8_ep7_expert_0 [label="select tokens" style=dashed]
	layer_8_ep7_expert_1 [label="Expert-1\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep7_gate -> layer_8_ep7_expert_1 [label="select tokens" style=dashed]
	layer_8_ep7_expert_2 [label="Expert-2\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep7_gate -> layer_8_ep7_expert_2 [label="select tokens" style=dashed]
	layer_8_ep7_expert_3 [label="Expert-3\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep7_gate -> layer_8_ep7_expert_3 [label="select tokens" style=dashed]
	layer_8_ep7_expert_aggr [label="Expert Aggregation\nEP-Group-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_8_ep7_expert_0 -> layer_8_ep7_expert_aggr
	layer_8_ep7_expert_1 -> layer_8_ep7_expert_aggr
	layer_8_ep7_expert_2 -> layer_8_ep7_expert_aggr
	layer_8_ep7_expert_3 -> layer_8_ep7_expert_aggr
	layer_8_ep8_gate [label="MoE Gate\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_8_ep8_expert_0 [label="Expert-0\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep8_gate -> layer_8_ep8_expert_0 [label="select tokens" style=dashed]
	layer_8_ep8_expert_1 [label="Expert-1\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep8_gate -> layer_8_ep8_expert_1 [label="select tokens" style=dashed]
	layer_8_ep8_expert_2 [label="Expert-2\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep8_gate -> layer_8_ep8_expert_2 [label="select tokens" style=dashed]
	layer_8_ep8_expert_3 [label="Expert-3\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep8_gate -> layer_8_ep8_expert_3 [label="select tokens" style=dashed]
	layer_8_ep8_expert_aggr [label="Expert Aggregation\nEP-Group-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_8_ep8_expert_0 -> layer_8_ep8_expert_aggr
	layer_8_ep8_expert_1 -> layer_8_ep8_expert_aggr
	layer_8_ep8_expert_2 -> layer_8_ep8_expert_aggr
	layer_8_ep8_expert_3 -> layer_8_ep8_expert_aggr
	layer_8_ep9_gate [label="MoE Gate\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_8_ep9_expert_0 [label="Expert-0\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep9_gate -> layer_8_ep9_expert_0 [label="select tokens" style=dashed]
	layer_8_ep9_expert_1 [label="Expert-1\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep9_gate -> layer_8_ep9_expert_1 [label="select tokens" style=dashed]
	layer_8_ep9_expert_2 [label="Expert-2\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep9_gate -> layer_8_ep9_expert_2 [label="select tokens" style=dashed]
	layer_8_ep9_expert_3 [label="Expert-3\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep9_gate -> layer_8_ep9_expert_3 [label="select tokens" style=dashed]
	layer_8_ep9_expert_aggr [label="Expert Aggregation\nEP-Group-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_8_ep9_expert_0 -> layer_8_ep9_expert_aggr
	layer_8_ep9_expert_1 -> layer_8_ep9_expert_aggr
	layer_8_ep9_expert_2 -> layer_8_ep9_expert_aggr
	layer_8_ep9_expert_3 -> layer_8_ep9_expert_aggr
	layer_8_ep10_gate [label="MoE Gate\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_8_ep10_expert_0 [label="Expert-0\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep10_gate -> layer_8_ep10_expert_0 [label="select tokens" style=dashed]
	layer_8_ep10_expert_1 [label="Expert-1\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep10_gate -> layer_8_ep10_expert_1 [label="select tokens" style=dashed]
	layer_8_ep10_expert_2 [label="Expert-2\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep10_gate -> layer_8_ep10_expert_2 [label="select tokens" style=dashed]
	layer_8_ep10_expert_3 [label="Expert-3\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep10_gate -> layer_8_ep10_expert_3 [label="select tokens" style=dashed]
	layer_8_ep10_expert_aggr [label="Expert Aggregation\nEP-Group-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_8_ep10_expert_0 -> layer_8_ep10_expert_aggr
	layer_8_ep10_expert_1 -> layer_8_ep10_expert_aggr
	layer_8_ep10_expert_2 -> layer_8_ep10_expert_aggr
	layer_8_ep10_expert_3 -> layer_8_ep10_expert_aggr
	layer_8_ep11_gate [label="MoE Gate\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_8_ep11_expert_0 [label="Expert-0\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep11_gate -> layer_8_ep11_expert_0 [label="select tokens" style=dashed]
	layer_8_ep11_expert_1 [label="Expert-1\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep11_gate -> layer_8_ep11_expert_1 [label="select tokens" style=dashed]
	layer_8_ep11_expert_2 [label="Expert-2\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep11_gate -> layer_8_ep11_expert_2 [label="select tokens" style=dashed]
	layer_8_ep11_expert_3 [label="Expert-3\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep11_gate -> layer_8_ep11_expert_3 [label="select tokens" style=dashed]
	layer_8_ep11_expert_aggr [label="Expert Aggregation\nEP-Group-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_8_ep11_expert_0 -> layer_8_ep11_expert_aggr
	layer_8_ep11_expert_1 -> layer_8_ep11_expert_aggr
	layer_8_ep11_expert_2 -> layer_8_ep11_expert_aggr
	layer_8_ep11_expert_3 -> layer_8_ep11_expert_aggr
	layer_8_ep12_gate [label="MoE Gate\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_8_ep12_expert_0 [label="Expert-0\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep12_gate -> layer_8_ep12_expert_0 [label="select tokens" style=dashed]
	layer_8_ep12_expert_1 [label="Expert-1\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep12_gate -> layer_8_ep12_expert_1 [label="select tokens" style=dashed]
	layer_8_ep12_expert_2 [label="Expert-2\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep12_gate -> layer_8_ep12_expert_2 [label="select tokens" style=dashed]
	layer_8_ep12_expert_3 [label="Expert-3\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep12_gate -> layer_8_ep12_expert_3 [label="select tokens" style=dashed]
	layer_8_ep12_expert_aggr [label="Expert Aggregation\nEP-Group-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_8_ep12_expert_0 -> layer_8_ep12_expert_aggr
	layer_8_ep12_expert_1 -> layer_8_ep12_expert_aggr
	layer_8_ep12_expert_2 -> layer_8_ep12_expert_aggr
	layer_8_ep12_expert_3 -> layer_8_ep12_expert_aggr
	layer_8_ep13_gate [label="MoE Gate\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_8_ep13_expert_0 [label="Expert-0\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep13_gate -> layer_8_ep13_expert_0 [label="select tokens" style=dashed]
	layer_8_ep13_expert_1 [label="Expert-1\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep13_gate -> layer_8_ep13_expert_1 [label="select tokens" style=dashed]
	layer_8_ep13_expert_2 [label="Expert-2\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep13_gate -> layer_8_ep13_expert_2 [label="select tokens" style=dashed]
	layer_8_ep13_expert_3 [label="Expert-3\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep13_gate -> layer_8_ep13_expert_3 [label="select tokens" style=dashed]
	layer_8_ep13_expert_aggr [label="Expert Aggregation\nEP-Group-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_8_ep13_expert_0 -> layer_8_ep13_expert_aggr
	layer_8_ep13_expert_1 -> layer_8_ep13_expert_aggr
	layer_8_ep13_expert_2 -> layer_8_ep13_expert_aggr
	layer_8_ep13_expert_3 -> layer_8_ep13_expert_aggr
	layer_8_ep14_gate [label="MoE Gate\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_8_ep14_expert_0 [label="Expert-0\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep14_gate -> layer_8_ep14_expert_0 [label="select tokens" style=dashed]
	layer_8_ep14_expert_1 [label="Expert-1\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep14_gate -> layer_8_ep14_expert_1 [label="select tokens" style=dashed]
	layer_8_ep14_expert_2 [label="Expert-2\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep14_gate -> layer_8_ep14_expert_2 [label="select tokens" style=dashed]
	layer_8_ep14_expert_3 [label="Expert-3\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep14_gate -> layer_8_ep14_expert_3 [label="select tokens" style=dashed]
	layer_8_ep14_expert_aggr [label="Expert Aggregation\nEP-Group-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_8_ep14_expert_0 -> layer_8_ep14_expert_aggr
	layer_8_ep14_expert_1 -> layer_8_ep14_expert_aggr
	layer_8_ep14_expert_2 -> layer_8_ep14_expert_aggr
	layer_8_ep14_expert_3 -> layer_8_ep14_expert_aggr
	layer_8_ep15_gate [label="MoE Gate\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_8_ep15_expert_0 [label="Expert-0\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep15_gate -> layer_8_ep15_expert_0 [label="select tokens" style=dashed]
	layer_8_ep15_expert_1 [label="Expert-1\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep15_gate -> layer_8_ep15_expert_1 [label="select tokens" style=dashed]
	layer_8_ep15_expert_2 [label="Expert-2\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep15_gate -> layer_8_ep15_expert_2 [label="select tokens" style=dashed]
	layer_8_ep15_expert_3 [label="Expert-3\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_8_ep15_gate -> layer_8_ep15_expert_3 [label="select tokens" style=dashed]
	layer_8_ep15_expert_aggr [label="Expert Aggregation\nEP-Group-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_8_ep15_expert_0 -> layer_8_ep15_expert_aggr
	layer_8_ep15_expert_1 -> layer_8_ep15_expert_aggr
	layer_8_ep15_expert_2 -> layer_8_ep15_expert_aggr
	layer_8_ep15_expert_3 -> layer_8_ep15_expert_aggr
	layer_8_to_9_ep0_pp [label="Pipeline Stage Transfer\nEP-Group-0\nLayer-8 to Layer-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_8_ep0_expert_aggr -> layer_8_to_9_ep0_pp
	layer_8_to_9_ep1_pp [label="Pipeline Stage Transfer\nEP-Group-1\nLayer-8 to Layer-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_8_ep1_expert_aggr -> layer_8_to_9_ep1_pp
	layer_8_to_9_ep2_pp [label="Pipeline Stage Transfer\nEP-Group-2\nLayer-8 to Layer-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_8_ep2_expert_aggr -> layer_8_to_9_ep2_pp
	layer_8_to_9_ep3_pp [label="Pipeline Stage Transfer\nEP-Group-3\nLayer-8 to Layer-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_8_ep3_expert_aggr -> layer_8_to_9_ep3_pp
	layer_8_to_9_ep4_pp [label="Pipeline Stage Transfer\nEP-Group-4\nLayer-8 to Layer-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_8_ep4_expert_aggr -> layer_8_to_9_ep4_pp
	layer_8_to_9_ep5_pp [label="Pipeline Stage Transfer\nEP-Group-5\nLayer-8 to Layer-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_8_ep5_expert_aggr -> layer_8_to_9_ep5_pp
	layer_8_to_9_ep6_pp [label="Pipeline Stage Transfer\nEP-Group-6\nLayer-8 to Layer-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_8_ep6_expert_aggr -> layer_8_to_9_ep6_pp
	layer_8_to_9_ep7_pp [label="Pipeline Stage Transfer\nEP-Group-7\nLayer-8 to Layer-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_8_ep7_expert_aggr -> layer_8_to_9_ep7_pp
	layer_8_to_9_ep8_pp [label="Pipeline Stage Transfer\nEP-Group-8\nLayer-8 to Layer-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_8_ep8_expert_aggr -> layer_8_to_9_ep8_pp
	layer_8_to_9_ep9_pp [label="Pipeline Stage Transfer\nEP-Group-9\nLayer-8 to Layer-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_8_ep9_expert_aggr -> layer_8_to_9_ep9_pp
	layer_8_to_9_ep10_pp [label="Pipeline Stage Transfer\nEP-Group-10\nLayer-8 to Layer-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_8_ep10_expert_aggr -> layer_8_to_9_ep10_pp
	layer_8_to_9_ep11_pp [label="Pipeline Stage Transfer\nEP-Group-11\nLayer-8 to Layer-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_8_ep11_expert_aggr -> layer_8_to_9_ep11_pp
	layer_8_to_9_ep12_pp [label="Pipeline Stage Transfer\nEP-Group-12\nLayer-8 to Layer-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_8_ep12_expert_aggr -> layer_8_to_9_ep12_pp
	layer_8_to_9_ep13_pp [label="Pipeline Stage Transfer\nEP-Group-13\nLayer-8 to Layer-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_8_ep13_expert_aggr -> layer_8_to_9_ep13_pp
	layer_8_to_9_ep14_pp [label="Pipeline Stage Transfer\nEP-Group-14\nLayer-8 to Layer-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_8_ep14_expert_aggr -> layer_8_to_9_ep14_pp
	layer_8_to_9_ep15_pp [label="Pipeline Stage Transfer\nEP-Group-15\nLayer-8 to Layer-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_8_ep15_expert_aggr -> layer_8_to_9_ep15_pp
	layer_9_ep0_tp0_sa_qkv [label="Self-Attn QKV\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep0_tp0_sa_attn [label="Self-Attn Compute\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep0_tp0_sa_out [label="Self-Attn Output\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep0_tp0_sa_qkv -> layer_9_ep0_tp0_sa_attn
	layer_9_ep0_tp0_sa_attn -> layer_9_ep0_tp0_sa_out
	layer_9_ep0_tp1_sa_qkv [label="Self-Attn QKV\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep0_tp1_sa_attn [label="Self-Attn Compute\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep0_tp1_sa_out [label="Self-Attn Output\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep0_tp1_sa_qkv -> layer_9_ep0_tp1_sa_attn
	layer_9_ep0_tp1_sa_attn -> layer_9_ep0_tp1_sa_out
	layer_9_ep0_tp2_sa_qkv [label="Self-Attn QKV\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep0_tp2_sa_attn [label="Self-Attn Compute\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep0_tp2_sa_out [label="Self-Attn Output\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep0_tp2_sa_qkv -> layer_9_ep0_tp2_sa_attn
	layer_9_ep0_tp2_sa_attn -> layer_9_ep0_tp2_sa_out
	layer_9_ep0_tp3_sa_qkv [label="Self-Attn QKV\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep0_tp3_sa_attn [label="Self-Attn Compute\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep0_tp3_sa_out [label="Self-Attn Output\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep0_tp3_sa_qkv -> layer_9_ep0_tp3_sa_attn
	layer_9_ep0_tp3_sa_attn -> layer_9_ep0_tp3_sa_out
	layer_9_ep1_tp0_sa_qkv [label="Self-Attn QKV\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep1_tp0_sa_attn [label="Self-Attn Compute\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep1_tp0_sa_out [label="Self-Attn Output\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep1_tp0_sa_qkv -> layer_9_ep1_tp0_sa_attn
	layer_9_ep1_tp0_sa_attn -> layer_9_ep1_tp0_sa_out
	layer_9_ep1_tp1_sa_qkv [label="Self-Attn QKV\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep1_tp1_sa_attn [label="Self-Attn Compute\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep1_tp1_sa_out [label="Self-Attn Output\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep1_tp1_sa_qkv -> layer_9_ep1_tp1_sa_attn
	layer_9_ep1_tp1_sa_attn -> layer_9_ep1_tp1_sa_out
	layer_9_ep1_tp2_sa_qkv [label="Self-Attn QKV\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep1_tp2_sa_attn [label="Self-Attn Compute\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep1_tp2_sa_out [label="Self-Attn Output\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep1_tp2_sa_qkv -> layer_9_ep1_tp2_sa_attn
	layer_9_ep1_tp2_sa_attn -> layer_9_ep1_tp2_sa_out
	layer_9_ep1_tp3_sa_qkv [label="Self-Attn QKV\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep1_tp3_sa_attn [label="Self-Attn Compute\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep1_tp3_sa_out [label="Self-Attn Output\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep1_tp3_sa_qkv -> layer_9_ep1_tp3_sa_attn
	layer_9_ep1_tp3_sa_attn -> layer_9_ep1_tp3_sa_out
	layer_9_ep2_tp0_sa_qkv [label="Self-Attn QKV\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep2_tp0_sa_attn [label="Self-Attn Compute\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep2_tp0_sa_out [label="Self-Attn Output\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep2_tp0_sa_qkv -> layer_9_ep2_tp0_sa_attn
	layer_9_ep2_tp0_sa_attn -> layer_9_ep2_tp0_sa_out
	layer_9_ep2_tp1_sa_qkv [label="Self-Attn QKV\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep2_tp1_sa_attn [label="Self-Attn Compute\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep2_tp1_sa_out [label="Self-Attn Output\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep2_tp1_sa_qkv -> layer_9_ep2_tp1_sa_attn
	layer_9_ep2_tp1_sa_attn -> layer_9_ep2_tp1_sa_out
	layer_9_ep2_tp2_sa_qkv [label="Self-Attn QKV\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep2_tp2_sa_attn [label="Self-Attn Compute\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep2_tp2_sa_out [label="Self-Attn Output\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep2_tp2_sa_qkv -> layer_9_ep2_tp2_sa_attn
	layer_9_ep2_tp2_sa_attn -> layer_9_ep2_tp2_sa_out
	layer_9_ep2_tp3_sa_qkv [label="Self-Attn QKV\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep2_tp3_sa_attn [label="Self-Attn Compute\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep2_tp3_sa_out [label="Self-Attn Output\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep2_tp3_sa_qkv -> layer_9_ep2_tp3_sa_attn
	layer_9_ep2_tp3_sa_attn -> layer_9_ep2_tp3_sa_out
	layer_9_ep3_tp0_sa_qkv [label="Self-Attn QKV\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep3_tp0_sa_attn [label="Self-Attn Compute\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep3_tp0_sa_out [label="Self-Attn Output\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep3_tp0_sa_qkv -> layer_9_ep3_tp0_sa_attn
	layer_9_ep3_tp0_sa_attn -> layer_9_ep3_tp0_sa_out
	layer_9_ep3_tp1_sa_qkv [label="Self-Attn QKV\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep3_tp1_sa_attn [label="Self-Attn Compute\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep3_tp1_sa_out [label="Self-Attn Output\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep3_tp1_sa_qkv -> layer_9_ep3_tp1_sa_attn
	layer_9_ep3_tp1_sa_attn -> layer_9_ep3_tp1_sa_out
	layer_9_ep3_tp2_sa_qkv [label="Self-Attn QKV\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep3_tp2_sa_attn [label="Self-Attn Compute\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep3_tp2_sa_out [label="Self-Attn Output\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep3_tp2_sa_qkv -> layer_9_ep3_tp2_sa_attn
	layer_9_ep3_tp2_sa_attn -> layer_9_ep3_tp2_sa_out
	layer_9_ep3_tp3_sa_qkv [label="Self-Attn QKV\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep3_tp3_sa_attn [label="Self-Attn Compute\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep3_tp3_sa_out [label="Self-Attn Output\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep3_tp3_sa_qkv -> layer_9_ep3_tp3_sa_attn
	layer_9_ep3_tp3_sa_attn -> layer_9_ep3_tp3_sa_out
	layer_9_ep4_tp0_sa_qkv [label="Self-Attn QKV\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep4_tp0_sa_attn [label="Self-Attn Compute\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep4_tp0_sa_out [label="Self-Attn Output\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep4_tp0_sa_qkv -> layer_9_ep4_tp0_sa_attn
	layer_9_ep4_tp0_sa_attn -> layer_9_ep4_tp0_sa_out
	layer_9_ep4_tp1_sa_qkv [label="Self-Attn QKV\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep4_tp1_sa_attn [label="Self-Attn Compute\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep4_tp1_sa_out [label="Self-Attn Output\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep4_tp1_sa_qkv -> layer_9_ep4_tp1_sa_attn
	layer_9_ep4_tp1_sa_attn -> layer_9_ep4_tp1_sa_out
	layer_9_ep4_tp2_sa_qkv [label="Self-Attn QKV\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep4_tp2_sa_attn [label="Self-Attn Compute\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep4_tp2_sa_out [label="Self-Attn Output\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep4_tp2_sa_qkv -> layer_9_ep4_tp2_sa_attn
	layer_9_ep4_tp2_sa_attn -> layer_9_ep4_tp2_sa_out
	layer_9_ep4_tp3_sa_qkv [label="Self-Attn QKV\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep4_tp3_sa_attn [label="Self-Attn Compute\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep4_tp3_sa_out [label="Self-Attn Output\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep4_tp3_sa_qkv -> layer_9_ep4_tp3_sa_attn
	layer_9_ep4_tp3_sa_attn -> layer_9_ep4_tp3_sa_out
	layer_9_ep5_tp0_sa_qkv [label="Self-Attn QKV\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep5_tp0_sa_attn [label="Self-Attn Compute\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep5_tp0_sa_out [label="Self-Attn Output\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep5_tp0_sa_qkv -> layer_9_ep5_tp0_sa_attn
	layer_9_ep5_tp0_sa_attn -> layer_9_ep5_tp0_sa_out
	layer_9_ep5_tp1_sa_qkv [label="Self-Attn QKV\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep5_tp1_sa_attn [label="Self-Attn Compute\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep5_tp1_sa_out [label="Self-Attn Output\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep5_tp1_sa_qkv -> layer_9_ep5_tp1_sa_attn
	layer_9_ep5_tp1_sa_attn -> layer_9_ep5_tp1_sa_out
	layer_9_ep5_tp2_sa_qkv [label="Self-Attn QKV\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep5_tp2_sa_attn [label="Self-Attn Compute\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep5_tp2_sa_out [label="Self-Attn Output\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep5_tp2_sa_qkv -> layer_9_ep5_tp2_sa_attn
	layer_9_ep5_tp2_sa_attn -> layer_9_ep5_tp2_sa_out
	layer_9_ep5_tp3_sa_qkv [label="Self-Attn QKV\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep5_tp3_sa_attn [label="Self-Attn Compute\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep5_tp3_sa_out [label="Self-Attn Output\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep5_tp3_sa_qkv -> layer_9_ep5_tp3_sa_attn
	layer_9_ep5_tp3_sa_attn -> layer_9_ep5_tp3_sa_out
	layer_9_ep6_tp0_sa_qkv [label="Self-Attn QKV\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep6_tp0_sa_attn [label="Self-Attn Compute\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep6_tp0_sa_out [label="Self-Attn Output\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep6_tp0_sa_qkv -> layer_9_ep6_tp0_sa_attn
	layer_9_ep6_tp0_sa_attn -> layer_9_ep6_tp0_sa_out
	layer_9_ep6_tp1_sa_qkv [label="Self-Attn QKV\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep6_tp1_sa_attn [label="Self-Attn Compute\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep6_tp1_sa_out [label="Self-Attn Output\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep6_tp1_sa_qkv -> layer_9_ep6_tp1_sa_attn
	layer_9_ep6_tp1_sa_attn -> layer_9_ep6_tp1_sa_out
	layer_9_ep6_tp2_sa_qkv [label="Self-Attn QKV\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep6_tp2_sa_attn [label="Self-Attn Compute\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep6_tp2_sa_out [label="Self-Attn Output\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep6_tp2_sa_qkv -> layer_9_ep6_tp2_sa_attn
	layer_9_ep6_tp2_sa_attn -> layer_9_ep6_tp2_sa_out
	layer_9_ep6_tp3_sa_qkv [label="Self-Attn QKV\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep6_tp3_sa_attn [label="Self-Attn Compute\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep6_tp3_sa_out [label="Self-Attn Output\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep6_tp3_sa_qkv -> layer_9_ep6_tp3_sa_attn
	layer_9_ep6_tp3_sa_attn -> layer_9_ep6_tp3_sa_out
	layer_9_ep7_tp0_sa_qkv [label="Self-Attn QKV\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep7_tp0_sa_attn [label="Self-Attn Compute\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep7_tp0_sa_out [label="Self-Attn Output\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep7_tp0_sa_qkv -> layer_9_ep7_tp0_sa_attn
	layer_9_ep7_tp0_sa_attn -> layer_9_ep7_tp0_sa_out
	layer_9_ep7_tp1_sa_qkv [label="Self-Attn QKV\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep7_tp1_sa_attn [label="Self-Attn Compute\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep7_tp1_sa_out [label="Self-Attn Output\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep7_tp1_sa_qkv -> layer_9_ep7_tp1_sa_attn
	layer_9_ep7_tp1_sa_attn -> layer_9_ep7_tp1_sa_out
	layer_9_ep7_tp2_sa_qkv [label="Self-Attn QKV\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep7_tp2_sa_attn [label="Self-Attn Compute\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep7_tp2_sa_out [label="Self-Attn Output\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep7_tp2_sa_qkv -> layer_9_ep7_tp2_sa_attn
	layer_9_ep7_tp2_sa_attn -> layer_9_ep7_tp2_sa_out
	layer_9_ep7_tp3_sa_qkv [label="Self-Attn QKV\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep7_tp3_sa_attn [label="Self-Attn Compute\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep7_tp3_sa_out [label="Self-Attn Output\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep7_tp3_sa_qkv -> layer_9_ep7_tp3_sa_attn
	layer_9_ep7_tp3_sa_attn -> layer_9_ep7_tp3_sa_out
	layer_9_ep8_tp0_sa_qkv [label="Self-Attn QKV\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep8_tp0_sa_attn [label="Self-Attn Compute\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep8_tp0_sa_out [label="Self-Attn Output\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep8_tp0_sa_qkv -> layer_9_ep8_tp0_sa_attn
	layer_9_ep8_tp0_sa_attn -> layer_9_ep8_tp0_sa_out
	layer_9_ep8_tp1_sa_qkv [label="Self-Attn QKV\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep8_tp1_sa_attn [label="Self-Attn Compute\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep8_tp1_sa_out [label="Self-Attn Output\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep8_tp1_sa_qkv -> layer_9_ep8_tp1_sa_attn
	layer_9_ep8_tp1_sa_attn -> layer_9_ep8_tp1_sa_out
	layer_9_ep8_tp2_sa_qkv [label="Self-Attn QKV\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep8_tp2_sa_attn [label="Self-Attn Compute\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep8_tp2_sa_out [label="Self-Attn Output\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep8_tp2_sa_qkv -> layer_9_ep8_tp2_sa_attn
	layer_9_ep8_tp2_sa_attn -> layer_9_ep8_tp2_sa_out
	layer_9_ep8_tp3_sa_qkv [label="Self-Attn QKV\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep8_tp3_sa_attn [label="Self-Attn Compute\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep8_tp3_sa_out [label="Self-Attn Output\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep8_tp3_sa_qkv -> layer_9_ep8_tp3_sa_attn
	layer_9_ep8_tp3_sa_attn -> layer_9_ep8_tp3_sa_out
	layer_9_ep9_tp0_sa_qkv [label="Self-Attn QKV\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep9_tp0_sa_attn [label="Self-Attn Compute\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep9_tp0_sa_out [label="Self-Attn Output\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep9_tp0_sa_qkv -> layer_9_ep9_tp0_sa_attn
	layer_9_ep9_tp0_sa_attn -> layer_9_ep9_tp0_sa_out
	layer_9_ep9_tp1_sa_qkv [label="Self-Attn QKV\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep9_tp1_sa_attn [label="Self-Attn Compute\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep9_tp1_sa_out [label="Self-Attn Output\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep9_tp1_sa_qkv -> layer_9_ep9_tp1_sa_attn
	layer_9_ep9_tp1_sa_attn -> layer_9_ep9_tp1_sa_out
	layer_9_ep9_tp2_sa_qkv [label="Self-Attn QKV\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep9_tp2_sa_attn [label="Self-Attn Compute\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep9_tp2_sa_out [label="Self-Attn Output\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep9_tp2_sa_qkv -> layer_9_ep9_tp2_sa_attn
	layer_9_ep9_tp2_sa_attn -> layer_9_ep9_tp2_sa_out
	layer_9_ep9_tp3_sa_qkv [label="Self-Attn QKV\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep9_tp3_sa_attn [label="Self-Attn Compute\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep9_tp3_sa_out [label="Self-Attn Output\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep9_tp3_sa_qkv -> layer_9_ep9_tp3_sa_attn
	layer_9_ep9_tp3_sa_attn -> layer_9_ep9_tp3_sa_out
	layer_9_ep10_tp0_sa_qkv [label="Self-Attn QKV\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep10_tp0_sa_attn [label="Self-Attn Compute\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep10_tp0_sa_out [label="Self-Attn Output\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep10_tp0_sa_qkv -> layer_9_ep10_tp0_sa_attn
	layer_9_ep10_tp0_sa_attn -> layer_9_ep10_tp0_sa_out
	layer_9_ep10_tp1_sa_qkv [label="Self-Attn QKV\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep10_tp1_sa_attn [label="Self-Attn Compute\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep10_tp1_sa_out [label="Self-Attn Output\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep10_tp1_sa_qkv -> layer_9_ep10_tp1_sa_attn
	layer_9_ep10_tp1_sa_attn -> layer_9_ep10_tp1_sa_out
	layer_9_ep10_tp2_sa_qkv [label="Self-Attn QKV\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep10_tp2_sa_attn [label="Self-Attn Compute\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep10_tp2_sa_out [label="Self-Attn Output\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep10_tp2_sa_qkv -> layer_9_ep10_tp2_sa_attn
	layer_9_ep10_tp2_sa_attn -> layer_9_ep10_tp2_sa_out
	layer_9_ep10_tp3_sa_qkv [label="Self-Attn QKV\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep10_tp3_sa_attn [label="Self-Attn Compute\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep10_tp3_sa_out [label="Self-Attn Output\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep10_tp3_sa_qkv -> layer_9_ep10_tp3_sa_attn
	layer_9_ep10_tp3_sa_attn -> layer_9_ep10_tp3_sa_out
	layer_9_ep11_tp0_sa_qkv [label="Self-Attn QKV\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep11_tp0_sa_attn [label="Self-Attn Compute\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep11_tp0_sa_out [label="Self-Attn Output\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep11_tp0_sa_qkv -> layer_9_ep11_tp0_sa_attn
	layer_9_ep11_tp0_sa_attn -> layer_9_ep11_tp0_sa_out
	layer_9_ep11_tp1_sa_qkv [label="Self-Attn QKV\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep11_tp1_sa_attn [label="Self-Attn Compute\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep11_tp1_sa_out [label="Self-Attn Output\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep11_tp1_sa_qkv -> layer_9_ep11_tp1_sa_attn
	layer_9_ep11_tp1_sa_attn -> layer_9_ep11_tp1_sa_out
	layer_9_ep11_tp2_sa_qkv [label="Self-Attn QKV\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep11_tp2_sa_attn [label="Self-Attn Compute\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep11_tp2_sa_out [label="Self-Attn Output\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep11_tp2_sa_qkv -> layer_9_ep11_tp2_sa_attn
	layer_9_ep11_tp2_sa_attn -> layer_9_ep11_tp2_sa_out
	layer_9_ep11_tp3_sa_qkv [label="Self-Attn QKV\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep11_tp3_sa_attn [label="Self-Attn Compute\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep11_tp3_sa_out [label="Self-Attn Output\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep11_tp3_sa_qkv -> layer_9_ep11_tp3_sa_attn
	layer_9_ep11_tp3_sa_attn -> layer_9_ep11_tp3_sa_out
	layer_9_ep12_tp0_sa_qkv [label="Self-Attn QKV\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep12_tp0_sa_attn [label="Self-Attn Compute\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep12_tp0_sa_out [label="Self-Attn Output\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep12_tp0_sa_qkv -> layer_9_ep12_tp0_sa_attn
	layer_9_ep12_tp0_sa_attn -> layer_9_ep12_tp0_sa_out
	layer_9_ep12_tp1_sa_qkv [label="Self-Attn QKV\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep12_tp1_sa_attn [label="Self-Attn Compute\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep12_tp1_sa_out [label="Self-Attn Output\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep12_tp1_sa_qkv -> layer_9_ep12_tp1_sa_attn
	layer_9_ep12_tp1_sa_attn -> layer_9_ep12_tp1_sa_out
	layer_9_ep12_tp2_sa_qkv [label="Self-Attn QKV\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep12_tp2_sa_attn [label="Self-Attn Compute\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep12_tp2_sa_out [label="Self-Attn Output\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep12_tp2_sa_qkv -> layer_9_ep12_tp2_sa_attn
	layer_9_ep12_tp2_sa_attn -> layer_9_ep12_tp2_sa_out
	layer_9_ep12_tp3_sa_qkv [label="Self-Attn QKV\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep12_tp3_sa_attn [label="Self-Attn Compute\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep12_tp3_sa_out [label="Self-Attn Output\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep12_tp3_sa_qkv -> layer_9_ep12_tp3_sa_attn
	layer_9_ep12_tp3_sa_attn -> layer_9_ep12_tp3_sa_out
	layer_9_ep13_tp0_sa_qkv [label="Self-Attn QKV\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep13_tp0_sa_attn [label="Self-Attn Compute\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep13_tp0_sa_out [label="Self-Attn Output\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep13_tp0_sa_qkv -> layer_9_ep13_tp0_sa_attn
	layer_9_ep13_tp0_sa_attn -> layer_9_ep13_tp0_sa_out
	layer_9_ep13_tp1_sa_qkv [label="Self-Attn QKV\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep13_tp1_sa_attn [label="Self-Attn Compute\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep13_tp1_sa_out [label="Self-Attn Output\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep13_tp1_sa_qkv -> layer_9_ep13_tp1_sa_attn
	layer_9_ep13_tp1_sa_attn -> layer_9_ep13_tp1_sa_out
	layer_9_ep13_tp2_sa_qkv [label="Self-Attn QKV\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep13_tp2_sa_attn [label="Self-Attn Compute\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep13_tp2_sa_out [label="Self-Attn Output\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep13_tp2_sa_qkv -> layer_9_ep13_tp2_sa_attn
	layer_9_ep13_tp2_sa_attn -> layer_9_ep13_tp2_sa_out
	layer_9_ep13_tp3_sa_qkv [label="Self-Attn QKV\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep13_tp3_sa_attn [label="Self-Attn Compute\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep13_tp3_sa_out [label="Self-Attn Output\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep13_tp3_sa_qkv -> layer_9_ep13_tp3_sa_attn
	layer_9_ep13_tp3_sa_attn -> layer_9_ep13_tp3_sa_out
	layer_9_ep14_tp0_sa_qkv [label="Self-Attn QKV\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep14_tp0_sa_attn [label="Self-Attn Compute\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep14_tp0_sa_out [label="Self-Attn Output\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep14_tp0_sa_qkv -> layer_9_ep14_tp0_sa_attn
	layer_9_ep14_tp0_sa_attn -> layer_9_ep14_tp0_sa_out
	layer_9_ep14_tp1_sa_qkv [label="Self-Attn QKV\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep14_tp1_sa_attn [label="Self-Attn Compute\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep14_tp1_sa_out [label="Self-Attn Output\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep14_tp1_sa_qkv -> layer_9_ep14_tp1_sa_attn
	layer_9_ep14_tp1_sa_attn -> layer_9_ep14_tp1_sa_out
	layer_9_ep14_tp2_sa_qkv [label="Self-Attn QKV\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep14_tp2_sa_attn [label="Self-Attn Compute\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep14_tp2_sa_out [label="Self-Attn Output\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep14_tp2_sa_qkv -> layer_9_ep14_tp2_sa_attn
	layer_9_ep14_tp2_sa_attn -> layer_9_ep14_tp2_sa_out
	layer_9_ep14_tp3_sa_qkv [label="Self-Attn QKV\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep14_tp3_sa_attn [label="Self-Attn Compute\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep14_tp3_sa_out [label="Self-Attn Output\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep14_tp3_sa_qkv -> layer_9_ep14_tp3_sa_attn
	layer_9_ep14_tp3_sa_attn -> layer_9_ep14_tp3_sa_out
	layer_9_ep15_tp0_sa_qkv [label="Self-Attn QKV\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep15_tp0_sa_attn [label="Self-Attn Compute\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep15_tp0_sa_out [label="Self-Attn Output\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep15_tp0_sa_qkv -> layer_9_ep15_tp0_sa_attn
	layer_9_ep15_tp0_sa_attn -> layer_9_ep15_tp0_sa_out
	layer_9_ep15_tp1_sa_qkv [label="Self-Attn QKV\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep15_tp1_sa_attn [label="Self-Attn Compute\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep15_tp1_sa_out [label="Self-Attn Output\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep15_tp1_sa_qkv -> layer_9_ep15_tp1_sa_attn
	layer_9_ep15_tp1_sa_attn -> layer_9_ep15_tp1_sa_out
	layer_9_ep15_tp2_sa_qkv [label="Self-Attn QKV\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep15_tp2_sa_attn [label="Self-Attn Compute\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep15_tp2_sa_out [label="Self-Attn Output\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep15_tp2_sa_qkv -> layer_9_ep15_tp2_sa_attn
	layer_9_ep15_tp2_sa_attn -> layer_9_ep15_tp2_sa_out
	layer_9_ep15_tp3_sa_qkv [label="Self-Attn QKV\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep15_tp3_sa_attn [label="Self-Attn Compute\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep15_tp3_sa_out [label="Self-Attn Output\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep15_tp3_sa_qkv -> layer_9_ep15_tp3_sa_attn
	layer_9_ep15_tp3_sa_attn -> layer_9_ep15_tp3_sa_out
	layer_9_ep0_tp_allreduce [label="TP All-Reduce\nEP-Group-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_9_ep0_tp0_sa_out -> layer_9_ep0_tp_allreduce
	layer_9_ep0_tp1_sa_out -> layer_9_ep0_tp_allreduce
	layer_9_ep0_tp2_sa_out -> layer_9_ep0_tp_allreduce
	layer_9_ep0_tp3_sa_out -> layer_9_ep0_tp_allreduce
	layer_9_ep1_tp_allreduce [label="TP All-Reduce\nEP-Group-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_9_ep1_tp0_sa_out -> layer_9_ep1_tp_allreduce
	layer_9_ep1_tp1_sa_out -> layer_9_ep1_tp_allreduce
	layer_9_ep1_tp2_sa_out -> layer_9_ep1_tp_allreduce
	layer_9_ep1_tp3_sa_out -> layer_9_ep1_tp_allreduce
	layer_9_ep2_tp_allreduce [label="TP All-Reduce\nEP-Group-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_9_ep2_tp0_sa_out -> layer_9_ep2_tp_allreduce
	layer_9_ep2_tp1_sa_out -> layer_9_ep2_tp_allreduce
	layer_9_ep2_tp2_sa_out -> layer_9_ep2_tp_allreduce
	layer_9_ep2_tp3_sa_out -> layer_9_ep2_tp_allreduce
	layer_9_ep3_tp_allreduce [label="TP All-Reduce\nEP-Group-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_9_ep3_tp0_sa_out -> layer_9_ep3_tp_allreduce
	layer_9_ep3_tp1_sa_out -> layer_9_ep3_tp_allreduce
	layer_9_ep3_tp2_sa_out -> layer_9_ep3_tp_allreduce
	layer_9_ep3_tp3_sa_out -> layer_9_ep3_tp_allreduce
	layer_9_ep4_tp_allreduce [label="TP All-Reduce\nEP-Group-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_9_ep4_tp0_sa_out -> layer_9_ep4_tp_allreduce
	layer_9_ep4_tp1_sa_out -> layer_9_ep4_tp_allreduce
	layer_9_ep4_tp2_sa_out -> layer_9_ep4_tp_allreduce
	layer_9_ep4_tp3_sa_out -> layer_9_ep4_tp_allreduce
	layer_9_ep5_tp_allreduce [label="TP All-Reduce\nEP-Group-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_9_ep5_tp0_sa_out -> layer_9_ep5_tp_allreduce
	layer_9_ep5_tp1_sa_out -> layer_9_ep5_tp_allreduce
	layer_9_ep5_tp2_sa_out -> layer_9_ep5_tp_allreduce
	layer_9_ep5_tp3_sa_out -> layer_9_ep5_tp_allreduce
	layer_9_ep6_tp_allreduce [label="TP All-Reduce\nEP-Group-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_9_ep6_tp0_sa_out -> layer_9_ep6_tp_allreduce
	layer_9_ep6_tp1_sa_out -> layer_9_ep6_tp_allreduce
	layer_9_ep6_tp2_sa_out -> layer_9_ep6_tp_allreduce
	layer_9_ep6_tp3_sa_out -> layer_9_ep6_tp_allreduce
	layer_9_ep7_tp_allreduce [label="TP All-Reduce\nEP-Group-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_9_ep7_tp0_sa_out -> layer_9_ep7_tp_allreduce
	layer_9_ep7_tp1_sa_out -> layer_9_ep7_tp_allreduce
	layer_9_ep7_tp2_sa_out -> layer_9_ep7_tp_allreduce
	layer_9_ep7_tp3_sa_out -> layer_9_ep7_tp_allreduce
	layer_9_ep8_tp_allreduce [label="TP All-Reduce\nEP-Group-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_9_ep8_tp0_sa_out -> layer_9_ep8_tp_allreduce
	layer_9_ep8_tp1_sa_out -> layer_9_ep8_tp_allreduce
	layer_9_ep8_tp2_sa_out -> layer_9_ep8_tp_allreduce
	layer_9_ep8_tp3_sa_out -> layer_9_ep8_tp_allreduce
	layer_9_ep9_tp_allreduce [label="TP All-Reduce\nEP-Group-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_9_ep9_tp0_sa_out -> layer_9_ep9_tp_allreduce
	layer_9_ep9_tp1_sa_out -> layer_9_ep9_tp_allreduce
	layer_9_ep9_tp2_sa_out -> layer_9_ep9_tp_allreduce
	layer_9_ep9_tp3_sa_out -> layer_9_ep9_tp_allreduce
	layer_9_ep10_tp_allreduce [label="TP All-Reduce\nEP-Group-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_9_ep10_tp0_sa_out -> layer_9_ep10_tp_allreduce
	layer_9_ep10_tp1_sa_out -> layer_9_ep10_tp_allreduce
	layer_9_ep10_tp2_sa_out -> layer_9_ep10_tp_allreduce
	layer_9_ep10_tp3_sa_out -> layer_9_ep10_tp_allreduce
	layer_9_ep11_tp_allreduce [label="TP All-Reduce\nEP-Group-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_9_ep11_tp0_sa_out -> layer_9_ep11_tp_allreduce
	layer_9_ep11_tp1_sa_out -> layer_9_ep11_tp_allreduce
	layer_9_ep11_tp2_sa_out -> layer_9_ep11_tp_allreduce
	layer_9_ep11_tp3_sa_out -> layer_9_ep11_tp_allreduce
	layer_9_ep12_tp_allreduce [label="TP All-Reduce\nEP-Group-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_9_ep12_tp0_sa_out -> layer_9_ep12_tp_allreduce
	layer_9_ep12_tp1_sa_out -> layer_9_ep12_tp_allreduce
	layer_9_ep12_tp2_sa_out -> layer_9_ep12_tp_allreduce
	layer_9_ep12_tp3_sa_out -> layer_9_ep12_tp_allreduce
	layer_9_ep13_tp_allreduce [label="TP All-Reduce\nEP-Group-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_9_ep13_tp0_sa_out -> layer_9_ep13_tp_allreduce
	layer_9_ep13_tp1_sa_out -> layer_9_ep13_tp_allreduce
	layer_9_ep13_tp2_sa_out -> layer_9_ep13_tp_allreduce
	layer_9_ep13_tp3_sa_out -> layer_9_ep13_tp_allreduce
	layer_9_ep14_tp_allreduce [label="TP All-Reduce\nEP-Group-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_9_ep14_tp0_sa_out -> layer_9_ep14_tp_allreduce
	layer_9_ep14_tp1_sa_out -> layer_9_ep14_tp_allreduce
	layer_9_ep14_tp2_sa_out -> layer_9_ep14_tp_allreduce
	layer_9_ep14_tp3_sa_out -> layer_9_ep14_tp_allreduce
	layer_9_ep15_tp_allreduce [label="TP All-Reduce\nEP-Group-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_9_ep15_tp0_sa_out -> layer_9_ep15_tp_allreduce
	layer_9_ep15_tp1_sa_out -> layer_9_ep15_tp_allreduce
	layer_9_ep15_tp2_sa_out -> layer_9_ep15_tp_allreduce
	layer_9_ep15_tp3_sa_out -> layer_9_ep15_tp_allreduce
	layer_9_ep0_gate [label="MoE Gate\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_9_ep0_expert_0 [label="Expert-0\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep0_gate -> layer_9_ep0_expert_0 [label="select tokens" style=dashed]
	layer_9_ep0_expert_1 [label="Expert-1\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep0_gate -> layer_9_ep0_expert_1 [label="select tokens" style=dashed]
	layer_9_ep0_expert_2 [label="Expert-2\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep0_gate -> layer_9_ep0_expert_2 [label="select tokens" style=dashed]
	layer_9_ep0_expert_3 [label="Expert-3\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep0_gate -> layer_9_ep0_expert_3 [label="select tokens" style=dashed]
	layer_9_ep0_expert_aggr [label="Expert Aggregation\nEP-Group-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_9_ep0_expert_0 -> layer_9_ep0_expert_aggr
	layer_9_ep0_expert_1 -> layer_9_ep0_expert_aggr
	layer_9_ep0_expert_2 -> layer_9_ep0_expert_aggr
	layer_9_ep0_expert_3 -> layer_9_ep0_expert_aggr
	layer_9_ep1_gate [label="MoE Gate\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_9_ep1_expert_0 [label="Expert-0\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep1_gate -> layer_9_ep1_expert_0 [label="select tokens" style=dashed]
	layer_9_ep1_expert_1 [label="Expert-1\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep1_gate -> layer_9_ep1_expert_1 [label="select tokens" style=dashed]
	layer_9_ep1_expert_2 [label="Expert-2\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep1_gate -> layer_9_ep1_expert_2 [label="select tokens" style=dashed]
	layer_9_ep1_expert_3 [label="Expert-3\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep1_gate -> layer_9_ep1_expert_3 [label="select tokens" style=dashed]
	layer_9_ep1_expert_aggr [label="Expert Aggregation\nEP-Group-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_9_ep1_expert_0 -> layer_9_ep1_expert_aggr
	layer_9_ep1_expert_1 -> layer_9_ep1_expert_aggr
	layer_9_ep1_expert_2 -> layer_9_ep1_expert_aggr
	layer_9_ep1_expert_3 -> layer_9_ep1_expert_aggr
	layer_9_ep2_gate [label="MoE Gate\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_9_ep2_expert_0 [label="Expert-0\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep2_gate -> layer_9_ep2_expert_0 [label="select tokens" style=dashed]
	layer_9_ep2_expert_1 [label="Expert-1\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep2_gate -> layer_9_ep2_expert_1 [label="select tokens" style=dashed]
	layer_9_ep2_expert_2 [label="Expert-2\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep2_gate -> layer_9_ep2_expert_2 [label="select tokens" style=dashed]
	layer_9_ep2_expert_3 [label="Expert-3\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep2_gate -> layer_9_ep2_expert_3 [label="select tokens" style=dashed]
	layer_9_ep2_expert_aggr [label="Expert Aggregation\nEP-Group-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_9_ep2_expert_0 -> layer_9_ep2_expert_aggr
	layer_9_ep2_expert_1 -> layer_9_ep2_expert_aggr
	layer_9_ep2_expert_2 -> layer_9_ep2_expert_aggr
	layer_9_ep2_expert_3 -> layer_9_ep2_expert_aggr
	layer_9_ep3_gate [label="MoE Gate\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_9_ep3_expert_0 [label="Expert-0\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep3_gate -> layer_9_ep3_expert_0 [label="select tokens" style=dashed]
	layer_9_ep3_expert_1 [label="Expert-1\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep3_gate -> layer_9_ep3_expert_1 [label="select tokens" style=dashed]
	layer_9_ep3_expert_2 [label="Expert-2\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep3_gate -> layer_9_ep3_expert_2 [label="select tokens" style=dashed]
	layer_9_ep3_expert_3 [label="Expert-3\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep3_gate -> layer_9_ep3_expert_3 [label="select tokens" style=dashed]
	layer_9_ep3_expert_aggr [label="Expert Aggregation\nEP-Group-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_9_ep3_expert_0 -> layer_9_ep3_expert_aggr
	layer_9_ep3_expert_1 -> layer_9_ep3_expert_aggr
	layer_9_ep3_expert_2 -> layer_9_ep3_expert_aggr
	layer_9_ep3_expert_3 -> layer_9_ep3_expert_aggr
	layer_9_ep4_gate [label="MoE Gate\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_9_ep4_expert_0 [label="Expert-0\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep4_gate -> layer_9_ep4_expert_0 [label="select tokens" style=dashed]
	layer_9_ep4_expert_1 [label="Expert-1\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep4_gate -> layer_9_ep4_expert_1 [label="select tokens" style=dashed]
	layer_9_ep4_expert_2 [label="Expert-2\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep4_gate -> layer_9_ep4_expert_2 [label="select tokens" style=dashed]
	layer_9_ep4_expert_3 [label="Expert-3\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep4_gate -> layer_9_ep4_expert_3 [label="select tokens" style=dashed]
	layer_9_ep4_expert_aggr [label="Expert Aggregation\nEP-Group-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_9_ep4_expert_0 -> layer_9_ep4_expert_aggr
	layer_9_ep4_expert_1 -> layer_9_ep4_expert_aggr
	layer_9_ep4_expert_2 -> layer_9_ep4_expert_aggr
	layer_9_ep4_expert_3 -> layer_9_ep4_expert_aggr
	layer_9_ep5_gate [label="MoE Gate\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_9_ep5_expert_0 [label="Expert-0\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep5_gate -> layer_9_ep5_expert_0 [label="select tokens" style=dashed]
	layer_9_ep5_expert_1 [label="Expert-1\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep5_gate -> layer_9_ep5_expert_1 [label="select tokens" style=dashed]
	layer_9_ep5_expert_2 [label="Expert-2\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep5_gate -> layer_9_ep5_expert_2 [label="select tokens" style=dashed]
	layer_9_ep5_expert_3 [label="Expert-3\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep5_gate -> layer_9_ep5_expert_3 [label="select tokens" style=dashed]
	layer_9_ep5_expert_aggr [label="Expert Aggregation\nEP-Group-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_9_ep5_expert_0 -> layer_9_ep5_expert_aggr
	layer_9_ep5_expert_1 -> layer_9_ep5_expert_aggr
	layer_9_ep5_expert_2 -> layer_9_ep5_expert_aggr
	layer_9_ep5_expert_3 -> layer_9_ep5_expert_aggr
	layer_9_ep6_gate [label="MoE Gate\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_9_ep6_expert_0 [label="Expert-0\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep6_gate -> layer_9_ep6_expert_0 [label="select tokens" style=dashed]
	layer_9_ep6_expert_1 [label="Expert-1\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep6_gate -> layer_9_ep6_expert_1 [label="select tokens" style=dashed]
	layer_9_ep6_expert_2 [label="Expert-2\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep6_gate -> layer_9_ep6_expert_2 [label="select tokens" style=dashed]
	layer_9_ep6_expert_3 [label="Expert-3\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep6_gate -> layer_9_ep6_expert_3 [label="select tokens" style=dashed]
	layer_9_ep6_expert_aggr [label="Expert Aggregation\nEP-Group-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_9_ep6_expert_0 -> layer_9_ep6_expert_aggr
	layer_9_ep6_expert_1 -> layer_9_ep6_expert_aggr
	layer_9_ep6_expert_2 -> layer_9_ep6_expert_aggr
	layer_9_ep6_expert_3 -> layer_9_ep6_expert_aggr
	layer_9_ep7_gate [label="MoE Gate\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_9_ep7_expert_0 [label="Expert-0\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep7_gate -> layer_9_ep7_expert_0 [label="select tokens" style=dashed]
	layer_9_ep7_expert_1 [label="Expert-1\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep7_gate -> layer_9_ep7_expert_1 [label="select tokens" style=dashed]
	layer_9_ep7_expert_2 [label="Expert-2\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep7_gate -> layer_9_ep7_expert_2 [label="select tokens" style=dashed]
	layer_9_ep7_expert_3 [label="Expert-3\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep7_gate -> layer_9_ep7_expert_3 [label="select tokens" style=dashed]
	layer_9_ep7_expert_aggr [label="Expert Aggregation\nEP-Group-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_9_ep7_expert_0 -> layer_9_ep7_expert_aggr
	layer_9_ep7_expert_1 -> layer_9_ep7_expert_aggr
	layer_9_ep7_expert_2 -> layer_9_ep7_expert_aggr
	layer_9_ep7_expert_3 -> layer_9_ep7_expert_aggr
	layer_9_ep8_gate [label="MoE Gate\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_9_ep8_expert_0 [label="Expert-0\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep8_gate -> layer_9_ep8_expert_0 [label="select tokens" style=dashed]
	layer_9_ep8_expert_1 [label="Expert-1\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep8_gate -> layer_9_ep8_expert_1 [label="select tokens" style=dashed]
	layer_9_ep8_expert_2 [label="Expert-2\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep8_gate -> layer_9_ep8_expert_2 [label="select tokens" style=dashed]
	layer_9_ep8_expert_3 [label="Expert-3\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep8_gate -> layer_9_ep8_expert_3 [label="select tokens" style=dashed]
	layer_9_ep8_expert_aggr [label="Expert Aggregation\nEP-Group-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_9_ep8_expert_0 -> layer_9_ep8_expert_aggr
	layer_9_ep8_expert_1 -> layer_9_ep8_expert_aggr
	layer_9_ep8_expert_2 -> layer_9_ep8_expert_aggr
	layer_9_ep8_expert_3 -> layer_9_ep8_expert_aggr
	layer_9_ep9_gate [label="MoE Gate\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_9_ep9_expert_0 [label="Expert-0\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep9_gate -> layer_9_ep9_expert_0 [label="select tokens" style=dashed]
	layer_9_ep9_expert_1 [label="Expert-1\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep9_gate -> layer_9_ep9_expert_1 [label="select tokens" style=dashed]
	layer_9_ep9_expert_2 [label="Expert-2\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep9_gate -> layer_9_ep9_expert_2 [label="select tokens" style=dashed]
	layer_9_ep9_expert_3 [label="Expert-3\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep9_gate -> layer_9_ep9_expert_3 [label="select tokens" style=dashed]
	layer_9_ep9_expert_aggr [label="Expert Aggregation\nEP-Group-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_9_ep9_expert_0 -> layer_9_ep9_expert_aggr
	layer_9_ep9_expert_1 -> layer_9_ep9_expert_aggr
	layer_9_ep9_expert_2 -> layer_9_ep9_expert_aggr
	layer_9_ep9_expert_3 -> layer_9_ep9_expert_aggr
	layer_9_ep10_gate [label="MoE Gate\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_9_ep10_expert_0 [label="Expert-0\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep10_gate -> layer_9_ep10_expert_0 [label="select tokens" style=dashed]
	layer_9_ep10_expert_1 [label="Expert-1\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep10_gate -> layer_9_ep10_expert_1 [label="select tokens" style=dashed]
	layer_9_ep10_expert_2 [label="Expert-2\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep10_gate -> layer_9_ep10_expert_2 [label="select tokens" style=dashed]
	layer_9_ep10_expert_3 [label="Expert-3\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep10_gate -> layer_9_ep10_expert_3 [label="select tokens" style=dashed]
	layer_9_ep10_expert_aggr [label="Expert Aggregation\nEP-Group-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_9_ep10_expert_0 -> layer_9_ep10_expert_aggr
	layer_9_ep10_expert_1 -> layer_9_ep10_expert_aggr
	layer_9_ep10_expert_2 -> layer_9_ep10_expert_aggr
	layer_9_ep10_expert_3 -> layer_9_ep10_expert_aggr
	layer_9_ep11_gate [label="MoE Gate\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_9_ep11_expert_0 [label="Expert-0\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep11_gate -> layer_9_ep11_expert_0 [label="select tokens" style=dashed]
	layer_9_ep11_expert_1 [label="Expert-1\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep11_gate -> layer_9_ep11_expert_1 [label="select tokens" style=dashed]
	layer_9_ep11_expert_2 [label="Expert-2\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep11_gate -> layer_9_ep11_expert_2 [label="select tokens" style=dashed]
	layer_9_ep11_expert_3 [label="Expert-3\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep11_gate -> layer_9_ep11_expert_3 [label="select tokens" style=dashed]
	layer_9_ep11_expert_aggr [label="Expert Aggregation\nEP-Group-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_9_ep11_expert_0 -> layer_9_ep11_expert_aggr
	layer_9_ep11_expert_1 -> layer_9_ep11_expert_aggr
	layer_9_ep11_expert_2 -> layer_9_ep11_expert_aggr
	layer_9_ep11_expert_3 -> layer_9_ep11_expert_aggr
	layer_9_ep12_gate [label="MoE Gate\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_9_ep12_expert_0 [label="Expert-0\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep12_gate -> layer_9_ep12_expert_0 [label="select tokens" style=dashed]
	layer_9_ep12_expert_1 [label="Expert-1\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep12_gate -> layer_9_ep12_expert_1 [label="select tokens" style=dashed]
	layer_9_ep12_expert_2 [label="Expert-2\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep12_gate -> layer_9_ep12_expert_2 [label="select tokens" style=dashed]
	layer_9_ep12_expert_3 [label="Expert-3\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep12_gate -> layer_9_ep12_expert_3 [label="select tokens" style=dashed]
	layer_9_ep12_expert_aggr [label="Expert Aggregation\nEP-Group-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_9_ep12_expert_0 -> layer_9_ep12_expert_aggr
	layer_9_ep12_expert_1 -> layer_9_ep12_expert_aggr
	layer_9_ep12_expert_2 -> layer_9_ep12_expert_aggr
	layer_9_ep12_expert_3 -> layer_9_ep12_expert_aggr
	layer_9_ep13_gate [label="MoE Gate\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_9_ep13_expert_0 [label="Expert-0\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep13_gate -> layer_9_ep13_expert_0 [label="select tokens" style=dashed]
	layer_9_ep13_expert_1 [label="Expert-1\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep13_gate -> layer_9_ep13_expert_1 [label="select tokens" style=dashed]
	layer_9_ep13_expert_2 [label="Expert-2\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep13_gate -> layer_9_ep13_expert_2 [label="select tokens" style=dashed]
	layer_9_ep13_expert_3 [label="Expert-3\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep13_gate -> layer_9_ep13_expert_3 [label="select tokens" style=dashed]
	layer_9_ep13_expert_aggr [label="Expert Aggregation\nEP-Group-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_9_ep13_expert_0 -> layer_9_ep13_expert_aggr
	layer_9_ep13_expert_1 -> layer_9_ep13_expert_aggr
	layer_9_ep13_expert_2 -> layer_9_ep13_expert_aggr
	layer_9_ep13_expert_3 -> layer_9_ep13_expert_aggr
	layer_9_ep14_gate [label="MoE Gate\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_9_ep14_expert_0 [label="Expert-0\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep14_gate -> layer_9_ep14_expert_0 [label="select tokens" style=dashed]
	layer_9_ep14_expert_1 [label="Expert-1\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep14_gate -> layer_9_ep14_expert_1 [label="select tokens" style=dashed]
	layer_9_ep14_expert_2 [label="Expert-2\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep14_gate -> layer_9_ep14_expert_2 [label="select tokens" style=dashed]
	layer_9_ep14_expert_3 [label="Expert-3\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep14_gate -> layer_9_ep14_expert_3 [label="select tokens" style=dashed]
	layer_9_ep14_expert_aggr [label="Expert Aggregation\nEP-Group-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_9_ep14_expert_0 -> layer_9_ep14_expert_aggr
	layer_9_ep14_expert_1 -> layer_9_ep14_expert_aggr
	layer_9_ep14_expert_2 -> layer_9_ep14_expert_aggr
	layer_9_ep14_expert_3 -> layer_9_ep14_expert_aggr
	layer_9_ep15_gate [label="MoE Gate\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_9_ep15_expert_0 [label="Expert-0\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep15_gate -> layer_9_ep15_expert_0 [label="select tokens" style=dashed]
	layer_9_ep15_expert_1 [label="Expert-1\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep15_gate -> layer_9_ep15_expert_1 [label="select tokens" style=dashed]
	layer_9_ep15_expert_2 [label="Expert-2\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep15_gate -> layer_9_ep15_expert_2 [label="select tokens" style=dashed]
	layer_9_ep15_expert_3 [label="Expert-3\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_9_ep15_gate -> layer_9_ep15_expert_3 [label="select tokens" style=dashed]
	layer_9_ep15_expert_aggr [label="Expert Aggregation\nEP-Group-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_9_ep15_expert_0 -> layer_9_ep15_expert_aggr
	layer_9_ep15_expert_1 -> layer_9_ep15_expert_aggr
	layer_9_ep15_expert_2 -> layer_9_ep15_expert_aggr
	layer_9_ep15_expert_3 -> layer_9_ep15_expert_aggr
	layer_9_to_10_ep0_pp [label="Pipeline Stage Transfer\nEP-Group-0\nLayer-9 to Layer-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_9_ep0_expert_aggr -> layer_9_to_10_ep0_pp
	layer_9_to_10_ep1_pp [label="Pipeline Stage Transfer\nEP-Group-1\nLayer-9 to Layer-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_9_ep1_expert_aggr -> layer_9_to_10_ep1_pp
	layer_9_to_10_ep2_pp [label="Pipeline Stage Transfer\nEP-Group-2\nLayer-9 to Layer-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_9_ep2_expert_aggr -> layer_9_to_10_ep2_pp
	layer_9_to_10_ep3_pp [label="Pipeline Stage Transfer\nEP-Group-3\nLayer-9 to Layer-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_9_ep3_expert_aggr -> layer_9_to_10_ep3_pp
	layer_9_to_10_ep4_pp [label="Pipeline Stage Transfer\nEP-Group-4\nLayer-9 to Layer-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_9_ep4_expert_aggr -> layer_9_to_10_ep4_pp
	layer_9_to_10_ep5_pp [label="Pipeline Stage Transfer\nEP-Group-5\nLayer-9 to Layer-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_9_ep5_expert_aggr -> layer_9_to_10_ep5_pp
	layer_9_to_10_ep6_pp [label="Pipeline Stage Transfer\nEP-Group-6\nLayer-9 to Layer-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_9_ep6_expert_aggr -> layer_9_to_10_ep6_pp
	layer_9_to_10_ep7_pp [label="Pipeline Stage Transfer\nEP-Group-7\nLayer-9 to Layer-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_9_ep7_expert_aggr -> layer_9_to_10_ep7_pp
	layer_9_to_10_ep8_pp [label="Pipeline Stage Transfer\nEP-Group-8\nLayer-9 to Layer-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_9_ep8_expert_aggr -> layer_9_to_10_ep8_pp
	layer_9_to_10_ep9_pp [label="Pipeline Stage Transfer\nEP-Group-9\nLayer-9 to Layer-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_9_ep9_expert_aggr -> layer_9_to_10_ep9_pp
	layer_9_to_10_ep10_pp [label="Pipeline Stage Transfer\nEP-Group-10\nLayer-9 to Layer-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_9_ep10_expert_aggr -> layer_9_to_10_ep10_pp
	layer_9_to_10_ep11_pp [label="Pipeline Stage Transfer\nEP-Group-11\nLayer-9 to Layer-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_9_ep11_expert_aggr -> layer_9_to_10_ep11_pp
	layer_9_to_10_ep12_pp [label="Pipeline Stage Transfer\nEP-Group-12\nLayer-9 to Layer-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_9_ep12_expert_aggr -> layer_9_to_10_ep12_pp
	layer_9_to_10_ep13_pp [label="Pipeline Stage Transfer\nEP-Group-13\nLayer-9 to Layer-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_9_ep13_expert_aggr -> layer_9_to_10_ep13_pp
	layer_9_to_10_ep14_pp [label="Pipeline Stage Transfer\nEP-Group-14\nLayer-9 to Layer-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_9_ep14_expert_aggr -> layer_9_to_10_ep14_pp
	layer_9_to_10_ep15_pp [label="Pipeline Stage Transfer\nEP-Group-15\nLayer-9 to Layer-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_9_ep15_expert_aggr -> layer_9_to_10_ep15_pp
	layer_10_ep0_tp0_sa_qkv [label="Self-Attn QKV\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep0_tp0_sa_attn [label="Self-Attn Compute\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep0_tp0_sa_out [label="Self-Attn Output\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep0_tp0_sa_qkv -> layer_10_ep0_tp0_sa_attn
	layer_10_ep0_tp0_sa_attn -> layer_10_ep0_tp0_sa_out
	layer_10_ep0_tp1_sa_qkv [label="Self-Attn QKV\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep0_tp1_sa_attn [label="Self-Attn Compute\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep0_tp1_sa_out [label="Self-Attn Output\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep0_tp1_sa_qkv -> layer_10_ep0_tp1_sa_attn
	layer_10_ep0_tp1_sa_attn -> layer_10_ep0_tp1_sa_out
	layer_10_ep0_tp2_sa_qkv [label="Self-Attn QKV\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep0_tp2_sa_attn [label="Self-Attn Compute\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep0_tp2_sa_out [label="Self-Attn Output\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep0_tp2_sa_qkv -> layer_10_ep0_tp2_sa_attn
	layer_10_ep0_tp2_sa_attn -> layer_10_ep0_tp2_sa_out
	layer_10_ep0_tp3_sa_qkv [label="Self-Attn QKV\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep0_tp3_sa_attn [label="Self-Attn Compute\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep0_tp3_sa_out [label="Self-Attn Output\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep0_tp3_sa_qkv -> layer_10_ep0_tp3_sa_attn
	layer_10_ep0_tp3_sa_attn -> layer_10_ep0_tp3_sa_out
	layer_10_ep1_tp0_sa_qkv [label="Self-Attn QKV\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep1_tp0_sa_attn [label="Self-Attn Compute\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep1_tp0_sa_out [label="Self-Attn Output\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep1_tp0_sa_qkv -> layer_10_ep1_tp0_sa_attn
	layer_10_ep1_tp0_sa_attn -> layer_10_ep1_tp0_sa_out
	layer_10_ep1_tp1_sa_qkv [label="Self-Attn QKV\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep1_tp1_sa_attn [label="Self-Attn Compute\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep1_tp1_sa_out [label="Self-Attn Output\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep1_tp1_sa_qkv -> layer_10_ep1_tp1_sa_attn
	layer_10_ep1_tp1_sa_attn -> layer_10_ep1_tp1_sa_out
	layer_10_ep1_tp2_sa_qkv [label="Self-Attn QKV\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep1_tp2_sa_attn [label="Self-Attn Compute\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep1_tp2_sa_out [label="Self-Attn Output\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep1_tp2_sa_qkv -> layer_10_ep1_tp2_sa_attn
	layer_10_ep1_tp2_sa_attn -> layer_10_ep1_tp2_sa_out
	layer_10_ep1_tp3_sa_qkv [label="Self-Attn QKV\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep1_tp3_sa_attn [label="Self-Attn Compute\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep1_tp3_sa_out [label="Self-Attn Output\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep1_tp3_sa_qkv -> layer_10_ep1_tp3_sa_attn
	layer_10_ep1_tp3_sa_attn -> layer_10_ep1_tp3_sa_out
	layer_10_ep2_tp0_sa_qkv [label="Self-Attn QKV\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep2_tp0_sa_attn [label="Self-Attn Compute\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep2_tp0_sa_out [label="Self-Attn Output\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep2_tp0_sa_qkv -> layer_10_ep2_tp0_sa_attn
	layer_10_ep2_tp0_sa_attn -> layer_10_ep2_tp0_sa_out
	layer_10_ep2_tp1_sa_qkv [label="Self-Attn QKV\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep2_tp1_sa_attn [label="Self-Attn Compute\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep2_tp1_sa_out [label="Self-Attn Output\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep2_tp1_sa_qkv -> layer_10_ep2_tp1_sa_attn
	layer_10_ep2_tp1_sa_attn -> layer_10_ep2_tp1_sa_out
	layer_10_ep2_tp2_sa_qkv [label="Self-Attn QKV\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep2_tp2_sa_attn [label="Self-Attn Compute\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep2_tp2_sa_out [label="Self-Attn Output\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep2_tp2_sa_qkv -> layer_10_ep2_tp2_sa_attn
	layer_10_ep2_tp2_sa_attn -> layer_10_ep2_tp2_sa_out
	layer_10_ep2_tp3_sa_qkv [label="Self-Attn QKV\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep2_tp3_sa_attn [label="Self-Attn Compute\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep2_tp3_sa_out [label="Self-Attn Output\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep2_tp3_sa_qkv -> layer_10_ep2_tp3_sa_attn
	layer_10_ep2_tp3_sa_attn -> layer_10_ep2_tp3_sa_out
	layer_10_ep3_tp0_sa_qkv [label="Self-Attn QKV\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep3_tp0_sa_attn [label="Self-Attn Compute\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep3_tp0_sa_out [label="Self-Attn Output\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep3_tp0_sa_qkv -> layer_10_ep3_tp0_sa_attn
	layer_10_ep3_tp0_sa_attn -> layer_10_ep3_tp0_sa_out
	layer_10_ep3_tp1_sa_qkv [label="Self-Attn QKV\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep3_tp1_sa_attn [label="Self-Attn Compute\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep3_tp1_sa_out [label="Self-Attn Output\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep3_tp1_sa_qkv -> layer_10_ep3_tp1_sa_attn
	layer_10_ep3_tp1_sa_attn -> layer_10_ep3_tp1_sa_out
	layer_10_ep3_tp2_sa_qkv [label="Self-Attn QKV\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep3_tp2_sa_attn [label="Self-Attn Compute\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep3_tp2_sa_out [label="Self-Attn Output\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep3_tp2_sa_qkv -> layer_10_ep3_tp2_sa_attn
	layer_10_ep3_tp2_sa_attn -> layer_10_ep3_tp2_sa_out
	layer_10_ep3_tp3_sa_qkv [label="Self-Attn QKV\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep3_tp3_sa_attn [label="Self-Attn Compute\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep3_tp3_sa_out [label="Self-Attn Output\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep3_tp3_sa_qkv -> layer_10_ep3_tp3_sa_attn
	layer_10_ep3_tp3_sa_attn -> layer_10_ep3_tp3_sa_out
	layer_10_ep4_tp0_sa_qkv [label="Self-Attn QKV\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep4_tp0_sa_attn [label="Self-Attn Compute\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep4_tp0_sa_out [label="Self-Attn Output\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep4_tp0_sa_qkv -> layer_10_ep4_tp0_sa_attn
	layer_10_ep4_tp0_sa_attn -> layer_10_ep4_tp0_sa_out
	layer_10_ep4_tp1_sa_qkv [label="Self-Attn QKV\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep4_tp1_sa_attn [label="Self-Attn Compute\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep4_tp1_sa_out [label="Self-Attn Output\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep4_tp1_sa_qkv -> layer_10_ep4_tp1_sa_attn
	layer_10_ep4_tp1_sa_attn -> layer_10_ep4_tp1_sa_out
	layer_10_ep4_tp2_sa_qkv [label="Self-Attn QKV\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep4_tp2_sa_attn [label="Self-Attn Compute\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep4_tp2_sa_out [label="Self-Attn Output\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep4_tp2_sa_qkv -> layer_10_ep4_tp2_sa_attn
	layer_10_ep4_tp2_sa_attn -> layer_10_ep4_tp2_sa_out
	layer_10_ep4_tp3_sa_qkv [label="Self-Attn QKV\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep4_tp3_sa_attn [label="Self-Attn Compute\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep4_tp3_sa_out [label="Self-Attn Output\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep4_tp3_sa_qkv -> layer_10_ep4_tp3_sa_attn
	layer_10_ep4_tp3_sa_attn -> layer_10_ep4_tp3_sa_out
	layer_10_ep5_tp0_sa_qkv [label="Self-Attn QKV\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep5_tp0_sa_attn [label="Self-Attn Compute\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep5_tp0_sa_out [label="Self-Attn Output\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep5_tp0_sa_qkv -> layer_10_ep5_tp0_sa_attn
	layer_10_ep5_tp0_sa_attn -> layer_10_ep5_tp0_sa_out
	layer_10_ep5_tp1_sa_qkv [label="Self-Attn QKV\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep5_tp1_sa_attn [label="Self-Attn Compute\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep5_tp1_sa_out [label="Self-Attn Output\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep5_tp1_sa_qkv -> layer_10_ep5_tp1_sa_attn
	layer_10_ep5_tp1_sa_attn -> layer_10_ep5_tp1_sa_out
	layer_10_ep5_tp2_sa_qkv [label="Self-Attn QKV\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep5_tp2_sa_attn [label="Self-Attn Compute\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep5_tp2_sa_out [label="Self-Attn Output\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep5_tp2_sa_qkv -> layer_10_ep5_tp2_sa_attn
	layer_10_ep5_tp2_sa_attn -> layer_10_ep5_tp2_sa_out
	layer_10_ep5_tp3_sa_qkv [label="Self-Attn QKV\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep5_tp3_sa_attn [label="Self-Attn Compute\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep5_tp3_sa_out [label="Self-Attn Output\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep5_tp3_sa_qkv -> layer_10_ep5_tp3_sa_attn
	layer_10_ep5_tp3_sa_attn -> layer_10_ep5_tp3_sa_out
	layer_10_ep6_tp0_sa_qkv [label="Self-Attn QKV\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep6_tp0_sa_attn [label="Self-Attn Compute\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep6_tp0_sa_out [label="Self-Attn Output\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep6_tp0_sa_qkv -> layer_10_ep6_tp0_sa_attn
	layer_10_ep6_tp0_sa_attn -> layer_10_ep6_tp0_sa_out
	layer_10_ep6_tp1_sa_qkv [label="Self-Attn QKV\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep6_tp1_sa_attn [label="Self-Attn Compute\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep6_tp1_sa_out [label="Self-Attn Output\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep6_tp1_sa_qkv -> layer_10_ep6_tp1_sa_attn
	layer_10_ep6_tp1_sa_attn -> layer_10_ep6_tp1_sa_out
	layer_10_ep6_tp2_sa_qkv [label="Self-Attn QKV\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep6_tp2_sa_attn [label="Self-Attn Compute\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep6_tp2_sa_out [label="Self-Attn Output\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep6_tp2_sa_qkv -> layer_10_ep6_tp2_sa_attn
	layer_10_ep6_tp2_sa_attn -> layer_10_ep6_tp2_sa_out
	layer_10_ep6_tp3_sa_qkv [label="Self-Attn QKV\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep6_tp3_sa_attn [label="Self-Attn Compute\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep6_tp3_sa_out [label="Self-Attn Output\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep6_tp3_sa_qkv -> layer_10_ep6_tp3_sa_attn
	layer_10_ep6_tp3_sa_attn -> layer_10_ep6_tp3_sa_out
	layer_10_ep7_tp0_sa_qkv [label="Self-Attn QKV\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep7_tp0_sa_attn [label="Self-Attn Compute\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep7_tp0_sa_out [label="Self-Attn Output\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep7_tp0_sa_qkv -> layer_10_ep7_tp0_sa_attn
	layer_10_ep7_tp0_sa_attn -> layer_10_ep7_tp0_sa_out
	layer_10_ep7_tp1_sa_qkv [label="Self-Attn QKV\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep7_tp1_sa_attn [label="Self-Attn Compute\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep7_tp1_sa_out [label="Self-Attn Output\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep7_tp1_sa_qkv -> layer_10_ep7_tp1_sa_attn
	layer_10_ep7_tp1_sa_attn -> layer_10_ep7_tp1_sa_out
	layer_10_ep7_tp2_sa_qkv [label="Self-Attn QKV\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep7_tp2_sa_attn [label="Self-Attn Compute\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep7_tp2_sa_out [label="Self-Attn Output\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep7_tp2_sa_qkv -> layer_10_ep7_tp2_sa_attn
	layer_10_ep7_tp2_sa_attn -> layer_10_ep7_tp2_sa_out
	layer_10_ep7_tp3_sa_qkv [label="Self-Attn QKV\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep7_tp3_sa_attn [label="Self-Attn Compute\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep7_tp3_sa_out [label="Self-Attn Output\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep7_tp3_sa_qkv -> layer_10_ep7_tp3_sa_attn
	layer_10_ep7_tp3_sa_attn -> layer_10_ep7_tp3_sa_out
	layer_10_ep8_tp0_sa_qkv [label="Self-Attn QKV\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep8_tp0_sa_attn [label="Self-Attn Compute\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep8_tp0_sa_out [label="Self-Attn Output\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep8_tp0_sa_qkv -> layer_10_ep8_tp0_sa_attn
	layer_10_ep8_tp0_sa_attn -> layer_10_ep8_tp0_sa_out
	layer_10_ep8_tp1_sa_qkv [label="Self-Attn QKV\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep8_tp1_sa_attn [label="Self-Attn Compute\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep8_tp1_sa_out [label="Self-Attn Output\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep8_tp1_sa_qkv -> layer_10_ep8_tp1_sa_attn
	layer_10_ep8_tp1_sa_attn -> layer_10_ep8_tp1_sa_out
	layer_10_ep8_tp2_sa_qkv [label="Self-Attn QKV\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep8_tp2_sa_attn [label="Self-Attn Compute\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep8_tp2_sa_out [label="Self-Attn Output\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep8_tp2_sa_qkv -> layer_10_ep8_tp2_sa_attn
	layer_10_ep8_tp2_sa_attn -> layer_10_ep8_tp2_sa_out
	layer_10_ep8_tp3_sa_qkv [label="Self-Attn QKV\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep8_tp3_sa_attn [label="Self-Attn Compute\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep8_tp3_sa_out [label="Self-Attn Output\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep8_tp3_sa_qkv -> layer_10_ep8_tp3_sa_attn
	layer_10_ep8_tp3_sa_attn -> layer_10_ep8_tp3_sa_out
	layer_10_ep9_tp0_sa_qkv [label="Self-Attn QKV\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep9_tp0_sa_attn [label="Self-Attn Compute\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep9_tp0_sa_out [label="Self-Attn Output\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep9_tp0_sa_qkv -> layer_10_ep9_tp0_sa_attn
	layer_10_ep9_tp0_sa_attn -> layer_10_ep9_tp0_sa_out
	layer_10_ep9_tp1_sa_qkv [label="Self-Attn QKV\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep9_tp1_sa_attn [label="Self-Attn Compute\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep9_tp1_sa_out [label="Self-Attn Output\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep9_tp1_sa_qkv -> layer_10_ep9_tp1_sa_attn
	layer_10_ep9_tp1_sa_attn -> layer_10_ep9_tp1_sa_out
	layer_10_ep9_tp2_sa_qkv [label="Self-Attn QKV\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep9_tp2_sa_attn [label="Self-Attn Compute\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep9_tp2_sa_out [label="Self-Attn Output\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep9_tp2_sa_qkv -> layer_10_ep9_tp2_sa_attn
	layer_10_ep9_tp2_sa_attn -> layer_10_ep9_tp2_sa_out
	layer_10_ep9_tp3_sa_qkv [label="Self-Attn QKV\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep9_tp3_sa_attn [label="Self-Attn Compute\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep9_tp3_sa_out [label="Self-Attn Output\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep9_tp3_sa_qkv -> layer_10_ep9_tp3_sa_attn
	layer_10_ep9_tp3_sa_attn -> layer_10_ep9_tp3_sa_out
	layer_10_ep10_tp0_sa_qkv [label="Self-Attn QKV\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep10_tp0_sa_attn [label="Self-Attn Compute\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep10_tp0_sa_out [label="Self-Attn Output\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep10_tp0_sa_qkv -> layer_10_ep10_tp0_sa_attn
	layer_10_ep10_tp0_sa_attn -> layer_10_ep10_tp0_sa_out
	layer_10_ep10_tp1_sa_qkv [label="Self-Attn QKV\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep10_tp1_sa_attn [label="Self-Attn Compute\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep10_tp1_sa_out [label="Self-Attn Output\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep10_tp1_sa_qkv -> layer_10_ep10_tp1_sa_attn
	layer_10_ep10_tp1_sa_attn -> layer_10_ep10_tp1_sa_out
	layer_10_ep10_tp2_sa_qkv [label="Self-Attn QKV\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep10_tp2_sa_attn [label="Self-Attn Compute\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep10_tp2_sa_out [label="Self-Attn Output\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep10_tp2_sa_qkv -> layer_10_ep10_tp2_sa_attn
	layer_10_ep10_tp2_sa_attn -> layer_10_ep10_tp2_sa_out
	layer_10_ep10_tp3_sa_qkv [label="Self-Attn QKV\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep10_tp3_sa_attn [label="Self-Attn Compute\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep10_tp3_sa_out [label="Self-Attn Output\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep10_tp3_sa_qkv -> layer_10_ep10_tp3_sa_attn
	layer_10_ep10_tp3_sa_attn -> layer_10_ep10_tp3_sa_out
	layer_10_ep11_tp0_sa_qkv [label="Self-Attn QKV\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep11_tp0_sa_attn [label="Self-Attn Compute\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep11_tp0_sa_out [label="Self-Attn Output\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep11_tp0_sa_qkv -> layer_10_ep11_tp0_sa_attn
	layer_10_ep11_tp0_sa_attn -> layer_10_ep11_tp0_sa_out
	layer_10_ep11_tp1_sa_qkv [label="Self-Attn QKV\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep11_tp1_sa_attn [label="Self-Attn Compute\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep11_tp1_sa_out [label="Self-Attn Output\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep11_tp1_sa_qkv -> layer_10_ep11_tp1_sa_attn
	layer_10_ep11_tp1_sa_attn -> layer_10_ep11_tp1_sa_out
	layer_10_ep11_tp2_sa_qkv [label="Self-Attn QKV\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep11_tp2_sa_attn [label="Self-Attn Compute\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep11_tp2_sa_out [label="Self-Attn Output\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep11_tp2_sa_qkv -> layer_10_ep11_tp2_sa_attn
	layer_10_ep11_tp2_sa_attn -> layer_10_ep11_tp2_sa_out
	layer_10_ep11_tp3_sa_qkv [label="Self-Attn QKV\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep11_tp3_sa_attn [label="Self-Attn Compute\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep11_tp3_sa_out [label="Self-Attn Output\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep11_tp3_sa_qkv -> layer_10_ep11_tp3_sa_attn
	layer_10_ep11_tp3_sa_attn -> layer_10_ep11_tp3_sa_out
	layer_10_ep12_tp0_sa_qkv [label="Self-Attn QKV\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep12_tp0_sa_attn [label="Self-Attn Compute\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep12_tp0_sa_out [label="Self-Attn Output\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep12_tp0_sa_qkv -> layer_10_ep12_tp0_sa_attn
	layer_10_ep12_tp0_sa_attn -> layer_10_ep12_tp0_sa_out
	layer_10_ep12_tp1_sa_qkv [label="Self-Attn QKV\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep12_tp1_sa_attn [label="Self-Attn Compute\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep12_tp1_sa_out [label="Self-Attn Output\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep12_tp1_sa_qkv -> layer_10_ep12_tp1_sa_attn
	layer_10_ep12_tp1_sa_attn -> layer_10_ep12_tp1_sa_out
	layer_10_ep12_tp2_sa_qkv [label="Self-Attn QKV\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep12_tp2_sa_attn [label="Self-Attn Compute\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep12_tp2_sa_out [label="Self-Attn Output\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep12_tp2_sa_qkv -> layer_10_ep12_tp2_sa_attn
	layer_10_ep12_tp2_sa_attn -> layer_10_ep12_tp2_sa_out
	layer_10_ep12_tp3_sa_qkv [label="Self-Attn QKV\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep12_tp3_sa_attn [label="Self-Attn Compute\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep12_tp3_sa_out [label="Self-Attn Output\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep12_tp3_sa_qkv -> layer_10_ep12_tp3_sa_attn
	layer_10_ep12_tp3_sa_attn -> layer_10_ep12_tp3_sa_out
	layer_10_ep13_tp0_sa_qkv [label="Self-Attn QKV\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep13_tp0_sa_attn [label="Self-Attn Compute\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep13_tp0_sa_out [label="Self-Attn Output\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep13_tp0_sa_qkv -> layer_10_ep13_tp0_sa_attn
	layer_10_ep13_tp0_sa_attn -> layer_10_ep13_tp0_sa_out
	layer_10_ep13_tp1_sa_qkv [label="Self-Attn QKV\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep13_tp1_sa_attn [label="Self-Attn Compute\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep13_tp1_sa_out [label="Self-Attn Output\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep13_tp1_sa_qkv -> layer_10_ep13_tp1_sa_attn
	layer_10_ep13_tp1_sa_attn -> layer_10_ep13_tp1_sa_out
	layer_10_ep13_tp2_sa_qkv [label="Self-Attn QKV\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep13_tp2_sa_attn [label="Self-Attn Compute\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep13_tp2_sa_out [label="Self-Attn Output\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep13_tp2_sa_qkv -> layer_10_ep13_tp2_sa_attn
	layer_10_ep13_tp2_sa_attn -> layer_10_ep13_tp2_sa_out
	layer_10_ep13_tp3_sa_qkv [label="Self-Attn QKV\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep13_tp3_sa_attn [label="Self-Attn Compute\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep13_tp3_sa_out [label="Self-Attn Output\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep13_tp3_sa_qkv -> layer_10_ep13_tp3_sa_attn
	layer_10_ep13_tp3_sa_attn -> layer_10_ep13_tp3_sa_out
	layer_10_ep14_tp0_sa_qkv [label="Self-Attn QKV\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep14_tp0_sa_attn [label="Self-Attn Compute\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep14_tp0_sa_out [label="Self-Attn Output\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep14_tp0_sa_qkv -> layer_10_ep14_tp0_sa_attn
	layer_10_ep14_tp0_sa_attn -> layer_10_ep14_tp0_sa_out
	layer_10_ep14_tp1_sa_qkv [label="Self-Attn QKV\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep14_tp1_sa_attn [label="Self-Attn Compute\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep14_tp1_sa_out [label="Self-Attn Output\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep14_tp1_sa_qkv -> layer_10_ep14_tp1_sa_attn
	layer_10_ep14_tp1_sa_attn -> layer_10_ep14_tp1_sa_out
	layer_10_ep14_tp2_sa_qkv [label="Self-Attn QKV\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep14_tp2_sa_attn [label="Self-Attn Compute\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep14_tp2_sa_out [label="Self-Attn Output\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep14_tp2_sa_qkv -> layer_10_ep14_tp2_sa_attn
	layer_10_ep14_tp2_sa_attn -> layer_10_ep14_tp2_sa_out
	layer_10_ep14_tp3_sa_qkv [label="Self-Attn QKV\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep14_tp3_sa_attn [label="Self-Attn Compute\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep14_tp3_sa_out [label="Self-Attn Output\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep14_tp3_sa_qkv -> layer_10_ep14_tp3_sa_attn
	layer_10_ep14_tp3_sa_attn -> layer_10_ep14_tp3_sa_out
	layer_10_ep15_tp0_sa_qkv [label="Self-Attn QKV\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep15_tp0_sa_attn [label="Self-Attn Compute\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep15_tp0_sa_out [label="Self-Attn Output\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep15_tp0_sa_qkv -> layer_10_ep15_tp0_sa_attn
	layer_10_ep15_tp0_sa_attn -> layer_10_ep15_tp0_sa_out
	layer_10_ep15_tp1_sa_qkv [label="Self-Attn QKV\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep15_tp1_sa_attn [label="Self-Attn Compute\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep15_tp1_sa_out [label="Self-Attn Output\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep15_tp1_sa_qkv -> layer_10_ep15_tp1_sa_attn
	layer_10_ep15_tp1_sa_attn -> layer_10_ep15_tp1_sa_out
	layer_10_ep15_tp2_sa_qkv [label="Self-Attn QKV\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep15_tp2_sa_attn [label="Self-Attn Compute\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep15_tp2_sa_out [label="Self-Attn Output\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep15_tp2_sa_qkv -> layer_10_ep15_tp2_sa_attn
	layer_10_ep15_tp2_sa_attn -> layer_10_ep15_tp2_sa_out
	layer_10_ep15_tp3_sa_qkv [label="Self-Attn QKV\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep15_tp3_sa_attn [label="Self-Attn Compute\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep15_tp3_sa_out [label="Self-Attn Output\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep15_tp3_sa_qkv -> layer_10_ep15_tp3_sa_attn
	layer_10_ep15_tp3_sa_attn -> layer_10_ep15_tp3_sa_out
	layer_10_ep0_tp_allreduce [label="TP All-Reduce\nEP-Group-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_10_ep0_tp0_sa_out -> layer_10_ep0_tp_allreduce
	layer_10_ep0_tp1_sa_out -> layer_10_ep0_tp_allreduce
	layer_10_ep0_tp2_sa_out -> layer_10_ep0_tp_allreduce
	layer_10_ep0_tp3_sa_out -> layer_10_ep0_tp_allreduce
	layer_10_ep1_tp_allreduce [label="TP All-Reduce\nEP-Group-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_10_ep1_tp0_sa_out -> layer_10_ep1_tp_allreduce
	layer_10_ep1_tp1_sa_out -> layer_10_ep1_tp_allreduce
	layer_10_ep1_tp2_sa_out -> layer_10_ep1_tp_allreduce
	layer_10_ep1_tp3_sa_out -> layer_10_ep1_tp_allreduce
	layer_10_ep2_tp_allreduce [label="TP All-Reduce\nEP-Group-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_10_ep2_tp0_sa_out -> layer_10_ep2_tp_allreduce
	layer_10_ep2_tp1_sa_out -> layer_10_ep2_tp_allreduce
	layer_10_ep2_tp2_sa_out -> layer_10_ep2_tp_allreduce
	layer_10_ep2_tp3_sa_out -> layer_10_ep2_tp_allreduce
	layer_10_ep3_tp_allreduce [label="TP All-Reduce\nEP-Group-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_10_ep3_tp0_sa_out -> layer_10_ep3_tp_allreduce
	layer_10_ep3_tp1_sa_out -> layer_10_ep3_tp_allreduce
	layer_10_ep3_tp2_sa_out -> layer_10_ep3_tp_allreduce
	layer_10_ep3_tp3_sa_out -> layer_10_ep3_tp_allreduce
	layer_10_ep4_tp_allreduce [label="TP All-Reduce\nEP-Group-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_10_ep4_tp0_sa_out -> layer_10_ep4_tp_allreduce
	layer_10_ep4_tp1_sa_out -> layer_10_ep4_tp_allreduce
	layer_10_ep4_tp2_sa_out -> layer_10_ep4_tp_allreduce
	layer_10_ep4_tp3_sa_out -> layer_10_ep4_tp_allreduce
	layer_10_ep5_tp_allreduce [label="TP All-Reduce\nEP-Group-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_10_ep5_tp0_sa_out -> layer_10_ep5_tp_allreduce
	layer_10_ep5_tp1_sa_out -> layer_10_ep5_tp_allreduce
	layer_10_ep5_tp2_sa_out -> layer_10_ep5_tp_allreduce
	layer_10_ep5_tp3_sa_out -> layer_10_ep5_tp_allreduce
	layer_10_ep6_tp_allreduce [label="TP All-Reduce\nEP-Group-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_10_ep6_tp0_sa_out -> layer_10_ep6_tp_allreduce
	layer_10_ep6_tp1_sa_out -> layer_10_ep6_tp_allreduce
	layer_10_ep6_tp2_sa_out -> layer_10_ep6_tp_allreduce
	layer_10_ep6_tp3_sa_out -> layer_10_ep6_tp_allreduce
	layer_10_ep7_tp_allreduce [label="TP All-Reduce\nEP-Group-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_10_ep7_tp0_sa_out -> layer_10_ep7_tp_allreduce
	layer_10_ep7_tp1_sa_out -> layer_10_ep7_tp_allreduce
	layer_10_ep7_tp2_sa_out -> layer_10_ep7_tp_allreduce
	layer_10_ep7_tp3_sa_out -> layer_10_ep7_tp_allreduce
	layer_10_ep8_tp_allreduce [label="TP All-Reduce\nEP-Group-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_10_ep8_tp0_sa_out -> layer_10_ep8_tp_allreduce
	layer_10_ep8_tp1_sa_out -> layer_10_ep8_tp_allreduce
	layer_10_ep8_tp2_sa_out -> layer_10_ep8_tp_allreduce
	layer_10_ep8_tp3_sa_out -> layer_10_ep8_tp_allreduce
	layer_10_ep9_tp_allreduce [label="TP All-Reduce\nEP-Group-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_10_ep9_tp0_sa_out -> layer_10_ep9_tp_allreduce
	layer_10_ep9_tp1_sa_out -> layer_10_ep9_tp_allreduce
	layer_10_ep9_tp2_sa_out -> layer_10_ep9_tp_allreduce
	layer_10_ep9_tp3_sa_out -> layer_10_ep9_tp_allreduce
	layer_10_ep10_tp_allreduce [label="TP All-Reduce\nEP-Group-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_10_ep10_tp0_sa_out -> layer_10_ep10_tp_allreduce
	layer_10_ep10_tp1_sa_out -> layer_10_ep10_tp_allreduce
	layer_10_ep10_tp2_sa_out -> layer_10_ep10_tp_allreduce
	layer_10_ep10_tp3_sa_out -> layer_10_ep10_tp_allreduce
	layer_10_ep11_tp_allreduce [label="TP All-Reduce\nEP-Group-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_10_ep11_tp0_sa_out -> layer_10_ep11_tp_allreduce
	layer_10_ep11_tp1_sa_out -> layer_10_ep11_tp_allreduce
	layer_10_ep11_tp2_sa_out -> layer_10_ep11_tp_allreduce
	layer_10_ep11_tp3_sa_out -> layer_10_ep11_tp_allreduce
	layer_10_ep12_tp_allreduce [label="TP All-Reduce\nEP-Group-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_10_ep12_tp0_sa_out -> layer_10_ep12_tp_allreduce
	layer_10_ep12_tp1_sa_out -> layer_10_ep12_tp_allreduce
	layer_10_ep12_tp2_sa_out -> layer_10_ep12_tp_allreduce
	layer_10_ep12_tp3_sa_out -> layer_10_ep12_tp_allreduce
	layer_10_ep13_tp_allreduce [label="TP All-Reduce\nEP-Group-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_10_ep13_tp0_sa_out -> layer_10_ep13_tp_allreduce
	layer_10_ep13_tp1_sa_out -> layer_10_ep13_tp_allreduce
	layer_10_ep13_tp2_sa_out -> layer_10_ep13_tp_allreduce
	layer_10_ep13_tp3_sa_out -> layer_10_ep13_tp_allreduce
	layer_10_ep14_tp_allreduce [label="TP All-Reduce\nEP-Group-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_10_ep14_tp0_sa_out -> layer_10_ep14_tp_allreduce
	layer_10_ep14_tp1_sa_out -> layer_10_ep14_tp_allreduce
	layer_10_ep14_tp2_sa_out -> layer_10_ep14_tp_allreduce
	layer_10_ep14_tp3_sa_out -> layer_10_ep14_tp_allreduce
	layer_10_ep15_tp_allreduce [label="TP All-Reduce\nEP-Group-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_10_ep15_tp0_sa_out -> layer_10_ep15_tp_allreduce
	layer_10_ep15_tp1_sa_out -> layer_10_ep15_tp_allreduce
	layer_10_ep15_tp2_sa_out -> layer_10_ep15_tp_allreduce
	layer_10_ep15_tp3_sa_out -> layer_10_ep15_tp_allreduce
	layer_10_ep0_gate [label="MoE Gate\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_10_ep0_expert_0 [label="Expert-0\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep0_gate -> layer_10_ep0_expert_0 [label="select tokens" style=dashed]
	layer_10_ep0_expert_1 [label="Expert-1\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep0_gate -> layer_10_ep0_expert_1 [label="select tokens" style=dashed]
	layer_10_ep0_expert_2 [label="Expert-2\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep0_gate -> layer_10_ep0_expert_2 [label="select tokens" style=dashed]
	layer_10_ep0_expert_3 [label="Expert-3\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep0_gate -> layer_10_ep0_expert_3 [label="select tokens" style=dashed]
	layer_10_ep0_expert_aggr [label="Expert Aggregation\nEP-Group-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_10_ep0_expert_0 -> layer_10_ep0_expert_aggr
	layer_10_ep0_expert_1 -> layer_10_ep0_expert_aggr
	layer_10_ep0_expert_2 -> layer_10_ep0_expert_aggr
	layer_10_ep0_expert_3 -> layer_10_ep0_expert_aggr
	layer_10_ep1_gate [label="MoE Gate\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_10_ep1_expert_0 [label="Expert-0\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep1_gate -> layer_10_ep1_expert_0 [label="select tokens" style=dashed]
	layer_10_ep1_expert_1 [label="Expert-1\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep1_gate -> layer_10_ep1_expert_1 [label="select tokens" style=dashed]
	layer_10_ep1_expert_2 [label="Expert-2\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep1_gate -> layer_10_ep1_expert_2 [label="select tokens" style=dashed]
	layer_10_ep1_expert_3 [label="Expert-3\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep1_gate -> layer_10_ep1_expert_3 [label="select tokens" style=dashed]
	layer_10_ep1_expert_aggr [label="Expert Aggregation\nEP-Group-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_10_ep1_expert_0 -> layer_10_ep1_expert_aggr
	layer_10_ep1_expert_1 -> layer_10_ep1_expert_aggr
	layer_10_ep1_expert_2 -> layer_10_ep1_expert_aggr
	layer_10_ep1_expert_3 -> layer_10_ep1_expert_aggr
	layer_10_ep2_gate [label="MoE Gate\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_10_ep2_expert_0 [label="Expert-0\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep2_gate -> layer_10_ep2_expert_0 [label="select tokens" style=dashed]
	layer_10_ep2_expert_1 [label="Expert-1\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep2_gate -> layer_10_ep2_expert_1 [label="select tokens" style=dashed]
	layer_10_ep2_expert_2 [label="Expert-2\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep2_gate -> layer_10_ep2_expert_2 [label="select tokens" style=dashed]
	layer_10_ep2_expert_3 [label="Expert-3\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep2_gate -> layer_10_ep2_expert_3 [label="select tokens" style=dashed]
	layer_10_ep2_expert_aggr [label="Expert Aggregation\nEP-Group-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_10_ep2_expert_0 -> layer_10_ep2_expert_aggr
	layer_10_ep2_expert_1 -> layer_10_ep2_expert_aggr
	layer_10_ep2_expert_2 -> layer_10_ep2_expert_aggr
	layer_10_ep2_expert_3 -> layer_10_ep2_expert_aggr
	layer_10_ep3_gate [label="MoE Gate\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_10_ep3_expert_0 [label="Expert-0\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep3_gate -> layer_10_ep3_expert_0 [label="select tokens" style=dashed]
	layer_10_ep3_expert_1 [label="Expert-1\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep3_gate -> layer_10_ep3_expert_1 [label="select tokens" style=dashed]
	layer_10_ep3_expert_2 [label="Expert-2\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep3_gate -> layer_10_ep3_expert_2 [label="select tokens" style=dashed]
	layer_10_ep3_expert_3 [label="Expert-3\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep3_gate -> layer_10_ep3_expert_3 [label="select tokens" style=dashed]
	layer_10_ep3_expert_aggr [label="Expert Aggregation\nEP-Group-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_10_ep3_expert_0 -> layer_10_ep3_expert_aggr
	layer_10_ep3_expert_1 -> layer_10_ep3_expert_aggr
	layer_10_ep3_expert_2 -> layer_10_ep3_expert_aggr
	layer_10_ep3_expert_3 -> layer_10_ep3_expert_aggr
	layer_10_ep4_gate [label="MoE Gate\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_10_ep4_expert_0 [label="Expert-0\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep4_gate -> layer_10_ep4_expert_0 [label="select tokens" style=dashed]
	layer_10_ep4_expert_1 [label="Expert-1\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep4_gate -> layer_10_ep4_expert_1 [label="select tokens" style=dashed]
	layer_10_ep4_expert_2 [label="Expert-2\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep4_gate -> layer_10_ep4_expert_2 [label="select tokens" style=dashed]
	layer_10_ep4_expert_3 [label="Expert-3\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep4_gate -> layer_10_ep4_expert_3 [label="select tokens" style=dashed]
	layer_10_ep4_expert_aggr [label="Expert Aggregation\nEP-Group-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_10_ep4_expert_0 -> layer_10_ep4_expert_aggr
	layer_10_ep4_expert_1 -> layer_10_ep4_expert_aggr
	layer_10_ep4_expert_2 -> layer_10_ep4_expert_aggr
	layer_10_ep4_expert_3 -> layer_10_ep4_expert_aggr
	layer_10_ep5_gate [label="MoE Gate\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_10_ep5_expert_0 [label="Expert-0\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep5_gate -> layer_10_ep5_expert_0 [label="select tokens" style=dashed]
	layer_10_ep5_expert_1 [label="Expert-1\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep5_gate -> layer_10_ep5_expert_1 [label="select tokens" style=dashed]
	layer_10_ep5_expert_2 [label="Expert-2\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep5_gate -> layer_10_ep5_expert_2 [label="select tokens" style=dashed]
	layer_10_ep5_expert_3 [label="Expert-3\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep5_gate -> layer_10_ep5_expert_3 [label="select tokens" style=dashed]
	layer_10_ep5_expert_aggr [label="Expert Aggregation\nEP-Group-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_10_ep5_expert_0 -> layer_10_ep5_expert_aggr
	layer_10_ep5_expert_1 -> layer_10_ep5_expert_aggr
	layer_10_ep5_expert_2 -> layer_10_ep5_expert_aggr
	layer_10_ep5_expert_3 -> layer_10_ep5_expert_aggr
	layer_10_ep6_gate [label="MoE Gate\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_10_ep6_expert_0 [label="Expert-0\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep6_gate -> layer_10_ep6_expert_0 [label="select tokens" style=dashed]
	layer_10_ep6_expert_1 [label="Expert-1\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep6_gate -> layer_10_ep6_expert_1 [label="select tokens" style=dashed]
	layer_10_ep6_expert_2 [label="Expert-2\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep6_gate -> layer_10_ep6_expert_2 [label="select tokens" style=dashed]
	layer_10_ep6_expert_3 [label="Expert-3\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep6_gate -> layer_10_ep6_expert_3 [label="select tokens" style=dashed]
	layer_10_ep6_expert_aggr [label="Expert Aggregation\nEP-Group-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_10_ep6_expert_0 -> layer_10_ep6_expert_aggr
	layer_10_ep6_expert_1 -> layer_10_ep6_expert_aggr
	layer_10_ep6_expert_2 -> layer_10_ep6_expert_aggr
	layer_10_ep6_expert_3 -> layer_10_ep6_expert_aggr
	layer_10_ep7_gate [label="MoE Gate\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_10_ep7_expert_0 [label="Expert-0\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep7_gate -> layer_10_ep7_expert_0 [label="select tokens" style=dashed]
	layer_10_ep7_expert_1 [label="Expert-1\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep7_gate -> layer_10_ep7_expert_1 [label="select tokens" style=dashed]
	layer_10_ep7_expert_2 [label="Expert-2\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep7_gate -> layer_10_ep7_expert_2 [label="select tokens" style=dashed]
	layer_10_ep7_expert_3 [label="Expert-3\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep7_gate -> layer_10_ep7_expert_3 [label="select tokens" style=dashed]
	layer_10_ep7_expert_aggr [label="Expert Aggregation\nEP-Group-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_10_ep7_expert_0 -> layer_10_ep7_expert_aggr
	layer_10_ep7_expert_1 -> layer_10_ep7_expert_aggr
	layer_10_ep7_expert_2 -> layer_10_ep7_expert_aggr
	layer_10_ep7_expert_3 -> layer_10_ep7_expert_aggr
	layer_10_ep8_gate [label="MoE Gate\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_10_ep8_expert_0 [label="Expert-0\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep8_gate -> layer_10_ep8_expert_0 [label="select tokens" style=dashed]
	layer_10_ep8_expert_1 [label="Expert-1\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep8_gate -> layer_10_ep8_expert_1 [label="select tokens" style=dashed]
	layer_10_ep8_expert_2 [label="Expert-2\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep8_gate -> layer_10_ep8_expert_2 [label="select tokens" style=dashed]
	layer_10_ep8_expert_3 [label="Expert-3\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep8_gate -> layer_10_ep8_expert_3 [label="select tokens" style=dashed]
	layer_10_ep8_expert_aggr [label="Expert Aggregation\nEP-Group-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_10_ep8_expert_0 -> layer_10_ep8_expert_aggr
	layer_10_ep8_expert_1 -> layer_10_ep8_expert_aggr
	layer_10_ep8_expert_2 -> layer_10_ep8_expert_aggr
	layer_10_ep8_expert_3 -> layer_10_ep8_expert_aggr
	layer_10_ep9_gate [label="MoE Gate\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_10_ep9_expert_0 [label="Expert-0\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep9_gate -> layer_10_ep9_expert_0 [label="select tokens" style=dashed]
	layer_10_ep9_expert_1 [label="Expert-1\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep9_gate -> layer_10_ep9_expert_1 [label="select tokens" style=dashed]
	layer_10_ep9_expert_2 [label="Expert-2\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep9_gate -> layer_10_ep9_expert_2 [label="select tokens" style=dashed]
	layer_10_ep9_expert_3 [label="Expert-3\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep9_gate -> layer_10_ep9_expert_3 [label="select tokens" style=dashed]
	layer_10_ep9_expert_aggr [label="Expert Aggregation\nEP-Group-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_10_ep9_expert_0 -> layer_10_ep9_expert_aggr
	layer_10_ep9_expert_1 -> layer_10_ep9_expert_aggr
	layer_10_ep9_expert_2 -> layer_10_ep9_expert_aggr
	layer_10_ep9_expert_3 -> layer_10_ep9_expert_aggr
	layer_10_ep10_gate [label="MoE Gate\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_10_ep10_expert_0 [label="Expert-0\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep10_gate -> layer_10_ep10_expert_0 [label="select tokens" style=dashed]
	layer_10_ep10_expert_1 [label="Expert-1\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep10_gate -> layer_10_ep10_expert_1 [label="select tokens" style=dashed]
	layer_10_ep10_expert_2 [label="Expert-2\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep10_gate -> layer_10_ep10_expert_2 [label="select tokens" style=dashed]
	layer_10_ep10_expert_3 [label="Expert-3\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep10_gate -> layer_10_ep10_expert_3 [label="select tokens" style=dashed]
	layer_10_ep10_expert_aggr [label="Expert Aggregation\nEP-Group-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_10_ep10_expert_0 -> layer_10_ep10_expert_aggr
	layer_10_ep10_expert_1 -> layer_10_ep10_expert_aggr
	layer_10_ep10_expert_2 -> layer_10_ep10_expert_aggr
	layer_10_ep10_expert_3 -> layer_10_ep10_expert_aggr
	layer_10_ep11_gate [label="MoE Gate\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_10_ep11_expert_0 [label="Expert-0\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep11_gate -> layer_10_ep11_expert_0 [label="select tokens" style=dashed]
	layer_10_ep11_expert_1 [label="Expert-1\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep11_gate -> layer_10_ep11_expert_1 [label="select tokens" style=dashed]
	layer_10_ep11_expert_2 [label="Expert-2\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep11_gate -> layer_10_ep11_expert_2 [label="select tokens" style=dashed]
	layer_10_ep11_expert_3 [label="Expert-3\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep11_gate -> layer_10_ep11_expert_3 [label="select tokens" style=dashed]
	layer_10_ep11_expert_aggr [label="Expert Aggregation\nEP-Group-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_10_ep11_expert_0 -> layer_10_ep11_expert_aggr
	layer_10_ep11_expert_1 -> layer_10_ep11_expert_aggr
	layer_10_ep11_expert_2 -> layer_10_ep11_expert_aggr
	layer_10_ep11_expert_3 -> layer_10_ep11_expert_aggr
	layer_10_ep12_gate [label="MoE Gate\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_10_ep12_expert_0 [label="Expert-0\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep12_gate -> layer_10_ep12_expert_0 [label="select tokens" style=dashed]
	layer_10_ep12_expert_1 [label="Expert-1\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep12_gate -> layer_10_ep12_expert_1 [label="select tokens" style=dashed]
	layer_10_ep12_expert_2 [label="Expert-2\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep12_gate -> layer_10_ep12_expert_2 [label="select tokens" style=dashed]
	layer_10_ep12_expert_3 [label="Expert-3\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep12_gate -> layer_10_ep12_expert_3 [label="select tokens" style=dashed]
	layer_10_ep12_expert_aggr [label="Expert Aggregation\nEP-Group-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_10_ep12_expert_0 -> layer_10_ep12_expert_aggr
	layer_10_ep12_expert_1 -> layer_10_ep12_expert_aggr
	layer_10_ep12_expert_2 -> layer_10_ep12_expert_aggr
	layer_10_ep12_expert_3 -> layer_10_ep12_expert_aggr
	layer_10_ep13_gate [label="MoE Gate\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_10_ep13_expert_0 [label="Expert-0\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep13_gate -> layer_10_ep13_expert_0 [label="select tokens" style=dashed]
	layer_10_ep13_expert_1 [label="Expert-1\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep13_gate -> layer_10_ep13_expert_1 [label="select tokens" style=dashed]
	layer_10_ep13_expert_2 [label="Expert-2\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep13_gate -> layer_10_ep13_expert_2 [label="select tokens" style=dashed]
	layer_10_ep13_expert_3 [label="Expert-3\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep13_gate -> layer_10_ep13_expert_3 [label="select tokens" style=dashed]
	layer_10_ep13_expert_aggr [label="Expert Aggregation\nEP-Group-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_10_ep13_expert_0 -> layer_10_ep13_expert_aggr
	layer_10_ep13_expert_1 -> layer_10_ep13_expert_aggr
	layer_10_ep13_expert_2 -> layer_10_ep13_expert_aggr
	layer_10_ep13_expert_3 -> layer_10_ep13_expert_aggr
	layer_10_ep14_gate [label="MoE Gate\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_10_ep14_expert_0 [label="Expert-0\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep14_gate -> layer_10_ep14_expert_0 [label="select tokens" style=dashed]
	layer_10_ep14_expert_1 [label="Expert-1\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep14_gate -> layer_10_ep14_expert_1 [label="select tokens" style=dashed]
	layer_10_ep14_expert_2 [label="Expert-2\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep14_gate -> layer_10_ep14_expert_2 [label="select tokens" style=dashed]
	layer_10_ep14_expert_3 [label="Expert-3\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep14_gate -> layer_10_ep14_expert_3 [label="select tokens" style=dashed]
	layer_10_ep14_expert_aggr [label="Expert Aggregation\nEP-Group-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_10_ep14_expert_0 -> layer_10_ep14_expert_aggr
	layer_10_ep14_expert_1 -> layer_10_ep14_expert_aggr
	layer_10_ep14_expert_2 -> layer_10_ep14_expert_aggr
	layer_10_ep14_expert_3 -> layer_10_ep14_expert_aggr
	layer_10_ep15_gate [label="MoE Gate\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_10_ep15_expert_0 [label="Expert-0\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep15_gate -> layer_10_ep15_expert_0 [label="select tokens" style=dashed]
	layer_10_ep15_expert_1 [label="Expert-1\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep15_gate -> layer_10_ep15_expert_1 [label="select tokens" style=dashed]
	layer_10_ep15_expert_2 [label="Expert-2\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep15_gate -> layer_10_ep15_expert_2 [label="select tokens" style=dashed]
	layer_10_ep15_expert_3 [label="Expert-3\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_10_ep15_gate -> layer_10_ep15_expert_3 [label="select tokens" style=dashed]
	layer_10_ep15_expert_aggr [label="Expert Aggregation\nEP-Group-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_10_ep15_expert_0 -> layer_10_ep15_expert_aggr
	layer_10_ep15_expert_1 -> layer_10_ep15_expert_aggr
	layer_10_ep15_expert_2 -> layer_10_ep15_expert_aggr
	layer_10_ep15_expert_3 -> layer_10_ep15_expert_aggr
	layer_10_to_11_ep0_pp [label="Pipeline Stage Transfer\nEP-Group-0\nLayer-10 to Layer-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_10_ep0_expert_aggr -> layer_10_to_11_ep0_pp
	layer_10_to_11_ep1_pp [label="Pipeline Stage Transfer\nEP-Group-1\nLayer-10 to Layer-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_10_ep1_expert_aggr -> layer_10_to_11_ep1_pp
	layer_10_to_11_ep2_pp [label="Pipeline Stage Transfer\nEP-Group-2\nLayer-10 to Layer-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_10_ep2_expert_aggr -> layer_10_to_11_ep2_pp
	layer_10_to_11_ep3_pp [label="Pipeline Stage Transfer\nEP-Group-3\nLayer-10 to Layer-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_10_ep3_expert_aggr -> layer_10_to_11_ep3_pp
	layer_10_to_11_ep4_pp [label="Pipeline Stage Transfer\nEP-Group-4\nLayer-10 to Layer-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_10_ep4_expert_aggr -> layer_10_to_11_ep4_pp
	layer_10_to_11_ep5_pp [label="Pipeline Stage Transfer\nEP-Group-5\nLayer-10 to Layer-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_10_ep5_expert_aggr -> layer_10_to_11_ep5_pp
	layer_10_to_11_ep6_pp [label="Pipeline Stage Transfer\nEP-Group-6\nLayer-10 to Layer-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_10_ep6_expert_aggr -> layer_10_to_11_ep6_pp
	layer_10_to_11_ep7_pp [label="Pipeline Stage Transfer\nEP-Group-7\nLayer-10 to Layer-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_10_ep7_expert_aggr -> layer_10_to_11_ep7_pp
	layer_10_to_11_ep8_pp [label="Pipeline Stage Transfer\nEP-Group-8\nLayer-10 to Layer-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_10_ep8_expert_aggr -> layer_10_to_11_ep8_pp
	layer_10_to_11_ep9_pp [label="Pipeline Stage Transfer\nEP-Group-9\nLayer-10 to Layer-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_10_ep9_expert_aggr -> layer_10_to_11_ep9_pp
	layer_10_to_11_ep10_pp [label="Pipeline Stage Transfer\nEP-Group-10\nLayer-10 to Layer-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_10_ep10_expert_aggr -> layer_10_to_11_ep10_pp
	layer_10_to_11_ep11_pp [label="Pipeline Stage Transfer\nEP-Group-11\nLayer-10 to Layer-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_10_ep11_expert_aggr -> layer_10_to_11_ep11_pp
	layer_10_to_11_ep12_pp [label="Pipeline Stage Transfer\nEP-Group-12\nLayer-10 to Layer-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_10_ep12_expert_aggr -> layer_10_to_11_ep12_pp
	layer_10_to_11_ep13_pp [label="Pipeline Stage Transfer\nEP-Group-13\nLayer-10 to Layer-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_10_ep13_expert_aggr -> layer_10_to_11_ep13_pp
	layer_10_to_11_ep14_pp [label="Pipeline Stage Transfer\nEP-Group-14\nLayer-10 to Layer-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_10_ep14_expert_aggr -> layer_10_to_11_ep14_pp
	layer_10_to_11_ep15_pp [label="Pipeline Stage Transfer\nEP-Group-15\nLayer-10 to Layer-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_10_ep15_expert_aggr -> layer_10_to_11_ep15_pp
	layer_11_ep0_tp0_sa_qkv [label="Self-Attn QKV\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep0_tp0_sa_attn [label="Self-Attn Compute\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep0_tp0_sa_out [label="Self-Attn Output\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep0_tp0_sa_qkv -> layer_11_ep0_tp0_sa_attn
	layer_11_ep0_tp0_sa_attn -> layer_11_ep0_tp0_sa_out
	layer_11_ep0_tp1_sa_qkv [label="Self-Attn QKV\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep0_tp1_sa_attn [label="Self-Attn Compute\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep0_tp1_sa_out [label="Self-Attn Output\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep0_tp1_sa_qkv -> layer_11_ep0_tp1_sa_attn
	layer_11_ep0_tp1_sa_attn -> layer_11_ep0_tp1_sa_out
	layer_11_ep0_tp2_sa_qkv [label="Self-Attn QKV\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep0_tp2_sa_attn [label="Self-Attn Compute\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep0_tp2_sa_out [label="Self-Attn Output\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep0_tp2_sa_qkv -> layer_11_ep0_tp2_sa_attn
	layer_11_ep0_tp2_sa_attn -> layer_11_ep0_tp2_sa_out
	layer_11_ep0_tp3_sa_qkv [label="Self-Attn QKV\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep0_tp3_sa_attn [label="Self-Attn Compute\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep0_tp3_sa_out [label="Self-Attn Output\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep0_tp3_sa_qkv -> layer_11_ep0_tp3_sa_attn
	layer_11_ep0_tp3_sa_attn -> layer_11_ep0_tp3_sa_out
	layer_11_ep1_tp0_sa_qkv [label="Self-Attn QKV\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep1_tp0_sa_attn [label="Self-Attn Compute\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep1_tp0_sa_out [label="Self-Attn Output\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep1_tp0_sa_qkv -> layer_11_ep1_tp0_sa_attn
	layer_11_ep1_tp0_sa_attn -> layer_11_ep1_tp0_sa_out
	layer_11_ep1_tp1_sa_qkv [label="Self-Attn QKV\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep1_tp1_sa_attn [label="Self-Attn Compute\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep1_tp1_sa_out [label="Self-Attn Output\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep1_tp1_sa_qkv -> layer_11_ep1_tp1_sa_attn
	layer_11_ep1_tp1_sa_attn -> layer_11_ep1_tp1_sa_out
	layer_11_ep1_tp2_sa_qkv [label="Self-Attn QKV\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep1_tp2_sa_attn [label="Self-Attn Compute\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep1_tp2_sa_out [label="Self-Attn Output\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep1_tp2_sa_qkv -> layer_11_ep1_tp2_sa_attn
	layer_11_ep1_tp2_sa_attn -> layer_11_ep1_tp2_sa_out
	layer_11_ep1_tp3_sa_qkv [label="Self-Attn QKV\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep1_tp3_sa_attn [label="Self-Attn Compute\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep1_tp3_sa_out [label="Self-Attn Output\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep1_tp3_sa_qkv -> layer_11_ep1_tp3_sa_attn
	layer_11_ep1_tp3_sa_attn -> layer_11_ep1_tp3_sa_out
	layer_11_ep2_tp0_sa_qkv [label="Self-Attn QKV\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep2_tp0_sa_attn [label="Self-Attn Compute\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep2_tp0_sa_out [label="Self-Attn Output\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep2_tp0_sa_qkv -> layer_11_ep2_tp0_sa_attn
	layer_11_ep2_tp0_sa_attn -> layer_11_ep2_tp0_sa_out
	layer_11_ep2_tp1_sa_qkv [label="Self-Attn QKV\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep2_tp1_sa_attn [label="Self-Attn Compute\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep2_tp1_sa_out [label="Self-Attn Output\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep2_tp1_sa_qkv -> layer_11_ep2_tp1_sa_attn
	layer_11_ep2_tp1_sa_attn -> layer_11_ep2_tp1_sa_out
	layer_11_ep2_tp2_sa_qkv [label="Self-Attn QKV\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep2_tp2_sa_attn [label="Self-Attn Compute\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep2_tp2_sa_out [label="Self-Attn Output\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep2_tp2_sa_qkv -> layer_11_ep2_tp2_sa_attn
	layer_11_ep2_tp2_sa_attn -> layer_11_ep2_tp2_sa_out
	layer_11_ep2_tp3_sa_qkv [label="Self-Attn QKV\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep2_tp3_sa_attn [label="Self-Attn Compute\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep2_tp3_sa_out [label="Self-Attn Output\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep2_tp3_sa_qkv -> layer_11_ep2_tp3_sa_attn
	layer_11_ep2_tp3_sa_attn -> layer_11_ep2_tp3_sa_out
	layer_11_ep3_tp0_sa_qkv [label="Self-Attn QKV\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep3_tp0_sa_attn [label="Self-Attn Compute\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep3_tp0_sa_out [label="Self-Attn Output\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep3_tp0_sa_qkv -> layer_11_ep3_tp0_sa_attn
	layer_11_ep3_tp0_sa_attn -> layer_11_ep3_tp0_sa_out
	layer_11_ep3_tp1_sa_qkv [label="Self-Attn QKV\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep3_tp1_sa_attn [label="Self-Attn Compute\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep3_tp1_sa_out [label="Self-Attn Output\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep3_tp1_sa_qkv -> layer_11_ep3_tp1_sa_attn
	layer_11_ep3_tp1_sa_attn -> layer_11_ep3_tp1_sa_out
	layer_11_ep3_tp2_sa_qkv [label="Self-Attn QKV\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep3_tp2_sa_attn [label="Self-Attn Compute\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep3_tp2_sa_out [label="Self-Attn Output\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep3_tp2_sa_qkv -> layer_11_ep3_tp2_sa_attn
	layer_11_ep3_tp2_sa_attn -> layer_11_ep3_tp2_sa_out
	layer_11_ep3_tp3_sa_qkv [label="Self-Attn QKV\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep3_tp3_sa_attn [label="Self-Attn Compute\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep3_tp3_sa_out [label="Self-Attn Output\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep3_tp3_sa_qkv -> layer_11_ep3_tp3_sa_attn
	layer_11_ep3_tp3_sa_attn -> layer_11_ep3_tp3_sa_out
	layer_11_ep4_tp0_sa_qkv [label="Self-Attn QKV\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep4_tp0_sa_attn [label="Self-Attn Compute\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep4_tp0_sa_out [label="Self-Attn Output\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep4_tp0_sa_qkv -> layer_11_ep4_tp0_sa_attn
	layer_11_ep4_tp0_sa_attn -> layer_11_ep4_tp0_sa_out
	layer_11_ep4_tp1_sa_qkv [label="Self-Attn QKV\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep4_tp1_sa_attn [label="Self-Attn Compute\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep4_tp1_sa_out [label="Self-Attn Output\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep4_tp1_sa_qkv -> layer_11_ep4_tp1_sa_attn
	layer_11_ep4_tp1_sa_attn -> layer_11_ep4_tp1_sa_out
	layer_11_ep4_tp2_sa_qkv [label="Self-Attn QKV\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep4_tp2_sa_attn [label="Self-Attn Compute\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep4_tp2_sa_out [label="Self-Attn Output\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep4_tp2_sa_qkv -> layer_11_ep4_tp2_sa_attn
	layer_11_ep4_tp2_sa_attn -> layer_11_ep4_tp2_sa_out
	layer_11_ep4_tp3_sa_qkv [label="Self-Attn QKV\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep4_tp3_sa_attn [label="Self-Attn Compute\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep4_tp3_sa_out [label="Self-Attn Output\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep4_tp3_sa_qkv -> layer_11_ep4_tp3_sa_attn
	layer_11_ep4_tp3_sa_attn -> layer_11_ep4_tp3_sa_out
	layer_11_ep5_tp0_sa_qkv [label="Self-Attn QKV\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep5_tp0_sa_attn [label="Self-Attn Compute\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep5_tp0_sa_out [label="Self-Attn Output\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep5_tp0_sa_qkv -> layer_11_ep5_tp0_sa_attn
	layer_11_ep5_tp0_sa_attn -> layer_11_ep5_tp0_sa_out
	layer_11_ep5_tp1_sa_qkv [label="Self-Attn QKV\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep5_tp1_sa_attn [label="Self-Attn Compute\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep5_tp1_sa_out [label="Self-Attn Output\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep5_tp1_sa_qkv -> layer_11_ep5_tp1_sa_attn
	layer_11_ep5_tp1_sa_attn -> layer_11_ep5_tp1_sa_out
	layer_11_ep5_tp2_sa_qkv [label="Self-Attn QKV\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep5_tp2_sa_attn [label="Self-Attn Compute\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep5_tp2_sa_out [label="Self-Attn Output\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep5_tp2_sa_qkv -> layer_11_ep5_tp2_sa_attn
	layer_11_ep5_tp2_sa_attn -> layer_11_ep5_tp2_sa_out
	layer_11_ep5_tp3_sa_qkv [label="Self-Attn QKV\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep5_tp3_sa_attn [label="Self-Attn Compute\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep5_tp3_sa_out [label="Self-Attn Output\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep5_tp3_sa_qkv -> layer_11_ep5_tp3_sa_attn
	layer_11_ep5_tp3_sa_attn -> layer_11_ep5_tp3_sa_out
	layer_11_ep6_tp0_sa_qkv [label="Self-Attn QKV\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep6_tp0_sa_attn [label="Self-Attn Compute\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep6_tp0_sa_out [label="Self-Attn Output\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep6_tp0_sa_qkv -> layer_11_ep6_tp0_sa_attn
	layer_11_ep6_tp0_sa_attn -> layer_11_ep6_tp0_sa_out
	layer_11_ep6_tp1_sa_qkv [label="Self-Attn QKV\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep6_tp1_sa_attn [label="Self-Attn Compute\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep6_tp1_sa_out [label="Self-Attn Output\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep6_tp1_sa_qkv -> layer_11_ep6_tp1_sa_attn
	layer_11_ep6_tp1_sa_attn -> layer_11_ep6_tp1_sa_out
	layer_11_ep6_tp2_sa_qkv [label="Self-Attn QKV\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep6_tp2_sa_attn [label="Self-Attn Compute\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep6_tp2_sa_out [label="Self-Attn Output\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep6_tp2_sa_qkv -> layer_11_ep6_tp2_sa_attn
	layer_11_ep6_tp2_sa_attn -> layer_11_ep6_tp2_sa_out
	layer_11_ep6_tp3_sa_qkv [label="Self-Attn QKV\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep6_tp3_sa_attn [label="Self-Attn Compute\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep6_tp3_sa_out [label="Self-Attn Output\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep6_tp3_sa_qkv -> layer_11_ep6_tp3_sa_attn
	layer_11_ep6_tp3_sa_attn -> layer_11_ep6_tp3_sa_out
	layer_11_ep7_tp0_sa_qkv [label="Self-Attn QKV\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep7_tp0_sa_attn [label="Self-Attn Compute\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep7_tp0_sa_out [label="Self-Attn Output\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep7_tp0_sa_qkv -> layer_11_ep7_tp0_sa_attn
	layer_11_ep7_tp0_sa_attn -> layer_11_ep7_tp0_sa_out
	layer_11_ep7_tp1_sa_qkv [label="Self-Attn QKV\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep7_tp1_sa_attn [label="Self-Attn Compute\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep7_tp1_sa_out [label="Self-Attn Output\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep7_tp1_sa_qkv -> layer_11_ep7_tp1_sa_attn
	layer_11_ep7_tp1_sa_attn -> layer_11_ep7_tp1_sa_out
	layer_11_ep7_tp2_sa_qkv [label="Self-Attn QKV\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep7_tp2_sa_attn [label="Self-Attn Compute\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep7_tp2_sa_out [label="Self-Attn Output\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep7_tp2_sa_qkv -> layer_11_ep7_tp2_sa_attn
	layer_11_ep7_tp2_sa_attn -> layer_11_ep7_tp2_sa_out
	layer_11_ep7_tp3_sa_qkv [label="Self-Attn QKV\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep7_tp3_sa_attn [label="Self-Attn Compute\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep7_tp3_sa_out [label="Self-Attn Output\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep7_tp3_sa_qkv -> layer_11_ep7_tp3_sa_attn
	layer_11_ep7_tp3_sa_attn -> layer_11_ep7_tp3_sa_out
	layer_11_ep8_tp0_sa_qkv [label="Self-Attn QKV\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep8_tp0_sa_attn [label="Self-Attn Compute\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep8_tp0_sa_out [label="Self-Attn Output\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep8_tp0_sa_qkv -> layer_11_ep8_tp0_sa_attn
	layer_11_ep8_tp0_sa_attn -> layer_11_ep8_tp0_sa_out
	layer_11_ep8_tp1_sa_qkv [label="Self-Attn QKV\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep8_tp1_sa_attn [label="Self-Attn Compute\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep8_tp1_sa_out [label="Self-Attn Output\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep8_tp1_sa_qkv -> layer_11_ep8_tp1_sa_attn
	layer_11_ep8_tp1_sa_attn -> layer_11_ep8_tp1_sa_out
	layer_11_ep8_tp2_sa_qkv [label="Self-Attn QKV\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep8_tp2_sa_attn [label="Self-Attn Compute\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep8_tp2_sa_out [label="Self-Attn Output\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep8_tp2_sa_qkv -> layer_11_ep8_tp2_sa_attn
	layer_11_ep8_tp2_sa_attn -> layer_11_ep8_tp2_sa_out
	layer_11_ep8_tp3_sa_qkv [label="Self-Attn QKV\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep8_tp3_sa_attn [label="Self-Attn Compute\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep8_tp3_sa_out [label="Self-Attn Output\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep8_tp3_sa_qkv -> layer_11_ep8_tp3_sa_attn
	layer_11_ep8_tp3_sa_attn -> layer_11_ep8_tp3_sa_out
	layer_11_ep9_tp0_sa_qkv [label="Self-Attn QKV\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep9_tp0_sa_attn [label="Self-Attn Compute\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep9_tp0_sa_out [label="Self-Attn Output\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep9_tp0_sa_qkv -> layer_11_ep9_tp0_sa_attn
	layer_11_ep9_tp0_sa_attn -> layer_11_ep9_tp0_sa_out
	layer_11_ep9_tp1_sa_qkv [label="Self-Attn QKV\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep9_tp1_sa_attn [label="Self-Attn Compute\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep9_tp1_sa_out [label="Self-Attn Output\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep9_tp1_sa_qkv -> layer_11_ep9_tp1_sa_attn
	layer_11_ep9_tp1_sa_attn -> layer_11_ep9_tp1_sa_out
	layer_11_ep9_tp2_sa_qkv [label="Self-Attn QKV\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep9_tp2_sa_attn [label="Self-Attn Compute\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep9_tp2_sa_out [label="Self-Attn Output\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep9_tp2_sa_qkv -> layer_11_ep9_tp2_sa_attn
	layer_11_ep9_tp2_sa_attn -> layer_11_ep9_tp2_sa_out
	layer_11_ep9_tp3_sa_qkv [label="Self-Attn QKV\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep9_tp3_sa_attn [label="Self-Attn Compute\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep9_tp3_sa_out [label="Self-Attn Output\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep9_tp3_sa_qkv -> layer_11_ep9_tp3_sa_attn
	layer_11_ep9_tp3_sa_attn -> layer_11_ep9_tp3_sa_out
	layer_11_ep10_tp0_sa_qkv [label="Self-Attn QKV\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep10_tp0_sa_attn [label="Self-Attn Compute\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep10_tp0_sa_out [label="Self-Attn Output\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep10_tp0_sa_qkv -> layer_11_ep10_tp0_sa_attn
	layer_11_ep10_tp0_sa_attn -> layer_11_ep10_tp0_sa_out
	layer_11_ep10_tp1_sa_qkv [label="Self-Attn QKV\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep10_tp1_sa_attn [label="Self-Attn Compute\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep10_tp1_sa_out [label="Self-Attn Output\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep10_tp1_sa_qkv -> layer_11_ep10_tp1_sa_attn
	layer_11_ep10_tp1_sa_attn -> layer_11_ep10_tp1_sa_out
	layer_11_ep10_tp2_sa_qkv [label="Self-Attn QKV\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep10_tp2_sa_attn [label="Self-Attn Compute\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep10_tp2_sa_out [label="Self-Attn Output\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep10_tp2_sa_qkv -> layer_11_ep10_tp2_sa_attn
	layer_11_ep10_tp2_sa_attn -> layer_11_ep10_tp2_sa_out
	layer_11_ep10_tp3_sa_qkv [label="Self-Attn QKV\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep10_tp3_sa_attn [label="Self-Attn Compute\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep10_tp3_sa_out [label="Self-Attn Output\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep10_tp3_sa_qkv -> layer_11_ep10_tp3_sa_attn
	layer_11_ep10_tp3_sa_attn -> layer_11_ep10_tp3_sa_out
	layer_11_ep11_tp0_sa_qkv [label="Self-Attn QKV\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep11_tp0_sa_attn [label="Self-Attn Compute\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep11_tp0_sa_out [label="Self-Attn Output\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep11_tp0_sa_qkv -> layer_11_ep11_tp0_sa_attn
	layer_11_ep11_tp0_sa_attn -> layer_11_ep11_tp0_sa_out
	layer_11_ep11_tp1_sa_qkv [label="Self-Attn QKV\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep11_tp1_sa_attn [label="Self-Attn Compute\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep11_tp1_sa_out [label="Self-Attn Output\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep11_tp1_sa_qkv -> layer_11_ep11_tp1_sa_attn
	layer_11_ep11_tp1_sa_attn -> layer_11_ep11_tp1_sa_out
	layer_11_ep11_tp2_sa_qkv [label="Self-Attn QKV\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep11_tp2_sa_attn [label="Self-Attn Compute\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep11_tp2_sa_out [label="Self-Attn Output\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep11_tp2_sa_qkv -> layer_11_ep11_tp2_sa_attn
	layer_11_ep11_tp2_sa_attn -> layer_11_ep11_tp2_sa_out
	layer_11_ep11_tp3_sa_qkv [label="Self-Attn QKV\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep11_tp3_sa_attn [label="Self-Attn Compute\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep11_tp3_sa_out [label="Self-Attn Output\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep11_tp3_sa_qkv -> layer_11_ep11_tp3_sa_attn
	layer_11_ep11_tp3_sa_attn -> layer_11_ep11_tp3_sa_out
	layer_11_ep12_tp0_sa_qkv [label="Self-Attn QKV\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep12_tp0_sa_attn [label="Self-Attn Compute\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep12_tp0_sa_out [label="Self-Attn Output\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep12_tp0_sa_qkv -> layer_11_ep12_tp0_sa_attn
	layer_11_ep12_tp0_sa_attn -> layer_11_ep12_tp0_sa_out
	layer_11_ep12_tp1_sa_qkv [label="Self-Attn QKV\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep12_tp1_sa_attn [label="Self-Attn Compute\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep12_tp1_sa_out [label="Self-Attn Output\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep12_tp1_sa_qkv -> layer_11_ep12_tp1_sa_attn
	layer_11_ep12_tp1_sa_attn -> layer_11_ep12_tp1_sa_out
	layer_11_ep12_tp2_sa_qkv [label="Self-Attn QKV\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep12_tp2_sa_attn [label="Self-Attn Compute\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep12_tp2_sa_out [label="Self-Attn Output\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep12_tp2_sa_qkv -> layer_11_ep12_tp2_sa_attn
	layer_11_ep12_tp2_sa_attn -> layer_11_ep12_tp2_sa_out
	layer_11_ep12_tp3_sa_qkv [label="Self-Attn QKV\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep12_tp3_sa_attn [label="Self-Attn Compute\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep12_tp3_sa_out [label="Self-Attn Output\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep12_tp3_sa_qkv -> layer_11_ep12_tp3_sa_attn
	layer_11_ep12_tp3_sa_attn -> layer_11_ep12_tp3_sa_out
	layer_11_ep13_tp0_sa_qkv [label="Self-Attn QKV\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep13_tp0_sa_attn [label="Self-Attn Compute\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep13_tp0_sa_out [label="Self-Attn Output\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep13_tp0_sa_qkv -> layer_11_ep13_tp0_sa_attn
	layer_11_ep13_tp0_sa_attn -> layer_11_ep13_tp0_sa_out
	layer_11_ep13_tp1_sa_qkv [label="Self-Attn QKV\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep13_tp1_sa_attn [label="Self-Attn Compute\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep13_tp1_sa_out [label="Self-Attn Output\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep13_tp1_sa_qkv -> layer_11_ep13_tp1_sa_attn
	layer_11_ep13_tp1_sa_attn -> layer_11_ep13_tp1_sa_out
	layer_11_ep13_tp2_sa_qkv [label="Self-Attn QKV\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep13_tp2_sa_attn [label="Self-Attn Compute\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep13_tp2_sa_out [label="Self-Attn Output\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep13_tp2_sa_qkv -> layer_11_ep13_tp2_sa_attn
	layer_11_ep13_tp2_sa_attn -> layer_11_ep13_tp2_sa_out
	layer_11_ep13_tp3_sa_qkv [label="Self-Attn QKV\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep13_tp3_sa_attn [label="Self-Attn Compute\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep13_tp3_sa_out [label="Self-Attn Output\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep13_tp3_sa_qkv -> layer_11_ep13_tp3_sa_attn
	layer_11_ep13_tp3_sa_attn -> layer_11_ep13_tp3_sa_out
	layer_11_ep14_tp0_sa_qkv [label="Self-Attn QKV\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep14_tp0_sa_attn [label="Self-Attn Compute\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep14_tp0_sa_out [label="Self-Attn Output\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep14_tp0_sa_qkv -> layer_11_ep14_tp0_sa_attn
	layer_11_ep14_tp0_sa_attn -> layer_11_ep14_tp0_sa_out
	layer_11_ep14_tp1_sa_qkv [label="Self-Attn QKV\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep14_tp1_sa_attn [label="Self-Attn Compute\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep14_tp1_sa_out [label="Self-Attn Output\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep14_tp1_sa_qkv -> layer_11_ep14_tp1_sa_attn
	layer_11_ep14_tp1_sa_attn -> layer_11_ep14_tp1_sa_out
	layer_11_ep14_tp2_sa_qkv [label="Self-Attn QKV\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep14_tp2_sa_attn [label="Self-Attn Compute\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep14_tp2_sa_out [label="Self-Attn Output\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep14_tp2_sa_qkv -> layer_11_ep14_tp2_sa_attn
	layer_11_ep14_tp2_sa_attn -> layer_11_ep14_tp2_sa_out
	layer_11_ep14_tp3_sa_qkv [label="Self-Attn QKV\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep14_tp3_sa_attn [label="Self-Attn Compute\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep14_tp3_sa_out [label="Self-Attn Output\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep14_tp3_sa_qkv -> layer_11_ep14_tp3_sa_attn
	layer_11_ep14_tp3_sa_attn -> layer_11_ep14_tp3_sa_out
	layer_11_ep15_tp0_sa_qkv [label="Self-Attn QKV\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep15_tp0_sa_attn [label="Self-Attn Compute\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep15_tp0_sa_out [label="Self-Attn Output\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep15_tp0_sa_qkv -> layer_11_ep15_tp0_sa_attn
	layer_11_ep15_tp0_sa_attn -> layer_11_ep15_tp0_sa_out
	layer_11_ep15_tp1_sa_qkv [label="Self-Attn QKV\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep15_tp1_sa_attn [label="Self-Attn Compute\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep15_tp1_sa_out [label="Self-Attn Output\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep15_tp1_sa_qkv -> layer_11_ep15_tp1_sa_attn
	layer_11_ep15_tp1_sa_attn -> layer_11_ep15_tp1_sa_out
	layer_11_ep15_tp2_sa_qkv [label="Self-Attn QKV\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep15_tp2_sa_attn [label="Self-Attn Compute\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep15_tp2_sa_out [label="Self-Attn Output\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep15_tp2_sa_qkv -> layer_11_ep15_tp2_sa_attn
	layer_11_ep15_tp2_sa_attn -> layer_11_ep15_tp2_sa_out
	layer_11_ep15_tp3_sa_qkv [label="Self-Attn QKV\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep15_tp3_sa_attn [label="Self-Attn Compute\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep15_tp3_sa_out [label="Self-Attn Output\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep15_tp3_sa_qkv -> layer_11_ep15_tp3_sa_attn
	layer_11_ep15_tp3_sa_attn -> layer_11_ep15_tp3_sa_out
	layer_11_ep0_tp_allreduce [label="TP All-Reduce\nEP-Group-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_11_ep0_tp0_sa_out -> layer_11_ep0_tp_allreduce
	layer_11_ep0_tp1_sa_out -> layer_11_ep0_tp_allreduce
	layer_11_ep0_tp2_sa_out -> layer_11_ep0_tp_allreduce
	layer_11_ep0_tp3_sa_out -> layer_11_ep0_tp_allreduce
	layer_11_ep1_tp_allreduce [label="TP All-Reduce\nEP-Group-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_11_ep1_tp0_sa_out -> layer_11_ep1_tp_allreduce
	layer_11_ep1_tp1_sa_out -> layer_11_ep1_tp_allreduce
	layer_11_ep1_tp2_sa_out -> layer_11_ep1_tp_allreduce
	layer_11_ep1_tp3_sa_out -> layer_11_ep1_tp_allreduce
	layer_11_ep2_tp_allreduce [label="TP All-Reduce\nEP-Group-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_11_ep2_tp0_sa_out -> layer_11_ep2_tp_allreduce
	layer_11_ep2_tp1_sa_out -> layer_11_ep2_tp_allreduce
	layer_11_ep2_tp2_sa_out -> layer_11_ep2_tp_allreduce
	layer_11_ep2_tp3_sa_out -> layer_11_ep2_tp_allreduce
	layer_11_ep3_tp_allreduce [label="TP All-Reduce\nEP-Group-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_11_ep3_tp0_sa_out -> layer_11_ep3_tp_allreduce
	layer_11_ep3_tp1_sa_out -> layer_11_ep3_tp_allreduce
	layer_11_ep3_tp2_sa_out -> layer_11_ep3_tp_allreduce
	layer_11_ep3_tp3_sa_out -> layer_11_ep3_tp_allreduce
	layer_11_ep4_tp_allreduce [label="TP All-Reduce\nEP-Group-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_11_ep4_tp0_sa_out -> layer_11_ep4_tp_allreduce
	layer_11_ep4_tp1_sa_out -> layer_11_ep4_tp_allreduce
	layer_11_ep4_tp2_sa_out -> layer_11_ep4_tp_allreduce
	layer_11_ep4_tp3_sa_out -> layer_11_ep4_tp_allreduce
	layer_11_ep5_tp_allreduce [label="TP All-Reduce\nEP-Group-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_11_ep5_tp0_sa_out -> layer_11_ep5_tp_allreduce
	layer_11_ep5_tp1_sa_out -> layer_11_ep5_tp_allreduce
	layer_11_ep5_tp2_sa_out -> layer_11_ep5_tp_allreduce
	layer_11_ep5_tp3_sa_out -> layer_11_ep5_tp_allreduce
	layer_11_ep6_tp_allreduce [label="TP All-Reduce\nEP-Group-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_11_ep6_tp0_sa_out -> layer_11_ep6_tp_allreduce
	layer_11_ep6_tp1_sa_out -> layer_11_ep6_tp_allreduce
	layer_11_ep6_tp2_sa_out -> layer_11_ep6_tp_allreduce
	layer_11_ep6_tp3_sa_out -> layer_11_ep6_tp_allreduce
	layer_11_ep7_tp_allreduce [label="TP All-Reduce\nEP-Group-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_11_ep7_tp0_sa_out -> layer_11_ep7_tp_allreduce
	layer_11_ep7_tp1_sa_out -> layer_11_ep7_tp_allreduce
	layer_11_ep7_tp2_sa_out -> layer_11_ep7_tp_allreduce
	layer_11_ep7_tp3_sa_out -> layer_11_ep7_tp_allreduce
	layer_11_ep8_tp_allreduce [label="TP All-Reduce\nEP-Group-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_11_ep8_tp0_sa_out -> layer_11_ep8_tp_allreduce
	layer_11_ep8_tp1_sa_out -> layer_11_ep8_tp_allreduce
	layer_11_ep8_tp2_sa_out -> layer_11_ep8_tp_allreduce
	layer_11_ep8_tp3_sa_out -> layer_11_ep8_tp_allreduce
	layer_11_ep9_tp_allreduce [label="TP All-Reduce\nEP-Group-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_11_ep9_tp0_sa_out -> layer_11_ep9_tp_allreduce
	layer_11_ep9_tp1_sa_out -> layer_11_ep9_tp_allreduce
	layer_11_ep9_tp2_sa_out -> layer_11_ep9_tp_allreduce
	layer_11_ep9_tp3_sa_out -> layer_11_ep9_tp_allreduce
	layer_11_ep10_tp_allreduce [label="TP All-Reduce\nEP-Group-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_11_ep10_tp0_sa_out -> layer_11_ep10_tp_allreduce
	layer_11_ep10_tp1_sa_out -> layer_11_ep10_tp_allreduce
	layer_11_ep10_tp2_sa_out -> layer_11_ep10_tp_allreduce
	layer_11_ep10_tp3_sa_out -> layer_11_ep10_tp_allreduce
	layer_11_ep11_tp_allreduce [label="TP All-Reduce\nEP-Group-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_11_ep11_tp0_sa_out -> layer_11_ep11_tp_allreduce
	layer_11_ep11_tp1_sa_out -> layer_11_ep11_tp_allreduce
	layer_11_ep11_tp2_sa_out -> layer_11_ep11_tp_allreduce
	layer_11_ep11_tp3_sa_out -> layer_11_ep11_tp_allreduce
	layer_11_ep12_tp_allreduce [label="TP All-Reduce\nEP-Group-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_11_ep12_tp0_sa_out -> layer_11_ep12_tp_allreduce
	layer_11_ep12_tp1_sa_out -> layer_11_ep12_tp_allreduce
	layer_11_ep12_tp2_sa_out -> layer_11_ep12_tp_allreduce
	layer_11_ep12_tp3_sa_out -> layer_11_ep12_tp_allreduce
	layer_11_ep13_tp_allreduce [label="TP All-Reduce\nEP-Group-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_11_ep13_tp0_sa_out -> layer_11_ep13_tp_allreduce
	layer_11_ep13_tp1_sa_out -> layer_11_ep13_tp_allreduce
	layer_11_ep13_tp2_sa_out -> layer_11_ep13_tp_allreduce
	layer_11_ep13_tp3_sa_out -> layer_11_ep13_tp_allreduce
	layer_11_ep14_tp_allreduce [label="TP All-Reduce\nEP-Group-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_11_ep14_tp0_sa_out -> layer_11_ep14_tp_allreduce
	layer_11_ep14_tp1_sa_out -> layer_11_ep14_tp_allreduce
	layer_11_ep14_tp2_sa_out -> layer_11_ep14_tp_allreduce
	layer_11_ep14_tp3_sa_out -> layer_11_ep14_tp_allreduce
	layer_11_ep15_tp_allreduce [label="TP All-Reduce\nEP-Group-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_11_ep15_tp0_sa_out -> layer_11_ep15_tp_allreduce
	layer_11_ep15_tp1_sa_out -> layer_11_ep15_tp_allreduce
	layer_11_ep15_tp2_sa_out -> layer_11_ep15_tp_allreduce
	layer_11_ep15_tp3_sa_out -> layer_11_ep15_tp_allreduce
	layer_11_ep0_gate [label="MoE Gate\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_11_ep0_expert_0 [label="Expert-0\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep0_gate -> layer_11_ep0_expert_0 [label="select tokens" style=dashed]
	layer_11_ep0_expert_1 [label="Expert-1\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep0_gate -> layer_11_ep0_expert_1 [label="select tokens" style=dashed]
	layer_11_ep0_expert_2 [label="Expert-2\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep0_gate -> layer_11_ep0_expert_2 [label="select tokens" style=dashed]
	layer_11_ep0_expert_3 [label="Expert-3\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep0_gate -> layer_11_ep0_expert_3 [label="select tokens" style=dashed]
	layer_11_ep0_expert_aggr [label="Expert Aggregation\nEP-Group-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_11_ep0_expert_0 -> layer_11_ep0_expert_aggr
	layer_11_ep0_expert_1 -> layer_11_ep0_expert_aggr
	layer_11_ep0_expert_2 -> layer_11_ep0_expert_aggr
	layer_11_ep0_expert_3 -> layer_11_ep0_expert_aggr
	layer_11_ep1_gate [label="MoE Gate\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_11_ep1_expert_0 [label="Expert-0\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep1_gate -> layer_11_ep1_expert_0 [label="select tokens" style=dashed]
	layer_11_ep1_expert_1 [label="Expert-1\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep1_gate -> layer_11_ep1_expert_1 [label="select tokens" style=dashed]
	layer_11_ep1_expert_2 [label="Expert-2\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep1_gate -> layer_11_ep1_expert_2 [label="select tokens" style=dashed]
	layer_11_ep1_expert_3 [label="Expert-3\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep1_gate -> layer_11_ep1_expert_3 [label="select tokens" style=dashed]
	layer_11_ep1_expert_aggr [label="Expert Aggregation\nEP-Group-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_11_ep1_expert_0 -> layer_11_ep1_expert_aggr
	layer_11_ep1_expert_1 -> layer_11_ep1_expert_aggr
	layer_11_ep1_expert_2 -> layer_11_ep1_expert_aggr
	layer_11_ep1_expert_3 -> layer_11_ep1_expert_aggr
	layer_11_ep2_gate [label="MoE Gate\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_11_ep2_expert_0 [label="Expert-0\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep2_gate -> layer_11_ep2_expert_0 [label="select tokens" style=dashed]
	layer_11_ep2_expert_1 [label="Expert-1\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep2_gate -> layer_11_ep2_expert_1 [label="select tokens" style=dashed]
	layer_11_ep2_expert_2 [label="Expert-2\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep2_gate -> layer_11_ep2_expert_2 [label="select tokens" style=dashed]
	layer_11_ep2_expert_3 [label="Expert-3\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep2_gate -> layer_11_ep2_expert_3 [label="select tokens" style=dashed]
	layer_11_ep2_expert_aggr [label="Expert Aggregation\nEP-Group-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_11_ep2_expert_0 -> layer_11_ep2_expert_aggr
	layer_11_ep2_expert_1 -> layer_11_ep2_expert_aggr
	layer_11_ep2_expert_2 -> layer_11_ep2_expert_aggr
	layer_11_ep2_expert_3 -> layer_11_ep2_expert_aggr
	layer_11_ep3_gate [label="MoE Gate\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_11_ep3_expert_0 [label="Expert-0\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep3_gate -> layer_11_ep3_expert_0 [label="select tokens" style=dashed]
	layer_11_ep3_expert_1 [label="Expert-1\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep3_gate -> layer_11_ep3_expert_1 [label="select tokens" style=dashed]
	layer_11_ep3_expert_2 [label="Expert-2\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep3_gate -> layer_11_ep3_expert_2 [label="select tokens" style=dashed]
	layer_11_ep3_expert_3 [label="Expert-3\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep3_gate -> layer_11_ep3_expert_3 [label="select tokens" style=dashed]
	layer_11_ep3_expert_aggr [label="Expert Aggregation\nEP-Group-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_11_ep3_expert_0 -> layer_11_ep3_expert_aggr
	layer_11_ep3_expert_1 -> layer_11_ep3_expert_aggr
	layer_11_ep3_expert_2 -> layer_11_ep3_expert_aggr
	layer_11_ep3_expert_3 -> layer_11_ep3_expert_aggr
	layer_11_ep4_gate [label="MoE Gate\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_11_ep4_expert_0 [label="Expert-0\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep4_gate -> layer_11_ep4_expert_0 [label="select tokens" style=dashed]
	layer_11_ep4_expert_1 [label="Expert-1\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep4_gate -> layer_11_ep4_expert_1 [label="select tokens" style=dashed]
	layer_11_ep4_expert_2 [label="Expert-2\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep4_gate -> layer_11_ep4_expert_2 [label="select tokens" style=dashed]
	layer_11_ep4_expert_3 [label="Expert-3\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep4_gate -> layer_11_ep4_expert_3 [label="select tokens" style=dashed]
	layer_11_ep4_expert_aggr [label="Expert Aggregation\nEP-Group-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_11_ep4_expert_0 -> layer_11_ep4_expert_aggr
	layer_11_ep4_expert_1 -> layer_11_ep4_expert_aggr
	layer_11_ep4_expert_2 -> layer_11_ep4_expert_aggr
	layer_11_ep4_expert_3 -> layer_11_ep4_expert_aggr
	layer_11_ep5_gate [label="MoE Gate\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_11_ep5_expert_0 [label="Expert-0\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep5_gate -> layer_11_ep5_expert_0 [label="select tokens" style=dashed]
	layer_11_ep5_expert_1 [label="Expert-1\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep5_gate -> layer_11_ep5_expert_1 [label="select tokens" style=dashed]
	layer_11_ep5_expert_2 [label="Expert-2\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep5_gate -> layer_11_ep5_expert_2 [label="select tokens" style=dashed]
	layer_11_ep5_expert_3 [label="Expert-3\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep5_gate -> layer_11_ep5_expert_3 [label="select tokens" style=dashed]
	layer_11_ep5_expert_aggr [label="Expert Aggregation\nEP-Group-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_11_ep5_expert_0 -> layer_11_ep5_expert_aggr
	layer_11_ep5_expert_1 -> layer_11_ep5_expert_aggr
	layer_11_ep5_expert_2 -> layer_11_ep5_expert_aggr
	layer_11_ep5_expert_3 -> layer_11_ep5_expert_aggr
	layer_11_ep6_gate [label="MoE Gate\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_11_ep6_expert_0 [label="Expert-0\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep6_gate -> layer_11_ep6_expert_0 [label="select tokens" style=dashed]
	layer_11_ep6_expert_1 [label="Expert-1\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep6_gate -> layer_11_ep6_expert_1 [label="select tokens" style=dashed]
	layer_11_ep6_expert_2 [label="Expert-2\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep6_gate -> layer_11_ep6_expert_2 [label="select tokens" style=dashed]
	layer_11_ep6_expert_3 [label="Expert-3\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep6_gate -> layer_11_ep6_expert_3 [label="select tokens" style=dashed]
	layer_11_ep6_expert_aggr [label="Expert Aggregation\nEP-Group-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_11_ep6_expert_0 -> layer_11_ep6_expert_aggr
	layer_11_ep6_expert_1 -> layer_11_ep6_expert_aggr
	layer_11_ep6_expert_2 -> layer_11_ep6_expert_aggr
	layer_11_ep6_expert_3 -> layer_11_ep6_expert_aggr
	layer_11_ep7_gate [label="MoE Gate\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_11_ep7_expert_0 [label="Expert-0\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep7_gate -> layer_11_ep7_expert_0 [label="select tokens" style=dashed]
	layer_11_ep7_expert_1 [label="Expert-1\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep7_gate -> layer_11_ep7_expert_1 [label="select tokens" style=dashed]
	layer_11_ep7_expert_2 [label="Expert-2\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep7_gate -> layer_11_ep7_expert_2 [label="select tokens" style=dashed]
	layer_11_ep7_expert_3 [label="Expert-3\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep7_gate -> layer_11_ep7_expert_3 [label="select tokens" style=dashed]
	layer_11_ep7_expert_aggr [label="Expert Aggregation\nEP-Group-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_11_ep7_expert_0 -> layer_11_ep7_expert_aggr
	layer_11_ep7_expert_1 -> layer_11_ep7_expert_aggr
	layer_11_ep7_expert_2 -> layer_11_ep7_expert_aggr
	layer_11_ep7_expert_3 -> layer_11_ep7_expert_aggr
	layer_11_ep8_gate [label="MoE Gate\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_11_ep8_expert_0 [label="Expert-0\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep8_gate -> layer_11_ep8_expert_0 [label="select tokens" style=dashed]
	layer_11_ep8_expert_1 [label="Expert-1\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep8_gate -> layer_11_ep8_expert_1 [label="select tokens" style=dashed]
	layer_11_ep8_expert_2 [label="Expert-2\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep8_gate -> layer_11_ep8_expert_2 [label="select tokens" style=dashed]
	layer_11_ep8_expert_3 [label="Expert-3\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep8_gate -> layer_11_ep8_expert_3 [label="select tokens" style=dashed]
	layer_11_ep8_expert_aggr [label="Expert Aggregation\nEP-Group-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_11_ep8_expert_0 -> layer_11_ep8_expert_aggr
	layer_11_ep8_expert_1 -> layer_11_ep8_expert_aggr
	layer_11_ep8_expert_2 -> layer_11_ep8_expert_aggr
	layer_11_ep8_expert_3 -> layer_11_ep8_expert_aggr
	layer_11_ep9_gate [label="MoE Gate\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_11_ep9_expert_0 [label="Expert-0\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep9_gate -> layer_11_ep9_expert_0 [label="select tokens" style=dashed]
	layer_11_ep9_expert_1 [label="Expert-1\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep9_gate -> layer_11_ep9_expert_1 [label="select tokens" style=dashed]
	layer_11_ep9_expert_2 [label="Expert-2\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep9_gate -> layer_11_ep9_expert_2 [label="select tokens" style=dashed]
	layer_11_ep9_expert_3 [label="Expert-3\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep9_gate -> layer_11_ep9_expert_3 [label="select tokens" style=dashed]
	layer_11_ep9_expert_aggr [label="Expert Aggregation\nEP-Group-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_11_ep9_expert_0 -> layer_11_ep9_expert_aggr
	layer_11_ep9_expert_1 -> layer_11_ep9_expert_aggr
	layer_11_ep9_expert_2 -> layer_11_ep9_expert_aggr
	layer_11_ep9_expert_3 -> layer_11_ep9_expert_aggr
	layer_11_ep10_gate [label="MoE Gate\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_11_ep10_expert_0 [label="Expert-0\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep10_gate -> layer_11_ep10_expert_0 [label="select tokens" style=dashed]
	layer_11_ep10_expert_1 [label="Expert-1\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep10_gate -> layer_11_ep10_expert_1 [label="select tokens" style=dashed]
	layer_11_ep10_expert_2 [label="Expert-2\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep10_gate -> layer_11_ep10_expert_2 [label="select tokens" style=dashed]
	layer_11_ep10_expert_3 [label="Expert-3\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep10_gate -> layer_11_ep10_expert_3 [label="select tokens" style=dashed]
	layer_11_ep10_expert_aggr [label="Expert Aggregation\nEP-Group-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_11_ep10_expert_0 -> layer_11_ep10_expert_aggr
	layer_11_ep10_expert_1 -> layer_11_ep10_expert_aggr
	layer_11_ep10_expert_2 -> layer_11_ep10_expert_aggr
	layer_11_ep10_expert_3 -> layer_11_ep10_expert_aggr
	layer_11_ep11_gate [label="MoE Gate\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_11_ep11_expert_0 [label="Expert-0\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep11_gate -> layer_11_ep11_expert_0 [label="select tokens" style=dashed]
	layer_11_ep11_expert_1 [label="Expert-1\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep11_gate -> layer_11_ep11_expert_1 [label="select tokens" style=dashed]
	layer_11_ep11_expert_2 [label="Expert-2\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep11_gate -> layer_11_ep11_expert_2 [label="select tokens" style=dashed]
	layer_11_ep11_expert_3 [label="Expert-3\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep11_gate -> layer_11_ep11_expert_3 [label="select tokens" style=dashed]
	layer_11_ep11_expert_aggr [label="Expert Aggregation\nEP-Group-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_11_ep11_expert_0 -> layer_11_ep11_expert_aggr
	layer_11_ep11_expert_1 -> layer_11_ep11_expert_aggr
	layer_11_ep11_expert_2 -> layer_11_ep11_expert_aggr
	layer_11_ep11_expert_3 -> layer_11_ep11_expert_aggr
	layer_11_ep12_gate [label="MoE Gate\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_11_ep12_expert_0 [label="Expert-0\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep12_gate -> layer_11_ep12_expert_0 [label="select tokens" style=dashed]
	layer_11_ep12_expert_1 [label="Expert-1\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep12_gate -> layer_11_ep12_expert_1 [label="select tokens" style=dashed]
	layer_11_ep12_expert_2 [label="Expert-2\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep12_gate -> layer_11_ep12_expert_2 [label="select tokens" style=dashed]
	layer_11_ep12_expert_3 [label="Expert-3\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep12_gate -> layer_11_ep12_expert_3 [label="select tokens" style=dashed]
	layer_11_ep12_expert_aggr [label="Expert Aggregation\nEP-Group-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_11_ep12_expert_0 -> layer_11_ep12_expert_aggr
	layer_11_ep12_expert_1 -> layer_11_ep12_expert_aggr
	layer_11_ep12_expert_2 -> layer_11_ep12_expert_aggr
	layer_11_ep12_expert_3 -> layer_11_ep12_expert_aggr
	layer_11_ep13_gate [label="MoE Gate\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_11_ep13_expert_0 [label="Expert-0\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep13_gate -> layer_11_ep13_expert_0 [label="select tokens" style=dashed]
	layer_11_ep13_expert_1 [label="Expert-1\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep13_gate -> layer_11_ep13_expert_1 [label="select tokens" style=dashed]
	layer_11_ep13_expert_2 [label="Expert-2\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep13_gate -> layer_11_ep13_expert_2 [label="select tokens" style=dashed]
	layer_11_ep13_expert_3 [label="Expert-3\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep13_gate -> layer_11_ep13_expert_3 [label="select tokens" style=dashed]
	layer_11_ep13_expert_aggr [label="Expert Aggregation\nEP-Group-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_11_ep13_expert_0 -> layer_11_ep13_expert_aggr
	layer_11_ep13_expert_1 -> layer_11_ep13_expert_aggr
	layer_11_ep13_expert_2 -> layer_11_ep13_expert_aggr
	layer_11_ep13_expert_3 -> layer_11_ep13_expert_aggr
	layer_11_ep14_gate [label="MoE Gate\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_11_ep14_expert_0 [label="Expert-0\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep14_gate -> layer_11_ep14_expert_0 [label="select tokens" style=dashed]
	layer_11_ep14_expert_1 [label="Expert-1\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep14_gate -> layer_11_ep14_expert_1 [label="select tokens" style=dashed]
	layer_11_ep14_expert_2 [label="Expert-2\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep14_gate -> layer_11_ep14_expert_2 [label="select tokens" style=dashed]
	layer_11_ep14_expert_3 [label="Expert-3\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep14_gate -> layer_11_ep14_expert_3 [label="select tokens" style=dashed]
	layer_11_ep14_expert_aggr [label="Expert Aggregation\nEP-Group-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_11_ep14_expert_0 -> layer_11_ep14_expert_aggr
	layer_11_ep14_expert_1 -> layer_11_ep14_expert_aggr
	layer_11_ep14_expert_2 -> layer_11_ep14_expert_aggr
	layer_11_ep14_expert_3 -> layer_11_ep14_expert_aggr
	layer_11_ep15_gate [label="MoE Gate\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_11_ep15_expert_0 [label="Expert-0\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep15_gate -> layer_11_ep15_expert_0 [label="select tokens" style=dashed]
	layer_11_ep15_expert_1 [label="Expert-1\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep15_gate -> layer_11_ep15_expert_1 [label="select tokens" style=dashed]
	layer_11_ep15_expert_2 [label="Expert-2\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep15_gate -> layer_11_ep15_expert_2 [label="select tokens" style=dashed]
	layer_11_ep15_expert_3 [label="Expert-3\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_11_ep15_gate -> layer_11_ep15_expert_3 [label="select tokens" style=dashed]
	layer_11_ep15_expert_aggr [label="Expert Aggregation\nEP-Group-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_11_ep15_expert_0 -> layer_11_ep15_expert_aggr
	layer_11_ep15_expert_1 -> layer_11_ep15_expert_aggr
	layer_11_ep15_expert_2 -> layer_11_ep15_expert_aggr
	layer_11_ep15_expert_3 -> layer_11_ep15_expert_aggr
	layer_11_to_12_ep0_pp [label="Pipeline Stage Transfer\nEP-Group-0\nLayer-11 to Layer-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_11_ep0_expert_aggr -> layer_11_to_12_ep0_pp
	layer_11_to_12_ep1_pp [label="Pipeline Stage Transfer\nEP-Group-1\nLayer-11 to Layer-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_11_ep1_expert_aggr -> layer_11_to_12_ep1_pp
	layer_11_to_12_ep2_pp [label="Pipeline Stage Transfer\nEP-Group-2\nLayer-11 to Layer-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_11_ep2_expert_aggr -> layer_11_to_12_ep2_pp
	layer_11_to_12_ep3_pp [label="Pipeline Stage Transfer\nEP-Group-3\nLayer-11 to Layer-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_11_ep3_expert_aggr -> layer_11_to_12_ep3_pp
	layer_11_to_12_ep4_pp [label="Pipeline Stage Transfer\nEP-Group-4\nLayer-11 to Layer-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_11_ep4_expert_aggr -> layer_11_to_12_ep4_pp
	layer_11_to_12_ep5_pp [label="Pipeline Stage Transfer\nEP-Group-5\nLayer-11 to Layer-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_11_ep5_expert_aggr -> layer_11_to_12_ep5_pp
	layer_11_to_12_ep6_pp [label="Pipeline Stage Transfer\nEP-Group-6\nLayer-11 to Layer-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_11_ep6_expert_aggr -> layer_11_to_12_ep6_pp
	layer_11_to_12_ep7_pp [label="Pipeline Stage Transfer\nEP-Group-7\nLayer-11 to Layer-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_11_ep7_expert_aggr -> layer_11_to_12_ep7_pp
	layer_11_to_12_ep8_pp [label="Pipeline Stage Transfer\nEP-Group-8\nLayer-11 to Layer-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_11_ep8_expert_aggr -> layer_11_to_12_ep8_pp
	layer_11_to_12_ep9_pp [label="Pipeline Stage Transfer\nEP-Group-9\nLayer-11 to Layer-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_11_ep9_expert_aggr -> layer_11_to_12_ep9_pp
	layer_11_to_12_ep10_pp [label="Pipeline Stage Transfer\nEP-Group-10\nLayer-11 to Layer-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_11_ep10_expert_aggr -> layer_11_to_12_ep10_pp
	layer_11_to_12_ep11_pp [label="Pipeline Stage Transfer\nEP-Group-11\nLayer-11 to Layer-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_11_ep11_expert_aggr -> layer_11_to_12_ep11_pp
	layer_11_to_12_ep12_pp [label="Pipeline Stage Transfer\nEP-Group-12\nLayer-11 to Layer-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_11_ep12_expert_aggr -> layer_11_to_12_ep12_pp
	layer_11_to_12_ep13_pp [label="Pipeline Stage Transfer\nEP-Group-13\nLayer-11 to Layer-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_11_ep13_expert_aggr -> layer_11_to_12_ep13_pp
	layer_11_to_12_ep14_pp [label="Pipeline Stage Transfer\nEP-Group-14\nLayer-11 to Layer-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_11_ep14_expert_aggr -> layer_11_to_12_ep14_pp
	layer_11_to_12_ep15_pp [label="Pipeline Stage Transfer\nEP-Group-15\nLayer-11 to Layer-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_11_ep15_expert_aggr -> layer_11_to_12_ep15_pp
	layer_12_ep0_tp0_sa_qkv [label="Self-Attn QKV\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep0_tp0_sa_attn [label="Self-Attn Compute\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep0_tp0_sa_out [label="Self-Attn Output\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep0_tp0_sa_qkv -> layer_12_ep0_tp0_sa_attn
	layer_12_ep0_tp0_sa_attn -> layer_12_ep0_tp0_sa_out
	layer_12_ep0_tp1_sa_qkv [label="Self-Attn QKV\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep0_tp1_sa_attn [label="Self-Attn Compute\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep0_tp1_sa_out [label="Self-Attn Output\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep0_tp1_sa_qkv -> layer_12_ep0_tp1_sa_attn
	layer_12_ep0_tp1_sa_attn -> layer_12_ep0_tp1_sa_out
	layer_12_ep0_tp2_sa_qkv [label="Self-Attn QKV\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep0_tp2_sa_attn [label="Self-Attn Compute\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep0_tp2_sa_out [label="Self-Attn Output\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep0_tp2_sa_qkv -> layer_12_ep0_tp2_sa_attn
	layer_12_ep0_tp2_sa_attn -> layer_12_ep0_tp2_sa_out
	layer_12_ep0_tp3_sa_qkv [label="Self-Attn QKV\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep0_tp3_sa_attn [label="Self-Attn Compute\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep0_tp3_sa_out [label="Self-Attn Output\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep0_tp3_sa_qkv -> layer_12_ep0_tp3_sa_attn
	layer_12_ep0_tp3_sa_attn -> layer_12_ep0_tp3_sa_out
	layer_12_ep1_tp0_sa_qkv [label="Self-Attn QKV\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep1_tp0_sa_attn [label="Self-Attn Compute\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep1_tp0_sa_out [label="Self-Attn Output\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep1_tp0_sa_qkv -> layer_12_ep1_tp0_sa_attn
	layer_12_ep1_tp0_sa_attn -> layer_12_ep1_tp0_sa_out
	layer_12_ep1_tp1_sa_qkv [label="Self-Attn QKV\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep1_tp1_sa_attn [label="Self-Attn Compute\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep1_tp1_sa_out [label="Self-Attn Output\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep1_tp1_sa_qkv -> layer_12_ep1_tp1_sa_attn
	layer_12_ep1_tp1_sa_attn -> layer_12_ep1_tp1_sa_out
	layer_12_ep1_tp2_sa_qkv [label="Self-Attn QKV\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep1_tp2_sa_attn [label="Self-Attn Compute\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep1_tp2_sa_out [label="Self-Attn Output\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep1_tp2_sa_qkv -> layer_12_ep1_tp2_sa_attn
	layer_12_ep1_tp2_sa_attn -> layer_12_ep1_tp2_sa_out
	layer_12_ep1_tp3_sa_qkv [label="Self-Attn QKV\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep1_tp3_sa_attn [label="Self-Attn Compute\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep1_tp3_sa_out [label="Self-Attn Output\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep1_tp3_sa_qkv -> layer_12_ep1_tp3_sa_attn
	layer_12_ep1_tp3_sa_attn -> layer_12_ep1_tp3_sa_out
	layer_12_ep2_tp0_sa_qkv [label="Self-Attn QKV\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep2_tp0_sa_attn [label="Self-Attn Compute\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep2_tp0_sa_out [label="Self-Attn Output\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep2_tp0_sa_qkv -> layer_12_ep2_tp0_sa_attn
	layer_12_ep2_tp0_sa_attn -> layer_12_ep2_tp0_sa_out
	layer_12_ep2_tp1_sa_qkv [label="Self-Attn QKV\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep2_tp1_sa_attn [label="Self-Attn Compute\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep2_tp1_sa_out [label="Self-Attn Output\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep2_tp1_sa_qkv -> layer_12_ep2_tp1_sa_attn
	layer_12_ep2_tp1_sa_attn -> layer_12_ep2_tp1_sa_out
	layer_12_ep2_tp2_sa_qkv [label="Self-Attn QKV\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep2_tp2_sa_attn [label="Self-Attn Compute\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep2_tp2_sa_out [label="Self-Attn Output\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep2_tp2_sa_qkv -> layer_12_ep2_tp2_sa_attn
	layer_12_ep2_tp2_sa_attn -> layer_12_ep2_tp2_sa_out
	layer_12_ep2_tp3_sa_qkv [label="Self-Attn QKV\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep2_tp3_sa_attn [label="Self-Attn Compute\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep2_tp3_sa_out [label="Self-Attn Output\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep2_tp3_sa_qkv -> layer_12_ep2_tp3_sa_attn
	layer_12_ep2_tp3_sa_attn -> layer_12_ep2_tp3_sa_out
	layer_12_ep3_tp0_sa_qkv [label="Self-Attn QKV\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep3_tp0_sa_attn [label="Self-Attn Compute\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep3_tp0_sa_out [label="Self-Attn Output\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep3_tp0_sa_qkv -> layer_12_ep3_tp0_sa_attn
	layer_12_ep3_tp0_sa_attn -> layer_12_ep3_tp0_sa_out
	layer_12_ep3_tp1_sa_qkv [label="Self-Attn QKV\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep3_tp1_sa_attn [label="Self-Attn Compute\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep3_tp1_sa_out [label="Self-Attn Output\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep3_tp1_sa_qkv -> layer_12_ep3_tp1_sa_attn
	layer_12_ep3_tp1_sa_attn -> layer_12_ep3_tp1_sa_out
	layer_12_ep3_tp2_sa_qkv [label="Self-Attn QKV\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep3_tp2_sa_attn [label="Self-Attn Compute\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep3_tp2_sa_out [label="Self-Attn Output\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep3_tp2_sa_qkv -> layer_12_ep3_tp2_sa_attn
	layer_12_ep3_tp2_sa_attn -> layer_12_ep3_tp2_sa_out
	layer_12_ep3_tp3_sa_qkv [label="Self-Attn QKV\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep3_tp3_sa_attn [label="Self-Attn Compute\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep3_tp3_sa_out [label="Self-Attn Output\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep3_tp3_sa_qkv -> layer_12_ep3_tp3_sa_attn
	layer_12_ep3_tp3_sa_attn -> layer_12_ep3_tp3_sa_out
	layer_12_ep4_tp0_sa_qkv [label="Self-Attn QKV\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep4_tp0_sa_attn [label="Self-Attn Compute\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep4_tp0_sa_out [label="Self-Attn Output\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep4_tp0_sa_qkv -> layer_12_ep4_tp0_sa_attn
	layer_12_ep4_tp0_sa_attn -> layer_12_ep4_tp0_sa_out
	layer_12_ep4_tp1_sa_qkv [label="Self-Attn QKV\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep4_tp1_sa_attn [label="Self-Attn Compute\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep4_tp1_sa_out [label="Self-Attn Output\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep4_tp1_sa_qkv -> layer_12_ep4_tp1_sa_attn
	layer_12_ep4_tp1_sa_attn -> layer_12_ep4_tp1_sa_out
	layer_12_ep4_tp2_sa_qkv [label="Self-Attn QKV\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep4_tp2_sa_attn [label="Self-Attn Compute\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep4_tp2_sa_out [label="Self-Attn Output\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep4_tp2_sa_qkv -> layer_12_ep4_tp2_sa_attn
	layer_12_ep4_tp2_sa_attn -> layer_12_ep4_tp2_sa_out
	layer_12_ep4_tp3_sa_qkv [label="Self-Attn QKV\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep4_tp3_sa_attn [label="Self-Attn Compute\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep4_tp3_sa_out [label="Self-Attn Output\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep4_tp3_sa_qkv -> layer_12_ep4_tp3_sa_attn
	layer_12_ep4_tp3_sa_attn -> layer_12_ep4_tp3_sa_out
	layer_12_ep5_tp0_sa_qkv [label="Self-Attn QKV\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep5_tp0_sa_attn [label="Self-Attn Compute\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep5_tp0_sa_out [label="Self-Attn Output\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep5_tp0_sa_qkv -> layer_12_ep5_tp0_sa_attn
	layer_12_ep5_tp0_sa_attn -> layer_12_ep5_tp0_sa_out
	layer_12_ep5_tp1_sa_qkv [label="Self-Attn QKV\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep5_tp1_sa_attn [label="Self-Attn Compute\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep5_tp1_sa_out [label="Self-Attn Output\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep5_tp1_sa_qkv -> layer_12_ep5_tp1_sa_attn
	layer_12_ep5_tp1_sa_attn -> layer_12_ep5_tp1_sa_out
	layer_12_ep5_tp2_sa_qkv [label="Self-Attn QKV\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep5_tp2_sa_attn [label="Self-Attn Compute\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep5_tp2_sa_out [label="Self-Attn Output\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep5_tp2_sa_qkv -> layer_12_ep5_tp2_sa_attn
	layer_12_ep5_tp2_sa_attn -> layer_12_ep5_tp2_sa_out
	layer_12_ep5_tp3_sa_qkv [label="Self-Attn QKV\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep5_tp3_sa_attn [label="Self-Attn Compute\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep5_tp3_sa_out [label="Self-Attn Output\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep5_tp3_sa_qkv -> layer_12_ep5_tp3_sa_attn
	layer_12_ep5_tp3_sa_attn -> layer_12_ep5_tp3_sa_out
	layer_12_ep6_tp0_sa_qkv [label="Self-Attn QKV\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep6_tp0_sa_attn [label="Self-Attn Compute\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep6_tp0_sa_out [label="Self-Attn Output\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep6_tp0_sa_qkv -> layer_12_ep6_tp0_sa_attn
	layer_12_ep6_tp0_sa_attn -> layer_12_ep6_tp0_sa_out
	layer_12_ep6_tp1_sa_qkv [label="Self-Attn QKV\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep6_tp1_sa_attn [label="Self-Attn Compute\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep6_tp1_sa_out [label="Self-Attn Output\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep6_tp1_sa_qkv -> layer_12_ep6_tp1_sa_attn
	layer_12_ep6_tp1_sa_attn -> layer_12_ep6_tp1_sa_out
	layer_12_ep6_tp2_sa_qkv [label="Self-Attn QKV\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep6_tp2_sa_attn [label="Self-Attn Compute\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep6_tp2_sa_out [label="Self-Attn Output\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep6_tp2_sa_qkv -> layer_12_ep6_tp2_sa_attn
	layer_12_ep6_tp2_sa_attn -> layer_12_ep6_tp2_sa_out
	layer_12_ep6_tp3_sa_qkv [label="Self-Attn QKV\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep6_tp3_sa_attn [label="Self-Attn Compute\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep6_tp3_sa_out [label="Self-Attn Output\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep6_tp3_sa_qkv -> layer_12_ep6_tp3_sa_attn
	layer_12_ep6_tp3_sa_attn -> layer_12_ep6_tp3_sa_out
	layer_12_ep7_tp0_sa_qkv [label="Self-Attn QKV\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep7_tp0_sa_attn [label="Self-Attn Compute\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep7_tp0_sa_out [label="Self-Attn Output\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep7_tp0_sa_qkv -> layer_12_ep7_tp0_sa_attn
	layer_12_ep7_tp0_sa_attn -> layer_12_ep7_tp0_sa_out
	layer_12_ep7_tp1_sa_qkv [label="Self-Attn QKV\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep7_tp1_sa_attn [label="Self-Attn Compute\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep7_tp1_sa_out [label="Self-Attn Output\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep7_tp1_sa_qkv -> layer_12_ep7_tp1_sa_attn
	layer_12_ep7_tp1_sa_attn -> layer_12_ep7_tp1_sa_out
	layer_12_ep7_tp2_sa_qkv [label="Self-Attn QKV\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep7_tp2_sa_attn [label="Self-Attn Compute\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep7_tp2_sa_out [label="Self-Attn Output\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep7_tp2_sa_qkv -> layer_12_ep7_tp2_sa_attn
	layer_12_ep7_tp2_sa_attn -> layer_12_ep7_tp2_sa_out
	layer_12_ep7_tp3_sa_qkv [label="Self-Attn QKV\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep7_tp3_sa_attn [label="Self-Attn Compute\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep7_tp3_sa_out [label="Self-Attn Output\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep7_tp3_sa_qkv -> layer_12_ep7_tp3_sa_attn
	layer_12_ep7_tp3_sa_attn -> layer_12_ep7_tp3_sa_out
	layer_12_ep8_tp0_sa_qkv [label="Self-Attn QKV\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep8_tp0_sa_attn [label="Self-Attn Compute\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep8_tp0_sa_out [label="Self-Attn Output\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep8_tp0_sa_qkv -> layer_12_ep8_tp0_sa_attn
	layer_12_ep8_tp0_sa_attn -> layer_12_ep8_tp0_sa_out
	layer_12_ep8_tp1_sa_qkv [label="Self-Attn QKV\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep8_tp1_sa_attn [label="Self-Attn Compute\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep8_tp1_sa_out [label="Self-Attn Output\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep8_tp1_sa_qkv -> layer_12_ep8_tp1_sa_attn
	layer_12_ep8_tp1_sa_attn -> layer_12_ep8_tp1_sa_out
	layer_12_ep8_tp2_sa_qkv [label="Self-Attn QKV\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep8_tp2_sa_attn [label="Self-Attn Compute\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep8_tp2_sa_out [label="Self-Attn Output\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep8_tp2_sa_qkv -> layer_12_ep8_tp2_sa_attn
	layer_12_ep8_tp2_sa_attn -> layer_12_ep8_tp2_sa_out
	layer_12_ep8_tp3_sa_qkv [label="Self-Attn QKV\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep8_tp3_sa_attn [label="Self-Attn Compute\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep8_tp3_sa_out [label="Self-Attn Output\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep8_tp3_sa_qkv -> layer_12_ep8_tp3_sa_attn
	layer_12_ep8_tp3_sa_attn -> layer_12_ep8_tp3_sa_out
	layer_12_ep9_tp0_sa_qkv [label="Self-Attn QKV\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep9_tp0_sa_attn [label="Self-Attn Compute\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep9_tp0_sa_out [label="Self-Attn Output\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep9_tp0_sa_qkv -> layer_12_ep9_tp0_sa_attn
	layer_12_ep9_tp0_sa_attn -> layer_12_ep9_tp0_sa_out
	layer_12_ep9_tp1_sa_qkv [label="Self-Attn QKV\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep9_tp1_sa_attn [label="Self-Attn Compute\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep9_tp1_sa_out [label="Self-Attn Output\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep9_tp1_sa_qkv -> layer_12_ep9_tp1_sa_attn
	layer_12_ep9_tp1_sa_attn -> layer_12_ep9_tp1_sa_out
	layer_12_ep9_tp2_sa_qkv [label="Self-Attn QKV\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep9_tp2_sa_attn [label="Self-Attn Compute\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep9_tp2_sa_out [label="Self-Attn Output\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep9_tp2_sa_qkv -> layer_12_ep9_tp2_sa_attn
	layer_12_ep9_tp2_sa_attn -> layer_12_ep9_tp2_sa_out
	layer_12_ep9_tp3_sa_qkv [label="Self-Attn QKV\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep9_tp3_sa_attn [label="Self-Attn Compute\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep9_tp3_sa_out [label="Self-Attn Output\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep9_tp3_sa_qkv -> layer_12_ep9_tp3_sa_attn
	layer_12_ep9_tp3_sa_attn -> layer_12_ep9_tp3_sa_out
	layer_12_ep10_tp0_sa_qkv [label="Self-Attn QKV\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep10_tp0_sa_attn [label="Self-Attn Compute\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep10_tp0_sa_out [label="Self-Attn Output\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep10_tp0_sa_qkv -> layer_12_ep10_tp0_sa_attn
	layer_12_ep10_tp0_sa_attn -> layer_12_ep10_tp0_sa_out
	layer_12_ep10_tp1_sa_qkv [label="Self-Attn QKV\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep10_tp1_sa_attn [label="Self-Attn Compute\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep10_tp1_sa_out [label="Self-Attn Output\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep10_tp1_sa_qkv -> layer_12_ep10_tp1_sa_attn
	layer_12_ep10_tp1_sa_attn -> layer_12_ep10_tp1_sa_out
	layer_12_ep10_tp2_sa_qkv [label="Self-Attn QKV\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep10_tp2_sa_attn [label="Self-Attn Compute\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep10_tp2_sa_out [label="Self-Attn Output\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep10_tp2_sa_qkv -> layer_12_ep10_tp2_sa_attn
	layer_12_ep10_tp2_sa_attn -> layer_12_ep10_tp2_sa_out
	layer_12_ep10_tp3_sa_qkv [label="Self-Attn QKV\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep10_tp3_sa_attn [label="Self-Attn Compute\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep10_tp3_sa_out [label="Self-Attn Output\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep10_tp3_sa_qkv -> layer_12_ep10_tp3_sa_attn
	layer_12_ep10_tp3_sa_attn -> layer_12_ep10_tp3_sa_out
	layer_12_ep11_tp0_sa_qkv [label="Self-Attn QKV\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep11_tp0_sa_attn [label="Self-Attn Compute\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep11_tp0_sa_out [label="Self-Attn Output\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep11_tp0_sa_qkv -> layer_12_ep11_tp0_sa_attn
	layer_12_ep11_tp0_sa_attn -> layer_12_ep11_tp0_sa_out
	layer_12_ep11_tp1_sa_qkv [label="Self-Attn QKV\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep11_tp1_sa_attn [label="Self-Attn Compute\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep11_tp1_sa_out [label="Self-Attn Output\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep11_tp1_sa_qkv -> layer_12_ep11_tp1_sa_attn
	layer_12_ep11_tp1_sa_attn -> layer_12_ep11_tp1_sa_out
	layer_12_ep11_tp2_sa_qkv [label="Self-Attn QKV\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep11_tp2_sa_attn [label="Self-Attn Compute\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep11_tp2_sa_out [label="Self-Attn Output\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep11_tp2_sa_qkv -> layer_12_ep11_tp2_sa_attn
	layer_12_ep11_tp2_sa_attn -> layer_12_ep11_tp2_sa_out
	layer_12_ep11_tp3_sa_qkv [label="Self-Attn QKV\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep11_tp3_sa_attn [label="Self-Attn Compute\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep11_tp3_sa_out [label="Self-Attn Output\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep11_tp3_sa_qkv -> layer_12_ep11_tp3_sa_attn
	layer_12_ep11_tp3_sa_attn -> layer_12_ep11_tp3_sa_out
	layer_12_ep12_tp0_sa_qkv [label="Self-Attn QKV\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep12_tp0_sa_attn [label="Self-Attn Compute\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep12_tp0_sa_out [label="Self-Attn Output\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep12_tp0_sa_qkv -> layer_12_ep12_tp0_sa_attn
	layer_12_ep12_tp0_sa_attn -> layer_12_ep12_tp0_sa_out
	layer_12_ep12_tp1_sa_qkv [label="Self-Attn QKV\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep12_tp1_sa_attn [label="Self-Attn Compute\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep12_tp1_sa_out [label="Self-Attn Output\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep12_tp1_sa_qkv -> layer_12_ep12_tp1_sa_attn
	layer_12_ep12_tp1_sa_attn -> layer_12_ep12_tp1_sa_out
	layer_12_ep12_tp2_sa_qkv [label="Self-Attn QKV\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep12_tp2_sa_attn [label="Self-Attn Compute\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep12_tp2_sa_out [label="Self-Attn Output\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep12_tp2_sa_qkv -> layer_12_ep12_tp2_sa_attn
	layer_12_ep12_tp2_sa_attn -> layer_12_ep12_tp2_sa_out
	layer_12_ep12_tp3_sa_qkv [label="Self-Attn QKV\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep12_tp3_sa_attn [label="Self-Attn Compute\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep12_tp3_sa_out [label="Self-Attn Output\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep12_tp3_sa_qkv -> layer_12_ep12_tp3_sa_attn
	layer_12_ep12_tp3_sa_attn -> layer_12_ep12_tp3_sa_out
	layer_12_ep13_tp0_sa_qkv [label="Self-Attn QKV\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep13_tp0_sa_attn [label="Self-Attn Compute\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep13_tp0_sa_out [label="Self-Attn Output\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep13_tp0_sa_qkv -> layer_12_ep13_tp0_sa_attn
	layer_12_ep13_tp0_sa_attn -> layer_12_ep13_tp0_sa_out
	layer_12_ep13_tp1_sa_qkv [label="Self-Attn QKV\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep13_tp1_sa_attn [label="Self-Attn Compute\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep13_tp1_sa_out [label="Self-Attn Output\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep13_tp1_sa_qkv -> layer_12_ep13_tp1_sa_attn
	layer_12_ep13_tp1_sa_attn -> layer_12_ep13_tp1_sa_out
	layer_12_ep13_tp2_sa_qkv [label="Self-Attn QKV\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep13_tp2_sa_attn [label="Self-Attn Compute\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep13_tp2_sa_out [label="Self-Attn Output\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep13_tp2_sa_qkv -> layer_12_ep13_tp2_sa_attn
	layer_12_ep13_tp2_sa_attn -> layer_12_ep13_tp2_sa_out
	layer_12_ep13_tp3_sa_qkv [label="Self-Attn QKV\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep13_tp3_sa_attn [label="Self-Attn Compute\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep13_tp3_sa_out [label="Self-Attn Output\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep13_tp3_sa_qkv -> layer_12_ep13_tp3_sa_attn
	layer_12_ep13_tp3_sa_attn -> layer_12_ep13_tp3_sa_out
	layer_12_ep14_tp0_sa_qkv [label="Self-Attn QKV\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep14_tp0_sa_attn [label="Self-Attn Compute\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep14_tp0_sa_out [label="Self-Attn Output\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep14_tp0_sa_qkv -> layer_12_ep14_tp0_sa_attn
	layer_12_ep14_tp0_sa_attn -> layer_12_ep14_tp0_sa_out
	layer_12_ep14_tp1_sa_qkv [label="Self-Attn QKV\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep14_tp1_sa_attn [label="Self-Attn Compute\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep14_tp1_sa_out [label="Self-Attn Output\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep14_tp1_sa_qkv -> layer_12_ep14_tp1_sa_attn
	layer_12_ep14_tp1_sa_attn -> layer_12_ep14_tp1_sa_out
	layer_12_ep14_tp2_sa_qkv [label="Self-Attn QKV\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep14_tp2_sa_attn [label="Self-Attn Compute\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep14_tp2_sa_out [label="Self-Attn Output\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep14_tp2_sa_qkv -> layer_12_ep14_tp2_sa_attn
	layer_12_ep14_tp2_sa_attn -> layer_12_ep14_tp2_sa_out
	layer_12_ep14_tp3_sa_qkv [label="Self-Attn QKV\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep14_tp3_sa_attn [label="Self-Attn Compute\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep14_tp3_sa_out [label="Self-Attn Output\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep14_tp3_sa_qkv -> layer_12_ep14_tp3_sa_attn
	layer_12_ep14_tp3_sa_attn -> layer_12_ep14_tp3_sa_out
	layer_12_ep15_tp0_sa_qkv [label="Self-Attn QKV\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep15_tp0_sa_attn [label="Self-Attn Compute\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep15_tp0_sa_out [label="Self-Attn Output\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep15_tp0_sa_qkv -> layer_12_ep15_tp0_sa_attn
	layer_12_ep15_tp0_sa_attn -> layer_12_ep15_tp0_sa_out
	layer_12_ep15_tp1_sa_qkv [label="Self-Attn QKV\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep15_tp1_sa_attn [label="Self-Attn Compute\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep15_tp1_sa_out [label="Self-Attn Output\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep15_tp1_sa_qkv -> layer_12_ep15_tp1_sa_attn
	layer_12_ep15_tp1_sa_attn -> layer_12_ep15_tp1_sa_out
	layer_12_ep15_tp2_sa_qkv [label="Self-Attn QKV\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep15_tp2_sa_attn [label="Self-Attn Compute\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep15_tp2_sa_out [label="Self-Attn Output\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep15_tp2_sa_qkv -> layer_12_ep15_tp2_sa_attn
	layer_12_ep15_tp2_sa_attn -> layer_12_ep15_tp2_sa_out
	layer_12_ep15_tp3_sa_qkv [label="Self-Attn QKV\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep15_tp3_sa_attn [label="Self-Attn Compute\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep15_tp3_sa_out [label="Self-Attn Output\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep15_tp3_sa_qkv -> layer_12_ep15_tp3_sa_attn
	layer_12_ep15_tp3_sa_attn -> layer_12_ep15_tp3_sa_out
	layer_12_ep0_tp_allreduce [label="TP All-Reduce\nEP-Group-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_12_ep0_tp0_sa_out -> layer_12_ep0_tp_allreduce
	layer_12_ep0_tp1_sa_out -> layer_12_ep0_tp_allreduce
	layer_12_ep0_tp2_sa_out -> layer_12_ep0_tp_allreduce
	layer_12_ep0_tp3_sa_out -> layer_12_ep0_tp_allreduce
	layer_12_ep1_tp_allreduce [label="TP All-Reduce\nEP-Group-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_12_ep1_tp0_sa_out -> layer_12_ep1_tp_allreduce
	layer_12_ep1_tp1_sa_out -> layer_12_ep1_tp_allreduce
	layer_12_ep1_tp2_sa_out -> layer_12_ep1_tp_allreduce
	layer_12_ep1_tp3_sa_out -> layer_12_ep1_tp_allreduce
	layer_12_ep2_tp_allreduce [label="TP All-Reduce\nEP-Group-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_12_ep2_tp0_sa_out -> layer_12_ep2_tp_allreduce
	layer_12_ep2_tp1_sa_out -> layer_12_ep2_tp_allreduce
	layer_12_ep2_tp2_sa_out -> layer_12_ep2_tp_allreduce
	layer_12_ep2_tp3_sa_out -> layer_12_ep2_tp_allreduce
	layer_12_ep3_tp_allreduce [label="TP All-Reduce\nEP-Group-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_12_ep3_tp0_sa_out -> layer_12_ep3_tp_allreduce
	layer_12_ep3_tp1_sa_out -> layer_12_ep3_tp_allreduce
	layer_12_ep3_tp2_sa_out -> layer_12_ep3_tp_allreduce
	layer_12_ep3_tp3_sa_out -> layer_12_ep3_tp_allreduce
	layer_12_ep4_tp_allreduce [label="TP All-Reduce\nEP-Group-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_12_ep4_tp0_sa_out -> layer_12_ep4_tp_allreduce
	layer_12_ep4_tp1_sa_out -> layer_12_ep4_tp_allreduce
	layer_12_ep4_tp2_sa_out -> layer_12_ep4_tp_allreduce
	layer_12_ep4_tp3_sa_out -> layer_12_ep4_tp_allreduce
	layer_12_ep5_tp_allreduce [label="TP All-Reduce\nEP-Group-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_12_ep5_tp0_sa_out -> layer_12_ep5_tp_allreduce
	layer_12_ep5_tp1_sa_out -> layer_12_ep5_tp_allreduce
	layer_12_ep5_tp2_sa_out -> layer_12_ep5_tp_allreduce
	layer_12_ep5_tp3_sa_out -> layer_12_ep5_tp_allreduce
	layer_12_ep6_tp_allreduce [label="TP All-Reduce\nEP-Group-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_12_ep6_tp0_sa_out -> layer_12_ep6_tp_allreduce
	layer_12_ep6_tp1_sa_out -> layer_12_ep6_tp_allreduce
	layer_12_ep6_tp2_sa_out -> layer_12_ep6_tp_allreduce
	layer_12_ep6_tp3_sa_out -> layer_12_ep6_tp_allreduce
	layer_12_ep7_tp_allreduce [label="TP All-Reduce\nEP-Group-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_12_ep7_tp0_sa_out -> layer_12_ep7_tp_allreduce
	layer_12_ep7_tp1_sa_out -> layer_12_ep7_tp_allreduce
	layer_12_ep7_tp2_sa_out -> layer_12_ep7_tp_allreduce
	layer_12_ep7_tp3_sa_out -> layer_12_ep7_tp_allreduce
	layer_12_ep8_tp_allreduce [label="TP All-Reduce\nEP-Group-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_12_ep8_tp0_sa_out -> layer_12_ep8_tp_allreduce
	layer_12_ep8_tp1_sa_out -> layer_12_ep8_tp_allreduce
	layer_12_ep8_tp2_sa_out -> layer_12_ep8_tp_allreduce
	layer_12_ep8_tp3_sa_out -> layer_12_ep8_tp_allreduce
	layer_12_ep9_tp_allreduce [label="TP All-Reduce\nEP-Group-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_12_ep9_tp0_sa_out -> layer_12_ep9_tp_allreduce
	layer_12_ep9_tp1_sa_out -> layer_12_ep9_tp_allreduce
	layer_12_ep9_tp2_sa_out -> layer_12_ep9_tp_allreduce
	layer_12_ep9_tp3_sa_out -> layer_12_ep9_tp_allreduce
	layer_12_ep10_tp_allreduce [label="TP All-Reduce\nEP-Group-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_12_ep10_tp0_sa_out -> layer_12_ep10_tp_allreduce
	layer_12_ep10_tp1_sa_out -> layer_12_ep10_tp_allreduce
	layer_12_ep10_tp2_sa_out -> layer_12_ep10_tp_allreduce
	layer_12_ep10_tp3_sa_out -> layer_12_ep10_tp_allreduce
	layer_12_ep11_tp_allreduce [label="TP All-Reduce\nEP-Group-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_12_ep11_tp0_sa_out -> layer_12_ep11_tp_allreduce
	layer_12_ep11_tp1_sa_out -> layer_12_ep11_tp_allreduce
	layer_12_ep11_tp2_sa_out -> layer_12_ep11_tp_allreduce
	layer_12_ep11_tp3_sa_out -> layer_12_ep11_tp_allreduce
	layer_12_ep12_tp_allreduce [label="TP All-Reduce\nEP-Group-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_12_ep12_tp0_sa_out -> layer_12_ep12_tp_allreduce
	layer_12_ep12_tp1_sa_out -> layer_12_ep12_tp_allreduce
	layer_12_ep12_tp2_sa_out -> layer_12_ep12_tp_allreduce
	layer_12_ep12_tp3_sa_out -> layer_12_ep12_tp_allreduce
	layer_12_ep13_tp_allreduce [label="TP All-Reduce\nEP-Group-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_12_ep13_tp0_sa_out -> layer_12_ep13_tp_allreduce
	layer_12_ep13_tp1_sa_out -> layer_12_ep13_tp_allreduce
	layer_12_ep13_tp2_sa_out -> layer_12_ep13_tp_allreduce
	layer_12_ep13_tp3_sa_out -> layer_12_ep13_tp_allreduce
	layer_12_ep14_tp_allreduce [label="TP All-Reduce\nEP-Group-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_12_ep14_tp0_sa_out -> layer_12_ep14_tp_allreduce
	layer_12_ep14_tp1_sa_out -> layer_12_ep14_tp_allreduce
	layer_12_ep14_tp2_sa_out -> layer_12_ep14_tp_allreduce
	layer_12_ep14_tp3_sa_out -> layer_12_ep14_tp_allreduce
	layer_12_ep15_tp_allreduce [label="TP All-Reduce\nEP-Group-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_12_ep15_tp0_sa_out -> layer_12_ep15_tp_allreduce
	layer_12_ep15_tp1_sa_out -> layer_12_ep15_tp_allreduce
	layer_12_ep15_tp2_sa_out -> layer_12_ep15_tp_allreduce
	layer_12_ep15_tp3_sa_out -> layer_12_ep15_tp_allreduce
	layer_12_ep0_gate [label="MoE Gate\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_12_ep0_expert_0 [label="Expert-0\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep0_gate -> layer_12_ep0_expert_0 [label="select tokens" style=dashed]
	layer_12_ep0_expert_1 [label="Expert-1\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep0_gate -> layer_12_ep0_expert_1 [label="select tokens" style=dashed]
	layer_12_ep0_expert_2 [label="Expert-2\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep0_gate -> layer_12_ep0_expert_2 [label="select tokens" style=dashed]
	layer_12_ep0_expert_3 [label="Expert-3\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep0_gate -> layer_12_ep0_expert_3 [label="select tokens" style=dashed]
	layer_12_ep0_expert_aggr [label="Expert Aggregation\nEP-Group-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_12_ep0_expert_0 -> layer_12_ep0_expert_aggr
	layer_12_ep0_expert_1 -> layer_12_ep0_expert_aggr
	layer_12_ep0_expert_2 -> layer_12_ep0_expert_aggr
	layer_12_ep0_expert_3 -> layer_12_ep0_expert_aggr
	layer_12_ep1_gate [label="MoE Gate\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_12_ep1_expert_0 [label="Expert-0\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep1_gate -> layer_12_ep1_expert_0 [label="select tokens" style=dashed]
	layer_12_ep1_expert_1 [label="Expert-1\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep1_gate -> layer_12_ep1_expert_1 [label="select tokens" style=dashed]
	layer_12_ep1_expert_2 [label="Expert-2\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep1_gate -> layer_12_ep1_expert_2 [label="select tokens" style=dashed]
	layer_12_ep1_expert_3 [label="Expert-3\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep1_gate -> layer_12_ep1_expert_3 [label="select tokens" style=dashed]
	layer_12_ep1_expert_aggr [label="Expert Aggregation\nEP-Group-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_12_ep1_expert_0 -> layer_12_ep1_expert_aggr
	layer_12_ep1_expert_1 -> layer_12_ep1_expert_aggr
	layer_12_ep1_expert_2 -> layer_12_ep1_expert_aggr
	layer_12_ep1_expert_3 -> layer_12_ep1_expert_aggr
	layer_12_ep2_gate [label="MoE Gate\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_12_ep2_expert_0 [label="Expert-0\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep2_gate -> layer_12_ep2_expert_0 [label="select tokens" style=dashed]
	layer_12_ep2_expert_1 [label="Expert-1\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep2_gate -> layer_12_ep2_expert_1 [label="select tokens" style=dashed]
	layer_12_ep2_expert_2 [label="Expert-2\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep2_gate -> layer_12_ep2_expert_2 [label="select tokens" style=dashed]
	layer_12_ep2_expert_3 [label="Expert-3\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep2_gate -> layer_12_ep2_expert_3 [label="select tokens" style=dashed]
	layer_12_ep2_expert_aggr [label="Expert Aggregation\nEP-Group-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_12_ep2_expert_0 -> layer_12_ep2_expert_aggr
	layer_12_ep2_expert_1 -> layer_12_ep2_expert_aggr
	layer_12_ep2_expert_2 -> layer_12_ep2_expert_aggr
	layer_12_ep2_expert_3 -> layer_12_ep2_expert_aggr
	layer_12_ep3_gate [label="MoE Gate\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_12_ep3_expert_0 [label="Expert-0\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep3_gate -> layer_12_ep3_expert_0 [label="select tokens" style=dashed]
	layer_12_ep3_expert_1 [label="Expert-1\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep3_gate -> layer_12_ep3_expert_1 [label="select tokens" style=dashed]
	layer_12_ep3_expert_2 [label="Expert-2\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep3_gate -> layer_12_ep3_expert_2 [label="select tokens" style=dashed]
	layer_12_ep3_expert_3 [label="Expert-3\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep3_gate -> layer_12_ep3_expert_3 [label="select tokens" style=dashed]
	layer_12_ep3_expert_aggr [label="Expert Aggregation\nEP-Group-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_12_ep3_expert_0 -> layer_12_ep3_expert_aggr
	layer_12_ep3_expert_1 -> layer_12_ep3_expert_aggr
	layer_12_ep3_expert_2 -> layer_12_ep3_expert_aggr
	layer_12_ep3_expert_3 -> layer_12_ep3_expert_aggr
	layer_12_ep4_gate [label="MoE Gate\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_12_ep4_expert_0 [label="Expert-0\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep4_gate -> layer_12_ep4_expert_0 [label="select tokens" style=dashed]
	layer_12_ep4_expert_1 [label="Expert-1\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep4_gate -> layer_12_ep4_expert_1 [label="select tokens" style=dashed]
	layer_12_ep4_expert_2 [label="Expert-2\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep4_gate -> layer_12_ep4_expert_2 [label="select tokens" style=dashed]
	layer_12_ep4_expert_3 [label="Expert-3\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep4_gate -> layer_12_ep4_expert_3 [label="select tokens" style=dashed]
	layer_12_ep4_expert_aggr [label="Expert Aggregation\nEP-Group-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_12_ep4_expert_0 -> layer_12_ep4_expert_aggr
	layer_12_ep4_expert_1 -> layer_12_ep4_expert_aggr
	layer_12_ep4_expert_2 -> layer_12_ep4_expert_aggr
	layer_12_ep4_expert_3 -> layer_12_ep4_expert_aggr
	layer_12_ep5_gate [label="MoE Gate\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_12_ep5_expert_0 [label="Expert-0\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep5_gate -> layer_12_ep5_expert_0 [label="select tokens" style=dashed]
	layer_12_ep5_expert_1 [label="Expert-1\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep5_gate -> layer_12_ep5_expert_1 [label="select tokens" style=dashed]
	layer_12_ep5_expert_2 [label="Expert-2\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep5_gate -> layer_12_ep5_expert_2 [label="select tokens" style=dashed]
	layer_12_ep5_expert_3 [label="Expert-3\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep5_gate -> layer_12_ep5_expert_3 [label="select tokens" style=dashed]
	layer_12_ep5_expert_aggr [label="Expert Aggregation\nEP-Group-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_12_ep5_expert_0 -> layer_12_ep5_expert_aggr
	layer_12_ep5_expert_1 -> layer_12_ep5_expert_aggr
	layer_12_ep5_expert_2 -> layer_12_ep5_expert_aggr
	layer_12_ep5_expert_3 -> layer_12_ep5_expert_aggr
	layer_12_ep6_gate [label="MoE Gate\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_12_ep6_expert_0 [label="Expert-0\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep6_gate -> layer_12_ep6_expert_0 [label="select tokens" style=dashed]
	layer_12_ep6_expert_1 [label="Expert-1\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep6_gate -> layer_12_ep6_expert_1 [label="select tokens" style=dashed]
	layer_12_ep6_expert_2 [label="Expert-2\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep6_gate -> layer_12_ep6_expert_2 [label="select tokens" style=dashed]
	layer_12_ep6_expert_3 [label="Expert-3\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep6_gate -> layer_12_ep6_expert_3 [label="select tokens" style=dashed]
	layer_12_ep6_expert_aggr [label="Expert Aggregation\nEP-Group-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_12_ep6_expert_0 -> layer_12_ep6_expert_aggr
	layer_12_ep6_expert_1 -> layer_12_ep6_expert_aggr
	layer_12_ep6_expert_2 -> layer_12_ep6_expert_aggr
	layer_12_ep6_expert_3 -> layer_12_ep6_expert_aggr
	layer_12_ep7_gate [label="MoE Gate\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_12_ep7_expert_0 [label="Expert-0\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep7_gate -> layer_12_ep7_expert_0 [label="select tokens" style=dashed]
	layer_12_ep7_expert_1 [label="Expert-1\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep7_gate -> layer_12_ep7_expert_1 [label="select tokens" style=dashed]
	layer_12_ep7_expert_2 [label="Expert-2\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep7_gate -> layer_12_ep7_expert_2 [label="select tokens" style=dashed]
	layer_12_ep7_expert_3 [label="Expert-3\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep7_gate -> layer_12_ep7_expert_3 [label="select tokens" style=dashed]
	layer_12_ep7_expert_aggr [label="Expert Aggregation\nEP-Group-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_12_ep7_expert_0 -> layer_12_ep7_expert_aggr
	layer_12_ep7_expert_1 -> layer_12_ep7_expert_aggr
	layer_12_ep7_expert_2 -> layer_12_ep7_expert_aggr
	layer_12_ep7_expert_3 -> layer_12_ep7_expert_aggr
	layer_12_ep8_gate [label="MoE Gate\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_12_ep8_expert_0 [label="Expert-0\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep8_gate -> layer_12_ep8_expert_0 [label="select tokens" style=dashed]
	layer_12_ep8_expert_1 [label="Expert-1\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep8_gate -> layer_12_ep8_expert_1 [label="select tokens" style=dashed]
	layer_12_ep8_expert_2 [label="Expert-2\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep8_gate -> layer_12_ep8_expert_2 [label="select tokens" style=dashed]
	layer_12_ep8_expert_3 [label="Expert-3\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep8_gate -> layer_12_ep8_expert_3 [label="select tokens" style=dashed]
	layer_12_ep8_expert_aggr [label="Expert Aggregation\nEP-Group-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_12_ep8_expert_0 -> layer_12_ep8_expert_aggr
	layer_12_ep8_expert_1 -> layer_12_ep8_expert_aggr
	layer_12_ep8_expert_2 -> layer_12_ep8_expert_aggr
	layer_12_ep8_expert_3 -> layer_12_ep8_expert_aggr
	layer_12_ep9_gate [label="MoE Gate\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_12_ep9_expert_0 [label="Expert-0\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep9_gate -> layer_12_ep9_expert_0 [label="select tokens" style=dashed]
	layer_12_ep9_expert_1 [label="Expert-1\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep9_gate -> layer_12_ep9_expert_1 [label="select tokens" style=dashed]
	layer_12_ep9_expert_2 [label="Expert-2\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep9_gate -> layer_12_ep9_expert_2 [label="select tokens" style=dashed]
	layer_12_ep9_expert_3 [label="Expert-3\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep9_gate -> layer_12_ep9_expert_3 [label="select tokens" style=dashed]
	layer_12_ep9_expert_aggr [label="Expert Aggregation\nEP-Group-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_12_ep9_expert_0 -> layer_12_ep9_expert_aggr
	layer_12_ep9_expert_1 -> layer_12_ep9_expert_aggr
	layer_12_ep9_expert_2 -> layer_12_ep9_expert_aggr
	layer_12_ep9_expert_3 -> layer_12_ep9_expert_aggr
	layer_12_ep10_gate [label="MoE Gate\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_12_ep10_expert_0 [label="Expert-0\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep10_gate -> layer_12_ep10_expert_0 [label="select tokens" style=dashed]
	layer_12_ep10_expert_1 [label="Expert-1\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep10_gate -> layer_12_ep10_expert_1 [label="select tokens" style=dashed]
	layer_12_ep10_expert_2 [label="Expert-2\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep10_gate -> layer_12_ep10_expert_2 [label="select tokens" style=dashed]
	layer_12_ep10_expert_3 [label="Expert-3\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep10_gate -> layer_12_ep10_expert_3 [label="select tokens" style=dashed]
	layer_12_ep10_expert_aggr [label="Expert Aggregation\nEP-Group-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_12_ep10_expert_0 -> layer_12_ep10_expert_aggr
	layer_12_ep10_expert_1 -> layer_12_ep10_expert_aggr
	layer_12_ep10_expert_2 -> layer_12_ep10_expert_aggr
	layer_12_ep10_expert_3 -> layer_12_ep10_expert_aggr
	layer_12_ep11_gate [label="MoE Gate\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_12_ep11_expert_0 [label="Expert-0\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep11_gate -> layer_12_ep11_expert_0 [label="select tokens" style=dashed]
	layer_12_ep11_expert_1 [label="Expert-1\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep11_gate -> layer_12_ep11_expert_1 [label="select tokens" style=dashed]
	layer_12_ep11_expert_2 [label="Expert-2\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep11_gate -> layer_12_ep11_expert_2 [label="select tokens" style=dashed]
	layer_12_ep11_expert_3 [label="Expert-3\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep11_gate -> layer_12_ep11_expert_3 [label="select tokens" style=dashed]
	layer_12_ep11_expert_aggr [label="Expert Aggregation\nEP-Group-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_12_ep11_expert_0 -> layer_12_ep11_expert_aggr
	layer_12_ep11_expert_1 -> layer_12_ep11_expert_aggr
	layer_12_ep11_expert_2 -> layer_12_ep11_expert_aggr
	layer_12_ep11_expert_3 -> layer_12_ep11_expert_aggr
	layer_12_ep12_gate [label="MoE Gate\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_12_ep12_expert_0 [label="Expert-0\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep12_gate -> layer_12_ep12_expert_0 [label="select tokens" style=dashed]
	layer_12_ep12_expert_1 [label="Expert-1\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep12_gate -> layer_12_ep12_expert_1 [label="select tokens" style=dashed]
	layer_12_ep12_expert_2 [label="Expert-2\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep12_gate -> layer_12_ep12_expert_2 [label="select tokens" style=dashed]
	layer_12_ep12_expert_3 [label="Expert-3\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep12_gate -> layer_12_ep12_expert_3 [label="select tokens" style=dashed]
	layer_12_ep12_expert_aggr [label="Expert Aggregation\nEP-Group-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_12_ep12_expert_0 -> layer_12_ep12_expert_aggr
	layer_12_ep12_expert_1 -> layer_12_ep12_expert_aggr
	layer_12_ep12_expert_2 -> layer_12_ep12_expert_aggr
	layer_12_ep12_expert_3 -> layer_12_ep12_expert_aggr
	layer_12_ep13_gate [label="MoE Gate\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_12_ep13_expert_0 [label="Expert-0\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep13_gate -> layer_12_ep13_expert_0 [label="select tokens" style=dashed]
	layer_12_ep13_expert_1 [label="Expert-1\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep13_gate -> layer_12_ep13_expert_1 [label="select tokens" style=dashed]
	layer_12_ep13_expert_2 [label="Expert-2\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep13_gate -> layer_12_ep13_expert_2 [label="select tokens" style=dashed]
	layer_12_ep13_expert_3 [label="Expert-3\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep13_gate -> layer_12_ep13_expert_3 [label="select tokens" style=dashed]
	layer_12_ep13_expert_aggr [label="Expert Aggregation\nEP-Group-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_12_ep13_expert_0 -> layer_12_ep13_expert_aggr
	layer_12_ep13_expert_1 -> layer_12_ep13_expert_aggr
	layer_12_ep13_expert_2 -> layer_12_ep13_expert_aggr
	layer_12_ep13_expert_3 -> layer_12_ep13_expert_aggr
	layer_12_ep14_gate [label="MoE Gate\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_12_ep14_expert_0 [label="Expert-0\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep14_gate -> layer_12_ep14_expert_0 [label="select tokens" style=dashed]
	layer_12_ep14_expert_1 [label="Expert-1\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep14_gate -> layer_12_ep14_expert_1 [label="select tokens" style=dashed]
	layer_12_ep14_expert_2 [label="Expert-2\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep14_gate -> layer_12_ep14_expert_2 [label="select tokens" style=dashed]
	layer_12_ep14_expert_3 [label="Expert-3\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep14_gate -> layer_12_ep14_expert_3 [label="select tokens" style=dashed]
	layer_12_ep14_expert_aggr [label="Expert Aggregation\nEP-Group-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_12_ep14_expert_0 -> layer_12_ep14_expert_aggr
	layer_12_ep14_expert_1 -> layer_12_ep14_expert_aggr
	layer_12_ep14_expert_2 -> layer_12_ep14_expert_aggr
	layer_12_ep14_expert_3 -> layer_12_ep14_expert_aggr
	layer_12_ep15_gate [label="MoE Gate\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_12_ep15_expert_0 [label="Expert-0\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep15_gate -> layer_12_ep15_expert_0 [label="select tokens" style=dashed]
	layer_12_ep15_expert_1 [label="Expert-1\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep15_gate -> layer_12_ep15_expert_1 [label="select tokens" style=dashed]
	layer_12_ep15_expert_2 [label="Expert-2\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep15_gate -> layer_12_ep15_expert_2 [label="select tokens" style=dashed]
	layer_12_ep15_expert_3 [label="Expert-3\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_12_ep15_gate -> layer_12_ep15_expert_3 [label="select tokens" style=dashed]
	layer_12_ep15_expert_aggr [label="Expert Aggregation\nEP-Group-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_12_ep15_expert_0 -> layer_12_ep15_expert_aggr
	layer_12_ep15_expert_1 -> layer_12_ep15_expert_aggr
	layer_12_ep15_expert_2 -> layer_12_ep15_expert_aggr
	layer_12_ep15_expert_3 -> layer_12_ep15_expert_aggr
	layer_12_to_13_ep0_pp [label="Pipeline Stage Transfer\nEP-Group-0\nLayer-12 to Layer-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_12_ep0_expert_aggr -> layer_12_to_13_ep0_pp
	layer_12_to_13_ep1_pp [label="Pipeline Stage Transfer\nEP-Group-1\nLayer-12 to Layer-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_12_ep1_expert_aggr -> layer_12_to_13_ep1_pp
	layer_12_to_13_ep2_pp [label="Pipeline Stage Transfer\nEP-Group-2\nLayer-12 to Layer-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_12_ep2_expert_aggr -> layer_12_to_13_ep2_pp
	layer_12_to_13_ep3_pp [label="Pipeline Stage Transfer\nEP-Group-3\nLayer-12 to Layer-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_12_ep3_expert_aggr -> layer_12_to_13_ep3_pp
	layer_12_to_13_ep4_pp [label="Pipeline Stage Transfer\nEP-Group-4\nLayer-12 to Layer-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_12_ep4_expert_aggr -> layer_12_to_13_ep4_pp
	layer_12_to_13_ep5_pp [label="Pipeline Stage Transfer\nEP-Group-5\nLayer-12 to Layer-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_12_ep5_expert_aggr -> layer_12_to_13_ep5_pp
	layer_12_to_13_ep6_pp [label="Pipeline Stage Transfer\nEP-Group-6\nLayer-12 to Layer-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_12_ep6_expert_aggr -> layer_12_to_13_ep6_pp
	layer_12_to_13_ep7_pp [label="Pipeline Stage Transfer\nEP-Group-7\nLayer-12 to Layer-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_12_ep7_expert_aggr -> layer_12_to_13_ep7_pp
	layer_12_to_13_ep8_pp [label="Pipeline Stage Transfer\nEP-Group-8\nLayer-12 to Layer-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_12_ep8_expert_aggr -> layer_12_to_13_ep8_pp
	layer_12_to_13_ep9_pp [label="Pipeline Stage Transfer\nEP-Group-9\nLayer-12 to Layer-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_12_ep9_expert_aggr -> layer_12_to_13_ep9_pp
	layer_12_to_13_ep10_pp [label="Pipeline Stage Transfer\nEP-Group-10\nLayer-12 to Layer-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_12_ep10_expert_aggr -> layer_12_to_13_ep10_pp
	layer_12_to_13_ep11_pp [label="Pipeline Stage Transfer\nEP-Group-11\nLayer-12 to Layer-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_12_ep11_expert_aggr -> layer_12_to_13_ep11_pp
	layer_12_to_13_ep12_pp [label="Pipeline Stage Transfer\nEP-Group-12\nLayer-12 to Layer-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_12_ep12_expert_aggr -> layer_12_to_13_ep12_pp
	layer_12_to_13_ep13_pp [label="Pipeline Stage Transfer\nEP-Group-13\nLayer-12 to Layer-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_12_ep13_expert_aggr -> layer_12_to_13_ep13_pp
	layer_12_to_13_ep14_pp [label="Pipeline Stage Transfer\nEP-Group-14\nLayer-12 to Layer-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_12_ep14_expert_aggr -> layer_12_to_13_ep14_pp
	layer_12_to_13_ep15_pp [label="Pipeline Stage Transfer\nEP-Group-15\nLayer-12 to Layer-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_12_ep15_expert_aggr -> layer_12_to_13_ep15_pp
	layer_13_ep0_tp0_sa_qkv [label="Self-Attn QKV\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep0_tp0_sa_attn [label="Self-Attn Compute\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep0_tp0_sa_out [label="Self-Attn Output\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep0_tp0_sa_qkv -> layer_13_ep0_tp0_sa_attn
	layer_13_ep0_tp0_sa_attn -> layer_13_ep0_tp0_sa_out
	layer_13_ep0_tp1_sa_qkv [label="Self-Attn QKV\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep0_tp1_sa_attn [label="Self-Attn Compute\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep0_tp1_sa_out [label="Self-Attn Output\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep0_tp1_sa_qkv -> layer_13_ep0_tp1_sa_attn
	layer_13_ep0_tp1_sa_attn -> layer_13_ep0_tp1_sa_out
	layer_13_ep0_tp2_sa_qkv [label="Self-Attn QKV\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep0_tp2_sa_attn [label="Self-Attn Compute\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep0_tp2_sa_out [label="Self-Attn Output\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep0_tp2_sa_qkv -> layer_13_ep0_tp2_sa_attn
	layer_13_ep0_tp2_sa_attn -> layer_13_ep0_tp2_sa_out
	layer_13_ep0_tp3_sa_qkv [label="Self-Attn QKV\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep0_tp3_sa_attn [label="Self-Attn Compute\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep0_tp3_sa_out [label="Self-Attn Output\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep0_tp3_sa_qkv -> layer_13_ep0_tp3_sa_attn
	layer_13_ep0_tp3_sa_attn -> layer_13_ep0_tp3_sa_out
	layer_13_ep1_tp0_sa_qkv [label="Self-Attn QKV\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep1_tp0_sa_attn [label="Self-Attn Compute\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep1_tp0_sa_out [label="Self-Attn Output\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep1_tp0_sa_qkv -> layer_13_ep1_tp0_sa_attn
	layer_13_ep1_tp0_sa_attn -> layer_13_ep1_tp0_sa_out
	layer_13_ep1_tp1_sa_qkv [label="Self-Attn QKV\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep1_tp1_sa_attn [label="Self-Attn Compute\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep1_tp1_sa_out [label="Self-Attn Output\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep1_tp1_sa_qkv -> layer_13_ep1_tp1_sa_attn
	layer_13_ep1_tp1_sa_attn -> layer_13_ep1_tp1_sa_out
	layer_13_ep1_tp2_sa_qkv [label="Self-Attn QKV\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep1_tp2_sa_attn [label="Self-Attn Compute\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep1_tp2_sa_out [label="Self-Attn Output\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep1_tp2_sa_qkv -> layer_13_ep1_tp2_sa_attn
	layer_13_ep1_tp2_sa_attn -> layer_13_ep1_tp2_sa_out
	layer_13_ep1_tp3_sa_qkv [label="Self-Attn QKV\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep1_tp3_sa_attn [label="Self-Attn Compute\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep1_tp3_sa_out [label="Self-Attn Output\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep1_tp3_sa_qkv -> layer_13_ep1_tp3_sa_attn
	layer_13_ep1_tp3_sa_attn -> layer_13_ep1_tp3_sa_out
	layer_13_ep2_tp0_sa_qkv [label="Self-Attn QKV\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep2_tp0_sa_attn [label="Self-Attn Compute\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep2_tp0_sa_out [label="Self-Attn Output\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep2_tp0_sa_qkv -> layer_13_ep2_tp0_sa_attn
	layer_13_ep2_tp0_sa_attn -> layer_13_ep2_tp0_sa_out
	layer_13_ep2_tp1_sa_qkv [label="Self-Attn QKV\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep2_tp1_sa_attn [label="Self-Attn Compute\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep2_tp1_sa_out [label="Self-Attn Output\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep2_tp1_sa_qkv -> layer_13_ep2_tp1_sa_attn
	layer_13_ep2_tp1_sa_attn -> layer_13_ep2_tp1_sa_out
	layer_13_ep2_tp2_sa_qkv [label="Self-Attn QKV\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep2_tp2_sa_attn [label="Self-Attn Compute\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep2_tp2_sa_out [label="Self-Attn Output\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep2_tp2_sa_qkv -> layer_13_ep2_tp2_sa_attn
	layer_13_ep2_tp2_sa_attn -> layer_13_ep2_tp2_sa_out
	layer_13_ep2_tp3_sa_qkv [label="Self-Attn QKV\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep2_tp3_sa_attn [label="Self-Attn Compute\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep2_tp3_sa_out [label="Self-Attn Output\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep2_tp3_sa_qkv -> layer_13_ep2_tp3_sa_attn
	layer_13_ep2_tp3_sa_attn -> layer_13_ep2_tp3_sa_out
	layer_13_ep3_tp0_sa_qkv [label="Self-Attn QKV\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep3_tp0_sa_attn [label="Self-Attn Compute\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep3_tp0_sa_out [label="Self-Attn Output\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep3_tp0_sa_qkv -> layer_13_ep3_tp0_sa_attn
	layer_13_ep3_tp0_sa_attn -> layer_13_ep3_tp0_sa_out
	layer_13_ep3_tp1_sa_qkv [label="Self-Attn QKV\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep3_tp1_sa_attn [label="Self-Attn Compute\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep3_tp1_sa_out [label="Self-Attn Output\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep3_tp1_sa_qkv -> layer_13_ep3_tp1_sa_attn
	layer_13_ep3_tp1_sa_attn -> layer_13_ep3_tp1_sa_out
	layer_13_ep3_tp2_sa_qkv [label="Self-Attn QKV\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep3_tp2_sa_attn [label="Self-Attn Compute\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep3_tp2_sa_out [label="Self-Attn Output\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep3_tp2_sa_qkv -> layer_13_ep3_tp2_sa_attn
	layer_13_ep3_tp2_sa_attn -> layer_13_ep3_tp2_sa_out
	layer_13_ep3_tp3_sa_qkv [label="Self-Attn QKV\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep3_tp3_sa_attn [label="Self-Attn Compute\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep3_tp3_sa_out [label="Self-Attn Output\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep3_tp3_sa_qkv -> layer_13_ep3_tp3_sa_attn
	layer_13_ep3_tp3_sa_attn -> layer_13_ep3_tp3_sa_out
	layer_13_ep4_tp0_sa_qkv [label="Self-Attn QKV\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep4_tp0_sa_attn [label="Self-Attn Compute\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep4_tp0_sa_out [label="Self-Attn Output\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep4_tp0_sa_qkv -> layer_13_ep4_tp0_sa_attn
	layer_13_ep4_tp0_sa_attn -> layer_13_ep4_tp0_sa_out
	layer_13_ep4_tp1_sa_qkv [label="Self-Attn QKV\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep4_tp1_sa_attn [label="Self-Attn Compute\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep4_tp1_sa_out [label="Self-Attn Output\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep4_tp1_sa_qkv -> layer_13_ep4_tp1_sa_attn
	layer_13_ep4_tp1_sa_attn -> layer_13_ep4_tp1_sa_out
	layer_13_ep4_tp2_sa_qkv [label="Self-Attn QKV\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep4_tp2_sa_attn [label="Self-Attn Compute\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep4_tp2_sa_out [label="Self-Attn Output\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep4_tp2_sa_qkv -> layer_13_ep4_tp2_sa_attn
	layer_13_ep4_tp2_sa_attn -> layer_13_ep4_tp2_sa_out
	layer_13_ep4_tp3_sa_qkv [label="Self-Attn QKV\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep4_tp3_sa_attn [label="Self-Attn Compute\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep4_tp3_sa_out [label="Self-Attn Output\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep4_tp3_sa_qkv -> layer_13_ep4_tp3_sa_attn
	layer_13_ep4_tp3_sa_attn -> layer_13_ep4_tp3_sa_out
	layer_13_ep5_tp0_sa_qkv [label="Self-Attn QKV\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep5_tp0_sa_attn [label="Self-Attn Compute\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep5_tp0_sa_out [label="Self-Attn Output\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep5_tp0_sa_qkv -> layer_13_ep5_tp0_sa_attn
	layer_13_ep5_tp0_sa_attn -> layer_13_ep5_tp0_sa_out
	layer_13_ep5_tp1_sa_qkv [label="Self-Attn QKV\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep5_tp1_sa_attn [label="Self-Attn Compute\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep5_tp1_sa_out [label="Self-Attn Output\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep5_tp1_sa_qkv -> layer_13_ep5_tp1_sa_attn
	layer_13_ep5_tp1_sa_attn -> layer_13_ep5_tp1_sa_out
	layer_13_ep5_tp2_sa_qkv [label="Self-Attn QKV\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep5_tp2_sa_attn [label="Self-Attn Compute\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep5_tp2_sa_out [label="Self-Attn Output\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep5_tp2_sa_qkv -> layer_13_ep5_tp2_sa_attn
	layer_13_ep5_tp2_sa_attn -> layer_13_ep5_tp2_sa_out
	layer_13_ep5_tp3_sa_qkv [label="Self-Attn QKV\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep5_tp3_sa_attn [label="Self-Attn Compute\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep5_tp3_sa_out [label="Self-Attn Output\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep5_tp3_sa_qkv -> layer_13_ep5_tp3_sa_attn
	layer_13_ep5_tp3_sa_attn -> layer_13_ep5_tp3_sa_out
	layer_13_ep6_tp0_sa_qkv [label="Self-Attn QKV\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep6_tp0_sa_attn [label="Self-Attn Compute\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep6_tp0_sa_out [label="Self-Attn Output\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep6_tp0_sa_qkv -> layer_13_ep6_tp0_sa_attn
	layer_13_ep6_tp0_sa_attn -> layer_13_ep6_tp0_sa_out
	layer_13_ep6_tp1_sa_qkv [label="Self-Attn QKV\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep6_tp1_sa_attn [label="Self-Attn Compute\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep6_tp1_sa_out [label="Self-Attn Output\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep6_tp1_sa_qkv -> layer_13_ep6_tp1_sa_attn
	layer_13_ep6_tp1_sa_attn -> layer_13_ep6_tp1_sa_out
	layer_13_ep6_tp2_sa_qkv [label="Self-Attn QKV\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep6_tp2_sa_attn [label="Self-Attn Compute\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep6_tp2_sa_out [label="Self-Attn Output\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep6_tp2_sa_qkv -> layer_13_ep6_tp2_sa_attn
	layer_13_ep6_tp2_sa_attn -> layer_13_ep6_tp2_sa_out
	layer_13_ep6_tp3_sa_qkv [label="Self-Attn QKV\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep6_tp3_sa_attn [label="Self-Attn Compute\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep6_tp3_sa_out [label="Self-Attn Output\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep6_tp3_sa_qkv -> layer_13_ep6_tp3_sa_attn
	layer_13_ep6_tp3_sa_attn -> layer_13_ep6_tp3_sa_out
	layer_13_ep7_tp0_sa_qkv [label="Self-Attn QKV\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep7_tp0_sa_attn [label="Self-Attn Compute\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep7_tp0_sa_out [label="Self-Attn Output\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep7_tp0_sa_qkv -> layer_13_ep7_tp0_sa_attn
	layer_13_ep7_tp0_sa_attn -> layer_13_ep7_tp0_sa_out
	layer_13_ep7_tp1_sa_qkv [label="Self-Attn QKV\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep7_tp1_sa_attn [label="Self-Attn Compute\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep7_tp1_sa_out [label="Self-Attn Output\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep7_tp1_sa_qkv -> layer_13_ep7_tp1_sa_attn
	layer_13_ep7_tp1_sa_attn -> layer_13_ep7_tp1_sa_out
	layer_13_ep7_tp2_sa_qkv [label="Self-Attn QKV\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep7_tp2_sa_attn [label="Self-Attn Compute\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep7_tp2_sa_out [label="Self-Attn Output\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep7_tp2_sa_qkv -> layer_13_ep7_tp2_sa_attn
	layer_13_ep7_tp2_sa_attn -> layer_13_ep7_tp2_sa_out
	layer_13_ep7_tp3_sa_qkv [label="Self-Attn QKV\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep7_tp3_sa_attn [label="Self-Attn Compute\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep7_tp3_sa_out [label="Self-Attn Output\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep7_tp3_sa_qkv -> layer_13_ep7_tp3_sa_attn
	layer_13_ep7_tp3_sa_attn -> layer_13_ep7_tp3_sa_out
	layer_13_ep8_tp0_sa_qkv [label="Self-Attn QKV\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep8_tp0_sa_attn [label="Self-Attn Compute\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep8_tp0_sa_out [label="Self-Attn Output\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep8_tp0_sa_qkv -> layer_13_ep8_tp0_sa_attn
	layer_13_ep8_tp0_sa_attn -> layer_13_ep8_tp0_sa_out
	layer_13_ep8_tp1_sa_qkv [label="Self-Attn QKV\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep8_tp1_sa_attn [label="Self-Attn Compute\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep8_tp1_sa_out [label="Self-Attn Output\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep8_tp1_sa_qkv -> layer_13_ep8_tp1_sa_attn
	layer_13_ep8_tp1_sa_attn -> layer_13_ep8_tp1_sa_out
	layer_13_ep8_tp2_sa_qkv [label="Self-Attn QKV\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep8_tp2_sa_attn [label="Self-Attn Compute\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep8_tp2_sa_out [label="Self-Attn Output\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep8_tp2_sa_qkv -> layer_13_ep8_tp2_sa_attn
	layer_13_ep8_tp2_sa_attn -> layer_13_ep8_tp2_sa_out
	layer_13_ep8_tp3_sa_qkv [label="Self-Attn QKV\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep8_tp3_sa_attn [label="Self-Attn Compute\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep8_tp3_sa_out [label="Self-Attn Output\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep8_tp3_sa_qkv -> layer_13_ep8_tp3_sa_attn
	layer_13_ep8_tp3_sa_attn -> layer_13_ep8_tp3_sa_out
	layer_13_ep9_tp0_sa_qkv [label="Self-Attn QKV\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep9_tp0_sa_attn [label="Self-Attn Compute\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep9_tp0_sa_out [label="Self-Attn Output\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep9_tp0_sa_qkv -> layer_13_ep9_tp0_sa_attn
	layer_13_ep9_tp0_sa_attn -> layer_13_ep9_tp0_sa_out
	layer_13_ep9_tp1_sa_qkv [label="Self-Attn QKV\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep9_tp1_sa_attn [label="Self-Attn Compute\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep9_tp1_sa_out [label="Self-Attn Output\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep9_tp1_sa_qkv -> layer_13_ep9_tp1_sa_attn
	layer_13_ep9_tp1_sa_attn -> layer_13_ep9_tp1_sa_out
	layer_13_ep9_tp2_sa_qkv [label="Self-Attn QKV\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep9_tp2_sa_attn [label="Self-Attn Compute\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep9_tp2_sa_out [label="Self-Attn Output\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep9_tp2_sa_qkv -> layer_13_ep9_tp2_sa_attn
	layer_13_ep9_tp2_sa_attn -> layer_13_ep9_tp2_sa_out
	layer_13_ep9_tp3_sa_qkv [label="Self-Attn QKV\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep9_tp3_sa_attn [label="Self-Attn Compute\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep9_tp3_sa_out [label="Self-Attn Output\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep9_tp3_sa_qkv -> layer_13_ep9_tp3_sa_attn
	layer_13_ep9_tp3_sa_attn -> layer_13_ep9_tp3_sa_out
	layer_13_ep10_tp0_sa_qkv [label="Self-Attn QKV\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep10_tp0_sa_attn [label="Self-Attn Compute\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep10_tp0_sa_out [label="Self-Attn Output\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep10_tp0_sa_qkv -> layer_13_ep10_tp0_sa_attn
	layer_13_ep10_tp0_sa_attn -> layer_13_ep10_tp0_sa_out
	layer_13_ep10_tp1_sa_qkv [label="Self-Attn QKV\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep10_tp1_sa_attn [label="Self-Attn Compute\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep10_tp1_sa_out [label="Self-Attn Output\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep10_tp1_sa_qkv -> layer_13_ep10_tp1_sa_attn
	layer_13_ep10_tp1_sa_attn -> layer_13_ep10_tp1_sa_out
	layer_13_ep10_tp2_sa_qkv [label="Self-Attn QKV\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep10_tp2_sa_attn [label="Self-Attn Compute\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep10_tp2_sa_out [label="Self-Attn Output\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep10_tp2_sa_qkv -> layer_13_ep10_tp2_sa_attn
	layer_13_ep10_tp2_sa_attn -> layer_13_ep10_tp2_sa_out
	layer_13_ep10_tp3_sa_qkv [label="Self-Attn QKV\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep10_tp3_sa_attn [label="Self-Attn Compute\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep10_tp3_sa_out [label="Self-Attn Output\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep10_tp3_sa_qkv -> layer_13_ep10_tp3_sa_attn
	layer_13_ep10_tp3_sa_attn -> layer_13_ep10_tp3_sa_out
	layer_13_ep11_tp0_sa_qkv [label="Self-Attn QKV\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep11_tp0_sa_attn [label="Self-Attn Compute\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep11_tp0_sa_out [label="Self-Attn Output\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep11_tp0_sa_qkv -> layer_13_ep11_tp0_sa_attn
	layer_13_ep11_tp0_sa_attn -> layer_13_ep11_tp0_sa_out
	layer_13_ep11_tp1_sa_qkv [label="Self-Attn QKV\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep11_tp1_sa_attn [label="Self-Attn Compute\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep11_tp1_sa_out [label="Self-Attn Output\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep11_tp1_sa_qkv -> layer_13_ep11_tp1_sa_attn
	layer_13_ep11_tp1_sa_attn -> layer_13_ep11_tp1_sa_out
	layer_13_ep11_tp2_sa_qkv [label="Self-Attn QKV\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep11_tp2_sa_attn [label="Self-Attn Compute\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep11_tp2_sa_out [label="Self-Attn Output\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep11_tp2_sa_qkv -> layer_13_ep11_tp2_sa_attn
	layer_13_ep11_tp2_sa_attn -> layer_13_ep11_tp2_sa_out
	layer_13_ep11_tp3_sa_qkv [label="Self-Attn QKV\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep11_tp3_sa_attn [label="Self-Attn Compute\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep11_tp3_sa_out [label="Self-Attn Output\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep11_tp3_sa_qkv -> layer_13_ep11_tp3_sa_attn
	layer_13_ep11_tp3_sa_attn -> layer_13_ep11_tp3_sa_out
	layer_13_ep12_tp0_sa_qkv [label="Self-Attn QKV\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep12_tp0_sa_attn [label="Self-Attn Compute\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep12_tp0_sa_out [label="Self-Attn Output\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep12_tp0_sa_qkv -> layer_13_ep12_tp0_sa_attn
	layer_13_ep12_tp0_sa_attn -> layer_13_ep12_tp0_sa_out
	layer_13_ep12_tp1_sa_qkv [label="Self-Attn QKV\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep12_tp1_sa_attn [label="Self-Attn Compute\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep12_tp1_sa_out [label="Self-Attn Output\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep12_tp1_sa_qkv -> layer_13_ep12_tp1_sa_attn
	layer_13_ep12_tp1_sa_attn -> layer_13_ep12_tp1_sa_out
	layer_13_ep12_tp2_sa_qkv [label="Self-Attn QKV\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep12_tp2_sa_attn [label="Self-Attn Compute\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep12_tp2_sa_out [label="Self-Attn Output\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep12_tp2_sa_qkv -> layer_13_ep12_tp2_sa_attn
	layer_13_ep12_tp2_sa_attn -> layer_13_ep12_tp2_sa_out
	layer_13_ep12_tp3_sa_qkv [label="Self-Attn QKV\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep12_tp3_sa_attn [label="Self-Attn Compute\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep12_tp3_sa_out [label="Self-Attn Output\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep12_tp3_sa_qkv -> layer_13_ep12_tp3_sa_attn
	layer_13_ep12_tp3_sa_attn -> layer_13_ep12_tp3_sa_out
	layer_13_ep13_tp0_sa_qkv [label="Self-Attn QKV\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep13_tp0_sa_attn [label="Self-Attn Compute\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep13_tp0_sa_out [label="Self-Attn Output\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep13_tp0_sa_qkv -> layer_13_ep13_tp0_sa_attn
	layer_13_ep13_tp0_sa_attn -> layer_13_ep13_tp0_sa_out
	layer_13_ep13_tp1_sa_qkv [label="Self-Attn QKV\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep13_tp1_sa_attn [label="Self-Attn Compute\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep13_tp1_sa_out [label="Self-Attn Output\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep13_tp1_sa_qkv -> layer_13_ep13_tp1_sa_attn
	layer_13_ep13_tp1_sa_attn -> layer_13_ep13_tp1_sa_out
	layer_13_ep13_tp2_sa_qkv [label="Self-Attn QKV\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep13_tp2_sa_attn [label="Self-Attn Compute\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep13_tp2_sa_out [label="Self-Attn Output\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep13_tp2_sa_qkv -> layer_13_ep13_tp2_sa_attn
	layer_13_ep13_tp2_sa_attn -> layer_13_ep13_tp2_sa_out
	layer_13_ep13_tp3_sa_qkv [label="Self-Attn QKV\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep13_tp3_sa_attn [label="Self-Attn Compute\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep13_tp3_sa_out [label="Self-Attn Output\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep13_tp3_sa_qkv -> layer_13_ep13_tp3_sa_attn
	layer_13_ep13_tp3_sa_attn -> layer_13_ep13_tp3_sa_out
	layer_13_ep14_tp0_sa_qkv [label="Self-Attn QKV\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep14_tp0_sa_attn [label="Self-Attn Compute\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep14_tp0_sa_out [label="Self-Attn Output\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep14_tp0_sa_qkv -> layer_13_ep14_tp0_sa_attn
	layer_13_ep14_tp0_sa_attn -> layer_13_ep14_tp0_sa_out
	layer_13_ep14_tp1_sa_qkv [label="Self-Attn QKV\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep14_tp1_sa_attn [label="Self-Attn Compute\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep14_tp1_sa_out [label="Self-Attn Output\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep14_tp1_sa_qkv -> layer_13_ep14_tp1_sa_attn
	layer_13_ep14_tp1_sa_attn -> layer_13_ep14_tp1_sa_out
	layer_13_ep14_tp2_sa_qkv [label="Self-Attn QKV\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep14_tp2_sa_attn [label="Self-Attn Compute\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep14_tp2_sa_out [label="Self-Attn Output\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep14_tp2_sa_qkv -> layer_13_ep14_tp2_sa_attn
	layer_13_ep14_tp2_sa_attn -> layer_13_ep14_tp2_sa_out
	layer_13_ep14_tp3_sa_qkv [label="Self-Attn QKV\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep14_tp3_sa_attn [label="Self-Attn Compute\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep14_tp3_sa_out [label="Self-Attn Output\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep14_tp3_sa_qkv -> layer_13_ep14_tp3_sa_attn
	layer_13_ep14_tp3_sa_attn -> layer_13_ep14_tp3_sa_out
	layer_13_ep15_tp0_sa_qkv [label="Self-Attn QKV\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep15_tp0_sa_attn [label="Self-Attn Compute\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep15_tp0_sa_out [label="Self-Attn Output\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep15_tp0_sa_qkv -> layer_13_ep15_tp0_sa_attn
	layer_13_ep15_tp0_sa_attn -> layer_13_ep15_tp0_sa_out
	layer_13_ep15_tp1_sa_qkv [label="Self-Attn QKV\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep15_tp1_sa_attn [label="Self-Attn Compute\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep15_tp1_sa_out [label="Self-Attn Output\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep15_tp1_sa_qkv -> layer_13_ep15_tp1_sa_attn
	layer_13_ep15_tp1_sa_attn -> layer_13_ep15_tp1_sa_out
	layer_13_ep15_tp2_sa_qkv [label="Self-Attn QKV\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep15_tp2_sa_attn [label="Self-Attn Compute\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep15_tp2_sa_out [label="Self-Attn Output\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep15_tp2_sa_qkv -> layer_13_ep15_tp2_sa_attn
	layer_13_ep15_tp2_sa_attn -> layer_13_ep15_tp2_sa_out
	layer_13_ep15_tp3_sa_qkv [label="Self-Attn QKV\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep15_tp3_sa_attn [label="Self-Attn Compute\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep15_tp3_sa_out [label="Self-Attn Output\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep15_tp3_sa_qkv -> layer_13_ep15_tp3_sa_attn
	layer_13_ep15_tp3_sa_attn -> layer_13_ep15_tp3_sa_out
	layer_13_ep0_tp_allreduce [label="TP All-Reduce\nEP-Group-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_13_ep0_tp0_sa_out -> layer_13_ep0_tp_allreduce
	layer_13_ep0_tp1_sa_out -> layer_13_ep0_tp_allreduce
	layer_13_ep0_tp2_sa_out -> layer_13_ep0_tp_allreduce
	layer_13_ep0_tp3_sa_out -> layer_13_ep0_tp_allreduce
	layer_13_ep1_tp_allreduce [label="TP All-Reduce\nEP-Group-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_13_ep1_tp0_sa_out -> layer_13_ep1_tp_allreduce
	layer_13_ep1_tp1_sa_out -> layer_13_ep1_tp_allreduce
	layer_13_ep1_tp2_sa_out -> layer_13_ep1_tp_allreduce
	layer_13_ep1_tp3_sa_out -> layer_13_ep1_tp_allreduce
	layer_13_ep2_tp_allreduce [label="TP All-Reduce\nEP-Group-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_13_ep2_tp0_sa_out -> layer_13_ep2_tp_allreduce
	layer_13_ep2_tp1_sa_out -> layer_13_ep2_tp_allreduce
	layer_13_ep2_tp2_sa_out -> layer_13_ep2_tp_allreduce
	layer_13_ep2_tp3_sa_out -> layer_13_ep2_tp_allreduce
	layer_13_ep3_tp_allreduce [label="TP All-Reduce\nEP-Group-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_13_ep3_tp0_sa_out -> layer_13_ep3_tp_allreduce
	layer_13_ep3_tp1_sa_out -> layer_13_ep3_tp_allreduce
	layer_13_ep3_tp2_sa_out -> layer_13_ep3_tp_allreduce
	layer_13_ep3_tp3_sa_out -> layer_13_ep3_tp_allreduce
	layer_13_ep4_tp_allreduce [label="TP All-Reduce\nEP-Group-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_13_ep4_tp0_sa_out -> layer_13_ep4_tp_allreduce
	layer_13_ep4_tp1_sa_out -> layer_13_ep4_tp_allreduce
	layer_13_ep4_tp2_sa_out -> layer_13_ep4_tp_allreduce
	layer_13_ep4_tp3_sa_out -> layer_13_ep4_tp_allreduce
	layer_13_ep5_tp_allreduce [label="TP All-Reduce\nEP-Group-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_13_ep5_tp0_sa_out -> layer_13_ep5_tp_allreduce
	layer_13_ep5_tp1_sa_out -> layer_13_ep5_tp_allreduce
	layer_13_ep5_tp2_sa_out -> layer_13_ep5_tp_allreduce
	layer_13_ep5_tp3_sa_out -> layer_13_ep5_tp_allreduce
	layer_13_ep6_tp_allreduce [label="TP All-Reduce\nEP-Group-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_13_ep6_tp0_sa_out -> layer_13_ep6_tp_allreduce
	layer_13_ep6_tp1_sa_out -> layer_13_ep6_tp_allreduce
	layer_13_ep6_tp2_sa_out -> layer_13_ep6_tp_allreduce
	layer_13_ep6_tp3_sa_out -> layer_13_ep6_tp_allreduce
	layer_13_ep7_tp_allreduce [label="TP All-Reduce\nEP-Group-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_13_ep7_tp0_sa_out -> layer_13_ep7_tp_allreduce
	layer_13_ep7_tp1_sa_out -> layer_13_ep7_tp_allreduce
	layer_13_ep7_tp2_sa_out -> layer_13_ep7_tp_allreduce
	layer_13_ep7_tp3_sa_out -> layer_13_ep7_tp_allreduce
	layer_13_ep8_tp_allreduce [label="TP All-Reduce\nEP-Group-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_13_ep8_tp0_sa_out -> layer_13_ep8_tp_allreduce
	layer_13_ep8_tp1_sa_out -> layer_13_ep8_tp_allreduce
	layer_13_ep8_tp2_sa_out -> layer_13_ep8_tp_allreduce
	layer_13_ep8_tp3_sa_out -> layer_13_ep8_tp_allreduce
	layer_13_ep9_tp_allreduce [label="TP All-Reduce\nEP-Group-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_13_ep9_tp0_sa_out -> layer_13_ep9_tp_allreduce
	layer_13_ep9_tp1_sa_out -> layer_13_ep9_tp_allreduce
	layer_13_ep9_tp2_sa_out -> layer_13_ep9_tp_allreduce
	layer_13_ep9_tp3_sa_out -> layer_13_ep9_tp_allreduce
	layer_13_ep10_tp_allreduce [label="TP All-Reduce\nEP-Group-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_13_ep10_tp0_sa_out -> layer_13_ep10_tp_allreduce
	layer_13_ep10_tp1_sa_out -> layer_13_ep10_tp_allreduce
	layer_13_ep10_tp2_sa_out -> layer_13_ep10_tp_allreduce
	layer_13_ep10_tp3_sa_out -> layer_13_ep10_tp_allreduce
	layer_13_ep11_tp_allreduce [label="TP All-Reduce\nEP-Group-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_13_ep11_tp0_sa_out -> layer_13_ep11_tp_allreduce
	layer_13_ep11_tp1_sa_out -> layer_13_ep11_tp_allreduce
	layer_13_ep11_tp2_sa_out -> layer_13_ep11_tp_allreduce
	layer_13_ep11_tp3_sa_out -> layer_13_ep11_tp_allreduce
	layer_13_ep12_tp_allreduce [label="TP All-Reduce\nEP-Group-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_13_ep12_tp0_sa_out -> layer_13_ep12_tp_allreduce
	layer_13_ep12_tp1_sa_out -> layer_13_ep12_tp_allreduce
	layer_13_ep12_tp2_sa_out -> layer_13_ep12_tp_allreduce
	layer_13_ep12_tp3_sa_out -> layer_13_ep12_tp_allreduce
	layer_13_ep13_tp_allreduce [label="TP All-Reduce\nEP-Group-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_13_ep13_tp0_sa_out -> layer_13_ep13_tp_allreduce
	layer_13_ep13_tp1_sa_out -> layer_13_ep13_tp_allreduce
	layer_13_ep13_tp2_sa_out -> layer_13_ep13_tp_allreduce
	layer_13_ep13_tp3_sa_out -> layer_13_ep13_tp_allreduce
	layer_13_ep14_tp_allreduce [label="TP All-Reduce\nEP-Group-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_13_ep14_tp0_sa_out -> layer_13_ep14_tp_allreduce
	layer_13_ep14_tp1_sa_out -> layer_13_ep14_tp_allreduce
	layer_13_ep14_tp2_sa_out -> layer_13_ep14_tp_allreduce
	layer_13_ep14_tp3_sa_out -> layer_13_ep14_tp_allreduce
	layer_13_ep15_tp_allreduce [label="TP All-Reduce\nEP-Group-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_13_ep15_tp0_sa_out -> layer_13_ep15_tp_allreduce
	layer_13_ep15_tp1_sa_out -> layer_13_ep15_tp_allreduce
	layer_13_ep15_tp2_sa_out -> layer_13_ep15_tp_allreduce
	layer_13_ep15_tp3_sa_out -> layer_13_ep15_tp_allreduce
	layer_13_ep0_gate [label="MoE Gate\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_13_ep0_expert_0 [label="Expert-0\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep0_gate -> layer_13_ep0_expert_0 [label="select tokens" style=dashed]
	layer_13_ep0_expert_1 [label="Expert-1\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep0_gate -> layer_13_ep0_expert_1 [label="select tokens" style=dashed]
	layer_13_ep0_expert_2 [label="Expert-2\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep0_gate -> layer_13_ep0_expert_2 [label="select tokens" style=dashed]
	layer_13_ep0_expert_3 [label="Expert-3\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep0_gate -> layer_13_ep0_expert_3 [label="select tokens" style=dashed]
	layer_13_ep0_expert_aggr [label="Expert Aggregation\nEP-Group-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_13_ep0_expert_0 -> layer_13_ep0_expert_aggr
	layer_13_ep0_expert_1 -> layer_13_ep0_expert_aggr
	layer_13_ep0_expert_2 -> layer_13_ep0_expert_aggr
	layer_13_ep0_expert_3 -> layer_13_ep0_expert_aggr
	layer_13_ep1_gate [label="MoE Gate\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_13_ep1_expert_0 [label="Expert-0\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep1_gate -> layer_13_ep1_expert_0 [label="select tokens" style=dashed]
	layer_13_ep1_expert_1 [label="Expert-1\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep1_gate -> layer_13_ep1_expert_1 [label="select tokens" style=dashed]
	layer_13_ep1_expert_2 [label="Expert-2\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep1_gate -> layer_13_ep1_expert_2 [label="select tokens" style=dashed]
	layer_13_ep1_expert_3 [label="Expert-3\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep1_gate -> layer_13_ep1_expert_3 [label="select tokens" style=dashed]
	layer_13_ep1_expert_aggr [label="Expert Aggregation\nEP-Group-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_13_ep1_expert_0 -> layer_13_ep1_expert_aggr
	layer_13_ep1_expert_1 -> layer_13_ep1_expert_aggr
	layer_13_ep1_expert_2 -> layer_13_ep1_expert_aggr
	layer_13_ep1_expert_3 -> layer_13_ep1_expert_aggr
	layer_13_ep2_gate [label="MoE Gate\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_13_ep2_expert_0 [label="Expert-0\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep2_gate -> layer_13_ep2_expert_0 [label="select tokens" style=dashed]
	layer_13_ep2_expert_1 [label="Expert-1\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep2_gate -> layer_13_ep2_expert_1 [label="select tokens" style=dashed]
	layer_13_ep2_expert_2 [label="Expert-2\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep2_gate -> layer_13_ep2_expert_2 [label="select tokens" style=dashed]
	layer_13_ep2_expert_3 [label="Expert-3\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep2_gate -> layer_13_ep2_expert_3 [label="select tokens" style=dashed]
	layer_13_ep2_expert_aggr [label="Expert Aggregation\nEP-Group-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_13_ep2_expert_0 -> layer_13_ep2_expert_aggr
	layer_13_ep2_expert_1 -> layer_13_ep2_expert_aggr
	layer_13_ep2_expert_2 -> layer_13_ep2_expert_aggr
	layer_13_ep2_expert_3 -> layer_13_ep2_expert_aggr
	layer_13_ep3_gate [label="MoE Gate\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_13_ep3_expert_0 [label="Expert-0\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep3_gate -> layer_13_ep3_expert_0 [label="select tokens" style=dashed]
	layer_13_ep3_expert_1 [label="Expert-1\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep3_gate -> layer_13_ep3_expert_1 [label="select tokens" style=dashed]
	layer_13_ep3_expert_2 [label="Expert-2\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep3_gate -> layer_13_ep3_expert_2 [label="select tokens" style=dashed]
	layer_13_ep3_expert_3 [label="Expert-3\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep3_gate -> layer_13_ep3_expert_3 [label="select tokens" style=dashed]
	layer_13_ep3_expert_aggr [label="Expert Aggregation\nEP-Group-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_13_ep3_expert_0 -> layer_13_ep3_expert_aggr
	layer_13_ep3_expert_1 -> layer_13_ep3_expert_aggr
	layer_13_ep3_expert_2 -> layer_13_ep3_expert_aggr
	layer_13_ep3_expert_3 -> layer_13_ep3_expert_aggr
	layer_13_ep4_gate [label="MoE Gate\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_13_ep4_expert_0 [label="Expert-0\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep4_gate -> layer_13_ep4_expert_0 [label="select tokens" style=dashed]
	layer_13_ep4_expert_1 [label="Expert-1\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep4_gate -> layer_13_ep4_expert_1 [label="select tokens" style=dashed]
	layer_13_ep4_expert_2 [label="Expert-2\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep4_gate -> layer_13_ep4_expert_2 [label="select tokens" style=dashed]
	layer_13_ep4_expert_3 [label="Expert-3\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep4_gate -> layer_13_ep4_expert_3 [label="select tokens" style=dashed]
	layer_13_ep4_expert_aggr [label="Expert Aggregation\nEP-Group-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_13_ep4_expert_0 -> layer_13_ep4_expert_aggr
	layer_13_ep4_expert_1 -> layer_13_ep4_expert_aggr
	layer_13_ep4_expert_2 -> layer_13_ep4_expert_aggr
	layer_13_ep4_expert_3 -> layer_13_ep4_expert_aggr
	layer_13_ep5_gate [label="MoE Gate\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_13_ep5_expert_0 [label="Expert-0\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep5_gate -> layer_13_ep5_expert_0 [label="select tokens" style=dashed]
	layer_13_ep5_expert_1 [label="Expert-1\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep5_gate -> layer_13_ep5_expert_1 [label="select tokens" style=dashed]
	layer_13_ep5_expert_2 [label="Expert-2\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep5_gate -> layer_13_ep5_expert_2 [label="select tokens" style=dashed]
	layer_13_ep5_expert_3 [label="Expert-3\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep5_gate -> layer_13_ep5_expert_3 [label="select tokens" style=dashed]
	layer_13_ep5_expert_aggr [label="Expert Aggregation\nEP-Group-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_13_ep5_expert_0 -> layer_13_ep5_expert_aggr
	layer_13_ep5_expert_1 -> layer_13_ep5_expert_aggr
	layer_13_ep5_expert_2 -> layer_13_ep5_expert_aggr
	layer_13_ep5_expert_3 -> layer_13_ep5_expert_aggr
	layer_13_ep6_gate [label="MoE Gate\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_13_ep6_expert_0 [label="Expert-0\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep6_gate -> layer_13_ep6_expert_0 [label="select tokens" style=dashed]
	layer_13_ep6_expert_1 [label="Expert-1\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep6_gate -> layer_13_ep6_expert_1 [label="select tokens" style=dashed]
	layer_13_ep6_expert_2 [label="Expert-2\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep6_gate -> layer_13_ep6_expert_2 [label="select tokens" style=dashed]
	layer_13_ep6_expert_3 [label="Expert-3\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep6_gate -> layer_13_ep6_expert_3 [label="select tokens" style=dashed]
	layer_13_ep6_expert_aggr [label="Expert Aggregation\nEP-Group-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_13_ep6_expert_0 -> layer_13_ep6_expert_aggr
	layer_13_ep6_expert_1 -> layer_13_ep6_expert_aggr
	layer_13_ep6_expert_2 -> layer_13_ep6_expert_aggr
	layer_13_ep6_expert_3 -> layer_13_ep6_expert_aggr
	layer_13_ep7_gate [label="MoE Gate\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_13_ep7_expert_0 [label="Expert-0\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep7_gate -> layer_13_ep7_expert_0 [label="select tokens" style=dashed]
	layer_13_ep7_expert_1 [label="Expert-1\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep7_gate -> layer_13_ep7_expert_1 [label="select tokens" style=dashed]
	layer_13_ep7_expert_2 [label="Expert-2\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep7_gate -> layer_13_ep7_expert_2 [label="select tokens" style=dashed]
	layer_13_ep7_expert_3 [label="Expert-3\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep7_gate -> layer_13_ep7_expert_3 [label="select tokens" style=dashed]
	layer_13_ep7_expert_aggr [label="Expert Aggregation\nEP-Group-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_13_ep7_expert_0 -> layer_13_ep7_expert_aggr
	layer_13_ep7_expert_1 -> layer_13_ep7_expert_aggr
	layer_13_ep7_expert_2 -> layer_13_ep7_expert_aggr
	layer_13_ep7_expert_3 -> layer_13_ep7_expert_aggr
	layer_13_ep8_gate [label="MoE Gate\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_13_ep8_expert_0 [label="Expert-0\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep8_gate -> layer_13_ep8_expert_0 [label="select tokens" style=dashed]
	layer_13_ep8_expert_1 [label="Expert-1\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep8_gate -> layer_13_ep8_expert_1 [label="select tokens" style=dashed]
	layer_13_ep8_expert_2 [label="Expert-2\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep8_gate -> layer_13_ep8_expert_2 [label="select tokens" style=dashed]
	layer_13_ep8_expert_3 [label="Expert-3\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep8_gate -> layer_13_ep8_expert_3 [label="select tokens" style=dashed]
	layer_13_ep8_expert_aggr [label="Expert Aggregation\nEP-Group-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_13_ep8_expert_0 -> layer_13_ep8_expert_aggr
	layer_13_ep8_expert_1 -> layer_13_ep8_expert_aggr
	layer_13_ep8_expert_2 -> layer_13_ep8_expert_aggr
	layer_13_ep8_expert_3 -> layer_13_ep8_expert_aggr
	layer_13_ep9_gate [label="MoE Gate\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_13_ep9_expert_0 [label="Expert-0\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep9_gate -> layer_13_ep9_expert_0 [label="select tokens" style=dashed]
	layer_13_ep9_expert_1 [label="Expert-1\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep9_gate -> layer_13_ep9_expert_1 [label="select tokens" style=dashed]
	layer_13_ep9_expert_2 [label="Expert-2\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep9_gate -> layer_13_ep9_expert_2 [label="select tokens" style=dashed]
	layer_13_ep9_expert_3 [label="Expert-3\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep9_gate -> layer_13_ep9_expert_3 [label="select tokens" style=dashed]
	layer_13_ep9_expert_aggr [label="Expert Aggregation\nEP-Group-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_13_ep9_expert_0 -> layer_13_ep9_expert_aggr
	layer_13_ep9_expert_1 -> layer_13_ep9_expert_aggr
	layer_13_ep9_expert_2 -> layer_13_ep9_expert_aggr
	layer_13_ep9_expert_3 -> layer_13_ep9_expert_aggr
	layer_13_ep10_gate [label="MoE Gate\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_13_ep10_expert_0 [label="Expert-0\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep10_gate -> layer_13_ep10_expert_0 [label="select tokens" style=dashed]
	layer_13_ep10_expert_1 [label="Expert-1\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep10_gate -> layer_13_ep10_expert_1 [label="select tokens" style=dashed]
	layer_13_ep10_expert_2 [label="Expert-2\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep10_gate -> layer_13_ep10_expert_2 [label="select tokens" style=dashed]
	layer_13_ep10_expert_3 [label="Expert-3\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep10_gate -> layer_13_ep10_expert_3 [label="select tokens" style=dashed]
	layer_13_ep10_expert_aggr [label="Expert Aggregation\nEP-Group-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_13_ep10_expert_0 -> layer_13_ep10_expert_aggr
	layer_13_ep10_expert_1 -> layer_13_ep10_expert_aggr
	layer_13_ep10_expert_2 -> layer_13_ep10_expert_aggr
	layer_13_ep10_expert_3 -> layer_13_ep10_expert_aggr
	layer_13_ep11_gate [label="MoE Gate\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_13_ep11_expert_0 [label="Expert-0\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep11_gate -> layer_13_ep11_expert_0 [label="select tokens" style=dashed]
	layer_13_ep11_expert_1 [label="Expert-1\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep11_gate -> layer_13_ep11_expert_1 [label="select tokens" style=dashed]
	layer_13_ep11_expert_2 [label="Expert-2\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep11_gate -> layer_13_ep11_expert_2 [label="select tokens" style=dashed]
	layer_13_ep11_expert_3 [label="Expert-3\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep11_gate -> layer_13_ep11_expert_3 [label="select tokens" style=dashed]
	layer_13_ep11_expert_aggr [label="Expert Aggregation\nEP-Group-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_13_ep11_expert_0 -> layer_13_ep11_expert_aggr
	layer_13_ep11_expert_1 -> layer_13_ep11_expert_aggr
	layer_13_ep11_expert_2 -> layer_13_ep11_expert_aggr
	layer_13_ep11_expert_3 -> layer_13_ep11_expert_aggr
	layer_13_ep12_gate [label="MoE Gate\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_13_ep12_expert_0 [label="Expert-0\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep12_gate -> layer_13_ep12_expert_0 [label="select tokens" style=dashed]
	layer_13_ep12_expert_1 [label="Expert-1\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep12_gate -> layer_13_ep12_expert_1 [label="select tokens" style=dashed]
	layer_13_ep12_expert_2 [label="Expert-2\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep12_gate -> layer_13_ep12_expert_2 [label="select tokens" style=dashed]
	layer_13_ep12_expert_3 [label="Expert-3\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep12_gate -> layer_13_ep12_expert_3 [label="select tokens" style=dashed]
	layer_13_ep12_expert_aggr [label="Expert Aggregation\nEP-Group-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_13_ep12_expert_0 -> layer_13_ep12_expert_aggr
	layer_13_ep12_expert_1 -> layer_13_ep12_expert_aggr
	layer_13_ep12_expert_2 -> layer_13_ep12_expert_aggr
	layer_13_ep12_expert_3 -> layer_13_ep12_expert_aggr
	layer_13_ep13_gate [label="MoE Gate\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_13_ep13_expert_0 [label="Expert-0\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep13_gate -> layer_13_ep13_expert_0 [label="select tokens" style=dashed]
	layer_13_ep13_expert_1 [label="Expert-1\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep13_gate -> layer_13_ep13_expert_1 [label="select tokens" style=dashed]
	layer_13_ep13_expert_2 [label="Expert-2\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep13_gate -> layer_13_ep13_expert_2 [label="select tokens" style=dashed]
	layer_13_ep13_expert_3 [label="Expert-3\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep13_gate -> layer_13_ep13_expert_3 [label="select tokens" style=dashed]
	layer_13_ep13_expert_aggr [label="Expert Aggregation\nEP-Group-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_13_ep13_expert_0 -> layer_13_ep13_expert_aggr
	layer_13_ep13_expert_1 -> layer_13_ep13_expert_aggr
	layer_13_ep13_expert_2 -> layer_13_ep13_expert_aggr
	layer_13_ep13_expert_3 -> layer_13_ep13_expert_aggr
	layer_13_ep14_gate [label="MoE Gate\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_13_ep14_expert_0 [label="Expert-0\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep14_gate -> layer_13_ep14_expert_0 [label="select tokens" style=dashed]
	layer_13_ep14_expert_1 [label="Expert-1\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep14_gate -> layer_13_ep14_expert_1 [label="select tokens" style=dashed]
	layer_13_ep14_expert_2 [label="Expert-2\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep14_gate -> layer_13_ep14_expert_2 [label="select tokens" style=dashed]
	layer_13_ep14_expert_3 [label="Expert-3\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep14_gate -> layer_13_ep14_expert_3 [label="select tokens" style=dashed]
	layer_13_ep14_expert_aggr [label="Expert Aggregation\nEP-Group-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_13_ep14_expert_0 -> layer_13_ep14_expert_aggr
	layer_13_ep14_expert_1 -> layer_13_ep14_expert_aggr
	layer_13_ep14_expert_2 -> layer_13_ep14_expert_aggr
	layer_13_ep14_expert_3 -> layer_13_ep14_expert_aggr
	layer_13_ep15_gate [label="MoE Gate\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_13_ep15_expert_0 [label="Expert-0\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep15_gate -> layer_13_ep15_expert_0 [label="select tokens" style=dashed]
	layer_13_ep15_expert_1 [label="Expert-1\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep15_gate -> layer_13_ep15_expert_1 [label="select tokens" style=dashed]
	layer_13_ep15_expert_2 [label="Expert-2\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep15_gate -> layer_13_ep15_expert_2 [label="select tokens" style=dashed]
	layer_13_ep15_expert_3 [label="Expert-3\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_13_ep15_gate -> layer_13_ep15_expert_3 [label="select tokens" style=dashed]
	layer_13_ep15_expert_aggr [label="Expert Aggregation\nEP-Group-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_13_ep15_expert_0 -> layer_13_ep15_expert_aggr
	layer_13_ep15_expert_1 -> layer_13_ep15_expert_aggr
	layer_13_ep15_expert_2 -> layer_13_ep15_expert_aggr
	layer_13_ep15_expert_3 -> layer_13_ep15_expert_aggr
	layer_13_to_14_ep0_pp [label="Pipeline Stage Transfer\nEP-Group-0\nLayer-13 to Layer-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_13_ep0_expert_aggr -> layer_13_to_14_ep0_pp
	layer_13_to_14_ep1_pp [label="Pipeline Stage Transfer\nEP-Group-1\nLayer-13 to Layer-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_13_ep1_expert_aggr -> layer_13_to_14_ep1_pp
	layer_13_to_14_ep2_pp [label="Pipeline Stage Transfer\nEP-Group-2\nLayer-13 to Layer-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_13_ep2_expert_aggr -> layer_13_to_14_ep2_pp
	layer_13_to_14_ep3_pp [label="Pipeline Stage Transfer\nEP-Group-3\nLayer-13 to Layer-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_13_ep3_expert_aggr -> layer_13_to_14_ep3_pp
	layer_13_to_14_ep4_pp [label="Pipeline Stage Transfer\nEP-Group-4\nLayer-13 to Layer-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_13_ep4_expert_aggr -> layer_13_to_14_ep4_pp
	layer_13_to_14_ep5_pp [label="Pipeline Stage Transfer\nEP-Group-5\nLayer-13 to Layer-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_13_ep5_expert_aggr -> layer_13_to_14_ep5_pp
	layer_13_to_14_ep6_pp [label="Pipeline Stage Transfer\nEP-Group-6\nLayer-13 to Layer-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_13_ep6_expert_aggr -> layer_13_to_14_ep6_pp
	layer_13_to_14_ep7_pp [label="Pipeline Stage Transfer\nEP-Group-7\nLayer-13 to Layer-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_13_ep7_expert_aggr -> layer_13_to_14_ep7_pp
	layer_13_to_14_ep8_pp [label="Pipeline Stage Transfer\nEP-Group-8\nLayer-13 to Layer-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_13_ep8_expert_aggr -> layer_13_to_14_ep8_pp
	layer_13_to_14_ep9_pp [label="Pipeline Stage Transfer\nEP-Group-9\nLayer-13 to Layer-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_13_ep9_expert_aggr -> layer_13_to_14_ep9_pp
	layer_13_to_14_ep10_pp [label="Pipeline Stage Transfer\nEP-Group-10\nLayer-13 to Layer-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_13_ep10_expert_aggr -> layer_13_to_14_ep10_pp
	layer_13_to_14_ep11_pp [label="Pipeline Stage Transfer\nEP-Group-11\nLayer-13 to Layer-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_13_ep11_expert_aggr -> layer_13_to_14_ep11_pp
	layer_13_to_14_ep12_pp [label="Pipeline Stage Transfer\nEP-Group-12\nLayer-13 to Layer-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_13_ep12_expert_aggr -> layer_13_to_14_ep12_pp
	layer_13_to_14_ep13_pp [label="Pipeline Stage Transfer\nEP-Group-13\nLayer-13 to Layer-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_13_ep13_expert_aggr -> layer_13_to_14_ep13_pp
	layer_13_to_14_ep14_pp [label="Pipeline Stage Transfer\nEP-Group-14\nLayer-13 to Layer-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_13_ep14_expert_aggr -> layer_13_to_14_ep14_pp
	layer_13_to_14_ep15_pp [label="Pipeline Stage Transfer\nEP-Group-15\nLayer-13 to Layer-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_13_ep15_expert_aggr -> layer_13_to_14_ep15_pp
	layer_14_ep0_tp0_sa_qkv [label="Self-Attn QKV\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep0_tp0_sa_attn [label="Self-Attn Compute\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep0_tp0_sa_out [label="Self-Attn Output\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep0_tp0_sa_qkv -> layer_14_ep0_tp0_sa_attn
	layer_14_ep0_tp0_sa_attn -> layer_14_ep0_tp0_sa_out
	layer_14_ep0_tp1_sa_qkv [label="Self-Attn QKV\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep0_tp1_sa_attn [label="Self-Attn Compute\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep0_tp1_sa_out [label="Self-Attn Output\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep0_tp1_sa_qkv -> layer_14_ep0_tp1_sa_attn
	layer_14_ep0_tp1_sa_attn -> layer_14_ep0_tp1_sa_out
	layer_14_ep0_tp2_sa_qkv [label="Self-Attn QKV\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep0_tp2_sa_attn [label="Self-Attn Compute\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep0_tp2_sa_out [label="Self-Attn Output\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep0_tp2_sa_qkv -> layer_14_ep0_tp2_sa_attn
	layer_14_ep0_tp2_sa_attn -> layer_14_ep0_tp2_sa_out
	layer_14_ep0_tp3_sa_qkv [label="Self-Attn QKV\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep0_tp3_sa_attn [label="Self-Attn Compute\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep0_tp3_sa_out [label="Self-Attn Output\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep0_tp3_sa_qkv -> layer_14_ep0_tp3_sa_attn
	layer_14_ep0_tp3_sa_attn -> layer_14_ep0_tp3_sa_out
	layer_14_ep1_tp0_sa_qkv [label="Self-Attn QKV\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep1_tp0_sa_attn [label="Self-Attn Compute\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep1_tp0_sa_out [label="Self-Attn Output\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep1_tp0_sa_qkv -> layer_14_ep1_tp0_sa_attn
	layer_14_ep1_tp0_sa_attn -> layer_14_ep1_tp0_sa_out
	layer_14_ep1_tp1_sa_qkv [label="Self-Attn QKV\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep1_tp1_sa_attn [label="Self-Attn Compute\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep1_tp1_sa_out [label="Self-Attn Output\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep1_tp1_sa_qkv -> layer_14_ep1_tp1_sa_attn
	layer_14_ep1_tp1_sa_attn -> layer_14_ep1_tp1_sa_out
	layer_14_ep1_tp2_sa_qkv [label="Self-Attn QKV\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep1_tp2_sa_attn [label="Self-Attn Compute\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep1_tp2_sa_out [label="Self-Attn Output\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep1_tp2_sa_qkv -> layer_14_ep1_tp2_sa_attn
	layer_14_ep1_tp2_sa_attn -> layer_14_ep1_tp2_sa_out
	layer_14_ep1_tp3_sa_qkv [label="Self-Attn QKV\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep1_tp3_sa_attn [label="Self-Attn Compute\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep1_tp3_sa_out [label="Self-Attn Output\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep1_tp3_sa_qkv -> layer_14_ep1_tp3_sa_attn
	layer_14_ep1_tp3_sa_attn -> layer_14_ep1_tp3_sa_out
	layer_14_ep2_tp0_sa_qkv [label="Self-Attn QKV\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep2_tp0_sa_attn [label="Self-Attn Compute\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep2_tp0_sa_out [label="Self-Attn Output\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep2_tp0_sa_qkv -> layer_14_ep2_tp0_sa_attn
	layer_14_ep2_tp0_sa_attn -> layer_14_ep2_tp0_sa_out
	layer_14_ep2_tp1_sa_qkv [label="Self-Attn QKV\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep2_tp1_sa_attn [label="Self-Attn Compute\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep2_tp1_sa_out [label="Self-Attn Output\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep2_tp1_sa_qkv -> layer_14_ep2_tp1_sa_attn
	layer_14_ep2_tp1_sa_attn -> layer_14_ep2_tp1_sa_out
	layer_14_ep2_tp2_sa_qkv [label="Self-Attn QKV\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep2_tp2_sa_attn [label="Self-Attn Compute\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep2_tp2_sa_out [label="Self-Attn Output\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep2_tp2_sa_qkv -> layer_14_ep2_tp2_sa_attn
	layer_14_ep2_tp2_sa_attn -> layer_14_ep2_tp2_sa_out
	layer_14_ep2_tp3_sa_qkv [label="Self-Attn QKV\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep2_tp3_sa_attn [label="Self-Attn Compute\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep2_tp3_sa_out [label="Self-Attn Output\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep2_tp3_sa_qkv -> layer_14_ep2_tp3_sa_attn
	layer_14_ep2_tp3_sa_attn -> layer_14_ep2_tp3_sa_out
	layer_14_ep3_tp0_sa_qkv [label="Self-Attn QKV\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep3_tp0_sa_attn [label="Self-Attn Compute\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep3_tp0_sa_out [label="Self-Attn Output\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep3_tp0_sa_qkv -> layer_14_ep3_tp0_sa_attn
	layer_14_ep3_tp0_sa_attn -> layer_14_ep3_tp0_sa_out
	layer_14_ep3_tp1_sa_qkv [label="Self-Attn QKV\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep3_tp1_sa_attn [label="Self-Attn Compute\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep3_tp1_sa_out [label="Self-Attn Output\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep3_tp1_sa_qkv -> layer_14_ep3_tp1_sa_attn
	layer_14_ep3_tp1_sa_attn -> layer_14_ep3_tp1_sa_out
	layer_14_ep3_tp2_sa_qkv [label="Self-Attn QKV\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep3_tp2_sa_attn [label="Self-Attn Compute\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep3_tp2_sa_out [label="Self-Attn Output\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep3_tp2_sa_qkv -> layer_14_ep3_tp2_sa_attn
	layer_14_ep3_tp2_sa_attn -> layer_14_ep3_tp2_sa_out
	layer_14_ep3_tp3_sa_qkv [label="Self-Attn QKV\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep3_tp3_sa_attn [label="Self-Attn Compute\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep3_tp3_sa_out [label="Self-Attn Output\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep3_tp3_sa_qkv -> layer_14_ep3_tp3_sa_attn
	layer_14_ep3_tp3_sa_attn -> layer_14_ep3_tp3_sa_out
	layer_14_ep4_tp0_sa_qkv [label="Self-Attn QKV\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep4_tp0_sa_attn [label="Self-Attn Compute\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep4_tp0_sa_out [label="Self-Attn Output\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep4_tp0_sa_qkv -> layer_14_ep4_tp0_sa_attn
	layer_14_ep4_tp0_sa_attn -> layer_14_ep4_tp0_sa_out
	layer_14_ep4_tp1_sa_qkv [label="Self-Attn QKV\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep4_tp1_sa_attn [label="Self-Attn Compute\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep4_tp1_sa_out [label="Self-Attn Output\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep4_tp1_sa_qkv -> layer_14_ep4_tp1_sa_attn
	layer_14_ep4_tp1_sa_attn -> layer_14_ep4_tp1_sa_out
	layer_14_ep4_tp2_sa_qkv [label="Self-Attn QKV\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep4_tp2_sa_attn [label="Self-Attn Compute\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep4_tp2_sa_out [label="Self-Attn Output\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep4_tp2_sa_qkv -> layer_14_ep4_tp2_sa_attn
	layer_14_ep4_tp2_sa_attn -> layer_14_ep4_tp2_sa_out
	layer_14_ep4_tp3_sa_qkv [label="Self-Attn QKV\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep4_tp3_sa_attn [label="Self-Attn Compute\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep4_tp3_sa_out [label="Self-Attn Output\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep4_tp3_sa_qkv -> layer_14_ep4_tp3_sa_attn
	layer_14_ep4_tp3_sa_attn -> layer_14_ep4_tp3_sa_out
	layer_14_ep5_tp0_sa_qkv [label="Self-Attn QKV\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep5_tp0_sa_attn [label="Self-Attn Compute\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep5_tp0_sa_out [label="Self-Attn Output\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep5_tp0_sa_qkv -> layer_14_ep5_tp0_sa_attn
	layer_14_ep5_tp0_sa_attn -> layer_14_ep5_tp0_sa_out
	layer_14_ep5_tp1_sa_qkv [label="Self-Attn QKV\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep5_tp1_sa_attn [label="Self-Attn Compute\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep5_tp1_sa_out [label="Self-Attn Output\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep5_tp1_sa_qkv -> layer_14_ep5_tp1_sa_attn
	layer_14_ep5_tp1_sa_attn -> layer_14_ep5_tp1_sa_out
	layer_14_ep5_tp2_sa_qkv [label="Self-Attn QKV\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep5_tp2_sa_attn [label="Self-Attn Compute\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep5_tp2_sa_out [label="Self-Attn Output\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep5_tp2_sa_qkv -> layer_14_ep5_tp2_sa_attn
	layer_14_ep5_tp2_sa_attn -> layer_14_ep5_tp2_sa_out
	layer_14_ep5_tp3_sa_qkv [label="Self-Attn QKV\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep5_tp3_sa_attn [label="Self-Attn Compute\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep5_tp3_sa_out [label="Self-Attn Output\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep5_tp3_sa_qkv -> layer_14_ep5_tp3_sa_attn
	layer_14_ep5_tp3_sa_attn -> layer_14_ep5_tp3_sa_out
	layer_14_ep6_tp0_sa_qkv [label="Self-Attn QKV\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep6_tp0_sa_attn [label="Self-Attn Compute\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep6_tp0_sa_out [label="Self-Attn Output\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep6_tp0_sa_qkv -> layer_14_ep6_tp0_sa_attn
	layer_14_ep6_tp0_sa_attn -> layer_14_ep6_tp0_sa_out
	layer_14_ep6_tp1_sa_qkv [label="Self-Attn QKV\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep6_tp1_sa_attn [label="Self-Attn Compute\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep6_tp1_sa_out [label="Self-Attn Output\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep6_tp1_sa_qkv -> layer_14_ep6_tp1_sa_attn
	layer_14_ep6_tp1_sa_attn -> layer_14_ep6_tp1_sa_out
	layer_14_ep6_tp2_sa_qkv [label="Self-Attn QKV\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep6_tp2_sa_attn [label="Self-Attn Compute\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep6_tp2_sa_out [label="Self-Attn Output\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep6_tp2_sa_qkv -> layer_14_ep6_tp2_sa_attn
	layer_14_ep6_tp2_sa_attn -> layer_14_ep6_tp2_sa_out
	layer_14_ep6_tp3_sa_qkv [label="Self-Attn QKV\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep6_tp3_sa_attn [label="Self-Attn Compute\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep6_tp3_sa_out [label="Self-Attn Output\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep6_tp3_sa_qkv -> layer_14_ep6_tp3_sa_attn
	layer_14_ep6_tp3_sa_attn -> layer_14_ep6_tp3_sa_out
	layer_14_ep7_tp0_sa_qkv [label="Self-Attn QKV\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep7_tp0_sa_attn [label="Self-Attn Compute\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep7_tp0_sa_out [label="Self-Attn Output\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep7_tp0_sa_qkv -> layer_14_ep7_tp0_sa_attn
	layer_14_ep7_tp0_sa_attn -> layer_14_ep7_tp0_sa_out
	layer_14_ep7_tp1_sa_qkv [label="Self-Attn QKV\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep7_tp1_sa_attn [label="Self-Attn Compute\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep7_tp1_sa_out [label="Self-Attn Output\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep7_tp1_sa_qkv -> layer_14_ep7_tp1_sa_attn
	layer_14_ep7_tp1_sa_attn -> layer_14_ep7_tp1_sa_out
	layer_14_ep7_tp2_sa_qkv [label="Self-Attn QKV\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep7_tp2_sa_attn [label="Self-Attn Compute\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep7_tp2_sa_out [label="Self-Attn Output\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep7_tp2_sa_qkv -> layer_14_ep7_tp2_sa_attn
	layer_14_ep7_tp2_sa_attn -> layer_14_ep7_tp2_sa_out
	layer_14_ep7_tp3_sa_qkv [label="Self-Attn QKV\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep7_tp3_sa_attn [label="Self-Attn Compute\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep7_tp3_sa_out [label="Self-Attn Output\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep7_tp3_sa_qkv -> layer_14_ep7_tp3_sa_attn
	layer_14_ep7_tp3_sa_attn -> layer_14_ep7_tp3_sa_out
	layer_14_ep8_tp0_sa_qkv [label="Self-Attn QKV\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep8_tp0_sa_attn [label="Self-Attn Compute\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep8_tp0_sa_out [label="Self-Attn Output\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep8_tp0_sa_qkv -> layer_14_ep8_tp0_sa_attn
	layer_14_ep8_tp0_sa_attn -> layer_14_ep8_tp0_sa_out
	layer_14_ep8_tp1_sa_qkv [label="Self-Attn QKV\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep8_tp1_sa_attn [label="Self-Attn Compute\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep8_tp1_sa_out [label="Self-Attn Output\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep8_tp1_sa_qkv -> layer_14_ep8_tp1_sa_attn
	layer_14_ep8_tp1_sa_attn -> layer_14_ep8_tp1_sa_out
	layer_14_ep8_tp2_sa_qkv [label="Self-Attn QKV\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep8_tp2_sa_attn [label="Self-Attn Compute\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep8_tp2_sa_out [label="Self-Attn Output\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep8_tp2_sa_qkv -> layer_14_ep8_tp2_sa_attn
	layer_14_ep8_tp2_sa_attn -> layer_14_ep8_tp2_sa_out
	layer_14_ep8_tp3_sa_qkv [label="Self-Attn QKV\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep8_tp3_sa_attn [label="Self-Attn Compute\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep8_tp3_sa_out [label="Self-Attn Output\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep8_tp3_sa_qkv -> layer_14_ep8_tp3_sa_attn
	layer_14_ep8_tp3_sa_attn -> layer_14_ep8_tp3_sa_out
	layer_14_ep9_tp0_sa_qkv [label="Self-Attn QKV\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep9_tp0_sa_attn [label="Self-Attn Compute\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep9_tp0_sa_out [label="Self-Attn Output\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep9_tp0_sa_qkv -> layer_14_ep9_tp0_sa_attn
	layer_14_ep9_tp0_sa_attn -> layer_14_ep9_tp0_sa_out
	layer_14_ep9_tp1_sa_qkv [label="Self-Attn QKV\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep9_tp1_sa_attn [label="Self-Attn Compute\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep9_tp1_sa_out [label="Self-Attn Output\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep9_tp1_sa_qkv -> layer_14_ep9_tp1_sa_attn
	layer_14_ep9_tp1_sa_attn -> layer_14_ep9_tp1_sa_out
	layer_14_ep9_tp2_sa_qkv [label="Self-Attn QKV\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep9_tp2_sa_attn [label="Self-Attn Compute\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep9_tp2_sa_out [label="Self-Attn Output\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep9_tp2_sa_qkv -> layer_14_ep9_tp2_sa_attn
	layer_14_ep9_tp2_sa_attn -> layer_14_ep9_tp2_sa_out
	layer_14_ep9_tp3_sa_qkv [label="Self-Attn QKV\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep9_tp3_sa_attn [label="Self-Attn Compute\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep9_tp3_sa_out [label="Self-Attn Output\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep9_tp3_sa_qkv -> layer_14_ep9_tp3_sa_attn
	layer_14_ep9_tp3_sa_attn -> layer_14_ep9_tp3_sa_out
	layer_14_ep10_tp0_sa_qkv [label="Self-Attn QKV\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep10_tp0_sa_attn [label="Self-Attn Compute\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep10_tp0_sa_out [label="Self-Attn Output\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep10_tp0_sa_qkv -> layer_14_ep10_tp0_sa_attn
	layer_14_ep10_tp0_sa_attn -> layer_14_ep10_tp0_sa_out
	layer_14_ep10_tp1_sa_qkv [label="Self-Attn QKV\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep10_tp1_sa_attn [label="Self-Attn Compute\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep10_tp1_sa_out [label="Self-Attn Output\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep10_tp1_sa_qkv -> layer_14_ep10_tp1_sa_attn
	layer_14_ep10_tp1_sa_attn -> layer_14_ep10_tp1_sa_out
	layer_14_ep10_tp2_sa_qkv [label="Self-Attn QKV\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep10_tp2_sa_attn [label="Self-Attn Compute\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep10_tp2_sa_out [label="Self-Attn Output\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep10_tp2_sa_qkv -> layer_14_ep10_tp2_sa_attn
	layer_14_ep10_tp2_sa_attn -> layer_14_ep10_tp2_sa_out
	layer_14_ep10_tp3_sa_qkv [label="Self-Attn QKV\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep10_tp3_sa_attn [label="Self-Attn Compute\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep10_tp3_sa_out [label="Self-Attn Output\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep10_tp3_sa_qkv -> layer_14_ep10_tp3_sa_attn
	layer_14_ep10_tp3_sa_attn -> layer_14_ep10_tp3_sa_out
	layer_14_ep11_tp0_sa_qkv [label="Self-Attn QKV\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep11_tp0_sa_attn [label="Self-Attn Compute\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep11_tp0_sa_out [label="Self-Attn Output\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep11_tp0_sa_qkv -> layer_14_ep11_tp0_sa_attn
	layer_14_ep11_tp0_sa_attn -> layer_14_ep11_tp0_sa_out
	layer_14_ep11_tp1_sa_qkv [label="Self-Attn QKV\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep11_tp1_sa_attn [label="Self-Attn Compute\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep11_tp1_sa_out [label="Self-Attn Output\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep11_tp1_sa_qkv -> layer_14_ep11_tp1_sa_attn
	layer_14_ep11_tp1_sa_attn -> layer_14_ep11_tp1_sa_out
	layer_14_ep11_tp2_sa_qkv [label="Self-Attn QKV\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep11_tp2_sa_attn [label="Self-Attn Compute\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep11_tp2_sa_out [label="Self-Attn Output\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep11_tp2_sa_qkv -> layer_14_ep11_tp2_sa_attn
	layer_14_ep11_tp2_sa_attn -> layer_14_ep11_tp2_sa_out
	layer_14_ep11_tp3_sa_qkv [label="Self-Attn QKV\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep11_tp3_sa_attn [label="Self-Attn Compute\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep11_tp3_sa_out [label="Self-Attn Output\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep11_tp3_sa_qkv -> layer_14_ep11_tp3_sa_attn
	layer_14_ep11_tp3_sa_attn -> layer_14_ep11_tp3_sa_out
	layer_14_ep12_tp0_sa_qkv [label="Self-Attn QKV\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep12_tp0_sa_attn [label="Self-Attn Compute\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep12_tp0_sa_out [label="Self-Attn Output\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep12_tp0_sa_qkv -> layer_14_ep12_tp0_sa_attn
	layer_14_ep12_tp0_sa_attn -> layer_14_ep12_tp0_sa_out
	layer_14_ep12_tp1_sa_qkv [label="Self-Attn QKV\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep12_tp1_sa_attn [label="Self-Attn Compute\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep12_tp1_sa_out [label="Self-Attn Output\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep12_tp1_sa_qkv -> layer_14_ep12_tp1_sa_attn
	layer_14_ep12_tp1_sa_attn -> layer_14_ep12_tp1_sa_out
	layer_14_ep12_tp2_sa_qkv [label="Self-Attn QKV\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep12_tp2_sa_attn [label="Self-Attn Compute\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep12_tp2_sa_out [label="Self-Attn Output\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep12_tp2_sa_qkv -> layer_14_ep12_tp2_sa_attn
	layer_14_ep12_tp2_sa_attn -> layer_14_ep12_tp2_sa_out
	layer_14_ep12_tp3_sa_qkv [label="Self-Attn QKV\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep12_tp3_sa_attn [label="Self-Attn Compute\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep12_tp3_sa_out [label="Self-Attn Output\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep12_tp3_sa_qkv -> layer_14_ep12_tp3_sa_attn
	layer_14_ep12_tp3_sa_attn -> layer_14_ep12_tp3_sa_out
	layer_14_ep13_tp0_sa_qkv [label="Self-Attn QKV\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep13_tp0_sa_attn [label="Self-Attn Compute\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep13_tp0_sa_out [label="Self-Attn Output\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep13_tp0_sa_qkv -> layer_14_ep13_tp0_sa_attn
	layer_14_ep13_tp0_sa_attn -> layer_14_ep13_tp0_sa_out
	layer_14_ep13_tp1_sa_qkv [label="Self-Attn QKV\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep13_tp1_sa_attn [label="Self-Attn Compute\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep13_tp1_sa_out [label="Self-Attn Output\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep13_tp1_sa_qkv -> layer_14_ep13_tp1_sa_attn
	layer_14_ep13_tp1_sa_attn -> layer_14_ep13_tp1_sa_out
	layer_14_ep13_tp2_sa_qkv [label="Self-Attn QKV\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep13_tp2_sa_attn [label="Self-Attn Compute\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep13_tp2_sa_out [label="Self-Attn Output\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep13_tp2_sa_qkv -> layer_14_ep13_tp2_sa_attn
	layer_14_ep13_tp2_sa_attn -> layer_14_ep13_tp2_sa_out
	layer_14_ep13_tp3_sa_qkv [label="Self-Attn QKV\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep13_tp3_sa_attn [label="Self-Attn Compute\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep13_tp3_sa_out [label="Self-Attn Output\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep13_tp3_sa_qkv -> layer_14_ep13_tp3_sa_attn
	layer_14_ep13_tp3_sa_attn -> layer_14_ep13_tp3_sa_out
	layer_14_ep14_tp0_sa_qkv [label="Self-Attn QKV\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep14_tp0_sa_attn [label="Self-Attn Compute\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep14_tp0_sa_out [label="Self-Attn Output\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep14_tp0_sa_qkv -> layer_14_ep14_tp0_sa_attn
	layer_14_ep14_tp0_sa_attn -> layer_14_ep14_tp0_sa_out
	layer_14_ep14_tp1_sa_qkv [label="Self-Attn QKV\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep14_tp1_sa_attn [label="Self-Attn Compute\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep14_tp1_sa_out [label="Self-Attn Output\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep14_tp1_sa_qkv -> layer_14_ep14_tp1_sa_attn
	layer_14_ep14_tp1_sa_attn -> layer_14_ep14_tp1_sa_out
	layer_14_ep14_tp2_sa_qkv [label="Self-Attn QKV\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep14_tp2_sa_attn [label="Self-Attn Compute\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep14_tp2_sa_out [label="Self-Attn Output\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep14_tp2_sa_qkv -> layer_14_ep14_tp2_sa_attn
	layer_14_ep14_tp2_sa_attn -> layer_14_ep14_tp2_sa_out
	layer_14_ep14_tp3_sa_qkv [label="Self-Attn QKV\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep14_tp3_sa_attn [label="Self-Attn Compute\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep14_tp3_sa_out [label="Self-Attn Output\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep14_tp3_sa_qkv -> layer_14_ep14_tp3_sa_attn
	layer_14_ep14_tp3_sa_attn -> layer_14_ep14_tp3_sa_out
	layer_14_ep15_tp0_sa_qkv [label="Self-Attn QKV\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep15_tp0_sa_attn [label="Self-Attn Compute\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep15_tp0_sa_out [label="Self-Attn Output\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep15_tp0_sa_qkv -> layer_14_ep15_tp0_sa_attn
	layer_14_ep15_tp0_sa_attn -> layer_14_ep15_tp0_sa_out
	layer_14_ep15_tp1_sa_qkv [label="Self-Attn QKV\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep15_tp1_sa_attn [label="Self-Attn Compute\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep15_tp1_sa_out [label="Self-Attn Output\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep15_tp1_sa_qkv -> layer_14_ep15_tp1_sa_attn
	layer_14_ep15_tp1_sa_attn -> layer_14_ep15_tp1_sa_out
	layer_14_ep15_tp2_sa_qkv [label="Self-Attn QKV\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep15_tp2_sa_attn [label="Self-Attn Compute\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep15_tp2_sa_out [label="Self-Attn Output\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep15_tp2_sa_qkv -> layer_14_ep15_tp2_sa_attn
	layer_14_ep15_tp2_sa_attn -> layer_14_ep15_tp2_sa_out
	layer_14_ep15_tp3_sa_qkv [label="Self-Attn QKV\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep15_tp3_sa_attn [label="Self-Attn Compute\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep15_tp3_sa_out [label="Self-Attn Output\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep15_tp3_sa_qkv -> layer_14_ep15_tp3_sa_attn
	layer_14_ep15_tp3_sa_attn -> layer_14_ep15_tp3_sa_out
	layer_14_ep0_tp_allreduce [label="TP All-Reduce\nEP-Group-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_14_ep0_tp0_sa_out -> layer_14_ep0_tp_allreduce
	layer_14_ep0_tp1_sa_out -> layer_14_ep0_tp_allreduce
	layer_14_ep0_tp2_sa_out -> layer_14_ep0_tp_allreduce
	layer_14_ep0_tp3_sa_out -> layer_14_ep0_tp_allreduce
	layer_14_ep1_tp_allreduce [label="TP All-Reduce\nEP-Group-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_14_ep1_tp0_sa_out -> layer_14_ep1_tp_allreduce
	layer_14_ep1_tp1_sa_out -> layer_14_ep1_tp_allreduce
	layer_14_ep1_tp2_sa_out -> layer_14_ep1_tp_allreduce
	layer_14_ep1_tp3_sa_out -> layer_14_ep1_tp_allreduce
	layer_14_ep2_tp_allreduce [label="TP All-Reduce\nEP-Group-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_14_ep2_tp0_sa_out -> layer_14_ep2_tp_allreduce
	layer_14_ep2_tp1_sa_out -> layer_14_ep2_tp_allreduce
	layer_14_ep2_tp2_sa_out -> layer_14_ep2_tp_allreduce
	layer_14_ep2_tp3_sa_out -> layer_14_ep2_tp_allreduce
	layer_14_ep3_tp_allreduce [label="TP All-Reduce\nEP-Group-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_14_ep3_tp0_sa_out -> layer_14_ep3_tp_allreduce
	layer_14_ep3_tp1_sa_out -> layer_14_ep3_tp_allreduce
	layer_14_ep3_tp2_sa_out -> layer_14_ep3_tp_allreduce
	layer_14_ep3_tp3_sa_out -> layer_14_ep3_tp_allreduce
	layer_14_ep4_tp_allreduce [label="TP All-Reduce\nEP-Group-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_14_ep4_tp0_sa_out -> layer_14_ep4_tp_allreduce
	layer_14_ep4_tp1_sa_out -> layer_14_ep4_tp_allreduce
	layer_14_ep4_tp2_sa_out -> layer_14_ep4_tp_allreduce
	layer_14_ep4_tp3_sa_out -> layer_14_ep4_tp_allreduce
	layer_14_ep5_tp_allreduce [label="TP All-Reduce\nEP-Group-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_14_ep5_tp0_sa_out -> layer_14_ep5_tp_allreduce
	layer_14_ep5_tp1_sa_out -> layer_14_ep5_tp_allreduce
	layer_14_ep5_tp2_sa_out -> layer_14_ep5_tp_allreduce
	layer_14_ep5_tp3_sa_out -> layer_14_ep5_tp_allreduce
	layer_14_ep6_tp_allreduce [label="TP All-Reduce\nEP-Group-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_14_ep6_tp0_sa_out -> layer_14_ep6_tp_allreduce
	layer_14_ep6_tp1_sa_out -> layer_14_ep6_tp_allreduce
	layer_14_ep6_tp2_sa_out -> layer_14_ep6_tp_allreduce
	layer_14_ep6_tp3_sa_out -> layer_14_ep6_tp_allreduce
	layer_14_ep7_tp_allreduce [label="TP All-Reduce\nEP-Group-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_14_ep7_tp0_sa_out -> layer_14_ep7_tp_allreduce
	layer_14_ep7_tp1_sa_out -> layer_14_ep7_tp_allreduce
	layer_14_ep7_tp2_sa_out -> layer_14_ep7_tp_allreduce
	layer_14_ep7_tp3_sa_out -> layer_14_ep7_tp_allreduce
	layer_14_ep8_tp_allreduce [label="TP All-Reduce\nEP-Group-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_14_ep8_tp0_sa_out -> layer_14_ep8_tp_allreduce
	layer_14_ep8_tp1_sa_out -> layer_14_ep8_tp_allreduce
	layer_14_ep8_tp2_sa_out -> layer_14_ep8_tp_allreduce
	layer_14_ep8_tp3_sa_out -> layer_14_ep8_tp_allreduce
	layer_14_ep9_tp_allreduce [label="TP All-Reduce\nEP-Group-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_14_ep9_tp0_sa_out -> layer_14_ep9_tp_allreduce
	layer_14_ep9_tp1_sa_out -> layer_14_ep9_tp_allreduce
	layer_14_ep9_tp2_sa_out -> layer_14_ep9_tp_allreduce
	layer_14_ep9_tp3_sa_out -> layer_14_ep9_tp_allreduce
	layer_14_ep10_tp_allreduce [label="TP All-Reduce\nEP-Group-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_14_ep10_tp0_sa_out -> layer_14_ep10_tp_allreduce
	layer_14_ep10_tp1_sa_out -> layer_14_ep10_tp_allreduce
	layer_14_ep10_tp2_sa_out -> layer_14_ep10_tp_allreduce
	layer_14_ep10_tp3_sa_out -> layer_14_ep10_tp_allreduce
	layer_14_ep11_tp_allreduce [label="TP All-Reduce\nEP-Group-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_14_ep11_tp0_sa_out -> layer_14_ep11_tp_allreduce
	layer_14_ep11_tp1_sa_out -> layer_14_ep11_tp_allreduce
	layer_14_ep11_tp2_sa_out -> layer_14_ep11_tp_allreduce
	layer_14_ep11_tp3_sa_out -> layer_14_ep11_tp_allreduce
	layer_14_ep12_tp_allreduce [label="TP All-Reduce\nEP-Group-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_14_ep12_tp0_sa_out -> layer_14_ep12_tp_allreduce
	layer_14_ep12_tp1_sa_out -> layer_14_ep12_tp_allreduce
	layer_14_ep12_tp2_sa_out -> layer_14_ep12_tp_allreduce
	layer_14_ep12_tp3_sa_out -> layer_14_ep12_tp_allreduce
	layer_14_ep13_tp_allreduce [label="TP All-Reduce\nEP-Group-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_14_ep13_tp0_sa_out -> layer_14_ep13_tp_allreduce
	layer_14_ep13_tp1_sa_out -> layer_14_ep13_tp_allreduce
	layer_14_ep13_tp2_sa_out -> layer_14_ep13_tp_allreduce
	layer_14_ep13_tp3_sa_out -> layer_14_ep13_tp_allreduce
	layer_14_ep14_tp_allreduce [label="TP All-Reduce\nEP-Group-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_14_ep14_tp0_sa_out -> layer_14_ep14_tp_allreduce
	layer_14_ep14_tp1_sa_out -> layer_14_ep14_tp_allreduce
	layer_14_ep14_tp2_sa_out -> layer_14_ep14_tp_allreduce
	layer_14_ep14_tp3_sa_out -> layer_14_ep14_tp_allreduce
	layer_14_ep15_tp_allreduce [label="TP All-Reduce\nEP-Group-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_14_ep15_tp0_sa_out -> layer_14_ep15_tp_allreduce
	layer_14_ep15_tp1_sa_out -> layer_14_ep15_tp_allreduce
	layer_14_ep15_tp2_sa_out -> layer_14_ep15_tp_allreduce
	layer_14_ep15_tp3_sa_out -> layer_14_ep15_tp_allreduce
	layer_14_ep0_gate [label="MoE Gate\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_14_ep0_expert_0 [label="Expert-0\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep0_gate -> layer_14_ep0_expert_0 [label="select tokens" style=dashed]
	layer_14_ep0_expert_1 [label="Expert-1\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep0_gate -> layer_14_ep0_expert_1 [label="select tokens" style=dashed]
	layer_14_ep0_expert_2 [label="Expert-2\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep0_gate -> layer_14_ep0_expert_2 [label="select tokens" style=dashed]
	layer_14_ep0_expert_3 [label="Expert-3\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep0_gate -> layer_14_ep0_expert_3 [label="select tokens" style=dashed]
	layer_14_ep0_expert_aggr [label="Expert Aggregation\nEP-Group-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_14_ep0_expert_0 -> layer_14_ep0_expert_aggr
	layer_14_ep0_expert_1 -> layer_14_ep0_expert_aggr
	layer_14_ep0_expert_2 -> layer_14_ep0_expert_aggr
	layer_14_ep0_expert_3 -> layer_14_ep0_expert_aggr
	layer_14_ep1_gate [label="MoE Gate\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_14_ep1_expert_0 [label="Expert-0\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep1_gate -> layer_14_ep1_expert_0 [label="select tokens" style=dashed]
	layer_14_ep1_expert_1 [label="Expert-1\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep1_gate -> layer_14_ep1_expert_1 [label="select tokens" style=dashed]
	layer_14_ep1_expert_2 [label="Expert-2\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep1_gate -> layer_14_ep1_expert_2 [label="select tokens" style=dashed]
	layer_14_ep1_expert_3 [label="Expert-3\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep1_gate -> layer_14_ep1_expert_3 [label="select tokens" style=dashed]
	layer_14_ep1_expert_aggr [label="Expert Aggregation\nEP-Group-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_14_ep1_expert_0 -> layer_14_ep1_expert_aggr
	layer_14_ep1_expert_1 -> layer_14_ep1_expert_aggr
	layer_14_ep1_expert_2 -> layer_14_ep1_expert_aggr
	layer_14_ep1_expert_3 -> layer_14_ep1_expert_aggr
	layer_14_ep2_gate [label="MoE Gate\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_14_ep2_expert_0 [label="Expert-0\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep2_gate -> layer_14_ep2_expert_0 [label="select tokens" style=dashed]
	layer_14_ep2_expert_1 [label="Expert-1\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep2_gate -> layer_14_ep2_expert_1 [label="select tokens" style=dashed]
	layer_14_ep2_expert_2 [label="Expert-2\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep2_gate -> layer_14_ep2_expert_2 [label="select tokens" style=dashed]
	layer_14_ep2_expert_3 [label="Expert-3\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep2_gate -> layer_14_ep2_expert_3 [label="select tokens" style=dashed]
	layer_14_ep2_expert_aggr [label="Expert Aggregation\nEP-Group-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_14_ep2_expert_0 -> layer_14_ep2_expert_aggr
	layer_14_ep2_expert_1 -> layer_14_ep2_expert_aggr
	layer_14_ep2_expert_2 -> layer_14_ep2_expert_aggr
	layer_14_ep2_expert_3 -> layer_14_ep2_expert_aggr
	layer_14_ep3_gate [label="MoE Gate\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_14_ep3_expert_0 [label="Expert-0\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep3_gate -> layer_14_ep3_expert_0 [label="select tokens" style=dashed]
	layer_14_ep3_expert_1 [label="Expert-1\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep3_gate -> layer_14_ep3_expert_1 [label="select tokens" style=dashed]
	layer_14_ep3_expert_2 [label="Expert-2\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep3_gate -> layer_14_ep3_expert_2 [label="select tokens" style=dashed]
	layer_14_ep3_expert_3 [label="Expert-3\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep3_gate -> layer_14_ep3_expert_3 [label="select tokens" style=dashed]
	layer_14_ep3_expert_aggr [label="Expert Aggregation\nEP-Group-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_14_ep3_expert_0 -> layer_14_ep3_expert_aggr
	layer_14_ep3_expert_1 -> layer_14_ep3_expert_aggr
	layer_14_ep3_expert_2 -> layer_14_ep3_expert_aggr
	layer_14_ep3_expert_3 -> layer_14_ep3_expert_aggr
	layer_14_ep4_gate [label="MoE Gate\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_14_ep4_expert_0 [label="Expert-0\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep4_gate -> layer_14_ep4_expert_0 [label="select tokens" style=dashed]
	layer_14_ep4_expert_1 [label="Expert-1\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep4_gate -> layer_14_ep4_expert_1 [label="select tokens" style=dashed]
	layer_14_ep4_expert_2 [label="Expert-2\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep4_gate -> layer_14_ep4_expert_2 [label="select tokens" style=dashed]
	layer_14_ep4_expert_3 [label="Expert-3\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep4_gate -> layer_14_ep4_expert_3 [label="select tokens" style=dashed]
	layer_14_ep4_expert_aggr [label="Expert Aggregation\nEP-Group-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_14_ep4_expert_0 -> layer_14_ep4_expert_aggr
	layer_14_ep4_expert_1 -> layer_14_ep4_expert_aggr
	layer_14_ep4_expert_2 -> layer_14_ep4_expert_aggr
	layer_14_ep4_expert_3 -> layer_14_ep4_expert_aggr
	layer_14_ep5_gate [label="MoE Gate\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_14_ep5_expert_0 [label="Expert-0\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep5_gate -> layer_14_ep5_expert_0 [label="select tokens" style=dashed]
	layer_14_ep5_expert_1 [label="Expert-1\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep5_gate -> layer_14_ep5_expert_1 [label="select tokens" style=dashed]
	layer_14_ep5_expert_2 [label="Expert-2\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep5_gate -> layer_14_ep5_expert_2 [label="select tokens" style=dashed]
	layer_14_ep5_expert_3 [label="Expert-3\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep5_gate -> layer_14_ep5_expert_3 [label="select tokens" style=dashed]
	layer_14_ep5_expert_aggr [label="Expert Aggregation\nEP-Group-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_14_ep5_expert_0 -> layer_14_ep5_expert_aggr
	layer_14_ep5_expert_1 -> layer_14_ep5_expert_aggr
	layer_14_ep5_expert_2 -> layer_14_ep5_expert_aggr
	layer_14_ep5_expert_3 -> layer_14_ep5_expert_aggr
	layer_14_ep6_gate [label="MoE Gate\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_14_ep6_expert_0 [label="Expert-0\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep6_gate -> layer_14_ep6_expert_0 [label="select tokens" style=dashed]
	layer_14_ep6_expert_1 [label="Expert-1\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep6_gate -> layer_14_ep6_expert_1 [label="select tokens" style=dashed]
	layer_14_ep6_expert_2 [label="Expert-2\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep6_gate -> layer_14_ep6_expert_2 [label="select tokens" style=dashed]
	layer_14_ep6_expert_3 [label="Expert-3\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep6_gate -> layer_14_ep6_expert_3 [label="select tokens" style=dashed]
	layer_14_ep6_expert_aggr [label="Expert Aggregation\nEP-Group-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_14_ep6_expert_0 -> layer_14_ep6_expert_aggr
	layer_14_ep6_expert_1 -> layer_14_ep6_expert_aggr
	layer_14_ep6_expert_2 -> layer_14_ep6_expert_aggr
	layer_14_ep6_expert_3 -> layer_14_ep6_expert_aggr
	layer_14_ep7_gate [label="MoE Gate\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_14_ep7_expert_0 [label="Expert-0\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep7_gate -> layer_14_ep7_expert_0 [label="select tokens" style=dashed]
	layer_14_ep7_expert_1 [label="Expert-1\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep7_gate -> layer_14_ep7_expert_1 [label="select tokens" style=dashed]
	layer_14_ep7_expert_2 [label="Expert-2\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep7_gate -> layer_14_ep7_expert_2 [label="select tokens" style=dashed]
	layer_14_ep7_expert_3 [label="Expert-3\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep7_gate -> layer_14_ep7_expert_3 [label="select tokens" style=dashed]
	layer_14_ep7_expert_aggr [label="Expert Aggregation\nEP-Group-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_14_ep7_expert_0 -> layer_14_ep7_expert_aggr
	layer_14_ep7_expert_1 -> layer_14_ep7_expert_aggr
	layer_14_ep7_expert_2 -> layer_14_ep7_expert_aggr
	layer_14_ep7_expert_3 -> layer_14_ep7_expert_aggr
	layer_14_ep8_gate [label="MoE Gate\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_14_ep8_expert_0 [label="Expert-0\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep8_gate -> layer_14_ep8_expert_0 [label="select tokens" style=dashed]
	layer_14_ep8_expert_1 [label="Expert-1\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep8_gate -> layer_14_ep8_expert_1 [label="select tokens" style=dashed]
	layer_14_ep8_expert_2 [label="Expert-2\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep8_gate -> layer_14_ep8_expert_2 [label="select tokens" style=dashed]
	layer_14_ep8_expert_3 [label="Expert-3\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep8_gate -> layer_14_ep8_expert_3 [label="select tokens" style=dashed]
	layer_14_ep8_expert_aggr [label="Expert Aggregation\nEP-Group-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_14_ep8_expert_0 -> layer_14_ep8_expert_aggr
	layer_14_ep8_expert_1 -> layer_14_ep8_expert_aggr
	layer_14_ep8_expert_2 -> layer_14_ep8_expert_aggr
	layer_14_ep8_expert_3 -> layer_14_ep8_expert_aggr
	layer_14_ep9_gate [label="MoE Gate\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_14_ep9_expert_0 [label="Expert-0\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep9_gate -> layer_14_ep9_expert_0 [label="select tokens" style=dashed]
	layer_14_ep9_expert_1 [label="Expert-1\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep9_gate -> layer_14_ep9_expert_1 [label="select tokens" style=dashed]
	layer_14_ep9_expert_2 [label="Expert-2\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep9_gate -> layer_14_ep9_expert_2 [label="select tokens" style=dashed]
	layer_14_ep9_expert_3 [label="Expert-3\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep9_gate -> layer_14_ep9_expert_3 [label="select tokens" style=dashed]
	layer_14_ep9_expert_aggr [label="Expert Aggregation\nEP-Group-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_14_ep9_expert_0 -> layer_14_ep9_expert_aggr
	layer_14_ep9_expert_1 -> layer_14_ep9_expert_aggr
	layer_14_ep9_expert_2 -> layer_14_ep9_expert_aggr
	layer_14_ep9_expert_3 -> layer_14_ep9_expert_aggr
	layer_14_ep10_gate [label="MoE Gate\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_14_ep10_expert_0 [label="Expert-0\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep10_gate -> layer_14_ep10_expert_0 [label="select tokens" style=dashed]
	layer_14_ep10_expert_1 [label="Expert-1\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep10_gate -> layer_14_ep10_expert_1 [label="select tokens" style=dashed]
	layer_14_ep10_expert_2 [label="Expert-2\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep10_gate -> layer_14_ep10_expert_2 [label="select tokens" style=dashed]
	layer_14_ep10_expert_3 [label="Expert-3\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep10_gate -> layer_14_ep10_expert_3 [label="select tokens" style=dashed]
	layer_14_ep10_expert_aggr [label="Expert Aggregation\nEP-Group-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_14_ep10_expert_0 -> layer_14_ep10_expert_aggr
	layer_14_ep10_expert_1 -> layer_14_ep10_expert_aggr
	layer_14_ep10_expert_2 -> layer_14_ep10_expert_aggr
	layer_14_ep10_expert_3 -> layer_14_ep10_expert_aggr
	layer_14_ep11_gate [label="MoE Gate\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_14_ep11_expert_0 [label="Expert-0\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep11_gate -> layer_14_ep11_expert_0 [label="select tokens" style=dashed]
	layer_14_ep11_expert_1 [label="Expert-1\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep11_gate -> layer_14_ep11_expert_1 [label="select tokens" style=dashed]
	layer_14_ep11_expert_2 [label="Expert-2\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep11_gate -> layer_14_ep11_expert_2 [label="select tokens" style=dashed]
	layer_14_ep11_expert_3 [label="Expert-3\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep11_gate -> layer_14_ep11_expert_3 [label="select tokens" style=dashed]
	layer_14_ep11_expert_aggr [label="Expert Aggregation\nEP-Group-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_14_ep11_expert_0 -> layer_14_ep11_expert_aggr
	layer_14_ep11_expert_1 -> layer_14_ep11_expert_aggr
	layer_14_ep11_expert_2 -> layer_14_ep11_expert_aggr
	layer_14_ep11_expert_3 -> layer_14_ep11_expert_aggr
	layer_14_ep12_gate [label="MoE Gate\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_14_ep12_expert_0 [label="Expert-0\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep12_gate -> layer_14_ep12_expert_0 [label="select tokens" style=dashed]
	layer_14_ep12_expert_1 [label="Expert-1\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep12_gate -> layer_14_ep12_expert_1 [label="select tokens" style=dashed]
	layer_14_ep12_expert_2 [label="Expert-2\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep12_gate -> layer_14_ep12_expert_2 [label="select tokens" style=dashed]
	layer_14_ep12_expert_3 [label="Expert-3\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep12_gate -> layer_14_ep12_expert_3 [label="select tokens" style=dashed]
	layer_14_ep12_expert_aggr [label="Expert Aggregation\nEP-Group-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_14_ep12_expert_0 -> layer_14_ep12_expert_aggr
	layer_14_ep12_expert_1 -> layer_14_ep12_expert_aggr
	layer_14_ep12_expert_2 -> layer_14_ep12_expert_aggr
	layer_14_ep12_expert_3 -> layer_14_ep12_expert_aggr
	layer_14_ep13_gate [label="MoE Gate\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_14_ep13_expert_0 [label="Expert-0\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep13_gate -> layer_14_ep13_expert_0 [label="select tokens" style=dashed]
	layer_14_ep13_expert_1 [label="Expert-1\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep13_gate -> layer_14_ep13_expert_1 [label="select tokens" style=dashed]
	layer_14_ep13_expert_2 [label="Expert-2\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep13_gate -> layer_14_ep13_expert_2 [label="select tokens" style=dashed]
	layer_14_ep13_expert_3 [label="Expert-3\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep13_gate -> layer_14_ep13_expert_3 [label="select tokens" style=dashed]
	layer_14_ep13_expert_aggr [label="Expert Aggregation\nEP-Group-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_14_ep13_expert_0 -> layer_14_ep13_expert_aggr
	layer_14_ep13_expert_1 -> layer_14_ep13_expert_aggr
	layer_14_ep13_expert_2 -> layer_14_ep13_expert_aggr
	layer_14_ep13_expert_3 -> layer_14_ep13_expert_aggr
	layer_14_ep14_gate [label="MoE Gate\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_14_ep14_expert_0 [label="Expert-0\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep14_gate -> layer_14_ep14_expert_0 [label="select tokens" style=dashed]
	layer_14_ep14_expert_1 [label="Expert-1\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep14_gate -> layer_14_ep14_expert_1 [label="select tokens" style=dashed]
	layer_14_ep14_expert_2 [label="Expert-2\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep14_gate -> layer_14_ep14_expert_2 [label="select tokens" style=dashed]
	layer_14_ep14_expert_3 [label="Expert-3\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep14_gate -> layer_14_ep14_expert_3 [label="select tokens" style=dashed]
	layer_14_ep14_expert_aggr [label="Expert Aggregation\nEP-Group-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_14_ep14_expert_0 -> layer_14_ep14_expert_aggr
	layer_14_ep14_expert_1 -> layer_14_ep14_expert_aggr
	layer_14_ep14_expert_2 -> layer_14_ep14_expert_aggr
	layer_14_ep14_expert_3 -> layer_14_ep14_expert_aggr
	layer_14_ep15_gate [label="MoE Gate\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_14_ep15_expert_0 [label="Expert-0\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep15_gate -> layer_14_ep15_expert_0 [label="select tokens" style=dashed]
	layer_14_ep15_expert_1 [label="Expert-1\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep15_gate -> layer_14_ep15_expert_1 [label="select tokens" style=dashed]
	layer_14_ep15_expert_2 [label="Expert-2\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep15_gate -> layer_14_ep15_expert_2 [label="select tokens" style=dashed]
	layer_14_ep15_expert_3 [label="Expert-3\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_14_ep15_gate -> layer_14_ep15_expert_3 [label="select tokens" style=dashed]
	layer_14_ep15_expert_aggr [label="Expert Aggregation\nEP-Group-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_14_ep15_expert_0 -> layer_14_ep15_expert_aggr
	layer_14_ep15_expert_1 -> layer_14_ep15_expert_aggr
	layer_14_ep15_expert_2 -> layer_14_ep15_expert_aggr
	layer_14_ep15_expert_3 -> layer_14_ep15_expert_aggr
	layer_14_to_15_ep0_pp [label="Pipeline Stage Transfer\nEP-Group-0\nLayer-14 to Layer-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_14_ep0_expert_aggr -> layer_14_to_15_ep0_pp
	layer_14_to_15_ep1_pp [label="Pipeline Stage Transfer\nEP-Group-1\nLayer-14 to Layer-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_14_ep1_expert_aggr -> layer_14_to_15_ep1_pp
	layer_14_to_15_ep2_pp [label="Pipeline Stage Transfer\nEP-Group-2\nLayer-14 to Layer-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_14_ep2_expert_aggr -> layer_14_to_15_ep2_pp
	layer_14_to_15_ep3_pp [label="Pipeline Stage Transfer\nEP-Group-3\nLayer-14 to Layer-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_14_ep3_expert_aggr -> layer_14_to_15_ep3_pp
	layer_14_to_15_ep4_pp [label="Pipeline Stage Transfer\nEP-Group-4\nLayer-14 to Layer-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_14_ep4_expert_aggr -> layer_14_to_15_ep4_pp
	layer_14_to_15_ep5_pp [label="Pipeline Stage Transfer\nEP-Group-5\nLayer-14 to Layer-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_14_ep5_expert_aggr -> layer_14_to_15_ep5_pp
	layer_14_to_15_ep6_pp [label="Pipeline Stage Transfer\nEP-Group-6\nLayer-14 to Layer-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_14_ep6_expert_aggr -> layer_14_to_15_ep6_pp
	layer_14_to_15_ep7_pp [label="Pipeline Stage Transfer\nEP-Group-7\nLayer-14 to Layer-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_14_ep7_expert_aggr -> layer_14_to_15_ep7_pp
	layer_14_to_15_ep8_pp [label="Pipeline Stage Transfer\nEP-Group-8\nLayer-14 to Layer-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_14_ep8_expert_aggr -> layer_14_to_15_ep8_pp
	layer_14_to_15_ep9_pp [label="Pipeline Stage Transfer\nEP-Group-9\nLayer-14 to Layer-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_14_ep9_expert_aggr -> layer_14_to_15_ep9_pp
	layer_14_to_15_ep10_pp [label="Pipeline Stage Transfer\nEP-Group-10\nLayer-14 to Layer-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_14_ep10_expert_aggr -> layer_14_to_15_ep10_pp
	layer_14_to_15_ep11_pp [label="Pipeline Stage Transfer\nEP-Group-11\nLayer-14 to Layer-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_14_ep11_expert_aggr -> layer_14_to_15_ep11_pp
	layer_14_to_15_ep12_pp [label="Pipeline Stage Transfer\nEP-Group-12\nLayer-14 to Layer-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_14_ep12_expert_aggr -> layer_14_to_15_ep12_pp
	layer_14_to_15_ep13_pp [label="Pipeline Stage Transfer\nEP-Group-13\nLayer-14 to Layer-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_14_ep13_expert_aggr -> layer_14_to_15_ep13_pp
	layer_14_to_15_ep14_pp [label="Pipeline Stage Transfer\nEP-Group-14\nLayer-14 to Layer-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_14_ep14_expert_aggr -> layer_14_to_15_ep14_pp
	layer_14_to_15_ep15_pp [label="Pipeline Stage Transfer\nEP-Group-15\nLayer-14 to Layer-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_14_ep15_expert_aggr -> layer_14_to_15_ep15_pp
	layer_15_ep0_tp0_sa_qkv [label="Self-Attn QKV\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep0_tp0_sa_attn [label="Self-Attn Compute\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep0_tp0_sa_out [label="Self-Attn Output\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep0_tp0_sa_qkv -> layer_15_ep0_tp0_sa_attn
	layer_15_ep0_tp0_sa_attn -> layer_15_ep0_tp0_sa_out
	layer_15_ep0_tp1_sa_qkv [label="Self-Attn QKV\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep0_tp1_sa_attn [label="Self-Attn Compute\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep0_tp1_sa_out [label="Self-Attn Output\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep0_tp1_sa_qkv -> layer_15_ep0_tp1_sa_attn
	layer_15_ep0_tp1_sa_attn -> layer_15_ep0_tp1_sa_out
	layer_15_ep0_tp2_sa_qkv [label="Self-Attn QKV\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep0_tp2_sa_attn [label="Self-Attn Compute\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep0_tp2_sa_out [label="Self-Attn Output\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep0_tp2_sa_qkv -> layer_15_ep0_tp2_sa_attn
	layer_15_ep0_tp2_sa_attn -> layer_15_ep0_tp2_sa_out
	layer_15_ep0_tp3_sa_qkv [label="Self-Attn QKV\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep0_tp3_sa_attn [label="Self-Attn Compute\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep0_tp3_sa_out [label="Self-Attn Output\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep0_tp3_sa_qkv -> layer_15_ep0_tp3_sa_attn
	layer_15_ep0_tp3_sa_attn -> layer_15_ep0_tp3_sa_out
	layer_15_ep1_tp0_sa_qkv [label="Self-Attn QKV\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep1_tp0_sa_attn [label="Self-Attn Compute\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep1_tp0_sa_out [label="Self-Attn Output\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep1_tp0_sa_qkv -> layer_15_ep1_tp0_sa_attn
	layer_15_ep1_tp0_sa_attn -> layer_15_ep1_tp0_sa_out
	layer_15_ep1_tp1_sa_qkv [label="Self-Attn QKV\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep1_tp1_sa_attn [label="Self-Attn Compute\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep1_tp1_sa_out [label="Self-Attn Output\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep1_tp1_sa_qkv -> layer_15_ep1_tp1_sa_attn
	layer_15_ep1_tp1_sa_attn -> layer_15_ep1_tp1_sa_out
	layer_15_ep1_tp2_sa_qkv [label="Self-Attn QKV\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep1_tp2_sa_attn [label="Self-Attn Compute\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep1_tp2_sa_out [label="Self-Attn Output\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep1_tp2_sa_qkv -> layer_15_ep1_tp2_sa_attn
	layer_15_ep1_tp2_sa_attn -> layer_15_ep1_tp2_sa_out
	layer_15_ep1_tp3_sa_qkv [label="Self-Attn QKV\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep1_tp3_sa_attn [label="Self-Attn Compute\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep1_tp3_sa_out [label="Self-Attn Output\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep1_tp3_sa_qkv -> layer_15_ep1_tp3_sa_attn
	layer_15_ep1_tp3_sa_attn -> layer_15_ep1_tp3_sa_out
	layer_15_ep2_tp0_sa_qkv [label="Self-Attn QKV\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep2_tp0_sa_attn [label="Self-Attn Compute\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep2_tp0_sa_out [label="Self-Attn Output\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep2_tp0_sa_qkv -> layer_15_ep2_tp0_sa_attn
	layer_15_ep2_tp0_sa_attn -> layer_15_ep2_tp0_sa_out
	layer_15_ep2_tp1_sa_qkv [label="Self-Attn QKV\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep2_tp1_sa_attn [label="Self-Attn Compute\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep2_tp1_sa_out [label="Self-Attn Output\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep2_tp1_sa_qkv -> layer_15_ep2_tp1_sa_attn
	layer_15_ep2_tp1_sa_attn -> layer_15_ep2_tp1_sa_out
	layer_15_ep2_tp2_sa_qkv [label="Self-Attn QKV\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep2_tp2_sa_attn [label="Self-Attn Compute\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep2_tp2_sa_out [label="Self-Attn Output\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep2_tp2_sa_qkv -> layer_15_ep2_tp2_sa_attn
	layer_15_ep2_tp2_sa_attn -> layer_15_ep2_tp2_sa_out
	layer_15_ep2_tp3_sa_qkv [label="Self-Attn QKV\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep2_tp3_sa_attn [label="Self-Attn Compute\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep2_tp3_sa_out [label="Self-Attn Output\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep2_tp3_sa_qkv -> layer_15_ep2_tp3_sa_attn
	layer_15_ep2_tp3_sa_attn -> layer_15_ep2_tp3_sa_out
	layer_15_ep3_tp0_sa_qkv [label="Self-Attn QKV\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep3_tp0_sa_attn [label="Self-Attn Compute\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep3_tp0_sa_out [label="Self-Attn Output\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep3_tp0_sa_qkv -> layer_15_ep3_tp0_sa_attn
	layer_15_ep3_tp0_sa_attn -> layer_15_ep3_tp0_sa_out
	layer_15_ep3_tp1_sa_qkv [label="Self-Attn QKV\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep3_tp1_sa_attn [label="Self-Attn Compute\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep3_tp1_sa_out [label="Self-Attn Output\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep3_tp1_sa_qkv -> layer_15_ep3_tp1_sa_attn
	layer_15_ep3_tp1_sa_attn -> layer_15_ep3_tp1_sa_out
	layer_15_ep3_tp2_sa_qkv [label="Self-Attn QKV\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep3_tp2_sa_attn [label="Self-Attn Compute\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep3_tp2_sa_out [label="Self-Attn Output\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep3_tp2_sa_qkv -> layer_15_ep3_tp2_sa_attn
	layer_15_ep3_tp2_sa_attn -> layer_15_ep3_tp2_sa_out
	layer_15_ep3_tp3_sa_qkv [label="Self-Attn QKV\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep3_tp3_sa_attn [label="Self-Attn Compute\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep3_tp3_sa_out [label="Self-Attn Output\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep3_tp3_sa_qkv -> layer_15_ep3_tp3_sa_attn
	layer_15_ep3_tp3_sa_attn -> layer_15_ep3_tp3_sa_out
	layer_15_ep4_tp0_sa_qkv [label="Self-Attn QKV\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep4_tp0_sa_attn [label="Self-Attn Compute\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep4_tp0_sa_out [label="Self-Attn Output\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep4_tp0_sa_qkv -> layer_15_ep4_tp0_sa_attn
	layer_15_ep4_tp0_sa_attn -> layer_15_ep4_tp0_sa_out
	layer_15_ep4_tp1_sa_qkv [label="Self-Attn QKV\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep4_tp1_sa_attn [label="Self-Attn Compute\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep4_tp1_sa_out [label="Self-Attn Output\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep4_tp1_sa_qkv -> layer_15_ep4_tp1_sa_attn
	layer_15_ep4_tp1_sa_attn -> layer_15_ep4_tp1_sa_out
	layer_15_ep4_tp2_sa_qkv [label="Self-Attn QKV\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep4_tp2_sa_attn [label="Self-Attn Compute\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep4_tp2_sa_out [label="Self-Attn Output\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep4_tp2_sa_qkv -> layer_15_ep4_tp2_sa_attn
	layer_15_ep4_tp2_sa_attn -> layer_15_ep4_tp2_sa_out
	layer_15_ep4_tp3_sa_qkv [label="Self-Attn QKV\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep4_tp3_sa_attn [label="Self-Attn Compute\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep4_tp3_sa_out [label="Self-Attn Output\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep4_tp3_sa_qkv -> layer_15_ep4_tp3_sa_attn
	layer_15_ep4_tp3_sa_attn -> layer_15_ep4_tp3_sa_out
	layer_15_ep5_tp0_sa_qkv [label="Self-Attn QKV\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep5_tp0_sa_attn [label="Self-Attn Compute\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep5_tp0_sa_out [label="Self-Attn Output\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep5_tp0_sa_qkv -> layer_15_ep5_tp0_sa_attn
	layer_15_ep5_tp0_sa_attn -> layer_15_ep5_tp0_sa_out
	layer_15_ep5_tp1_sa_qkv [label="Self-Attn QKV\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep5_tp1_sa_attn [label="Self-Attn Compute\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep5_tp1_sa_out [label="Self-Attn Output\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep5_tp1_sa_qkv -> layer_15_ep5_tp1_sa_attn
	layer_15_ep5_tp1_sa_attn -> layer_15_ep5_tp1_sa_out
	layer_15_ep5_tp2_sa_qkv [label="Self-Attn QKV\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep5_tp2_sa_attn [label="Self-Attn Compute\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep5_tp2_sa_out [label="Self-Attn Output\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep5_tp2_sa_qkv -> layer_15_ep5_tp2_sa_attn
	layer_15_ep5_tp2_sa_attn -> layer_15_ep5_tp2_sa_out
	layer_15_ep5_tp3_sa_qkv [label="Self-Attn QKV\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep5_tp3_sa_attn [label="Self-Attn Compute\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep5_tp3_sa_out [label="Self-Attn Output\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep5_tp3_sa_qkv -> layer_15_ep5_tp3_sa_attn
	layer_15_ep5_tp3_sa_attn -> layer_15_ep5_tp3_sa_out
	layer_15_ep6_tp0_sa_qkv [label="Self-Attn QKV\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep6_tp0_sa_attn [label="Self-Attn Compute\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep6_tp0_sa_out [label="Self-Attn Output\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep6_tp0_sa_qkv -> layer_15_ep6_tp0_sa_attn
	layer_15_ep6_tp0_sa_attn -> layer_15_ep6_tp0_sa_out
	layer_15_ep6_tp1_sa_qkv [label="Self-Attn QKV\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep6_tp1_sa_attn [label="Self-Attn Compute\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep6_tp1_sa_out [label="Self-Attn Output\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep6_tp1_sa_qkv -> layer_15_ep6_tp1_sa_attn
	layer_15_ep6_tp1_sa_attn -> layer_15_ep6_tp1_sa_out
	layer_15_ep6_tp2_sa_qkv [label="Self-Attn QKV\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep6_tp2_sa_attn [label="Self-Attn Compute\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep6_tp2_sa_out [label="Self-Attn Output\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep6_tp2_sa_qkv -> layer_15_ep6_tp2_sa_attn
	layer_15_ep6_tp2_sa_attn -> layer_15_ep6_tp2_sa_out
	layer_15_ep6_tp3_sa_qkv [label="Self-Attn QKV\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep6_tp3_sa_attn [label="Self-Attn Compute\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep6_tp3_sa_out [label="Self-Attn Output\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep6_tp3_sa_qkv -> layer_15_ep6_tp3_sa_attn
	layer_15_ep6_tp3_sa_attn -> layer_15_ep6_tp3_sa_out
	layer_15_ep7_tp0_sa_qkv [label="Self-Attn QKV\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep7_tp0_sa_attn [label="Self-Attn Compute\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep7_tp0_sa_out [label="Self-Attn Output\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep7_tp0_sa_qkv -> layer_15_ep7_tp0_sa_attn
	layer_15_ep7_tp0_sa_attn -> layer_15_ep7_tp0_sa_out
	layer_15_ep7_tp1_sa_qkv [label="Self-Attn QKV\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep7_tp1_sa_attn [label="Self-Attn Compute\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep7_tp1_sa_out [label="Self-Attn Output\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep7_tp1_sa_qkv -> layer_15_ep7_tp1_sa_attn
	layer_15_ep7_tp1_sa_attn -> layer_15_ep7_tp1_sa_out
	layer_15_ep7_tp2_sa_qkv [label="Self-Attn QKV\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep7_tp2_sa_attn [label="Self-Attn Compute\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep7_tp2_sa_out [label="Self-Attn Output\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep7_tp2_sa_qkv -> layer_15_ep7_tp2_sa_attn
	layer_15_ep7_tp2_sa_attn -> layer_15_ep7_tp2_sa_out
	layer_15_ep7_tp3_sa_qkv [label="Self-Attn QKV\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep7_tp3_sa_attn [label="Self-Attn Compute\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep7_tp3_sa_out [label="Self-Attn Output\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep7_tp3_sa_qkv -> layer_15_ep7_tp3_sa_attn
	layer_15_ep7_tp3_sa_attn -> layer_15_ep7_tp3_sa_out
	layer_15_ep8_tp0_sa_qkv [label="Self-Attn QKV\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep8_tp0_sa_attn [label="Self-Attn Compute\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep8_tp0_sa_out [label="Self-Attn Output\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep8_tp0_sa_qkv -> layer_15_ep8_tp0_sa_attn
	layer_15_ep8_tp0_sa_attn -> layer_15_ep8_tp0_sa_out
	layer_15_ep8_tp1_sa_qkv [label="Self-Attn QKV\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep8_tp1_sa_attn [label="Self-Attn Compute\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep8_tp1_sa_out [label="Self-Attn Output\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep8_tp1_sa_qkv -> layer_15_ep8_tp1_sa_attn
	layer_15_ep8_tp1_sa_attn -> layer_15_ep8_tp1_sa_out
	layer_15_ep8_tp2_sa_qkv [label="Self-Attn QKV\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep8_tp2_sa_attn [label="Self-Attn Compute\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep8_tp2_sa_out [label="Self-Attn Output\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep8_tp2_sa_qkv -> layer_15_ep8_tp2_sa_attn
	layer_15_ep8_tp2_sa_attn -> layer_15_ep8_tp2_sa_out
	layer_15_ep8_tp3_sa_qkv [label="Self-Attn QKV\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep8_tp3_sa_attn [label="Self-Attn Compute\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep8_tp3_sa_out [label="Self-Attn Output\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep8_tp3_sa_qkv -> layer_15_ep8_tp3_sa_attn
	layer_15_ep8_tp3_sa_attn -> layer_15_ep8_tp3_sa_out
	layer_15_ep9_tp0_sa_qkv [label="Self-Attn QKV\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep9_tp0_sa_attn [label="Self-Attn Compute\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep9_tp0_sa_out [label="Self-Attn Output\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep9_tp0_sa_qkv -> layer_15_ep9_tp0_sa_attn
	layer_15_ep9_tp0_sa_attn -> layer_15_ep9_tp0_sa_out
	layer_15_ep9_tp1_sa_qkv [label="Self-Attn QKV\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep9_tp1_sa_attn [label="Self-Attn Compute\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep9_tp1_sa_out [label="Self-Attn Output\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep9_tp1_sa_qkv -> layer_15_ep9_tp1_sa_attn
	layer_15_ep9_tp1_sa_attn -> layer_15_ep9_tp1_sa_out
	layer_15_ep9_tp2_sa_qkv [label="Self-Attn QKV\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep9_tp2_sa_attn [label="Self-Attn Compute\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep9_tp2_sa_out [label="Self-Attn Output\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep9_tp2_sa_qkv -> layer_15_ep9_tp2_sa_attn
	layer_15_ep9_tp2_sa_attn -> layer_15_ep9_tp2_sa_out
	layer_15_ep9_tp3_sa_qkv [label="Self-Attn QKV\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep9_tp3_sa_attn [label="Self-Attn Compute\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep9_tp3_sa_out [label="Self-Attn Output\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep9_tp3_sa_qkv -> layer_15_ep9_tp3_sa_attn
	layer_15_ep9_tp3_sa_attn -> layer_15_ep9_tp3_sa_out
	layer_15_ep10_tp0_sa_qkv [label="Self-Attn QKV\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep10_tp0_sa_attn [label="Self-Attn Compute\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep10_tp0_sa_out [label="Self-Attn Output\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep10_tp0_sa_qkv -> layer_15_ep10_tp0_sa_attn
	layer_15_ep10_tp0_sa_attn -> layer_15_ep10_tp0_sa_out
	layer_15_ep10_tp1_sa_qkv [label="Self-Attn QKV\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep10_tp1_sa_attn [label="Self-Attn Compute\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep10_tp1_sa_out [label="Self-Attn Output\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep10_tp1_sa_qkv -> layer_15_ep10_tp1_sa_attn
	layer_15_ep10_tp1_sa_attn -> layer_15_ep10_tp1_sa_out
	layer_15_ep10_tp2_sa_qkv [label="Self-Attn QKV\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep10_tp2_sa_attn [label="Self-Attn Compute\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep10_tp2_sa_out [label="Self-Attn Output\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep10_tp2_sa_qkv -> layer_15_ep10_tp2_sa_attn
	layer_15_ep10_tp2_sa_attn -> layer_15_ep10_tp2_sa_out
	layer_15_ep10_tp3_sa_qkv [label="Self-Attn QKV\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep10_tp3_sa_attn [label="Self-Attn Compute\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep10_tp3_sa_out [label="Self-Attn Output\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep10_tp3_sa_qkv -> layer_15_ep10_tp3_sa_attn
	layer_15_ep10_tp3_sa_attn -> layer_15_ep10_tp3_sa_out
	layer_15_ep11_tp0_sa_qkv [label="Self-Attn QKV\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep11_tp0_sa_attn [label="Self-Attn Compute\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep11_tp0_sa_out [label="Self-Attn Output\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep11_tp0_sa_qkv -> layer_15_ep11_tp0_sa_attn
	layer_15_ep11_tp0_sa_attn -> layer_15_ep11_tp0_sa_out
	layer_15_ep11_tp1_sa_qkv [label="Self-Attn QKV\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep11_tp1_sa_attn [label="Self-Attn Compute\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep11_tp1_sa_out [label="Self-Attn Output\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep11_tp1_sa_qkv -> layer_15_ep11_tp1_sa_attn
	layer_15_ep11_tp1_sa_attn -> layer_15_ep11_tp1_sa_out
	layer_15_ep11_tp2_sa_qkv [label="Self-Attn QKV\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep11_tp2_sa_attn [label="Self-Attn Compute\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep11_tp2_sa_out [label="Self-Attn Output\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep11_tp2_sa_qkv -> layer_15_ep11_tp2_sa_attn
	layer_15_ep11_tp2_sa_attn -> layer_15_ep11_tp2_sa_out
	layer_15_ep11_tp3_sa_qkv [label="Self-Attn QKV\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep11_tp3_sa_attn [label="Self-Attn Compute\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep11_tp3_sa_out [label="Self-Attn Output\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep11_tp3_sa_qkv -> layer_15_ep11_tp3_sa_attn
	layer_15_ep11_tp3_sa_attn -> layer_15_ep11_tp3_sa_out
	layer_15_ep12_tp0_sa_qkv [label="Self-Attn QKV\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep12_tp0_sa_attn [label="Self-Attn Compute\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep12_tp0_sa_out [label="Self-Attn Output\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep12_tp0_sa_qkv -> layer_15_ep12_tp0_sa_attn
	layer_15_ep12_tp0_sa_attn -> layer_15_ep12_tp0_sa_out
	layer_15_ep12_tp1_sa_qkv [label="Self-Attn QKV\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep12_tp1_sa_attn [label="Self-Attn Compute\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep12_tp1_sa_out [label="Self-Attn Output\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep12_tp1_sa_qkv -> layer_15_ep12_tp1_sa_attn
	layer_15_ep12_tp1_sa_attn -> layer_15_ep12_tp1_sa_out
	layer_15_ep12_tp2_sa_qkv [label="Self-Attn QKV\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep12_tp2_sa_attn [label="Self-Attn Compute\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep12_tp2_sa_out [label="Self-Attn Output\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep12_tp2_sa_qkv -> layer_15_ep12_tp2_sa_attn
	layer_15_ep12_tp2_sa_attn -> layer_15_ep12_tp2_sa_out
	layer_15_ep12_tp3_sa_qkv [label="Self-Attn QKV\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep12_tp3_sa_attn [label="Self-Attn Compute\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep12_tp3_sa_out [label="Self-Attn Output\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep12_tp3_sa_qkv -> layer_15_ep12_tp3_sa_attn
	layer_15_ep12_tp3_sa_attn -> layer_15_ep12_tp3_sa_out
	layer_15_ep13_tp0_sa_qkv [label="Self-Attn QKV\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep13_tp0_sa_attn [label="Self-Attn Compute\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep13_tp0_sa_out [label="Self-Attn Output\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep13_tp0_sa_qkv -> layer_15_ep13_tp0_sa_attn
	layer_15_ep13_tp0_sa_attn -> layer_15_ep13_tp0_sa_out
	layer_15_ep13_tp1_sa_qkv [label="Self-Attn QKV\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep13_tp1_sa_attn [label="Self-Attn Compute\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep13_tp1_sa_out [label="Self-Attn Output\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep13_tp1_sa_qkv -> layer_15_ep13_tp1_sa_attn
	layer_15_ep13_tp1_sa_attn -> layer_15_ep13_tp1_sa_out
	layer_15_ep13_tp2_sa_qkv [label="Self-Attn QKV\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep13_tp2_sa_attn [label="Self-Attn Compute\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep13_tp2_sa_out [label="Self-Attn Output\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep13_tp2_sa_qkv -> layer_15_ep13_tp2_sa_attn
	layer_15_ep13_tp2_sa_attn -> layer_15_ep13_tp2_sa_out
	layer_15_ep13_tp3_sa_qkv [label="Self-Attn QKV\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep13_tp3_sa_attn [label="Self-Attn Compute\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep13_tp3_sa_out [label="Self-Attn Output\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep13_tp3_sa_qkv -> layer_15_ep13_tp3_sa_attn
	layer_15_ep13_tp3_sa_attn -> layer_15_ep13_tp3_sa_out
	layer_15_ep14_tp0_sa_qkv [label="Self-Attn QKV\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep14_tp0_sa_attn [label="Self-Attn Compute\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep14_tp0_sa_out [label="Self-Attn Output\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep14_tp0_sa_qkv -> layer_15_ep14_tp0_sa_attn
	layer_15_ep14_tp0_sa_attn -> layer_15_ep14_tp0_sa_out
	layer_15_ep14_tp1_sa_qkv [label="Self-Attn QKV\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep14_tp1_sa_attn [label="Self-Attn Compute\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep14_tp1_sa_out [label="Self-Attn Output\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep14_tp1_sa_qkv -> layer_15_ep14_tp1_sa_attn
	layer_15_ep14_tp1_sa_attn -> layer_15_ep14_tp1_sa_out
	layer_15_ep14_tp2_sa_qkv [label="Self-Attn QKV\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep14_tp2_sa_attn [label="Self-Attn Compute\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep14_tp2_sa_out [label="Self-Attn Output\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep14_tp2_sa_qkv -> layer_15_ep14_tp2_sa_attn
	layer_15_ep14_tp2_sa_attn -> layer_15_ep14_tp2_sa_out
	layer_15_ep14_tp3_sa_qkv [label="Self-Attn QKV\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep14_tp3_sa_attn [label="Self-Attn Compute\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep14_tp3_sa_out [label="Self-Attn Output\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep14_tp3_sa_qkv -> layer_15_ep14_tp3_sa_attn
	layer_15_ep14_tp3_sa_attn -> layer_15_ep14_tp3_sa_out
	layer_15_ep15_tp0_sa_qkv [label="Self-Attn QKV\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep15_tp0_sa_attn [label="Self-Attn Compute\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep15_tp0_sa_out [label="Self-Attn Output\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep15_tp0_sa_qkv -> layer_15_ep15_tp0_sa_attn
	layer_15_ep15_tp0_sa_attn -> layer_15_ep15_tp0_sa_out
	layer_15_ep15_tp1_sa_qkv [label="Self-Attn QKV\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep15_tp1_sa_attn [label="Self-Attn Compute\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep15_tp1_sa_out [label="Self-Attn Output\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep15_tp1_sa_qkv -> layer_15_ep15_tp1_sa_attn
	layer_15_ep15_tp1_sa_attn -> layer_15_ep15_tp1_sa_out
	layer_15_ep15_tp2_sa_qkv [label="Self-Attn QKV\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep15_tp2_sa_attn [label="Self-Attn Compute\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep15_tp2_sa_out [label="Self-Attn Output\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep15_tp2_sa_qkv -> layer_15_ep15_tp2_sa_attn
	layer_15_ep15_tp2_sa_attn -> layer_15_ep15_tp2_sa_out
	layer_15_ep15_tp3_sa_qkv [label="Self-Attn QKV\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep15_tp3_sa_attn [label="Self-Attn Compute\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep15_tp3_sa_out [label="Self-Attn Output\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep15_tp3_sa_qkv -> layer_15_ep15_tp3_sa_attn
	layer_15_ep15_tp3_sa_attn -> layer_15_ep15_tp3_sa_out
	layer_15_ep0_tp_allreduce [label="TP All-Reduce\nEP-Group-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_15_ep0_tp0_sa_out -> layer_15_ep0_tp_allreduce
	layer_15_ep0_tp1_sa_out -> layer_15_ep0_tp_allreduce
	layer_15_ep0_tp2_sa_out -> layer_15_ep0_tp_allreduce
	layer_15_ep0_tp3_sa_out -> layer_15_ep0_tp_allreduce
	layer_15_ep1_tp_allreduce [label="TP All-Reduce\nEP-Group-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_15_ep1_tp0_sa_out -> layer_15_ep1_tp_allreduce
	layer_15_ep1_tp1_sa_out -> layer_15_ep1_tp_allreduce
	layer_15_ep1_tp2_sa_out -> layer_15_ep1_tp_allreduce
	layer_15_ep1_tp3_sa_out -> layer_15_ep1_tp_allreduce
	layer_15_ep2_tp_allreduce [label="TP All-Reduce\nEP-Group-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_15_ep2_tp0_sa_out -> layer_15_ep2_tp_allreduce
	layer_15_ep2_tp1_sa_out -> layer_15_ep2_tp_allreduce
	layer_15_ep2_tp2_sa_out -> layer_15_ep2_tp_allreduce
	layer_15_ep2_tp3_sa_out -> layer_15_ep2_tp_allreduce
	layer_15_ep3_tp_allreduce [label="TP All-Reduce\nEP-Group-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_15_ep3_tp0_sa_out -> layer_15_ep3_tp_allreduce
	layer_15_ep3_tp1_sa_out -> layer_15_ep3_tp_allreduce
	layer_15_ep3_tp2_sa_out -> layer_15_ep3_tp_allreduce
	layer_15_ep3_tp3_sa_out -> layer_15_ep3_tp_allreduce
	layer_15_ep4_tp_allreduce [label="TP All-Reduce\nEP-Group-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_15_ep4_tp0_sa_out -> layer_15_ep4_tp_allreduce
	layer_15_ep4_tp1_sa_out -> layer_15_ep4_tp_allreduce
	layer_15_ep4_tp2_sa_out -> layer_15_ep4_tp_allreduce
	layer_15_ep4_tp3_sa_out -> layer_15_ep4_tp_allreduce
	layer_15_ep5_tp_allreduce [label="TP All-Reduce\nEP-Group-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_15_ep5_tp0_sa_out -> layer_15_ep5_tp_allreduce
	layer_15_ep5_tp1_sa_out -> layer_15_ep5_tp_allreduce
	layer_15_ep5_tp2_sa_out -> layer_15_ep5_tp_allreduce
	layer_15_ep5_tp3_sa_out -> layer_15_ep5_tp_allreduce
	layer_15_ep6_tp_allreduce [label="TP All-Reduce\nEP-Group-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_15_ep6_tp0_sa_out -> layer_15_ep6_tp_allreduce
	layer_15_ep6_tp1_sa_out -> layer_15_ep6_tp_allreduce
	layer_15_ep6_tp2_sa_out -> layer_15_ep6_tp_allreduce
	layer_15_ep6_tp3_sa_out -> layer_15_ep6_tp_allreduce
	layer_15_ep7_tp_allreduce [label="TP All-Reduce\nEP-Group-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_15_ep7_tp0_sa_out -> layer_15_ep7_tp_allreduce
	layer_15_ep7_tp1_sa_out -> layer_15_ep7_tp_allreduce
	layer_15_ep7_tp2_sa_out -> layer_15_ep7_tp_allreduce
	layer_15_ep7_tp3_sa_out -> layer_15_ep7_tp_allreduce
	layer_15_ep8_tp_allreduce [label="TP All-Reduce\nEP-Group-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_15_ep8_tp0_sa_out -> layer_15_ep8_tp_allreduce
	layer_15_ep8_tp1_sa_out -> layer_15_ep8_tp_allreduce
	layer_15_ep8_tp2_sa_out -> layer_15_ep8_tp_allreduce
	layer_15_ep8_tp3_sa_out -> layer_15_ep8_tp_allreduce
	layer_15_ep9_tp_allreduce [label="TP All-Reduce\nEP-Group-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_15_ep9_tp0_sa_out -> layer_15_ep9_tp_allreduce
	layer_15_ep9_tp1_sa_out -> layer_15_ep9_tp_allreduce
	layer_15_ep9_tp2_sa_out -> layer_15_ep9_tp_allreduce
	layer_15_ep9_tp3_sa_out -> layer_15_ep9_tp_allreduce
	layer_15_ep10_tp_allreduce [label="TP All-Reduce\nEP-Group-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_15_ep10_tp0_sa_out -> layer_15_ep10_tp_allreduce
	layer_15_ep10_tp1_sa_out -> layer_15_ep10_tp_allreduce
	layer_15_ep10_tp2_sa_out -> layer_15_ep10_tp_allreduce
	layer_15_ep10_tp3_sa_out -> layer_15_ep10_tp_allreduce
	layer_15_ep11_tp_allreduce [label="TP All-Reduce\nEP-Group-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_15_ep11_tp0_sa_out -> layer_15_ep11_tp_allreduce
	layer_15_ep11_tp1_sa_out -> layer_15_ep11_tp_allreduce
	layer_15_ep11_tp2_sa_out -> layer_15_ep11_tp_allreduce
	layer_15_ep11_tp3_sa_out -> layer_15_ep11_tp_allreduce
	layer_15_ep12_tp_allreduce [label="TP All-Reduce\nEP-Group-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_15_ep12_tp0_sa_out -> layer_15_ep12_tp_allreduce
	layer_15_ep12_tp1_sa_out -> layer_15_ep12_tp_allreduce
	layer_15_ep12_tp2_sa_out -> layer_15_ep12_tp_allreduce
	layer_15_ep12_tp3_sa_out -> layer_15_ep12_tp_allreduce
	layer_15_ep13_tp_allreduce [label="TP All-Reduce\nEP-Group-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_15_ep13_tp0_sa_out -> layer_15_ep13_tp_allreduce
	layer_15_ep13_tp1_sa_out -> layer_15_ep13_tp_allreduce
	layer_15_ep13_tp2_sa_out -> layer_15_ep13_tp_allreduce
	layer_15_ep13_tp3_sa_out -> layer_15_ep13_tp_allreduce
	layer_15_ep14_tp_allreduce [label="TP All-Reduce\nEP-Group-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_15_ep14_tp0_sa_out -> layer_15_ep14_tp_allreduce
	layer_15_ep14_tp1_sa_out -> layer_15_ep14_tp_allreduce
	layer_15_ep14_tp2_sa_out -> layer_15_ep14_tp_allreduce
	layer_15_ep14_tp3_sa_out -> layer_15_ep14_tp_allreduce
	layer_15_ep15_tp_allreduce [label="TP All-Reduce\nEP-Group-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgreen shape=ellipse]
	layer_15_ep15_tp0_sa_out -> layer_15_ep15_tp_allreduce
	layer_15_ep15_tp1_sa_out -> layer_15_ep15_tp_allreduce
	layer_15_ep15_tp2_sa_out -> layer_15_ep15_tp_allreduce
	layer_15_ep15_tp3_sa_out -> layer_15_ep15_tp_allreduce
	layer_15_ep0_gate [label="MoE Gate\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_15_ep0_expert_0 [label="Expert-0\nGPU-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep0_gate -> layer_15_ep0_expert_0 [label="select tokens" style=dashed]
	layer_15_ep0_expert_1 [label="Expert-1\nGPU-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep0_gate -> layer_15_ep0_expert_1 [label="select tokens" style=dashed]
	layer_15_ep0_expert_2 [label="Expert-2\nGPU-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep0_gate -> layer_15_ep0_expert_2 [label="select tokens" style=dashed]
	layer_15_ep0_expert_3 [label="Expert-3\nGPU-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep0_gate -> layer_15_ep0_expert_3 [label="select tokens" style=dashed]
	layer_15_ep0_expert_aggr [label="Expert Aggregation\nEP-Group-0\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_15_ep0_expert_0 -> layer_15_ep0_expert_aggr
	layer_15_ep0_expert_1 -> layer_15_ep0_expert_aggr
	layer_15_ep0_expert_2 -> layer_15_ep0_expert_aggr
	layer_15_ep0_expert_3 -> layer_15_ep0_expert_aggr
	layer_15_ep1_gate [label="MoE Gate\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_15_ep1_expert_0 [label="Expert-0\nGPU-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep1_gate -> layer_15_ep1_expert_0 [label="select tokens" style=dashed]
	layer_15_ep1_expert_1 [label="Expert-1\nGPU-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep1_gate -> layer_15_ep1_expert_1 [label="select tokens" style=dashed]
	layer_15_ep1_expert_2 [label="Expert-2\nGPU-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep1_gate -> layer_15_ep1_expert_2 [label="select tokens" style=dashed]
	layer_15_ep1_expert_3 [label="Expert-3\nGPU-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep1_gate -> layer_15_ep1_expert_3 [label="select tokens" style=dashed]
	layer_15_ep1_expert_aggr [label="Expert Aggregation\nEP-Group-1\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_15_ep1_expert_0 -> layer_15_ep1_expert_aggr
	layer_15_ep1_expert_1 -> layer_15_ep1_expert_aggr
	layer_15_ep1_expert_2 -> layer_15_ep1_expert_aggr
	layer_15_ep1_expert_3 -> layer_15_ep1_expert_aggr
	layer_15_ep2_gate [label="MoE Gate\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_15_ep2_expert_0 [label="Expert-0\nGPU-16\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep2_gate -> layer_15_ep2_expert_0 [label="select tokens" style=dashed]
	layer_15_ep2_expert_1 [label="Expert-1\nGPU-17\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep2_gate -> layer_15_ep2_expert_1 [label="select tokens" style=dashed]
	layer_15_ep2_expert_2 [label="Expert-2\nGPU-18\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep2_gate -> layer_15_ep2_expert_2 [label="select tokens" style=dashed]
	layer_15_ep2_expert_3 [label="Expert-3\nGPU-19\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep2_gate -> layer_15_ep2_expert_3 [label="select tokens" style=dashed]
	layer_15_ep2_expert_aggr [label="Expert Aggregation\nEP-Group-2\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_15_ep2_expert_0 -> layer_15_ep2_expert_aggr
	layer_15_ep2_expert_1 -> layer_15_ep2_expert_aggr
	layer_15_ep2_expert_2 -> layer_15_ep2_expert_aggr
	layer_15_ep2_expert_3 -> layer_15_ep2_expert_aggr
	layer_15_ep3_gate [label="MoE Gate\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_15_ep3_expert_0 [label="Expert-0\nGPU-24\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep3_gate -> layer_15_ep3_expert_0 [label="select tokens" style=dashed]
	layer_15_ep3_expert_1 [label="Expert-1\nGPU-25\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep3_gate -> layer_15_ep3_expert_1 [label="select tokens" style=dashed]
	layer_15_ep3_expert_2 [label="Expert-2\nGPU-26\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep3_gate -> layer_15_ep3_expert_2 [label="select tokens" style=dashed]
	layer_15_ep3_expert_3 [label="Expert-3\nGPU-27\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep3_gate -> layer_15_ep3_expert_3 [label="select tokens" style=dashed]
	layer_15_ep3_expert_aggr [label="Expert Aggregation\nEP-Group-3\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_15_ep3_expert_0 -> layer_15_ep3_expert_aggr
	layer_15_ep3_expert_1 -> layer_15_ep3_expert_aggr
	layer_15_ep3_expert_2 -> layer_15_ep3_expert_aggr
	layer_15_ep3_expert_3 -> layer_15_ep3_expert_aggr
	layer_15_ep4_gate [label="MoE Gate\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_15_ep4_expert_0 [label="Expert-0\nGPU-32\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep4_gate -> layer_15_ep4_expert_0 [label="select tokens" style=dashed]
	layer_15_ep4_expert_1 [label="Expert-1\nGPU-33\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep4_gate -> layer_15_ep4_expert_1 [label="select tokens" style=dashed]
	layer_15_ep4_expert_2 [label="Expert-2\nGPU-34\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep4_gate -> layer_15_ep4_expert_2 [label="select tokens" style=dashed]
	layer_15_ep4_expert_3 [label="Expert-3\nGPU-35\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep4_gate -> layer_15_ep4_expert_3 [label="select tokens" style=dashed]
	layer_15_ep4_expert_aggr [label="Expert Aggregation\nEP-Group-4\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_15_ep4_expert_0 -> layer_15_ep4_expert_aggr
	layer_15_ep4_expert_1 -> layer_15_ep4_expert_aggr
	layer_15_ep4_expert_2 -> layer_15_ep4_expert_aggr
	layer_15_ep4_expert_3 -> layer_15_ep4_expert_aggr
	layer_15_ep5_gate [label="MoE Gate\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_15_ep5_expert_0 [label="Expert-0\nGPU-40\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep5_gate -> layer_15_ep5_expert_0 [label="select tokens" style=dashed]
	layer_15_ep5_expert_1 [label="Expert-1\nGPU-41\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep5_gate -> layer_15_ep5_expert_1 [label="select tokens" style=dashed]
	layer_15_ep5_expert_2 [label="Expert-2\nGPU-42\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep5_gate -> layer_15_ep5_expert_2 [label="select tokens" style=dashed]
	layer_15_ep5_expert_3 [label="Expert-3\nGPU-43\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep5_gate -> layer_15_ep5_expert_3 [label="select tokens" style=dashed]
	layer_15_ep5_expert_aggr [label="Expert Aggregation\nEP-Group-5\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_15_ep5_expert_0 -> layer_15_ep5_expert_aggr
	layer_15_ep5_expert_1 -> layer_15_ep5_expert_aggr
	layer_15_ep5_expert_2 -> layer_15_ep5_expert_aggr
	layer_15_ep5_expert_3 -> layer_15_ep5_expert_aggr
	layer_15_ep6_gate [label="MoE Gate\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_15_ep6_expert_0 [label="Expert-0\nGPU-48\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep6_gate -> layer_15_ep6_expert_0 [label="select tokens" style=dashed]
	layer_15_ep6_expert_1 [label="Expert-1\nGPU-49\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep6_gate -> layer_15_ep6_expert_1 [label="select tokens" style=dashed]
	layer_15_ep6_expert_2 [label="Expert-2\nGPU-50\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep6_gate -> layer_15_ep6_expert_2 [label="select tokens" style=dashed]
	layer_15_ep6_expert_3 [label="Expert-3\nGPU-51\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep6_gate -> layer_15_ep6_expert_3 [label="select tokens" style=dashed]
	layer_15_ep6_expert_aggr [label="Expert Aggregation\nEP-Group-6\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_15_ep6_expert_0 -> layer_15_ep6_expert_aggr
	layer_15_ep6_expert_1 -> layer_15_ep6_expert_aggr
	layer_15_ep6_expert_2 -> layer_15_ep6_expert_aggr
	layer_15_ep6_expert_3 -> layer_15_ep6_expert_aggr
	layer_15_ep7_gate [label="MoE Gate\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_15_ep7_expert_0 [label="Expert-0\nGPU-56\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep7_gate -> layer_15_ep7_expert_0 [label="select tokens" style=dashed]
	layer_15_ep7_expert_1 [label="Expert-1\nGPU-57\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep7_gate -> layer_15_ep7_expert_1 [label="select tokens" style=dashed]
	layer_15_ep7_expert_2 [label="Expert-2\nGPU-58\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep7_gate -> layer_15_ep7_expert_2 [label="select tokens" style=dashed]
	layer_15_ep7_expert_3 [label="Expert-3\nGPU-59\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep7_gate -> layer_15_ep7_expert_3 [label="select tokens" style=dashed]
	layer_15_ep7_expert_aggr [label="Expert Aggregation\nEP-Group-7\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_15_ep7_expert_0 -> layer_15_ep7_expert_aggr
	layer_15_ep7_expert_1 -> layer_15_ep7_expert_aggr
	layer_15_ep7_expert_2 -> layer_15_ep7_expert_aggr
	layer_15_ep7_expert_3 -> layer_15_ep7_expert_aggr
	layer_15_ep8_gate [label="MoE Gate\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_15_ep8_expert_0 [label="Expert-0\nGPU-64\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep8_gate -> layer_15_ep8_expert_0 [label="select tokens" style=dashed]
	layer_15_ep8_expert_1 [label="Expert-1\nGPU-65\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep8_gate -> layer_15_ep8_expert_1 [label="select tokens" style=dashed]
	layer_15_ep8_expert_2 [label="Expert-2\nGPU-66\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep8_gate -> layer_15_ep8_expert_2 [label="select tokens" style=dashed]
	layer_15_ep8_expert_3 [label="Expert-3\nGPU-67\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep8_gate -> layer_15_ep8_expert_3 [label="select tokens" style=dashed]
	layer_15_ep8_expert_aggr [label="Expert Aggregation\nEP-Group-8\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_15_ep8_expert_0 -> layer_15_ep8_expert_aggr
	layer_15_ep8_expert_1 -> layer_15_ep8_expert_aggr
	layer_15_ep8_expert_2 -> layer_15_ep8_expert_aggr
	layer_15_ep8_expert_3 -> layer_15_ep8_expert_aggr
	layer_15_ep9_gate [label="MoE Gate\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_15_ep9_expert_0 [label="Expert-0\nGPU-72\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep9_gate -> layer_15_ep9_expert_0 [label="select tokens" style=dashed]
	layer_15_ep9_expert_1 [label="Expert-1\nGPU-73\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep9_gate -> layer_15_ep9_expert_1 [label="select tokens" style=dashed]
	layer_15_ep9_expert_2 [label="Expert-2\nGPU-74\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep9_gate -> layer_15_ep9_expert_2 [label="select tokens" style=dashed]
	layer_15_ep9_expert_3 [label="Expert-3\nGPU-75\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep9_gate -> layer_15_ep9_expert_3 [label="select tokens" style=dashed]
	layer_15_ep9_expert_aggr [label="Expert Aggregation\nEP-Group-9\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_15_ep9_expert_0 -> layer_15_ep9_expert_aggr
	layer_15_ep9_expert_1 -> layer_15_ep9_expert_aggr
	layer_15_ep9_expert_2 -> layer_15_ep9_expert_aggr
	layer_15_ep9_expert_3 -> layer_15_ep9_expert_aggr
	layer_15_ep10_gate [label="MoE Gate\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_15_ep10_expert_0 [label="Expert-0\nGPU-80\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep10_gate -> layer_15_ep10_expert_0 [label="select tokens" style=dashed]
	layer_15_ep10_expert_1 [label="Expert-1\nGPU-81\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep10_gate -> layer_15_ep10_expert_1 [label="select tokens" style=dashed]
	layer_15_ep10_expert_2 [label="Expert-2\nGPU-82\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep10_gate -> layer_15_ep10_expert_2 [label="select tokens" style=dashed]
	layer_15_ep10_expert_3 [label="Expert-3\nGPU-83\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep10_gate -> layer_15_ep10_expert_3 [label="select tokens" style=dashed]
	layer_15_ep10_expert_aggr [label="Expert Aggregation\nEP-Group-10\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_15_ep10_expert_0 -> layer_15_ep10_expert_aggr
	layer_15_ep10_expert_1 -> layer_15_ep10_expert_aggr
	layer_15_ep10_expert_2 -> layer_15_ep10_expert_aggr
	layer_15_ep10_expert_3 -> layer_15_ep10_expert_aggr
	layer_15_ep11_gate [label="MoE Gate\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_15_ep11_expert_0 [label="Expert-0\nGPU-88\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep11_gate -> layer_15_ep11_expert_0 [label="select tokens" style=dashed]
	layer_15_ep11_expert_1 [label="Expert-1\nGPU-89\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep11_gate -> layer_15_ep11_expert_1 [label="select tokens" style=dashed]
	layer_15_ep11_expert_2 [label="Expert-2\nGPU-90\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep11_gate -> layer_15_ep11_expert_2 [label="select tokens" style=dashed]
	layer_15_ep11_expert_3 [label="Expert-3\nGPU-91\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep11_gate -> layer_15_ep11_expert_3 [label="select tokens" style=dashed]
	layer_15_ep11_expert_aggr [label="Expert Aggregation\nEP-Group-11\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_15_ep11_expert_0 -> layer_15_ep11_expert_aggr
	layer_15_ep11_expert_1 -> layer_15_ep11_expert_aggr
	layer_15_ep11_expert_2 -> layer_15_ep11_expert_aggr
	layer_15_ep11_expert_3 -> layer_15_ep11_expert_aggr
	layer_15_ep12_gate [label="MoE Gate\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_15_ep12_expert_0 [label="Expert-0\nGPU-96\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep12_gate -> layer_15_ep12_expert_0 [label="select tokens" style=dashed]
	layer_15_ep12_expert_1 [label="Expert-1\nGPU-97\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep12_gate -> layer_15_ep12_expert_1 [label="select tokens" style=dashed]
	layer_15_ep12_expert_2 [label="Expert-2\nGPU-98\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep12_gate -> layer_15_ep12_expert_2 [label="select tokens" style=dashed]
	layer_15_ep12_expert_3 [label="Expert-3\nGPU-99\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep12_gate -> layer_15_ep12_expert_3 [label="select tokens" style=dashed]
	layer_15_ep12_expert_aggr [label="Expert Aggregation\nEP-Group-12\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_15_ep12_expert_0 -> layer_15_ep12_expert_aggr
	layer_15_ep12_expert_1 -> layer_15_ep12_expert_aggr
	layer_15_ep12_expert_2 -> layer_15_ep12_expert_aggr
	layer_15_ep12_expert_3 -> layer_15_ep12_expert_aggr
	layer_15_ep13_gate [label="MoE Gate\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_15_ep13_expert_0 [label="Expert-0\nGPU-104\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep13_gate -> layer_15_ep13_expert_0 [label="select tokens" style=dashed]
	layer_15_ep13_expert_1 [label="Expert-1\nGPU-105\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep13_gate -> layer_15_ep13_expert_1 [label="select tokens" style=dashed]
	layer_15_ep13_expert_2 [label="Expert-2\nGPU-106\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep13_gate -> layer_15_ep13_expert_2 [label="select tokens" style=dashed]
	layer_15_ep13_expert_3 [label="Expert-3\nGPU-107\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep13_gate -> layer_15_ep13_expert_3 [label="select tokens" style=dashed]
	layer_15_ep13_expert_aggr [label="Expert Aggregation\nEP-Group-13\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_15_ep13_expert_0 -> layer_15_ep13_expert_aggr
	layer_15_ep13_expert_1 -> layer_15_ep13_expert_aggr
	layer_15_ep13_expert_2 -> layer_15_ep13_expert_aggr
	layer_15_ep13_expert_3 -> layer_15_ep13_expert_aggr
	layer_15_ep14_gate [label="MoE Gate\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_15_ep14_expert_0 [label="Expert-0\nGPU-112\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep14_gate -> layer_15_ep14_expert_0 [label="select tokens" style=dashed]
	layer_15_ep14_expert_1 [label="Expert-1\nGPU-113\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep14_gate -> layer_15_ep14_expert_1 [label="select tokens" style=dashed]
	layer_15_ep14_expert_2 [label="Expert-2\nGPU-114\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep14_gate -> layer_15_ep14_expert_2 [label="select tokens" style=dashed]
	layer_15_ep14_expert_3 [label="Expert-3\nGPU-115\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep14_gate -> layer_15_ep14_expert_3 [label="select tokens" style=dashed]
	layer_15_ep14_expert_aggr [label="Expert Aggregation\nEP-Group-14\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_15_ep14_expert_0 -> layer_15_ep14_expert_aggr
	layer_15_ep14_expert_1 -> layer_15_ep14_expert_aggr
	layer_15_ep14_expert_2 -> layer_15_ep14_expert_aggr
	layer_15_ep14_expert_3 -> layer_15_ep14_expert_aggr
	layer_15_ep15_gate [label="MoE Gate\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, num_experts=4]" fillcolor=lightblue shape=rectangle]
	layer_15_ep15_expert_0 [label="Expert-0\nGPU-120\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep15_gate -> layer_15_ep15_expert_0 [label="select tokens" style=dashed]
	layer_15_ep15_expert_1 [label="Expert-1\nGPU-121\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep15_gate -> layer_15_ep15_expert_1 [label="select tokens" style=dashed]
	layer_15_ep15_expert_2 [label="Expert-2\nGPU-122\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep15_gate -> layer_15_ep15_expert_2 [label="select tokens" style=dashed]
	layer_15_ep15_expert_3 [label="Expert-3\nGPU-123\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightblue shape=rectangle]
	layer_15_ep15_gate -> layer_15_ep15_expert_3 [label="select tokens" style=dashed]
	layer_15_ep15_expert_aggr [label="Expert Aggregation\nEP-Group-15\nInput: [batch_size=128, seq_len=1024, token_dim=1024]\nOutput: [batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightyellow shape=parallelogram]
	layer_15_ep15_expert_0 -> layer_15_ep15_expert_aggr
	layer_15_ep15_expert_1 -> layer_15_ep15_expert_aggr
	layer_15_ep15_expert_2 -> layer_15_ep15_expert_aggr
	layer_15_ep15_expert_3 -> layer_15_ep15_expert_aggr
	output [label="Output\n[batch_size=128, seq_len=1024, token_dim=1024]" fillcolor=lightgray shape=hexagon]
	layer_15_ep0_expert_aggr -> output
	layer_15_ep1_expert_aggr -> output
	layer_15_ep2_expert_aggr -> output
	layer_15_ep3_expert_aggr -> output
	layer_15_ep4_expert_aggr -> output
	layer_15_ep5_expert_aggr -> output
	layer_15_ep6_expert_aggr -> output
	layer_15_ep7_expert_aggr -> output
	layer_15_ep8_expert_aggr -> output
	layer_15_ep9_expert_aggr -> output
	layer_15_ep10_expert_aggr -> output
	layer_15_ep11_expert_aggr -> output
	layer_15_ep12_expert_aggr -> output
	layer_15_ep13_expert_aggr -> output
	layer_15_ep14_expert_aggr -> output
	layer_15_ep15_expert_aggr -> output
}
