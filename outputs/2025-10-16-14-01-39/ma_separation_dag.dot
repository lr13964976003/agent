digraph MA_Separation_DAG {
	nodesep=0.8 rankdir=TB ranksep=1.2 splines=ortho
	model_input [label="Model Input\nInput: Raw tokens\nOutput: [batch_size=batch_size, seq_len=2048]\nGPU: CPU" fillcolor=lightblue shape=ellipse style=filled]
	token_embedding [label="Token Embedding\nInput: [batch_size=batch_size, seq_len=2048]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: all GPUs" fillcolor=lightyellow shape=rectangle style=filled]
	model_input -> token_embedding [label="" style=solid]
	position_embedding [label="Position Embedding\nInput: [seq_len=2048]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: all GPUs" fillcolor=lightyellow shape=rectangle style=filled]
	add_embeddings [label="Add Embeddings\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096], [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: all GPUs" fillcolor=lightblue shape=ellipse style=filled]
	token_embedding -> add_embeddings [label="" style=solid]
	position_embedding -> add_embeddings [label="" style=solid]
	layer0_attn_norm_gpu0 [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 0" fillcolor=lightyellow shape=rectangle style=filled]
	add_embeddings -> layer0_attn_norm_gpu0 [label="" style=solid]
	layer0_q_proj_gpu0 [label="Q Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 0" fillcolor=lightgreen shape=rectangle style=filled]
	layer0_attn_norm_gpu0 -> layer0_q_proj_gpu0 [label="" style=solid]
	layer0_k_proj_gpu0 [label="K Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 0" fillcolor=lightgreen shape=rectangle style=filled]
	layer0_attn_norm_gpu0 -> layer0_k_proj_gpu0 [label="" style=solid]
	layer0_v_proj_gpu0 [label="V Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 0" fillcolor=lightgreen shape=rectangle style=filled]
	layer0_attn_norm_gpu0 -> layer0_v_proj_gpu0 [label="" style=solid]
	layer0_gather_q_gpu0 [label="All-Gather Q\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 0" fillcolor=lightblue shape=ellipse style=filled]
	layer0_q_proj_gpu0 -> layer0_gather_q_gpu0 [label="" style=solid]
	layer0_gather_k_gpu0 [label="All-Gather K\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 0" fillcolor=lightblue shape=ellipse style=filled]
	layer0_k_proj_gpu0 -> layer0_gather_k_gpu0 [label="" style=solid]
	layer0_gather_v_gpu0 [label="All-Gather V\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 0" fillcolor=lightblue shape=ellipse style=filled]
	layer0_v_proj_gpu0 -> layer0_gather_v_gpu0 [label="" style=solid]
	layer0_attn_scores_gpu0 [label="QK^T / sqrt(d_k)\nInput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 0" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_gather_q_gpu0 -> layer0_attn_scores_gpu0 [label="" style=solid]
	layer0_gather_k_gpu0 -> layer0_attn_scores_gpu0 [label="" style=solid]
	layer0_softmax_gpu0 [label="Softmax\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 0" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_attn_scores_gpu0 -> layer0_softmax_gpu0 [label="" style=solid]
	layer0_attn_out_gpu0 [label="Attention×V\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 0" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_softmax_gpu0 -> layer0_attn_out_gpu0 [label="" style=solid]
	layer0_gather_v_gpu0 -> layer0_attn_out_gpu0 [label="" style=solid]
	layer0_out_proj_gpu0 [label="Output Projection\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=512]\nGPU: 0" fillcolor=lightgreen shape=rectangle style=filled]
	layer0_attn_out_gpu0 -> layer0_out_proj_gpu0 [label="" style=solid]
	layer0_attn_norm_gpu1 [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 1" fillcolor=lightyellow shape=rectangle style=filled]
	add_embeddings -> layer0_attn_norm_gpu1 [label="" style=solid]
	layer0_q_proj_gpu1 [label="Q Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 1" fillcolor=lightgreen shape=rectangle style=filled]
	layer0_attn_norm_gpu1 -> layer0_q_proj_gpu1 [label="" style=solid]
	layer0_k_proj_gpu1 [label="K Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 1" fillcolor=lightgreen shape=rectangle style=filled]
	layer0_attn_norm_gpu1 -> layer0_k_proj_gpu1 [label="" style=solid]
	layer0_v_proj_gpu1 [label="V Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 1" fillcolor=lightgreen shape=rectangle style=filled]
	layer0_attn_norm_gpu1 -> layer0_v_proj_gpu1 [label="" style=solid]
	layer0_gather_q_gpu1 [label="All-Gather Q\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 1" fillcolor=lightblue shape=ellipse style=filled]
	layer0_q_proj_gpu1 -> layer0_gather_q_gpu1 [label="" style=solid]
	layer0_gather_k_gpu1 [label="All-Gather K\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 1" fillcolor=lightblue shape=ellipse style=filled]
	layer0_k_proj_gpu1 -> layer0_gather_k_gpu1 [label="" style=solid]
	layer0_gather_v_gpu1 [label="All-Gather V\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 1" fillcolor=lightblue shape=ellipse style=filled]
	layer0_v_proj_gpu1 -> layer0_gather_v_gpu1 [label="" style=solid]
	layer0_attn_scores_gpu1 [label="QK^T / sqrt(d_k)\nInput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 1" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_gather_q_gpu1 -> layer0_attn_scores_gpu1 [label="" style=solid]
	layer0_gather_k_gpu1 -> layer0_attn_scores_gpu1 [label="" style=solid]
	layer0_softmax_gpu1 [label="Softmax\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 1" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_attn_scores_gpu1 -> layer0_softmax_gpu1 [label="" style=solid]
	layer0_attn_out_gpu1 [label="Attention×V\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 1" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_softmax_gpu1 -> layer0_attn_out_gpu1 [label="" style=solid]
	layer0_gather_v_gpu1 -> layer0_attn_out_gpu1 [label="" style=solid]
	layer0_out_proj_gpu1 [label="Output Projection\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=512]\nGPU: 1" fillcolor=lightgreen shape=rectangle style=filled]
	layer0_attn_out_gpu1 -> layer0_out_proj_gpu1 [label="" style=solid]
	layer0_attn_norm_gpu2 [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 2" fillcolor=lightyellow shape=rectangle style=filled]
	add_embeddings -> layer0_attn_norm_gpu2 [label="" style=solid]
	layer0_q_proj_gpu2 [label="Q Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 2" fillcolor=lightgreen shape=rectangle style=filled]
	layer0_attn_norm_gpu2 -> layer0_q_proj_gpu2 [label="" style=solid]
	layer0_k_proj_gpu2 [label="K Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 2" fillcolor=lightgreen shape=rectangle style=filled]
	layer0_attn_norm_gpu2 -> layer0_k_proj_gpu2 [label="" style=solid]
	layer0_v_proj_gpu2 [label="V Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 2" fillcolor=lightgreen shape=rectangle style=filled]
	layer0_attn_norm_gpu2 -> layer0_v_proj_gpu2 [label="" style=solid]
	layer0_gather_q_gpu2 [label="All-Gather Q\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 2" fillcolor=lightblue shape=ellipse style=filled]
	layer0_q_proj_gpu2 -> layer0_gather_q_gpu2 [label="" style=solid]
	layer0_gather_k_gpu2 [label="All-Gather K\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 2" fillcolor=lightblue shape=ellipse style=filled]
	layer0_k_proj_gpu2 -> layer0_gather_k_gpu2 [label="" style=solid]
	layer0_gather_v_gpu2 [label="All-Gather V\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 2" fillcolor=lightblue shape=ellipse style=filled]
	layer0_v_proj_gpu2 -> layer0_gather_v_gpu2 [label="" style=solid]
	layer0_attn_scores_gpu2 [label="QK^T / sqrt(d_k)\nInput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 2" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_gather_q_gpu2 -> layer0_attn_scores_gpu2 [label="" style=solid]
	layer0_gather_k_gpu2 -> layer0_attn_scores_gpu2 [label="" style=solid]
	layer0_softmax_gpu2 [label="Softmax\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 2" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_attn_scores_gpu2 -> layer0_softmax_gpu2 [label="" style=solid]
	layer0_attn_out_gpu2 [label="Attention×V\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 2" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_softmax_gpu2 -> layer0_attn_out_gpu2 [label="" style=solid]
	layer0_gather_v_gpu2 -> layer0_attn_out_gpu2 [label="" style=solid]
	layer0_out_proj_gpu2 [label="Output Projection\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=512]\nGPU: 2" fillcolor=lightgreen shape=rectangle style=filled]
	layer0_attn_out_gpu2 -> layer0_out_proj_gpu2 [label="" style=solid]
	layer0_attn_norm_gpu3 [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 3" fillcolor=lightyellow shape=rectangle style=filled]
	add_embeddings -> layer0_attn_norm_gpu3 [label="" style=solid]
	layer0_q_proj_gpu3 [label="Q Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 3" fillcolor=lightgreen shape=rectangle style=filled]
	layer0_attn_norm_gpu3 -> layer0_q_proj_gpu3 [label="" style=solid]
	layer0_k_proj_gpu3 [label="K Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 3" fillcolor=lightgreen shape=rectangle style=filled]
	layer0_attn_norm_gpu3 -> layer0_k_proj_gpu3 [label="" style=solid]
	layer0_v_proj_gpu3 [label="V Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 3" fillcolor=lightgreen shape=rectangle style=filled]
	layer0_attn_norm_gpu3 -> layer0_v_proj_gpu3 [label="" style=solid]
	layer0_gather_q_gpu3 [label="All-Gather Q\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 3" fillcolor=lightblue shape=ellipse style=filled]
	layer0_q_proj_gpu3 -> layer0_gather_q_gpu3 [label="" style=solid]
	layer0_gather_k_gpu3 [label="All-Gather K\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 3" fillcolor=lightblue shape=ellipse style=filled]
	layer0_k_proj_gpu3 -> layer0_gather_k_gpu3 [label="" style=solid]
	layer0_gather_v_gpu3 [label="All-Gather V\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 3" fillcolor=lightblue shape=ellipse style=filled]
	layer0_v_proj_gpu3 -> layer0_gather_v_gpu3 [label="" style=solid]
	layer0_attn_scores_gpu3 [label="QK^T / sqrt(d_k)\nInput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 3" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_gather_q_gpu3 -> layer0_attn_scores_gpu3 [label="" style=solid]
	layer0_gather_k_gpu3 -> layer0_attn_scores_gpu3 [label="" style=solid]
	layer0_softmax_gpu3 [label="Softmax\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 3" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_attn_scores_gpu3 -> layer0_softmax_gpu3 [label="" style=solid]
	layer0_attn_out_gpu3 [label="Attention×V\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 3" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_softmax_gpu3 -> layer0_attn_out_gpu3 [label="" style=solid]
	layer0_gather_v_gpu3 -> layer0_attn_out_gpu3 [label="" style=solid]
	layer0_out_proj_gpu3 [label="Output Projection\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=512]\nGPU: 3" fillcolor=lightgreen shape=rectangle style=filled]
	layer0_attn_out_gpu3 -> layer0_out_proj_gpu3 [label="" style=solid]
	layer0_attn_norm_gpu4 [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 4" fillcolor=lightyellow shape=rectangle style=filled]
	add_embeddings -> layer0_attn_norm_gpu4 [label="" style=solid]
	layer0_q_proj_gpu4 [label="Q Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 4" fillcolor=lightgreen shape=rectangle style=filled]
	layer0_attn_norm_gpu4 -> layer0_q_proj_gpu4 [label="" style=solid]
	layer0_k_proj_gpu4 [label="K Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 4" fillcolor=lightgreen shape=rectangle style=filled]
	layer0_attn_norm_gpu4 -> layer0_k_proj_gpu4 [label="" style=solid]
	layer0_v_proj_gpu4 [label="V Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 4" fillcolor=lightgreen shape=rectangle style=filled]
	layer0_attn_norm_gpu4 -> layer0_v_proj_gpu4 [label="" style=solid]
	layer0_gather_q_gpu4 [label="All-Gather Q\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 4" fillcolor=lightblue shape=ellipse style=filled]
	layer0_q_proj_gpu4 -> layer0_gather_q_gpu4 [label="" style=solid]
	layer0_gather_k_gpu4 [label="All-Gather K\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 4" fillcolor=lightblue shape=ellipse style=filled]
	layer0_k_proj_gpu4 -> layer0_gather_k_gpu4 [label="" style=solid]
	layer0_gather_v_gpu4 [label="All-Gather V\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 4" fillcolor=lightblue shape=ellipse style=filled]
	layer0_v_proj_gpu4 -> layer0_gather_v_gpu4 [label="" style=solid]
	layer0_attn_scores_gpu4 [label="QK^T / sqrt(d_k)\nInput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 4" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_gather_q_gpu4 -> layer0_attn_scores_gpu4 [label="" style=solid]
	layer0_gather_k_gpu4 -> layer0_attn_scores_gpu4 [label="" style=solid]
	layer0_softmax_gpu4 [label="Softmax\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 4" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_attn_scores_gpu4 -> layer0_softmax_gpu4 [label="" style=solid]
	layer0_attn_out_gpu4 [label="Attention×V\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 4" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_softmax_gpu4 -> layer0_attn_out_gpu4 [label="" style=solid]
	layer0_gather_v_gpu4 -> layer0_attn_out_gpu4 [label="" style=solid]
	layer0_out_proj_gpu4 [label="Output Projection\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=512]\nGPU: 4" fillcolor=lightgreen shape=rectangle style=filled]
	layer0_attn_out_gpu4 -> layer0_out_proj_gpu4 [label="" style=solid]
	layer0_attn_norm_gpu5 [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 5" fillcolor=lightyellow shape=rectangle style=filled]
	add_embeddings -> layer0_attn_norm_gpu5 [label="" style=solid]
	layer0_q_proj_gpu5 [label="Q Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 5" fillcolor=lightgreen shape=rectangle style=filled]
	layer0_attn_norm_gpu5 -> layer0_q_proj_gpu5 [label="" style=solid]
	layer0_k_proj_gpu5 [label="K Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 5" fillcolor=lightgreen shape=rectangle style=filled]
	layer0_attn_norm_gpu5 -> layer0_k_proj_gpu5 [label="" style=solid]
	layer0_v_proj_gpu5 [label="V Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 5" fillcolor=lightgreen shape=rectangle style=filled]
	layer0_attn_norm_gpu5 -> layer0_v_proj_gpu5 [label="" style=solid]
	layer0_gather_q_gpu5 [label="All-Gather Q\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 5" fillcolor=lightblue shape=ellipse style=filled]
	layer0_q_proj_gpu5 -> layer0_gather_q_gpu5 [label="" style=solid]
	layer0_gather_k_gpu5 [label="All-Gather K\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 5" fillcolor=lightblue shape=ellipse style=filled]
	layer0_k_proj_gpu5 -> layer0_gather_k_gpu5 [label="" style=solid]
	layer0_gather_v_gpu5 [label="All-Gather V\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 5" fillcolor=lightblue shape=ellipse style=filled]
	layer0_v_proj_gpu5 -> layer0_gather_v_gpu5 [label="" style=solid]
	layer0_attn_scores_gpu5 [label="QK^T / sqrt(d_k)\nInput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 5" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_gather_q_gpu5 -> layer0_attn_scores_gpu5 [label="" style=solid]
	layer0_gather_k_gpu5 -> layer0_attn_scores_gpu5 [label="" style=solid]
	layer0_softmax_gpu5 [label="Softmax\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 5" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_attn_scores_gpu5 -> layer0_softmax_gpu5 [label="" style=solid]
	layer0_attn_out_gpu5 [label="Attention×V\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 5" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_softmax_gpu5 -> layer0_attn_out_gpu5 [label="" style=solid]
	layer0_gather_v_gpu5 -> layer0_attn_out_gpu5 [label="" style=solid]
	layer0_out_proj_gpu5 [label="Output Projection\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=512]\nGPU: 5" fillcolor=lightgreen shape=rectangle style=filled]
	layer0_attn_out_gpu5 -> layer0_out_proj_gpu5 [label="" style=solid]
	layer0_attn_norm_gpu6 [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 6" fillcolor=lightyellow shape=rectangle style=filled]
	add_embeddings -> layer0_attn_norm_gpu6 [label="" style=solid]
	layer0_q_proj_gpu6 [label="Q Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 6" fillcolor=lightgreen shape=rectangle style=filled]
	layer0_attn_norm_gpu6 -> layer0_q_proj_gpu6 [label="" style=solid]
	layer0_k_proj_gpu6 [label="K Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 6" fillcolor=lightgreen shape=rectangle style=filled]
	layer0_attn_norm_gpu6 -> layer0_k_proj_gpu6 [label="" style=solid]
	layer0_v_proj_gpu6 [label="V Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 6" fillcolor=lightgreen shape=rectangle style=filled]
	layer0_attn_norm_gpu6 -> layer0_v_proj_gpu6 [label="" style=solid]
	layer0_gather_q_gpu6 [label="All-Gather Q\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 6" fillcolor=lightblue shape=ellipse style=filled]
	layer0_q_proj_gpu6 -> layer0_gather_q_gpu6 [label="" style=solid]
	layer0_gather_k_gpu6 [label="All-Gather K\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 6" fillcolor=lightblue shape=ellipse style=filled]
	layer0_k_proj_gpu6 -> layer0_gather_k_gpu6 [label="" style=solid]
	layer0_gather_v_gpu6 [label="All-Gather V\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 6" fillcolor=lightblue shape=ellipse style=filled]
	layer0_v_proj_gpu6 -> layer0_gather_v_gpu6 [label="" style=solid]
	layer0_attn_scores_gpu6 [label="QK^T / sqrt(d_k)\nInput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 6" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_gather_q_gpu6 -> layer0_attn_scores_gpu6 [label="" style=solid]
	layer0_gather_k_gpu6 -> layer0_attn_scores_gpu6 [label="" style=solid]
	layer0_softmax_gpu6 [label="Softmax\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 6" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_attn_scores_gpu6 -> layer0_softmax_gpu6 [label="" style=solid]
	layer0_attn_out_gpu6 [label="Attention×V\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 6" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_softmax_gpu6 -> layer0_attn_out_gpu6 [label="" style=solid]
	layer0_gather_v_gpu6 -> layer0_attn_out_gpu6 [label="" style=solid]
	layer0_out_proj_gpu6 [label="Output Projection\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=512]\nGPU: 6" fillcolor=lightgreen shape=rectangle style=filled]
	layer0_attn_out_gpu6 -> layer0_out_proj_gpu6 [label="" style=solid]
	layer0_attn_norm_gpu7 [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 7" fillcolor=lightyellow shape=rectangle style=filled]
	add_embeddings -> layer0_attn_norm_gpu7 [label="" style=solid]
	layer0_q_proj_gpu7 [label="Q Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 7" fillcolor=lightgreen shape=rectangle style=filled]
	layer0_attn_norm_gpu7 -> layer0_q_proj_gpu7 [label="" style=solid]
	layer0_k_proj_gpu7 [label="K Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 7" fillcolor=lightgreen shape=rectangle style=filled]
	layer0_attn_norm_gpu7 -> layer0_k_proj_gpu7 [label="" style=solid]
	layer0_v_proj_gpu7 [label="V Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 7" fillcolor=lightgreen shape=rectangle style=filled]
	layer0_attn_norm_gpu7 -> layer0_v_proj_gpu7 [label="" style=solid]
	layer0_gather_q_gpu7 [label="All-Gather Q\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 7" fillcolor=lightblue shape=ellipse style=filled]
	layer0_q_proj_gpu7 -> layer0_gather_q_gpu7 [label="" style=solid]
	layer0_gather_k_gpu7 [label="All-Gather K\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 7" fillcolor=lightblue shape=ellipse style=filled]
	layer0_k_proj_gpu7 -> layer0_gather_k_gpu7 [label="" style=solid]
	layer0_gather_v_gpu7 [label="All-Gather V\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 7" fillcolor=lightblue shape=ellipse style=filled]
	layer0_v_proj_gpu7 -> layer0_gather_v_gpu7 [label="" style=solid]
	layer0_attn_scores_gpu7 [label="QK^T / sqrt(d_k)\nInput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 7" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_gather_q_gpu7 -> layer0_attn_scores_gpu7 [label="" style=solid]
	layer0_gather_k_gpu7 -> layer0_attn_scores_gpu7 [label="" style=solid]
	layer0_softmax_gpu7 [label="Softmax\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 7" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_attn_scores_gpu7 -> layer0_softmax_gpu7 [label="" style=solid]
	layer0_attn_out_gpu7 [label="Attention×V\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 7" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_softmax_gpu7 -> layer0_attn_out_gpu7 [label="" style=solid]
	layer0_gather_v_gpu7 -> layer0_attn_out_gpu7 [label="" style=solid]
	layer0_out_proj_gpu7 [label="Output Projection\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=512]\nGPU: 7" fillcolor=lightgreen shape=rectangle style=filled]
	layer0_attn_out_gpu7 -> layer0_out_proj_gpu7 [label="" style=solid]
	layer0_attn_all_reduce [label="All-Reduce Attention\nInput: 8×[512]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: GPUs 0-7" fillcolor=lightblue shape=ellipse style=filled]
	layer0_out_proj_gpu0 -> layer0_attn_all_reduce [label="" style=solid]
	layer0_out_proj_gpu1 -> layer0_attn_all_reduce [label="" style=solid]
	layer0_out_proj_gpu2 -> layer0_attn_all_reduce [label="" style=solid]
	layer0_out_proj_gpu3 -> layer0_attn_all_reduce [label="" style=solid]
	layer0_out_proj_gpu4 -> layer0_attn_all_reduce [label="" style=solid]
	layer0_out_proj_gpu5 -> layer0_attn_all_reduce [label="" style=solid]
	layer0_out_proj_gpu6 -> layer0_attn_all_reduce [label="" style=solid]
	layer0_out_proj_gpu7 -> layer0_attn_all_reduce [label="" style=solid]
	layer0_attn_residual [label="Residual Add\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096], [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: all GPUs" fillcolor=lightblue shape=ellipse style=filled]
	add_embeddings -> layer0_attn_residual [label="" style=solid]
	layer0_attn_all_reduce -> layer0_attn_residual [label="" style=solid]
	layer0_broadcast_to_moe [label="Broadcast to MoE GPUs\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: GPUs 8-15" fillcolor=lightblue shape=ellipse style=filled]
	layer0_attn_residual -> layer0_broadcast_to_moe [label="" style=solid]
	layer0_moe_norm [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: all GPUs" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_broadcast_to_moe -> layer0_moe_norm [label="" style=solid]
	layer0_gate [label="Gate Network\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, experts=16]\nGPU: all GPUs" fillcolor=lightpink shape=parallelogram style=filled]
	layer0_moe_norm -> layer0_gate [label="" style=solid]
	layer0_route_expert0 [label="Route to Expert 0\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 8" fillcolor=lightpink shape=parallelogram style=filled]
	layer0_gate -> layer0_route_expert0 [label="" style=dashed]
	layer0_moe_norm -> layer0_route_expert0 [label="" style=solid]
	layer0_expert0_up [label="Expert 0 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 8" fillcolor=lightcoral shape=rectangle style=filled]
	layer0_route_expert0 -> layer0_expert0_up [label="" style=solid]
	layer0_expert0_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 8" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_expert0_up -> layer0_expert0_activation [label="" style=solid]
	layer0_expert0_down [label="Expert 0 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 8" fillcolor=lightcoral shape=rectangle style=filled]
	layer0_expert0_activation -> layer0_expert0_down [label="" style=solid]
	layer0_route_back_expert0 [label="Route Back Expert 0\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 8" fillcolor=lightpink shape=parallelogram style=filled]
	layer0_expert0_down -> layer0_route_back_expert0 [label="" style=solid]
	layer0_route_expert1 [label="Route to Expert 1\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 8" fillcolor=lightpink shape=parallelogram style=filled]
	layer0_gate -> layer0_route_expert1 [label="" style=dashed]
	layer0_moe_norm -> layer0_route_expert1 [label="" style=solid]
	layer0_expert1_up [label="Expert 1 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 8" fillcolor=lightcoral shape=rectangle style=filled]
	layer0_route_expert1 -> layer0_expert1_up [label="" style=solid]
	layer0_expert1_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 8" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_expert1_up -> layer0_expert1_activation [label="" style=solid]
	layer0_expert1_down [label="Expert 1 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 8" fillcolor=lightcoral shape=rectangle style=filled]
	layer0_expert1_activation -> layer0_expert1_down [label="" style=solid]
	layer0_route_back_expert1 [label="Route Back Expert 1\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 8" fillcolor=lightpink shape=parallelogram style=filled]
	layer0_expert1_down -> layer0_route_back_expert1 [label="" style=solid]
	layer0_route_expert2 [label="Route to Expert 2\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 9" fillcolor=lightpink shape=parallelogram style=filled]
	layer0_gate -> layer0_route_expert2 [label="" style=dashed]
	layer0_moe_norm -> layer0_route_expert2 [label="" style=solid]
	layer0_expert2_up [label="Expert 2 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 9" fillcolor=lightcoral shape=rectangle style=filled]
	layer0_route_expert2 -> layer0_expert2_up [label="" style=solid]
	layer0_expert2_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 9" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_expert2_up -> layer0_expert2_activation [label="" style=solid]
	layer0_expert2_down [label="Expert 2 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 9" fillcolor=lightcoral shape=rectangle style=filled]
	layer0_expert2_activation -> layer0_expert2_down [label="" style=solid]
	layer0_route_back_expert2 [label="Route Back Expert 2\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 9" fillcolor=lightpink shape=parallelogram style=filled]
	layer0_expert2_down -> layer0_route_back_expert2 [label="" style=solid]
	layer0_route_expert3 [label="Route to Expert 3\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 9" fillcolor=lightpink shape=parallelogram style=filled]
	layer0_gate -> layer0_route_expert3 [label="" style=dashed]
	layer0_moe_norm -> layer0_route_expert3 [label="" style=solid]
	layer0_expert3_up [label="Expert 3 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 9" fillcolor=lightcoral shape=rectangle style=filled]
	layer0_route_expert3 -> layer0_expert3_up [label="" style=solid]
	layer0_expert3_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 9" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_expert3_up -> layer0_expert3_activation [label="" style=solid]
	layer0_expert3_down [label="Expert 3 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 9" fillcolor=lightcoral shape=rectangle style=filled]
	layer0_expert3_activation -> layer0_expert3_down [label="" style=solid]
	layer0_route_back_expert3 [label="Route Back Expert 3\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 9" fillcolor=lightpink shape=parallelogram style=filled]
	layer0_expert3_down -> layer0_route_back_expert3 [label="" style=solid]
	layer0_route_expert4 [label="Route to Expert 4\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 10" fillcolor=lightpink shape=parallelogram style=filled]
	layer0_gate -> layer0_route_expert4 [label="" style=dashed]
	layer0_moe_norm -> layer0_route_expert4 [label="" style=solid]
	layer0_expert4_up [label="Expert 4 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 10" fillcolor=lightcoral shape=rectangle style=filled]
	layer0_route_expert4 -> layer0_expert4_up [label="" style=solid]
	layer0_expert4_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 10" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_expert4_up -> layer0_expert4_activation [label="" style=solid]
	layer0_expert4_down [label="Expert 4 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 10" fillcolor=lightcoral shape=rectangle style=filled]
	layer0_expert4_activation -> layer0_expert4_down [label="" style=solid]
	layer0_route_back_expert4 [label="Route Back Expert 4\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 10" fillcolor=lightpink shape=parallelogram style=filled]
	layer0_expert4_down -> layer0_route_back_expert4 [label="" style=solid]
	layer0_route_expert5 [label="Route to Expert 5\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 10" fillcolor=lightpink shape=parallelogram style=filled]
	layer0_gate -> layer0_route_expert5 [label="" style=dashed]
	layer0_moe_norm -> layer0_route_expert5 [label="" style=solid]
	layer0_expert5_up [label="Expert 5 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 10" fillcolor=lightcoral shape=rectangle style=filled]
	layer0_route_expert5 -> layer0_expert5_up [label="" style=solid]
	layer0_expert5_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 10" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_expert5_up -> layer0_expert5_activation [label="" style=solid]
	layer0_expert5_down [label="Expert 5 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 10" fillcolor=lightcoral shape=rectangle style=filled]
	layer0_expert5_activation -> layer0_expert5_down [label="" style=solid]
	layer0_route_back_expert5 [label="Route Back Expert 5\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 10" fillcolor=lightpink shape=parallelogram style=filled]
	layer0_expert5_down -> layer0_route_back_expert5 [label="" style=solid]
	layer0_route_expert6 [label="Route to Expert 6\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 11" fillcolor=lightpink shape=parallelogram style=filled]
	layer0_gate -> layer0_route_expert6 [label="" style=dashed]
	layer0_moe_norm -> layer0_route_expert6 [label="" style=solid]
	layer0_expert6_up [label="Expert 6 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 11" fillcolor=lightcoral shape=rectangle style=filled]
	layer0_route_expert6 -> layer0_expert6_up [label="" style=solid]
	layer0_expert6_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 11" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_expert6_up -> layer0_expert6_activation [label="" style=solid]
	layer0_expert6_down [label="Expert 6 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 11" fillcolor=lightcoral shape=rectangle style=filled]
	layer0_expert6_activation -> layer0_expert6_down [label="" style=solid]
	layer0_route_back_expert6 [label="Route Back Expert 6\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 11" fillcolor=lightpink shape=parallelogram style=filled]
	layer0_expert6_down -> layer0_route_back_expert6 [label="" style=solid]
	layer0_route_expert7 [label="Route to Expert 7\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 11" fillcolor=lightpink shape=parallelogram style=filled]
	layer0_gate -> layer0_route_expert7 [label="" style=dashed]
	layer0_moe_norm -> layer0_route_expert7 [label="" style=solid]
	layer0_expert7_up [label="Expert 7 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 11" fillcolor=lightcoral shape=rectangle style=filled]
	layer0_route_expert7 -> layer0_expert7_up [label="" style=solid]
	layer0_expert7_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 11" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_expert7_up -> layer0_expert7_activation [label="" style=solid]
	layer0_expert7_down [label="Expert 7 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 11" fillcolor=lightcoral shape=rectangle style=filled]
	layer0_expert7_activation -> layer0_expert7_down [label="" style=solid]
	layer0_route_back_expert7 [label="Route Back Expert 7\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 11" fillcolor=lightpink shape=parallelogram style=filled]
	layer0_expert7_down -> layer0_route_back_expert7 [label="" style=solid]
	layer0_route_expert8 [label="Route to Expert 8\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 12" fillcolor=lightpink shape=parallelogram style=filled]
	layer0_gate -> layer0_route_expert8 [label="" style=dashed]
	layer0_moe_norm -> layer0_route_expert8 [label="" style=solid]
	layer0_expert8_up [label="Expert 8 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 12" fillcolor=lightcoral shape=rectangle style=filled]
	layer0_route_expert8 -> layer0_expert8_up [label="" style=solid]
	layer0_expert8_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 12" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_expert8_up -> layer0_expert8_activation [label="" style=solid]
	layer0_expert8_down [label="Expert 8 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 12" fillcolor=lightcoral shape=rectangle style=filled]
	layer0_expert8_activation -> layer0_expert8_down [label="" style=solid]
	layer0_route_back_expert8 [label="Route Back Expert 8\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 12" fillcolor=lightpink shape=parallelogram style=filled]
	layer0_expert8_down -> layer0_route_back_expert8 [label="" style=solid]
	layer0_route_expert9 [label="Route to Expert 9\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 12" fillcolor=lightpink shape=parallelogram style=filled]
	layer0_gate -> layer0_route_expert9 [label="" style=dashed]
	layer0_moe_norm -> layer0_route_expert9 [label="" style=solid]
	layer0_expert9_up [label="Expert 9 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 12" fillcolor=lightcoral shape=rectangle style=filled]
	layer0_route_expert9 -> layer0_expert9_up [label="" style=solid]
	layer0_expert9_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 12" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_expert9_up -> layer0_expert9_activation [label="" style=solid]
	layer0_expert9_down [label="Expert 9 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 12" fillcolor=lightcoral shape=rectangle style=filled]
	layer0_expert9_activation -> layer0_expert9_down [label="" style=solid]
	layer0_route_back_expert9 [label="Route Back Expert 9\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 12" fillcolor=lightpink shape=parallelogram style=filled]
	layer0_expert9_down -> layer0_route_back_expert9 [label="" style=solid]
	layer0_route_expert10 [label="Route to Expert 10\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 13" fillcolor=lightpink shape=parallelogram style=filled]
	layer0_gate -> layer0_route_expert10 [label="" style=dashed]
	layer0_moe_norm -> layer0_route_expert10 [label="" style=solid]
	layer0_expert10_up [label="Expert 10 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 13" fillcolor=lightcoral shape=rectangle style=filled]
	layer0_route_expert10 -> layer0_expert10_up [label="" style=solid]
	layer0_expert10_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 13" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_expert10_up -> layer0_expert10_activation [label="" style=solid]
	layer0_expert10_down [label="Expert 10 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 13" fillcolor=lightcoral shape=rectangle style=filled]
	layer0_expert10_activation -> layer0_expert10_down [label="" style=solid]
	layer0_route_back_expert10 [label="Route Back Expert 10\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 13" fillcolor=lightpink shape=parallelogram style=filled]
	layer0_expert10_down -> layer0_route_back_expert10 [label="" style=solid]
	layer0_route_expert11 [label="Route to Expert 11\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 13" fillcolor=lightpink shape=parallelogram style=filled]
	layer0_gate -> layer0_route_expert11 [label="" style=dashed]
	layer0_moe_norm -> layer0_route_expert11 [label="" style=solid]
	layer0_expert11_up [label="Expert 11 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 13" fillcolor=lightcoral shape=rectangle style=filled]
	layer0_route_expert11 -> layer0_expert11_up [label="" style=solid]
	layer0_expert11_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 13" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_expert11_up -> layer0_expert11_activation [label="" style=solid]
	layer0_expert11_down [label="Expert 11 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 13" fillcolor=lightcoral shape=rectangle style=filled]
	layer0_expert11_activation -> layer0_expert11_down [label="" style=solid]
	layer0_route_back_expert11 [label="Route Back Expert 11\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 13" fillcolor=lightpink shape=parallelogram style=filled]
	layer0_expert11_down -> layer0_route_back_expert11 [label="" style=solid]
	layer0_route_expert12 [label="Route to Expert 12\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 14" fillcolor=lightpink shape=parallelogram style=filled]
	layer0_gate -> layer0_route_expert12 [label="" style=dashed]
	layer0_moe_norm -> layer0_route_expert12 [label="" style=solid]
	layer0_expert12_up [label="Expert 12 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 14" fillcolor=lightcoral shape=rectangle style=filled]
	layer0_route_expert12 -> layer0_expert12_up [label="" style=solid]
	layer0_expert12_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 14" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_expert12_up -> layer0_expert12_activation [label="" style=solid]
	layer0_expert12_down [label="Expert 12 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 14" fillcolor=lightcoral shape=rectangle style=filled]
	layer0_expert12_activation -> layer0_expert12_down [label="" style=solid]
	layer0_route_back_expert12 [label="Route Back Expert 12\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 14" fillcolor=lightpink shape=parallelogram style=filled]
	layer0_expert12_down -> layer0_route_back_expert12 [label="" style=solid]
	layer0_route_expert13 [label="Route to Expert 13\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 14" fillcolor=lightpink shape=parallelogram style=filled]
	layer0_gate -> layer0_route_expert13 [label="" style=dashed]
	layer0_moe_norm -> layer0_route_expert13 [label="" style=solid]
	layer0_expert13_up [label="Expert 13 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 14" fillcolor=lightcoral shape=rectangle style=filled]
	layer0_route_expert13 -> layer0_expert13_up [label="" style=solid]
	layer0_expert13_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 14" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_expert13_up -> layer0_expert13_activation [label="" style=solid]
	layer0_expert13_down [label="Expert 13 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 14" fillcolor=lightcoral shape=rectangle style=filled]
	layer0_expert13_activation -> layer0_expert13_down [label="" style=solid]
	layer0_route_back_expert13 [label="Route Back Expert 13\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 14" fillcolor=lightpink shape=parallelogram style=filled]
	layer0_expert13_down -> layer0_route_back_expert13 [label="" style=solid]
	layer0_route_expert14 [label="Route to Expert 14\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 15" fillcolor=lightpink shape=parallelogram style=filled]
	layer0_gate -> layer0_route_expert14 [label="" style=dashed]
	layer0_moe_norm -> layer0_route_expert14 [label="" style=solid]
	layer0_expert14_up [label="Expert 14 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 15" fillcolor=lightcoral shape=rectangle style=filled]
	layer0_route_expert14 -> layer0_expert14_up [label="" style=solid]
	layer0_expert14_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 15" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_expert14_up -> layer0_expert14_activation [label="" style=solid]
	layer0_expert14_down [label="Expert 14 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 15" fillcolor=lightcoral shape=rectangle style=filled]
	layer0_expert14_activation -> layer0_expert14_down [label="" style=solid]
	layer0_route_back_expert14 [label="Route Back Expert 14\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 15" fillcolor=lightpink shape=parallelogram style=filled]
	layer0_expert14_down -> layer0_route_back_expert14 [label="" style=solid]
	layer0_route_expert15 [label="Route to Expert 15\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 15" fillcolor=lightpink shape=parallelogram style=filled]
	layer0_gate -> layer0_route_expert15 [label="" style=dashed]
	layer0_moe_norm -> layer0_route_expert15 [label="" style=solid]
	layer0_expert15_up [label="Expert 15 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 15" fillcolor=lightcoral shape=rectangle style=filled]
	layer0_route_expert15 -> layer0_expert15_up [label="" style=solid]
	layer0_expert15_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 15" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_expert15_up -> layer0_expert15_activation [label="" style=solid]
	layer0_expert15_down [label="Expert 15 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 15" fillcolor=lightcoral shape=rectangle style=filled]
	layer0_expert15_activation -> layer0_expert15_down [label="" style=solid]
	layer0_route_back_expert15 [label="Route Back Expert 15\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 15" fillcolor=lightpink shape=parallelogram style=filled]
	layer0_expert15_down -> layer0_route_back_expert15 [label="" style=solid]
	layer0_expert_agg [label="Aggregate Experts\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: all GPUs" fillcolor=lightblue shape=ellipse style=filled]
	layer0_route_back_expert0 -> layer0_expert_agg [label="" style=solid]
	layer0_route_back_expert1 -> layer0_expert_agg [label="" style=solid]
	layer0_route_back_expert2 -> layer0_expert_agg [label="" style=solid]
	layer0_route_back_expert3 -> layer0_expert_agg [label="" style=solid]
	layer0_route_back_expert4 -> layer0_expert_agg [label="" style=solid]
	layer0_route_back_expert5 -> layer0_expert_agg [label="" style=solid]
	layer0_route_back_expert6 -> layer0_expert_agg [label="" style=solid]
	layer0_route_back_expert7 -> layer0_expert_agg [label="" style=solid]
	layer0_route_back_expert8 -> layer0_expert_agg [label="" style=solid]
	layer0_route_back_expert9 -> layer0_expert_agg [label="" style=solid]
	layer0_route_back_expert10 -> layer0_expert_agg [label="" style=solid]
	layer0_route_back_expert11 -> layer0_expert_agg [label="" style=solid]
	layer0_route_back_expert12 -> layer0_expert_agg [label="" style=solid]
	layer0_route_back_expert13 -> layer0_expert_agg [label="" style=solid]
	layer0_route_back_expert14 -> layer0_expert_agg [label="" style=solid]
	layer0_route_back_expert15 -> layer0_expert_agg [label="" style=solid]
	layer0_final_residual [label="Final Residual Add\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096], [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: all GPUs" fillcolor=lightblue shape=ellipse style=filled]
	layer0_attn_residual -> layer0_final_residual [label="" style=solid]
	layer0_expert_agg -> layer0_final_residual [label="" style=solid]
	layer1_attn_norm_gpu0 [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 0" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_final_residual -> layer1_attn_norm_gpu0 [label="" style=solid]
	layer1_q_proj_gpu0 [label="Q Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 0" fillcolor=lightgreen shape=rectangle style=filled]
	layer1_attn_norm_gpu0 -> layer1_q_proj_gpu0 [label="" style=solid]
	layer1_k_proj_gpu0 [label="K Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 0" fillcolor=lightgreen shape=rectangle style=filled]
	layer1_attn_norm_gpu0 -> layer1_k_proj_gpu0 [label="" style=solid]
	layer1_v_proj_gpu0 [label="V Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 0" fillcolor=lightgreen shape=rectangle style=filled]
	layer1_attn_norm_gpu0 -> layer1_v_proj_gpu0 [label="" style=solid]
	layer1_gather_q_gpu0 [label="All-Gather Q\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 0" fillcolor=lightblue shape=ellipse style=filled]
	layer1_q_proj_gpu0 -> layer1_gather_q_gpu0 [label="" style=solid]
	layer1_gather_k_gpu0 [label="All-Gather K\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 0" fillcolor=lightblue shape=ellipse style=filled]
	layer1_k_proj_gpu0 -> layer1_gather_k_gpu0 [label="" style=solid]
	layer1_gather_v_gpu0 [label="All-Gather V\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 0" fillcolor=lightblue shape=ellipse style=filled]
	layer1_v_proj_gpu0 -> layer1_gather_v_gpu0 [label="" style=solid]
	layer1_attn_scores_gpu0 [label="QK^T / sqrt(d_k)\nInput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 0" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_gather_q_gpu0 -> layer1_attn_scores_gpu0 [label="" style=solid]
	layer1_gather_k_gpu0 -> layer1_attn_scores_gpu0 [label="" style=solid]
	layer1_softmax_gpu0 [label="Softmax\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 0" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_attn_scores_gpu0 -> layer1_softmax_gpu0 [label="" style=solid]
	layer1_attn_out_gpu0 [label="Attention×V\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 0" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_softmax_gpu0 -> layer1_attn_out_gpu0 [label="" style=solid]
	layer1_gather_v_gpu0 -> layer1_attn_out_gpu0 [label="" style=solid]
	layer1_out_proj_gpu0 [label="Output Projection\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=512]\nGPU: 0" fillcolor=lightgreen shape=rectangle style=filled]
	layer1_attn_out_gpu0 -> layer1_out_proj_gpu0 [label="" style=solid]
	layer1_attn_norm_gpu1 [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 1" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_final_residual -> layer1_attn_norm_gpu1 [label="" style=solid]
	layer1_q_proj_gpu1 [label="Q Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 1" fillcolor=lightgreen shape=rectangle style=filled]
	layer1_attn_norm_gpu1 -> layer1_q_proj_gpu1 [label="" style=solid]
	layer1_k_proj_gpu1 [label="K Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 1" fillcolor=lightgreen shape=rectangle style=filled]
	layer1_attn_norm_gpu1 -> layer1_k_proj_gpu1 [label="" style=solid]
	layer1_v_proj_gpu1 [label="V Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 1" fillcolor=lightgreen shape=rectangle style=filled]
	layer1_attn_norm_gpu1 -> layer1_v_proj_gpu1 [label="" style=solid]
	layer1_gather_q_gpu1 [label="All-Gather Q\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 1" fillcolor=lightblue shape=ellipse style=filled]
	layer1_q_proj_gpu1 -> layer1_gather_q_gpu1 [label="" style=solid]
	layer1_gather_k_gpu1 [label="All-Gather K\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 1" fillcolor=lightblue shape=ellipse style=filled]
	layer1_k_proj_gpu1 -> layer1_gather_k_gpu1 [label="" style=solid]
	layer1_gather_v_gpu1 [label="All-Gather V\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 1" fillcolor=lightblue shape=ellipse style=filled]
	layer1_v_proj_gpu1 -> layer1_gather_v_gpu1 [label="" style=solid]
	layer1_attn_scores_gpu1 [label="QK^T / sqrt(d_k)\nInput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 1" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_gather_q_gpu1 -> layer1_attn_scores_gpu1 [label="" style=solid]
	layer1_gather_k_gpu1 -> layer1_attn_scores_gpu1 [label="" style=solid]
	layer1_softmax_gpu1 [label="Softmax\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 1" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_attn_scores_gpu1 -> layer1_softmax_gpu1 [label="" style=solid]
	layer1_attn_out_gpu1 [label="Attention×V\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 1" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_softmax_gpu1 -> layer1_attn_out_gpu1 [label="" style=solid]
	layer1_gather_v_gpu1 -> layer1_attn_out_gpu1 [label="" style=solid]
	layer1_out_proj_gpu1 [label="Output Projection\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=512]\nGPU: 1" fillcolor=lightgreen shape=rectangle style=filled]
	layer1_attn_out_gpu1 -> layer1_out_proj_gpu1 [label="" style=solid]
	layer1_attn_norm_gpu2 [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 2" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_final_residual -> layer1_attn_norm_gpu2 [label="" style=solid]
	layer1_q_proj_gpu2 [label="Q Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 2" fillcolor=lightgreen shape=rectangle style=filled]
	layer1_attn_norm_gpu2 -> layer1_q_proj_gpu2 [label="" style=solid]
	layer1_k_proj_gpu2 [label="K Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 2" fillcolor=lightgreen shape=rectangle style=filled]
	layer1_attn_norm_gpu2 -> layer1_k_proj_gpu2 [label="" style=solid]
	layer1_v_proj_gpu2 [label="V Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 2" fillcolor=lightgreen shape=rectangle style=filled]
	layer1_attn_norm_gpu2 -> layer1_v_proj_gpu2 [label="" style=solid]
	layer1_gather_q_gpu2 [label="All-Gather Q\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 2" fillcolor=lightblue shape=ellipse style=filled]
	layer1_q_proj_gpu2 -> layer1_gather_q_gpu2 [label="" style=solid]
	layer1_gather_k_gpu2 [label="All-Gather K\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 2" fillcolor=lightblue shape=ellipse style=filled]
	layer1_k_proj_gpu2 -> layer1_gather_k_gpu2 [label="" style=solid]
	layer1_gather_v_gpu2 [label="All-Gather V\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 2" fillcolor=lightblue shape=ellipse style=filled]
	layer1_v_proj_gpu2 -> layer1_gather_v_gpu2 [label="" style=solid]
	layer1_attn_scores_gpu2 [label="QK^T / sqrt(d_k)\nInput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 2" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_gather_q_gpu2 -> layer1_attn_scores_gpu2 [label="" style=solid]
	layer1_gather_k_gpu2 -> layer1_attn_scores_gpu2 [label="" style=solid]
	layer1_softmax_gpu2 [label="Softmax\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 2" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_attn_scores_gpu2 -> layer1_softmax_gpu2 [label="" style=solid]
	layer1_attn_out_gpu2 [label="Attention×V\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 2" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_softmax_gpu2 -> layer1_attn_out_gpu2 [label="" style=solid]
	layer1_gather_v_gpu2 -> layer1_attn_out_gpu2 [label="" style=solid]
	layer1_out_proj_gpu2 [label="Output Projection\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=512]\nGPU: 2" fillcolor=lightgreen shape=rectangle style=filled]
	layer1_attn_out_gpu2 -> layer1_out_proj_gpu2 [label="" style=solid]
	layer1_attn_norm_gpu3 [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 3" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_final_residual -> layer1_attn_norm_gpu3 [label="" style=solid]
	layer1_q_proj_gpu3 [label="Q Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 3" fillcolor=lightgreen shape=rectangle style=filled]
	layer1_attn_norm_gpu3 -> layer1_q_proj_gpu3 [label="" style=solid]
	layer1_k_proj_gpu3 [label="K Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 3" fillcolor=lightgreen shape=rectangle style=filled]
	layer1_attn_norm_gpu3 -> layer1_k_proj_gpu3 [label="" style=solid]
	layer1_v_proj_gpu3 [label="V Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 3" fillcolor=lightgreen shape=rectangle style=filled]
	layer1_attn_norm_gpu3 -> layer1_v_proj_gpu3 [label="" style=solid]
	layer1_gather_q_gpu3 [label="All-Gather Q\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 3" fillcolor=lightblue shape=ellipse style=filled]
	layer1_q_proj_gpu3 -> layer1_gather_q_gpu3 [label="" style=solid]
	layer1_gather_k_gpu3 [label="All-Gather K\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 3" fillcolor=lightblue shape=ellipse style=filled]
	layer1_k_proj_gpu3 -> layer1_gather_k_gpu3 [label="" style=solid]
	layer1_gather_v_gpu3 [label="All-Gather V\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 3" fillcolor=lightblue shape=ellipse style=filled]
	layer1_v_proj_gpu3 -> layer1_gather_v_gpu3 [label="" style=solid]
	layer1_attn_scores_gpu3 [label="QK^T / sqrt(d_k)\nInput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 3" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_gather_q_gpu3 -> layer1_attn_scores_gpu3 [label="" style=solid]
	layer1_gather_k_gpu3 -> layer1_attn_scores_gpu3 [label="" style=solid]
	layer1_softmax_gpu3 [label="Softmax\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 3" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_attn_scores_gpu3 -> layer1_softmax_gpu3 [label="" style=solid]
	layer1_attn_out_gpu3 [label="Attention×V\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 3" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_softmax_gpu3 -> layer1_attn_out_gpu3 [label="" style=solid]
	layer1_gather_v_gpu3 -> layer1_attn_out_gpu3 [label="" style=solid]
	layer1_out_proj_gpu3 [label="Output Projection\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=512]\nGPU: 3" fillcolor=lightgreen shape=rectangle style=filled]
	layer1_attn_out_gpu3 -> layer1_out_proj_gpu3 [label="" style=solid]
	layer1_attn_norm_gpu4 [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 4" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_final_residual -> layer1_attn_norm_gpu4 [label="" style=solid]
	layer1_q_proj_gpu4 [label="Q Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 4" fillcolor=lightgreen shape=rectangle style=filled]
	layer1_attn_norm_gpu4 -> layer1_q_proj_gpu4 [label="" style=solid]
	layer1_k_proj_gpu4 [label="K Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 4" fillcolor=lightgreen shape=rectangle style=filled]
	layer1_attn_norm_gpu4 -> layer1_k_proj_gpu4 [label="" style=solid]
	layer1_v_proj_gpu4 [label="V Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 4" fillcolor=lightgreen shape=rectangle style=filled]
	layer1_attn_norm_gpu4 -> layer1_v_proj_gpu4 [label="" style=solid]
	layer1_gather_q_gpu4 [label="All-Gather Q\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 4" fillcolor=lightblue shape=ellipse style=filled]
	layer1_q_proj_gpu4 -> layer1_gather_q_gpu4 [label="" style=solid]
	layer1_gather_k_gpu4 [label="All-Gather K\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 4" fillcolor=lightblue shape=ellipse style=filled]
	layer1_k_proj_gpu4 -> layer1_gather_k_gpu4 [label="" style=solid]
	layer1_gather_v_gpu4 [label="All-Gather V\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 4" fillcolor=lightblue shape=ellipse style=filled]
	layer1_v_proj_gpu4 -> layer1_gather_v_gpu4 [label="" style=solid]
	layer1_attn_scores_gpu4 [label="QK^T / sqrt(d_k)\nInput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 4" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_gather_q_gpu4 -> layer1_attn_scores_gpu4 [label="" style=solid]
	layer1_gather_k_gpu4 -> layer1_attn_scores_gpu4 [label="" style=solid]
	layer1_softmax_gpu4 [label="Softmax\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 4" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_attn_scores_gpu4 -> layer1_softmax_gpu4 [label="" style=solid]
	layer1_attn_out_gpu4 [label="Attention×V\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 4" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_softmax_gpu4 -> layer1_attn_out_gpu4 [label="" style=solid]
	layer1_gather_v_gpu4 -> layer1_attn_out_gpu4 [label="" style=solid]
	layer1_out_proj_gpu4 [label="Output Projection\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=512]\nGPU: 4" fillcolor=lightgreen shape=rectangle style=filled]
	layer1_attn_out_gpu4 -> layer1_out_proj_gpu4 [label="" style=solid]
	layer1_attn_norm_gpu5 [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 5" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_final_residual -> layer1_attn_norm_gpu5 [label="" style=solid]
	layer1_q_proj_gpu5 [label="Q Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 5" fillcolor=lightgreen shape=rectangle style=filled]
	layer1_attn_norm_gpu5 -> layer1_q_proj_gpu5 [label="" style=solid]
	layer1_k_proj_gpu5 [label="K Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 5" fillcolor=lightgreen shape=rectangle style=filled]
	layer1_attn_norm_gpu5 -> layer1_k_proj_gpu5 [label="" style=solid]
	layer1_v_proj_gpu5 [label="V Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 5" fillcolor=lightgreen shape=rectangle style=filled]
	layer1_attn_norm_gpu5 -> layer1_v_proj_gpu5 [label="" style=solid]
	layer1_gather_q_gpu5 [label="All-Gather Q\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 5" fillcolor=lightblue shape=ellipse style=filled]
	layer1_q_proj_gpu5 -> layer1_gather_q_gpu5 [label="" style=solid]
	layer1_gather_k_gpu5 [label="All-Gather K\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 5" fillcolor=lightblue shape=ellipse style=filled]
	layer1_k_proj_gpu5 -> layer1_gather_k_gpu5 [label="" style=solid]
	layer1_gather_v_gpu5 [label="All-Gather V\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 5" fillcolor=lightblue shape=ellipse style=filled]
	layer1_v_proj_gpu5 -> layer1_gather_v_gpu5 [label="" style=solid]
	layer1_attn_scores_gpu5 [label="QK^T / sqrt(d_k)\nInput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 5" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_gather_q_gpu5 -> layer1_attn_scores_gpu5 [label="" style=solid]
	layer1_gather_k_gpu5 -> layer1_attn_scores_gpu5 [label="" style=solid]
	layer1_softmax_gpu5 [label="Softmax\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 5" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_attn_scores_gpu5 -> layer1_softmax_gpu5 [label="" style=solid]
	layer1_attn_out_gpu5 [label="Attention×V\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 5" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_softmax_gpu5 -> layer1_attn_out_gpu5 [label="" style=solid]
	layer1_gather_v_gpu5 -> layer1_attn_out_gpu5 [label="" style=solid]
	layer1_out_proj_gpu5 [label="Output Projection\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=512]\nGPU: 5" fillcolor=lightgreen shape=rectangle style=filled]
	layer1_attn_out_gpu5 -> layer1_out_proj_gpu5 [label="" style=solid]
	layer1_attn_norm_gpu6 [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 6" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_final_residual -> layer1_attn_norm_gpu6 [label="" style=solid]
	layer1_q_proj_gpu6 [label="Q Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 6" fillcolor=lightgreen shape=rectangle style=filled]
	layer1_attn_norm_gpu6 -> layer1_q_proj_gpu6 [label="" style=solid]
	layer1_k_proj_gpu6 [label="K Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 6" fillcolor=lightgreen shape=rectangle style=filled]
	layer1_attn_norm_gpu6 -> layer1_k_proj_gpu6 [label="" style=solid]
	layer1_v_proj_gpu6 [label="V Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 6" fillcolor=lightgreen shape=rectangle style=filled]
	layer1_attn_norm_gpu6 -> layer1_v_proj_gpu6 [label="" style=solid]
	layer1_gather_q_gpu6 [label="All-Gather Q\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 6" fillcolor=lightblue shape=ellipse style=filled]
	layer1_q_proj_gpu6 -> layer1_gather_q_gpu6 [label="" style=solid]
	layer1_gather_k_gpu6 [label="All-Gather K\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 6" fillcolor=lightblue shape=ellipse style=filled]
	layer1_k_proj_gpu6 -> layer1_gather_k_gpu6 [label="" style=solid]
	layer1_gather_v_gpu6 [label="All-Gather V\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 6" fillcolor=lightblue shape=ellipse style=filled]
	layer1_v_proj_gpu6 -> layer1_gather_v_gpu6 [label="" style=solid]
	layer1_attn_scores_gpu6 [label="QK^T / sqrt(d_k)\nInput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 6" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_gather_q_gpu6 -> layer1_attn_scores_gpu6 [label="" style=solid]
	layer1_gather_k_gpu6 -> layer1_attn_scores_gpu6 [label="" style=solid]
	layer1_softmax_gpu6 [label="Softmax\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 6" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_attn_scores_gpu6 -> layer1_softmax_gpu6 [label="" style=solid]
	layer1_attn_out_gpu6 [label="Attention×V\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 6" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_softmax_gpu6 -> layer1_attn_out_gpu6 [label="" style=solid]
	layer1_gather_v_gpu6 -> layer1_attn_out_gpu6 [label="" style=solid]
	layer1_out_proj_gpu6 [label="Output Projection\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=512]\nGPU: 6" fillcolor=lightgreen shape=rectangle style=filled]
	layer1_attn_out_gpu6 -> layer1_out_proj_gpu6 [label="" style=solid]
	layer1_attn_norm_gpu7 [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 7" fillcolor=lightyellow shape=rectangle style=filled]
	layer0_final_residual -> layer1_attn_norm_gpu7 [label="" style=solid]
	layer1_q_proj_gpu7 [label="Q Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 7" fillcolor=lightgreen shape=rectangle style=filled]
	layer1_attn_norm_gpu7 -> layer1_q_proj_gpu7 [label="" style=solid]
	layer1_k_proj_gpu7 [label="K Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 7" fillcolor=lightgreen shape=rectangle style=filled]
	layer1_attn_norm_gpu7 -> layer1_k_proj_gpu7 [label="" style=solid]
	layer1_v_proj_gpu7 [label="V Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 7" fillcolor=lightgreen shape=rectangle style=filled]
	layer1_attn_norm_gpu7 -> layer1_v_proj_gpu7 [label="" style=solid]
	layer1_gather_q_gpu7 [label="All-Gather Q\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 7" fillcolor=lightblue shape=ellipse style=filled]
	layer1_q_proj_gpu7 -> layer1_gather_q_gpu7 [label="" style=solid]
	layer1_gather_k_gpu7 [label="All-Gather K\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 7" fillcolor=lightblue shape=ellipse style=filled]
	layer1_k_proj_gpu7 -> layer1_gather_k_gpu7 [label="" style=solid]
	layer1_gather_v_gpu7 [label="All-Gather V\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 7" fillcolor=lightblue shape=ellipse style=filled]
	layer1_v_proj_gpu7 -> layer1_gather_v_gpu7 [label="" style=solid]
	layer1_attn_scores_gpu7 [label="QK^T / sqrt(d_k)\nInput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 7" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_gather_q_gpu7 -> layer1_attn_scores_gpu7 [label="" style=solid]
	layer1_gather_k_gpu7 -> layer1_attn_scores_gpu7 [label="" style=solid]
	layer1_softmax_gpu7 [label="Softmax\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 7" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_attn_scores_gpu7 -> layer1_softmax_gpu7 [label="" style=solid]
	layer1_attn_out_gpu7 [label="Attention×V\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 7" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_softmax_gpu7 -> layer1_attn_out_gpu7 [label="" style=solid]
	layer1_gather_v_gpu7 -> layer1_attn_out_gpu7 [label="" style=solid]
	layer1_out_proj_gpu7 [label="Output Projection\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=512]\nGPU: 7" fillcolor=lightgreen shape=rectangle style=filled]
	layer1_attn_out_gpu7 -> layer1_out_proj_gpu7 [label="" style=solid]
	layer1_attn_all_reduce [label="All-Reduce Attention\nInput: 8×[512]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: GPUs 0-7" fillcolor=lightblue shape=ellipse style=filled]
	layer1_out_proj_gpu0 -> layer1_attn_all_reduce [label="" style=solid]
	layer1_out_proj_gpu1 -> layer1_attn_all_reduce [label="" style=solid]
	layer1_out_proj_gpu2 -> layer1_attn_all_reduce [label="" style=solid]
	layer1_out_proj_gpu3 -> layer1_attn_all_reduce [label="" style=solid]
	layer1_out_proj_gpu4 -> layer1_attn_all_reduce [label="" style=solid]
	layer1_out_proj_gpu5 -> layer1_attn_all_reduce [label="" style=solid]
	layer1_out_proj_gpu6 -> layer1_attn_all_reduce [label="" style=solid]
	layer1_out_proj_gpu7 -> layer1_attn_all_reduce [label="" style=solid]
	layer1_attn_residual [label="Residual Add\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096], [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: all GPUs" fillcolor=lightblue shape=ellipse style=filled]
	layer0_final_residual -> layer1_attn_residual [label="" style=solid]
	layer1_attn_all_reduce -> layer1_attn_residual [label="" style=solid]
	layer1_broadcast_to_moe [label="Broadcast to MoE GPUs\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: GPUs 8-15" fillcolor=lightblue shape=ellipse style=filled]
	layer1_attn_residual -> layer1_broadcast_to_moe [label="" style=solid]
	layer1_moe_norm [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: all GPUs" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_broadcast_to_moe -> layer1_moe_norm [label="" style=solid]
	layer1_gate [label="Gate Network\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, experts=16]\nGPU: all GPUs" fillcolor=lightpink shape=parallelogram style=filled]
	layer1_moe_norm -> layer1_gate [label="" style=solid]
	layer1_route_expert0 [label="Route to Expert 0\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 8" fillcolor=lightpink shape=parallelogram style=filled]
	layer1_gate -> layer1_route_expert0 [label="" style=dashed]
	layer1_moe_norm -> layer1_route_expert0 [label="" style=solid]
	layer1_expert0_up [label="Expert 0 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 8" fillcolor=lightcoral shape=rectangle style=filled]
	layer1_route_expert0 -> layer1_expert0_up [label="" style=solid]
	layer1_expert0_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 8" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_expert0_up -> layer1_expert0_activation [label="" style=solid]
	layer1_expert0_down [label="Expert 0 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 8" fillcolor=lightcoral shape=rectangle style=filled]
	layer1_expert0_activation -> layer1_expert0_down [label="" style=solid]
	layer1_route_back_expert0 [label="Route Back Expert 0\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 8" fillcolor=lightpink shape=parallelogram style=filled]
	layer1_expert0_down -> layer1_route_back_expert0 [label="" style=solid]
	layer1_route_expert1 [label="Route to Expert 1\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 8" fillcolor=lightpink shape=parallelogram style=filled]
	layer1_gate -> layer1_route_expert1 [label="" style=dashed]
	layer1_moe_norm -> layer1_route_expert1 [label="" style=solid]
	layer1_expert1_up [label="Expert 1 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 8" fillcolor=lightcoral shape=rectangle style=filled]
	layer1_route_expert1 -> layer1_expert1_up [label="" style=solid]
	layer1_expert1_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 8" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_expert1_up -> layer1_expert1_activation [label="" style=solid]
	layer1_expert1_down [label="Expert 1 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 8" fillcolor=lightcoral shape=rectangle style=filled]
	layer1_expert1_activation -> layer1_expert1_down [label="" style=solid]
	layer1_route_back_expert1 [label="Route Back Expert 1\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 8" fillcolor=lightpink shape=parallelogram style=filled]
	layer1_expert1_down -> layer1_route_back_expert1 [label="" style=solid]
	layer1_route_expert2 [label="Route to Expert 2\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 9" fillcolor=lightpink shape=parallelogram style=filled]
	layer1_gate -> layer1_route_expert2 [label="" style=dashed]
	layer1_moe_norm -> layer1_route_expert2 [label="" style=solid]
	layer1_expert2_up [label="Expert 2 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 9" fillcolor=lightcoral shape=rectangle style=filled]
	layer1_route_expert2 -> layer1_expert2_up [label="" style=solid]
	layer1_expert2_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 9" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_expert2_up -> layer1_expert2_activation [label="" style=solid]
	layer1_expert2_down [label="Expert 2 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 9" fillcolor=lightcoral shape=rectangle style=filled]
	layer1_expert2_activation -> layer1_expert2_down [label="" style=solid]
	layer1_route_back_expert2 [label="Route Back Expert 2\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 9" fillcolor=lightpink shape=parallelogram style=filled]
	layer1_expert2_down -> layer1_route_back_expert2 [label="" style=solid]
	layer1_route_expert3 [label="Route to Expert 3\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 9" fillcolor=lightpink shape=parallelogram style=filled]
	layer1_gate -> layer1_route_expert3 [label="" style=dashed]
	layer1_moe_norm -> layer1_route_expert3 [label="" style=solid]
	layer1_expert3_up [label="Expert 3 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 9" fillcolor=lightcoral shape=rectangle style=filled]
	layer1_route_expert3 -> layer1_expert3_up [label="" style=solid]
	layer1_expert3_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 9" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_expert3_up -> layer1_expert3_activation [label="" style=solid]
	layer1_expert3_down [label="Expert 3 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 9" fillcolor=lightcoral shape=rectangle style=filled]
	layer1_expert3_activation -> layer1_expert3_down [label="" style=solid]
	layer1_route_back_expert3 [label="Route Back Expert 3\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 9" fillcolor=lightpink shape=parallelogram style=filled]
	layer1_expert3_down -> layer1_route_back_expert3 [label="" style=solid]
	layer1_route_expert4 [label="Route to Expert 4\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 10" fillcolor=lightpink shape=parallelogram style=filled]
	layer1_gate -> layer1_route_expert4 [label="" style=dashed]
	layer1_moe_norm -> layer1_route_expert4 [label="" style=solid]
	layer1_expert4_up [label="Expert 4 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 10" fillcolor=lightcoral shape=rectangle style=filled]
	layer1_route_expert4 -> layer1_expert4_up [label="" style=solid]
	layer1_expert4_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 10" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_expert4_up -> layer1_expert4_activation [label="" style=solid]
	layer1_expert4_down [label="Expert 4 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 10" fillcolor=lightcoral shape=rectangle style=filled]
	layer1_expert4_activation -> layer1_expert4_down [label="" style=solid]
	layer1_route_back_expert4 [label="Route Back Expert 4\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 10" fillcolor=lightpink shape=parallelogram style=filled]
	layer1_expert4_down -> layer1_route_back_expert4 [label="" style=solid]
	layer1_route_expert5 [label="Route to Expert 5\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 10" fillcolor=lightpink shape=parallelogram style=filled]
	layer1_gate -> layer1_route_expert5 [label="" style=dashed]
	layer1_moe_norm -> layer1_route_expert5 [label="" style=solid]
	layer1_expert5_up [label="Expert 5 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 10" fillcolor=lightcoral shape=rectangle style=filled]
	layer1_route_expert5 -> layer1_expert5_up [label="" style=solid]
	layer1_expert5_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 10" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_expert5_up -> layer1_expert5_activation [label="" style=solid]
	layer1_expert5_down [label="Expert 5 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 10" fillcolor=lightcoral shape=rectangle style=filled]
	layer1_expert5_activation -> layer1_expert5_down [label="" style=solid]
	layer1_route_back_expert5 [label="Route Back Expert 5\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 10" fillcolor=lightpink shape=parallelogram style=filled]
	layer1_expert5_down -> layer1_route_back_expert5 [label="" style=solid]
	layer1_route_expert6 [label="Route to Expert 6\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 11" fillcolor=lightpink shape=parallelogram style=filled]
	layer1_gate -> layer1_route_expert6 [label="" style=dashed]
	layer1_moe_norm -> layer1_route_expert6 [label="" style=solid]
	layer1_expert6_up [label="Expert 6 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 11" fillcolor=lightcoral shape=rectangle style=filled]
	layer1_route_expert6 -> layer1_expert6_up [label="" style=solid]
	layer1_expert6_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 11" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_expert6_up -> layer1_expert6_activation [label="" style=solid]
	layer1_expert6_down [label="Expert 6 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 11" fillcolor=lightcoral shape=rectangle style=filled]
	layer1_expert6_activation -> layer1_expert6_down [label="" style=solid]
	layer1_route_back_expert6 [label="Route Back Expert 6\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 11" fillcolor=lightpink shape=parallelogram style=filled]
	layer1_expert6_down -> layer1_route_back_expert6 [label="" style=solid]
	layer1_route_expert7 [label="Route to Expert 7\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 11" fillcolor=lightpink shape=parallelogram style=filled]
	layer1_gate -> layer1_route_expert7 [label="" style=dashed]
	layer1_moe_norm -> layer1_route_expert7 [label="" style=solid]
	layer1_expert7_up [label="Expert 7 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 11" fillcolor=lightcoral shape=rectangle style=filled]
	layer1_route_expert7 -> layer1_expert7_up [label="" style=solid]
	layer1_expert7_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 11" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_expert7_up -> layer1_expert7_activation [label="" style=solid]
	layer1_expert7_down [label="Expert 7 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 11" fillcolor=lightcoral shape=rectangle style=filled]
	layer1_expert7_activation -> layer1_expert7_down [label="" style=solid]
	layer1_route_back_expert7 [label="Route Back Expert 7\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 11" fillcolor=lightpink shape=parallelogram style=filled]
	layer1_expert7_down -> layer1_route_back_expert7 [label="" style=solid]
	layer1_route_expert8 [label="Route to Expert 8\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 12" fillcolor=lightpink shape=parallelogram style=filled]
	layer1_gate -> layer1_route_expert8 [label="" style=dashed]
	layer1_moe_norm -> layer1_route_expert8 [label="" style=solid]
	layer1_expert8_up [label="Expert 8 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 12" fillcolor=lightcoral shape=rectangle style=filled]
	layer1_route_expert8 -> layer1_expert8_up [label="" style=solid]
	layer1_expert8_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 12" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_expert8_up -> layer1_expert8_activation [label="" style=solid]
	layer1_expert8_down [label="Expert 8 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 12" fillcolor=lightcoral shape=rectangle style=filled]
	layer1_expert8_activation -> layer1_expert8_down [label="" style=solid]
	layer1_route_back_expert8 [label="Route Back Expert 8\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 12" fillcolor=lightpink shape=parallelogram style=filled]
	layer1_expert8_down -> layer1_route_back_expert8 [label="" style=solid]
	layer1_route_expert9 [label="Route to Expert 9\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 12" fillcolor=lightpink shape=parallelogram style=filled]
	layer1_gate -> layer1_route_expert9 [label="" style=dashed]
	layer1_moe_norm -> layer1_route_expert9 [label="" style=solid]
	layer1_expert9_up [label="Expert 9 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 12" fillcolor=lightcoral shape=rectangle style=filled]
	layer1_route_expert9 -> layer1_expert9_up [label="" style=solid]
	layer1_expert9_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 12" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_expert9_up -> layer1_expert9_activation [label="" style=solid]
	layer1_expert9_down [label="Expert 9 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 12" fillcolor=lightcoral shape=rectangle style=filled]
	layer1_expert9_activation -> layer1_expert9_down [label="" style=solid]
	layer1_route_back_expert9 [label="Route Back Expert 9\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 12" fillcolor=lightpink shape=parallelogram style=filled]
	layer1_expert9_down -> layer1_route_back_expert9 [label="" style=solid]
	layer1_route_expert10 [label="Route to Expert 10\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 13" fillcolor=lightpink shape=parallelogram style=filled]
	layer1_gate -> layer1_route_expert10 [label="" style=dashed]
	layer1_moe_norm -> layer1_route_expert10 [label="" style=solid]
	layer1_expert10_up [label="Expert 10 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 13" fillcolor=lightcoral shape=rectangle style=filled]
	layer1_route_expert10 -> layer1_expert10_up [label="" style=solid]
	layer1_expert10_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 13" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_expert10_up -> layer1_expert10_activation [label="" style=solid]
	layer1_expert10_down [label="Expert 10 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 13" fillcolor=lightcoral shape=rectangle style=filled]
	layer1_expert10_activation -> layer1_expert10_down [label="" style=solid]
	layer1_route_back_expert10 [label="Route Back Expert 10\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 13" fillcolor=lightpink shape=parallelogram style=filled]
	layer1_expert10_down -> layer1_route_back_expert10 [label="" style=solid]
	layer1_route_expert11 [label="Route to Expert 11\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 13" fillcolor=lightpink shape=parallelogram style=filled]
	layer1_gate -> layer1_route_expert11 [label="" style=dashed]
	layer1_moe_norm -> layer1_route_expert11 [label="" style=solid]
	layer1_expert11_up [label="Expert 11 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 13" fillcolor=lightcoral shape=rectangle style=filled]
	layer1_route_expert11 -> layer1_expert11_up [label="" style=solid]
	layer1_expert11_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 13" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_expert11_up -> layer1_expert11_activation [label="" style=solid]
	layer1_expert11_down [label="Expert 11 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 13" fillcolor=lightcoral shape=rectangle style=filled]
	layer1_expert11_activation -> layer1_expert11_down [label="" style=solid]
	layer1_route_back_expert11 [label="Route Back Expert 11\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 13" fillcolor=lightpink shape=parallelogram style=filled]
	layer1_expert11_down -> layer1_route_back_expert11 [label="" style=solid]
	layer1_route_expert12 [label="Route to Expert 12\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 14" fillcolor=lightpink shape=parallelogram style=filled]
	layer1_gate -> layer1_route_expert12 [label="" style=dashed]
	layer1_moe_norm -> layer1_route_expert12 [label="" style=solid]
	layer1_expert12_up [label="Expert 12 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 14" fillcolor=lightcoral shape=rectangle style=filled]
	layer1_route_expert12 -> layer1_expert12_up [label="" style=solid]
	layer1_expert12_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 14" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_expert12_up -> layer1_expert12_activation [label="" style=solid]
	layer1_expert12_down [label="Expert 12 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 14" fillcolor=lightcoral shape=rectangle style=filled]
	layer1_expert12_activation -> layer1_expert12_down [label="" style=solid]
	layer1_route_back_expert12 [label="Route Back Expert 12\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 14" fillcolor=lightpink shape=parallelogram style=filled]
	layer1_expert12_down -> layer1_route_back_expert12 [label="" style=solid]
	layer1_route_expert13 [label="Route to Expert 13\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 14" fillcolor=lightpink shape=parallelogram style=filled]
	layer1_gate -> layer1_route_expert13 [label="" style=dashed]
	layer1_moe_norm -> layer1_route_expert13 [label="" style=solid]
	layer1_expert13_up [label="Expert 13 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 14" fillcolor=lightcoral shape=rectangle style=filled]
	layer1_route_expert13 -> layer1_expert13_up [label="" style=solid]
	layer1_expert13_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 14" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_expert13_up -> layer1_expert13_activation [label="" style=solid]
	layer1_expert13_down [label="Expert 13 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 14" fillcolor=lightcoral shape=rectangle style=filled]
	layer1_expert13_activation -> layer1_expert13_down [label="" style=solid]
	layer1_route_back_expert13 [label="Route Back Expert 13\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 14" fillcolor=lightpink shape=parallelogram style=filled]
	layer1_expert13_down -> layer1_route_back_expert13 [label="" style=solid]
	layer1_route_expert14 [label="Route to Expert 14\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 15" fillcolor=lightpink shape=parallelogram style=filled]
	layer1_gate -> layer1_route_expert14 [label="" style=dashed]
	layer1_moe_norm -> layer1_route_expert14 [label="" style=solid]
	layer1_expert14_up [label="Expert 14 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 15" fillcolor=lightcoral shape=rectangle style=filled]
	layer1_route_expert14 -> layer1_expert14_up [label="" style=solid]
	layer1_expert14_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 15" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_expert14_up -> layer1_expert14_activation [label="" style=solid]
	layer1_expert14_down [label="Expert 14 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 15" fillcolor=lightcoral shape=rectangle style=filled]
	layer1_expert14_activation -> layer1_expert14_down [label="" style=solid]
	layer1_route_back_expert14 [label="Route Back Expert 14\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 15" fillcolor=lightpink shape=parallelogram style=filled]
	layer1_expert14_down -> layer1_route_back_expert14 [label="" style=solid]
	layer1_route_expert15 [label="Route to Expert 15\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 15" fillcolor=lightpink shape=parallelogram style=filled]
	layer1_gate -> layer1_route_expert15 [label="" style=dashed]
	layer1_moe_norm -> layer1_route_expert15 [label="" style=solid]
	layer1_expert15_up [label="Expert 15 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 15" fillcolor=lightcoral shape=rectangle style=filled]
	layer1_route_expert15 -> layer1_expert15_up [label="" style=solid]
	layer1_expert15_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 15" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_expert15_up -> layer1_expert15_activation [label="" style=solid]
	layer1_expert15_down [label="Expert 15 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 15" fillcolor=lightcoral shape=rectangle style=filled]
	layer1_expert15_activation -> layer1_expert15_down [label="" style=solid]
	layer1_route_back_expert15 [label="Route Back Expert 15\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 15" fillcolor=lightpink shape=parallelogram style=filled]
	layer1_expert15_down -> layer1_route_back_expert15 [label="" style=solid]
	layer1_expert_agg [label="Aggregate Experts\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: all GPUs" fillcolor=lightblue shape=ellipse style=filled]
	layer1_route_back_expert0 -> layer1_expert_agg [label="" style=solid]
	layer1_route_back_expert1 -> layer1_expert_agg [label="" style=solid]
	layer1_route_back_expert2 -> layer1_expert_agg [label="" style=solid]
	layer1_route_back_expert3 -> layer1_expert_agg [label="" style=solid]
	layer1_route_back_expert4 -> layer1_expert_agg [label="" style=solid]
	layer1_route_back_expert5 -> layer1_expert_agg [label="" style=solid]
	layer1_route_back_expert6 -> layer1_expert_agg [label="" style=solid]
	layer1_route_back_expert7 -> layer1_expert_agg [label="" style=solid]
	layer1_route_back_expert8 -> layer1_expert_agg [label="" style=solid]
	layer1_route_back_expert9 -> layer1_expert_agg [label="" style=solid]
	layer1_route_back_expert10 -> layer1_expert_agg [label="" style=solid]
	layer1_route_back_expert11 -> layer1_expert_agg [label="" style=solid]
	layer1_route_back_expert12 -> layer1_expert_agg [label="" style=solid]
	layer1_route_back_expert13 -> layer1_expert_agg [label="" style=solid]
	layer1_route_back_expert14 -> layer1_expert_agg [label="" style=solid]
	layer1_route_back_expert15 -> layer1_expert_agg [label="" style=solid]
	layer1_final_residual [label="Final Residual Add\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096], [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: all GPUs" fillcolor=lightblue shape=ellipse style=filled]
	layer1_attn_residual -> layer1_final_residual [label="" style=solid]
	layer1_expert_agg -> layer1_final_residual [label="" style=solid]
	layer2_attn_norm_gpu0 [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 0" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_final_residual -> layer2_attn_norm_gpu0 [label="" style=solid]
	layer2_q_proj_gpu0 [label="Q Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 0" fillcolor=lightgreen shape=rectangle style=filled]
	layer2_attn_norm_gpu0 -> layer2_q_proj_gpu0 [label="" style=solid]
	layer2_k_proj_gpu0 [label="K Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 0" fillcolor=lightgreen shape=rectangle style=filled]
	layer2_attn_norm_gpu0 -> layer2_k_proj_gpu0 [label="" style=solid]
	layer2_v_proj_gpu0 [label="V Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 0" fillcolor=lightgreen shape=rectangle style=filled]
	layer2_attn_norm_gpu0 -> layer2_v_proj_gpu0 [label="" style=solid]
	layer2_gather_q_gpu0 [label="All-Gather Q\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 0" fillcolor=lightblue shape=ellipse style=filled]
	layer2_q_proj_gpu0 -> layer2_gather_q_gpu0 [label="" style=solid]
	layer2_gather_k_gpu0 [label="All-Gather K\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 0" fillcolor=lightblue shape=ellipse style=filled]
	layer2_k_proj_gpu0 -> layer2_gather_k_gpu0 [label="" style=solid]
	layer2_gather_v_gpu0 [label="All-Gather V\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 0" fillcolor=lightblue shape=ellipse style=filled]
	layer2_v_proj_gpu0 -> layer2_gather_v_gpu0 [label="" style=solid]
	layer2_attn_scores_gpu0 [label="QK^T / sqrt(d_k)\nInput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 0" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_gather_q_gpu0 -> layer2_attn_scores_gpu0 [label="" style=solid]
	layer2_gather_k_gpu0 -> layer2_attn_scores_gpu0 [label="" style=solid]
	layer2_softmax_gpu0 [label="Softmax\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 0" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_attn_scores_gpu0 -> layer2_softmax_gpu0 [label="" style=solid]
	layer2_attn_out_gpu0 [label="Attention×V\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 0" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_softmax_gpu0 -> layer2_attn_out_gpu0 [label="" style=solid]
	layer2_gather_v_gpu0 -> layer2_attn_out_gpu0 [label="" style=solid]
	layer2_out_proj_gpu0 [label="Output Projection\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=512]\nGPU: 0" fillcolor=lightgreen shape=rectangle style=filled]
	layer2_attn_out_gpu0 -> layer2_out_proj_gpu0 [label="" style=solid]
	layer2_attn_norm_gpu1 [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 1" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_final_residual -> layer2_attn_norm_gpu1 [label="" style=solid]
	layer2_q_proj_gpu1 [label="Q Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 1" fillcolor=lightgreen shape=rectangle style=filled]
	layer2_attn_norm_gpu1 -> layer2_q_proj_gpu1 [label="" style=solid]
	layer2_k_proj_gpu1 [label="K Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 1" fillcolor=lightgreen shape=rectangle style=filled]
	layer2_attn_norm_gpu1 -> layer2_k_proj_gpu1 [label="" style=solid]
	layer2_v_proj_gpu1 [label="V Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 1" fillcolor=lightgreen shape=rectangle style=filled]
	layer2_attn_norm_gpu1 -> layer2_v_proj_gpu1 [label="" style=solid]
	layer2_gather_q_gpu1 [label="All-Gather Q\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 1" fillcolor=lightblue shape=ellipse style=filled]
	layer2_q_proj_gpu1 -> layer2_gather_q_gpu1 [label="" style=solid]
	layer2_gather_k_gpu1 [label="All-Gather K\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 1" fillcolor=lightblue shape=ellipse style=filled]
	layer2_k_proj_gpu1 -> layer2_gather_k_gpu1 [label="" style=solid]
	layer2_gather_v_gpu1 [label="All-Gather V\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 1" fillcolor=lightblue shape=ellipse style=filled]
	layer2_v_proj_gpu1 -> layer2_gather_v_gpu1 [label="" style=solid]
	layer2_attn_scores_gpu1 [label="QK^T / sqrt(d_k)\nInput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 1" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_gather_q_gpu1 -> layer2_attn_scores_gpu1 [label="" style=solid]
	layer2_gather_k_gpu1 -> layer2_attn_scores_gpu1 [label="" style=solid]
	layer2_softmax_gpu1 [label="Softmax\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 1" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_attn_scores_gpu1 -> layer2_softmax_gpu1 [label="" style=solid]
	layer2_attn_out_gpu1 [label="Attention×V\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 1" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_softmax_gpu1 -> layer2_attn_out_gpu1 [label="" style=solid]
	layer2_gather_v_gpu1 -> layer2_attn_out_gpu1 [label="" style=solid]
	layer2_out_proj_gpu1 [label="Output Projection\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=512]\nGPU: 1" fillcolor=lightgreen shape=rectangle style=filled]
	layer2_attn_out_gpu1 -> layer2_out_proj_gpu1 [label="" style=solid]
	layer2_attn_norm_gpu2 [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 2" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_final_residual -> layer2_attn_norm_gpu2 [label="" style=solid]
	layer2_q_proj_gpu2 [label="Q Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 2" fillcolor=lightgreen shape=rectangle style=filled]
	layer2_attn_norm_gpu2 -> layer2_q_proj_gpu2 [label="" style=solid]
	layer2_k_proj_gpu2 [label="K Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 2" fillcolor=lightgreen shape=rectangle style=filled]
	layer2_attn_norm_gpu2 -> layer2_k_proj_gpu2 [label="" style=solid]
	layer2_v_proj_gpu2 [label="V Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 2" fillcolor=lightgreen shape=rectangle style=filled]
	layer2_attn_norm_gpu2 -> layer2_v_proj_gpu2 [label="" style=solid]
	layer2_gather_q_gpu2 [label="All-Gather Q\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 2" fillcolor=lightblue shape=ellipse style=filled]
	layer2_q_proj_gpu2 -> layer2_gather_q_gpu2 [label="" style=solid]
	layer2_gather_k_gpu2 [label="All-Gather K\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 2" fillcolor=lightblue shape=ellipse style=filled]
	layer2_k_proj_gpu2 -> layer2_gather_k_gpu2 [label="" style=solid]
	layer2_gather_v_gpu2 [label="All-Gather V\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 2" fillcolor=lightblue shape=ellipse style=filled]
	layer2_v_proj_gpu2 -> layer2_gather_v_gpu2 [label="" style=solid]
	layer2_attn_scores_gpu2 [label="QK^T / sqrt(d_k)\nInput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 2" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_gather_q_gpu2 -> layer2_attn_scores_gpu2 [label="" style=solid]
	layer2_gather_k_gpu2 -> layer2_attn_scores_gpu2 [label="" style=solid]
	layer2_softmax_gpu2 [label="Softmax\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 2" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_attn_scores_gpu2 -> layer2_softmax_gpu2 [label="" style=solid]
	layer2_attn_out_gpu2 [label="Attention×V\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 2" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_softmax_gpu2 -> layer2_attn_out_gpu2 [label="" style=solid]
	layer2_gather_v_gpu2 -> layer2_attn_out_gpu2 [label="" style=solid]
	layer2_out_proj_gpu2 [label="Output Projection\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=512]\nGPU: 2" fillcolor=lightgreen shape=rectangle style=filled]
	layer2_attn_out_gpu2 -> layer2_out_proj_gpu2 [label="" style=solid]
	layer2_attn_norm_gpu3 [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 3" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_final_residual -> layer2_attn_norm_gpu3 [label="" style=solid]
	layer2_q_proj_gpu3 [label="Q Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 3" fillcolor=lightgreen shape=rectangle style=filled]
	layer2_attn_norm_gpu3 -> layer2_q_proj_gpu3 [label="" style=solid]
	layer2_k_proj_gpu3 [label="K Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 3" fillcolor=lightgreen shape=rectangle style=filled]
	layer2_attn_norm_gpu3 -> layer2_k_proj_gpu3 [label="" style=solid]
	layer2_v_proj_gpu3 [label="V Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 3" fillcolor=lightgreen shape=rectangle style=filled]
	layer2_attn_norm_gpu3 -> layer2_v_proj_gpu3 [label="" style=solid]
	layer2_gather_q_gpu3 [label="All-Gather Q\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 3" fillcolor=lightblue shape=ellipse style=filled]
	layer2_q_proj_gpu3 -> layer2_gather_q_gpu3 [label="" style=solid]
	layer2_gather_k_gpu3 [label="All-Gather K\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 3" fillcolor=lightblue shape=ellipse style=filled]
	layer2_k_proj_gpu3 -> layer2_gather_k_gpu3 [label="" style=solid]
	layer2_gather_v_gpu3 [label="All-Gather V\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 3" fillcolor=lightblue shape=ellipse style=filled]
	layer2_v_proj_gpu3 -> layer2_gather_v_gpu3 [label="" style=solid]
	layer2_attn_scores_gpu3 [label="QK^T / sqrt(d_k)\nInput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 3" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_gather_q_gpu3 -> layer2_attn_scores_gpu3 [label="" style=solid]
	layer2_gather_k_gpu3 -> layer2_attn_scores_gpu3 [label="" style=solid]
	layer2_softmax_gpu3 [label="Softmax\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 3" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_attn_scores_gpu3 -> layer2_softmax_gpu3 [label="" style=solid]
	layer2_attn_out_gpu3 [label="Attention×V\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 3" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_softmax_gpu3 -> layer2_attn_out_gpu3 [label="" style=solid]
	layer2_gather_v_gpu3 -> layer2_attn_out_gpu3 [label="" style=solid]
	layer2_out_proj_gpu3 [label="Output Projection\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=512]\nGPU: 3" fillcolor=lightgreen shape=rectangle style=filled]
	layer2_attn_out_gpu3 -> layer2_out_proj_gpu3 [label="" style=solid]
	layer2_attn_norm_gpu4 [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 4" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_final_residual -> layer2_attn_norm_gpu4 [label="" style=solid]
	layer2_q_proj_gpu4 [label="Q Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 4" fillcolor=lightgreen shape=rectangle style=filled]
	layer2_attn_norm_gpu4 -> layer2_q_proj_gpu4 [label="" style=solid]
	layer2_k_proj_gpu4 [label="K Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 4" fillcolor=lightgreen shape=rectangle style=filled]
	layer2_attn_norm_gpu4 -> layer2_k_proj_gpu4 [label="" style=solid]
	layer2_v_proj_gpu4 [label="V Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 4" fillcolor=lightgreen shape=rectangle style=filled]
	layer2_attn_norm_gpu4 -> layer2_v_proj_gpu4 [label="" style=solid]
	layer2_gather_q_gpu4 [label="All-Gather Q\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 4" fillcolor=lightblue shape=ellipse style=filled]
	layer2_q_proj_gpu4 -> layer2_gather_q_gpu4 [label="" style=solid]
	layer2_gather_k_gpu4 [label="All-Gather K\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 4" fillcolor=lightblue shape=ellipse style=filled]
	layer2_k_proj_gpu4 -> layer2_gather_k_gpu4 [label="" style=solid]
	layer2_gather_v_gpu4 [label="All-Gather V\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 4" fillcolor=lightblue shape=ellipse style=filled]
	layer2_v_proj_gpu4 -> layer2_gather_v_gpu4 [label="" style=solid]
	layer2_attn_scores_gpu4 [label="QK^T / sqrt(d_k)\nInput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 4" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_gather_q_gpu4 -> layer2_attn_scores_gpu4 [label="" style=solid]
	layer2_gather_k_gpu4 -> layer2_attn_scores_gpu4 [label="" style=solid]
	layer2_softmax_gpu4 [label="Softmax\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 4" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_attn_scores_gpu4 -> layer2_softmax_gpu4 [label="" style=solid]
	layer2_attn_out_gpu4 [label="Attention×V\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 4" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_softmax_gpu4 -> layer2_attn_out_gpu4 [label="" style=solid]
	layer2_gather_v_gpu4 -> layer2_attn_out_gpu4 [label="" style=solid]
	layer2_out_proj_gpu4 [label="Output Projection\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=512]\nGPU: 4" fillcolor=lightgreen shape=rectangle style=filled]
	layer2_attn_out_gpu4 -> layer2_out_proj_gpu4 [label="" style=solid]
	layer2_attn_norm_gpu5 [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 5" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_final_residual -> layer2_attn_norm_gpu5 [label="" style=solid]
	layer2_q_proj_gpu5 [label="Q Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 5" fillcolor=lightgreen shape=rectangle style=filled]
	layer2_attn_norm_gpu5 -> layer2_q_proj_gpu5 [label="" style=solid]
	layer2_k_proj_gpu5 [label="K Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 5" fillcolor=lightgreen shape=rectangle style=filled]
	layer2_attn_norm_gpu5 -> layer2_k_proj_gpu5 [label="" style=solid]
	layer2_v_proj_gpu5 [label="V Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 5" fillcolor=lightgreen shape=rectangle style=filled]
	layer2_attn_norm_gpu5 -> layer2_v_proj_gpu5 [label="" style=solid]
	layer2_gather_q_gpu5 [label="All-Gather Q\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 5" fillcolor=lightblue shape=ellipse style=filled]
	layer2_q_proj_gpu5 -> layer2_gather_q_gpu5 [label="" style=solid]
	layer2_gather_k_gpu5 [label="All-Gather K\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 5" fillcolor=lightblue shape=ellipse style=filled]
	layer2_k_proj_gpu5 -> layer2_gather_k_gpu5 [label="" style=solid]
	layer2_gather_v_gpu5 [label="All-Gather V\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 5" fillcolor=lightblue shape=ellipse style=filled]
	layer2_v_proj_gpu5 -> layer2_gather_v_gpu5 [label="" style=solid]
	layer2_attn_scores_gpu5 [label="QK^T / sqrt(d_k)\nInput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 5" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_gather_q_gpu5 -> layer2_attn_scores_gpu5 [label="" style=solid]
	layer2_gather_k_gpu5 -> layer2_attn_scores_gpu5 [label="" style=solid]
	layer2_softmax_gpu5 [label="Softmax\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 5" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_attn_scores_gpu5 -> layer2_softmax_gpu5 [label="" style=solid]
	layer2_attn_out_gpu5 [label="Attention×V\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 5" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_softmax_gpu5 -> layer2_attn_out_gpu5 [label="" style=solid]
	layer2_gather_v_gpu5 -> layer2_attn_out_gpu5 [label="" style=solid]
	layer2_out_proj_gpu5 [label="Output Projection\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=512]\nGPU: 5" fillcolor=lightgreen shape=rectangle style=filled]
	layer2_attn_out_gpu5 -> layer2_out_proj_gpu5 [label="" style=solid]
	layer2_attn_norm_gpu6 [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 6" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_final_residual -> layer2_attn_norm_gpu6 [label="" style=solid]
	layer2_q_proj_gpu6 [label="Q Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 6" fillcolor=lightgreen shape=rectangle style=filled]
	layer2_attn_norm_gpu6 -> layer2_q_proj_gpu6 [label="" style=solid]
	layer2_k_proj_gpu6 [label="K Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 6" fillcolor=lightgreen shape=rectangle style=filled]
	layer2_attn_norm_gpu6 -> layer2_k_proj_gpu6 [label="" style=solid]
	layer2_v_proj_gpu6 [label="V Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 6" fillcolor=lightgreen shape=rectangle style=filled]
	layer2_attn_norm_gpu6 -> layer2_v_proj_gpu6 [label="" style=solid]
	layer2_gather_q_gpu6 [label="All-Gather Q\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 6" fillcolor=lightblue shape=ellipse style=filled]
	layer2_q_proj_gpu6 -> layer2_gather_q_gpu6 [label="" style=solid]
	layer2_gather_k_gpu6 [label="All-Gather K\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 6" fillcolor=lightblue shape=ellipse style=filled]
	layer2_k_proj_gpu6 -> layer2_gather_k_gpu6 [label="" style=solid]
	layer2_gather_v_gpu6 [label="All-Gather V\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 6" fillcolor=lightblue shape=ellipse style=filled]
	layer2_v_proj_gpu6 -> layer2_gather_v_gpu6 [label="" style=solid]
	layer2_attn_scores_gpu6 [label="QK^T / sqrt(d_k)\nInput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 6" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_gather_q_gpu6 -> layer2_attn_scores_gpu6 [label="" style=solid]
	layer2_gather_k_gpu6 -> layer2_attn_scores_gpu6 [label="" style=solid]
	layer2_softmax_gpu6 [label="Softmax\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 6" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_attn_scores_gpu6 -> layer2_softmax_gpu6 [label="" style=solid]
	layer2_attn_out_gpu6 [label="Attention×V\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 6" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_softmax_gpu6 -> layer2_attn_out_gpu6 [label="" style=solid]
	layer2_gather_v_gpu6 -> layer2_attn_out_gpu6 [label="" style=solid]
	layer2_out_proj_gpu6 [label="Output Projection\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=512]\nGPU: 6" fillcolor=lightgreen shape=rectangle style=filled]
	layer2_attn_out_gpu6 -> layer2_out_proj_gpu6 [label="" style=solid]
	layer2_attn_norm_gpu7 [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 7" fillcolor=lightyellow shape=rectangle style=filled]
	layer1_final_residual -> layer2_attn_norm_gpu7 [label="" style=solid]
	layer2_q_proj_gpu7 [label="Q Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 7" fillcolor=lightgreen shape=rectangle style=filled]
	layer2_attn_norm_gpu7 -> layer2_q_proj_gpu7 [label="" style=solid]
	layer2_k_proj_gpu7 [label="K Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 7" fillcolor=lightgreen shape=rectangle style=filled]
	layer2_attn_norm_gpu7 -> layer2_k_proj_gpu7 [label="" style=solid]
	layer2_v_proj_gpu7 [label="V Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 7" fillcolor=lightgreen shape=rectangle style=filled]
	layer2_attn_norm_gpu7 -> layer2_v_proj_gpu7 [label="" style=solid]
	layer2_gather_q_gpu7 [label="All-Gather Q\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 7" fillcolor=lightblue shape=ellipse style=filled]
	layer2_q_proj_gpu7 -> layer2_gather_q_gpu7 [label="" style=solid]
	layer2_gather_k_gpu7 [label="All-Gather K\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 7" fillcolor=lightblue shape=ellipse style=filled]
	layer2_k_proj_gpu7 -> layer2_gather_k_gpu7 [label="" style=solid]
	layer2_gather_v_gpu7 [label="All-Gather V\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 7" fillcolor=lightblue shape=ellipse style=filled]
	layer2_v_proj_gpu7 -> layer2_gather_v_gpu7 [label="" style=solid]
	layer2_attn_scores_gpu7 [label="QK^T / sqrt(d_k)\nInput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 7" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_gather_q_gpu7 -> layer2_attn_scores_gpu7 [label="" style=solid]
	layer2_gather_k_gpu7 -> layer2_attn_scores_gpu7 [label="" style=solid]
	layer2_softmax_gpu7 [label="Softmax\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 7" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_attn_scores_gpu7 -> layer2_softmax_gpu7 [label="" style=solid]
	layer2_attn_out_gpu7 [label="Attention×V\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 7" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_softmax_gpu7 -> layer2_attn_out_gpu7 [label="" style=solid]
	layer2_gather_v_gpu7 -> layer2_attn_out_gpu7 [label="" style=solid]
	layer2_out_proj_gpu7 [label="Output Projection\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=512]\nGPU: 7" fillcolor=lightgreen shape=rectangle style=filled]
	layer2_attn_out_gpu7 -> layer2_out_proj_gpu7 [label="" style=solid]
	layer2_attn_all_reduce [label="All-Reduce Attention\nInput: 8×[512]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: GPUs 0-7" fillcolor=lightblue shape=ellipse style=filled]
	layer2_out_proj_gpu0 -> layer2_attn_all_reduce [label="" style=solid]
	layer2_out_proj_gpu1 -> layer2_attn_all_reduce [label="" style=solid]
	layer2_out_proj_gpu2 -> layer2_attn_all_reduce [label="" style=solid]
	layer2_out_proj_gpu3 -> layer2_attn_all_reduce [label="" style=solid]
	layer2_out_proj_gpu4 -> layer2_attn_all_reduce [label="" style=solid]
	layer2_out_proj_gpu5 -> layer2_attn_all_reduce [label="" style=solid]
	layer2_out_proj_gpu6 -> layer2_attn_all_reduce [label="" style=solid]
	layer2_out_proj_gpu7 -> layer2_attn_all_reduce [label="" style=solid]
	layer2_attn_residual [label="Residual Add\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096], [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: all GPUs" fillcolor=lightblue shape=ellipse style=filled]
	layer1_final_residual -> layer2_attn_residual [label="" style=solid]
	layer2_attn_all_reduce -> layer2_attn_residual [label="" style=solid]
	layer2_broadcast_to_moe [label="Broadcast to MoE GPUs\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: GPUs 8-15" fillcolor=lightblue shape=ellipse style=filled]
	layer2_attn_residual -> layer2_broadcast_to_moe [label="" style=solid]
	layer2_moe_norm [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: all GPUs" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_broadcast_to_moe -> layer2_moe_norm [label="" style=solid]
	layer2_gate [label="Gate Network\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, experts=16]\nGPU: all GPUs" fillcolor=lightpink shape=parallelogram style=filled]
	layer2_moe_norm -> layer2_gate [label="" style=solid]
	layer2_route_expert0 [label="Route to Expert 0\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 8" fillcolor=lightpink shape=parallelogram style=filled]
	layer2_gate -> layer2_route_expert0 [label="" style=dashed]
	layer2_moe_norm -> layer2_route_expert0 [label="" style=solid]
	layer2_expert0_up [label="Expert 0 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 8" fillcolor=lightcoral shape=rectangle style=filled]
	layer2_route_expert0 -> layer2_expert0_up [label="" style=solid]
	layer2_expert0_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 8" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_expert0_up -> layer2_expert0_activation [label="" style=solid]
	layer2_expert0_down [label="Expert 0 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 8" fillcolor=lightcoral shape=rectangle style=filled]
	layer2_expert0_activation -> layer2_expert0_down [label="" style=solid]
	layer2_route_back_expert0 [label="Route Back Expert 0\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 8" fillcolor=lightpink shape=parallelogram style=filled]
	layer2_expert0_down -> layer2_route_back_expert0 [label="" style=solid]
	layer2_route_expert1 [label="Route to Expert 1\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 8" fillcolor=lightpink shape=parallelogram style=filled]
	layer2_gate -> layer2_route_expert1 [label="" style=dashed]
	layer2_moe_norm -> layer2_route_expert1 [label="" style=solid]
	layer2_expert1_up [label="Expert 1 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 8" fillcolor=lightcoral shape=rectangle style=filled]
	layer2_route_expert1 -> layer2_expert1_up [label="" style=solid]
	layer2_expert1_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 8" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_expert1_up -> layer2_expert1_activation [label="" style=solid]
	layer2_expert1_down [label="Expert 1 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 8" fillcolor=lightcoral shape=rectangle style=filled]
	layer2_expert1_activation -> layer2_expert1_down [label="" style=solid]
	layer2_route_back_expert1 [label="Route Back Expert 1\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 8" fillcolor=lightpink shape=parallelogram style=filled]
	layer2_expert1_down -> layer2_route_back_expert1 [label="" style=solid]
	layer2_route_expert2 [label="Route to Expert 2\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 9" fillcolor=lightpink shape=parallelogram style=filled]
	layer2_gate -> layer2_route_expert2 [label="" style=dashed]
	layer2_moe_norm -> layer2_route_expert2 [label="" style=solid]
	layer2_expert2_up [label="Expert 2 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 9" fillcolor=lightcoral shape=rectangle style=filled]
	layer2_route_expert2 -> layer2_expert2_up [label="" style=solid]
	layer2_expert2_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 9" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_expert2_up -> layer2_expert2_activation [label="" style=solid]
	layer2_expert2_down [label="Expert 2 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 9" fillcolor=lightcoral shape=rectangle style=filled]
	layer2_expert2_activation -> layer2_expert2_down [label="" style=solid]
	layer2_route_back_expert2 [label="Route Back Expert 2\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 9" fillcolor=lightpink shape=parallelogram style=filled]
	layer2_expert2_down -> layer2_route_back_expert2 [label="" style=solid]
	layer2_route_expert3 [label="Route to Expert 3\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 9" fillcolor=lightpink shape=parallelogram style=filled]
	layer2_gate -> layer2_route_expert3 [label="" style=dashed]
	layer2_moe_norm -> layer2_route_expert3 [label="" style=solid]
	layer2_expert3_up [label="Expert 3 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 9" fillcolor=lightcoral shape=rectangle style=filled]
	layer2_route_expert3 -> layer2_expert3_up [label="" style=solid]
	layer2_expert3_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 9" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_expert3_up -> layer2_expert3_activation [label="" style=solid]
	layer2_expert3_down [label="Expert 3 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 9" fillcolor=lightcoral shape=rectangle style=filled]
	layer2_expert3_activation -> layer2_expert3_down [label="" style=solid]
	layer2_route_back_expert3 [label="Route Back Expert 3\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 9" fillcolor=lightpink shape=parallelogram style=filled]
	layer2_expert3_down -> layer2_route_back_expert3 [label="" style=solid]
	layer2_route_expert4 [label="Route to Expert 4\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 10" fillcolor=lightpink shape=parallelogram style=filled]
	layer2_gate -> layer2_route_expert4 [label="" style=dashed]
	layer2_moe_norm -> layer2_route_expert4 [label="" style=solid]
	layer2_expert4_up [label="Expert 4 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 10" fillcolor=lightcoral shape=rectangle style=filled]
	layer2_route_expert4 -> layer2_expert4_up [label="" style=solid]
	layer2_expert4_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 10" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_expert4_up -> layer2_expert4_activation [label="" style=solid]
	layer2_expert4_down [label="Expert 4 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 10" fillcolor=lightcoral shape=rectangle style=filled]
	layer2_expert4_activation -> layer2_expert4_down [label="" style=solid]
	layer2_route_back_expert4 [label="Route Back Expert 4\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 10" fillcolor=lightpink shape=parallelogram style=filled]
	layer2_expert4_down -> layer2_route_back_expert4 [label="" style=solid]
	layer2_route_expert5 [label="Route to Expert 5\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 10" fillcolor=lightpink shape=parallelogram style=filled]
	layer2_gate -> layer2_route_expert5 [label="" style=dashed]
	layer2_moe_norm -> layer2_route_expert5 [label="" style=solid]
	layer2_expert5_up [label="Expert 5 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 10" fillcolor=lightcoral shape=rectangle style=filled]
	layer2_route_expert5 -> layer2_expert5_up [label="" style=solid]
	layer2_expert5_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 10" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_expert5_up -> layer2_expert5_activation [label="" style=solid]
	layer2_expert5_down [label="Expert 5 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 10" fillcolor=lightcoral shape=rectangle style=filled]
	layer2_expert5_activation -> layer2_expert5_down [label="" style=solid]
	layer2_route_back_expert5 [label="Route Back Expert 5\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 10" fillcolor=lightpink shape=parallelogram style=filled]
	layer2_expert5_down -> layer2_route_back_expert5 [label="" style=solid]
	layer2_route_expert6 [label="Route to Expert 6\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 11" fillcolor=lightpink shape=parallelogram style=filled]
	layer2_gate -> layer2_route_expert6 [label="" style=dashed]
	layer2_moe_norm -> layer2_route_expert6 [label="" style=solid]
	layer2_expert6_up [label="Expert 6 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 11" fillcolor=lightcoral shape=rectangle style=filled]
	layer2_route_expert6 -> layer2_expert6_up [label="" style=solid]
	layer2_expert6_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 11" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_expert6_up -> layer2_expert6_activation [label="" style=solid]
	layer2_expert6_down [label="Expert 6 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 11" fillcolor=lightcoral shape=rectangle style=filled]
	layer2_expert6_activation -> layer2_expert6_down [label="" style=solid]
	layer2_route_back_expert6 [label="Route Back Expert 6\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 11" fillcolor=lightpink shape=parallelogram style=filled]
	layer2_expert6_down -> layer2_route_back_expert6 [label="" style=solid]
	layer2_route_expert7 [label="Route to Expert 7\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 11" fillcolor=lightpink shape=parallelogram style=filled]
	layer2_gate -> layer2_route_expert7 [label="" style=dashed]
	layer2_moe_norm -> layer2_route_expert7 [label="" style=solid]
	layer2_expert7_up [label="Expert 7 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 11" fillcolor=lightcoral shape=rectangle style=filled]
	layer2_route_expert7 -> layer2_expert7_up [label="" style=solid]
	layer2_expert7_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 11" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_expert7_up -> layer2_expert7_activation [label="" style=solid]
	layer2_expert7_down [label="Expert 7 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 11" fillcolor=lightcoral shape=rectangle style=filled]
	layer2_expert7_activation -> layer2_expert7_down [label="" style=solid]
	layer2_route_back_expert7 [label="Route Back Expert 7\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 11" fillcolor=lightpink shape=parallelogram style=filled]
	layer2_expert7_down -> layer2_route_back_expert7 [label="" style=solid]
	layer2_route_expert8 [label="Route to Expert 8\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 12" fillcolor=lightpink shape=parallelogram style=filled]
	layer2_gate -> layer2_route_expert8 [label="" style=dashed]
	layer2_moe_norm -> layer2_route_expert8 [label="" style=solid]
	layer2_expert8_up [label="Expert 8 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 12" fillcolor=lightcoral shape=rectangle style=filled]
	layer2_route_expert8 -> layer2_expert8_up [label="" style=solid]
	layer2_expert8_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 12" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_expert8_up -> layer2_expert8_activation [label="" style=solid]
	layer2_expert8_down [label="Expert 8 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 12" fillcolor=lightcoral shape=rectangle style=filled]
	layer2_expert8_activation -> layer2_expert8_down [label="" style=solid]
	layer2_route_back_expert8 [label="Route Back Expert 8\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 12" fillcolor=lightpink shape=parallelogram style=filled]
	layer2_expert8_down -> layer2_route_back_expert8 [label="" style=solid]
	layer2_route_expert9 [label="Route to Expert 9\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 12" fillcolor=lightpink shape=parallelogram style=filled]
	layer2_gate -> layer2_route_expert9 [label="" style=dashed]
	layer2_moe_norm -> layer2_route_expert9 [label="" style=solid]
	layer2_expert9_up [label="Expert 9 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 12" fillcolor=lightcoral shape=rectangle style=filled]
	layer2_route_expert9 -> layer2_expert9_up [label="" style=solid]
	layer2_expert9_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 12" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_expert9_up -> layer2_expert9_activation [label="" style=solid]
	layer2_expert9_down [label="Expert 9 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 12" fillcolor=lightcoral shape=rectangle style=filled]
	layer2_expert9_activation -> layer2_expert9_down [label="" style=solid]
	layer2_route_back_expert9 [label="Route Back Expert 9\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 12" fillcolor=lightpink shape=parallelogram style=filled]
	layer2_expert9_down -> layer2_route_back_expert9 [label="" style=solid]
	layer2_route_expert10 [label="Route to Expert 10\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 13" fillcolor=lightpink shape=parallelogram style=filled]
	layer2_gate -> layer2_route_expert10 [label="" style=dashed]
	layer2_moe_norm -> layer2_route_expert10 [label="" style=solid]
	layer2_expert10_up [label="Expert 10 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 13" fillcolor=lightcoral shape=rectangle style=filled]
	layer2_route_expert10 -> layer2_expert10_up [label="" style=solid]
	layer2_expert10_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 13" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_expert10_up -> layer2_expert10_activation [label="" style=solid]
	layer2_expert10_down [label="Expert 10 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 13" fillcolor=lightcoral shape=rectangle style=filled]
	layer2_expert10_activation -> layer2_expert10_down [label="" style=solid]
	layer2_route_back_expert10 [label="Route Back Expert 10\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 13" fillcolor=lightpink shape=parallelogram style=filled]
	layer2_expert10_down -> layer2_route_back_expert10 [label="" style=solid]
	layer2_route_expert11 [label="Route to Expert 11\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 13" fillcolor=lightpink shape=parallelogram style=filled]
	layer2_gate -> layer2_route_expert11 [label="" style=dashed]
	layer2_moe_norm -> layer2_route_expert11 [label="" style=solid]
	layer2_expert11_up [label="Expert 11 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 13" fillcolor=lightcoral shape=rectangle style=filled]
	layer2_route_expert11 -> layer2_expert11_up [label="" style=solid]
	layer2_expert11_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 13" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_expert11_up -> layer2_expert11_activation [label="" style=solid]
	layer2_expert11_down [label="Expert 11 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 13" fillcolor=lightcoral shape=rectangle style=filled]
	layer2_expert11_activation -> layer2_expert11_down [label="" style=solid]
	layer2_route_back_expert11 [label="Route Back Expert 11\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 13" fillcolor=lightpink shape=parallelogram style=filled]
	layer2_expert11_down -> layer2_route_back_expert11 [label="" style=solid]
	layer2_route_expert12 [label="Route to Expert 12\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 14" fillcolor=lightpink shape=parallelogram style=filled]
	layer2_gate -> layer2_route_expert12 [label="" style=dashed]
	layer2_moe_norm -> layer2_route_expert12 [label="" style=solid]
	layer2_expert12_up [label="Expert 12 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 14" fillcolor=lightcoral shape=rectangle style=filled]
	layer2_route_expert12 -> layer2_expert12_up [label="" style=solid]
	layer2_expert12_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 14" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_expert12_up -> layer2_expert12_activation [label="" style=solid]
	layer2_expert12_down [label="Expert 12 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 14" fillcolor=lightcoral shape=rectangle style=filled]
	layer2_expert12_activation -> layer2_expert12_down [label="" style=solid]
	layer2_route_back_expert12 [label="Route Back Expert 12\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 14" fillcolor=lightpink shape=parallelogram style=filled]
	layer2_expert12_down -> layer2_route_back_expert12 [label="" style=solid]
	layer2_route_expert13 [label="Route to Expert 13\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 14" fillcolor=lightpink shape=parallelogram style=filled]
	layer2_gate -> layer2_route_expert13 [label="" style=dashed]
	layer2_moe_norm -> layer2_route_expert13 [label="" style=solid]
	layer2_expert13_up [label="Expert 13 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 14" fillcolor=lightcoral shape=rectangle style=filled]
	layer2_route_expert13 -> layer2_expert13_up [label="" style=solid]
	layer2_expert13_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 14" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_expert13_up -> layer2_expert13_activation [label="" style=solid]
	layer2_expert13_down [label="Expert 13 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 14" fillcolor=lightcoral shape=rectangle style=filled]
	layer2_expert13_activation -> layer2_expert13_down [label="" style=solid]
	layer2_route_back_expert13 [label="Route Back Expert 13\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 14" fillcolor=lightpink shape=parallelogram style=filled]
	layer2_expert13_down -> layer2_route_back_expert13 [label="" style=solid]
	layer2_route_expert14 [label="Route to Expert 14\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 15" fillcolor=lightpink shape=parallelogram style=filled]
	layer2_gate -> layer2_route_expert14 [label="" style=dashed]
	layer2_moe_norm -> layer2_route_expert14 [label="" style=solid]
	layer2_expert14_up [label="Expert 14 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 15" fillcolor=lightcoral shape=rectangle style=filled]
	layer2_route_expert14 -> layer2_expert14_up [label="" style=solid]
	layer2_expert14_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 15" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_expert14_up -> layer2_expert14_activation [label="" style=solid]
	layer2_expert14_down [label="Expert 14 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 15" fillcolor=lightcoral shape=rectangle style=filled]
	layer2_expert14_activation -> layer2_expert14_down [label="" style=solid]
	layer2_route_back_expert14 [label="Route Back Expert 14\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 15" fillcolor=lightpink shape=parallelogram style=filled]
	layer2_expert14_down -> layer2_route_back_expert14 [label="" style=solid]
	layer2_route_expert15 [label="Route to Expert 15\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 15" fillcolor=lightpink shape=parallelogram style=filled]
	layer2_gate -> layer2_route_expert15 [label="" style=dashed]
	layer2_moe_norm -> layer2_route_expert15 [label="" style=solid]
	layer2_expert15_up [label="Expert 15 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 15" fillcolor=lightcoral shape=rectangle style=filled]
	layer2_route_expert15 -> layer2_expert15_up [label="" style=solid]
	layer2_expert15_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 15" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_expert15_up -> layer2_expert15_activation [label="" style=solid]
	layer2_expert15_down [label="Expert 15 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 15" fillcolor=lightcoral shape=rectangle style=filled]
	layer2_expert15_activation -> layer2_expert15_down [label="" style=solid]
	layer2_route_back_expert15 [label="Route Back Expert 15\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 15" fillcolor=lightpink shape=parallelogram style=filled]
	layer2_expert15_down -> layer2_route_back_expert15 [label="" style=solid]
	layer2_expert_agg [label="Aggregate Experts\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: all GPUs" fillcolor=lightblue shape=ellipse style=filled]
	layer2_route_back_expert0 -> layer2_expert_agg [label="" style=solid]
	layer2_route_back_expert1 -> layer2_expert_agg [label="" style=solid]
	layer2_route_back_expert2 -> layer2_expert_agg [label="" style=solid]
	layer2_route_back_expert3 -> layer2_expert_agg [label="" style=solid]
	layer2_route_back_expert4 -> layer2_expert_agg [label="" style=solid]
	layer2_route_back_expert5 -> layer2_expert_agg [label="" style=solid]
	layer2_route_back_expert6 -> layer2_expert_agg [label="" style=solid]
	layer2_route_back_expert7 -> layer2_expert_agg [label="" style=solid]
	layer2_route_back_expert8 -> layer2_expert_agg [label="" style=solid]
	layer2_route_back_expert9 -> layer2_expert_agg [label="" style=solid]
	layer2_route_back_expert10 -> layer2_expert_agg [label="" style=solid]
	layer2_route_back_expert11 -> layer2_expert_agg [label="" style=solid]
	layer2_route_back_expert12 -> layer2_expert_agg [label="" style=solid]
	layer2_route_back_expert13 -> layer2_expert_agg [label="" style=solid]
	layer2_route_back_expert14 -> layer2_expert_agg [label="" style=solid]
	layer2_route_back_expert15 -> layer2_expert_agg [label="" style=solid]
	layer2_final_residual [label="Final Residual Add\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096], [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: all GPUs" fillcolor=lightblue shape=ellipse style=filled]
	layer2_attn_residual -> layer2_final_residual [label="" style=solid]
	layer2_expert_agg -> layer2_final_residual [label="" style=solid]
	layer3_attn_norm_gpu0 [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 0" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_final_residual -> layer3_attn_norm_gpu0 [label="" style=solid]
	layer3_q_proj_gpu0 [label="Q Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 0" fillcolor=lightgreen shape=rectangle style=filled]
	layer3_attn_norm_gpu0 -> layer3_q_proj_gpu0 [label="" style=solid]
	layer3_k_proj_gpu0 [label="K Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 0" fillcolor=lightgreen shape=rectangle style=filled]
	layer3_attn_norm_gpu0 -> layer3_k_proj_gpu0 [label="" style=solid]
	layer3_v_proj_gpu0 [label="V Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 0" fillcolor=lightgreen shape=rectangle style=filled]
	layer3_attn_norm_gpu0 -> layer3_v_proj_gpu0 [label="" style=solid]
	layer3_gather_q_gpu0 [label="All-Gather Q\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 0" fillcolor=lightblue shape=ellipse style=filled]
	layer3_q_proj_gpu0 -> layer3_gather_q_gpu0 [label="" style=solid]
	layer3_gather_k_gpu0 [label="All-Gather K\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 0" fillcolor=lightblue shape=ellipse style=filled]
	layer3_k_proj_gpu0 -> layer3_gather_k_gpu0 [label="" style=solid]
	layer3_gather_v_gpu0 [label="All-Gather V\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 0" fillcolor=lightblue shape=ellipse style=filled]
	layer3_v_proj_gpu0 -> layer3_gather_v_gpu0 [label="" style=solid]
	layer3_attn_scores_gpu0 [label="QK^T / sqrt(d_k)\nInput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 0" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_gather_q_gpu0 -> layer3_attn_scores_gpu0 [label="" style=solid]
	layer3_gather_k_gpu0 -> layer3_attn_scores_gpu0 [label="" style=solid]
	layer3_softmax_gpu0 [label="Softmax\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 0" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_attn_scores_gpu0 -> layer3_softmax_gpu0 [label="" style=solid]
	layer3_attn_out_gpu0 [label="Attention×V\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 0" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_softmax_gpu0 -> layer3_attn_out_gpu0 [label="" style=solid]
	layer3_gather_v_gpu0 -> layer3_attn_out_gpu0 [label="" style=solid]
	layer3_out_proj_gpu0 [label="Output Projection\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=512]\nGPU: 0" fillcolor=lightgreen shape=rectangle style=filled]
	layer3_attn_out_gpu0 -> layer3_out_proj_gpu0 [label="" style=solid]
	layer3_attn_norm_gpu1 [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 1" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_final_residual -> layer3_attn_norm_gpu1 [label="" style=solid]
	layer3_q_proj_gpu1 [label="Q Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 1" fillcolor=lightgreen shape=rectangle style=filled]
	layer3_attn_norm_gpu1 -> layer3_q_proj_gpu1 [label="" style=solid]
	layer3_k_proj_gpu1 [label="K Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 1" fillcolor=lightgreen shape=rectangle style=filled]
	layer3_attn_norm_gpu1 -> layer3_k_proj_gpu1 [label="" style=solid]
	layer3_v_proj_gpu1 [label="V Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 1" fillcolor=lightgreen shape=rectangle style=filled]
	layer3_attn_norm_gpu1 -> layer3_v_proj_gpu1 [label="" style=solid]
	layer3_gather_q_gpu1 [label="All-Gather Q\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 1" fillcolor=lightblue shape=ellipse style=filled]
	layer3_q_proj_gpu1 -> layer3_gather_q_gpu1 [label="" style=solid]
	layer3_gather_k_gpu1 [label="All-Gather K\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 1" fillcolor=lightblue shape=ellipse style=filled]
	layer3_k_proj_gpu1 -> layer3_gather_k_gpu1 [label="" style=solid]
	layer3_gather_v_gpu1 [label="All-Gather V\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 1" fillcolor=lightblue shape=ellipse style=filled]
	layer3_v_proj_gpu1 -> layer3_gather_v_gpu1 [label="" style=solid]
	layer3_attn_scores_gpu1 [label="QK^T / sqrt(d_k)\nInput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 1" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_gather_q_gpu1 -> layer3_attn_scores_gpu1 [label="" style=solid]
	layer3_gather_k_gpu1 -> layer3_attn_scores_gpu1 [label="" style=solid]
	layer3_softmax_gpu1 [label="Softmax\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 1" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_attn_scores_gpu1 -> layer3_softmax_gpu1 [label="" style=solid]
	layer3_attn_out_gpu1 [label="Attention×V\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 1" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_softmax_gpu1 -> layer3_attn_out_gpu1 [label="" style=solid]
	layer3_gather_v_gpu1 -> layer3_attn_out_gpu1 [label="" style=solid]
	layer3_out_proj_gpu1 [label="Output Projection\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=512]\nGPU: 1" fillcolor=lightgreen shape=rectangle style=filled]
	layer3_attn_out_gpu1 -> layer3_out_proj_gpu1 [label="" style=solid]
	layer3_attn_norm_gpu2 [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 2" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_final_residual -> layer3_attn_norm_gpu2 [label="" style=solid]
	layer3_q_proj_gpu2 [label="Q Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 2" fillcolor=lightgreen shape=rectangle style=filled]
	layer3_attn_norm_gpu2 -> layer3_q_proj_gpu2 [label="" style=solid]
	layer3_k_proj_gpu2 [label="K Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 2" fillcolor=lightgreen shape=rectangle style=filled]
	layer3_attn_norm_gpu2 -> layer3_k_proj_gpu2 [label="" style=solid]
	layer3_v_proj_gpu2 [label="V Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 2" fillcolor=lightgreen shape=rectangle style=filled]
	layer3_attn_norm_gpu2 -> layer3_v_proj_gpu2 [label="" style=solid]
	layer3_gather_q_gpu2 [label="All-Gather Q\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 2" fillcolor=lightblue shape=ellipse style=filled]
	layer3_q_proj_gpu2 -> layer3_gather_q_gpu2 [label="" style=solid]
	layer3_gather_k_gpu2 [label="All-Gather K\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 2" fillcolor=lightblue shape=ellipse style=filled]
	layer3_k_proj_gpu2 -> layer3_gather_k_gpu2 [label="" style=solid]
	layer3_gather_v_gpu2 [label="All-Gather V\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 2" fillcolor=lightblue shape=ellipse style=filled]
	layer3_v_proj_gpu2 -> layer3_gather_v_gpu2 [label="" style=solid]
	layer3_attn_scores_gpu2 [label="QK^T / sqrt(d_k)\nInput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 2" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_gather_q_gpu2 -> layer3_attn_scores_gpu2 [label="" style=solid]
	layer3_gather_k_gpu2 -> layer3_attn_scores_gpu2 [label="" style=solid]
	layer3_softmax_gpu2 [label="Softmax\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 2" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_attn_scores_gpu2 -> layer3_softmax_gpu2 [label="" style=solid]
	layer3_attn_out_gpu2 [label="Attention×V\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 2" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_softmax_gpu2 -> layer3_attn_out_gpu2 [label="" style=solid]
	layer3_gather_v_gpu2 -> layer3_attn_out_gpu2 [label="" style=solid]
	layer3_out_proj_gpu2 [label="Output Projection\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=512]\nGPU: 2" fillcolor=lightgreen shape=rectangle style=filled]
	layer3_attn_out_gpu2 -> layer3_out_proj_gpu2 [label="" style=solid]
	layer3_attn_norm_gpu3 [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 3" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_final_residual -> layer3_attn_norm_gpu3 [label="" style=solid]
	layer3_q_proj_gpu3 [label="Q Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 3" fillcolor=lightgreen shape=rectangle style=filled]
	layer3_attn_norm_gpu3 -> layer3_q_proj_gpu3 [label="" style=solid]
	layer3_k_proj_gpu3 [label="K Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 3" fillcolor=lightgreen shape=rectangle style=filled]
	layer3_attn_norm_gpu3 -> layer3_k_proj_gpu3 [label="" style=solid]
	layer3_v_proj_gpu3 [label="V Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 3" fillcolor=lightgreen shape=rectangle style=filled]
	layer3_attn_norm_gpu3 -> layer3_v_proj_gpu3 [label="" style=solid]
	layer3_gather_q_gpu3 [label="All-Gather Q\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 3" fillcolor=lightblue shape=ellipse style=filled]
	layer3_q_proj_gpu3 -> layer3_gather_q_gpu3 [label="" style=solid]
	layer3_gather_k_gpu3 [label="All-Gather K\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 3" fillcolor=lightblue shape=ellipse style=filled]
	layer3_k_proj_gpu3 -> layer3_gather_k_gpu3 [label="" style=solid]
	layer3_gather_v_gpu3 [label="All-Gather V\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 3" fillcolor=lightblue shape=ellipse style=filled]
	layer3_v_proj_gpu3 -> layer3_gather_v_gpu3 [label="" style=solid]
	layer3_attn_scores_gpu3 [label="QK^T / sqrt(d_k)\nInput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 3" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_gather_q_gpu3 -> layer3_attn_scores_gpu3 [label="" style=solid]
	layer3_gather_k_gpu3 -> layer3_attn_scores_gpu3 [label="" style=solid]
	layer3_softmax_gpu3 [label="Softmax\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 3" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_attn_scores_gpu3 -> layer3_softmax_gpu3 [label="" style=solid]
	layer3_attn_out_gpu3 [label="Attention×V\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 3" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_softmax_gpu3 -> layer3_attn_out_gpu3 [label="" style=solid]
	layer3_gather_v_gpu3 -> layer3_attn_out_gpu3 [label="" style=solid]
	layer3_out_proj_gpu3 [label="Output Projection\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=512]\nGPU: 3" fillcolor=lightgreen shape=rectangle style=filled]
	layer3_attn_out_gpu3 -> layer3_out_proj_gpu3 [label="" style=solid]
	layer3_attn_norm_gpu4 [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 4" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_final_residual -> layer3_attn_norm_gpu4 [label="" style=solid]
	layer3_q_proj_gpu4 [label="Q Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 4" fillcolor=lightgreen shape=rectangle style=filled]
	layer3_attn_norm_gpu4 -> layer3_q_proj_gpu4 [label="" style=solid]
	layer3_k_proj_gpu4 [label="K Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 4" fillcolor=lightgreen shape=rectangle style=filled]
	layer3_attn_norm_gpu4 -> layer3_k_proj_gpu4 [label="" style=solid]
	layer3_v_proj_gpu4 [label="V Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 4" fillcolor=lightgreen shape=rectangle style=filled]
	layer3_attn_norm_gpu4 -> layer3_v_proj_gpu4 [label="" style=solid]
	layer3_gather_q_gpu4 [label="All-Gather Q\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 4" fillcolor=lightblue shape=ellipse style=filled]
	layer3_q_proj_gpu4 -> layer3_gather_q_gpu4 [label="" style=solid]
	layer3_gather_k_gpu4 [label="All-Gather K\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 4" fillcolor=lightblue shape=ellipse style=filled]
	layer3_k_proj_gpu4 -> layer3_gather_k_gpu4 [label="" style=solid]
	layer3_gather_v_gpu4 [label="All-Gather V\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 4" fillcolor=lightblue shape=ellipse style=filled]
	layer3_v_proj_gpu4 -> layer3_gather_v_gpu4 [label="" style=solid]
	layer3_attn_scores_gpu4 [label="QK^T / sqrt(d_k)\nInput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 4" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_gather_q_gpu4 -> layer3_attn_scores_gpu4 [label="" style=solid]
	layer3_gather_k_gpu4 -> layer3_attn_scores_gpu4 [label="" style=solid]
	layer3_softmax_gpu4 [label="Softmax\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 4" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_attn_scores_gpu4 -> layer3_softmax_gpu4 [label="" style=solid]
	layer3_attn_out_gpu4 [label="Attention×V\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 4" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_softmax_gpu4 -> layer3_attn_out_gpu4 [label="" style=solid]
	layer3_gather_v_gpu4 -> layer3_attn_out_gpu4 [label="" style=solid]
	layer3_out_proj_gpu4 [label="Output Projection\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=512]\nGPU: 4" fillcolor=lightgreen shape=rectangle style=filled]
	layer3_attn_out_gpu4 -> layer3_out_proj_gpu4 [label="" style=solid]
	layer3_attn_norm_gpu5 [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 5" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_final_residual -> layer3_attn_norm_gpu5 [label="" style=solid]
	layer3_q_proj_gpu5 [label="Q Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 5" fillcolor=lightgreen shape=rectangle style=filled]
	layer3_attn_norm_gpu5 -> layer3_q_proj_gpu5 [label="" style=solid]
	layer3_k_proj_gpu5 [label="K Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 5" fillcolor=lightgreen shape=rectangle style=filled]
	layer3_attn_norm_gpu5 -> layer3_k_proj_gpu5 [label="" style=solid]
	layer3_v_proj_gpu5 [label="V Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 5" fillcolor=lightgreen shape=rectangle style=filled]
	layer3_attn_norm_gpu5 -> layer3_v_proj_gpu5 [label="" style=solid]
	layer3_gather_q_gpu5 [label="All-Gather Q\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 5" fillcolor=lightblue shape=ellipse style=filled]
	layer3_q_proj_gpu5 -> layer3_gather_q_gpu5 [label="" style=solid]
	layer3_gather_k_gpu5 [label="All-Gather K\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 5" fillcolor=lightblue shape=ellipse style=filled]
	layer3_k_proj_gpu5 -> layer3_gather_k_gpu5 [label="" style=solid]
	layer3_gather_v_gpu5 [label="All-Gather V\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 5" fillcolor=lightblue shape=ellipse style=filled]
	layer3_v_proj_gpu5 -> layer3_gather_v_gpu5 [label="" style=solid]
	layer3_attn_scores_gpu5 [label="QK^T / sqrt(d_k)\nInput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 5" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_gather_q_gpu5 -> layer3_attn_scores_gpu5 [label="" style=solid]
	layer3_gather_k_gpu5 -> layer3_attn_scores_gpu5 [label="" style=solid]
	layer3_softmax_gpu5 [label="Softmax\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 5" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_attn_scores_gpu5 -> layer3_softmax_gpu5 [label="" style=solid]
	layer3_attn_out_gpu5 [label="Attention×V\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 5" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_softmax_gpu5 -> layer3_attn_out_gpu5 [label="" style=solid]
	layer3_gather_v_gpu5 -> layer3_attn_out_gpu5 [label="" style=solid]
	layer3_out_proj_gpu5 [label="Output Projection\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=512]\nGPU: 5" fillcolor=lightgreen shape=rectangle style=filled]
	layer3_attn_out_gpu5 -> layer3_out_proj_gpu5 [label="" style=solid]
	layer3_attn_norm_gpu6 [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 6" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_final_residual -> layer3_attn_norm_gpu6 [label="" style=solid]
	layer3_q_proj_gpu6 [label="Q Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 6" fillcolor=lightgreen shape=rectangle style=filled]
	layer3_attn_norm_gpu6 -> layer3_q_proj_gpu6 [label="" style=solid]
	layer3_k_proj_gpu6 [label="K Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 6" fillcolor=lightgreen shape=rectangle style=filled]
	layer3_attn_norm_gpu6 -> layer3_k_proj_gpu6 [label="" style=solid]
	layer3_v_proj_gpu6 [label="V Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 6" fillcolor=lightgreen shape=rectangle style=filled]
	layer3_attn_norm_gpu6 -> layer3_v_proj_gpu6 [label="" style=solid]
	layer3_gather_q_gpu6 [label="All-Gather Q\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 6" fillcolor=lightblue shape=ellipse style=filled]
	layer3_q_proj_gpu6 -> layer3_gather_q_gpu6 [label="" style=solid]
	layer3_gather_k_gpu6 [label="All-Gather K\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 6" fillcolor=lightblue shape=ellipse style=filled]
	layer3_k_proj_gpu6 -> layer3_gather_k_gpu6 [label="" style=solid]
	layer3_gather_v_gpu6 [label="All-Gather V\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 6" fillcolor=lightblue shape=ellipse style=filled]
	layer3_v_proj_gpu6 -> layer3_gather_v_gpu6 [label="" style=solid]
	layer3_attn_scores_gpu6 [label="QK^T / sqrt(d_k)\nInput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 6" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_gather_q_gpu6 -> layer3_attn_scores_gpu6 [label="" style=solid]
	layer3_gather_k_gpu6 -> layer3_attn_scores_gpu6 [label="" style=solid]
	layer3_softmax_gpu6 [label="Softmax\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 6" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_attn_scores_gpu6 -> layer3_softmax_gpu6 [label="" style=solid]
	layer3_attn_out_gpu6 [label="Attention×V\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 6" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_softmax_gpu6 -> layer3_attn_out_gpu6 [label="" style=solid]
	layer3_gather_v_gpu6 -> layer3_attn_out_gpu6 [label="" style=solid]
	layer3_out_proj_gpu6 [label="Output Projection\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=512]\nGPU: 6" fillcolor=lightgreen shape=rectangle style=filled]
	layer3_attn_out_gpu6 -> layer3_out_proj_gpu6 [label="" style=solid]
	layer3_attn_norm_gpu7 [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 7" fillcolor=lightyellow shape=rectangle style=filled]
	layer2_final_residual -> layer3_attn_norm_gpu7 [label="" style=solid]
	layer3_q_proj_gpu7 [label="Q Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 7" fillcolor=lightgreen shape=rectangle style=filled]
	layer3_attn_norm_gpu7 -> layer3_q_proj_gpu7 [label="" style=solid]
	layer3_k_proj_gpu7 [label="K Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 7" fillcolor=lightgreen shape=rectangle style=filled]
	layer3_attn_norm_gpu7 -> layer3_k_proj_gpu7 [label="" style=solid]
	layer3_v_proj_gpu7 [label="V Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 7" fillcolor=lightgreen shape=rectangle style=filled]
	layer3_attn_norm_gpu7 -> layer3_v_proj_gpu7 [label="" style=solid]
	layer3_gather_q_gpu7 [label="All-Gather Q\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 7" fillcolor=lightblue shape=ellipse style=filled]
	layer3_q_proj_gpu7 -> layer3_gather_q_gpu7 [label="" style=solid]
	layer3_gather_k_gpu7 [label="All-Gather K\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 7" fillcolor=lightblue shape=ellipse style=filled]
	layer3_k_proj_gpu7 -> layer3_gather_k_gpu7 [label="" style=solid]
	layer3_gather_v_gpu7 [label="All-Gather V\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nGPU: 7" fillcolor=lightblue shape=ellipse style=filled]
	layer3_v_proj_gpu7 -> layer3_gather_v_gpu7 [label="" style=solid]
	layer3_attn_scores_gpu7 [label="QK^T / sqrt(d_k)\nInput: [batch_size=batch_size, seq_len=2048, heads=32, d_k=128]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 7" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_gather_q_gpu7 -> layer3_attn_scores_gpu7 [label="" style=solid]
	layer3_gather_k_gpu7 -> layer3_attn_scores_gpu7 [label="" style=solid]
	layer3_softmax_gpu7 [label="Softmax\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nGPU: 7" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_attn_scores_gpu7 -> layer3_softmax_gpu7 [label="" style=solid]
	layer3_attn_out_gpu7 [label="Attention×V\nInput: [batch_size=batch_size, heads=4, seq_len=2048, seq_len=2048]\nOutput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nGPU: 7" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_softmax_gpu7 -> layer3_attn_out_gpu7 [label="" style=solid]
	layer3_gather_v_gpu7 -> layer3_attn_out_gpu7 [label="" style=solid]
	layer3_out_proj_gpu7 [label="Output Projection\nInput: [batch_size=batch_size, seq_len=2048, heads=4, d_k=128]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=512]\nGPU: 7" fillcolor=lightgreen shape=rectangle style=filled]
	layer3_attn_out_gpu7 -> layer3_out_proj_gpu7 [label="" style=solid]
	layer3_attn_all_reduce [label="All-Reduce Attention\nInput: 8×[512]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: GPUs 0-7" fillcolor=lightblue shape=ellipse style=filled]
	layer3_out_proj_gpu0 -> layer3_attn_all_reduce [label="" style=solid]
	layer3_out_proj_gpu1 -> layer3_attn_all_reduce [label="" style=solid]
	layer3_out_proj_gpu2 -> layer3_attn_all_reduce [label="" style=solid]
	layer3_out_proj_gpu3 -> layer3_attn_all_reduce [label="" style=solid]
	layer3_out_proj_gpu4 -> layer3_attn_all_reduce [label="" style=solid]
	layer3_out_proj_gpu5 -> layer3_attn_all_reduce [label="" style=solid]
	layer3_out_proj_gpu6 -> layer3_attn_all_reduce [label="" style=solid]
	layer3_out_proj_gpu7 -> layer3_attn_all_reduce [label="" style=solid]
	layer3_attn_residual [label="Residual Add\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096], [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: all GPUs" fillcolor=lightblue shape=ellipse style=filled]
	layer2_final_residual -> layer3_attn_residual [label="" style=solid]
	layer3_attn_all_reduce -> layer3_attn_residual [label="" style=solid]
	layer3_broadcast_to_moe [label="Broadcast to MoE GPUs\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: GPUs 8-15" fillcolor=lightblue shape=ellipse style=filled]
	layer3_attn_residual -> layer3_broadcast_to_moe [label="" style=solid]
	layer3_moe_norm [label="Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: all GPUs" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_broadcast_to_moe -> layer3_moe_norm [label="" style=solid]
	layer3_gate [label="Gate Network\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, experts=16]\nGPU: all GPUs" fillcolor=lightpink shape=parallelogram style=filled]
	layer3_moe_norm -> layer3_gate [label="" style=solid]
	layer3_route_expert0 [label="Route to Expert 0\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 8" fillcolor=lightpink shape=parallelogram style=filled]
	layer3_gate -> layer3_route_expert0 [label="" style=dashed]
	layer3_moe_norm -> layer3_route_expert0 [label="" style=solid]
	layer3_expert0_up [label="Expert 0 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 8" fillcolor=lightcoral shape=rectangle style=filled]
	layer3_route_expert0 -> layer3_expert0_up [label="" style=solid]
	layer3_expert0_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 8" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_expert0_up -> layer3_expert0_activation [label="" style=solid]
	layer3_expert0_down [label="Expert 0 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 8" fillcolor=lightcoral shape=rectangle style=filled]
	layer3_expert0_activation -> layer3_expert0_down [label="" style=solid]
	layer3_route_back_expert0 [label="Route Back Expert 0\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 8" fillcolor=lightpink shape=parallelogram style=filled]
	layer3_expert0_down -> layer3_route_back_expert0 [label="" style=solid]
	layer3_route_expert1 [label="Route to Expert 1\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 8" fillcolor=lightpink shape=parallelogram style=filled]
	layer3_gate -> layer3_route_expert1 [label="" style=dashed]
	layer3_moe_norm -> layer3_route_expert1 [label="" style=solid]
	layer3_expert1_up [label="Expert 1 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 8" fillcolor=lightcoral shape=rectangle style=filled]
	layer3_route_expert1 -> layer3_expert1_up [label="" style=solid]
	layer3_expert1_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 8" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_expert1_up -> layer3_expert1_activation [label="" style=solid]
	layer3_expert1_down [label="Expert 1 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 8" fillcolor=lightcoral shape=rectangle style=filled]
	layer3_expert1_activation -> layer3_expert1_down [label="" style=solid]
	layer3_route_back_expert1 [label="Route Back Expert 1\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 8" fillcolor=lightpink shape=parallelogram style=filled]
	layer3_expert1_down -> layer3_route_back_expert1 [label="" style=solid]
	layer3_route_expert2 [label="Route to Expert 2\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 9" fillcolor=lightpink shape=parallelogram style=filled]
	layer3_gate -> layer3_route_expert2 [label="" style=dashed]
	layer3_moe_norm -> layer3_route_expert2 [label="" style=solid]
	layer3_expert2_up [label="Expert 2 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 9" fillcolor=lightcoral shape=rectangle style=filled]
	layer3_route_expert2 -> layer3_expert2_up [label="" style=solid]
	layer3_expert2_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 9" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_expert2_up -> layer3_expert2_activation [label="" style=solid]
	layer3_expert2_down [label="Expert 2 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 9" fillcolor=lightcoral shape=rectangle style=filled]
	layer3_expert2_activation -> layer3_expert2_down [label="" style=solid]
	layer3_route_back_expert2 [label="Route Back Expert 2\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 9" fillcolor=lightpink shape=parallelogram style=filled]
	layer3_expert2_down -> layer3_route_back_expert2 [label="" style=solid]
	layer3_route_expert3 [label="Route to Expert 3\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 9" fillcolor=lightpink shape=parallelogram style=filled]
	layer3_gate -> layer3_route_expert3 [label="" style=dashed]
	layer3_moe_norm -> layer3_route_expert3 [label="" style=solid]
	layer3_expert3_up [label="Expert 3 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 9" fillcolor=lightcoral shape=rectangle style=filled]
	layer3_route_expert3 -> layer3_expert3_up [label="" style=solid]
	layer3_expert3_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 9" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_expert3_up -> layer3_expert3_activation [label="" style=solid]
	layer3_expert3_down [label="Expert 3 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 9" fillcolor=lightcoral shape=rectangle style=filled]
	layer3_expert3_activation -> layer3_expert3_down [label="" style=solid]
	layer3_route_back_expert3 [label="Route Back Expert 3\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 9" fillcolor=lightpink shape=parallelogram style=filled]
	layer3_expert3_down -> layer3_route_back_expert3 [label="" style=solid]
	layer3_route_expert4 [label="Route to Expert 4\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 10" fillcolor=lightpink shape=parallelogram style=filled]
	layer3_gate -> layer3_route_expert4 [label="" style=dashed]
	layer3_moe_norm -> layer3_route_expert4 [label="" style=solid]
	layer3_expert4_up [label="Expert 4 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 10" fillcolor=lightcoral shape=rectangle style=filled]
	layer3_route_expert4 -> layer3_expert4_up [label="" style=solid]
	layer3_expert4_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 10" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_expert4_up -> layer3_expert4_activation [label="" style=solid]
	layer3_expert4_down [label="Expert 4 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 10" fillcolor=lightcoral shape=rectangle style=filled]
	layer3_expert4_activation -> layer3_expert4_down [label="" style=solid]
	layer3_route_back_expert4 [label="Route Back Expert 4\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 10" fillcolor=lightpink shape=parallelogram style=filled]
	layer3_expert4_down -> layer3_route_back_expert4 [label="" style=solid]
	layer3_route_expert5 [label="Route to Expert 5\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 10" fillcolor=lightpink shape=parallelogram style=filled]
	layer3_gate -> layer3_route_expert5 [label="" style=dashed]
	layer3_moe_norm -> layer3_route_expert5 [label="" style=solid]
	layer3_expert5_up [label="Expert 5 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 10" fillcolor=lightcoral shape=rectangle style=filled]
	layer3_route_expert5 -> layer3_expert5_up [label="" style=solid]
	layer3_expert5_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 10" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_expert5_up -> layer3_expert5_activation [label="" style=solid]
	layer3_expert5_down [label="Expert 5 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 10" fillcolor=lightcoral shape=rectangle style=filled]
	layer3_expert5_activation -> layer3_expert5_down [label="" style=solid]
	layer3_route_back_expert5 [label="Route Back Expert 5\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 10" fillcolor=lightpink shape=parallelogram style=filled]
	layer3_expert5_down -> layer3_route_back_expert5 [label="" style=solid]
	layer3_route_expert6 [label="Route to Expert 6\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 11" fillcolor=lightpink shape=parallelogram style=filled]
	layer3_gate -> layer3_route_expert6 [label="" style=dashed]
	layer3_moe_norm -> layer3_route_expert6 [label="" style=solid]
	layer3_expert6_up [label="Expert 6 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 11" fillcolor=lightcoral shape=rectangle style=filled]
	layer3_route_expert6 -> layer3_expert6_up [label="" style=solid]
	layer3_expert6_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 11" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_expert6_up -> layer3_expert6_activation [label="" style=solid]
	layer3_expert6_down [label="Expert 6 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 11" fillcolor=lightcoral shape=rectangle style=filled]
	layer3_expert6_activation -> layer3_expert6_down [label="" style=solid]
	layer3_route_back_expert6 [label="Route Back Expert 6\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 11" fillcolor=lightpink shape=parallelogram style=filled]
	layer3_expert6_down -> layer3_route_back_expert6 [label="" style=solid]
	layer3_route_expert7 [label="Route to Expert 7\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 11" fillcolor=lightpink shape=parallelogram style=filled]
	layer3_gate -> layer3_route_expert7 [label="" style=dashed]
	layer3_moe_norm -> layer3_route_expert7 [label="" style=solid]
	layer3_expert7_up [label="Expert 7 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 11" fillcolor=lightcoral shape=rectangle style=filled]
	layer3_route_expert7 -> layer3_expert7_up [label="" style=solid]
	layer3_expert7_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 11" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_expert7_up -> layer3_expert7_activation [label="" style=solid]
	layer3_expert7_down [label="Expert 7 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 11" fillcolor=lightcoral shape=rectangle style=filled]
	layer3_expert7_activation -> layer3_expert7_down [label="" style=solid]
	layer3_route_back_expert7 [label="Route Back Expert 7\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 11" fillcolor=lightpink shape=parallelogram style=filled]
	layer3_expert7_down -> layer3_route_back_expert7 [label="" style=solid]
	layer3_route_expert8 [label="Route to Expert 8\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 12" fillcolor=lightpink shape=parallelogram style=filled]
	layer3_gate -> layer3_route_expert8 [label="" style=dashed]
	layer3_moe_norm -> layer3_route_expert8 [label="" style=solid]
	layer3_expert8_up [label="Expert 8 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 12" fillcolor=lightcoral shape=rectangle style=filled]
	layer3_route_expert8 -> layer3_expert8_up [label="" style=solid]
	layer3_expert8_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 12" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_expert8_up -> layer3_expert8_activation [label="" style=solid]
	layer3_expert8_down [label="Expert 8 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 12" fillcolor=lightcoral shape=rectangle style=filled]
	layer3_expert8_activation -> layer3_expert8_down [label="" style=solid]
	layer3_route_back_expert8 [label="Route Back Expert 8\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 12" fillcolor=lightpink shape=parallelogram style=filled]
	layer3_expert8_down -> layer3_route_back_expert8 [label="" style=solid]
	layer3_route_expert9 [label="Route to Expert 9\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 12" fillcolor=lightpink shape=parallelogram style=filled]
	layer3_gate -> layer3_route_expert9 [label="" style=dashed]
	layer3_moe_norm -> layer3_route_expert9 [label="" style=solid]
	layer3_expert9_up [label="Expert 9 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 12" fillcolor=lightcoral shape=rectangle style=filled]
	layer3_route_expert9 -> layer3_expert9_up [label="" style=solid]
	layer3_expert9_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 12" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_expert9_up -> layer3_expert9_activation [label="" style=solid]
	layer3_expert9_down [label="Expert 9 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 12" fillcolor=lightcoral shape=rectangle style=filled]
	layer3_expert9_activation -> layer3_expert9_down [label="" style=solid]
	layer3_route_back_expert9 [label="Route Back Expert 9\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 12" fillcolor=lightpink shape=parallelogram style=filled]
	layer3_expert9_down -> layer3_route_back_expert9 [label="" style=solid]
	layer3_route_expert10 [label="Route to Expert 10\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 13" fillcolor=lightpink shape=parallelogram style=filled]
	layer3_gate -> layer3_route_expert10 [label="" style=dashed]
	layer3_moe_norm -> layer3_route_expert10 [label="" style=solid]
	layer3_expert10_up [label="Expert 10 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 13" fillcolor=lightcoral shape=rectangle style=filled]
	layer3_route_expert10 -> layer3_expert10_up [label="" style=solid]
	layer3_expert10_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 13" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_expert10_up -> layer3_expert10_activation [label="" style=solid]
	layer3_expert10_down [label="Expert 10 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 13" fillcolor=lightcoral shape=rectangle style=filled]
	layer3_expert10_activation -> layer3_expert10_down [label="" style=solid]
	layer3_route_back_expert10 [label="Route Back Expert 10\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 13" fillcolor=lightpink shape=parallelogram style=filled]
	layer3_expert10_down -> layer3_route_back_expert10 [label="" style=solid]
	layer3_route_expert11 [label="Route to Expert 11\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 13" fillcolor=lightpink shape=parallelogram style=filled]
	layer3_gate -> layer3_route_expert11 [label="" style=dashed]
	layer3_moe_norm -> layer3_route_expert11 [label="" style=solid]
	layer3_expert11_up [label="Expert 11 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 13" fillcolor=lightcoral shape=rectangle style=filled]
	layer3_route_expert11 -> layer3_expert11_up [label="" style=solid]
	layer3_expert11_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 13" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_expert11_up -> layer3_expert11_activation [label="" style=solid]
	layer3_expert11_down [label="Expert 11 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 13" fillcolor=lightcoral shape=rectangle style=filled]
	layer3_expert11_activation -> layer3_expert11_down [label="" style=solid]
	layer3_route_back_expert11 [label="Route Back Expert 11\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 13" fillcolor=lightpink shape=parallelogram style=filled]
	layer3_expert11_down -> layer3_route_back_expert11 [label="" style=solid]
	layer3_route_expert12 [label="Route to Expert 12\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 14" fillcolor=lightpink shape=parallelogram style=filled]
	layer3_gate -> layer3_route_expert12 [label="" style=dashed]
	layer3_moe_norm -> layer3_route_expert12 [label="" style=solid]
	layer3_expert12_up [label="Expert 12 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 14" fillcolor=lightcoral shape=rectangle style=filled]
	layer3_route_expert12 -> layer3_expert12_up [label="" style=solid]
	layer3_expert12_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 14" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_expert12_up -> layer3_expert12_activation [label="" style=solid]
	layer3_expert12_down [label="Expert 12 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 14" fillcolor=lightcoral shape=rectangle style=filled]
	layer3_expert12_activation -> layer3_expert12_down [label="" style=solid]
	layer3_route_back_expert12 [label="Route Back Expert 12\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 14" fillcolor=lightpink shape=parallelogram style=filled]
	layer3_expert12_down -> layer3_route_back_expert12 [label="" style=solid]
	layer3_route_expert13 [label="Route to Expert 13\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 14" fillcolor=lightpink shape=parallelogram style=filled]
	layer3_gate -> layer3_route_expert13 [label="" style=dashed]
	layer3_moe_norm -> layer3_route_expert13 [label="" style=solid]
	layer3_expert13_up [label="Expert 13 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 14" fillcolor=lightcoral shape=rectangle style=filled]
	layer3_route_expert13 -> layer3_expert13_up [label="" style=solid]
	layer3_expert13_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 14" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_expert13_up -> layer3_expert13_activation [label="" style=solid]
	layer3_expert13_down [label="Expert 13 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 14" fillcolor=lightcoral shape=rectangle style=filled]
	layer3_expert13_activation -> layer3_expert13_down [label="" style=solid]
	layer3_route_back_expert13 [label="Route Back Expert 13\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 14" fillcolor=lightpink shape=parallelogram style=filled]
	layer3_expert13_down -> layer3_route_back_expert13 [label="" style=solid]
	layer3_route_expert14 [label="Route to Expert 14\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 15" fillcolor=lightpink shape=parallelogram style=filled]
	layer3_gate -> layer3_route_expert14 [label="" style=dashed]
	layer3_moe_norm -> layer3_route_expert14 [label="" style=solid]
	layer3_expert14_up [label="Expert 14 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 15" fillcolor=lightcoral shape=rectangle style=filled]
	layer3_route_expert14 -> layer3_expert14_up [label="" style=solid]
	layer3_expert14_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 15" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_expert14_up -> layer3_expert14_activation [label="" style=solid]
	layer3_expert14_down [label="Expert 14 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 15" fillcolor=lightcoral shape=rectangle style=filled]
	layer3_expert14_activation -> layer3_expert14_down [label="" style=solid]
	layer3_route_back_expert14 [label="Route Back Expert 14\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 15" fillcolor=lightpink shape=parallelogram style=filled]
	layer3_expert14_down -> layer3_route_back_expert14 [label="" style=solid]
	layer3_route_expert15 [label="Route to Expert 15\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [tokens, hidden_dim=4096]\nGPU: 15" fillcolor=lightpink shape=parallelogram style=filled]
	layer3_gate -> layer3_route_expert15 [label="" style=dashed]
	layer3_moe_norm -> layer3_route_expert15 [label="" style=solid]
	layer3_expert15_up [label="Expert 15 Up\nInput: [tokens, hidden_dim=4096]\nOutput: [tokens, hidden_dim=16384]\nGPU: 15" fillcolor=lightcoral shape=rectangle style=filled]
	layer3_route_expert15 -> layer3_expert15_up [label="" style=solid]
	layer3_expert15_activation [label="GELU\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=16384]\nGPU: 15" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_expert15_up -> layer3_expert15_activation [label="" style=solid]
	layer3_expert15_down [label="Expert 15 Down\nInput: [tokens, hidden_dim=16384]\nOutput: [tokens, hidden_dim=4096]\nGPU: 15" fillcolor=lightcoral shape=rectangle style=filled]
	layer3_expert15_activation -> layer3_expert15_down [label="" style=solid]
	layer3_route_back_expert15 [label="Route Back Expert 15\nInput: [tokens, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: 15" fillcolor=lightpink shape=parallelogram style=filled]
	layer3_expert15_down -> layer3_route_back_expert15 [label="" style=solid]
	layer3_expert_agg [label="Aggregate Experts\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: all GPUs" fillcolor=lightblue shape=ellipse style=filled]
	layer3_route_back_expert0 -> layer3_expert_agg [label="" style=solid]
	layer3_route_back_expert1 -> layer3_expert_agg [label="" style=solid]
	layer3_route_back_expert2 -> layer3_expert_agg [label="" style=solid]
	layer3_route_back_expert3 -> layer3_expert_agg [label="" style=solid]
	layer3_route_back_expert4 -> layer3_expert_agg [label="" style=solid]
	layer3_route_back_expert5 -> layer3_expert_agg [label="" style=solid]
	layer3_route_back_expert6 -> layer3_expert_agg [label="" style=solid]
	layer3_route_back_expert7 -> layer3_expert_agg [label="" style=solid]
	layer3_route_back_expert8 -> layer3_expert_agg [label="" style=solid]
	layer3_route_back_expert9 -> layer3_expert_agg [label="" style=solid]
	layer3_route_back_expert10 -> layer3_expert_agg [label="" style=solid]
	layer3_route_back_expert11 -> layer3_expert_agg [label="" style=solid]
	layer3_route_back_expert12 -> layer3_expert_agg [label="" style=solid]
	layer3_route_back_expert13 -> layer3_expert_agg [label="" style=solid]
	layer3_route_back_expert14 -> layer3_expert_agg [label="" style=solid]
	layer3_route_back_expert15 -> layer3_expert_agg [label="" style=solid]
	layer3_final_residual [label="Final Residual Add\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096], [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: all GPUs" fillcolor=lightblue shape=ellipse style=filled]
	layer3_attn_residual -> layer3_final_residual [label="" style=solid]
	layer3_expert_agg -> layer3_final_residual [label="" style=solid]
	final_norm [label="Final Layer Norm\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nGPU: all GPUs" fillcolor=lightyellow shape=rectangle style=filled]
	layer3_final_residual -> final_norm [label="" style=solid]
	output_projection [label="Output Projection\nInput: [batch_size=batch_size, seq_len=2048, hidden_dim=4096]\nOutput: [batch_size=batch_size, seq_len=2048, vocab_size=vocab_size]\nGPU: all GPUs" fillcolor=lightgreen shape=rectangle style=filled]
	final_norm -> output_projection [label="" style=solid]
	model_output [label="Model Output\nInput: [batch_size=batch_size, seq_len=2048, vocab_size=vocab_size]\nOutput: [batch_size=batch_size, seq_len=2048, vocab_size=vocab_size]\nGPU: all GPUs" fillcolor=lightblue shape=ellipse style=filled]
	output_projection -> model_output [label="" style=solid]
}
