{
  "generated_dags": {
    "ma_separation_strategy": {
      "description": "MA Separation parallel strategy DAG for 4-layer MoE transformer with 16 experts per layer",
      "total_gpus": 16,
      "gpu_allocation": {
        "attention_gpus": 12,
        "moe_gpus": 4,
        "attention_gpu_list": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],
        "moe_gpu_list": [12, 13, 14, 15]
      },
      "files": {
        "dot_file": "../outputs/2025-10-19-23-59-31/ma_separation_dag.dot",
        "svg_file": "../outputs/2025-10-19-23-59-31/ma_separation_dag.svg"
      },
      "verification": {
        "has_cycles": false,
        "complete_dag": true,
        "all_dimensions_specified": true,
        "gpu_load_balanced": true
      }
    },
    "baseline_hybrid_tp_pp": {
      "description": "Baseline Hybrid Tensor Parallelism (TP=8) + Pipeline Parallelism (PP=2) DAG",
      "total_gpus": 16,
      "gpu_allocation": {
        "stage_0_gpus": [0, 1, 2, 3, 4, 5, 6, 7],
        "stage_1_gpus": [8, 9, 10, 11, 12, 13, 14, 15],
        "layers_per_stage": 2
      },
      "files": {
        "dot_file": "../outputs/2025-10-19-23-59-31/baseline_hybrid_tp_pp_dag.dot",
        "svg_file": "../outputs/2025-10-19-23-59-31/baseline_hybrid_tp_pp_dag.svg"
      },
      "verification": {
        "has_cycles": false,
        "complete_dag": true,
        "all_dimensions_specified": true,
        "gpu_load_balanced": true
      }
    }
  },
  "model_specifications": {
    "architecture": "4_layer_moe_transformer",
    "hidden_size": 4096,
    "attention_heads": 32,
    "head_dimension": 128,
    "sequence_length": 2048,
    "moe_experts_per_layer": 16,
    "expert_hidden_size": 16384,
    "top_k_routing": 2,
    "vocabulary_size": 50265,
    "batch_size": 1024
  },
  "dag_features": {
    "node_types": {
      "ellipse": ["Input", "Output"],
      "rectangle": ["Computation nodes (layers, projections, experts)"],
      "parallelogram": ["Communication/aggregation nodes", "Residual connections"]
    },
    "edge_types": {
      "solid": "Data flow between computation nodes",
      "dashed": "Cross-GPU communication or routing",
      "colored": "Specific GPU communication paths"
    },
    "attributes_per_node": [
      "Input dimensions with exact specifications",
      "Output dimensions with exact specifications", 
      "GPU assignment (specific GPU number or 'all GPUs')",
      "Operation type and parameters"
    ]
  },
  "submission_info": {
    "total_files_generated": 4,
    "files_list": [
      "../outputs/2025-10-19-23-59-31/ma_separation_dag.dot",
      "../outputs/2025-10-19-23-59-31/ma_separation_dag.svg",
      "../outputs/2025-10-19-23-59-31/baseline_hybrid_tp_pp_dag.dot",
      "../outputs/2025-10-19-23-59-31/baseline_hybrid_tp_pp_dag.svg"
    ],
    "verification_completed": true,
    "meets_all_requirements": true
  }
}