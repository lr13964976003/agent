{
  "deployment_configuration": {
    "model_specifications": {
      "total_layers": 61,
      "dense_layers": 3,
      "moe_layers": 58,
      "token_dimension": 7168,
      "mlp_hidden_size": 18432,
      "mla_heads": 128,
      "mla_head_dimension": 56,
      "precision": "BF16"
    },
    "parallel_strategies": {
      "expert_parallelism": {
        "type": "large_scale_cross_node",
        "ep_degree": 16,
        "experts_per_gpu": 1,
        "placement_strategy": "topology_aware"
      },
      "tensor_parallelism": {
        "type": "optional_within_expert",
        "enabled": false,
        "tp_degree": 1
      },
      "data_parallelism": {
        "type": "replica_based",
        "dp_degree": 1
      }
    },
    "expert_configuration": {
      "experts_per_moe_layer": 16,
      "total_experts": 928,
      "expert_type": "MLP",
      "activation_function": "GELU"
    },
    "gpu_allocation": {
      "total_gpus_required": 928,
      "gpus_per_layer": 16,
      "gpu_model": "H100",
      "memory_per_gpu": "64GB",
      "compute_per_gpu": "400TFlops"
    },
    "communication_strategy": {
      "token_routing": "asynchronous",
      "batching_method": "destination_expert_grouping",
      "overlap_type": "compute_communication_interleaving",
      "libraries": ["NCCL", "MPI"],
      "streams": "CUDA_streams"
    },
    "device_mapping": {
      "layer_0_to_2": {
        "type": "dense_layers",
        "devices": ["gpu_0", "gpu_1", "gpu_2"],
        "distribution": "replicated_across_dp"
      },
      "layer_3_to_60": {
        "type": "moe_layers",
        "expert_placement": {
          "layer_3": {
            "expert_0": "gpu_0",
            "expert_1": "gpu_1",
            "expert_2": "gpu_2",
            "expert_3": "gpu_3",
            "expert_4": "gpu_4",
            "expert_5": "gpu_5",
            "expert_6": "gpu_6",
            "expert_7": "gpu_7",
            "expert_8": "gpu_8",
            "expert_9": "gpu_9",
            "expert_10": "gpu_10",
            "expert_11": "gpu_11",
            "expert_12": "gpu_12",
            "expert_13": "gpu_13",
            "expert_14": "gpu_14",
            "expert_15": "gpu_15"
          },
          "layer_4": {
            "expert_0": "gpu_16",
            "expert_1": "gpu_17",
            "expert_2": "gpu_18",
            "expert_3": "gpu_19",
            "expert_4": "gpu_20",
            "expert_5": "gpu_21",
            "expert_6": "gpu_22",
            "expert_7": "gpu_23",
            "expert_8": "gpu_24",
            "expert_9": "gpu_25",
            "expert_10": "gpu_26",
            "expert_11": "gpu_27",
            "expert_12": "gpu_28",
            "expert_13": "gpu_29",
            "expert_14": "gpu_30",
            "expert_15": "gpu_31"
          }
        }
      }
    },
    "routing_configuration": {
      "gating_mechanism": "top_k_selection",
      "k_value": 2,
      "load_balancing": "dynamic_probability_adjustment",
      "token_batching": "destination_based_grouping",
      "asynchronous_routing": true
    },
    "performance_parameters": {
      "mfu_utilization": "60%",
      "bandwidth_utilization": "80%",
      "target_throughput": "maximized",
      "target_latency": "minimized",
      "scalability_target": "near_linear"
    },
    "memory_configuration": {
      "kv_cache_optimization": "MLA_compressed",
      "latent_dimension": "reduced_from_7168",
      "memory_efficiency": "high"
    }
  }
}