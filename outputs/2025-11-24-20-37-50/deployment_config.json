{
  "deployment_configurations": {
    "baseline": {
      "name": "Traditional Tensor + Pipeline Parallelism",
      "total_devices": 16,
      "parallel_strategy": {
        "type": "hybrid",
        "tensor_parallelism": {
          "degree": 8,
          "method": "column_row_split"
        },
        "pipeline_parallelism": {
          "degree": 2,
          "stages": 2,
          "layers_per_stage": 2
        }
      },
      "device_mapping": {
        "stage_0": {
          "devices": [0, 1, 2, 3, 4, 5, 6, 7],
          "layers": [0, 1],
          "tensor_parallel_slices": {
            "attention_weights": 8,
            "mlp_weights": 8
          }
        },
        "stage_1": {
          "devices": [8, 9, 10, 11, 12, 13, 14, 15],
          "layers": [2, 3],
          "tensor_parallel_slices": {
            "attention_weights": 8,
            "mlp_weights": 8
          }
        }
      },
      "model_parameters": {
        "total_layers": 4,
        "hidden_size": 4096,
        "num_attention_heads": 32,
        "head_dimension": 128,
        "mlp_hidden_size": 16384,
        "sequence_length": 10000,
        "batch_size": 128,
        "precision": "FP16"
      },
      "communication_overhead": {
        "tensor_parallel_reduce": "all_reduce",
        "pipeline_parallel_send_recv": "point_to_point"
      }
    },
    "proposed": {
      "name": "Two-Level Attention Partitioning",
      "total_devices": 16,
      "parallel_strategy": {
        "type": "attention_partitioning",
        "head_partitions": {
          "n": 4,
          "heads_per_group": 8
        },
        "dimension_partitions": {
          "m": 4,
          "slice_size": 32
        },
        "total_partitions": 16
      },
      "device_mapping": {
        "partition_0_0": {
          "device": 0,
          "head_group": 0,
          "head_indices": [0, 1, 2, 3, 4, 5, 6, 7],
          "dimension_slice": [0, 31],
          "weight_blocks": {
            "W_Q": {"shape": [1024, 1024], "offsets": [0, 0]},
            "W_K": {"shape": [1024, 1024], "offsets": [0, 0]},
            "W_V": {"shape": [1024, 1024], "offsets": [0, 0]}
          }
        },
        "partition_0_1": {
          "device": 1,
          "head_group": 0,
          "head_indices": [0, 1, 2, 3, 4, 5, 6, 7],
          "dimension_slice": [32, 63],
          "weight_blocks": {
            "W_Q": {"shape": [1024, 1024], "offsets": [0, 1024]},
            "W_K": {"shape": [1024, 1024], "offsets": [0, 1024]},
            "W_V": {"shape": [1024, 1024], "offsets": [0, 1024]}
          }
        },
        "partition_0_2": {
          "device": 2,
          "head_group": 0,
          "head_indices": [0, 1, 2, 3, 4, 5, 6, 7],
          "dimension_slice": [64, 95],
          "weight_blocks": {
            "W_Q": {"shape": [1024, 1024], "offsets": [0, 2048]},
            "W_K": {"shape": [1024, 1024], "offsets": [0, 2048]},
            "W_V": {"shape": [1024, 1024], "offsets": [0, 2048]}
          }
        },
        "partition_0_3": {
          "device": 3,
          "head_group": 0,
          "head_indices": [0, 1, 2, 3, 4, 5, 6, 7],
          "dimension_slice": [96, 127],
          "weight_blocks": {
            "W_Q": {"shape": [1024, 1024], "offsets": [0, 3072]},
            "W_K": {"shape": [1024, 1024], "offsets": [0, 3072]},
            "W_V": {"shape": [1024, 1024], "offsets": [0, 3072]}
          }
        },
        "partition_1_0": {
          "device": 4,
          "head_group": 1,
          "head_indices": [8, 9, 10, 11, 12, 13, 14, 15],
          "dimension_slice": [0, 31],
          "weight_blocks": {
            "W_Q": {"shape": [1024, 1024], "offsets": [1024, 0]},
            "W_K": {"shape": [1024, 1024], "offsets": [1024, 0]},
            "W_V": {"shape": [1024, 1024], "offsets": [1024, 0]}
          }
        },
        "partition_1_1": {
          "device": 5,
          "head_group": 1,
          "head_indices": [8, 9, 10, 11, 12, 13, 14, 15],
          "dimension_slice": [32, 63],
          "weight_blocks": {
            "W_Q": {"shape": [1024, 1024], "offsets": [1024, 1024]},
            "W_K": {"shape": [1024, 1024], "offsets": [1024, 1024]},
            "W_V": {"shape": [1024, 1024], "offsets": [1024, 1024]}
          }
        },
        "partition_1_2": {
          "device": 6,
          "head_group": 1,
          "head_indices": [8, 9, 10, 11, 12, 13, 14, 15],
          "dimension_slice": [64, 95],
          "weight_blocks": {
            "W_Q": {"shape": [1024, 1024], "offsets": [1024, 2048]},
            "W_K": {"shape": [1024, 1024], "offsets": [1024, 2048]},
            "W_V": {"shape": [1024, 1024], "offsets": [1024, 2048]}
          }
        },
        "partition_1_3": {
          "device": 7,
          "head_group": 1,
          "head_indices": [8, 9, 10, 11, 12, 13, 14, 15],
          "dimension_slice": [96, 127],
          "weight_blocks": {
            "W_Q": {"shape": [1024, 1024], "offsets": [1024, 3072]},
            "W_K": {"shape": [1024, 1024], "offsets": [1024, 3072]},
            "W_V": {"shape": [1024, 1024], "offsets": [1024, 3072]}
          }
        },
        "partition_2_0": {
          "device": 8,
          "head_group": 2,
          "head_indices": [16, 17, 18, 19, 20, 21, 22, 23],
          "dimension_slice": [0, 31],
          "weight_blocks": {
            "W_Q": {"shape": [1024, 1024], "offsets": [2048, 0]},
            "W_K": {"shape": [1024, 1024], "offsets": [2048, 0]},
            "W_V": {"shape": [1024, 1024], "offsets": [2048, 0]}
          }
        },
        "partition_2_1": {
          "device": 9,
          "head_group": 2,
          "head_indices": [16, 17, 18, 19, 20, 21, 22, 23],
          "dimension_slice": [32, 63],
          "weight_blocks": {
            "W_Q": {"shape": [1024, 1024], "offsets": [2048, 1024]},
            "W_K": {"shape": [1024, 1024], "offsets": [2048, 1024]},
            "W_V": {"shape": [1024, 1024], "offsets": [2048, 1024]}
          }
        },
        "partition_2_2": {
          "device": 10,
          "head_group": 2,
          "head_indices": [16, 17, 18, 19, 20, 21, 22, 23],
          "dimension_slice": [64, 95],
          "weight_blocks": {
            "W_Q": {"shape": [1024, 1024], "offsets": [2048, 2048]},
            "W_K": {"shape": [1024, 1024], "offsets": [2048, 2048]},
            "W_V": {"shape": [1024, 1024], "offsets": [2048, 2048]}
          }
        },
        "partition_2_3": {
          "device": 11,
          "head_group": 2,
          "head_indices": [16, 17, 18, 19, 20, 21, 22, 23],
          "dimension_slice": [96, 127],
          "weight_blocks": {
            "W_Q": {"shape": [1024, 1024], "offsets": [2048, 3072]},
            "W_K": {"shape": [1024, 1024], "offsets": [2048, 3072]},
            "W_V": {"shape": [1024, 1024], "offsets": [2048, 3072]}
          }
        },
        "partition_3_0": {
          "device": 12,
          "head_group": 3,
          "head_indices": [24, 25, 26, 27, 28, 29, 30, 31],
          "dimension_slice": [0, 31],
          "weight_blocks": {
            "W_Q": {"shape": [1024, 1024], "offsets": [3072, 0]},
            "W_K": {"shape": [1024, 1024], "offsets": [3072, 0]},
            "W_V": {"shape": [1024, 1024], "offsets": [3072, 0]}
          }
        },
        "partition_3_1": {
          "device": 13,
          "head_group": 3,
          "head_indices": [24, 25, 26, 27, 28, 29, 30, 31],
          "dimension_slice": [32, 63],
          "weight_blocks": {
            "W_Q": {"shape": [1024, 1024], "offsets": [3072, 1024]},
            "W_K": {"shape": [1024, 1024], "offsets": [3072, 1024]},
            "W_V": {"shape": [1024, 1024], "offsets": [3072, 1024]}
          }
        },
        "partition_3_2": {
          "device": 14,
          "head_group": 3,
          "head_indices": [24, 25, 26, 27, 28, 29, 30, 31],
          "dimension_slice": [64, 95],
          "weight_blocks": {
            "W_Q": {"shape": [1024, 1024], "offsets": [3072, 2048]},
            "W_K": {"shape": [1024, 1024], "offsets": [3072, 2048]},
            "W_V": {"shape": [1024, 1024], "offsets": [3072, 2048]}
          }
        },
        "partition_3_3": {
          "device": 15,
          "head_group": 3,
          "head_indices": [24, 25, 26, 27, 28, 29, 30, 31],
          "dimension_slice": [96, 127],
          "weight_blocks": {
            "W_Q": {"shape": [1024, 1024], "offsets": [3072, 3072]},
            "W_K": {"shape": [1024, 1024], "offsets": [3072, 3072]},
            "W_V": {"shape": [1024, 1024], "offsets": [3072, 3072]}
          }
        }
      },
      "model_parameters": {
        "total_layers": 4,
        "hidden_size": 4096,
        "num_attention_heads": 32,
        "head_dimension": 128,
        "mlp_hidden_size": 16384,
        "sequence_length": 10000,
        "batch_size": 128,
        "precision": "FP16"
      },
      "communication_pattern": {
        "within_head_group": "concatenate_dimensions",
        "across_head_groups": "concatenate_heads",
        "input_distribution": "broadcast_to_all",
        "output_aggregation": "hierarchical_concatenation"
      },
      "aggregation_stages": {
        "stage_1": {
          "type": "dimension_concatenation",
          "groups": [
            {"group": 0, "devices": [0, 1, 2, 3], "output_shape": [1024, 128]},
            {"group": 1, "devices": [4, 5, 6, 7], "output_shape": [1024, 128]},
            {"group": 2, "devices": [8, 9, 10, 11], "output_shape": [1024, 128]},
            {"group": 3, "devices": [12, 13, 14, 15], "output_shape": [1024, 128]}
          ]
        },
        "stage_2": {
          "type": "head_concatenation",
          "devices": [0, 4, 8, 12],
          "final_output_shape": [4096, 128]
        }
      }
    }
  }
}