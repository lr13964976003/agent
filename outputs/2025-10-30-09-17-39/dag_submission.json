{
  "submission": {
    "timestamp": "2025-10-30-09-17-39",
    "hpipe_deployments": [
      {
        "model": "LLaMA-7B",
        "method": "HPipe",
        "files": {
          "dot_path": "../outputs/2025-10-30-09-17-39/llama_7b_hpipe.dot",
          "svg_path": "../outputs/2025-10-30-09-17-39/llama_7b_hpipe.svg",
          "python_generator": "../outputs/2025-10-30-09-17-39/llama_7b_hpipe_dag.py"
        },
        "deployment_details": {
          "total_layers": 32,
          "devices": ["P100_1", "P100_2", "P100_3", "P100_4", "RTX3090_1"],
          "layer_distribution": [
            {"device": "P100_1", "layers": [1, 4], "count": 4},
            {"device": "P100_2", "layers": [5, 9], "count": 5},
            {"device": "P100_3", "layers": [10, 14], "count": 5},
            {"device": "P100_4", "layers": [15, 18], "count": 4},
            {"device": "RTX3090_1", "layers": [19, 32], "count": 14}
          ],
          "token_pipelining": true,
          "sequence_slices": 15
        }
      },
      {
        "model": "GPT3-2B",
        "method": "HPipe",
        "files": {
          "dot_path": "../outputs/2025-10-30-09-17-39/gpt3_2b_hpipe.dot",
          "svg_path": "../outputs/2025-10-30-09-17-39/gpt3_2b_hpipe.svg",
          "python_generator": "../outputs/2025-10-30-09-17-39/gpt3_2b_hpipe_dag.py"
        },
        "deployment_details": {
          "total_layers": 24,
          "devices": ["P100_1", "P100_2", "P100_3", "P100_4", "RTX3090_1", "RTX3090_2"],
          "layer_distribution": [
            {"device": "P100_1", "layers": [1, 4], "count": 4},
            {"device": "P100_2", "layers": [5, 8], "count": 4},
            {"device": "P100_3", "layers": [9, 12], "count": 4},
            {"device": "P100_4", "layers": [13, 16], "count": 4},
            {"device": "RTX3090_1", "layers": [17, 20], "count": 4},
            {"device": "RTX3090_2", "layers": [21, 24], "count": 4}
          ],
          "token_pipelining": true,
          "sequence_slices": 12
        }
      }
    ],
    "baseline_comparisons": [
      {
        "method": "Sequential (Base)",
        "description": "Single GPU sequential execution without parallelism",
        "files": {
          "dot_path": "../outputs/2025-10-30-09-17-39/baseline_sequential.dot",
          "svg_path": "../outputs/2025-10-30-09-17-39/baseline_sequential.svg",
          "python_generator": "../outputs/2025-10-30-09-17-39/baseline_sequential_dag.py"
        }
      },
      {
        "method": "GPipe",
        "description": "Micro-batch pipeline parallelism with uniform layer distribution",
        "files": {
          "dot_path": "../outputs/2025-10-30-09-17-39/baseline_gpipe.dot",
          "svg_path": "../outputs/2025-10-30-09-17-39/baseline_gpipe.svg",
          "python_generator": "../outputs/2025-10-30-09-17-39/baseline_gpipe_dag.py"
        }
      },
      {
        "method": "Megatron-LM",
        "description": "Tensor parallelism + pipeline parallelism combination",
        "files": {
          "dot_path": "../outputs/2025-10-30-09-17-39/megatron_lm.dot",
          "svg_path": "../outputs/2025-10-30-09-17-39/megatron_lm.svg",
          "python_generator": "../outputs/2025-10-30-09-17-39/megatron_lm_dag.py"
        }
      }
    ],
    "validation": {
      "all_dags_generated": true,
      "formats_included": ["dot", "svg"],
      "dimensions_specified": true,
      "device_assignments_complete": true,
      "communication_paths_modeled": true,
      "load_balancing_addressed": true,
      "no_cycles_detected": true
    }
  }
}