digraph MoE_Proposed_EP16 {
	graph [bgcolor=white rankdir=TB]
	node [fontname=Arial fontsize=10]
	model_input [label="model_input\nModel Input\nGPU: 0-15\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=1024, seq_len=10000, hidden_dim=8192" color=black shape=ellipse]
	layer0_input_broadcast [label="layer0_input_broadcast\nLayer Input Broadcast\nGPU: 0-15\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=1024, seq_len=10000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu0_attn_input_reshape [label="layer0_gpu0_attn_input_reshape\nInput Reshape\nGPU: 0\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu0_q_proj [label="layer0_gpu0_q_proj\nQ Projection\nGPU: 0\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu0_k_proj [label="layer0_gpu0_k_proj\nK Projection\nGPU: 0\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu0_v_proj [label="layer0_gpu0_v_proj\nV Projection\nGPU: 0\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu0_mha [label="layer0_gpu0_mha\nMulti-Head Attention\nGPU: 0\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu0_o_proj [label="layer0_gpu0_o_proj\nOutput Projection\nGPU: 0\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer0_gpu0_attn_residual [label="layer0_gpu0_attn_residual\nResidual Add\nGPU: 0\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu0_attn_input_reshape -> layer0_gpu0_q_proj [label="" style=solid]
	layer0_gpu0_attn_input_reshape -> layer0_gpu0_k_proj [label="" style=solid]
	layer0_gpu0_attn_input_reshape -> layer0_gpu0_v_proj [label="" style=solid]
	layer0_gpu0_q_proj -> layer0_gpu0_mha [label="" style=solid]
	layer0_gpu0_k_proj -> layer0_gpu0_mha [label="" style=solid]
	layer0_gpu0_v_proj -> layer0_gpu0_mha [label="" style=solid]
	layer0_gpu0_mha -> layer0_gpu0_o_proj [label="" style=solid]
	layer0_gpu0_o_proj -> layer0_gpu0_attn_residual [label="" style=solid]
	layer0_gpu0_attn_input_reshape -> layer0_gpu0_attn_residual [label="" style=dashed]
	layer0_input_broadcast -> layer0_gpu0_attn_input_reshape [label="" style=solid]
	layer0_gpu1_attn_input_reshape [label="layer0_gpu1_attn_input_reshape\nInput Reshape\nGPU: 1\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu1_q_proj [label="layer0_gpu1_q_proj\nQ Projection\nGPU: 1\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu1_k_proj [label="layer0_gpu1_k_proj\nK Projection\nGPU: 1\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu1_v_proj [label="layer0_gpu1_v_proj\nV Projection\nGPU: 1\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu1_mha [label="layer0_gpu1_mha\nMulti-Head Attention\nGPU: 1\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu1_o_proj [label="layer0_gpu1_o_proj\nOutput Projection\nGPU: 1\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer0_gpu1_attn_residual [label="layer0_gpu1_attn_residual\nResidual Add\nGPU: 1\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu1_attn_input_reshape -> layer0_gpu1_q_proj [label="" style=solid]
	layer0_gpu1_attn_input_reshape -> layer0_gpu1_k_proj [label="" style=solid]
	layer0_gpu1_attn_input_reshape -> layer0_gpu1_v_proj [label="" style=solid]
	layer0_gpu1_q_proj -> layer0_gpu1_mha [label="" style=solid]
	layer0_gpu1_k_proj -> layer0_gpu1_mha [label="" style=solid]
	layer0_gpu1_v_proj -> layer0_gpu1_mha [label="" style=solid]
	layer0_gpu1_mha -> layer0_gpu1_o_proj [label="" style=solid]
	layer0_gpu1_o_proj -> layer0_gpu1_attn_residual [label="" style=solid]
	layer0_gpu1_attn_input_reshape -> layer0_gpu1_attn_residual [label="" style=dashed]
	layer0_input_broadcast -> layer0_gpu1_attn_input_reshape [label="" style=solid]
	layer0_gpu2_attn_input_reshape [label="layer0_gpu2_attn_input_reshape\nInput Reshape\nGPU: 2\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu2_q_proj [label="layer0_gpu2_q_proj\nQ Projection\nGPU: 2\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu2_k_proj [label="layer0_gpu2_k_proj\nK Projection\nGPU: 2\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu2_v_proj [label="layer0_gpu2_v_proj\nV Projection\nGPU: 2\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu2_mha [label="layer0_gpu2_mha\nMulti-Head Attention\nGPU: 2\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu2_o_proj [label="layer0_gpu2_o_proj\nOutput Projection\nGPU: 2\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer0_gpu2_attn_residual [label="layer0_gpu2_attn_residual\nResidual Add\nGPU: 2\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu2_attn_input_reshape -> layer0_gpu2_q_proj [label="" style=solid]
	layer0_gpu2_attn_input_reshape -> layer0_gpu2_k_proj [label="" style=solid]
	layer0_gpu2_attn_input_reshape -> layer0_gpu2_v_proj [label="" style=solid]
	layer0_gpu2_q_proj -> layer0_gpu2_mha [label="" style=solid]
	layer0_gpu2_k_proj -> layer0_gpu2_mha [label="" style=solid]
	layer0_gpu2_v_proj -> layer0_gpu2_mha [label="" style=solid]
	layer0_gpu2_mha -> layer0_gpu2_o_proj [label="" style=solid]
	layer0_gpu2_o_proj -> layer0_gpu2_attn_residual [label="" style=solid]
	layer0_gpu2_attn_input_reshape -> layer0_gpu2_attn_residual [label="" style=dashed]
	layer0_input_broadcast -> layer0_gpu2_attn_input_reshape [label="" style=solid]
	layer0_gpu3_attn_input_reshape [label="layer0_gpu3_attn_input_reshape\nInput Reshape\nGPU: 3\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu3_q_proj [label="layer0_gpu3_q_proj\nQ Projection\nGPU: 3\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu3_k_proj [label="layer0_gpu3_k_proj\nK Projection\nGPU: 3\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu3_v_proj [label="layer0_gpu3_v_proj\nV Projection\nGPU: 3\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu3_mha [label="layer0_gpu3_mha\nMulti-Head Attention\nGPU: 3\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu3_o_proj [label="layer0_gpu3_o_proj\nOutput Projection\nGPU: 3\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer0_gpu3_attn_residual [label="layer0_gpu3_attn_residual\nResidual Add\nGPU: 3\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu3_attn_input_reshape -> layer0_gpu3_q_proj [label="" style=solid]
	layer0_gpu3_attn_input_reshape -> layer0_gpu3_k_proj [label="" style=solid]
	layer0_gpu3_attn_input_reshape -> layer0_gpu3_v_proj [label="" style=solid]
	layer0_gpu3_q_proj -> layer0_gpu3_mha [label="" style=solid]
	layer0_gpu3_k_proj -> layer0_gpu3_mha [label="" style=solid]
	layer0_gpu3_v_proj -> layer0_gpu3_mha [label="" style=solid]
	layer0_gpu3_mha -> layer0_gpu3_o_proj [label="" style=solid]
	layer0_gpu3_o_proj -> layer0_gpu3_attn_residual [label="" style=solid]
	layer0_gpu3_attn_input_reshape -> layer0_gpu3_attn_residual [label="" style=dashed]
	layer0_input_broadcast -> layer0_gpu3_attn_input_reshape [label="" style=solid]
	layer0_gpu4_attn_input_reshape [label="layer0_gpu4_attn_input_reshape\nInput Reshape\nGPU: 4\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu4_q_proj [label="layer0_gpu4_q_proj\nQ Projection\nGPU: 4\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu4_k_proj [label="layer0_gpu4_k_proj\nK Projection\nGPU: 4\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu4_v_proj [label="layer0_gpu4_v_proj\nV Projection\nGPU: 4\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu4_mha [label="layer0_gpu4_mha\nMulti-Head Attention\nGPU: 4\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu4_o_proj [label="layer0_gpu4_o_proj\nOutput Projection\nGPU: 4\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer0_gpu4_attn_residual [label="layer0_gpu4_attn_residual\nResidual Add\nGPU: 4\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu4_attn_input_reshape -> layer0_gpu4_q_proj [label="" style=solid]
	layer0_gpu4_attn_input_reshape -> layer0_gpu4_k_proj [label="" style=solid]
	layer0_gpu4_attn_input_reshape -> layer0_gpu4_v_proj [label="" style=solid]
	layer0_gpu4_q_proj -> layer0_gpu4_mha [label="" style=solid]
	layer0_gpu4_k_proj -> layer0_gpu4_mha [label="" style=solid]
	layer0_gpu4_v_proj -> layer0_gpu4_mha [label="" style=solid]
	layer0_gpu4_mha -> layer0_gpu4_o_proj [label="" style=solid]
	layer0_gpu4_o_proj -> layer0_gpu4_attn_residual [label="" style=solid]
	layer0_gpu4_attn_input_reshape -> layer0_gpu4_attn_residual [label="" style=dashed]
	layer0_input_broadcast -> layer0_gpu4_attn_input_reshape [label="" style=solid]
	layer0_gpu5_attn_input_reshape [label="layer0_gpu5_attn_input_reshape\nInput Reshape\nGPU: 5\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu5_q_proj [label="layer0_gpu5_q_proj\nQ Projection\nGPU: 5\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu5_k_proj [label="layer0_gpu5_k_proj\nK Projection\nGPU: 5\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu5_v_proj [label="layer0_gpu5_v_proj\nV Projection\nGPU: 5\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu5_mha [label="layer0_gpu5_mha\nMulti-Head Attention\nGPU: 5\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu5_o_proj [label="layer0_gpu5_o_proj\nOutput Projection\nGPU: 5\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer0_gpu5_attn_residual [label="layer0_gpu5_attn_residual\nResidual Add\nGPU: 5\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu5_attn_input_reshape -> layer0_gpu5_q_proj [label="" style=solid]
	layer0_gpu5_attn_input_reshape -> layer0_gpu5_k_proj [label="" style=solid]
	layer0_gpu5_attn_input_reshape -> layer0_gpu5_v_proj [label="" style=solid]
	layer0_gpu5_q_proj -> layer0_gpu5_mha [label="" style=solid]
	layer0_gpu5_k_proj -> layer0_gpu5_mha [label="" style=solid]
	layer0_gpu5_v_proj -> layer0_gpu5_mha [label="" style=solid]
	layer0_gpu5_mha -> layer0_gpu5_o_proj [label="" style=solid]
	layer0_gpu5_o_proj -> layer0_gpu5_attn_residual [label="" style=solid]
	layer0_gpu5_attn_input_reshape -> layer0_gpu5_attn_residual [label="" style=dashed]
	layer0_input_broadcast -> layer0_gpu5_attn_input_reshape [label="" style=solid]
	layer0_gpu6_attn_input_reshape [label="layer0_gpu6_attn_input_reshape\nInput Reshape\nGPU: 6\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu6_q_proj [label="layer0_gpu6_q_proj\nQ Projection\nGPU: 6\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu6_k_proj [label="layer0_gpu6_k_proj\nK Projection\nGPU: 6\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu6_v_proj [label="layer0_gpu6_v_proj\nV Projection\nGPU: 6\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu6_mha [label="layer0_gpu6_mha\nMulti-Head Attention\nGPU: 6\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu6_o_proj [label="layer0_gpu6_o_proj\nOutput Projection\nGPU: 6\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer0_gpu6_attn_residual [label="layer0_gpu6_attn_residual\nResidual Add\nGPU: 6\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu6_attn_input_reshape -> layer0_gpu6_q_proj [label="" style=solid]
	layer0_gpu6_attn_input_reshape -> layer0_gpu6_k_proj [label="" style=solid]
	layer0_gpu6_attn_input_reshape -> layer0_gpu6_v_proj [label="" style=solid]
	layer0_gpu6_q_proj -> layer0_gpu6_mha [label="" style=solid]
	layer0_gpu6_k_proj -> layer0_gpu6_mha [label="" style=solid]
	layer0_gpu6_v_proj -> layer0_gpu6_mha [label="" style=solid]
	layer0_gpu6_mha -> layer0_gpu6_o_proj [label="" style=solid]
	layer0_gpu6_o_proj -> layer0_gpu6_attn_residual [label="" style=solid]
	layer0_gpu6_attn_input_reshape -> layer0_gpu6_attn_residual [label="" style=dashed]
	layer0_input_broadcast -> layer0_gpu6_attn_input_reshape [label="" style=solid]
	layer0_gpu7_attn_input_reshape [label="layer0_gpu7_attn_input_reshape\nInput Reshape\nGPU: 7\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu7_q_proj [label="layer0_gpu7_q_proj\nQ Projection\nGPU: 7\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu7_k_proj [label="layer0_gpu7_k_proj\nK Projection\nGPU: 7\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu7_v_proj [label="layer0_gpu7_v_proj\nV Projection\nGPU: 7\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu7_mha [label="layer0_gpu7_mha\nMulti-Head Attention\nGPU: 7\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu7_o_proj [label="layer0_gpu7_o_proj\nOutput Projection\nGPU: 7\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer0_gpu7_attn_residual [label="layer0_gpu7_attn_residual\nResidual Add\nGPU: 7\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu7_attn_input_reshape -> layer0_gpu7_q_proj [label="" style=solid]
	layer0_gpu7_attn_input_reshape -> layer0_gpu7_k_proj [label="" style=solid]
	layer0_gpu7_attn_input_reshape -> layer0_gpu7_v_proj [label="" style=solid]
	layer0_gpu7_q_proj -> layer0_gpu7_mha [label="" style=solid]
	layer0_gpu7_k_proj -> layer0_gpu7_mha [label="" style=solid]
	layer0_gpu7_v_proj -> layer0_gpu7_mha [label="" style=solid]
	layer0_gpu7_mha -> layer0_gpu7_o_proj [label="" style=solid]
	layer0_gpu7_o_proj -> layer0_gpu7_attn_residual [label="" style=solid]
	layer0_gpu7_attn_input_reshape -> layer0_gpu7_attn_residual [label="" style=dashed]
	layer0_input_broadcast -> layer0_gpu7_attn_input_reshape [label="" style=solid]
	layer0_gpu8_attn_input_reshape [label="layer0_gpu8_attn_input_reshape\nInput Reshape\nGPU: 8\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu8_q_proj [label="layer0_gpu8_q_proj\nQ Projection\nGPU: 8\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu8_k_proj [label="layer0_gpu8_k_proj\nK Projection\nGPU: 8\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu8_v_proj [label="layer0_gpu8_v_proj\nV Projection\nGPU: 8\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu8_mha [label="layer0_gpu8_mha\nMulti-Head Attention\nGPU: 8\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu8_o_proj [label="layer0_gpu8_o_proj\nOutput Projection\nGPU: 8\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer0_gpu8_attn_residual [label="layer0_gpu8_attn_residual\nResidual Add\nGPU: 8\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu8_attn_input_reshape -> layer0_gpu8_q_proj [label="" style=solid]
	layer0_gpu8_attn_input_reshape -> layer0_gpu8_k_proj [label="" style=solid]
	layer0_gpu8_attn_input_reshape -> layer0_gpu8_v_proj [label="" style=solid]
	layer0_gpu8_q_proj -> layer0_gpu8_mha [label="" style=solid]
	layer0_gpu8_k_proj -> layer0_gpu8_mha [label="" style=solid]
	layer0_gpu8_v_proj -> layer0_gpu8_mha [label="" style=solid]
	layer0_gpu8_mha -> layer0_gpu8_o_proj [label="" style=solid]
	layer0_gpu8_o_proj -> layer0_gpu8_attn_residual [label="" style=solid]
	layer0_gpu8_attn_input_reshape -> layer0_gpu8_attn_residual [label="" style=dashed]
	layer0_input_broadcast -> layer0_gpu8_attn_input_reshape [label="" style=solid]
	layer0_gpu9_attn_input_reshape [label="layer0_gpu9_attn_input_reshape\nInput Reshape\nGPU: 9\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu9_q_proj [label="layer0_gpu9_q_proj\nQ Projection\nGPU: 9\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu9_k_proj [label="layer0_gpu9_k_proj\nK Projection\nGPU: 9\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu9_v_proj [label="layer0_gpu9_v_proj\nV Projection\nGPU: 9\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu9_mha [label="layer0_gpu9_mha\nMulti-Head Attention\nGPU: 9\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu9_o_proj [label="layer0_gpu9_o_proj\nOutput Projection\nGPU: 9\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer0_gpu9_attn_residual [label="layer0_gpu9_attn_residual\nResidual Add\nGPU: 9\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu9_attn_input_reshape -> layer0_gpu9_q_proj [label="" style=solid]
	layer0_gpu9_attn_input_reshape -> layer0_gpu9_k_proj [label="" style=solid]
	layer0_gpu9_attn_input_reshape -> layer0_gpu9_v_proj [label="" style=solid]
	layer0_gpu9_q_proj -> layer0_gpu9_mha [label="" style=solid]
	layer0_gpu9_k_proj -> layer0_gpu9_mha [label="" style=solid]
	layer0_gpu9_v_proj -> layer0_gpu9_mha [label="" style=solid]
	layer0_gpu9_mha -> layer0_gpu9_o_proj [label="" style=solid]
	layer0_gpu9_o_proj -> layer0_gpu9_attn_residual [label="" style=solid]
	layer0_gpu9_attn_input_reshape -> layer0_gpu9_attn_residual [label="" style=dashed]
	layer0_input_broadcast -> layer0_gpu9_attn_input_reshape [label="" style=solid]
	layer0_gpu10_attn_input_reshape [label="layer0_gpu10_attn_input_reshape\nInput Reshape\nGPU: 10\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu10_q_proj [label="layer0_gpu10_q_proj\nQ Projection\nGPU: 10\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu10_k_proj [label="layer0_gpu10_k_proj\nK Projection\nGPU: 10\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu10_v_proj [label="layer0_gpu10_v_proj\nV Projection\nGPU: 10\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu10_mha [label="layer0_gpu10_mha\nMulti-Head Attention\nGPU: 10\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu10_o_proj [label="layer0_gpu10_o_proj\nOutput Projection\nGPU: 10\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer0_gpu10_attn_residual [label="layer0_gpu10_attn_residual\nResidual Add\nGPU: 10\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu10_attn_input_reshape -> layer0_gpu10_q_proj [label="" style=solid]
	layer0_gpu10_attn_input_reshape -> layer0_gpu10_k_proj [label="" style=solid]
	layer0_gpu10_attn_input_reshape -> layer0_gpu10_v_proj [label="" style=solid]
	layer0_gpu10_q_proj -> layer0_gpu10_mha [label="" style=solid]
	layer0_gpu10_k_proj -> layer0_gpu10_mha [label="" style=solid]
	layer0_gpu10_v_proj -> layer0_gpu10_mha [label="" style=solid]
	layer0_gpu10_mha -> layer0_gpu10_o_proj [label="" style=solid]
	layer0_gpu10_o_proj -> layer0_gpu10_attn_residual [label="" style=solid]
	layer0_gpu10_attn_input_reshape -> layer0_gpu10_attn_residual [label="" style=dashed]
	layer0_input_broadcast -> layer0_gpu10_attn_input_reshape [label="" style=solid]
	layer0_gpu11_attn_input_reshape [label="layer0_gpu11_attn_input_reshape\nInput Reshape\nGPU: 11\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu11_q_proj [label="layer0_gpu11_q_proj\nQ Projection\nGPU: 11\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu11_k_proj [label="layer0_gpu11_k_proj\nK Projection\nGPU: 11\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu11_v_proj [label="layer0_gpu11_v_proj\nV Projection\nGPU: 11\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu11_mha [label="layer0_gpu11_mha\nMulti-Head Attention\nGPU: 11\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu11_o_proj [label="layer0_gpu11_o_proj\nOutput Projection\nGPU: 11\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer0_gpu11_attn_residual [label="layer0_gpu11_attn_residual\nResidual Add\nGPU: 11\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu11_attn_input_reshape -> layer0_gpu11_q_proj [label="" style=solid]
	layer0_gpu11_attn_input_reshape -> layer0_gpu11_k_proj [label="" style=solid]
	layer0_gpu11_attn_input_reshape -> layer0_gpu11_v_proj [label="" style=solid]
	layer0_gpu11_q_proj -> layer0_gpu11_mha [label="" style=solid]
	layer0_gpu11_k_proj -> layer0_gpu11_mha [label="" style=solid]
	layer0_gpu11_v_proj -> layer0_gpu11_mha [label="" style=solid]
	layer0_gpu11_mha -> layer0_gpu11_o_proj [label="" style=solid]
	layer0_gpu11_o_proj -> layer0_gpu11_attn_residual [label="" style=solid]
	layer0_gpu11_attn_input_reshape -> layer0_gpu11_attn_residual [label="" style=dashed]
	layer0_input_broadcast -> layer0_gpu11_attn_input_reshape [label="" style=solid]
	layer0_gpu12_attn_input_reshape [label="layer0_gpu12_attn_input_reshape\nInput Reshape\nGPU: 12\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu12_q_proj [label="layer0_gpu12_q_proj\nQ Projection\nGPU: 12\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu12_k_proj [label="layer0_gpu12_k_proj\nK Projection\nGPU: 12\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu12_v_proj [label="layer0_gpu12_v_proj\nV Projection\nGPU: 12\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu12_mha [label="layer0_gpu12_mha\nMulti-Head Attention\nGPU: 12\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu12_o_proj [label="layer0_gpu12_o_proj\nOutput Projection\nGPU: 12\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer0_gpu12_attn_residual [label="layer0_gpu12_attn_residual\nResidual Add\nGPU: 12\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu12_attn_input_reshape -> layer0_gpu12_q_proj [label="" style=solid]
	layer0_gpu12_attn_input_reshape -> layer0_gpu12_k_proj [label="" style=solid]
	layer0_gpu12_attn_input_reshape -> layer0_gpu12_v_proj [label="" style=solid]
	layer0_gpu12_q_proj -> layer0_gpu12_mha [label="" style=solid]
	layer0_gpu12_k_proj -> layer0_gpu12_mha [label="" style=solid]
	layer0_gpu12_v_proj -> layer0_gpu12_mha [label="" style=solid]
	layer0_gpu12_mha -> layer0_gpu12_o_proj [label="" style=solid]
	layer0_gpu12_o_proj -> layer0_gpu12_attn_residual [label="" style=solid]
	layer0_gpu12_attn_input_reshape -> layer0_gpu12_attn_residual [label="" style=dashed]
	layer0_input_broadcast -> layer0_gpu12_attn_input_reshape [label="" style=solid]
	layer0_gpu13_attn_input_reshape [label="layer0_gpu13_attn_input_reshape\nInput Reshape\nGPU: 13\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu13_q_proj [label="layer0_gpu13_q_proj\nQ Projection\nGPU: 13\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu13_k_proj [label="layer0_gpu13_k_proj\nK Projection\nGPU: 13\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu13_v_proj [label="layer0_gpu13_v_proj\nV Projection\nGPU: 13\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu13_mha [label="layer0_gpu13_mha\nMulti-Head Attention\nGPU: 13\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu13_o_proj [label="layer0_gpu13_o_proj\nOutput Projection\nGPU: 13\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer0_gpu13_attn_residual [label="layer0_gpu13_attn_residual\nResidual Add\nGPU: 13\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu13_attn_input_reshape -> layer0_gpu13_q_proj [label="" style=solid]
	layer0_gpu13_attn_input_reshape -> layer0_gpu13_k_proj [label="" style=solid]
	layer0_gpu13_attn_input_reshape -> layer0_gpu13_v_proj [label="" style=solid]
	layer0_gpu13_q_proj -> layer0_gpu13_mha [label="" style=solid]
	layer0_gpu13_k_proj -> layer0_gpu13_mha [label="" style=solid]
	layer0_gpu13_v_proj -> layer0_gpu13_mha [label="" style=solid]
	layer0_gpu13_mha -> layer0_gpu13_o_proj [label="" style=solid]
	layer0_gpu13_o_proj -> layer0_gpu13_attn_residual [label="" style=solid]
	layer0_gpu13_attn_input_reshape -> layer0_gpu13_attn_residual [label="" style=dashed]
	layer0_input_broadcast -> layer0_gpu13_attn_input_reshape [label="" style=solid]
	layer0_gpu14_attn_input_reshape [label="layer0_gpu14_attn_input_reshape\nInput Reshape\nGPU: 14\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu14_q_proj [label="layer0_gpu14_q_proj\nQ Projection\nGPU: 14\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu14_k_proj [label="layer0_gpu14_k_proj\nK Projection\nGPU: 14\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu14_v_proj [label="layer0_gpu14_v_proj\nV Projection\nGPU: 14\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu14_mha [label="layer0_gpu14_mha\nMulti-Head Attention\nGPU: 14\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu14_o_proj [label="layer0_gpu14_o_proj\nOutput Projection\nGPU: 14\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer0_gpu14_attn_residual [label="layer0_gpu14_attn_residual\nResidual Add\nGPU: 14\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu14_attn_input_reshape -> layer0_gpu14_q_proj [label="" style=solid]
	layer0_gpu14_attn_input_reshape -> layer0_gpu14_k_proj [label="" style=solid]
	layer0_gpu14_attn_input_reshape -> layer0_gpu14_v_proj [label="" style=solid]
	layer0_gpu14_q_proj -> layer0_gpu14_mha [label="" style=solid]
	layer0_gpu14_k_proj -> layer0_gpu14_mha [label="" style=solid]
	layer0_gpu14_v_proj -> layer0_gpu14_mha [label="" style=solid]
	layer0_gpu14_mha -> layer0_gpu14_o_proj [label="" style=solid]
	layer0_gpu14_o_proj -> layer0_gpu14_attn_residual [label="" style=solid]
	layer0_gpu14_attn_input_reshape -> layer0_gpu14_attn_residual [label="" style=dashed]
	layer0_input_broadcast -> layer0_gpu14_attn_input_reshape [label="" style=solid]
	layer0_gpu15_attn_input_reshape [label="layer0_gpu15_attn_input_reshape\nInput Reshape\nGPU: 15\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu15_q_proj [label="layer0_gpu15_q_proj\nQ Projection\nGPU: 15\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu15_k_proj [label="layer0_gpu15_k_proj\nK Projection\nGPU: 15\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu15_v_proj [label="layer0_gpu15_v_proj\nV Projection\nGPU: 15\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu15_mha [label="layer0_gpu15_mha\nMulti-Head Attention\nGPU: 15\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer0_gpu15_o_proj [label="layer0_gpu15_o_proj\nOutput Projection\nGPU: 15\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer0_gpu15_attn_residual [label="layer0_gpu15_attn_residual\nResidual Add\nGPU: 15\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu15_attn_input_reshape -> layer0_gpu15_q_proj [label="" style=solid]
	layer0_gpu15_attn_input_reshape -> layer0_gpu15_k_proj [label="" style=solid]
	layer0_gpu15_attn_input_reshape -> layer0_gpu15_v_proj [label="" style=solid]
	layer0_gpu15_q_proj -> layer0_gpu15_mha [label="" style=solid]
	layer0_gpu15_k_proj -> layer0_gpu15_mha [label="" style=solid]
	layer0_gpu15_v_proj -> layer0_gpu15_mha [label="" style=solid]
	layer0_gpu15_mha -> layer0_gpu15_o_proj [label="" style=solid]
	layer0_gpu15_o_proj -> layer0_gpu15_attn_residual [label="" style=solid]
	layer0_gpu15_attn_input_reshape -> layer0_gpu15_attn_residual [label="" style=dashed]
	layer0_input_broadcast -> layer0_gpu15_attn_input_reshape [label="" style=solid]
	layer0_attn_output_broadcast_gpu0 [label="layer0_attn_output_broadcast_gpu0\nAttention Output Broadcast\nGPU: 0\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu0_attn_residual -> layer0_attn_output_broadcast_gpu0 [label="" style=solid]
	layer0_attn_output_broadcast_gpu1 [label="layer0_attn_output_broadcast_gpu1\nAttention Output Broadcast\nGPU: 1\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu1_attn_residual -> layer0_attn_output_broadcast_gpu1 [label="" style=solid]
	layer0_attn_output_broadcast_gpu2 [label="layer0_attn_output_broadcast_gpu2\nAttention Output Broadcast\nGPU: 2\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu2_attn_residual -> layer0_attn_output_broadcast_gpu2 [label="" style=solid]
	layer0_attn_output_broadcast_gpu3 [label="layer0_attn_output_broadcast_gpu3\nAttention Output Broadcast\nGPU: 3\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu3_attn_residual -> layer0_attn_output_broadcast_gpu3 [label="" style=solid]
	layer0_attn_output_broadcast_gpu4 [label="layer0_attn_output_broadcast_gpu4\nAttention Output Broadcast\nGPU: 4\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu4_attn_residual -> layer0_attn_output_broadcast_gpu4 [label="" style=solid]
	layer0_attn_output_broadcast_gpu5 [label="layer0_attn_output_broadcast_gpu5\nAttention Output Broadcast\nGPU: 5\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu5_attn_residual -> layer0_attn_output_broadcast_gpu5 [label="" style=solid]
	layer0_attn_output_broadcast_gpu6 [label="layer0_attn_output_broadcast_gpu6\nAttention Output Broadcast\nGPU: 6\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu6_attn_residual -> layer0_attn_output_broadcast_gpu6 [label="" style=solid]
	layer0_attn_output_broadcast_gpu7 [label="layer0_attn_output_broadcast_gpu7\nAttention Output Broadcast\nGPU: 7\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu7_attn_residual -> layer0_attn_output_broadcast_gpu7 [label="" style=solid]
	layer0_attn_output_broadcast_gpu8 [label="layer0_attn_output_broadcast_gpu8\nAttention Output Broadcast\nGPU: 8\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu8_attn_residual -> layer0_attn_output_broadcast_gpu8 [label="" style=solid]
	layer0_attn_output_broadcast_gpu9 [label="layer0_attn_output_broadcast_gpu9\nAttention Output Broadcast\nGPU: 9\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu9_attn_residual -> layer0_attn_output_broadcast_gpu9 [label="" style=solid]
	layer0_attn_output_broadcast_gpu10 [label="layer0_attn_output_broadcast_gpu10\nAttention Output Broadcast\nGPU: 10\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu10_attn_residual -> layer0_attn_output_broadcast_gpu10 [label="" style=solid]
	layer0_attn_output_broadcast_gpu11 [label="layer0_attn_output_broadcast_gpu11\nAttention Output Broadcast\nGPU: 11\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu11_attn_residual -> layer0_attn_output_broadcast_gpu11 [label="" style=solid]
	layer0_attn_output_broadcast_gpu12 [label="layer0_attn_output_broadcast_gpu12\nAttention Output Broadcast\nGPU: 12\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu12_attn_residual -> layer0_attn_output_broadcast_gpu12 [label="" style=solid]
	layer0_attn_output_broadcast_gpu13 [label="layer0_attn_output_broadcast_gpu13\nAttention Output Broadcast\nGPU: 13\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu13_attn_residual -> layer0_attn_output_broadcast_gpu13 [label="" style=solid]
	layer0_attn_output_broadcast_gpu14 [label="layer0_attn_output_broadcast_gpu14\nAttention Output Broadcast\nGPU: 14\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu14_attn_residual -> layer0_attn_output_broadcast_gpu14 [label="" style=solid]
	layer0_attn_output_broadcast_gpu15 [label="layer0_attn_output_broadcast_gpu15\nAttention Output Broadcast\nGPU: 15\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_gpu15_attn_residual -> layer0_attn_output_broadcast_gpu15 [label="" style=solid]
	layer0_gating_network [label="layer0_gating_network\nGating Network\nGPU: 0-15\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, num_experts=16" color=black shape=parallelogram]
	layer0_gating_selection [label="layer0_gating_selection\nExpert Selection\nGPU: 0-15\nIn: batch_size=10240000, num_experts=16\nOut: batch_size=10240000, selected_experts=2" color=black shape=parallelogram]
	layer0_gating_network -> layer0_gating_selection [label="" style=solid]
	layer0_routing_route_to_expert0 [label="layer0_routing_route_to_expert0\nRoute to Expert 0\nGPU: 0\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer0_gating_selection -> layer0_routing_route_to_expert0 [label="" style=dashed]
	layer0_routing_route_to_expert1 [label="layer0_routing_route_to_expert1\nRoute to Expert 1\nGPU: 1\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer0_gating_selection -> layer0_routing_route_to_expert1 [label="" style=dashed]
	layer0_routing_route_to_expert2 [label="layer0_routing_route_to_expert2\nRoute to Expert 2\nGPU: 2\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer0_gating_selection -> layer0_routing_route_to_expert2 [label="" style=dashed]
	layer0_routing_route_to_expert3 [label="layer0_routing_route_to_expert3\nRoute to Expert 3\nGPU: 3\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer0_gating_selection -> layer0_routing_route_to_expert3 [label="" style=dashed]
	layer0_routing_route_to_expert4 [label="layer0_routing_route_to_expert4\nRoute to Expert 4\nGPU: 4\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer0_gating_selection -> layer0_routing_route_to_expert4 [label="" style=dashed]
	layer0_routing_route_to_expert5 [label="layer0_routing_route_to_expert5\nRoute to Expert 5\nGPU: 5\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer0_gating_selection -> layer0_routing_route_to_expert5 [label="" style=dashed]
	layer0_routing_route_to_expert6 [label="layer0_routing_route_to_expert6\nRoute to Expert 6\nGPU: 6\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer0_gating_selection -> layer0_routing_route_to_expert6 [label="" style=dashed]
	layer0_routing_route_to_expert7 [label="layer0_routing_route_to_expert7\nRoute to Expert 7\nGPU: 7\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer0_gating_selection -> layer0_routing_route_to_expert7 [label="" style=dashed]
	layer0_routing_route_to_expert8 [label="layer0_routing_route_to_expert8\nRoute to Expert 8\nGPU: 8\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer0_gating_selection -> layer0_routing_route_to_expert8 [label="" style=dashed]
	layer0_routing_route_to_expert9 [label="layer0_routing_route_to_expert9\nRoute to Expert 9\nGPU: 9\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer0_gating_selection -> layer0_routing_route_to_expert9 [label="" style=dashed]
	layer0_routing_route_to_expert10 [label="layer0_routing_route_to_expert10\nRoute to Expert 10\nGPU: 10\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer0_gating_selection -> layer0_routing_route_to_expert10 [label="" style=dashed]
	layer0_routing_route_to_expert11 [label="layer0_routing_route_to_expert11\nRoute to Expert 11\nGPU: 11\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer0_gating_selection -> layer0_routing_route_to_expert11 [label="" style=dashed]
	layer0_routing_route_to_expert12 [label="layer0_routing_route_to_expert12\nRoute to Expert 12\nGPU: 12\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer0_gating_selection -> layer0_routing_route_to_expert12 [label="" style=dashed]
	layer0_routing_route_to_expert13 [label="layer0_routing_route_to_expert13\nRoute to Expert 13\nGPU: 13\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer0_gating_selection -> layer0_routing_route_to_expert13 [label="" style=dashed]
	layer0_routing_route_to_expert14 [label="layer0_routing_route_to_expert14\nRoute to Expert 14\nGPU: 14\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer0_gating_selection -> layer0_routing_route_to_expert14 [label="" style=dashed]
	layer0_routing_route_to_expert15 [label="layer0_routing_route_to_expert15\nRoute to Expert 15\nGPU: 15\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer0_gating_selection -> layer0_routing_route_to_expert15 [label="" style=dashed]
	layer0_expert0_gpu0_gate_proj [label="layer0_expert0_gpu0_gate_proj\nGate Projection\nGPU: 0\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer0_expert0_gpu0_up_proj [label="layer0_expert0_gpu0_up_proj\nUp Projection\nGPU: 0\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer0_expert0_gpu0_activation [label="layer0_expert0_gpu0_activation\nGELU Activation\nGPU: 0\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer0_expert0_gpu0_down_proj [label="layer0_expert0_gpu0_down_proj\nDown Projection\nGPU: 0\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer0_expert0_gpu0_gate_proj -> layer0_expert0_gpu0_activation [label="" style=solid]
	layer0_expert0_gpu0_up_proj -> layer0_expert0_gpu0_down_proj [label="" style=solid]
	layer0_expert0_gpu0_activation -> layer0_expert0_gpu0_down_proj [label="" style=solid]
	layer0_routing_route_to_expert0 -> layer0_expert0_gpu0_gate_proj [label="" style=solid]
	layer0_routing_route_to_expert0 -> layer0_expert0_gpu0_up_proj [label="" style=solid]
	layer0_expert1_gpu1_gate_proj [label="layer0_expert1_gpu1_gate_proj\nGate Projection\nGPU: 1\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer0_expert1_gpu1_up_proj [label="layer0_expert1_gpu1_up_proj\nUp Projection\nGPU: 1\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer0_expert1_gpu1_activation [label="layer0_expert1_gpu1_activation\nGELU Activation\nGPU: 1\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer0_expert1_gpu1_down_proj [label="layer0_expert1_gpu1_down_proj\nDown Projection\nGPU: 1\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer0_expert1_gpu1_gate_proj -> layer0_expert1_gpu1_activation [label="" style=solid]
	layer0_expert1_gpu1_up_proj -> layer0_expert1_gpu1_down_proj [label="" style=solid]
	layer0_expert1_gpu1_activation -> layer0_expert1_gpu1_down_proj [label="" style=solid]
	layer0_routing_route_to_expert1 -> layer0_expert1_gpu1_gate_proj [label="" style=solid]
	layer0_routing_route_to_expert1 -> layer0_expert1_gpu1_up_proj [label="" style=solid]
	layer0_expert2_gpu2_gate_proj [label="layer0_expert2_gpu2_gate_proj\nGate Projection\nGPU: 2\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer0_expert2_gpu2_up_proj [label="layer0_expert2_gpu2_up_proj\nUp Projection\nGPU: 2\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer0_expert2_gpu2_activation [label="layer0_expert2_gpu2_activation\nGELU Activation\nGPU: 2\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer0_expert2_gpu2_down_proj [label="layer0_expert2_gpu2_down_proj\nDown Projection\nGPU: 2\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer0_expert2_gpu2_gate_proj -> layer0_expert2_gpu2_activation [label="" style=solid]
	layer0_expert2_gpu2_up_proj -> layer0_expert2_gpu2_down_proj [label="" style=solid]
	layer0_expert2_gpu2_activation -> layer0_expert2_gpu2_down_proj [label="" style=solid]
	layer0_routing_route_to_expert2 -> layer0_expert2_gpu2_gate_proj [label="" style=solid]
	layer0_routing_route_to_expert2 -> layer0_expert2_gpu2_up_proj [label="" style=solid]
	layer0_expert3_gpu3_gate_proj [label="layer0_expert3_gpu3_gate_proj\nGate Projection\nGPU: 3\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer0_expert3_gpu3_up_proj [label="layer0_expert3_gpu3_up_proj\nUp Projection\nGPU: 3\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer0_expert3_gpu3_activation [label="layer0_expert3_gpu3_activation\nGELU Activation\nGPU: 3\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer0_expert3_gpu3_down_proj [label="layer0_expert3_gpu3_down_proj\nDown Projection\nGPU: 3\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer0_expert3_gpu3_gate_proj -> layer0_expert3_gpu3_activation [label="" style=solid]
	layer0_expert3_gpu3_up_proj -> layer0_expert3_gpu3_down_proj [label="" style=solid]
	layer0_expert3_gpu3_activation -> layer0_expert3_gpu3_down_proj [label="" style=solid]
	layer0_routing_route_to_expert3 -> layer0_expert3_gpu3_gate_proj [label="" style=solid]
	layer0_routing_route_to_expert3 -> layer0_expert3_gpu3_up_proj [label="" style=solid]
	layer0_expert4_gpu4_gate_proj [label="layer0_expert4_gpu4_gate_proj\nGate Projection\nGPU: 4\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer0_expert4_gpu4_up_proj [label="layer0_expert4_gpu4_up_proj\nUp Projection\nGPU: 4\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer0_expert4_gpu4_activation [label="layer0_expert4_gpu4_activation\nGELU Activation\nGPU: 4\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer0_expert4_gpu4_down_proj [label="layer0_expert4_gpu4_down_proj\nDown Projection\nGPU: 4\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer0_expert4_gpu4_gate_proj -> layer0_expert4_gpu4_activation [label="" style=solid]
	layer0_expert4_gpu4_up_proj -> layer0_expert4_gpu4_down_proj [label="" style=solid]
	layer0_expert4_gpu4_activation -> layer0_expert4_gpu4_down_proj [label="" style=solid]
	layer0_routing_route_to_expert4 -> layer0_expert4_gpu4_gate_proj [label="" style=solid]
	layer0_routing_route_to_expert4 -> layer0_expert4_gpu4_up_proj [label="" style=solid]
	layer0_expert5_gpu5_gate_proj [label="layer0_expert5_gpu5_gate_proj\nGate Projection\nGPU: 5\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer0_expert5_gpu5_up_proj [label="layer0_expert5_gpu5_up_proj\nUp Projection\nGPU: 5\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer0_expert5_gpu5_activation [label="layer0_expert5_gpu5_activation\nGELU Activation\nGPU: 5\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer0_expert5_gpu5_down_proj [label="layer0_expert5_gpu5_down_proj\nDown Projection\nGPU: 5\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer0_expert5_gpu5_gate_proj -> layer0_expert5_gpu5_activation [label="" style=solid]
	layer0_expert5_gpu5_up_proj -> layer0_expert5_gpu5_down_proj [label="" style=solid]
	layer0_expert5_gpu5_activation -> layer0_expert5_gpu5_down_proj [label="" style=solid]
	layer0_routing_route_to_expert5 -> layer0_expert5_gpu5_gate_proj [label="" style=solid]
	layer0_routing_route_to_expert5 -> layer0_expert5_gpu5_up_proj [label="" style=solid]
	layer0_expert6_gpu6_gate_proj [label="layer0_expert6_gpu6_gate_proj\nGate Projection\nGPU: 6\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer0_expert6_gpu6_up_proj [label="layer0_expert6_gpu6_up_proj\nUp Projection\nGPU: 6\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer0_expert6_gpu6_activation [label="layer0_expert6_gpu6_activation\nGELU Activation\nGPU: 6\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer0_expert6_gpu6_down_proj [label="layer0_expert6_gpu6_down_proj\nDown Projection\nGPU: 6\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer0_expert6_gpu6_gate_proj -> layer0_expert6_gpu6_activation [label="" style=solid]
	layer0_expert6_gpu6_up_proj -> layer0_expert6_gpu6_down_proj [label="" style=solid]
	layer0_expert6_gpu6_activation -> layer0_expert6_gpu6_down_proj [label="" style=solid]
	layer0_routing_route_to_expert6 -> layer0_expert6_gpu6_gate_proj [label="" style=solid]
	layer0_routing_route_to_expert6 -> layer0_expert6_gpu6_up_proj [label="" style=solid]
	layer0_expert7_gpu7_gate_proj [label="layer0_expert7_gpu7_gate_proj\nGate Projection\nGPU: 7\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer0_expert7_gpu7_up_proj [label="layer0_expert7_gpu7_up_proj\nUp Projection\nGPU: 7\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer0_expert7_gpu7_activation [label="layer0_expert7_gpu7_activation\nGELU Activation\nGPU: 7\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer0_expert7_gpu7_down_proj [label="layer0_expert7_gpu7_down_proj\nDown Projection\nGPU: 7\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer0_expert7_gpu7_gate_proj -> layer0_expert7_gpu7_activation [label="" style=solid]
	layer0_expert7_gpu7_up_proj -> layer0_expert7_gpu7_down_proj [label="" style=solid]
	layer0_expert7_gpu7_activation -> layer0_expert7_gpu7_down_proj [label="" style=solid]
	layer0_routing_route_to_expert7 -> layer0_expert7_gpu7_gate_proj [label="" style=solid]
	layer0_routing_route_to_expert7 -> layer0_expert7_gpu7_up_proj [label="" style=solid]
	layer0_expert8_gpu8_gate_proj [label="layer0_expert8_gpu8_gate_proj\nGate Projection\nGPU: 8\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer0_expert8_gpu8_up_proj [label="layer0_expert8_gpu8_up_proj\nUp Projection\nGPU: 8\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer0_expert8_gpu8_activation [label="layer0_expert8_gpu8_activation\nGELU Activation\nGPU: 8\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer0_expert8_gpu8_down_proj [label="layer0_expert8_gpu8_down_proj\nDown Projection\nGPU: 8\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer0_expert8_gpu8_gate_proj -> layer0_expert8_gpu8_activation [label="" style=solid]
	layer0_expert8_gpu8_up_proj -> layer0_expert8_gpu8_down_proj [label="" style=solid]
	layer0_expert8_gpu8_activation -> layer0_expert8_gpu8_down_proj [label="" style=solid]
	layer0_routing_route_to_expert8 -> layer0_expert8_gpu8_gate_proj [label="" style=solid]
	layer0_routing_route_to_expert8 -> layer0_expert8_gpu8_up_proj [label="" style=solid]
	layer0_expert9_gpu9_gate_proj [label="layer0_expert9_gpu9_gate_proj\nGate Projection\nGPU: 9\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer0_expert9_gpu9_up_proj [label="layer0_expert9_gpu9_up_proj\nUp Projection\nGPU: 9\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer0_expert9_gpu9_activation [label="layer0_expert9_gpu9_activation\nGELU Activation\nGPU: 9\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer0_expert9_gpu9_down_proj [label="layer0_expert9_gpu9_down_proj\nDown Projection\nGPU: 9\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer0_expert9_gpu9_gate_proj -> layer0_expert9_gpu9_activation [label="" style=solid]
	layer0_expert9_gpu9_up_proj -> layer0_expert9_gpu9_down_proj [label="" style=solid]
	layer0_expert9_gpu9_activation -> layer0_expert9_gpu9_down_proj [label="" style=solid]
	layer0_routing_route_to_expert9 -> layer0_expert9_gpu9_gate_proj [label="" style=solid]
	layer0_routing_route_to_expert9 -> layer0_expert9_gpu9_up_proj [label="" style=solid]
	layer0_expert10_gpu10_gate_proj [label="layer0_expert10_gpu10_gate_proj\nGate Projection\nGPU: 10\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer0_expert10_gpu10_up_proj [label="layer0_expert10_gpu10_up_proj\nUp Projection\nGPU: 10\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer0_expert10_gpu10_activation [label="layer0_expert10_gpu10_activation\nGELU Activation\nGPU: 10\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer0_expert10_gpu10_down_proj [label="layer0_expert10_gpu10_down_proj\nDown Projection\nGPU: 10\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer0_expert10_gpu10_gate_proj -> layer0_expert10_gpu10_activation [label="" style=solid]
	layer0_expert10_gpu10_up_proj -> layer0_expert10_gpu10_down_proj [label="" style=solid]
	layer0_expert10_gpu10_activation -> layer0_expert10_gpu10_down_proj [label="" style=solid]
	layer0_routing_route_to_expert10 -> layer0_expert10_gpu10_gate_proj [label="" style=solid]
	layer0_routing_route_to_expert10 -> layer0_expert10_gpu10_up_proj [label="" style=solid]
	layer0_expert11_gpu11_gate_proj [label="layer0_expert11_gpu11_gate_proj\nGate Projection\nGPU: 11\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer0_expert11_gpu11_up_proj [label="layer0_expert11_gpu11_up_proj\nUp Projection\nGPU: 11\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer0_expert11_gpu11_activation [label="layer0_expert11_gpu11_activation\nGELU Activation\nGPU: 11\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer0_expert11_gpu11_down_proj [label="layer0_expert11_gpu11_down_proj\nDown Projection\nGPU: 11\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer0_expert11_gpu11_gate_proj -> layer0_expert11_gpu11_activation [label="" style=solid]
	layer0_expert11_gpu11_up_proj -> layer0_expert11_gpu11_down_proj [label="" style=solid]
	layer0_expert11_gpu11_activation -> layer0_expert11_gpu11_down_proj [label="" style=solid]
	layer0_routing_route_to_expert11 -> layer0_expert11_gpu11_gate_proj [label="" style=solid]
	layer0_routing_route_to_expert11 -> layer0_expert11_gpu11_up_proj [label="" style=solid]
	layer0_expert12_gpu12_gate_proj [label="layer0_expert12_gpu12_gate_proj\nGate Projection\nGPU: 12\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer0_expert12_gpu12_up_proj [label="layer0_expert12_gpu12_up_proj\nUp Projection\nGPU: 12\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer0_expert12_gpu12_activation [label="layer0_expert12_gpu12_activation\nGELU Activation\nGPU: 12\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer0_expert12_gpu12_down_proj [label="layer0_expert12_gpu12_down_proj\nDown Projection\nGPU: 12\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer0_expert12_gpu12_gate_proj -> layer0_expert12_gpu12_activation [label="" style=solid]
	layer0_expert12_gpu12_up_proj -> layer0_expert12_gpu12_down_proj [label="" style=solid]
	layer0_expert12_gpu12_activation -> layer0_expert12_gpu12_down_proj [label="" style=solid]
	layer0_routing_route_to_expert12 -> layer0_expert12_gpu12_gate_proj [label="" style=solid]
	layer0_routing_route_to_expert12 -> layer0_expert12_gpu12_up_proj [label="" style=solid]
	layer0_expert13_gpu13_gate_proj [label="layer0_expert13_gpu13_gate_proj\nGate Projection\nGPU: 13\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer0_expert13_gpu13_up_proj [label="layer0_expert13_gpu13_up_proj\nUp Projection\nGPU: 13\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer0_expert13_gpu13_activation [label="layer0_expert13_gpu13_activation\nGELU Activation\nGPU: 13\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer0_expert13_gpu13_down_proj [label="layer0_expert13_gpu13_down_proj\nDown Projection\nGPU: 13\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer0_expert13_gpu13_gate_proj -> layer0_expert13_gpu13_activation [label="" style=solid]
	layer0_expert13_gpu13_up_proj -> layer0_expert13_gpu13_down_proj [label="" style=solid]
	layer0_expert13_gpu13_activation -> layer0_expert13_gpu13_down_proj [label="" style=solid]
	layer0_routing_route_to_expert13 -> layer0_expert13_gpu13_gate_proj [label="" style=solid]
	layer0_routing_route_to_expert13 -> layer0_expert13_gpu13_up_proj [label="" style=solid]
	layer0_expert14_gpu14_gate_proj [label="layer0_expert14_gpu14_gate_proj\nGate Projection\nGPU: 14\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer0_expert14_gpu14_up_proj [label="layer0_expert14_gpu14_up_proj\nUp Projection\nGPU: 14\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer0_expert14_gpu14_activation [label="layer0_expert14_gpu14_activation\nGELU Activation\nGPU: 14\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer0_expert14_gpu14_down_proj [label="layer0_expert14_gpu14_down_proj\nDown Projection\nGPU: 14\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer0_expert14_gpu14_gate_proj -> layer0_expert14_gpu14_activation [label="" style=solid]
	layer0_expert14_gpu14_up_proj -> layer0_expert14_gpu14_down_proj [label="" style=solid]
	layer0_expert14_gpu14_activation -> layer0_expert14_gpu14_down_proj [label="" style=solid]
	layer0_routing_route_to_expert14 -> layer0_expert14_gpu14_gate_proj [label="" style=solid]
	layer0_routing_route_to_expert14 -> layer0_expert14_gpu14_up_proj [label="" style=solid]
	layer0_expert15_gpu15_gate_proj [label="layer0_expert15_gpu15_gate_proj\nGate Projection\nGPU: 15\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer0_expert15_gpu15_up_proj [label="layer0_expert15_gpu15_up_proj\nUp Projection\nGPU: 15\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer0_expert15_gpu15_activation [label="layer0_expert15_gpu15_activation\nGELU Activation\nGPU: 15\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer0_expert15_gpu15_down_proj [label="layer0_expert15_gpu15_down_proj\nDown Projection\nGPU: 15\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer0_expert15_gpu15_gate_proj -> layer0_expert15_gpu15_activation [label="" style=solid]
	layer0_expert15_gpu15_up_proj -> layer0_expert15_gpu15_down_proj [label="" style=solid]
	layer0_expert15_gpu15_activation -> layer0_expert15_gpu15_down_proj [label="" style=solid]
	layer0_routing_route_to_expert15 -> layer0_expert15_gpu15_gate_proj [label="" style=solid]
	layer0_routing_route_to_expert15 -> layer0_expert15_gpu15_up_proj [label="" style=solid]
	layer0_routing_aggregate [label="layer0_routing_aggregate\nAggregate Expert Outputs\nGPU: 0-15\nIn: batch_size=640000, hidden_dim=8192 (x16)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=parallelogram]
	layer0_expert0_gpu0_down_proj -> layer0_routing_aggregate [label="" style=solid]
	layer0_expert1_gpu1_down_proj -> layer0_routing_aggregate [label="" style=solid]
	layer0_expert2_gpu2_down_proj -> layer0_routing_aggregate [label="" style=solid]
	layer0_expert3_gpu3_down_proj -> layer0_routing_aggregate [label="" style=solid]
	layer0_expert4_gpu4_down_proj -> layer0_routing_aggregate [label="" style=solid]
	layer0_expert5_gpu5_down_proj -> layer0_routing_aggregate [label="" style=solid]
	layer0_expert6_gpu6_down_proj -> layer0_routing_aggregate [label="" style=solid]
	layer0_expert7_gpu7_down_proj -> layer0_routing_aggregate [label="" style=solid]
	layer0_expert8_gpu8_down_proj -> layer0_routing_aggregate [label="" style=solid]
	layer0_expert9_gpu9_down_proj -> layer0_routing_aggregate [label="" style=solid]
	layer0_expert10_gpu10_down_proj -> layer0_routing_aggregate [label="" style=solid]
	layer0_expert11_gpu11_down_proj -> layer0_routing_aggregate [label="" style=solid]
	layer0_expert12_gpu12_down_proj -> layer0_routing_aggregate [label="" style=solid]
	layer0_expert13_gpu13_down_proj -> layer0_routing_aggregate [label="" style=solid]
	layer0_expert14_gpu14_down_proj -> layer0_routing_aggregate [label="" style=solid]
	layer0_expert15_gpu15_down_proj -> layer0_routing_aggregate [label="" style=solid]
	layer0_routing_weighted_sum [label="layer0_routing_weighted_sum\nWeighted Sum\nGPU: 0-15\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_routing_aggregate -> layer0_routing_weighted_sum [label="" style=solid]
	layer0_gating_selection -> layer0_routing_weighted_sum [label="" style=dashed]
	layer0_attn_output_broadcast_gpu0 -> layer0_gating_network [label="" style=solid]
	layer0_attn_output_broadcast_gpu1 -> layer0_gating_network [label="" style=solid]
	layer0_attn_output_broadcast_gpu2 -> layer0_gating_network [label="" style=solid]
	layer0_attn_output_broadcast_gpu3 -> layer0_gating_network [label="" style=solid]
	layer0_attn_output_broadcast_gpu4 -> layer0_gating_network [label="" style=solid]
	layer0_attn_output_broadcast_gpu5 -> layer0_gating_network [label="" style=solid]
	layer0_attn_output_broadcast_gpu6 -> layer0_gating_network [label="" style=solid]
	layer0_attn_output_broadcast_gpu7 -> layer0_gating_network [label="" style=solid]
	layer0_attn_output_broadcast_gpu8 -> layer0_gating_network [label="" style=solid]
	layer0_attn_output_broadcast_gpu9 -> layer0_gating_network [label="" style=solid]
	layer0_attn_output_broadcast_gpu10 -> layer0_gating_network [label="" style=solid]
	layer0_attn_output_broadcast_gpu11 -> layer0_gating_network [label="" style=solid]
	layer0_attn_output_broadcast_gpu12 -> layer0_gating_network [label="" style=solid]
	layer0_attn_output_broadcast_gpu13 -> layer0_gating_network [label="" style=solid]
	layer0_attn_output_broadcast_gpu14 -> layer0_gating_network [label="" style=solid]
	layer0_attn_output_broadcast_gpu15 -> layer0_gating_network [label="" style=solid]
	layer0_output [label="layer0_output\nLayer Output\nGPU: 0-15\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer0_attn_output_broadcast_gpu0 -> layer0_output [label="" style=dashed]
	layer0_attn_output_broadcast_gpu1 -> layer0_output [label="" style=dashed]
	layer0_attn_output_broadcast_gpu2 -> layer0_output [label="" style=dashed]
	layer0_attn_output_broadcast_gpu3 -> layer0_output [label="" style=dashed]
	layer0_attn_output_broadcast_gpu4 -> layer0_output [label="" style=dashed]
	layer0_attn_output_broadcast_gpu5 -> layer0_output [label="" style=dashed]
	layer0_attn_output_broadcast_gpu6 -> layer0_output [label="" style=dashed]
	layer0_attn_output_broadcast_gpu7 -> layer0_output [label="" style=dashed]
	layer0_attn_output_broadcast_gpu8 -> layer0_output [label="" style=dashed]
	layer0_attn_output_broadcast_gpu9 -> layer0_output [label="" style=dashed]
	layer0_attn_output_broadcast_gpu10 -> layer0_output [label="" style=dashed]
	layer0_attn_output_broadcast_gpu11 -> layer0_output [label="" style=dashed]
	layer0_attn_output_broadcast_gpu12 -> layer0_output [label="" style=dashed]
	layer0_attn_output_broadcast_gpu13 -> layer0_output [label="" style=dashed]
	layer0_attn_output_broadcast_gpu14 -> layer0_output [label="" style=dashed]
	layer0_attn_output_broadcast_gpu15 -> layer0_output [label="" style=dashed]
	layer0_routing_weighted_sum -> layer0_output [label="" style=solid]
	model_input -> layer0_input_broadcast [label="" style=solid]
	layer1_input_broadcast [label="layer1_input_broadcast\nLayer Input Broadcast\nGPU: 0-15\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=1024, seq_len=10000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu0_attn_input_reshape [label="layer1_gpu0_attn_input_reshape\nInput Reshape\nGPU: 0\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu0_q_proj [label="layer1_gpu0_q_proj\nQ Projection\nGPU: 0\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu0_k_proj [label="layer1_gpu0_k_proj\nK Projection\nGPU: 0\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu0_v_proj [label="layer1_gpu0_v_proj\nV Projection\nGPU: 0\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu0_mha [label="layer1_gpu0_mha\nMulti-Head Attention\nGPU: 0\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu0_o_proj [label="layer1_gpu0_o_proj\nOutput Projection\nGPU: 0\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer1_gpu0_attn_residual [label="layer1_gpu0_attn_residual\nResidual Add\nGPU: 0\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu0_attn_input_reshape -> layer1_gpu0_q_proj [label="" style=solid]
	layer1_gpu0_attn_input_reshape -> layer1_gpu0_k_proj [label="" style=solid]
	layer1_gpu0_attn_input_reshape -> layer1_gpu0_v_proj [label="" style=solid]
	layer1_gpu0_q_proj -> layer1_gpu0_mha [label="" style=solid]
	layer1_gpu0_k_proj -> layer1_gpu0_mha [label="" style=solid]
	layer1_gpu0_v_proj -> layer1_gpu0_mha [label="" style=solid]
	layer1_gpu0_mha -> layer1_gpu0_o_proj [label="" style=solid]
	layer1_gpu0_o_proj -> layer1_gpu0_attn_residual [label="" style=solid]
	layer1_gpu0_attn_input_reshape -> layer1_gpu0_attn_residual [label="" style=dashed]
	layer1_input_broadcast -> layer1_gpu0_attn_input_reshape [label="" style=solid]
	layer1_gpu1_attn_input_reshape [label="layer1_gpu1_attn_input_reshape\nInput Reshape\nGPU: 1\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu1_q_proj [label="layer1_gpu1_q_proj\nQ Projection\nGPU: 1\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu1_k_proj [label="layer1_gpu1_k_proj\nK Projection\nGPU: 1\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu1_v_proj [label="layer1_gpu1_v_proj\nV Projection\nGPU: 1\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu1_mha [label="layer1_gpu1_mha\nMulti-Head Attention\nGPU: 1\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu1_o_proj [label="layer1_gpu1_o_proj\nOutput Projection\nGPU: 1\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer1_gpu1_attn_residual [label="layer1_gpu1_attn_residual\nResidual Add\nGPU: 1\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu1_attn_input_reshape -> layer1_gpu1_q_proj [label="" style=solid]
	layer1_gpu1_attn_input_reshape -> layer1_gpu1_k_proj [label="" style=solid]
	layer1_gpu1_attn_input_reshape -> layer1_gpu1_v_proj [label="" style=solid]
	layer1_gpu1_q_proj -> layer1_gpu1_mha [label="" style=solid]
	layer1_gpu1_k_proj -> layer1_gpu1_mha [label="" style=solid]
	layer1_gpu1_v_proj -> layer1_gpu1_mha [label="" style=solid]
	layer1_gpu1_mha -> layer1_gpu1_o_proj [label="" style=solid]
	layer1_gpu1_o_proj -> layer1_gpu1_attn_residual [label="" style=solid]
	layer1_gpu1_attn_input_reshape -> layer1_gpu1_attn_residual [label="" style=dashed]
	layer1_input_broadcast -> layer1_gpu1_attn_input_reshape [label="" style=solid]
	layer1_gpu2_attn_input_reshape [label="layer1_gpu2_attn_input_reshape\nInput Reshape\nGPU: 2\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu2_q_proj [label="layer1_gpu2_q_proj\nQ Projection\nGPU: 2\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu2_k_proj [label="layer1_gpu2_k_proj\nK Projection\nGPU: 2\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu2_v_proj [label="layer1_gpu2_v_proj\nV Projection\nGPU: 2\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu2_mha [label="layer1_gpu2_mha\nMulti-Head Attention\nGPU: 2\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu2_o_proj [label="layer1_gpu2_o_proj\nOutput Projection\nGPU: 2\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer1_gpu2_attn_residual [label="layer1_gpu2_attn_residual\nResidual Add\nGPU: 2\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu2_attn_input_reshape -> layer1_gpu2_q_proj [label="" style=solid]
	layer1_gpu2_attn_input_reshape -> layer1_gpu2_k_proj [label="" style=solid]
	layer1_gpu2_attn_input_reshape -> layer1_gpu2_v_proj [label="" style=solid]
	layer1_gpu2_q_proj -> layer1_gpu2_mha [label="" style=solid]
	layer1_gpu2_k_proj -> layer1_gpu2_mha [label="" style=solid]
	layer1_gpu2_v_proj -> layer1_gpu2_mha [label="" style=solid]
	layer1_gpu2_mha -> layer1_gpu2_o_proj [label="" style=solid]
	layer1_gpu2_o_proj -> layer1_gpu2_attn_residual [label="" style=solid]
	layer1_gpu2_attn_input_reshape -> layer1_gpu2_attn_residual [label="" style=dashed]
	layer1_input_broadcast -> layer1_gpu2_attn_input_reshape [label="" style=solid]
	layer1_gpu3_attn_input_reshape [label="layer1_gpu3_attn_input_reshape\nInput Reshape\nGPU: 3\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu3_q_proj [label="layer1_gpu3_q_proj\nQ Projection\nGPU: 3\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu3_k_proj [label="layer1_gpu3_k_proj\nK Projection\nGPU: 3\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu3_v_proj [label="layer1_gpu3_v_proj\nV Projection\nGPU: 3\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu3_mha [label="layer1_gpu3_mha\nMulti-Head Attention\nGPU: 3\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu3_o_proj [label="layer1_gpu3_o_proj\nOutput Projection\nGPU: 3\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer1_gpu3_attn_residual [label="layer1_gpu3_attn_residual\nResidual Add\nGPU: 3\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu3_attn_input_reshape -> layer1_gpu3_q_proj [label="" style=solid]
	layer1_gpu3_attn_input_reshape -> layer1_gpu3_k_proj [label="" style=solid]
	layer1_gpu3_attn_input_reshape -> layer1_gpu3_v_proj [label="" style=solid]
	layer1_gpu3_q_proj -> layer1_gpu3_mha [label="" style=solid]
	layer1_gpu3_k_proj -> layer1_gpu3_mha [label="" style=solid]
	layer1_gpu3_v_proj -> layer1_gpu3_mha [label="" style=solid]
	layer1_gpu3_mha -> layer1_gpu3_o_proj [label="" style=solid]
	layer1_gpu3_o_proj -> layer1_gpu3_attn_residual [label="" style=solid]
	layer1_gpu3_attn_input_reshape -> layer1_gpu3_attn_residual [label="" style=dashed]
	layer1_input_broadcast -> layer1_gpu3_attn_input_reshape [label="" style=solid]
	layer1_gpu4_attn_input_reshape [label="layer1_gpu4_attn_input_reshape\nInput Reshape\nGPU: 4\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu4_q_proj [label="layer1_gpu4_q_proj\nQ Projection\nGPU: 4\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu4_k_proj [label="layer1_gpu4_k_proj\nK Projection\nGPU: 4\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu4_v_proj [label="layer1_gpu4_v_proj\nV Projection\nGPU: 4\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu4_mha [label="layer1_gpu4_mha\nMulti-Head Attention\nGPU: 4\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu4_o_proj [label="layer1_gpu4_o_proj\nOutput Projection\nGPU: 4\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer1_gpu4_attn_residual [label="layer1_gpu4_attn_residual\nResidual Add\nGPU: 4\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu4_attn_input_reshape -> layer1_gpu4_q_proj [label="" style=solid]
	layer1_gpu4_attn_input_reshape -> layer1_gpu4_k_proj [label="" style=solid]
	layer1_gpu4_attn_input_reshape -> layer1_gpu4_v_proj [label="" style=solid]
	layer1_gpu4_q_proj -> layer1_gpu4_mha [label="" style=solid]
	layer1_gpu4_k_proj -> layer1_gpu4_mha [label="" style=solid]
	layer1_gpu4_v_proj -> layer1_gpu4_mha [label="" style=solid]
	layer1_gpu4_mha -> layer1_gpu4_o_proj [label="" style=solid]
	layer1_gpu4_o_proj -> layer1_gpu4_attn_residual [label="" style=solid]
	layer1_gpu4_attn_input_reshape -> layer1_gpu4_attn_residual [label="" style=dashed]
	layer1_input_broadcast -> layer1_gpu4_attn_input_reshape [label="" style=solid]
	layer1_gpu5_attn_input_reshape [label="layer1_gpu5_attn_input_reshape\nInput Reshape\nGPU: 5\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu5_q_proj [label="layer1_gpu5_q_proj\nQ Projection\nGPU: 5\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu5_k_proj [label="layer1_gpu5_k_proj\nK Projection\nGPU: 5\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu5_v_proj [label="layer1_gpu5_v_proj\nV Projection\nGPU: 5\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu5_mha [label="layer1_gpu5_mha\nMulti-Head Attention\nGPU: 5\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu5_o_proj [label="layer1_gpu5_o_proj\nOutput Projection\nGPU: 5\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer1_gpu5_attn_residual [label="layer1_gpu5_attn_residual\nResidual Add\nGPU: 5\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu5_attn_input_reshape -> layer1_gpu5_q_proj [label="" style=solid]
	layer1_gpu5_attn_input_reshape -> layer1_gpu5_k_proj [label="" style=solid]
	layer1_gpu5_attn_input_reshape -> layer1_gpu5_v_proj [label="" style=solid]
	layer1_gpu5_q_proj -> layer1_gpu5_mha [label="" style=solid]
	layer1_gpu5_k_proj -> layer1_gpu5_mha [label="" style=solid]
	layer1_gpu5_v_proj -> layer1_gpu5_mha [label="" style=solid]
	layer1_gpu5_mha -> layer1_gpu5_o_proj [label="" style=solid]
	layer1_gpu5_o_proj -> layer1_gpu5_attn_residual [label="" style=solid]
	layer1_gpu5_attn_input_reshape -> layer1_gpu5_attn_residual [label="" style=dashed]
	layer1_input_broadcast -> layer1_gpu5_attn_input_reshape [label="" style=solid]
	layer1_gpu6_attn_input_reshape [label="layer1_gpu6_attn_input_reshape\nInput Reshape\nGPU: 6\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu6_q_proj [label="layer1_gpu6_q_proj\nQ Projection\nGPU: 6\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu6_k_proj [label="layer1_gpu6_k_proj\nK Projection\nGPU: 6\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu6_v_proj [label="layer1_gpu6_v_proj\nV Projection\nGPU: 6\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu6_mha [label="layer1_gpu6_mha\nMulti-Head Attention\nGPU: 6\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu6_o_proj [label="layer1_gpu6_o_proj\nOutput Projection\nGPU: 6\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer1_gpu6_attn_residual [label="layer1_gpu6_attn_residual\nResidual Add\nGPU: 6\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu6_attn_input_reshape -> layer1_gpu6_q_proj [label="" style=solid]
	layer1_gpu6_attn_input_reshape -> layer1_gpu6_k_proj [label="" style=solid]
	layer1_gpu6_attn_input_reshape -> layer1_gpu6_v_proj [label="" style=solid]
	layer1_gpu6_q_proj -> layer1_gpu6_mha [label="" style=solid]
	layer1_gpu6_k_proj -> layer1_gpu6_mha [label="" style=solid]
	layer1_gpu6_v_proj -> layer1_gpu6_mha [label="" style=solid]
	layer1_gpu6_mha -> layer1_gpu6_o_proj [label="" style=solid]
	layer1_gpu6_o_proj -> layer1_gpu6_attn_residual [label="" style=solid]
	layer1_gpu6_attn_input_reshape -> layer1_gpu6_attn_residual [label="" style=dashed]
	layer1_input_broadcast -> layer1_gpu6_attn_input_reshape [label="" style=solid]
	layer1_gpu7_attn_input_reshape [label="layer1_gpu7_attn_input_reshape\nInput Reshape\nGPU: 7\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu7_q_proj [label="layer1_gpu7_q_proj\nQ Projection\nGPU: 7\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu7_k_proj [label="layer1_gpu7_k_proj\nK Projection\nGPU: 7\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu7_v_proj [label="layer1_gpu7_v_proj\nV Projection\nGPU: 7\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu7_mha [label="layer1_gpu7_mha\nMulti-Head Attention\nGPU: 7\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu7_o_proj [label="layer1_gpu7_o_proj\nOutput Projection\nGPU: 7\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer1_gpu7_attn_residual [label="layer1_gpu7_attn_residual\nResidual Add\nGPU: 7\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu7_attn_input_reshape -> layer1_gpu7_q_proj [label="" style=solid]
	layer1_gpu7_attn_input_reshape -> layer1_gpu7_k_proj [label="" style=solid]
	layer1_gpu7_attn_input_reshape -> layer1_gpu7_v_proj [label="" style=solid]
	layer1_gpu7_q_proj -> layer1_gpu7_mha [label="" style=solid]
	layer1_gpu7_k_proj -> layer1_gpu7_mha [label="" style=solid]
	layer1_gpu7_v_proj -> layer1_gpu7_mha [label="" style=solid]
	layer1_gpu7_mha -> layer1_gpu7_o_proj [label="" style=solid]
	layer1_gpu7_o_proj -> layer1_gpu7_attn_residual [label="" style=solid]
	layer1_gpu7_attn_input_reshape -> layer1_gpu7_attn_residual [label="" style=dashed]
	layer1_input_broadcast -> layer1_gpu7_attn_input_reshape [label="" style=solid]
	layer1_gpu8_attn_input_reshape [label="layer1_gpu8_attn_input_reshape\nInput Reshape\nGPU: 8\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu8_q_proj [label="layer1_gpu8_q_proj\nQ Projection\nGPU: 8\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu8_k_proj [label="layer1_gpu8_k_proj\nK Projection\nGPU: 8\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu8_v_proj [label="layer1_gpu8_v_proj\nV Projection\nGPU: 8\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu8_mha [label="layer1_gpu8_mha\nMulti-Head Attention\nGPU: 8\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu8_o_proj [label="layer1_gpu8_o_proj\nOutput Projection\nGPU: 8\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer1_gpu8_attn_residual [label="layer1_gpu8_attn_residual\nResidual Add\nGPU: 8\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu8_attn_input_reshape -> layer1_gpu8_q_proj [label="" style=solid]
	layer1_gpu8_attn_input_reshape -> layer1_gpu8_k_proj [label="" style=solid]
	layer1_gpu8_attn_input_reshape -> layer1_gpu8_v_proj [label="" style=solid]
	layer1_gpu8_q_proj -> layer1_gpu8_mha [label="" style=solid]
	layer1_gpu8_k_proj -> layer1_gpu8_mha [label="" style=solid]
	layer1_gpu8_v_proj -> layer1_gpu8_mha [label="" style=solid]
	layer1_gpu8_mha -> layer1_gpu8_o_proj [label="" style=solid]
	layer1_gpu8_o_proj -> layer1_gpu8_attn_residual [label="" style=solid]
	layer1_gpu8_attn_input_reshape -> layer1_gpu8_attn_residual [label="" style=dashed]
	layer1_input_broadcast -> layer1_gpu8_attn_input_reshape [label="" style=solid]
	layer1_gpu9_attn_input_reshape [label="layer1_gpu9_attn_input_reshape\nInput Reshape\nGPU: 9\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu9_q_proj [label="layer1_gpu9_q_proj\nQ Projection\nGPU: 9\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu9_k_proj [label="layer1_gpu9_k_proj\nK Projection\nGPU: 9\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu9_v_proj [label="layer1_gpu9_v_proj\nV Projection\nGPU: 9\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu9_mha [label="layer1_gpu9_mha\nMulti-Head Attention\nGPU: 9\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu9_o_proj [label="layer1_gpu9_o_proj\nOutput Projection\nGPU: 9\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer1_gpu9_attn_residual [label="layer1_gpu9_attn_residual\nResidual Add\nGPU: 9\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu9_attn_input_reshape -> layer1_gpu9_q_proj [label="" style=solid]
	layer1_gpu9_attn_input_reshape -> layer1_gpu9_k_proj [label="" style=solid]
	layer1_gpu9_attn_input_reshape -> layer1_gpu9_v_proj [label="" style=solid]
	layer1_gpu9_q_proj -> layer1_gpu9_mha [label="" style=solid]
	layer1_gpu9_k_proj -> layer1_gpu9_mha [label="" style=solid]
	layer1_gpu9_v_proj -> layer1_gpu9_mha [label="" style=solid]
	layer1_gpu9_mha -> layer1_gpu9_o_proj [label="" style=solid]
	layer1_gpu9_o_proj -> layer1_gpu9_attn_residual [label="" style=solid]
	layer1_gpu9_attn_input_reshape -> layer1_gpu9_attn_residual [label="" style=dashed]
	layer1_input_broadcast -> layer1_gpu9_attn_input_reshape [label="" style=solid]
	layer1_gpu10_attn_input_reshape [label="layer1_gpu10_attn_input_reshape\nInput Reshape\nGPU: 10\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu10_q_proj [label="layer1_gpu10_q_proj\nQ Projection\nGPU: 10\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu10_k_proj [label="layer1_gpu10_k_proj\nK Projection\nGPU: 10\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu10_v_proj [label="layer1_gpu10_v_proj\nV Projection\nGPU: 10\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu10_mha [label="layer1_gpu10_mha\nMulti-Head Attention\nGPU: 10\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu10_o_proj [label="layer1_gpu10_o_proj\nOutput Projection\nGPU: 10\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer1_gpu10_attn_residual [label="layer1_gpu10_attn_residual\nResidual Add\nGPU: 10\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu10_attn_input_reshape -> layer1_gpu10_q_proj [label="" style=solid]
	layer1_gpu10_attn_input_reshape -> layer1_gpu10_k_proj [label="" style=solid]
	layer1_gpu10_attn_input_reshape -> layer1_gpu10_v_proj [label="" style=solid]
	layer1_gpu10_q_proj -> layer1_gpu10_mha [label="" style=solid]
	layer1_gpu10_k_proj -> layer1_gpu10_mha [label="" style=solid]
	layer1_gpu10_v_proj -> layer1_gpu10_mha [label="" style=solid]
	layer1_gpu10_mha -> layer1_gpu10_o_proj [label="" style=solid]
	layer1_gpu10_o_proj -> layer1_gpu10_attn_residual [label="" style=solid]
	layer1_gpu10_attn_input_reshape -> layer1_gpu10_attn_residual [label="" style=dashed]
	layer1_input_broadcast -> layer1_gpu10_attn_input_reshape [label="" style=solid]
	layer1_gpu11_attn_input_reshape [label="layer1_gpu11_attn_input_reshape\nInput Reshape\nGPU: 11\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu11_q_proj [label="layer1_gpu11_q_proj\nQ Projection\nGPU: 11\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu11_k_proj [label="layer1_gpu11_k_proj\nK Projection\nGPU: 11\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu11_v_proj [label="layer1_gpu11_v_proj\nV Projection\nGPU: 11\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu11_mha [label="layer1_gpu11_mha\nMulti-Head Attention\nGPU: 11\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu11_o_proj [label="layer1_gpu11_o_proj\nOutput Projection\nGPU: 11\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer1_gpu11_attn_residual [label="layer1_gpu11_attn_residual\nResidual Add\nGPU: 11\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu11_attn_input_reshape -> layer1_gpu11_q_proj [label="" style=solid]
	layer1_gpu11_attn_input_reshape -> layer1_gpu11_k_proj [label="" style=solid]
	layer1_gpu11_attn_input_reshape -> layer1_gpu11_v_proj [label="" style=solid]
	layer1_gpu11_q_proj -> layer1_gpu11_mha [label="" style=solid]
	layer1_gpu11_k_proj -> layer1_gpu11_mha [label="" style=solid]
	layer1_gpu11_v_proj -> layer1_gpu11_mha [label="" style=solid]
	layer1_gpu11_mha -> layer1_gpu11_o_proj [label="" style=solid]
	layer1_gpu11_o_proj -> layer1_gpu11_attn_residual [label="" style=solid]
	layer1_gpu11_attn_input_reshape -> layer1_gpu11_attn_residual [label="" style=dashed]
	layer1_input_broadcast -> layer1_gpu11_attn_input_reshape [label="" style=solid]
	layer1_gpu12_attn_input_reshape [label="layer1_gpu12_attn_input_reshape\nInput Reshape\nGPU: 12\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu12_q_proj [label="layer1_gpu12_q_proj\nQ Projection\nGPU: 12\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu12_k_proj [label="layer1_gpu12_k_proj\nK Projection\nGPU: 12\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu12_v_proj [label="layer1_gpu12_v_proj\nV Projection\nGPU: 12\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu12_mha [label="layer1_gpu12_mha\nMulti-Head Attention\nGPU: 12\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu12_o_proj [label="layer1_gpu12_o_proj\nOutput Projection\nGPU: 12\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer1_gpu12_attn_residual [label="layer1_gpu12_attn_residual\nResidual Add\nGPU: 12\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu12_attn_input_reshape -> layer1_gpu12_q_proj [label="" style=solid]
	layer1_gpu12_attn_input_reshape -> layer1_gpu12_k_proj [label="" style=solid]
	layer1_gpu12_attn_input_reshape -> layer1_gpu12_v_proj [label="" style=solid]
	layer1_gpu12_q_proj -> layer1_gpu12_mha [label="" style=solid]
	layer1_gpu12_k_proj -> layer1_gpu12_mha [label="" style=solid]
	layer1_gpu12_v_proj -> layer1_gpu12_mha [label="" style=solid]
	layer1_gpu12_mha -> layer1_gpu12_o_proj [label="" style=solid]
	layer1_gpu12_o_proj -> layer1_gpu12_attn_residual [label="" style=solid]
	layer1_gpu12_attn_input_reshape -> layer1_gpu12_attn_residual [label="" style=dashed]
	layer1_input_broadcast -> layer1_gpu12_attn_input_reshape [label="" style=solid]
	layer1_gpu13_attn_input_reshape [label="layer1_gpu13_attn_input_reshape\nInput Reshape\nGPU: 13\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu13_q_proj [label="layer1_gpu13_q_proj\nQ Projection\nGPU: 13\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu13_k_proj [label="layer1_gpu13_k_proj\nK Projection\nGPU: 13\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu13_v_proj [label="layer1_gpu13_v_proj\nV Projection\nGPU: 13\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu13_mha [label="layer1_gpu13_mha\nMulti-Head Attention\nGPU: 13\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu13_o_proj [label="layer1_gpu13_o_proj\nOutput Projection\nGPU: 13\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer1_gpu13_attn_residual [label="layer1_gpu13_attn_residual\nResidual Add\nGPU: 13\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu13_attn_input_reshape -> layer1_gpu13_q_proj [label="" style=solid]
	layer1_gpu13_attn_input_reshape -> layer1_gpu13_k_proj [label="" style=solid]
	layer1_gpu13_attn_input_reshape -> layer1_gpu13_v_proj [label="" style=solid]
	layer1_gpu13_q_proj -> layer1_gpu13_mha [label="" style=solid]
	layer1_gpu13_k_proj -> layer1_gpu13_mha [label="" style=solid]
	layer1_gpu13_v_proj -> layer1_gpu13_mha [label="" style=solid]
	layer1_gpu13_mha -> layer1_gpu13_o_proj [label="" style=solid]
	layer1_gpu13_o_proj -> layer1_gpu13_attn_residual [label="" style=solid]
	layer1_gpu13_attn_input_reshape -> layer1_gpu13_attn_residual [label="" style=dashed]
	layer1_input_broadcast -> layer1_gpu13_attn_input_reshape [label="" style=solid]
	layer1_gpu14_attn_input_reshape [label="layer1_gpu14_attn_input_reshape\nInput Reshape\nGPU: 14\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu14_q_proj [label="layer1_gpu14_q_proj\nQ Projection\nGPU: 14\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu14_k_proj [label="layer1_gpu14_k_proj\nK Projection\nGPU: 14\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu14_v_proj [label="layer1_gpu14_v_proj\nV Projection\nGPU: 14\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu14_mha [label="layer1_gpu14_mha\nMulti-Head Attention\nGPU: 14\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu14_o_proj [label="layer1_gpu14_o_proj\nOutput Projection\nGPU: 14\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer1_gpu14_attn_residual [label="layer1_gpu14_attn_residual\nResidual Add\nGPU: 14\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu14_attn_input_reshape -> layer1_gpu14_q_proj [label="" style=solid]
	layer1_gpu14_attn_input_reshape -> layer1_gpu14_k_proj [label="" style=solid]
	layer1_gpu14_attn_input_reshape -> layer1_gpu14_v_proj [label="" style=solid]
	layer1_gpu14_q_proj -> layer1_gpu14_mha [label="" style=solid]
	layer1_gpu14_k_proj -> layer1_gpu14_mha [label="" style=solid]
	layer1_gpu14_v_proj -> layer1_gpu14_mha [label="" style=solid]
	layer1_gpu14_mha -> layer1_gpu14_o_proj [label="" style=solid]
	layer1_gpu14_o_proj -> layer1_gpu14_attn_residual [label="" style=solid]
	layer1_gpu14_attn_input_reshape -> layer1_gpu14_attn_residual [label="" style=dashed]
	layer1_input_broadcast -> layer1_gpu14_attn_input_reshape [label="" style=solid]
	layer1_gpu15_attn_input_reshape [label="layer1_gpu15_attn_input_reshape\nInput Reshape\nGPU: 15\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu15_q_proj [label="layer1_gpu15_q_proj\nQ Projection\nGPU: 15\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu15_k_proj [label="layer1_gpu15_k_proj\nK Projection\nGPU: 15\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu15_v_proj [label="layer1_gpu15_v_proj\nV Projection\nGPU: 15\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu15_mha [label="layer1_gpu15_mha\nMulti-Head Attention\nGPU: 15\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer1_gpu15_o_proj [label="layer1_gpu15_o_proj\nOutput Projection\nGPU: 15\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer1_gpu15_attn_residual [label="layer1_gpu15_attn_residual\nResidual Add\nGPU: 15\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu15_attn_input_reshape -> layer1_gpu15_q_proj [label="" style=solid]
	layer1_gpu15_attn_input_reshape -> layer1_gpu15_k_proj [label="" style=solid]
	layer1_gpu15_attn_input_reshape -> layer1_gpu15_v_proj [label="" style=solid]
	layer1_gpu15_q_proj -> layer1_gpu15_mha [label="" style=solid]
	layer1_gpu15_k_proj -> layer1_gpu15_mha [label="" style=solid]
	layer1_gpu15_v_proj -> layer1_gpu15_mha [label="" style=solid]
	layer1_gpu15_mha -> layer1_gpu15_o_proj [label="" style=solid]
	layer1_gpu15_o_proj -> layer1_gpu15_attn_residual [label="" style=solid]
	layer1_gpu15_attn_input_reshape -> layer1_gpu15_attn_residual [label="" style=dashed]
	layer1_input_broadcast -> layer1_gpu15_attn_input_reshape [label="" style=solid]
	layer1_attn_output_broadcast_gpu0 [label="layer1_attn_output_broadcast_gpu0\nAttention Output Broadcast\nGPU: 0\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu0_attn_residual -> layer1_attn_output_broadcast_gpu0 [label="" style=solid]
	layer1_attn_output_broadcast_gpu1 [label="layer1_attn_output_broadcast_gpu1\nAttention Output Broadcast\nGPU: 1\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu1_attn_residual -> layer1_attn_output_broadcast_gpu1 [label="" style=solid]
	layer1_attn_output_broadcast_gpu2 [label="layer1_attn_output_broadcast_gpu2\nAttention Output Broadcast\nGPU: 2\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu2_attn_residual -> layer1_attn_output_broadcast_gpu2 [label="" style=solid]
	layer1_attn_output_broadcast_gpu3 [label="layer1_attn_output_broadcast_gpu3\nAttention Output Broadcast\nGPU: 3\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu3_attn_residual -> layer1_attn_output_broadcast_gpu3 [label="" style=solid]
	layer1_attn_output_broadcast_gpu4 [label="layer1_attn_output_broadcast_gpu4\nAttention Output Broadcast\nGPU: 4\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu4_attn_residual -> layer1_attn_output_broadcast_gpu4 [label="" style=solid]
	layer1_attn_output_broadcast_gpu5 [label="layer1_attn_output_broadcast_gpu5\nAttention Output Broadcast\nGPU: 5\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu5_attn_residual -> layer1_attn_output_broadcast_gpu5 [label="" style=solid]
	layer1_attn_output_broadcast_gpu6 [label="layer1_attn_output_broadcast_gpu6\nAttention Output Broadcast\nGPU: 6\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu6_attn_residual -> layer1_attn_output_broadcast_gpu6 [label="" style=solid]
	layer1_attn_output_broadcast_gpu7 [label="layer1_attn_output_broadcast_gpu7\nAttention Output Broadcast\nGPU: 7\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu7_attn_residual -> layer1_attn_output_broadcast_gpu7 [label="" style=solid]
	layer1_attn_output_broadcast_gpu8 [label="layer1_attn_output_broadcast_gpu8\nAttention Output Broadcast\nGPU: 8\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu8_attn_residual -> layer1_attn_output_broadcast_gpu8 [label="" style=solid]
	layer1_attn_output_broadcast_gpu9 [label="layer1_attn_output_broadcast_gpu9\nAttention Output Broadcast\nGPU: 9\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu9_attn_residual -> layer1_attn_output_broadcast_gpu9 [label="" style=solid]
	layer1_attn_output_broadcast_gpu10 [label="layer1_attn_output_broadcast_gpu10\nAttention Output Broadcast\nGPU: 10\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu10_attn_residual -> layer1_attn_output_broadcast_gpu10 [label="" style=solid]
	layer1_attn_output_broadcast_gpu11 [label="layer1_attn_output_broadcast_gpu11\nAttention Output Broadcast\nGPU: 11\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu11_attn_residual -> layer1_attn_output_broadcast_gpu11 [label="" style=solid]
	layer1_attn_output_broadcast_gpu12 [label="layer1_attn_output_broadcast_gpu12\nAttention Output Broadcast\nGPU: 12\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu12_attn_residual -> layer1_attn_output_broadcast_gpu12 [label="" style=solid]
	layer1_attn_output_broadcast_gpu13 [label="layer1_attn_output_broadcast_gpu13\nAttention Output Broadcast\nGPU: 13\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu13_attn_residual -> layer1_attn_output_broadcast_gpu13 [label="" style=solid]
	layer1_attn_output_broadcast_gpu14 [label="layer1_attn_output_broadcast_gpu14\nAttention Output Broadcast\nGPU: 14\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu14_attn_residual -> layer1_attn_output_broadcast_gpu14 [label="" style=solid]
	layer1_attn_output_broadcast_gpu15 [label="layer1_attn_output_broadcast_gpu15\nAttention Output Broadcast\nGPU: 15\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_gpu15_attn_residual -> layer1_attn_output_broadcast_gpu15 [label="" style=solid]
	layer1_gating_network [label="layer1_gating_network\nGating Network\nGPU: 0-15\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, num_experts=16" color=black shape=parallelogram]
	layer1_gating_selection [label="layer1_gating_selection\nExpert Selection\nGPU: 0-15\nIn: batch_size=10240000, num_experts=16\nOut: batch_size=10240000, selected_experts=2" color=black shape=parallelogram]
	layer1_gating_network -> layer1_gating_selection [label="" style=solid]
	layer1_routing_route_to_expert0 [label="layer1_routing_route_to_expert0\nRoute to Expert 0\nGPU: 0\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer1_gating_selection -> layer1_routing_route_to_expert0 [label="" style=dashed]
	layer1_routing_route_to_expert1 [label="layer1_routing_route_to_expert1\nRoute to Expert 1\nGPU: 1\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer1_gating_selection -> layer1_routing_route_to_expert1 [label="" style=dashed]
	layer1_routing_route_to_expert2 [label="layer1_routing_route_to_expert2\nRoute to Expert 2\nGPU: 2\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer1_gating_selection -> layer1_routing_route_to_expert2 [label="" style=dashed]
	layer1_routing_route_to_expert3 [label="layer1_routing_route_to_expert3\nRoute to Expert 3\nGPU: 3\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer1_gating_selection -> layer1_routing_route_to_expert3 [label="" style=dashed]
	layer1_routing_route_to_expert4 [label="layer1_routing_route_to_expert4\nRoute to Expert 4\nGPU: 4\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer1_gating_selection -> layer1_routing_route_to_expert4 [label="" style=dashed]
	layer1_routing_route_to_expert5 [label="layer1_routing_route_to_expert5\nRoute to Expert 5\nGPU: 5\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer1_gating_selection -> layer1_routing_route_to_expert5 [label="" style=dashed]
	layer1_routing_route_to_expert6 [label="layer1_routing_route_to_expert6\nRoute to Expert 6\nGPU: 6\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer1_gating_selection -> layer1_routing_route_to_expert6 [label="" style=dashed]
	layer1_routing_route_to_expert7 [label="layer1_routing_route_to_expert7\nRoute to Expert 7\nGPU: 7\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer1_gating_selection -> layer1_routing_route_to_expert7 [label="" style=dashed]
	layer1_routing_route_to_expert8 [label="layer1_routing_route_to_expert8\nRoute to Expert 8\nGPU: 8\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer1_gating_selection -> layer1_routing_route_to_expert8 [label="" style=dashed]
	layer1_routing_route_to_expert9 [label="layer1_routing_route_to_expert9\nRoute to Expert 9\nGPU: 9\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer1_gating_selection -> layer1_routing_route_to_expert9 [label="" style=dashed]
	layer1_routing_route_to_expert10 [label="layer1_routing_route_to_expert10\nRoute to Expert 10\nGPU: 10\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer1_gating_selection -> layer1_routing_route_to_expert10 [label="" style=dashed]
	layer1_routing_route_to_expert11 [label="layer1_routing_route_to_expert11\nRoute to Expert 11\nGPU: 11\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer1_gating_selection -> layer1_routing_route_to_expert11 [label="" style=dashed]
	layer1_routing_route_to_expert12 [label="layer1_routing_route_to_expert12\nRoute to Expert 12\nGPU: 12\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer1_gating_selection -> layer1_routing_route_to_expert12 [label="" style=dashed]
	layer1_routing_route_to_expert13 [label="layer1_routing_route_to_expert13\nRoute to Expert 13\nGPU: 13\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer1_gating_selection -> layer1_routing_route_to_expert13 [label="" style=dashed]
	layer1_routing_route_to_expert14 [label="layer1_routing_route_to_expert14\nRoute to Expert 14\nGPU: 14\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer1_gating_selection -> layer1_routing_route_to_expert14 [label="" style=dashed]
	layer1_routing_route_to_expert15 [label="layer1_routing_route_to_expert15\nRoute to Expert 15\nGPU: 15\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer1_gating_selection -> layer1_routing_route_to_expert15 [label="" style=dashed]
	layer1_expert0_gpu0_gate_proj [label="layer1_expert0_gpu0_gate_proj\nGate Projection\nGPU: 0\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer1_expert0_gpu0_up_proj [label="layer1_expert0_gpu0_up_proj\nUp Projection\nGPU: 0\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer1_expert0_gpu0_activation [label="layer1_expert0_gpu0_activation\nGELU Activation\nGPU: 0\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer1_expert0_gpu0_down_proj [label="layer1_expert0_gpu0_down_proj\nDown Projection\nGPU: 0\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer1_expert0_gpu0_gate_proj -> layer1_expert0_gpu0_activation [label="" style=solid]
	layer1_expert0_gpu0_up_proj -> layer1_expert0_gpu0_down_proj [label="" style=solid]
	layer1_expert0_gpu0_activation -> layer1_expert0_gpu0_down_proj [label="" style=solid]
	layer1_routing_route_to_expert0 -> layer1_expert0_gpu0_gate_proj [label="" style=solid]
	layer1_routing_route_to_expert0 -> layer1_expert0_gpu0_up_proj [label="" style=solid]
	layer1_expert1_gpu1_gate_proj [label="layer1_expert1_gpu1_gate_proj\nGate Projection\nGPU: 1\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer1_expert1_gpu1_up_proj [label="layer1_expert1_gpu1_up_proj\nUp Projection\nGPU: 1\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer1_expert1_gpu1_activation [label="layer1_expert1_gpu1_activation\nGELU Activation\nGPU: 1\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer1_expert1_gpu1_down_proj [label="layer1_expert1_gpu1_down_proj\nDown Projection\nGPU: 1\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer1_expert1_gpu1_gate_proj -> layer1_expert1_gpu1_activation [label="" style=solid]
	layer1_expert1_gpu1_up_proj -> layer1_expert1_gpu1_down_proj [label="" style=solid]
	layer1_expert1_gpu1_activation -> layer1_expert1_gpu1_down_proj [label="" style=solid]
	layer1_routing_route_to_expert1 -> layer1_expert1_gpu1_gate_proj [label="" style=solid]
	layer1_routing_route_to_expert1 -> layer1_expert1_gpu1_up_proj [label="" style=solid]
	layer1_expert2_gpu2_gate_proj [label="layer1_expert2_gpu2_gate_proj\nGate Projection\nGPU: 2\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer1_expert2_gpu2_up_proj [label="layer1_expert2_gpu2_up_proj\nUp Projection\nGPU: 2\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer1_expert2_gpu2_activation [label="layer1_expert2_gpu2_activation\nGELU Activation\nGPU: 2\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer1_expert2_gpu2_down_proj [label="layer1_expert2_gpu2_down_proj\nDown Projection\nGPU: 2\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer1_expert2_gpu2_gate_proj -> layer1_expert2_gpu2_activation [label="" style=solid]
	layer1_expert2_gpu2_up_proj -> layer1_expert2_gpu2_down_proj [label="" style=solid]
	layer1_expert2_gpu2_activation -> layer1_expert2_gpu2_down_proj [label="" style=solid]
	layer1_routing_route_to_expert2 -> layer1_expert2_gpu2_gate_proj [label="" style=solid]
	layer1_routing_route_to_expert2 -> layer1_expert2_gpu2_up_proj [label="" style=solid]
	layer1_expert3_gpu3_gate_proj [label="layer1_expert3_gpu3_gate_proj\nGate Projection\nGPU: 3\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer1_expert3_gpu3_up_proj [label="layer1_expert3_gpu3_up_proj\nUp Projection\nGPU: 3\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer1_expert3_gpu3_activation [label="layer1_expert3_gpu3_activation\nGELU Activation\nGPU: 3\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer1_expert3_gpu3_down_proj [label="layer1_expert3_gpu3_down_proj\nDown Projection\nGPU: 3\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer1_expert3_gpu3_gate_proj -> layer1_expert3_gpu3_activation [label="" style=solid]
	layer1_expert3_gpu3_up_proj -> layer1_expert3_gpu3_down_proj [label="" style=solid]
	layer1_expert3_gpu3_activation -> layer1_expert3_gpu3_down_proj [label="" style=solid]
	layer1_routing_route_to_expert3 -> layer1_expert3_gpu3_gate_proj [label="" style=solid]
	layer1_routing_route_to_expert3 -> layer1_expert3_gpu3_up_proj [label="" style=solid]
	layer1_expert4_gpu4_gate_proj [label="layer1_expert4_gpu4_gate_proj\nGate Projection\nGPU: 4\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer1_expert4_gpu4_up_proj [label="layer1_expert4_gpu4_up_proj\nUp Projection\nGPU: 4\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer1_expert4_gpu4_activation [label="layer1_expert4_gpu4_activation\nGELU Activation\nGPU: 4\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer1_expert4_gpu4_down_proj [label="layer1_expert4_gpu4_down_proj\nDown Projection\nGPU: 4\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer1_expert4_gpu4_gate_proj -> layer1_expert4_gpu4_activation [label="" style=solid]
	layer1_expert4_gpu4_up_proj -> layer1_expert4_gpu4_down_proj [label="" style=solid]
	layer1_expert4_gpu4_activation -> layer1_expert4_gpu4_down_proj [label="" style=solid]
	layer1_routing_route_to_expert4 -> layer1_expert4_gpu4_gate_proj [label="" style=solid]
	layer1_routing_route_to_expert4 -> layer1_expert4_gpu4_up_proj [label="" style=solid]
	layer1_expert5_gpu5_gate_proj [label="layer1_expert5_gpu5_gate_proj\nGate Projection\nGPU: 5\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer1_expert5_gpu5_up_proj [label="layer1_expert5_gpu5_up_proj\nUp Projection\nGPU: 5\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer1_expert5_gpu5_activation [label="layer1_expert5_gpu5_activation\nGELU Activation\nGPU: 5\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer1_expert5_gpu5_down_proj [label="layer1_expert5_gpu5_down_proj\nDown Projection\nGPU: 5\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer1_expert5_gpu5_gate_proj -> layer1_expert5_gpu5_activation [label="" style=solid]
	layer1_expert5_gpu5_up_proj -> layer1_expert5_gpu5_down_proj [label="" style=solid]
	layer1_expert5_gpu5_activation -> layer1_expert5_gpu5_down_proj [label="" style=solid]
	layer1_routing_route_to_expert5 -> layer1_expert5_gpu5_gate_proj [label="" style=solid]
	layer1_routing_route_to_expert5 -> layer1_expert5_gpu5_up_proj [label="" style=solid]
	layer1_expert6_gpu6_gate_proj [label="layer1_expert6_gpu6_gate_proj\nGate Projection\nGPU: 6\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer1_expert6_gpu6_up_proj [label="layer1_expert6_gpu6_up_proj\nUp Projection\nGPU: 6\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer1_expert6_gpu6_activation [label="layer1_expert6_gpu6_activation\nGELU Activation\nGPU: 6\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer1_expert6_gpu6_down_proj [label="layer1_expert6_gpu6_down_proj\nDown Projection\nGPU: 6\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer1_expert6_gpu6_gate_proj -> layer1_expert6_gpu6_activation [label="" style=solid]
	layer1_expert6_gpu6_up_proj -> layer1_expert6_gpu6_down_proj [label="" style=solid]
	layer1_expert6_gpu6_activation -> layer1_expert6_gpu6_down_proj [label="" style=solid]
	layer1_routing_route_to_expert6 -> layer1_expert6_gpu6_gate_proj [label="" style=solid]
	layer1_routing_route_to_expert6 -> layer1_expert6_gpu6_up_proj [label="" style=solid]
	layer1_expert7_gpu7_gate_proj [label="layer1_expert7_gpu7_gate_proj\nGate Projection\nGPU: 7\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer1_expert7_gpu7_up_proj [label="layer1_expert7_gpu7_up_proj\nUp Projection\nGPU: 7\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer1_expert7_gpu7_activation [label="layer1_expert7_gpu7_activation\nGELU Activation\nGPU: 7\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer1_expert7_gpu7_down_proj [label="layer1_expert7_gpu7_down_proj\nDown Projection\nGPU: 7\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer1_expert7_gpu7_gate_proj -> layer1_expert7_gpu7_activation [label="" style=solid]
	layer1_expert7_gpu7_up_proj -> layer1_expert7_gpu7_down_proj [label="" style=solid]
	layer1_expert7_gpu7_activation -> layer1_expert7_gpu7_down_proj [label="" style=solid]
	layer1_routing_route_to_expert7 -> layer1_expert7_gpu7_gate_proj [label="" style=solid]
	layer1_routing_route_to_expert7 -> layer1_expert7_gpu7_up_proj [label="" style=solid]
	layer1_expert8_gpu8_gate_proj [label="layer1_expert8_gpu8_gate_proj\nGate Projection\nGPU: 8\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer1_expert8_gpu8_up_proj [label="layer1_expert8_gpu8_up_proj\nUp Projection\nGPU: 8\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer1_expert8_gpu8_activation [label="layer1_expert8_gpu8_activation\nGELU Activation\nGPU: 8\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer1_expert8_gpu8_down_proj [label="layer1_expert8_gpu8_down_proj\nDown Projection\nGPU: 8\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer1_expert8_gpu8_gate_proj -> layer1_expert8_gpu8_activation [label="" style=solid]
	layer1_expert8_gpu8_up_proj -> layer1_expert8_gpu8_down_proj [label="" style=solid]
	layer1_expert8_gpu8_activation -> layer1_expert8_gpu8_down_proj [label="" style=solid]
	layer1_routing_route_to_expert8 -> layer1_expert8_gpu8_gate_proj [label="" style=solid]
	layer1_routing_route_to_expert8 -> layer1_expert8_gpu8_up_proj [label="" style=solid]
	layer1_expert9_gpu9_gate_proj [label="layer1_expert9_gpu9_gate_proj\nGate Projection\nGPU: 9\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer1_expert9_gpu9_up_proj [label="layer1_expert9_gpu9_up_proj\nUp Projection\nGPU: 9\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer1_expert9_gpu9_activation [label="layer1_expert9_gpu9_activation\nGELU Activation\nGPU: 9\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer1_expert9_gpu9_down_proj [label="layer1_expert9_gpu9_down_proj\nDown Projection\nGPU: 9\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer1_expert9_gpu9_gate_proj -> layer1_expert9_gpu9_activation [label="" style=solid]
	layer1_expert9_gpu9_up_proj -> layer1_expert9_gpu9_down_proj [label="" style=solid]
	layer1_expert9_gpu9_activation -> layer1_expert9_gpu9_down_proj [label="" style=solid]
	layer1_routing_route_to_expert9 -> layer1_expert9_gpu9_gate_proj [label="" style=solid]
	layer1_routing_route_to_expert9 -> layer1_expert9_gpu9_up_proj [label="" style=solid]
	layer1_expert10_gpu10_gate_proj [label="layer1_expert10_gpu10_gate_proj\nGate Projection\nGPU: 10\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer1_expert10_gpu10_up_proj [label="layer1_expert10_gpu10_up_proj\nUp Projection\nGPU: 10\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer1_expert10_gpu10_activation [label="layer1_expert10_gpu10_activation\nGELU Activation\nGPU: 10\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer1_expert10_gpu10_down_proj [label="layer1_expert10_gpu10_down_proj\nDown Projection\nGPU: 10\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer1_expert10_gpu10_gate_proj -> layer1_expert10_gpu10_activation [label="" style=solid]
	layer1_expert10_gpu10_up_proj -> layer1_expert10_gpu10_down_proj [label="" style=solid]
	layer1_expert10_gpu10_activation -> layer1_expert10_gpu10_down_proj [label="" style=solid]
	layer1_routing_route_to_expert10 -> layer1_expert10_gpu10_gate_proj [label="" style=solid]
	layer1_routing_route_to_expert10 -> layer1_expert10_gpu10_up_proj [label="" style=solid]
	layer1_expert11_gpu11_gate_proj [label="layer1_expert11_gpu11_gate_proj\nGate Projection\nGPU: 11\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer1_expert11_gpu11_up_proj [label="layer1_expert11_gpu11_up_proj\nUp Projection\nGPU: 11\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer1_expert11_gpu11_activation [label="layer1_expert11_gpu11_activation\nGELU Activation\nGPU: 11\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer1_expert11_gpu11_down_proj [label="layer1_expert11_gpu11_down_proj\nDown Projection\nGPU: 11\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer1_expert11_gpu11_gate_proj -> layer1_expert11_gpu11_activation [label="" style=solid]
	layer1_expert11_gpu11_up_proj -> layer1_expert11_gpu11_down_proj [label="" style=solid]
	layer1_expert11_gpu11_activation -> layer1_expert11_gpu11_down_proj [label="" style=solid]
	layer1_routing_route_to_expert11 -> layer1_expert11_gpu11_gate_proj [label="" style=solid]
	layer1_routing_route_to_expert11 -> layer1_expert11_gpu11_up_proj [label="" style=solid]
	layer1_expert12_gpu12_gate_proj [label="layer1_expert12_gpu12_gate_proj\nGate Projection\nGPU: 12\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer1_expert12_gpu12_up_proj [label="layer1_expert12_gpu12_up_proj\nUp Projection\nGPU: 12\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer1_expert12_gpu12_activation [label="layer1_expert12_gpu12_activation\nGELU Activation\nGPU: 12\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer1_expert12_gpu12_down_proj [label="layer1_expert12_gpu12_down_proj\nDown Projection\nGPU: 12\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer1_expert12_gpu12_gate_proj -> layer1_expert12_gpu12_activation [label="" style=solid]
	layer1_expert12_gpu12_up_proj -> layer1_expert12_gpu12_down_proj [label="" style=solid]
	layer1_expert12_gpu12_activation -> layer1_expert12_gpu12_down_proj [label="" style=solid]
	layer1_routing_route_to_expert12 -> layer1_expert12_gpu12_gate_proj [label="" style=solid]
	layer1_routing_route_to_expert12 -> layer1_expert12_gpu12_up_proj [label="" style=solid]
	layer1_expert13_gpu13_gate_proj [label="layer1_expert13_gpu13_gate_proj\nGate Projection\nGPU: 13\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer1_expert13_gpu13_up_proj [label="layer1_expert13_gpu13_up_proj\nUp Projection\nGPU: 13\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer1_expert13_gpu13_activation [label="layer1_expert13_gpu13_activation\nGELU Activation\nGPU: 13\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer1_expert13_gpu13_down_proj [label="layer1_expert13_gpu13_down_proj\nDown Projection\nGPU: 13\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer1_expert13_gpu13_gate_proj -> layer1_expert13_gpu13_activation [label="" style=solid]
	layer1_expert13_gpu13_up_proj -> layer1_expert13_gpu13_down_proj [label="" style=solid]
	layer1_expert13_gpu13_activation -> layer1_expert13_gpu13_down_proj [label="" style=solid]
	layer1_routing_route_to_expert13 -> layer1_expert13_gpu13_gate_proj [label="" style=solid]
	layer1_routing_route_to_expert13 -> layer1_expert13_gpu13_up_proj [label="" style=solid]
	layer1_expert14_gpu14_gate_proj [label="layer1_expert14_gpu14_gate_proj\nGate Projection\nGPU: 14\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer1_expert14_gpu14_up_proj [label="layer1_expert14_gpu14_up_proj\nUp Projection\nGPU: 14\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer1_expert14_gpu14_activation [label="layer1_expert14_gpu14_activation\nGELU Activation\nGPU: 14\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer1_expert14_gpu14_down_proj [label="layer1_expert14_gpu14_down_proj\nDown Projection\nGPU: 14\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer1_expert14_gpu14_gate_proj -> layer1_expert14_gpu14_activation [label="" style=solid]
	layer1_expert14_gpu14_up_proj -> layer1_expert14_gpu14_down_proj [label="" style=solid]
	layer1_expert14_gpu14_activation -> layer1_expert14_gpu14_down_proj [label="" style=solid]
	layer1_routing_route_to_expert14 -> layer1_expert14_gpu14_gate_proj [label="" style=solid]
	layer1_routing_route_to_expert14 -> layer1_expert14_gpu14_up_proj [label="" style=solid]
	layer1_expert15_gpu15_gate_proj [label="layer1_expert15_gpu15_gate_proj\nGate Projection\nGPU: 15\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer1_expert15_gpu15_up_proj [label="layer1_expert15_gpu15_up_proj\nUp Projection\nGPU: 15\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer1_expert15_gpu15_activation [label="layer1_expert15_gpu15_activation\nGELU Activation\nGPU: 15\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer1_expert15_gpu15_down_proj [label="layer1_expert15_gpu15_down_proj\nDown Projection\nGPU: 15\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer1_expert15_gpu15_gate_proj -> layer1_expert15_gpu15_activation [label="" style=solid]
	layer1_expert15_gpu15_up_proj -> layer1_expert15_gpu15_down_proj [label="" style=solid]
	layer1_expert15_gpu15_activation -> layer1_expert15_gpu15_down_proj [label="" style=solid]
	layer1_routing_route_to_expert15 -> layer1_expert15_gpu15_gate_proj [label="" style=solid]
	layer1_routing_route_to_expert15 -> layer1_expert15_gpu15_up_proj [label="" style=solid]
	layer1_routing_aggregate [label="layer1_routing_aggregate\nAggregate Expert Outputs\nGPU: 0-15\nIn: batch_size=640000, hidden_dim=8192 (x16)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=parallelogram]
	layer1_expert0_gpu0_down_proj -> layer1_routing_aggregate [label="" style=solid]
	layer1_expert1_gpu1_down_proj -> layer1_routing_aggregate [label="" style=solid]
	layer1_expert2_gpu2_down_proj -> layer1_routing_aggregate [label="" style=solid]
	layer1_expert3_gpu3_down_proj -> layer1_routing_aggregate [label="" style=solid]
	layer1_expert4_gpu4_down_proj -> layer1_routing_aggregate [label="" style=solid]
	layer1_expert5_gpu5_down_proj -> layer1_routing_aggregate [label="" style=solid]
	layer1_expert6_gpu6_down_proj -> layer1_routing_aggregate [label="" style=solid]
	layer1_expert7_gpu7_down_proj -> layer1_routing_aggregate [label="" style=solid]
	layer1_expert8_gpu8_down_proj -> layer1_routing_aggregate [label="" style=solid]
	layer1_expert9_gpu9_down_proj -> layer1_routing_aggregate [label="" style=solid]
	layer1_expert10_gpu10_down_proj -> layer1_routing_aggregate [label="" style=solid]
	layer1_expert11_gpu11_down_proj -> layer1_routing_aggregate [label="" style=solid]
	layer1_expert12_gpu12_down_proj -> layer1_routing_aggregate [label="" style=solid]
	layer1_expert13_gpu13_down_proj -> layer1_routing_aggregate [label="" style=solid]
	layer1_expert14_gpu14_down_proj -> layer1_routing_aggregate [label="" style=solid]
	layer1_expert15_gpu15_down_proj -> layer1_routing_aggregate [label="" style=solid]
	layer1_routing_weighted_sum [label="layer1_routing_weighted_sum\nWeighted Sum\nGPU: 0-15\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_routing_aggregate -> layer1_routing_weighted_sum [label="" style=solid]
	layer1_gating_selection -> layer1_routing_weighted_sum [label="" style=dashed]
	layer1_attn_output_broadcast_gpu0 -> layer1_gating_network [label="" style=solid]
	layer1_attn_output_broadcast_gpu1 -> layer1_gating_network [label="" style=solid]
	layer1_attn_output_broadcast_gpu2 -> layer1_gating_network [label="" style=solid]
	layer1_attn_output_broadcast_gpu3 -> layer1_gating_network [label="" style=solid]
	layer1_attn_output_broadcast_gpu4 -> layer1_gating_network [label="" style=solid]
	layer1_attn_output_broadcast_gpu5 -> layer1_gating_network [label="" style=solid]
	layer1_attn_output_broadcast_gpu6 -> layer1_gating_network [label="" style=solid]
	layer1_attn_output_broadcast_gpu7 -> layer1_gating_network [label="" style=solid]
	layer1_attn_output_broadcast_gpu8 -> layer1_gating_network [label="" style=solid]
	layer1_attn_output_broadcast_gpu9 -> layer1_gating_network [label="" style=solid]
	layer1_attn_output_broadcast_gpu10 -> layer1_gating_network [label="" style=solid]
	layer1_attn_output_broadcast_gpu11 -> layer1_gating_network [label="" style=solid]
	layer1_attn_output_broadcast_gpu12 -> layer1_gating_network [label="" style=solid]
	layer1_attn_output_broadcast_gpu13 -> layer1_gating_network [label="" style=solid]
	layer1_attn_output_broadcast_gpu14 -> layer1_gating_network [label="" style=solid]
	layer1_attn_output_broadcast_gpu15 -> layer1_gating_network [label="" style=solid]
	layer1_output [label="layer1_output\nLayer Output\nGPU: 0-15\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer1_attn_output_broadcast_gpu0 -> layer1_output [label="" style=dashed]
	layer1_attn_output_broadcast_gpu1 -> layer1_output [label="" style=dashed]
	layer1_attn_output_broadcast_gpu2 -> layer1_output [label="" style=dashed]
	layer1_attn_output_broadcast_gpu3 -> layer1_output [label="" style=dashed]
	layer1_attn_output_broadcast_gpu4 -> layer1_output [label="" style=dashed]
	layer1_attn_output_broadcast_gpu5 -> layer1_output [label="" style=dashed]
	layer1_attn_output_broadcast_gpu6 -> layer1_output [label="" style=dashed]
	layer1_attn_output_broadcast_gpu7 -> layer1_output [label="" style=dashed]
	layer1_attn_output_broadcast_gpu8 -> layer1_output [label="" style=dashed]
	layer1_attn_output_broadcast_gpu9 -> layer1_output [label="" style=dashed]
	layer1_attn_output_broadcast_gpu10 -> layer1_output [label="" style=dashed]
	layer1_attn_output_broadcast_gpu11 -> layer1_output [label="" style=dashed]
	layer1_attn_output_broadcast_gpu12 -> layer1_output [label="" style=dashed]
	layer1_attn_output_broadcast_gpu13 -> layer1_output [label="" style=dashed]
	layer1_attn_output_broadcast_gpu14 -> layer1_output [label="" style=dashed]
	layer1_attn_output_broadcast_gpu15 -> layer1_output [label="" style=dashed]
	layer1_routing_weighted_sum -> layer1_output [label="" style=solid]
	layer0_output -> layer1_input_broadcast [label="" style=solid]
	layer2_input_broadcast [label="layer2_input_broadcast\nLayer Input Broadcast\nGPU: 0-15\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=1024, seq_len=10000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu0_attn_input_reshape [label="layer2_gpu0_attn_input_reshape\nInput Reshape\nGPU: 0\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu0_q_proj [label="layer2_gpu0_q_proj\nQ Projection\nGPU: 0\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu0_k_proj [label="layer2_gpu0_k_proj\nK Projection\nGPU: 0\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu0_v_proj [label="layer2_gpu0_v_proj\nV Projection\nGPU: 0\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu0_mha [label="layer2_gpu0_mha\nMulti-Head Attention\nGPU: 0\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu0_o_proj [label="layer2_gpu0_o_proj\nOutput Projection\nGPU: 0\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer2_gpu0_attn_residual [label="layer2_gpu0_attn_residual\nResidual Add\nGPU: 0\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu0_attn_input_reshape -> layer2_gpu0_q_proj [label="" style=solid]
	layer2_gpu0_attn_input_reshape -> layer2_gpu0_k_proj [label="" style=solid]
	layer2_gpu0_attn_input_reshape -> layer2_gpu0_v_proj [label="" style=solid]
	layer2_gpu0_q_proj -> layer2_gpu0_mha [label="" style=solid]
	layer2_gpu0_k_proj -> layer2_gpu0_mha [label="" style=solid]
	layer2_gpu0_v_proj -> layer2_gpu0_mha [label="" style=solid]
	layer2_gpu0_mha -> layer2_gpu0_o_proj [label="" style=solid]
	layer2_gpu0_o_proj -> layer2_gpu0_attn_residual [label="" style=solid]
	layer2_gpu0_attn_input_reshape -> layer2_gpu0_attn_residual [label="" style=dashed]
	layer2_input_broadcast -> layer2_gpu0_attn_input_reshape [label="" style=solid]
	layer2_gpu1_attn_input_reshape [label="layer2_gpu1_attn_input_reshape\nInput Reshape\nGPU: 1\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu1_q_proj [label="layer2_gpu1_q_proj\nQ Projection\nGPU: 1\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu1_k_proj [label="layer2_gpu1_k_proj\nK Projection\nGPU: 1\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu1_v_proj [label="layer2_gpu1_v_proj\nV Projection\nGPU: 1\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu1_mha [label="layer2_gpu1_mha\nMulti-Head Attention\nGPU: 1\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu1_o_proj [label="layer2_gpu1_o_proj\nOutput Projection\nGPU: 1\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer2_gpu1_attn_residual [label="layer2_gpu1_attn_residual\nResidual Add\nGPU: 1\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu1_attn_input_reshape -> layer2_gpu1_q_proj [label="" style=solid]
	layer2_gpu1_attn_input_reshape -> layer2_gpu1_k_proj [label="" style=solid]
	layer2_gpu1_attn_input_reshape -> layer2_gpu1_v_proj [label="" style=solid]
	layer2_gpu1_q_proj -> layer2_gpu1_mha [label="" style=solid]
	layer2_gpu1_k_proj -> layer2_gpu1_mha [label="" style=solid]
	layer2_gpu1_v_proj -> layer2_gpu1_mha [label="" style=solid]
	layer2_gpu1_mha -> layer2_gpu1_o_proj [label="" style=solid]
	layer2_gpu1_o_proj -> layer2_gpu1_attn_residual [label="" style=solid]
	layer2_gpu1_attn_input_reshape -> layer2_gpu1_attn_residual [label="" style=dashed]
	layer2_input_broadcast -> layer2_gpu1_attn_input_reshape [label="" style=solid]
	layer2_gpu2_attn_input_reshape [label="layer2_gpu2_attn_input_reshape\nInput Reshape\nGPU: 2\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu2_q_proj [label="layer2_gpu2_q_proj\nQ Projection\nGPU: 2\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu2_k_proj [label="layer2_gpu2_k_proj\nK Projection\nGPU: 2\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu2_v_proj [label="layer2_gpu2_v_proj\nV Projection\nGPU: 2\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu2_mha [label="layer2_gpu2_mha\nMulti-Head Attention\nGPU: 2\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu2_o_proj [label="layer2_gpu2_o_proj\nOutput Projection\nGPU: 2\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer2_gpu2_attn_residual [label="layer2_gpu2_attn_residual\nResidual Add\nGPU: 2\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu2_attn_input_reshape -> layer2_gpu2_q_proj [label="" style=solid]
	layer2_gpu2_attn_input_reshape -> layer2_gpu2_k_proj [label="" style=solid]
	layer2_gpu2_attn_input_reshape -> layer2_gpu2_v_proj [label="" style=solid]
	layer2_gpu2_q_proj -> layer2_gpu2_mha [label="" style=solid]
	layer2_gpu2_k_proj -> layer2_gpu2_mha [label="" style=solid]
	layer2_gpu2_v_proj -> layer2_gpu2_mha [label="" style=solid]
	layer2_gpu2_mha -> layer2_gpu2_o_proj [label="" style=solid]
	layer2_gpu2_o_proj -> layer2_gpu2_attn_residual [label="" style=solid]
	layer2_gpu2_attn_input_reshape -> layer2_gpu2_attn_residual [label="" style=dashed]
	layer2_input_broadcast -> layer2_gpu2_attn_input_reshape [label="" style=solid]
	layer2_gpu3_attn_input_reshape [label="layer2_gpu3_attn_input_reshape\nInput Reshape\nGPU: 3\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu3_q_proj [label="layer2_gpu3_q_proj\nQ Projection\nGPU: 3\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu3_k_proj [label="layer2_gpu3_k_proj\nK Projection\nGPU: 3\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu3_v_proj [label="layer2_gpu3_v_proj\nV Projection\nGPU: 3\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu3_mha [label="layer2_gpu3_mha\nMulti-Head Attention\nGPU: 3\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu3_o_proj [label="layer2_gpu3_o_proj\nOutput Projection\nGPU: 3\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer2_gpu3_attn_residual [label="layer2_gpu3_attn_residual\nResidual Add\nGPU: 3\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu3_attn_input_reshape -> layer2_gpu3_q_proj [label="" style=solid]
	layer2_gpu3_attn_input_reshape -> layer2_gpu3_k_proj [label="" style=solid]
	layer2_gpu3_attn_input_reshape -> layer2_gpu3_v_proj [label="" style=solid]
	layer2_gpu3_q_proj -> layer2_gpu3_mha [label="" style=solid]
	layer2_gpu3_k_proj -> layer2_gpu3_mha [label="" style=solid]
	layer2_gpu3_v_proj -> layer2_gpu3_mha [label="" style=solid]
	layer2_gpu3_mha -> layer2_gpu3_o_proj [label="" style=solid]
	layer2_gpu3_o_proj -> layer2_gpu3_attn_residual [label="" style=solid]
	layer2_gpu3_attn_input_reshape -> layer2_gpu3_attn_residual [label="" style=dashed]
	layer2_input_broadcast -> layer2_gpu3_attn_input_reshape [label="" style=solid]
	layer2_gpu4_attn_input_reshape [label="layer2_gpu4_attn_input_reshape\nInput Reshape\nGPU: 4\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu4_q_proj [label="layer2_gpu4_q_proj\nQ Projection\nGPU: 4\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu4_k_proj [label="layer2_gpu4_k_proj\nK Projection\nGPU: 4\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu4_v_proj [label="layer2_gpu4_v_proj\nV Projection\nGPU: 4\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu4_mha [label="layer2_gpu4_mha\nMulti-Head Attention\nGPU: 4\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu4_o_proj [label="layer2_gpu4_o_proj\nOutput Projection\nGPU: 4\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer2_gpu4_attn_residual [label="layer2_gpu4_attn_residual\nResidual Add\nGPU: 4\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu4_attn_input_reshape -> layer2_gpu4_q_proj [label="" style=solid]
	layer2_gpu4_attn_input_reshape -> layer2_gpu4_k_proj [label="" style=solid]
	layer2_gpu4_attn_input_reshape -> layer2_gpu4_v_proj [label="" style=solid]
	layer2_gpu4_q_proj -> layer2_gpu4_mha [label="" style=solid]
	layer2_gpu4_k_proj -> layer2_gpu4_mha [label="" style=solid]
	layer2_gpu4_v_proj -> layer2_gpu4_mha [label="" style=solid]
	layer2_gpu4_mha -> layer2_gpu4_o_proj [label="" style=solid]
	layer2_gpu4_o_proj -> layer2_gpu4_attn_residual [label="" style=solid]
	layer2_gpu4_attn_input_reshape -> layer2_gpu4_attn_residual [label="" style=dashed]
	layer2_input_broadcast -> layer2_gpu4_attn_input_reshape [label="" style=solid]
	layer2_gpu5_attn_input_reshape [label="layer2_gpu5_attn_input_reshape\nInput Reshape\nGPU: 5\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu5_q_proj [label="layer2_gpu5_q_proj\nQ Projection\nGPU: 5\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu5_k_proj [label="layer2_gpu5_k_proj\nK Projection\nGPU: 5\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu5_v_proj [label="layer2_gpu5_v_proj\nV Projection\nGPU: 5\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu5_mha [label="layer2_gpu5_mha\nMulti-Head Attention\nGPU: 5\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu5_o_proj [label="layer2_gpu5_o_proj\nOutput Projection\nGPU: 5\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer2_gpu5_attn_residual [label="layer2_gpu5_attn_residual\nResidual Add\nGPU: 5\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu5_attn_input_reshape -> layer2_gpu5_q_proj [label="" style=solid]
	layer2_gpu5_attn_input_reshape -> layer2_gpu5_k_proj [label="" style=solid]
	layer2_gpu5_attn_input_reshape -> layer2_gpu5_v_proj [label="" style=solid]
	layer2_gpu5_q_proj -> layer2_gpu5_mha [label="" style=solid]
	layer2_gpu5_k_proj -> layer2_gpu5_mha [label="" style=solid]
	layer2_gpu5_v_proj -> layer2_gpu5_mha [label="" style=solid]
	layer2_gpu5_mha -> layer2_gpu5_o_proj [label="" style=solid]
	layer2_gpu5_o_proj -> layer2_gpu5_attn_residual [label="" style=solid]
	layer2_gpu5_attn_input_reshape -> layer2_gpu5_attn_residual [label="" style=dashed]
	layer2_input_broadcast -> layer2_gpu5_attn_input_reshape [label="" style=solid]
	layer2_gpu6_attn_input_reshape [label="layer2_gpu6_attn_input_reshape\nInput Reshape\nGPU: 6\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu6_q_proj [label="layer2_gpu6_q_proj\nQ Projection\nGPU: 6\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu6_k_proj [label="layer2_gpu6_k_proj\nK Projection\nGPU: 6\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu6_v_proj [label="layer2_gpu6_v_proj\nV Projection\nGPU: 6\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu6_mha [label="layer2_gpu6_mha\nMulti-Head Attention\nGPU: 6\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu6_o_proj [label="layer2_gpu6_o_proj\nOutput Projection\nGPU: 6\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer2_gpu6_attn_residual [label="layer2_gpu6_attn_residual\nResidual Add\nGPU: 6\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu6_attn_input_reshape -> layer2_gpu6_q_proj [label="" style=solid]
	layer2_gpu6_attn_input_reshape -> layer2_gpu6_k_proj [label="" style=solid]
	layer2_gpu6_attn_input_reshape -> layer2_gpu6_v_proj [label="" style=solid]
	layer2_gpu6_q_proj -> layer2_gpu6_mha [label="" style=solid]
	layer2_gpu6_k_proj -> layer2_gpu6_mha [label="" style=solid]
	layer2_gpu6_v_proj -> layer2_gpu6_mha [label="" style=solid]
	layer2_gpu6_mha -> layer2_gpu6_o_proj [label="" style=solid]
	layer2_gpu6_o_proj -> layer2_gpu6_attn_residual [label="" style=solid]
	layer2_gpu6_attn_input_reshape -> layer2_gpu6_attn_residual [label="" style=dashed]
	layer2_input_broadcast -> layer2_gpu6_attn_input_reshape [label="" style=solid]
	layer2_gpu7_attn_input_reshape [label="layer2_gpu7_attn_input_reshape\nInput Reshape\nGPU: 7\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu7_q_proj [label="layer2_gpu7_q_proj\nQ Projection\nGPU: 7\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu7_k_proj [label="layer2_gpu7_k_proj\nK Projection\nGPU: 7\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu7_v_proj [label="layer2_gpu7_v_proj\nV Projection\nGPU: 7\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu7_mha [label="layer2_gpu7_mha\nMulti-Head Attention\nGPU: 7\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu7_o_proj [label="layer2_gpu7_o_proj\nOutput Projection\nGPU: 7\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer2_gpu7_attn_residual [label="layer2_gpu7_attn_residual\nResidual Add\nGPU: 7\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu7_attn_input_reshape -> layer2_gpu7_q_proj [label="" style=solid]
	layer2_gpu7_attn_input_reshape -> layer2_gpu7_k_proj [label="" style=solid]
	layer2_gpu7_attn_input_reshape -> layer2_gpu7_v_proj [label="" style=solid]
	layer2_gpu7_q_proj -> layer2_gpu7_mha [label="" style=solid]
	layer2_gpu7_k_proj -> layer2_gpu7_mha [label="" style=solid]
	layer2_gpu7_v_proj -> layer2_gpu7_mha [label="" style=solid]
	layer2_gpu7_mha -> layer2_gpu7_o_proj [label="" style=solid]
	layer2_gpu7_o_proj -> layer2_gpu7_attn_residual [label="" style=solid]
	layer2_gpu7_attn_input_reshape -> layer2_gpu7_attn_residual [label="" style=dashed]
	layer2_input_broadcast -> layer2_gpu7_attn_input_reshape [label="" style=solid]
	layer2_gpu8_attn_input_reshape [label="layer2_gpu8_attn_input_reshape\nInput Reshape\nGPU: 8\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu8_q_proj [label="layer2_gpu8_q_proj\nQ Projection\nGPU: 8\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu8_k_proj [label="layer2_gpu8_k_proj\nK Projection\nGPU: 8\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu8_v_proj [label="layer2_gpu8_v_proj\nV Projection\nGPU: 8\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu8_mha [label="layer2_gpu8_mha\nMulti-Head Attention\nGPU: 8\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu8_o_proj [label="layer2_gpu8_o_proj\nOutput Projection\nGPU: 8\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer2_gpu8_attn_residual [label="layer2_gpu8_attn_residual\nResidual Add\nGPU: 8\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu8_attn_input_reshape -> layer2_gpu8_q_proj [label="" style=solid]
	layer2_gpu8_attn_input_reshape -> layer2_gpu8_k_proj [label="" style=solid]
	layer2_gpu8_attn_input_reshape -> layer2_gpu8_v_proj [label="" style=solid]
	layer2_gpu8_q_proj -> layer2_gpu8_mha [label="" style=solid]
	layer2_gpu8_k_proj -> layer2_gpu8_mha [label="" style=solid]
	layer2_gpu8_v_proj -> layer2_gpu8_mha [label="" style=solid]
	layer2_gpu8_mha -> layer2_gpu8_o_proj [label="" style=solid]
	layer2_gpu8_o_proj -> layer2_gpu8_attn_residual [label="" style=solid]
	layer2_gpu8_attn_input_reshape -> layer2_gpu8_attn_residual [label="" style=dashed]
	layer2_input_broadcast -> layer2_gpu8_attn_input_reshape [label="" style=solid]
	layer2_gpu9_attn_input_reshape [label="layer2_gpu9_attn_input_reshape\nInput Reshape\nGPU: 9\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu9_q_proj [label="layer2_gpu9_q_proj\nQ Projection\nGPU: 9\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu9_k_proj [label="layer2_gpu9_k_proj\nK Projection\nGPU: 9\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu9_v_proj [label="layer2_gpu9_v_proj\nV Projection\nGPU: 9\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu9_mha [label="layer2_gpu9_mha\nMulti-Head Attention\nGPU: 9\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu9_o_proj [label="layer2_gpu9_o_proj\nOutput Projection\nGPU: 9\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer2_gpu9_attn_residual [label="layer2_gpu9_attn_residual\nResidual Add\nGPU: 9\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu9_attn_input_reshape -> layer2_gpu9_q_proj [label="" style=solid]
	layer2_gpu9_attn_input_reshape -> layer2_gpu9_k_proj [label="" style=solid]
	layer2_gpu9_attn_input_reshape -> layer2_gpu9_v_proj [label="" style=solid]
	layer2_gpu9_q_proj -> layer2_gpu9_mha [label="" style=solid]
	layer2_gpu9_k_proj -> layer2_gpu9_mha [label="" style=solid]
	layer2_gpu9_v_proj -> layer2_gpu9_mha [label="" style=solid]
	layer2_gpu9_mha -> layer2_gpu9_o_proj [label="" style=solid]
	layer2_gpu9_o_proj -> layer2_gpu9_attn_residual [label="" style=solid]
	layer2_gpu9_attn_input_reshape -> layer2_gpu9_attn_residual [label="" style=dashed]
	layer2_input_broadcast -> layer2_gpu9_attn_input_reshape [label="" style=solid]
	layer2_gpu10_attn_input_reshape [label="layer2_gpu10_attn_input_reshape\nInput Reshape\nGPU: 10\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu10_q_proj [label="layer2_gpu10_q_proj\nQ Projection\nGPU: 10\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu10_k_proj [label="layer2_gpu10_k_proj\nK Projection\nGPU: 10\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu10_v_proj [label="layer2_gpu10_v_proj\nV Projection\nGPU: 10\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu10_mha [label="layer2_gpu10_mha\nMulti-Head Attention\nGPU: 10\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu10_o_proj [label="layer2_gpu10_o_proj\nOutput Projection\nGPU: 10\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer2_gpu10_attn_residual [label="layer2_gpu10_attn_residual\nResidual Add\nGPU: 10\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu10_attn_input_reshape -> layer2_gpu10_q_proj [label="" style=solid]
	layer2_gpu10_attn_input_reshape -> layer2_gpu10_k_proj [label="" style=solid]
	layer2_gpu10_attn_input_reshape -> layer2_gpu10_v_proj [label="" style=solid]
	layer2_gpu10_q_proj -> layer2_gpu10_mha [label="" style=solid]
	layer2_gpu10_k_proj -> layer2_gpu10_mha [label="" style=solid]
	layer2_gpu10_v_proj -> layer2_gpu10_mha [label="" style=solid]
	layer2_gpu10_mha -> layer2_gpu10_o_proj [label="" style=solid]
	layer2_gpu10_o_proj -> layer2_gpu10_attn_residual [label="" style=solid]
	layer2_gpu10_attn_input_reshape -> layer2_gpu10_attn_residual [label="" style=dashed]
	layer2_input_broadcast -> layer2_gpu10_attn_input_reshape [label="" style=solid]
	layer2_gpu11_attn_input_reshape [label="layer2_gpu11_attn_input_reshape\nInput Reshape\nGPU: 11\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu11_q_proj [label="layer2_gpu11_q_proj\nQ Projection\nGPU: 11\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu11_k_proj [label="layer2_gpu11_k_proj\nK Projection\nGPU: 11\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu11_v_proj [label="layer2_gpu11_v_proj\nV Projection\nGPU: 11\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu11_mha [label="layer2_gpu11_mha\nMulti-Head Attention\nGPU: 11\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu11_o_proj [label="layer2_gpu11_o_proj\nOutput Projection\nGPU: 11\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer2_gpu11_attn_residual [label="layer2_gpu11_attn_residual\nResidual Add\nGPU: 11\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu11_attn_input_reshape -> layer2_gpu11_q_proj [label="" style=solid]
	layer2_gpu11_attn_input_reshape -> layer2_gpu11_k_proj [label="" style=solid]
	layer2_gpu11_attn_input_reshape -> layer2_gpu11_v_proj [label="" style=solid]
	layer2_gpu11_q_proj -> layer2_gpu11_mha [label="" style=solid]
	layer2_gpu11_k_proj -> layer2_gpu11_mha [label="" style=solid]
	layer2_gpu11_v_proj -> layer2_gpu11_mha [label="" style=solid]
	layer2_gpu11_mha -> layer2_gpu11_o_proj [label="" style=solid]
	layer2_gpu11_o_proj -> layer2_gpu11_attn_residual [label="" style=solid]
	layer2_gpu11_attn_input_reshape -> layer2_gpu11_attn_residual [label="" style=dashed]
	layer2_input_broadcast -> layer2_gpu11_attn_input_reshape [label="" style=solid]
	layer2_gpu12_attn_input_reshape [label="layer2_gpu12_attn_input_reshape\nInput Reshape\nGPU: 12\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu12_q_proj [label="layer2_gpu12_q_proj\nQ Projection\nGPU: 12\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu12_k_proj [label="layer2_gpu12_k_proj\nK Projection\nGPU: 12\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu12_v_proj [label="layer2_gpu12_v_proj\nV Projection\nGPU: 12\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu12_mha [label="layer2_gpu12_mha\nMulti-Head Attention\nGPU: 12\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu12_o_proj [label="layer2_gpu12_o_proj\nOutput Projection\nGPU: 12\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer2_gpu12_attn_residual [label="layer2_gpu12_attn_residual\nResidual Add\nGPU: 12\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu12_attn_input_reshape -> layer2_gpu12_q_proj [label="" style=solid]
	layer2_gpu12_attn_input_reshape -> layer2_gpu12_k_proj [label="" style=solid]
	layer2_gpu12_attn_input_reshape -> layer2_gpu12_v_proj [label="" style=solid]
	layer2_gpu12_q_proj -> layer2_gpu12_mha [label="" style=solid]
	layer2_gpu12_k_proj -> layer2_gpu12_mha [label="" style=solid]
	layer2_gpu12_v_proj -> layer2_gpu12_mha [label="" style=solid]
	layer2_gpu12_mha -> layer2_gpu12_o_proj [label="" style=solid]
	layer2_gpu12_o_proj -> layer2_gpu12_attn_residual [label="" style=solid]
	layer2_gpu12_attn_input_reshape -> layer2_gpu12_attn_residual [label="" style=dashed]
	layer2_input_broadcast -> layer2_gpu12_attn_input_reshape [label="" style=solid]
	layer2_gpu13_attn_input_reshape [label="layer2_gpu13_attn_input_reshape\nInput Reshape\nGPU: 13\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu13_q_proj [label="layer2_gpu13_q_proj\nQ Projection\nGPU: 13\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu13_k_proj [label="layer2_gpu13_k_proj\nK Projection\nGPU: 13\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu13_v_proj [label="layer2_gpu13_v_proj\nV Projection\nGPU: 13\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu13_mha [label="layer2_gpu13_mha\nMulti-Head Attention\nGPU: 13\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu13_o_proj [label="layer2_gpu13_o_proj\nOutput Projection\nGPU: 13\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer2_gpu13_attn_residual [label="layer2_gpu13_attn_residual\nResidual Add\nGPU: 13\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu13_attn_input_reshape -> layer2_gpu13_q_proj [label="" style=solid]
	layer2_gpu13_attn_input_reshape -> layer2_gpu13_k_proj [label="" style=solid]
	layer2_gpu13_attn_input_reshape -> layer2_gpu13_v_proj [label="" style=solid]
	layer2_gpu13_q_proj -> layer2_gpu13_mha [label="" style=solid]
	layer2_gpu13_k_proj -> layer2_gpu13_mha [label="" style=solid]
	layer2_gpu13_v_proj -> layer2_gpu13_mha [label="" style=solid]
	layer2_gpu13_mha -> layer2_gpu13_o_proj [label="" style=solid]
	layer2_gpu13_o_proj -> layer2_gpu13_attn_residual [label="" style=solid]
	layer2_gpu13_attn_input_reshape -> layer2_gpu13_attn_residual [label="" style=dashed]
	layer2_input_broadcast -> layer2_gpu13_attn_input_reshape [label="" style=solid]
	layer2_gpu14_attn_input_reshape [label="layer2_gpu14_attn_input_reshape\nInput Reshape\nGPU: 14\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu14_q_proj [label="layer2_gpu14_q_proj\nQ Projection\nGPU: 14\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu14_k_proj [label="layer2_gpu14_k_proj\nK Projection\nGPU: 14\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu14_v_proj [label="layer2_gpu14_v_proj\nV Projection\nGPU: 14\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu14_mha [label="layer2_gpu14_mha\nMulti-Head Attention\nGPU: 14\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu14_o_proj [label="layer2_gpu14_o_proj\nOutput Projection\nGPU: 14\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer2_gpu14_attn_residual [label="layer2_gpu14_attn_residual\nResidual Add\nGPU: 14\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu14_attn_input_reshape -> layer2_gpu14_q_proj [label="" style=solid]
	layer2_gpu14_attn_input_reshape -> layer2_gpu14_k_proj [label="" style=solid]
	layer2_gpu14_attn_input_reshape -> layer2_gpu14_v_proj [label="" style=solid]
	layer2_gpu14_q_proj -> layer2_gpu14_mha [label="" style=solid]
	layer2_gpu14_k_proj -> layer2_gpu14_mha [label="" style=solid]
	layer2_gpu14_v_proj -> layer2_gpu14_mha [label="" style=solid]
	layer2_gpu14_mha -> layer2_gpu14_o_proj [label="" style=solid]
	layer2_gpu14_o_proj -> layer2_gpu14_attn_residual [label="" style=solid]
	layer2_gpu14_attn_input_reshape -> layer2_gpu14_attn_residual [label="" style=dashed]
	layer2_input_broadcast -> layer2_gpu14_attn_input_reshape [label="" style=solid]
	layer2_gpu15_attn_input_reshape [label="layer2_gpu15_attn_input_reshape\nInput Reshape\nGPU: 15\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu15_q_proj [label="layer2_gpu15_q_proj\nQ Projection\nGPU: 15\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu15_k_proj [label="layer2_gpu15_k_proj\nK Projection\nGPU: 15\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu15_v_proj [label="layer2_gpu15_v_proj\nV Projection\nGPU: 15\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu15_mha [label="layer2_gpu15_mha\nMulti-Head Attention\nGPU: 15\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer2_gpu15_o_proj [label="layer2_gpu15_o_proj\nOutput Projection\nGPU: 15\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer2_gpu15_attn_residual [label="layer2_gpu15_attn_residual\nResidual Add\nGPU: 15\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu15_attn_input_reshape -> layer2_gpu15_q_proj [label="" style=solid]
	layer2_gpu15_attn_input_reshape -> layer2_gpu15_k_proj [label="" style=solid]
	layer2_gpu15_attn_input_reshape -> layer2_gpu15_v_proj [label="" style=solid]
	layer2_gpu15_q_proj -> layer2_gpu15_mha [label="" style=solid]
	layer2_gpu15_k_proj -> layer2_gpu15_mha [label="" style=solid]
	layer2_gpu15_v_proj -> layer2_gpu15_mha [label="" style=solid]
	layer2_gpu15_mha -> layer2_gpu15_o_proj [label="" style=solid]
	layer2_gpu15_o_proj -> layer2_gpu15_attn_residual [label="" style=solid]
	layer2_gpu15_attn_input_reshape -> layer2_gpu15_attn_residual [label="" style=dashed]
	layer2_input_broadcast -> layer2_gpu15_attn_input_reshape [label="" style=solid]
	layer2_attn_output_broadcast_gpu0 [label="layer2_attn_output_broadcast_gpu0\nAttention Output Broadcast\nGPU: 0\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu0_attn_residual -> layer2_attn_output_broadcast_gpu0 [label="" style=solid]
	layer2_attn_output_broadcast_gpu1 [label="layer2_attn_output_broadcast_gpu1\nAttention Output Broadcast\nGPU: 1\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu1_attn_residual -> layer2_attn_output_broadcast_gpu1 [label="" style=solid]
	layer2_attn_output_broadcast_gpu2 [label="layer2_attn_output_broadcast_gpu2\nAttention Output Broadcast\nGPU: 2\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu2_attn_residual -> layer2_attn_output_broadcast_gpu2 [label="" style=solid]
	layer2_attn_output_broadcast_gpu3 [label="layer2_attn_output_broadcast_gpu3\nAttention Output Broadcast\nGPU: 3\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu3_attn_residual -> layer2_attn_output_broadcast_gpu3 [label="" style=solid]
	layer2_attn_output_broadcast_gpu4 [label="layer2_attn_output_broadcast_gpu4\nAttention Output Broadcast\nGPU: 4\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu4_attn_residual -> layer2_attn_output_broadcast_gpu4 [label="" style=solid]
	layer2_attn_output_broadcast_gpu5 [label="layer2_attn_output_broadcast_gpu5\nAttention Output Broadcast\nGPU: 5\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu5_attn_residual -> layer2_attn_output_broadcast_gpu5 [label="" style=solid]
	layer2_attn_output_broadcast_gpu6 [label="layer2_attn_output_broadcast_gpu6\nAttention Output Broadcast\nGPU: 6\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu6_attn_residual -> layer2_attn_output_broadcast_gpu6 [label="" style=solid]
	layer2_attn_output_broadcast_gpu7 [label="layer2_attn_output_broadcast_gpu7\nAttention Output Broadcast\nGPU: 7\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu7_attn_residual -> layer2_attn_output_broadcast_gpu7 [label="" style=solid]
	layer2_attn_output_broadcast_gpu8 [label="layer2_attn_output_broadcast_gpu8\nAttention Output Broadcast\nGPU: 8\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu8_attn_residual -> layer2_attn_output_broadcast_gpu8 [label="" style=solid]
	layer2_attn_output_broadcast_gpu9 [label="layer2_attn_output_broadcast_gpu9\nAttention Output Broadcast\nGPU: 9\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu9_attn_residual -> layer2_attn_output_broadcast_gpu9 [label="" style=solid]
	layer2_attn_output_broadcast_gpu10 [label="layer2_attn_output_broadcast_gpu10\nAttention Output Broadcast\nGPU: 10\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu10_attn_residual -> layer2_attn_output_broadcast_gpu10 [label="" style=solid]
	layer2_attn_output_broadcast_gpu11 [label="layer2_attn_output_broadcast_gpu11\nAttention Output Broadcast\nGPU: 11\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu11_attn_residual -> layer2_attn_output_broadcast_gpu11 [label="" style=solid]
	layer2_attn_output_broadcast_gpu12 [label="layer2_attn_output_broadcast_gpu12\nAttention Output Broadcast\nGPU: 12\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu12_attn_residual -> layer2_attn_output_broadcast_gpu12 [label="" style=solid]
	layer2_attn_output_broadcast_gpu13 [label="layer2_attn_output_broadcast_gpu13\nAttention Output Broadcast\nGPU: 13\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu13_attn_residual -> layer2_attn_output_broadcast_gpu13 [label="" style=solid]
	layer2_attn_output_broadcast_gpu14 [label="layer2_attn_output_broadcast_gpu14\nAttention Output Broadcast\nGPU: 14\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu14_attn_residual -> layer2_attn_output_broadcast_gpu14 [label="" style=solid]
	layer2_attn_output_broadcast_gpu15 [label="layer2_attn_output_broadcast_gpu15\nAttention Output Broadcast\nGPU: 15\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_gpu15_attn_residual -> layer2_attn_output_broadcast_gpu15 [label="" style=solid]
	layer2_gating_network [label="layer2_gating_network\nGating Network\nGPU: 0-15\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, num_experts=16" color=black shape=parallelogram]
	layer2_gating_selection [label="layer2_gating_selection\nExpert Selection\nGPU: 0-15\nIn: batch_size=10240000, num_experts=16\nOut: batch_size=10240000, selected_experts=2" color=black shape=parallelogram]
	layer2_gating_network -> layer2_gating_selection [label="" style=solid]
	layer2_routing_route_to_expert0 [label="layer2_routing_route_to_expert0\nRoute to Expert 0\nGPU: 0\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer2_gating_selection -> layer2_routing_route_to_expert0 [label="" style=dashed]
	layer2_routing_route_to_expert1 [label="layer2_routing_route_to_expert1\nRoute to Expert 1\nGPU: 1\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer2_gating_selection -> layer2_routing_route_to_expert1 [label="" style=dashed]
	layer2_routing_route_to_expert2 [label="layer2_routing_route_to_expert2\nRoute to Expert 2\nGPU: 2\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer2_gating_selection -> layer2_routing_route_to_expert2 [label="" style=dashed]
	layer2_routing_route_to_expert3 [label="layer2_routing_route_to_expert3\nRoute to Expert 3\nGPU: 3\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer2_gating_selection -> layer2_routing_route_to_expert3 [label="" style=dashed]
	layer2_routing_route_to_expert4 [label="layer2_routing_route_to_expert4\nRoute to Expert 4\nGPU: 4\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer2_gating_selection -> layer2_routing_route_to_expert4 [label="" style=dashed]
	layer2_routing_route_to_expert5 [label="layer2_routing_route_to_expert5\nRoute to Expert 5\nGPU: 5\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer2_gating_selection -> layer2_routing_route_to_expert5 [label="" style=dashed]
	layer2_routing_route_to_expert6 [label="layer2_routing_route_to_expert6\nRoute to Expert 6\nGPU: 6\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer2_gating_selection -> layer2_routing_route_to_expert6 [label="" style=dashed]
	layer2_routing_route_to_expert7 [label="layer2_routing_route_to_expert7\nRoute to Expert 7\nGPU: 7\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer2_gating_selection -> layer2_routing_route_to_expert7 [label="" style=dashed]
	layer2_routing_route_to_expert8 [label="layer2_routing_route_to_expert8\nRoute to Expert 8\nGPU: 8\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer2_gating_selection -> layer2_routing_route_to_expert8 [label="" style=dashed]
	layer2_routing_route_to_expert9 [label="layer2_routing_route_to_expert9\nRoute to Expert 9\nGPU: 9\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer2_gating_selection -> layer2_routing_route_to_expert9 [label="" style=dashed]
	layer2_routing_route_to_expert10 [label="layer2_routing_route_to_expert10\nRoute to Expert 10\nGPU: 10\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer2_gating_selection -> layer2_routing_route_to_expert10 [label="" style=dashed]
	layer2_routing_route_to_expert11 [label="layer2_routing_route_to_expert11\nRoute to Expert 11\nGPU: 11\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer2_gating_selection -> layer2_routing_route_to_expert11 [label="" style=dashed]
	layer2_routing_route_to_expert12 [label="layer2_routing_route_to_expert12\nRoute to Expert 12\nGPU: 12\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer2_gating_selection -> layer2_routing_route_to_expert12 [label="" style=dashed]
	layer2_routing_route_to_expert13 [label="layer2_routing_route_to_expert13\nRoute to Expert 13\nGPU: 13\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer2_gating_selection -> layer2_routing_route_to_expert13 [label="" style=dashed]
	layer2_routing_route_to_expert14 [label="layer2_routing_route_to_expert14\nRoute to Expert 14\nGPU: 14\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer2_gating_selection -> layer2_routing_route_to_expert14 [label="" style=dashed]
	layer2_routing_route_to_expert15 [label="layer2_routing_route_to_expert15\nRoute to Expert 15\nGPU: 15\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer2_gating_selection -> layer2_routing_route_to_expert15 [label="" style=dashed]
	layer2_expert0_gpu0_gate_proj [label="layer2_expert0_gpu0_gate_proj\nGate Projection\nGPU: 0\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer2_expert0_gpu0_up_proj [label="layer2_expert0_gpu0_up_proj\nUp Projection\nGPU: 0\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer2_expert0_gpu0_activation [label="layer2_expert0_gpu0_activation\nGELU Activation\nGPU: 0\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer2_expert0_gpu0_down_proj [label="layer2_expert0_gpu0_down_proj\nDown Projection\nGPU: 0\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer2_expert0_gpu0_gate_proj -> layer2_expert0_gpu0_activation [label="" style=solid]
	layer2_expert0_gpu0_up_proj -> layer2_expert0_gpu0_down_proj [label="" style=solid]
	layer2_expert0_gpu0_activation -> layer2_expert0_gpu0_down_proj [label="" style=solid]
	layer2_routing_route_to_expert0 -> layer2_expert0_gpu0_gate_proj [label="" style=solid]
	layer2_routing_route_to_expert0 -> layer2_expert0_gpu0_up_proj [label="" style=solid]
	layer2_expert1_gpu1_gate_proj [label="layer2_expert1_gpu1_gate_proj\nGate Projection\nGPU: 1\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer2_expert1_gpu1_up_proj [label="layer2_expert1_gpu1_up_proj\nUp Projection\nGPU: 1\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer2_expert1_gpu1_activation [label="layer2_expert1_gpu1_activation\nGELU Activation\nGPU: 1\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer2_expert1_gpu1_down_proj [label="layer2_expert1_gpu1_down_proj\nDown Projection\nGPU: 1\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer2_expert1_gpu1_gate_proj -> layer2_expert1_gpu1_activation [label="" style=solid]
	layer2_expert1_gpu1_up_proj -> layer2_expert1_gpu1_down_proj [label="" style=solid]
	layer2_expert1_gpu1_activation -> layer2_expert1_gpu1_down_proj [label="" style=solid]
	layer2_routing_route_to_expert1 -> layer2_expert1_gpu1_gate_proj [label="" style=solid]
	layer2_routing_route_to_expert1 -> layer2_expert1_gpu1_up_proj [label="" style=solid]
	layer2_expert2_gpu2_gate_proj [label="layer2_expert2_gpu2_gate_proj\nGate Projection\nGPU: 2\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer2_expert2_gpu2_up_proj [label="layer2_expert2_gpu2_up_proj\nUp Projection\nGPU: 2\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer2_expert2_gpu2_activation [label="layer2_expert2_gpu2_activation\nGELU Activation\nGPU: 2\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer2_expert2_gpu2_down_proj [label="layer2_expert2_gpu2_down_proj\nDown Projection\nGPU: 2\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer2_expert2_gpu2_gate_proj -> layer2_expert2_gpu2_activation [label="" style=solid]
	layer2_expert2_gpu2_up_proj -> layer2_expert2_gpu2_down_proj [label="" style=solid]
	layer2_expert2_gpu2_activation -> layer2_expert2_gpu2_down_proj [label="" style=solid]
	layer2_routing_route_to_expert2 -> layer2_expert2_gpu2_gate_proj [label="" style=solid]
	layer2_routing_route_to_expert2 -> layer2_expert2_gpu2_up_proj [label="" style=solid]
	layer2_expert3_gpu3_gate_proj [label="layer2_expert3_gpu3_gate_proj\nGate Projection\nGPU: 3\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer2_expert3_gpu3_up_proj [label="layer2_expert3_gpu3_up_proj\nUp Projection\nGPU: 3\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer2_expert3_gpu3_activation [label="layer2_expert3_gpu3_activation\nGELU Activation\nGPU: 3\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer2_expert3_gpu3_down_proj [label="layer2_expert3_gpu3_down_proj\nDown Projection\nGPU: 3\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer2_expert3_gpu3_gate_proj -> layer2_expert3_gpu3_activation [label="" style=solid]
	layer2_expert3_gpu3_up_proj -> layer2_expert3_gpu3_down_proj [label="" style=solid]
	layer2_expert3_gpu3_activation -> layer2_expert3_gpu3_down_proj [label="" style=solid]
	layer2_routing_route_to_expert3 -> layer2_expert3_gpu3_gate_proj [label="" style=solid]
	layer2_routing_route_to_expert3 -> layer2_expert3_gpu3_up_proj [label="" style=solid]
	layer2_expert4_gpu4_gate_proj [label="layer2_expert4_gpu4_gate_proj\nGate Projection\nGPU: 4\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer2_expert4_gpu4_up_proj [label="layer2_expert4_gpu4_up_proj\nUp Projection\nGPU: 4\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer2_expert4_gpu4_activation [label="layer2_expert4_gpu4_activation\nGELU Activation\nGPU: 4\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer2_expert4_gpu4_down_proj [label="layer2_expert4_gpu4_down_proj\nDown Projection\nGPU: 4\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer2_expert4_gpu4_gate_proj -> layer2_expert4_gpu4_activation [label="" style=solid]
	layer2_expert4_gpu4_up_proj -> layer2_expert4_gpu4_down_proj [label="" style=solid]
	layer2_expert4_gpu4_activation -> layer2_expert4_gpu4_down_proj [label="" style=solid]
	layer2_routing_route_to_expert4 -> layer2_expert4_gpu4_gate_proj [label="" style=solid]
	layer2_routing_route_to_expert4 -> layer2_expert4_gpu4_up_proj [label="" style=solid]
	layer2_expert5_gpu5_gate_proj [label="layer2_expert5_gpu5_gate_proj\nGate Projection\nGPU: 5\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer2_expert5_gpu5_up_proj [label="layer2_expert5_gpu5_up_proj\nUp Projection\nGPU: 5\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer2_expert5_gpu5_activation [label="layer2_expert5_gpu5_activation\nGELU Activation\nGPU: 5\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer2_expert5_gpu5_down_proj [label="layer2_expert5_gpu5_down_proj\nDown Projection\nGPU: 5\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer2_expert5_gpu5_gate_proj -> layer2_expert5_gpu5_activation [label="" style=solid]
	layer2_expert5_gpu5_up_proj -> layer2_expert5_gpu5_down_proj [label="" style=solid]
	layer2_expert5_gpu5_activation -> layer2_expert5_gpu5_down_proj [label="" style=solid]
	layer2_routing_route_to_expert5 -> layer2_expert5_gpu5_gate_proj [label="" style=solid]
	layer2_routing_route_to_expert5 -> layer2_expert5_gpu5_up_proj [label="" style=solid]
	layer2_expert6_gpu6_gate_proj [label="layer2_expert6_gpu6_gate_proj\nGate Projection\nGPU: 6\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer2_expert6_gpu6_up_proj [label="layer2_expert6_gpu6_up_proj\nUp Projection\nGPU: 6\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer2_expert6_gpu6_activation [label="layer2_expert6_gpu6_activation\nGELU Activation\nGPU: 6\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer2_expert6_gpu6_down_proj [label="layer2_expert6_gpu6_down_proj\nDown Projection\nGPU: 6\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer2_expert6_gpu6_gate_proj -> layer2_expert6_gpu6_activation [label="" style=solid]
	layer2_expert6_gpu6_up_proj -> layer2_expert6_gpu6_down_proj [label="" style=solid]
	layer2_expert6_gpu6_activation -> layer2_expert6_gpu6_down_proj [label="" style=solid]
	layer2_routing_route_to_expert6 -> layer2_expert6_gpu6_gate_proj [label="" style=solid]
	layer2_routing_route_to_expert6 -> layer2_expert6_gpu6_up_proj [label="" style=solid]
	layer2_expert7_gpu7_gate_proj [label="layer2_expert7_gpu7_gate_proj\nGate Projection\nGPU: 7\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer2_expert7_gpu7_up_proj [label="layer2_expert7_gpu7_up_proj\nUp Projection\nGPU: 7\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer2_expert7_gpu7_activation [label="layer2_expert7_gpu7_activation\nGELU Activation\nGPU: 7\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer2_expert7_gpu7_down_proj [label="layer2_expert7_gpu7_down_proj\nDown Projection\nGPU: 7\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer2_expert7_gpu7_gate_proj -> layer2_expert7_gpu7_activation [label="" style=solid]
	layer2_expert7_gpu7_up_proj -> layer2_expert7_gpu7_down_proj [label="" style=solid]
	layer2_expert7_gpu7_activation -> layer2_expert7_gpu7_down_proj [label="" style=solid]
	layer2_routing_route_to_expert7 -> layer2_expert7_gpu7_gate_proj [label="" style=solid]
	layer2_routing_route_to_expert7 -> layer2_expert7_gpu7_up_proj [label="" style=solid]
	layer2_expert8_gpu8_gate_proj [label="layer2_expert8_gpu8_gate_proj\nGate Projection\nGPU: 8\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer2_expert8_gpu8_up_proj [label="layer2_expert8_gpu8_up_proj\nUp Projection\nGPU: 8\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer2_expert8_gpu8_activation [label="layer2_expert8_gpu8_activation\nGELU Activation\nGPU: 8\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer2_expert8_gpu8_down_proj [label="layer2_expert8_gpu8_down_proj\nDown Projection\nGPU: 8\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer2_expert8_gpu8_gate_proj -> layer2_expert8_gpu8_activation [label="" style=solid]
	layer2_expert8_gpu8_up_proj -> layer2_expert8_gpu8_down_proj [label="" style=solid]
	layer2_expert8_gpu8_activation -> layer2_expert8_gpu8_down_proj [label="" style=solid]
	layer2_routing_route_to_expert8 -> layer2_expert8_gpu8_gate_proj [label="" style=solid]
	layer2_routing_route_to_expert8 -> layer2_expert8_gpu8_up_proj [label="" style=solid]
	layer2_expert9_gpu9_gate_proj [label="layer2_expert9_gpu9_gate_proj\nGate Projection\nGPU: 9\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer2_expert9_gpu9_up_proj [label="layer2_expert9_gpu9_up_proj\nUp Projection\nGPU: 9\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer2_expert9_gpu9_activation [label="layer2_expert9_gpu9_activation\nGELU Activation\nGPU: 9\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer2_expert9_gpu9_down_proj [label="layer2_expert9_gpu9_down_proj\nDown Projection\nGPU: 9\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer2_expert9_gpu9_gate_proj -> layer2_expert9_gpu9_activation [label="" style=solid]
	layer2_expert9_gpu9_up_proj -> layer2_expert9_gpu9_down_proj [label="" style=solid]
	layer2_expert9_gpu9_activation -> layer2_expert9_gpu9_down_proj [label="" style=solid]
	layer2_routing_route_to_expert9 -> layer2_expert9_gpu9_gate_proj [label="" style=solid]
	layer2_routing_route_to_expert9 -> layer2_expert9_gpu9_up_proj [label="" style=solid]
	layer2_expert10_gpu10_gate_proj [label="layer2_expert10_gpu10_gate_proj\nGate Projection\nGPU: 10\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer2_expert10_gpu10_up_proj [label="layer2_expert10_gpu10_up_proj\nUp Projection\nGPU: 10\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer2_expert10_gpu10_activation [label="layer2_expert10_gpu10_activation\nGELU Activation\nGPU: 10\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer2_expert10_gpu10_down_proj [label="layer2_expert10_gpu10_down_proj\nDown Projection\nGPU: 10\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer2_expert10_gpu10_gate_proj -> layer2_expert10_gpu10_activation [label="" style=solid]
	layer2_expert10_gpu10_up_proj -> layer2_expert10_gpu10_down_proj [label="" style=solid]
	layer2_expert10_gpu10_activation -> layer2_expert10_gpu10_down_proj [label="" style=solid]
	layer2_routing_route_to_expert10 -> layer2_expert10_gpu10_gate_proj [label="" style=solid]
	layer2_routing_route_to_expert10 -> layer2_expert10_gpu10_up_proj [label="" style=solid]
	layer2_expert11_gpu11_gate_proj [label="layer2_expert11_gpu11_gate_proj\nGate Projection\nGPU: 11\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer2_expert11_gpu11_up_proj [label="layer2_expert11_gpu11_up_proj\nUp Projection\nGPU: 11\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer2_expert11_gpu11_activation [label="layer2_expert11_gpu11_activation\nGELU Activation\nGPU: 11\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer2_expert11_gpu11_down_proj [label="layer2_expert11_gpu11_down_proj\nDown Projection\nGPU: 11\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer2_expert11_gpu11_gate_proj -> layer2_expert11_gpu11_activation [label="" style=solid]
	layer2_expert11_gpu11_up_proj -> layer2_expert11_gpu11_down_proj [label="" style=solid]
	layer2_expert11_gpu11_activation -> layer2_expert11_gpu11_down_proj [label="" style=solid]
	layer2_routing_route_to_expert11 -> layer2_expert11_gpu11_gate_proj [label="" style=solid]
	layer2_routing_route_to_expert11 -> layer2_expert11_gpu11_up_proj [label="" style=solid]
	layer2_expert12_gpu12_gate_proj [label="layer2_expert12_gpu12_gate_proj\nGate Projection\nGPU: 12\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer2_expert12_gpu12_up_proj [label="layer2_expert12_gpu12_up_proj\nUp Projection\nGPU: 12\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer2_expert12_gpu12_activation [label="layer2_expert12_gpu12_activation\nGELU Activation\nGPU: 12\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer2_expert12_gpu12_down_proj [label="layer2_expert12_gpu12_down_proj\nDown Projection\nGPU: 12\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer2_expert12_gpu12_gate_proj -> layer2_expert12_gpu12_activation [label="" style=solid]
	layer2_expert12_gpu12_up_proj -> layer2_expert12_gpu12_down_proj [label="" style=solid]
	layer2_expert12_gpu12_activation -> layer2_expert12_gpu12_down_proj [label="" style=solid]
	layer2_routing_route_to_expert12 -> layer2_expert12_gpu12_gate_proj [label="" style=solid]
	layer2_routing_route_to_expert12 -> layer2_expert12_gpu12_up_proj [label="" style=solid]
	layer2_expert13_gpu13_gate_proj [label="layer2_expert13_gpu13_gate_proj\nGate Projection\nGPU: 13\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer2_expert13_gpu13_up_proj [label="layer2_expert13_gpu13_up_proj\nUp Projection\nGPU: 13\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer2_expert13_gpu13_activation [label="layer2_expert13_gpu13_activation\nGELU Activation\nGPU: 13\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer2_expert13_gpu13_down_proj [label="layer2_expert13_gpu13_down_proj\nDown Projection\nGPU: 13\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer2_expert13_gpu13_gate_proj -> layer2_expert13_gpu13_activation [label="" style=solid]
	layer2_expert13_gpu13_up_proj -> layer2_expert13_gpu13_down_proj [label="" style=solid]
	layer2_expert13_gpu13_activation -> layer2_expert13_gpu13_down_proj [label="" style=solid]
	layer2_routing_route_to_expert13 -> layer2_expert13_gpu13_gate_proj [label="" style=solid]
	layer2_routing_route_to_expert13 -> layer2_expert13_gpu13_up_proj [label="" style=solid]
	layer2_expert14_gpu14_gate_proj [label="layer2_expert14_gpu14_gate_proj\nGate Projection\nGPU: 14\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer2_expert14_gpu14_up_proj [label="layer2_expert14_gpu14_up_proj\nUp Projection\nGPU: 14\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer2_expert14_gpu14_activation [label="layer2_expert14_gpu14_activation\nGELU Activation\nGPU: 14\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer2_expert14_gpu14_down_proj [label="layer2_expert14_gpu14_down_proj\nDown Projection\nGPU: 14\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer2_expert14_gpu14_gate_proj -> layer2_expert14_gpu14_activation [label="" style=solid]
	layer2_expert14_gpu14_up_proj -> layer2_expert14_gpu14_down_proj [label="" style=solid]
	layer2_expert14_gpu14_activation -> layer2_expert14_gpu14_down_proj [label="" style=solid]
	layer2_routing_route_to_expert14 -> layer2_expert14_gpu14_gate_proj [label="" style=solid]
	layer2_routing_route_to_expert14 -> layer2_expert14_gpu14_up_proj [label="" style=solid]
	layer2_expert15_gpu15_gate_proj [label="layer2_expert15_gpu15_gate_proj\nGate Projection\nGPU: 15\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer2_expert15_gpu15_up_proj [label="layer2_expert15_gpu15_up_proj\nUp Projection\nGPU: 15\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer2_expert15_gpu15_activation [label="layer2_expert15_gpu15_activation\nGELU Activation\nGPU: 15\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer2_expert15_gpu15_down_proj [label="layer2_expert15_gpu15_down_proj\nDown Projection\nGPU: 15\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer2_expert15_gpu15_gate_proj -> layer2_expert15_gpu15_activation [label="" style=solid]
	layer2_expert15_gpu15_up_proj -> layer2_expert15_gpu15_down_proj [label="" style=solid]
	layer2_expert15_gpu15_activation -> layer2_expert15_gpu15_down_proj [label="" style=solid]
	layer2_routing_route_to_expert15 -> layer2_expert15_gpu15_gate_proj [label="" style=solid]
	layer2_routing_route_to_expert15 -> layer2_expert15_gpu15_up_proj [label="" style=solid]
	layer2_routing_aggregate [label="layer2_routing_aggregate\nAggregate Expert Outputs\nGPU: 0-15\nIn: batch_size=640000, hidden_dim=8192 (x16)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=parallelogram]
	layer2_expert0_gpu0_down_proj -> layer2_routing_aggregate [label="" style=solid]
	layer2_expert1_gpu1_down_proj -> layer2_routing_aggregate [label="" style=solid]
	layer2_expert2_gpu2_down_proj -> layer2_routing_aggregate [label="" style=solid]
	layer2_expert3_gpu3_down_proj -> layer2_routing_aggregate [label="" style=solid]
	layer2_expert4_gpu4_down_proj -> layer2_routing_aggregate [label="" style=solid]
	layer2_expert5_gpu5_down_proj -> layer2_routing_aggregate [label="" style=solid]
	layer2_expert6_gpu6_down_proj -> layer2_routing_aggregate [label="" style=solid]
	layer2_expert7_gpu7_down_proj -> layer2_routing_aggregate [label="" style=solid]
	layer2_expert8_gpu8_down_proj -> layer2_routing_aggregate [label="" style=solid]
	layer2_expert9_gpu9_down_proj -> layer2_routing_aggregate [label="" style=solid]
	layer2_expert10_gpu10_down_proj -> layer2_routing_aggregate [label="" style=solid]
	layer2_expert11_gpu11_down_proj -> layer2_routing_aggregate [label="" style=solid]
	layer2_expert12_gpu12_down_proj -> layer2_routing_aggregate [label="" style=solid]
	layer2_expert13_gpu13_down_proj -> layer2_routing_aggregate [label="" style=solid]
	layer2_expert14_gpu14_down_proj -> layer2_routing_aggregate [label="" style=solid]
	layer2_expert15_gpu15_down_proj -> layer2_routing_aggregate [label="" style=solid]
	layer2_routing_weighted_sum [label="layer2_routing_weighted_sum\nWeighted Sum\nGPU: 0-15\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_routing_aggregate -> layer2_routing_weighted_sum [label="" style=solid]
	layer2_gating_selection -> layer2_routing_weighted_sum [label="" style=dashed]
	layer2_attn_output_broadcast_gpu0 -> layer2_gating_network [label="" style=solid]
	layer2_attn_output_broadcast_gpu1 -> layer2_gating_network [label="" style=solid]
	layer2_attn_output_broadcast_gpu2 -> layer2_gating_network [label="" style=solid]
	layer2_attn_output_broadcast_gpu3 -> layer2_gating_network [label="" style=solid]
	layer2_attn_output_broadcast_gpu4 -> layer2_gating_network [label="" style=solid]
	layer2_attn_output_broadcast_gpu5 -> layer2_gating_network [label="" style=solid]
	layer2_attn_output_broadcast_gpu6 -> layer2_gating_network [label="" style=solid]
	layer2_attn_output_broadcast_gpu7 -> layer2_gating_network [label="" style=solid]
	layer2_attn_output_broadcast_gpu8 -> layer2_gating_network [label="" style=solid]
	layer2_attn_output_broadcast_gpu9 -> layer2_gating_network [label="" style=solid]
	layer2_attn_output_broadcast_gpu10 -> layer2_gating_network [label="" style=solid]
	layer2_attn_output_broadcast_gpu11 -> layer2_gating_network [label="" style=solid]
	layer2_attn_output_broadcast_gpu12 -> layer2_gating_network [label="" style=solid]
	layer2_attn_output_broadcast_gpu13 -> layer2_gating_network [label="" style=solid]
	layer2_attn_output_broadcast_gpu14 -> layer2_gating_network [label="" style=solid]
	layer2_attn_output_broadcast_gpu15 -> layer2_gating_network [label="" style=solid]
	layer2_output [label="layer2_output\nLayer Output\nGPU: 0-15\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer2_attn_output_broadcast_gpu0 -> layer2_output [label="" style=dashed]
	layer2_attn_output_broadcast_gpu1 -> layer2_output [label="" style=dashed]
	layer2_attn_output_broadcast_gpu2 -> layer2_output [label="" style=dashed]
	layer2_attn_output_broadcast_gpu3 -> layer2_output [label="" style=dashed]
	layer2_attn_output_broadcast_gpu4 -> layer2_output [label="" style=dashed]
	layer2_attn_output_broadcast_gpu5 -> layer2_output [label="" style=dashed]
	layer2_attn_output_broadcast_gpu6 -> layer2_output [label="" style=dashed]
	layer2_attn_output_broadcast_gpu7 -> layer2_output [label="" style=dashed]
	layer2_attn_output_broadcast_gpu8 -> layer2_output [label="" style=dashed]
	layer2_attn_output_broadcast_gpu9 -> layer2_output [label="" style=dashed]
	layer2_attn_output_broadcast_gpu10 -> layer2_output [label="" style=dashed]
	layer2_attn_output_broadcast_gpu11 -> layer2_output [label="" style=dashed]
	layer2_attn_output_broadcast_gpu12 -> layer2_output [label="" style=dashed]
	layer2_attn_output_broadcast_gpu13 -> layer2_output [label="" style=dashed]
	layer2_attn_output_broadcast_gpu14 -> layer2_output [label="" style=dashed]
	layer2_attn_output_broadcast_gpu15 -> layer2_output [label="" style=dashed]
	layer2_routing_weighted_sum -> layer2_output [label="" style=solid]
	layer1_output -> layer2_input_broadcast [label="" style=solid]
	layer3_input_broadcast [label="layer3_input_broadcast\nLayer Input Broadcast\nGPU: 0-15\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=1024, seq_len=10000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu0_attn_input_reshape [label="layer3_gpu0_attn_input_reshape\nInput Reshape\nGPU: 0\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu0_q_proj [label="layer3_gpu0_q_proj\nQ Projection\nGPU: 0\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu0_k_proj [label="layer3_gpu0_k_proj\nK Projection\nGPU: 0\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu0_v_proj [label="layer3_gpu0_v_proj\nV Projection\nGPU: 0\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu0_mha [label="layer3_gpu0_mha\nMulti-Head Attention\nGPU: 0\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu0_o_proj [label="layer3_gpu0_o_proj\nOutput Projection\nGPU: 0\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer3_gpu0_attn_residual [label="layer3_gpu0_attn_residual\nResidual Add\nGPU: 0\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu0_attn_input_reshape -> layer3_gpu0_q_proj [label="" style=solid]
	layer3_gpu0_attn_input_reshape -> layer3_gpu0_k_proj [label="" style=solid]
	layer3_gpu0_attn_input_reshape -> layer3_gpu0_v_proj [label="" style=solid]
	layer3_gpu0_q_proj -> layer3_gpu0_mha [label="" style=solid]
	layer3_gpu0_k_proj -> layer3_gpu0_mha [label="" style=solid]
	layer3_gpu0_v_proj -> layer3_gpu0_mha [label="" style=solid]
	layer3_gpu0_mha -> layer3_gpu0_o_proj [label="" style=solid]
	layer3_gpu0_o_proj -> layer3_gpu0_attn_residual [label="" style=solid]
	layer3_gpu0_attn_input_reshape -> layer3_gpu0_attn_residual [label="" style=dashed]
	layer3_input_broadcast -> layer3_gpu0_attn_input_reshape [label="" style=solid]
	layer3_gpu1_attn_input_reshape [label="layer3_gpu1_attn_input_reshape\nInput Reshape\nGPU: 1\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu1_q_proj [label="layer3_gpu1_q_proj\nQ Projection\nGPU: 1\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu1_k_proj [label="layer3_gpu1_k_proj\nK Projection\nGPU: 1\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu1_v_proj [label="layer3_gpu1_v_proj\nV Projection\nGPU: 1\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu1_mha [label="layer3_gpu1_mha\nMulti-Head Attention\nGPU: 1\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu1_o_proj [label="layer3_gpu1_o_proj\nOutput Projection\nGPU: 1\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer3_gpu1_attn_residual [label="layer3_gpu1_attn_residual\nResidual Add\nGPU: 1\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu1_attn_input_reshape -> layer3_gpu1_q_proj [label="" style=solid]
	layer3_gpu1_attn_input_reshape -> layer3_gpu1_k_proj [label="" style=solid]
	layer3_gpu1_attn_input_reshape -> layer3_gpu1_v_proj [label="" style=solid]
	layer3_gpu1_q_proj -> layer3_gpu1_mha [label="" style=solid]
	layer3_gpu1_k_proj -> layer3_gpu1_mha [label="" style=solid]
	layer3_gpu1_v_proj -> layer3_gpu1_mha [label="" style=solid]
	layer3_gpu1_mha -> layer3_gpu1_o_proj [label="" style=solid]
	layer3_gpu1_o_proj -> layer3_gpu1_attn_residual [label="" style=solid]
	layer3_gpu1_attn_input_reshape -> layer3_gpu1_attn_residual [label="" style=dashed]
	layer3_input_broadcast -> layer3_gpu1_attn_input_reshape [label="" style=solid]
	layer3_gpu2_attn_input_reshape [label="layer3_gpu2_attn_input_reshape\nInput Reshape\nGPU: 2\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu2_q_proj [label="layer3_gpu2_q_proj\nQ Projection\nGPU: 2\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu2_k_proj [label="layer3_gpu2_k_proj\nK Projection\nGPU: 2\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu2_v_proj [label="layer3_gpu2_v_proj\nV Projection\nGPU: 2\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu2_mha [label="layer3_gpu2_mha\nMulti-Head Attention\nGPU: 2\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu2_o_proj [label="layer3_gpu2_o_proj\nOutput Projection\nGPU: 2\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer3_gpu2_attn_residual [label="layer3_gpu2_attn_residual\nResidual Add\nGPU: 2\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu2_attn_input_reshape -> layer3_gpu2_q_proj [label="" style=solid]
	layer3_gpu2_attn_input_reshape -> layer3_gpu2_k_proj [label="" style=solid]
	layer3_gpu2_attn_input_reshape -> layer3_gpu2_v_proj [label="" style=solid]
	layer3_gpu2_q_proj -> layer3_gpu2_mha [label="" style=solid]
	layer3_gpu2_k_proj -> layer3_gpu2_mha [label="" style=solid]
	layer3_gpu2_v_proj -> layer3_gpu2_mha [label="" style=solid]
	layer3_gpu2_mha -> layer3_gpu2_o_proj [label="" style=solid]
	layer3_gpu2_o_proj -> layer3_gpu2_attn_residual [label="" style=solid]
	layer3_gpu2_attn_input_reshape -> layer3_gpu2_attn_residual [label="" style=dashed]
	layer3_input_broadcast -> layer3_gpu2_attn_input_reshape [label="" style=solid]
	layer3_gpu3_attn_input_reshape [label="layer3_gpu3_attn_input_reshape\nInput Reshape\nGPU: 3\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu3_q_proj [label="layer3_gpu3_q_proj\nQ Projection\nGPU: 3\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu3_k_proj [label="layer3_gpu3_k_proj\nK Projection\nGPU: 3\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu3_v_proj [label="layer3_gpu3_v_proj\nV Projection\nGPU: 3\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu3_mha [label="layer3_gpu3_mha\nMulti-Head Attention\nGPU: 3\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu3_o_proj [label="layer3_gpu3_o_proj\nOutput Projection\nGPU: 3\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer3_gpu3_attn_residual [label="layer3_gpu3_attn_residual\nResidual Add\nGPU: 3\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu3_attn_input_reshape -> layer3_gpu3_q_proj [label="" style=solid]
	layer3_gpu3_attn_input_reshape -> layer3_gpu3_k_proj [label="" style=solid]
	layer3_gpu3_attn_input_reshape -> layer3_gpu3_v_proj [label="" style=solid]
	layer3_gpu3_q_proj -> layer3_gpu3_mha [label="" style=solid]
	layer3_gpu3_k_proj -> layer3_gpu3_mha [label="" style=solid]
	layer3_gpu3_v_proj -> layer3_gpu3_mha [label="" style=solid]
	layer3_gpu3_mha -> layer3_gpu3_o_proj [label="" style=solid]
	layer3_gpu3_o_proj -> layer3_gpu3_attn_residual [label="" style=solid]
	layer3_gpu3_attn_input_reshape -> layer3_gpu3_attn_residual [label="" style=dashed]
	layer3_input_broadcast -> layer3_gpu3_attn_input_reshape [label="" style=solid]
	layer3_gpu4_attn_input_reshape [label="layer3_gpu4_attn_input_reshape\nInput Reshape\nGPU: 4\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu4_q_proj [label="layer3_gpu4_q_proj\nQ Projection\nGPU: 4\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu4_k_proj [label="layer3_gpu4_k_proj\nK Projection\nGPU: 4\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu4_v_proj [label="layer3_gpu4_v_proj\nV Projection\nGPU: 4\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu4_mha [label="layer3_gpu4_mha\nMulti-Head Attention\nGPU: 4\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu4_o_proj [label="layer3_gpu4_o_proj\nOutput Projection\nGPU: 4\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer3_gpu4_attn_residual [label="layer3_gpu4_attn_residual\nResidual Add\nGPU: 4\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu4_attn_input_reshape -> layer3_gpu4_q_proj [label="" style=solid]
	layer3_gpu4_attn_input_reshape -> layer3_gpu4_k_proj [label="" style=solid]
	layer3_gpu4_attn_input_reshape -> layer3_gpu4_v_proj [label="" style=solid]
	layer3_gpu4_q_proj -> layer3_gpu4_mha [label="" style=solid]
	layer3_gpu4_k_proj -> layer3_gpu4_mha [label="" style=solid]
	layer3_gpu4_v_proj -> layer3_gpu4_mha [label="" style=solid]
	layer3_gpu4_mha -> layer3_gpu4_o_proj [label="" style=solid]
	layer3_gpu4_o_proj -> layer3_gpu4_attn_residual [label="" style=solid]
	layer3_gpu4_attn_input_reshape -> layer3_gpu4_attn_residual [label="" style=dashed]
	layer3_input_broadcast -> layer3_gpu4_attn_input_reshape [label="" style=solid]
	layer3_gpu5_attn_input_reshape [label="layer3_gpu5_attn_input_reshape\nInput Reshape\nGPU: 5\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu5_q_proj [label="layer3_gpu5_q_proj\nQ Projection\nGPU: 5\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu5_k_proj [label="layer3_gpu5_k_proj\nK Projection\nGPU: 5\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu5_v_proj [label="layer3_gpu5_v_proj\nV Projection\nGPU: 5\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu5_mha [label="layer3_gpu5_mha\nMulti-Head Attention\nGPU: 5\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu5_o_proj [label="layer3_gpu5_o_proj\nOutput Projection\nGPU: 5\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer3_gpu5_attn_residual [label="layer3_gpu5_attn_residual\nResidual Add\nGPU: 5\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu5_attn_input_reshape -> layer3_gpu5_q_proj [label="" style=solid]
	layer3_gpu5_attn_input_reshape -> layer3_gpu5_k_proj [label="" style=solid]
	layer3_gpu5_attn_input_reshape -> layer3_gpu5_v_proj [label="" style=solid]
	layer3_gpu5_q_proj -> layer3_gpu5_mha [label="" style=solid]
	layer3_gpu5_k_proj -> layer3_gpu5_mha [label="" style=solid]
	layer3_gpu5_v_proj -> layer3_gpu5_mha [label="" style=solid]
	layer3_gpu5_mha -> layer3_gpu5_o_proj [label="" style=solid]
	layer3_gpu5_o_proj -> layer3_gpu5_attn_residual [label="" style=solid]
	layer3_gpu5_attn_input_reshape -> layer3_gpu5_attn_residual [label="" style=dashed]
	layer3_input_broadcast -> layer3_gpu5_attn_input_reshape [label="" style=solid]
	layer3_gpu6_attn_input_reshape [label="layer3_gpu6_attn_input_reshape\nInput Reshape\nGPU: 6\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu6_q_proj [label="layer3_gpu6_q_proj\nQ Projection\nGPU: 6\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu6_k_proj [label="layer3_gpu6_k_proj\nK Projection\nGPU: 6\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu6_v_proj [label="layer3_gpu6_v_proj\nV Projection\nGPU: 6\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu6_mha [label="layer3_gpu6_mha\nMulti-Head Attention\nGPU: 6\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu6_o_proj [label="layer3_gpu6_o_proj\nOutput Projection\nGPU: 6\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer3_gpu6_attn_residual [label="layer3_gpu6_attn_residual\nResidual Add\nGPU: 6\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu6_attn_input_reshape -> layer3_gpu6_q_proj [label="" style=solid]
	layer3_gpu6_attn_input_reshape -> layer3_gpu6_k_proj [label="" style=solid]
	layer3_gpu6_attn_input_reshape -> layer3_gpu6_v_proj [label="" style=solid]
	layer3_gpu6_q_proj -> layer3_gpu6_mha [label="" style=solid]
	layer3_gpu6_k_proj -> layer3_gpu6_mha [label="" style=solid]
	layer3_gpu6_v_proj -> layer3_gpu6_mha [label="" style=solid]
	layer3_gpu6_mha -> layer3_gpu6_o_proj [label="" style=solid]
	layer3_gpu6_o_proj -> layer3_gpu6_attn_residual [label="" style=solid]
	layer3_gpu6_attn_input_reshape -> layer3_gpu6_attn_residual [label="" style=dashed]
	layer3_input_broadcast -> layer3_gpu6_attn_input_reshape [label="" style=solid]
	layer3_gpu7_attn_input_reshape [label="layer3_gpu7_attn_input_reshape\nInput Reshape\nGPU: 7\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu7_q_proj [label="layer3_gpu7_q_proj\nQ Projection\nGPU: 7\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu7_k_proj [label="layer3_gpu7_k_proj\nK Projection\nGPU: 7\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu7_v_proj [label="layer3_gpu7_v_proj\nV Projection\nGPU: 7\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu7_mha [label="layer3_gpu7_mha\nMulti-Head Attention\nGPU: 7\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu7_o_proj [label="layer3_gpu7_o_proj\nOutput Projection\nGPU: 7\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer3_gpu7_attn_residual [label="layer3_gpu7_attn_residual\nResidual Add\nGPU: 7\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu7_attn_input_reshape -> layer3_gpu7_q_proj [label="" style=solid]
	layer3_gpu7_attn_input_reshape -> layer3_gpu7_k_proj [label="" style=solid]
	layer3_gpu7_attn_input_reshape -> layer3_gpu7_v_proj [label="" style=solid]
	layer3_gpu7_q_proj -> layer3_gpu7_mha [label="" style=solid]
	layer3_gpu7_k_proj -> layer3_gpu7_mha [label="" style=solid]
	layer3_gpu7_v_proj -> layer3_gpu7_mha [label="" style=solid]
	layer3_gpu7_mha -> layer3_gpu7_o_proj [label="" style=solid]
	layer3_gpu7_o_proj -> layer3_gpu7_attn_residual [label="" style=solid]
	layer3_gpu7_attn_input_reshape -> layer3_gpu7_attn_residual [label="" style=dashed]
	layer3_input_broadcast -> layer3_gpu7_attn_input_reshape [label="" style=solid]
	layer3_gpu8_attn_input_reshape [label="layer3_gpu8_attn_input_reshape\nInput Reshape\nGPU: 8\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu8_q_proj [label="layer3_gpu8_q_proj\nQ Projection\nGPU: 8\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu8_k_proj [label="layer3_gpu8_k_proj\nK Projection\nGPU: 8\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu8_v_proj [label="layer3_gpu8_v_proj\nV Projection\nGPU: 8\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu8_mha [label="layer3_gpu8_mha\nMulti-Head Attention\nGPU: 8\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu8_o_proj [label="layer3_gpu8_o_proj\nOutput Projection\nGPU: 8\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer3_gpu8_attn_residual [label="layer3_gpu8_attn_residual\nResidual Add\nGPU: 8\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu8_attn_input_reshape -> layer3_gpu8_q_proj [label="" style=solid]
	layer3_gpu8_attn_input_reshape -> layer3_gpu8_k_proj [label="" style=solid]
	layer3_gpu8_attn_input_reshape -> layer3_gpu8_v_proj [label="" style=solid]
	layer3_gpu8_q_proj -> layer3_gpu8_mha [label="" style=solid]
	layer3_gpu8_k_proj -> layer3_gpu8_mha [label="" style=solid]
	layer3_gpu8_v_proj -> layer3_gpu8_mha [label="" style=solid]
	layer3_gpu8_mha -> layer3_gpu8_o_proj [label="" style=solid]
	layer3_gpu8_o_proj -> layer3_gpu8_attn_residual [label="" style=solid]
	layer3_gpu8_attn_input_reshape -> layer3_gpu8_attn_residual [label="" style=dashed]
	layer3_input_broadcast -> layer3_gpu8_attn_input_reshape [label="" style=solid]
	layer3_gpu9_attn_input_reshape [label="layer3_gpu9_attn_input_reshape\nInput Reshape\nGPU: 9\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu9_q_proj [label="layer3_gpu9_q_proj\nQ Projection\nGPU: 9\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu9_k_proj [label="layer3_gpu9_k_proj\nK Projection\nGPU: 9\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu9_v_proj [label="layer3_gpu9_v_proj\nV Projection\nGPU: 9\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu9_mha [label="layer3_gpu9_mha\nMulti-Head Attention\nGPU: 9\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu9_o_proj [label="layer3_gpu9_o_proj\nOutput Projection\nGPU: 9\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer3_gpu9_attn_residual [label="layer3_gpu9_attn_residual\nResidual Add\nGPU: 9\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu9_attn_input_reshape -> layer3_gpu9_q_proj [label="" style=solid]
	layer3_gpu9_attn_input_reshape -> layer3_gpu9_k_proj [label="" style=solid]
	layer3_gpu9_attn_input_reshape -> layer3_gpu9_v_proj [label="" style=solid]
	layer3_gpu9_q_proj -> layer3_gpu9_mha [label="" style=solid]
	layer3_gpu9_k_proj -> layer3_gpu9_mha [label="" style=solid]
	layer3_gpu9_v_proj -> layer3_gpu9_mha [label="" style=solid]
	layer3_gpu9_mha -> layer3_gpu9_o_proj [label="" style=solid]
	layer3_gpu9_o_proj -> layer3_gpu9_attn_residual [label="" style=solid]
	layer3_gpu9_attn_input_reshape -> layer3_gpu9_attn_residual [label="" style=dashed]
	layer3_input_broadcast -> layer3_gpu9_attn_input_reshape [label="" style=solid]
	layer3_gpu10_attn_input_reshape [label="layer3_gpu10_attn_input_reshape\nInput Reshape\nGPU: 10\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu10_q_proj [label="layer3_gpu10_q_proj\nQ Projection\nGPU: 10\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu10_k_proj [label="layer3_gpu10_k_proj\nK Projection\nGPU: 10\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu10_v_proj [label="layer3_gpu10_v_proj\nV Projection\nGPU: 10\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu10_mha [label="layer3_gpu10_mha\nMulti-Head Attention\nGPU: 10\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu10_o_proj [label="layer3_gpu10_o_proj\nOutput Projection\nGPU: 10\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer3_gpu10_attn_residual [label="layer3_gpu10_attn_residual\nResidual Add\nGPU: 10\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu10_attn_input_reshape -> layer3_gpu10_q_proj [label="" style=solid]
	layer3_gpu10_attn_input_reshape -> layer3_gpu10_k_proj [label="" style=solid]
	layer3_gpu10_attn_input_reshape -> layer3_gpu10_v_proj [label="" style=solid]
	layer3_gpu10_q_proj -> layer3_gpu10_mha [label="" style=solid]
	layer3_gpu10_k_proj -> layer3_gpu10_mha [label="" style=solid]
	layer3_gpu10_v_proj -> layer3_gpu10_mha [label="" style=solid]
	layer3_gpu10_mha -> layer3_gpu10_o_proj [label="" style=solid]
	layer3_gpu10_o_proj -> layer3_gpu10_attn_residual [label="" style=solid]
	layer3_gpu10_attn_input_reshape -> layer3_gpu10_attn_residual [label="" style=dashed]
	layer3_input_broadcast -> layer3_gpu10_attn_input_reshape [label="" style=solid]
	layer3_gpu11_attn_input_reshape [label="layer3_gpu11_attn_input_reshape\nInput Reshape\nGPU: 11\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu11_q_proj [label="layer3_gpu11_q_proj\nQ Projection\nGPU: 11\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu11_k_proj [label="layer3_gpu11_k_proj\nK Projection\nGPU: 11\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu11_v_proj [label="layer3_gpu11_v_proj\nV Projection\nGPU: 11\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu11_mha [label="layer3_gpu11_mha\nMulti-Head Attention\nGPU: 11\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu11_o_proj [label="layer3_gpu11_o_proj\nOutput Projection\nGPU: 11\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer3_gpu11_attn_residual [label="layer3_gpu11_attn_residual\nResidual Add\nGPU: 11\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu11_attn_input_reshape -> layer3_gpu11_q_proj [label="" style=solid]
	layer3_gpu11_attn_input_reshape -> layer3_gpu11_k_proj [label="" style=solid]
	layer3_gpu11_attn_input_reshape -> layer3_gpu11_v_proj [label="" style=solid]
	layer3_gpu11_q_proj -> layer3_gpu11_mha [label="" style=solid]
	layer3_gpu11_k_proj -> layer3_gpu11_mha [label="" style=solid]
	layer3_gpu11_v_proj -> layer3_gpu11_mha [label="" style=solid]
	layer3_gpu11_mha -> layer3_gpu11_o_proj [label="" style=solid]
	layer3_gpu11_o_proj -> layer3_gpu11_attn_residual [label="" style=solid]
	layer3_gpu11_attn_input_reshape -> layer3_gpu11_attn_residual [label="" style=dashed]
	layer3_input_broadcast -> layer3_gpu11_attn_input_reshape [label="" style=solid]
	layer3_gpu12_attn_input_reshape [label="layer3_gpu12_attn_input_reshape\nInput Reshape\nGPU: 12\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu12_q_proj [label="layer3_gpu12_q_proj\nQ Projection\nGPU: 12\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu12_k_proj [label="layer3_gpu12_k_proj\nK Projection\nGPU: 12\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu12_v_proj [label="layer3_gpu12_v_proj\nV Projection\nGPU: 12\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu12_mha [label="layer3_gpu12_mha\nMulti-Head Attention\nGPU: 12\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu12_o_proj [label="layer3_gpu12_o_proj\nOutput Projection\nGPU: 12\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer3_gpu12_attn_residual [label="layer3_gpu12_attn_residual\nResidual Add\nGPU: 12\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu12_attn_input_reshape -> layer3_gpu12_q_proj [label="" style=solid]
	layer3_gpu12_attn_input_reshape -> layer3_gpu12_k_proj [label="" style=solid]
	layer3_gpu12_attn_input_reshape -> layer3_gpu12_v_proj [label="" style=solid]
	layer3_gpu12_q_proj -> layer3_gpu12_mha [label="" style=solid]
	layer3_gpu12_k_proj -> layer3_gpu12_mha [label="" style=solid]
	layer3_gpu12_v_proj -> layer3_gpu12_mha [label="" style=solid]
	layer3_gpu12_mha -> layer3_gpu12_o_proj [label="" style=solid]
	layer3_gpu12_o_proj -> layer3_gpu12_attn_residual [label="" style=solid]
	layer3_gpu12_attn_input_reshape -> layer3_gpu12_attn_residual [label="" style=dashed]
	layer3_input_broadcast -> layer3_gpu12_attn_input_reshape [label="" style=solid]
	layer3_gpu13_attn_input_reshape [label="layer3_gpu13_attn_input_reshape\nInput Reshape\nGPU: 13\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu13_q_proj [label="layer3_gpu13_q_proj\nQ Projection\nGPU: 13\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu13_k_proj [label="layer3_gpu13_k_proj\nK Projection\nGPU: 13\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu13_v_proj [label="layer3_gpu13_v_proj\nV Projection\nGPU: 13\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu13_mha [label="layer3_gpu13_mha\nMulti-Head Attention\nGPU: 13\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu13_o_proj [label="layer3_gpu13_o_proj\nOutput Projection\nGPU: 13\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer3_gpu13_attn_residual [label="layer3_gpu13_attn_residual\nResidual Add\nGPU: 13\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu13_attn_input_reshape -> layer3_gpu13_q_proj [label="" style=solid]
	layer3_gpu13_attn_input_reshape -> layer3_gpu13_k_proj [label="" style=solid]
	layer3_gpu13_attn_input_reshape -> layer3_gpu13_v_proj [label="" style=solid]
	layer3_gpu13_q_proj -> layer3_gpu13_mha [label="" style=solid]
	layer3_gpu13_k_proj -> layer3_gpu13_mha [label="" style=solid]
	layer3_gpu13_v_proj -> layer3_gpu13_mha [label="" style=solid]
	layer3_gpu13_mha -> layer3_gpu13_o_proj [label="" style=solid]
	layer3_gpu13_o_proj -> layer3_gpu13_attn_residual [label="" style=solid]
	layer3_gpu13_attn_input_reshape -> layer3_gpu13_attn_residual [label="" style=dashed]
	layer3_input_broadcast -> layer3_gpu13_attn_input_reshape [label="" style=solid]
	layer3_gpu14_attn_input_reshape [label="layer3_gpu14_attn_input_reshape\nInput Reshape\nGPU: 14\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu14_q_proj [label="layer3_gpu14_q_proj\nQ Projection\nGPU: 14\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu14_k_proj [label="layer3_gpu14_k_proj\nK Projection\nGPU: 14\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu14_v_proj [label="layer3_gpu14_v_proj\nV Projection\nGPU: 14\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu14_mha [label="layer3_gpu14_mha\nMulti-Head Attention\nGPU: 14\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu14_o_proj [label="layer3_gpu14_o_proj\nOutput Projection\nGPU: 14\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer3_gpu14_attn_residual [label="layer3_gpu14_attn_residual\nResidual Add\nGPU: 14\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu14_attn_input_reshape -> layer3_gpu14_q_proj [label="" style=solid]
	layer3_gpu14_attn_input_reshape -> layer3_gpu14_k_proj [label="" style=solid]
	layer3_gpu14_attn_input_reshape -> layer3_gpu14_v_proj [label="" style=solid]
	layer3_gpu14_q_proj -> layer3_gpu14_mha [label="" style=solid]
	layer3_gpu14_k_proj -> layer3_gpu14_mha [label="" style=solid]
	layer3_gpu14_v_proj -> layer3_gpu14_mha [label="" style=solid]
	layer3_gpu14_mha -> layer3_gpu14_o_proj [label="" style=solid]
	layer3_gpu14_o_proj -> layer3_gpu14_attn_residual [label="" style=solid]
	layer3_gpu14_attn_input_reshape -> layer3_gpu14_attn_residual [label="" style=dashed]
	layer3_input_broadcast -> layer3_gpu14_attn_input_reshape [label="" style=solid]
	layer3_gpu15_attn_input_reshape [label="layer3_gpu15_attn_input_reshape\nInput Reshape\nGPU: 15\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu15_q_proj [label="layer3_gpu15_q_proj\nQ Projection\nGPU: 15\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu15_k_proj [label="layer3_gpu15_k_proj\nK Projection\nGPU: 15\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu15_v_proj [label="layer3_gpu15_v_proj\nV Projection\nGPU: 15\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu15_mha [label="layer3_gpu15_mha\nMulti-Head Attention\nGPU: 15\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=1024, seq_len=10000, heads=16, head_dim=512" color=black shape=rectangle]
	layer3_gpu15_o_proj [label="layer3_gpu15_o_proj\nOutput Projection\nGPU: 15\nIn: batch_size=1024, seq_len=10000, heads=16, head_dim=512\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=rectangle]
	layer3_gpu15_attn_residual [label="layer3_gpu15_attn_residual\nResidual Add\nGPU: 15\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu15_attn_input_reshape -> layer3_gpu15_q_proj [label="" style=solid]
	layer3_gpu15_attn_input_reshape -> layer3_gpu15_k_proj [label="" style=solid]
	layer3_gpu15_attn_input_reshape -> layer3_gpu15_v_proj [label="" style=solid]
	layer3_gpu15_q_proj -> layer3_gpu15_mha [label="" style=solid]
	layer3_gpu15_k_proj -> layer3_gpu15_mha [label="" style=solid]
	layer3_gpu15_v_proj -> layer3_gpu15_mha [label="" style=solid]
	layer3_gpu15_mha -> layer3_gpu15_o_proj [label="" style=solid]
	layer3_gpu15_o_proj -> layer3_gpu15_attn_residual [label="" style=solid]
	layer3_gpu15_attn_input_reshape -> layer3_gpu15_attn_residual [label="" style=dashed]
	layer3_input_broadcast -> layer3_gpu15_attn_input_reshape [label="" style=solid]
	layer3_attn_output_broadcast_gpu0 [label="layer3_attn_output_broadcast_gpu0\nAttention Output Broadcast\nGPU: 0\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu0_attn_residual -> layer3_attn_output_broadcast_gpu0 [label="" style=solid]
	layer3_attn_output_broadcast_gpu1 [label="layer3_attn_output_broadcast_gpu1\nAttention Output Broadcast\nGPU: 1\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu1_attn_residual -> layer3_attn_output_broadcast_gpu1 [label="" style=solid]
	layer3_attn_output_broadcast_gpu2 [label="layer3_attn_output_broadcast_gpu2\nAttention Output Broadcast\nGPU: 2\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu2_attn_residual -> layer3_attn_output_broadcast_gpu2 [label="" style=solid]
	layer3_attn_output_broadcast_gpu3 [label="layer3_attn_output_broadcast_gpu3\nAttention Output Broadcast\nGPU: 3\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu3_attn_residual -> layer3_attn_output_broadcast_gpu3 [label="" style=solid]
	layer3_attn_output_broadcast_gpu4 [label="layer3_attn_output_broadcast_gpu4\nAttention Output Broadcast\nGPU: 4\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu4_attn_residual -> layer3_attn_output_broadcast_gpu4 [label="" style=solid]
	layer3_attn_output_broadcast_gpu5 [label="layer3_attn_output_broadcast_gpu5\nAttention Output Broadcast\nGPU: 5\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu5_attn_residual -> layer3_attn_output_broadcast_gpu5 [label="" style=solid]
	layer3_attn_output_broadcast_gpu6 [label="layer3_attn_output_broadcast_gpu6\nAttention Output Broadcast\nGPU: 6\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu6_attn_residual -> layer3_attn_output_broadcast_gpu6 [label="" style=solid]
	layer3_attn_output_broadcast_gpu7 [label="layer3_attn_output_broadcast_gpu7\nAttention Output Broadcast\nGPU: 7\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu7_attn_residual -> layer3_attn_output_broadcast_gpu7 [label="" style=solid]
	layer3_attn_output_broadcast_gpu8 [label="layer3_attn_output_broadcast_gpu8\nAttention Output Broadcast\nGPU: 8\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu8_attn_residual -> layer3_attn_output_broadcast_gpu8 [label="" style=solid]
	layer3_attn_output_broadcast_gpu9 [label="layer3_attn_output_broadcast_gpu9\nAttention Output Broadcast\nGPU: 9\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu9_attn_residual -> layer3_attn_output_broadcast_gpu9 [label="" style=solid]
	layer3_attn_output_broadcast_gpu10 [label="layer3_attn_output_broadcast_gpu10\nAttention Output Broadcast\nGPU: 10\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu10_attn_residual -> layer3_attn_output_broadcast_gpu10 [label="" style=solid]
	layer3_attn_output_broadcast_gpu11 [label="layer3_attn_output_broadcast_gpu11\nAttention Output Broadcast\nGPU: 11\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu11_attn_residual -> layer3_attn_output_broadcast_gpu11 [label="" style=solid]
	layer3_attn_output_broadcast_gpu12 [label="layer3_attn_output_broadcast_gpu12\nAttention Output Broadcast\nGPU: 12\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu12_attn_residual -> layer3_attn_output_broadcast_gpu12 [label="" style=solid]
	layer3_attn_output_broadcast_gpu13 [label="layer3_attn_output_broadcast_gpu13\nAttention Output Broadcast\nGPU: 13\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu13_attn_residual -> layer3_attn_output_broadcast_gpu13 [label="" style=solid]
	layer3_attn_output_broadcast_gpu14 [label="layer3_attn_output_broadcast_gpu14\nAttention Output Broadcast\nGPU: 14\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu14_attn_residual -> layer3_attn_output_broadcast_gpu14 [label="" style=solid]
	layer3_attn_output_broadcast_gpu15 [label="layer3_attn_output_broadcast_gpu15\nAttention Output Broadcast\nGPU: 15\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_gpu15_attn_residual -> layer3_attn_output_broadcast_gpu15 [label="" style=solid]
	layer3_gating_network [label="layer3_gating_network\nGating Network\nGPU: 0-15\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=10240000, num_experts=16" color=black shape=parallelogram]
	layer3_gating_selection [label="layer3_gating_selection\nExpert Selection\nGPU: 0-15\nIn: batch_size=10240000, num_experts=16\nOut: batch_size=10240000, selected_experts=2" color=black shape=parallelogram]
	layer3_gating_network -> layer3_gating_selection [label="" style=solid]
	layer3_routing_route_to_expert0 [label="layer3_routing_route_to_expert0\nRoute to Expert 0\nGPU: 0\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer3_gating_selection -> layer3_routing_route_to_expert0 [label="" style=dashed]
	layer3_routing_route_to_expert1 [label="layer3_routing_route_to_expert1\nRoute to Expert 1\nGPU: 1\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer3_gating_selection -> layer3_routing_route_to_expert1 [label="" style=dashed]
	layer3_routing_route_to_expert2 [label="layer3_routing_route_to_expert2\nRoute to Expert 2\nGPU: 2\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer3_gating_selection -> layer3_routing_route_to_expert2 [label="" style=dashed]
	layer3_routing_route_to_expert3 [label="layer3_routing_route_to_expert3\nRoute to Expert 3\nGPU: 3\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer3_gating_selection -> layer3_routing_route_to_expert3 [label="" style=dashed]
	layer3_routing_route_to_expert4 [label="layer3_routing_route_to_expert4\nRoute to Expert 4\nGPU: 4\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer3_gating_selection -> layer3_routing_route_to_expert4 [label="" style=dashed]
	layer3_routing_route_to_expert5 [label="layer3_routing_route_to_expert5\nRoute to Expert 5\nGPU: 5\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer3_gating_selection -> layer3_routing_route_to_expert5 [label="" style=dashed]
	layer3_routing_route_to_expert6 [label="layer3_routing_route_to_expert6\nRoute to Expert 6\nGPU: 6\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer3_gating_selection -> layer3_routing_route_to_expert6 [label="" style=dashed]
	layer3_routing_route_to_expert7 [label="layer3_routing_route_to_expert7\nRoute to Expert 7\nGPU: 7\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer3_gating_selection -> layer3_routing_route_to_expert7 [label="" style=dashed]
	layer3_routing_route_to_expert8 [label="layer3_routing_route_to_expert8\nRoute to Expert 8\nGPU: 8\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer3_gating_selection -> layer3_routing_route_to_expert8 [label="" style=dashed]
	layer3_routing_route_to_expert9 [label="layer3_routing_route_to_expert9\nRoute to Expert 9\nGPU: 9\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer3_gating_selection -> layer3_routing_route_to_expert9 [label="" style=dashed]
	layer3_routing_route_to_expert10 [label="layer3_routing_route_to_expert10\nRoute to Expert 10\nGPU: 10\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer3_gating_selection -> layer3_routing_route_to_expert10 [label="" style=dashed]
	layer3_routing_route_to_expert11 [label="layer3_routing_route_to_expert11\nRoute to Expert 11\nGPU: 11\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer3_gating_selection -> layer3_routing_route_to_expert11 [label="" style=dashed]
	layer3_routing_route_to_expert12 [label="layer3_routing_route_to_expert12\nRoute to Expert 12\nGPU: 12\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer3_gating_selection -> layer3_routing_route_to_expert12 [label="" style=dashed]
	layer3_routing_route_to_expert13 [label="layer3_routing_route_to_expert13\nRoute to Expert 13\nGPU: 13\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer3_gating_selection -> layer3_routing_route_to_expert13 [label="" style=dashed]
	layer3_routing_route_to_expert14 [label="layer3_routing_route_to_expert14\nRoute to Expert 14\nGPU: 14\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer3_gating_selection -> layer3_routing_route_to_expert14 [label="" style=dashed]
	layer3_routing_route_to_expert15 [label="layer3_routing_route_to_expert15\nRoute to Expert 15\nGPU: 15\nIn: batch_size=10240000, hidden_dim=8192\nOut: batch_size=640000, hidden_dim=8192" color=black shape=parallelogram]
	layer3_gating_selection -> layer3_routing_route_to_expert15 [label="" style=dashed]
	layer3_expert0_gpu0_gate_proj [label="layer3_expert0_gpu0_gate_proj\nGate Projection\nGPU: 0\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer3_expert0_gpu0_up_proj [label="layer3_expert0_gpu0_up_proj\nUp Projection\nGPU: 0\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer3_expert0_gpu0_activation [label="layer3_expert0_gpu0_activation\nGELU Activation\nGPU: 0\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer3_expert0_gpu0_down_proj [label="layer3_expert0_gpu0_down_proj\nDown Projection\nGPU: 0\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer3_expert0_gpu0_gate_proj -> layer3_expert0_gpu0_activation [label="" style=solid]
	layer3_expert0_gpu0_up_proj -> layer3_expert0_gpu0_down_proj [label="" style=solid]
	layer3_expert0_gpu0_activation -> layer3_expert0_gpu0_down_proj [label="" style=solid]
	layer3_routing_route_to_expert0 -> layer3_expert0_gpu0_gate_proj [label="" style=solid]
	layer3_routing_route_to_expert0 -> layer3_expert0_gpu0_up_proj [label="" style=solid]
	layer3_expert1_gpu1_gate_proj [label="layer3_expert1_gpu1_gate_proj\nGate Projection\nGPU: 1\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer3_expert1_gpu1_up_proj [label="layer3_expert1_gpu1_up_proj\nUp Projection\nGPU: 1\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer3_expert1_gpu1_activation [label="layer3_expert1_gpu1_activation\nGELU Activation\nGPU: 1\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer3_expert1_gpu1_down_proj [label="layer3_expert1_gpu1_down_proj\nDown Projection\nGPU: 1\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer3_expert1_gpu1_gate_proj -> layer3_expert1_gpu1_activation [label="" style=solid]
	layer3_expert1_gpu1_up_proj -> layer3_expert1_gpu1_down_proj [label="" style=solid]
	layer3_expert1_gpu1_activation -> layer3_expert1_gpu1_down_proj [label="" style=solid]
	layer3_routing_route_to_expert1 -> layer3_expert1_gpu1_gate_proj [label="" style=solid]
	layer3_routing_route_to_expert1 -> layer3_expert1_gpu1_up_proj [label="" style=solid]
	layer3_expert2_gpu2_gate_proj [label="layer3_expert2_gpu2_gate_proj\nGate Projection\nGPU: 2\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer3_expert2_gpu2_up_proj [label="layer3_expert2_gpu2_up_proj\nUp Projection\nGPU: 2\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer3_expert2_gpu2_activation [label="layer3_expert2_gpu2_activation\nGELU Activation\nGPU: 2\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer3_expert2_gpu2_down_proj [label="layer3_expert2_gpu2_down_proj\nDown Projection\nGPU: 2\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer3_expert2_gpu2_gate_proj -> layer3_expert2_gpu2_activation [label="" style=solid]
	layer3_expert2_gpu2_up_proj -> layer3_expert2_gpu2_down_proj [label="" style=solid]
	layer3_expert2_gpu2_activation -> layer3_expert2_gpu2_down_proj [label="" style=solid]
	layer3_routing_route_to_expert2 -> layer3_expert2_gpu2_gate_proj [label="" style=solid]
	layer3_routing_route_to_expert2 -> layer3_expert2_gpu2_up_proj [label="" style=solid]
	layer3_expert3_gpu3_gate_proj [label="layer3_expert3_gpu3_gate_proj\nGate Projection\nGPU: 3\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer3_expert3_gpu3_up_proj [label="layer3_expert3_gpu3_up_proj\nUp Projection\nGPU: 3\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer3_expert3_gpu3_activation [label="layer3_expert3_gpu3_activation\nGELU Activation\nGPU: 3\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer3_expert3_gpu3_down_proj [label="layer3_expert3_gpu3_down_proj\nDown Projection\nGPU: 3\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer3_expert3_gpu3_gate_proj -> layer3_expert3_gpu3_activation [label="" style=solid]
	layer3_expert3_gpu3_up_proj -> layer3_expert3_gpu3_down_proj [label="" style=solid]
	layer3_expert3_gpu3_activation -> layer3_expert3_gpu3_down_proj [label="" style=solid]
	layer3_routing_route_to_expert3 -> layer3_expert3_gpu3_gate_proj [label="" style=solid]
	layer3_routing_route_to_expert3 -> layer3_expert3_gpu3_up_proj [label="" style=solid]
	layer3_expert4_gpu4_gate_proj [label="layer3_expert4_gpu4_gate_proj\nGate Projection\nGPU: 4\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer3_expert4_gpu4_up_proj [label="layer3_expert4_gpu4_up_proj\nUp Projection\nGPU: 4\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer3_expert4_gpu4_activation [label="layer3_expert4_gpu4_activation\nGELU Activation\nGPU: 4\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer3_expert4_gpu4_down_proj [label="layer3_expert4_gpu4_down_proj\nDown Projection\nGPU: 4\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer3_expert4_gpu4_gate_proj -> layer3_expert4_gpu4_activation [label="" style=solid]
	layer3_expert4_gpu4_up_proj -> layer3_expert4_gpu4_down_proj [label="" style=solid]
	layer3_expert4_gpu4_activation -> layer3_expert4_gpu4_down_proj [label="" style=solid]
	layer3_routing_route_to_expert4 -> layer3_expert4_gpu4_gate_proj [label="" style=solid]
	layer3_routing_route_to_expert4 -> layer3_expert4_gpu4_up_proj [label="" style=solid]
	layer3_expert5_gpu5_gate_proj [label="layer3_expert5_gpu5_gate_proj\nGate Projection\nGPU: 5\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer3_expert5_gpu5_up_proj [label="layer3_expert5_gpu5_up_proj\nUp Projection\nGPU: 5\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer3_expert5_gpu5_activation [label="layer3_expert5_gpu5_activation\nGELU Activation\nGPU: 5\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer3_expert5_gpu5_down_proj [label="layer3_expert5_gpu5_down_proj\nDown Projection\nGPU: 5\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer3_expert5_gpu5_gate_proj -> layer3_expert5_gpu5_activation [label="" style=solid]
	layer3_expert5_gpu5_up_proj -> layer3_expert5_gpu5_down_proj [label="" style=solid]
	layer3_expert5_gpu5_activation -> layer3_expert5_gpu5_down_proj [label="" style=solid]
	layer3_routing_route_to_expert5 -> layer3_expert5_gpu5_gate_proj [label="" style=solid]
	layer3_routing_route_to_expert5 -> layer3_expert5_gpu5_up_proj [label="" style=solid]
	layer3_expert6_gpu6_gate_proj [label="layer3_expert6_gpu6_gate_proj\nGate Projection\nGPU: 6\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer3_expert6_gpu6_up_proj [label="layer3_expert6_gpu6_up_proj\nUp Projection\nGPU: 6\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer3_expert6_gpu6_activation [label="layer3_expert6_gpu6_activation\nGELU Activation\nGPU: 6\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer3_expert6_gpu6_down_proj [label="layer3_expert6_gpu6_down_proj\nDown Projection\nGPU: 6\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer3_expert6_gpu6_gate_proj -> layer3_expert6_gpu6_activation [label="" style=solid]
	layer3_expert6_gpu6_up_proj -> layer3_expert6_gpu6_down_proj [label="" style=solid]
	layer3_expert6_gpu6_activation -> layer3_expert6_gpu6_down_proj [label="" style=solid]
	layer3_routing_route_to_expert6 -> layer3_expert6_gpu6_gate_proj [label="" style=solid]
	layer3_routing_route_to_expert6 -> layer3_expert6_gpu6_up_proj [label="" style=solid]
	layer3_expert7_gpu7_gate_proj [label="layer3_expert7_gpu7_gate_proj\nGate Projection\nGPU: 7\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer3_expert7_gpu7_up_proj [label="layer3_expert7_gpu7_up_proj\nUp Projection\nGPU: 7\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer3_expert7_gpu7_activation [label="layer3_expert7_gpu7_activation\nGELU Activation\nGPU: 7\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer3_expert7_gpu7_down_proj [label="layer3_expert7_gpu7_down_proj\nDown Projection\nGPU: 7\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer3_expert7_gpu7_gate_proj -> layer3_expert7_gpu7_activation [label="" style=solid]
	layer3_expert7_gpu7_up_proj -> layer3_expert7_gpu7_down_proj [label="" style=solid]
	layer3_expert7_gpu7_activation -> layer3_expert7_gpu7_down_proj [label="" style=solid]
	layer3_routing_route_to_expert7 -> layer3_expert7_gpu7_gate_proj [label="" style=solid]
	layer3_routing_route_to_expert7 -> layer3_expert7_gpu7_up_proj [label="" style=solid]
	layer3_expert8_gpu8_gate_proj [label="layer3_expert8_gpu8_gate_proj\nGate Projection\nGPU: 8\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer3_expert8_gpu8_up_proj [label="layer3_expert8_gpu8_up_proj\nUp Projection\nGPU: 8\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer3_expert8_gpu8_activation [label="layer3_expert8_gpu8_activation\nGELU Activation\nGPU: 8\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer3_expert8_gpu8_down_proj [label="layer3_expert8_gpu8_down_proj\nDown Projection\nGPU: 8\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer3_expert8_gpu8_gate_proj -> layer3_expert8_gpu8_activation [label="" style=solid]
	layer3_expert8_gpu8_up_proj -> layer3_expert8_gpu8_down_proj [label="" style=solid]
	layer3_expert8_gpu8_activation -> layer3_expert8_gpu8_down_proj [label="" style=solid]
	layer3_routing_route_to_expert8 -> layer3_expert8_gpu8_gate_proj [label="" style=solid]
	layer3_routing_route_to_expert8 -> layer3_expert8_gpu8_up_proj [label="" style=solid]
	layer3_expert9_gpu9_gate_proj [label="layer3_expert9_gpu9_gate_proj\nGate Projection\nGPU: 9\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer3_expert9_gpu9_up_proj [label="layer3_expert9_gpu9_up_proj\nUp Projection\nGPU: 9\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer3_expert9_gpu9_activation [label="layer3_expert9_gpu9_activation\nGELU Activation\nGPU: 9\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer3_expert9_gpu9_down_proj [label="layer3_expert9_gpu9_down_proj\nDown Projection\nGPU: 9\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer3_expert9_gpu9_gate_proj -> layer3_expert9_gpu9_activation [label="" style=solid]
	layer3_expert9_gpu9_up_proj -> layer3_expert9_gpu9_down_proj [label="" style=solid]
	layer3_expert9_gpu9_activation -> layer3_expert9_gpu9_down_proj [label="" style=solid]
	layer3_routing_route_to_expert9 -> layer3_expert9_gpu9_gate_proj [label="" style=solid]
	layer3_routing_route_to_expert9 -> layer3_expert9_gpu9_up_proj [label="" style=solid]
	layer3_expert10_gpu10_gate_proj [label="layer3_expert10_gpu10_gate_proj\nGate Projection\nGPU: 10\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer3_expert10_gpu10_up_proj [label="layer3_expert10_gpu10_up_proj\nUp Projection\nGPU: 10\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer3_expert10_gpu10_activation [label="layer3_expert10_gpu10_activation\nGELU Activation\nGPU: 10\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer3_expert10_gpu10_down_proj [label="layer3_expert10_gpu10_down_proj\nDown Projection\nGPU: 10\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer3_expert10_gpu10_gate_proj -> layer3_expert10_gpu10_activation [label="" style=solid]
	layer3_expert10_gpu10_up_proj -> layer3_expert10_gpu10_down_proj [label="" style=solid]
	layer3_expert10_gpu10_activation -> layer3_expert10_gpu10_down_proj [label="" style=solid]
	layer3_routing_route_to_expert10 -> layer3_expert10_gpu10_gate_proj [label="" style=solid]
	layer3_routing_route_to_expert10 -> layer3_expert10_gpu10_up_proj [label="" style=solid]
	layer3_expert11_gpu11_gate_proj [label="layer3_expert11_gpu11_gate_proj\nGate Projection\nGPU: 11\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer3_expert11_gpu11_up_proj [label="layer3_expert11_gpu11_up_proj\nUp Projection\nGPU: 11\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer3_expert11_gpu11_activation [label="layer3_expert11_gpu11_activation\nGELU Activation\nGPU: 11\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer3_expert11_gpu11_down_proj [label="layer3_expert11_gpu11_down_proj\nDown Projection\nGPU: 11\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer3_expert11_gpu11_gate_proj -> layer3_expert11_gpu11_activation [label="" style=solid]
	layer3_expert11_gpu11_up_proj -> layer3_expert11_gpu11_down_proj [label="" style=solid]
	layer3_expert11_gpu11_activation -> layer3_expert11_gpu11_down_proj [label="" style=solid]
	layer3_routing_route_to_expert11 -> layer3_expert11_gpu11_gate_proj [label="" style=solid]
	layer3_routing_route_to_expert11 -> layer3_expert11_gpu11_up_proj [label="" style=solid]
	layer3_expert12_gpu12_gate_proj [label="layer3_expert12_gpu12_gate_proj\nGate Projection\nGPU: 12\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer3_expert12_gpu12_up_proj [label="layer3_expert12_gpu12_up_proj\nUp Projection\nGPU: 12\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer3_expert12_gpu12_activation [label="layer3_expert12_gpu12_activation\nGELU Activation\nGPU: 12\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer3_expert12_gpu12_down_proj [label="layer3_expert12_gpu12_down_proj\nDown Projection\nGPU: 12\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer3_expert12_gpu12_gate_proj -> layer3_expert12_gpu12_activation [label="" style=solid]
	layer3_expert12_gpu12_up_proj -> layer3_expert12_gpu12_down_proj [label="" style=solid]
	layer3_expert12_gpu12_activation -> layer3_expert12_gpu12_down_proj [label="" style=solid]
	layer3_routing_route_to_expert12 -> layer3_expert12_gpu12_gate_proj [label="" style=solid]
	layer3_routing_route_to_expert12 -> layer3_expert12_gpu12_up_proj [label="" style=solid]
	layer3_expert13_gpu13_gate_proj [label="layer3_expert13_gpu13_gate_proj\nGate Projection\nGPU: 13\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer3_expert13_gpu13_up_proj [label="layer3_expert13_gpu13_up_proj\nUp Projection\nGPU: 13\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer3_expert13_gpu13_activation [label="layer3_expert13_gpu13_activation\nGELU Activation\nGPU: 13\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer3_expert13_gpu13_down_proj [label="layer3_expert13_gpu13_down_proj\nDown Projection\nGPU: 13\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer3_expert13_gpu13_gate_proj -> layer3_expert13_gpu13_activation [label="" style=solid]
	layer3_expert13_gpu13_up_proj -> layer3_expert13_gpu13_down_proj [label="" style=solid]
	layer3_expert13_gpu13_activation -> layer3_expert13_gpu13_down_proj [label="" style=solid]
	layer3_routing_route_to_expert13 -> layer3_expert13_gpu13_gate_proj [label="" style=solid]
	layer3_routing_route_to_expert13 -> layer3_expert13_gpu13_up_proj [label="" style=solid]
	layer3_expert14_gpu14_gate_proj [label="layer3_expert14_gpu14_gate_proj\nGate Projection\nGPU: 14\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer3_expert14_gpu14_up_proj [label="layer3_expert14_gpu14_up_proj\nUp Projection\nGPU: 14\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer3_expert14_gpu14_activation [label="layer3_expert14_gpu14_activation\nGELU Activation\nGPU: 14\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer3_expert14_gpu14_down_proj [label="layer3_expert14_gpu14_down_proj\nDown Projection\nGPU: 14\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer3_expert14_gpu14_gate_proj -> layer3_expert14_gpu14_activation [label="" style=solid]
	layer3_expert14_gpu14_up_proj -> layer3_expert14_gpu14_down_proj [label="" style=solid]
	layer3_expert14_gpu14_activation -> layer3_expert14_gpu14_down_proj [label="" style=solid]
	layer3_routing_route_to_expert14 -> layer3_expert14_gpu14_gate_proj [label="" style=solid]
	layer3_routing_route_to_expert14 -> layer3_expert14_gpu14_up_proj [label="" style=solid]
	layer3_expert15_gpu15_gate_proj [label="layer3_expert15_gpu15_gate_proj\nGate Projection\nGPU: 15\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer3_expert15_gpu15_up_proj [label="layer3_expert15_gpu15_up_proj\nUp Projection\nGPU: 15\nIn: batch_size=640000, hidden_dim=8192\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=rectangle]
	layer3_expert15_gpu15_activation [label="layer3_expert15_gpu15_activation\nGELU Activation\nGPU: 15\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, ffn_hidden=32768" color=black shape=ellipse]
	layer3_expert15_gpu15_down_proj [label="layer3_expert15_gpu15_down_proj\nDown Projection\nGPU: 15\nIn: batch_size=640000, ffn_hidden=32768\nOut: batch_size=640000, hidden_dim=8192" color=black shape=rectangle]
	layer3_expert15_gpu15_gate_proj -> layer3_expert15_gpu15_activation [label="" style=solid]
	layer3_expert15_gpu15_up_proj -> layer3_expert15_gpu15_down_proj [label="" style=solid]
	layer3_expert15_gpu15_activation -> layer3_expert15_gpu15_down_proj [label="" style=solid]
	layer3_routing_route_to_expert15 -> layer3_expert15_gpu15_gate_proj [label="" style=solid]
	layer3_routing_route_to_expert15 -> layer3_expert15_gpu15_up_proj [label="" style=solid]
	layer3_routing_aggregate [label="layer3_routing_aggregate\nAggregate Expert Outputs\nGPU: 0-15\nIn: batch_size=640000, hidden_dim=8192 (x16)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=parallelogram]
	layer3_expert0_gpu0_down_proj -> layer3_routing_aggregate [label="" style=solid]
	layer3_expert1_gpu1_down_proj -> layer3_routing_aggregate [label="" style=solid]
	layer3_expert2_gpu2_down_proj -> layer3_routing_aggregate [label="" style=solid]
	layer3_expert3_gpu3_down_proj -> layer3_routing_aggregate [label="" style=solid]
	layer3_expert4_gpu4_down_proj -> layer3_routing_aggregate [label="" style=solid]
	layer3_expert5_gpu5_down_proj -> layer3_routing_aggregate [label="" style=solid]
	layer3_expert6_gpu6_down_proj -> layer3_routing_aggregate [label="" style=solid]
	layer3_expert7_gpu7_down_proj -> layer3_routing_aggregate [label="" style=solid]
	layer3_expert8_gpu8_down_proj -> layer3_routing_aggregate [label="" style=solid]
	layer3_expert9_gpu9_down_proj -> layer3_routing_aggregate [label="" style=solid]
	layer3_expert10_gpu10_down_proj -> layer3_routing_aggregate [label="" style=solid]
	layer3_expert11_gpu11_down_proj -> layer3_routing_aggregate [label="" style=solid]
	layer3_expert12_gpu12_down_proj -> layer3_routing_aggregate [label="" style=solid]
	layer3_expert13_gpu13_down_proj -> layer3_routing_aggregate [label="" style=solid]
	layer3_expert14_gpu14_down_proj -> layer3_routing_aggregate [label="" style=solid]
	layer3_expert15_gpu15_down_proj -> layer3_routing_aggregate [label="" style=solid]
	layer3_routing_weighted_sum [label="layer3_routing_weighted_sum\nWeighted Sum\nGPU: 0-15\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_routing_aggregate -> layer3_routing_weighted_sum [label="" style=solid]
	layer3_gating_selection -> layer3_routing_weighted_sum [label="" style=dashed]
	layer3_attn_output_broadcast_gpu0 -> layer3_gating_network [label="" style=solid]
	layer3_attn_output_broadcast_gpu1 -> layer3_gating_network [label="" style=solid]
	layer3_attn_output_broadcast_gpu2 -> layer3_gating_network [label="" style=solid]
	layer3_attn_output_broadcast_gpu3 -> layer3_gating_network [label="" style=solid]
	layer3_attn_output_broadcast_gpu4 -> layer3_gating_network [label="" style=solid]
	layer3_attn_output_broadcast_gpu5 -> layer3_gating_network [label="" style=solid]
	layer3_attn_output_broadcast_gpu6 -> layer3_gating_network [label="" style=solid]
	layer3_attn_output_broadcast_gpu7 -> layer3_gating_network [label="" style=solid]
	layer3_attn_output_broadcast_gpu8 -> layer3_gating_network [label="" style=solid]
	layer3_attn_output_broadcast_gpu9 -> layer3_gating_network [label="" style=solid]
	layer3_attn_output_broadcast_gpu10 -> layer3_gating_network [label="" style=solid]
	layer3_attn_output_broadcast_gpu11 -> layer3_gating_network [label="" style=solid]
	layer3_attn_output_broadcast_gpu12 -> layer3_gating_network [label="" style=solid]
	layer3_attn_output_broadcast_gpu13 -> layer3_gating_network [label="" style=solid]
	layer3_attn_output_broadcast_gpu14 -> layer3_gating_network [label="" style=solid]
	layer3_attn_output_broadcast_gpu15 -> layer3_gating_network [label="" style=solid]
	layer3_output [label="layer3_output\nLayer Output\nGPU: 0-15\nIn: batch_size=10240000, hidden_dim=8192 (x2)\nOut: batch_size=10240000, hidden_dim=8192" color=black shape=ellipse]
	layer3_attn_output_broadcast_gpu0 -> layer3_output [label="" style=dashed]
	layer3_attn_output_broadcast_gpu1 -> layer3_output [label="" style=dashed]
	layer3_attn_output_broadcast_gpu2 -> layer3_output [label="" style=dashed]
	layer3_attn_output_broadcast_gpu3 -> layer3_output [label="" style=dashed]
	layer3_attn_output_broadcast_gpu4 -> layer3_output [label="" style=dashed]
	layer3_attn_output_broadcast_gpu5 -> layer3_output [label="" style=dashed]
	layer3_attn_output_broadcast_gpu6 -> layer3_output [label="" style=dashed]
	layer3_attn_output_broadcast_gpu7 -> layer3_output [label="" style=dashed]
	layer3_attn_output_broadcast_gpu8 -> layer3_output [label="" style=dashed]
	layer3_attn_output_broadcast_gpu9 -> layer3_output [label="" style=dashed]
	layer3_attn_output_broadcast_gpu10 -> layer3_output [label="" style=dashed]
	layer3_attn_output_broadcast_gpu11 -> layer3_output [label="" style=dashed]
	layer3_attn_output_broadcast_gpu12 -> layer3_output [label="" style=dashed]
	layer3_attn_output_broadcast_gpu13 -> layer3_output [label="" style=dashed]
	layer3_attn_output_broadcast_gpu14 -> layer3_output [label="" style=dashed]
	layer3_attn_output_broadcast_gpu15 -> layer3_output [label="" style=dashed]
	layer3_routing_weighted_sum -> layer3_output [label="" style=solid]
	layer2_output -> layer3_input_broadcast [label="" style=solid]
	model_output [label="model_output\nModel Output\nGPU: 0-15\nIn: batch_size=1024, seq_len=10000, hidden_dim=8192\nOut: batch_size=1024, seq_len=10000, hidden_dim=8192" color=black shape=ellipse]
	layer3_output -> model_output [label="" style=solid]
}
