// LLM Parallel Strategy DAG
digraph {
	dpi=300 rankdir=TB size="30,40"
	graph [bgcolor=white pad=0.5]
	node [fillcolor=lightblue shape=rectangle style=filled]
	edge [arrowhead=normal penwidth=1.5]
	input [label="Input\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=white penwidth=2 shape=ellipse style=filled]
	embed_0_0 [label="Embedding_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	embed_0_1 [label="Embedding_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	embed_0_2 [label="Embedding_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	embed_0_3 [label="Embedding_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	embed_1_0 [label="Embedding_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	embed_1_1 [label="Embedding_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	embed_1_2 [label="Embedding_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	embed_1_3 [label="Embedding_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	embed_2_0 [label="Embedding_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	embed_2_1 [label="Embedding_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	embed_2_2 [label="Embedding_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	embed_2_3 [label="Embedding_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	embed_3_0 [label="Embedding_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	embed_3_1 [label="Embedding_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	embed_3_2 [label="Embedding_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	embed_3_3 [label="Embedding_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	embed_4_0 [label="Embedding_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	embed_4_1 [label="Embedding_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	embed_4_2 [label="Embedding_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	embed_4_3 [label="Embedding_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	embed_5_0 [label="Embedding_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	embed_5_1 [label="Embedding_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	embed_5_2 [label="Embedding_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	embed_5_3 [label="Embedding_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	embed_6_0 [label="Embedding_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	embed_6_1 [label="Embedding_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	embed_6_2 [label="Embedding_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	embed_6_3 [label="Embedding_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	embed_7_0 [label="Embedding_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	embed_7_1 [label="Embedding_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	embed_7_2 [label="Embedding_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	embed_7_3 [label="Embedding_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	embed_8_0 [label="Embedding_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	embed_8_1 [label="Embedding_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	embed_8_2 [label="Embedding_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	embed_8_3 [label="Embedding_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	embed_9_0 [label="Embedding_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	embed_9_1 [label="Embedding_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	embed_9_2 [label="Embedding_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	embed_9_3 [label="Embedding_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	embed_10_0 [label="Embedding_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	embed_10_1 [label="Embedding_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	embed_10_2 [label="Embedding_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	embed_10_3 [label="Embedding_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	embed_11_0 [label="Embedding_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	embed_11_1 [label="Embedding_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	embed_11_2 [label="Embedding_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	embed_11_3 [label="Embedding_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	embed_12_0 [label="Embedding_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	embed_12_1 [label="Embedding_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	embed_12_2 [label="Embedding_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	embed_12_3 [label="Embedding_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	embed_13_0 [label="Embedding_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	embed_13_1 [label="Embedding_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	embed_13_2 [label="Embedding_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	embed_13_3 [label="Embedding_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	embed_14_0 [label="Embedding_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	embed_14_1 [label="Embedding_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	embed_14_2 [label="Embedding_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	embed_14_3 [label="Embedding_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	embed_15_0 [label="Embedding_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	embed_15_1 [label="Embedding_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	embed_15_2 [label="Embedding_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	embed_15_3 [label="Embedding_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	input -> embed_0_0
	input -> embed_0_1
	input -> embed_0_2
	input -> embed_0_3
	input -> embed_1_0
	input -> embed_1_1
	input -> embed_1_2
	input -> embed_1_3
	input -> embed_2_0
	input -> embed_2_1
	input -> embed_2_2
	input -> embed_2_3
	input -> embed_3_0
	input -> embed_3_1
	input -> embed_3_2
	input -> embed_3_3
	input -> embed_4_0
	input -> embed_4_1
	input -> embed_4_2
	input -> embed_4_3
	input -> embed_5_0
	input -> embed_5_1
	input -> embed_5_2
	input -> embed_5_3
	input -> embed_6_0
	input -> embed_6_1
	input -> embed_6_2
	input -> embed_6_3
	input -> embed_7_0
	input -> embed_7_1
	input -> embed_7_2
	input -> embed_7_3
	input -> embed_8_0
	input -> embed_8_1
	input -> embed_8_2
	input -> embed_8_3
	input -> embed_9_0
	input -> embed_9_1
	input -> embed_9_2
	input -> embed_9_3
	input -> embed_10_0
	input -> embed_10_1
	input -> embed_10_2
	input -> embed_10_3
	input -> embed_11_0
	input -> embed_11_1
	input -> embed_11_2
	input -> embed_11_3
	input -> embed_12_0
	input -> embed_12_1
	input -> embed_12_2
	input -> embed_12_3
	input -> embed_13_0
	input -> embed_13_1
	input -> embed_13_2
	input -> embed_13_3
	input -> embed_14_0
	input -> embed_14_1
	input -> embed_14_2
	input -> embed_14_3
	input -> embed_15_0
	input -> embed_15_1
	input -> embed_15_2
	input -> embed_15_3
	gate_0 [label="Gate_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, top_k=2]" fillcolor=gold penwidth=2 shape=parallelogram style="filled,dashed"]
	gate_1 [label="Gate_1\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, top_k=2]" fillcolor=gold penwidth=2 shape=parallelogram style="filled,dashed"]
	gate_2 [label="Gate_2\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, top_k=2]" fillcolor=gold penwidth=2 shape=parallelogram style="filled,dashed"]
	gate_3 [label="Gate_3\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, top_k=2]" fillcolor=gold penwidth=2 shape=parallelogram style="filled,dashed"]
	gate_4 [label="Gate_4\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, top_k=2]" fillcolor=gold penwidth=2 shape=parallelogram style="filled,dashed"]
	gate_5 [label="Gate_5\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, top_k=2]" fillcolor=gold penwidth=2 shape=parallelogram style="filled,dashed"]
	gate_6 [label="Gate_6\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, top_k=2]" fillcolor=gold penwidth=2 shape=parallelogram style="filled,dashed"]
	gate_7 [label="Gate_7\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, top_k=2]" fillcolor=gold penwidth=2 shape=parallelogram style="filled,dashed"]
	gate_8 [label="Gate_8\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, top_k=2]" fillcolor=gold penwidth=2 shape=parallelogram style="filled,dashed"]
	gate_9 [label="Gate_9\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, top_k=2]" fillcolor=gold penwidth=2 shape=parallelogram style="filled,dashed"]
	gate_10 [label="Gate_10\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, top_k=2]" fillcolor=gold penwidth=2 shape=parallelogram style="filled,dashed"]
	gate_11 [label="Gate_11\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, top_k=2]" fillcolor=gold penwidth=2 shape=parallelogram style="filled,dashed"]
	gate_12 [label="Gate_12\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, top_k=2]" fillcolor=gold penwidth=2 shape=parallelogram style="filled,dashed"]
	gate_13 [label="Gate_13\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, top_k=2]" fillcolor=gold penwidth=2 shape=parallelogram style="filled,dashed"]
	gate_14 [label="Gate_14\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, top_k=2]" fillcolor=gold penwidth=2 shape=parallelogram style="filled,dashed"]
	gate_15 [label="Gate_15\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, top_k=2]" fillcolor=gold penwidth=2 shape=parallelogram style="filled,dashed"]
	input -> gate_0 [penwidth=2 style=dashed]
	input -> gate_1 [penwidth=2 style=dashed]
	input -> gate_2 [penwidth=2 style=dashed]
	input -> gate_3 [penwidth=2 style=dashed]
	input -> gate_4 [penwidth=2 style=dashed]
	input -> gate_5 [penwidth=2 style=dashed]
	input -> gate_6 [penwidth=2 style=dashed]
	input -> gate_7 [penwidth=2 style=dashed]
	input -> gate_8 [penwidth=2 style=dashed]
	input -> gate_9 [penwidth=2 style=dashed]
	input -> gate_10 [penwidth=2 style=dashed]
	input -> gate_11 [penwidth=2 style=dashed]
	input -> gate_12 [penwidth=2 style=dashed]
	input -> gate_13 [penwidth=2 style=dashed]
	input -> gate_14 [penwidth=2 style=dashed]
	input -> gate_15 [penwidth=2 style=dashed]
	qkv_0_0_0 [label="QKV_Proj_0_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_0_0_0 [label="Attention_0_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_0_0_0 [label="Attention_Output_0_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_0_0_1 [label="QKV_Proj_0_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_0_0_1 [label="Attention_0_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_0_0_1 [label="Attention_Output_0_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_0_0_2 [label="QKV_Proj_0_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_0_0_2 [label="Attention_0_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_0_0_2 [label="Attention_Output_0_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_0_0_3 [label="QKV_Proj_0_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_0_0_3 [label="Attention_0_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_0_0_3 [label="Attention_Output_0_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	attn_allreduce_0_0 [label="Attention_AllReduce_0_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_0_1_0 [label="QKV_Proj_0_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_0_1_0 [label="Attention_0_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_0_1_0 [label="Attention_Output_0_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_0_1_1 [label="QKV_Proj_0_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_0_1_1 [label="Attention_0_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_0_1_1 [label="Attention_Output_0_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_0_1_2 [label="QKV_Proj_0_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_0_1_2 [label="Attention_0_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_0_1_2 [label="Attention_Output_0_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_0_1_3 [label="QKV_Proj_0_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_0_1_3 [label="Attention_0_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_0_1_3 [label="Attention_Output_0_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	attn_allreduce_0_1 [label="Attention_AllReduce_0_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_0_2_0 [label="QKV_Proj_0_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_0_2_0 [label="Attention_0_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_0_2_0 [label="Attention_Output_0_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_0_2_1 [label="QKV_Proj_0_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_0_2_1 [label="Attention_0_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_0_2_1 [label="Attention_Output_0_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_0_2_2 [label="QKV_Proj_0_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_0_2_2 [label="Attention_0_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_0_2_2 [label="Attention_Output_0_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_0_2_3 [label="QKV_Proj_0_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_0_2_3 [label="Attention_0_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_0_2_3 [label="Attention_Output_0_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	attn_allreduce_0_2 [label="Attention_AllReduce_0_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_0_3_0 [label="QKV_Proj_0_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_0_3_0 [label="Attention_0_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_0_3_0 [label="Attention_Output_0_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_0_3_1 [label="QKV_Proj_0_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_0_3_1 [label="Attention_0_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_0_3_1 [label="Attention_Output_0_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_0_3_2 [label="QKV_Proj_0_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_0_3_2 [label="Attention_0_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_0_3_2 [label="Attention_Output_0_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_0_3_3 [label="QKV_Proj_0_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_0_3_3 [label="Attention_0_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_0_3_3 [label="Attention_Output_0_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	attn_allreduce_0_3 [label="Attention_AllReduce_0_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_0_4_0 [label="QKV_Proj_0_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_0_4_0 [label="Attention_0_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_0_4_0 [label="Attention_Output_0_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_0_4_1 [label="QKV_Proj_0_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_0_4_1 [label="Attention_0_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_0_4_1 [label="Attention_Output_0_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_0_4_2 [label="QKV_Proj_0_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_0_4_2 [label="Attention_0_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_0_4_2 [label="Attention_Output_0_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_0_4_3 [label="QKV_Proj_0_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_0_4_3 [label="Attention_0_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_0_4_3 [label="Attention_Output_0_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	attn_allreduce_0_4 [label="Attention_AllReduce_0_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_0_5_0 [label="QKV_Proj_0_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_0_5_0 [label="Attention_0_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_0_5_0 [label="Attention_Output_0_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_0_5_1 [label="QKV_Proj_0_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_0_5_1 [label="Attention_0_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_0_5_1 [label="Attention_Output_0_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_0_5_2 [label="QKV_Proj_0_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_0_5_2 [label="Attention_0_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_0_5_2 [label="Attention_Output_0_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_0_5_3 [label="QKV_Proj_0_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_0_5_3 [label="Attention_0_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_0_5_3 [label="Attention_Output_0_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	attn_allreduce_0_5 [label="Attention_AllReduce_0_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_0_6_0 [label="QKV_Proj_0_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_0_6_0 [label="Attention_0_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_0_6_0 [label="Attention_Output_0_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_0_6_1 [label="QKV_Proj_0_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_0_6_1 [label="Attention_0_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_0_6_1 [label="Attention_Output_0_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_0_6_2 [label="QKV_Proj_0_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_0_6_2 [label="Attention_0_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_0_6_2 [label="Attention_Output_0_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_0_6_3 [label="QKV_Proj_0_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_0_6_3 [label="Attention_0_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_0_6_3 [label="Attention_Output_0_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	attn_allreduce_0_6 [label="Attention_AllReduce_0_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_0_7_0 [label="QKV_Proj_0_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_0_7_0 [label="Attention_0_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_0_7_0 [label="Attention_Output_0_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_0_7_1 [label="QKV_Proj_0_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_0_7_1 [label="Attention_0_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_0_7_1 [label="Attention_Output_0_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_0_7_2 [label="QKV_Proj_0_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_0_7_2 [label="Attention_0_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_0_7_2 [label="Attention_Output_0_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_0_7_3 [label="QKV_Proj_0_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_0_7_3 [label="Attention_0_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_0_7_3 [label="Attention_Output_0_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	attn_allreduce_0_7 [label="Attention_AllReduce_0_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_0_8_0 [label="QKV_Proj_0_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_0_8_0 [label="Attention_0_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_0_8_0 [label="Attention_Output_0_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_0_8_1 [label="QKV_Proj_0_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_0_8_1 [label="Attention_0_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_0_8_1 [label="Attention_Output_0_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_0_8_2 [label="QKV_Proj_0_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_0_8_2 [label="Attention_0_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_0_8_2 [label="Attention_Output_0_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_0_8_3 [label="QKV_Proj_0_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_0_8_3 [label="Attention_0_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_0_8_3 [label="Attention_Output_0_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	attn_allreduce_0_8 [label="Attention_AllReduce_0_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_0_9_0 [label="QKV_Proj_0_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_0_9_0 [label="Attention_0_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_0_9_0 [label="Attention_Output_0_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_0_9_1 [label="QKV_Proj_0_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_0_9_1 [label="Attention_0_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_0_9_1 [label="Attention_Output_0_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_0_9_2 [label="QKV_Proj_0_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_0_9_2 [label="Attention_0_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_0_9_2 [label="Attention_Output_0_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_0_9_3 [label="QKV_Proj_0_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_0_9_3 [label="Attention_0_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_0_9_3 [label="Attention_Output_0_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	attn_allreduce_0_9 [label="Attention_AllReduce_0_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_0_10_0 [label="QKV_Proj_0_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_0_10_0 [label="Attention_0_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_0_10_0 [label="Attention_Output_0_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_0_10_1 [label="QKV_Proj_0_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_0_10_1 [label="Attention_0_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_0_10_1 [label="Attention_Output_0_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_0_10_2 [label="QKV_Proj_0_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_0_10_2 [label="Attention_0_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_0_10_2 [label="Attention_Output_0_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_0_10_3 [label="QKV_Proj_0_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_0_10_3 [label="Attention_0_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_0_10_3 [label="Attention_Output_0_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	attn_allreduce_0_10 [label="Attention_AllReduce_0_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_0_11_0 [label="QKV_Proj_0_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_0_11_0 [label="Attention_0_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_0_11_0 [label="Attention_Output_0_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_0_11_1 [label="QKV_Proj_0_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_0_11_1 [label="Attention_0_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_0_11_1 [label="Attention_Output_0_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_0_11_2 [label="QKV_Proj_0_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_0_11_2 [label="Attention_0_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_0_11_2 [label="Attention_Output_0_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_0_11_3 [label="QKV_Proj_0_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_0_11_3 [label="Attention_0_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_0_11_3 [label="Attention_Output_0_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	attn_allreduce_0_11 [label="Attention_AllReduce_0_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_0_12_0 [label="QKV_Proj_0_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_0_12_0 [label="Attention_0_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_0_12_0 [label="Attention_Output_0_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_0_12_1 [label="QKV_Proj_0_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_0_12_1 [label="Attention_0_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_0_12_1 [label="Attention_Output_0_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_0_12_2 [label="QKV_Proj_0_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_0_12_2 [label="Attention_0_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_0_12_2 [label="Attention_Output_0_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_0_12_3 [label="QKV_Proj_0_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_0_12_3 [label="Attention_0_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_0_12_3 [label="Attention_Output_0_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	attn_allreduce_0_12 [label="Attention_AllReduce_0_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_0_13_0 [label="QKV_Proj_0_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_0_13_0 [label="Attention_0_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_0_13_0 [label="Attention_Output_0_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_0_13_1 [label="QKV_Proj_0_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_0_13_1 [label="Attention_0_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_0_13_1 [label="Attention_Output_0_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_0_13_2 [label="QKV_Proj_0_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_0_13_2 [label="Attention_0_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_0_13_2 [label="Attention_Output_0_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_0_13_3 [label="QKV_Proj_0_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_0_13_3 [label="Attention_0_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_0_13_3 [label="Attention_Output_0_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	attn_allreduce_0_13 [label="Attention_AllReduce_0_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_0_14_0 [label="QKV_Proj_0_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_0_14_0 [label="Attention_0_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_0_14_0 [label="Attention_Output_0_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_0_14_1 [label="QKV_Proj_0_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_0_14_1 [label="Attention_0_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_0_14_1 [label="Attention_Output_0_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_0_14_2 [label="QKV_Proj_0_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_0_14_2 [label="Attention_0_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_0_14_2 [label="Attention_Output_0_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_0_14_3 [label="QKV_Proj_0_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_0_14_3 [label="Attention_0_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_0_14_3 [label="Attention_Output_0_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	attn_allreduce_0_14 [label="Attention_AllReduce_0_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_0_15_0 [label="QKV_Proj_0_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_0_15_0 [label="Attention_0_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_0_15_0 [label="Attention_Output_0_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_0_15_1 [label="QKV_Proj_0_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_0_15_1 [label="Attention_0_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_0_15_1 [label="Attention_Output_0_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_0_15_2 [label="QKV_Proj_0_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_0_15_2 [label="Attention_0_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_0_15_2 [label="Attention_Output_0_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_0_15_3 [label="QKV_Proj_0_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_0_15_3 [label="Attention_0_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_0_15_3 [label="Attention_Output_0_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	attn_allreduce_0_15 [label="Attention_AllReduce_0_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_0_0_0 [label="MLP_Linear1_0_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_0_0_0 [label="GELU_0_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_0_0_0 [label="MLP_Linear2_0_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_0_0_1 [label="MLP_Linear1_0_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_0_0_1 [label="GELU_0_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_0_0_1 [label="MLP_Linear2_0_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_0_0_2 [label="MLP_Linear1_0_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_0_0_2 [label="GELU_0_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_0_0_2 [label="MLP_Linear2_0_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_0_0_3 [label="MLP_Linear1_0_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_0_0_3 [label="GELU_0_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_0_0_3 [label="MLP_Linear2_0_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp_allreduce_0_0 [label="MLP_AllReduce_0_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_0_1_0 [label="MLP_Linear1_0_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_0_1_0 [label="GELU_0_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_0_1_0 [label="MLP_Linear2_0_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_0_1_1 [label="MLP_Linear1_0_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_0_1_1 [label="GELU_0_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_0_1_1 [label="MLP_Linear2_0_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_0_1_2 [label="MLP_Linear1_0_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_0_1_2 [label="GELU_0_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_0_1_2 [label="MLP_Linear2_0_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_0_1_3 [label="MLP_Linear1_0_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_0_1_3 [label="GELU_0_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_0_1_3 [label="MLP_Linear2_0_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp_allreduce_0_1 [label="MLP_AllReduce_0_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_0_2_0 [label="MLP_Linear1_0_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_0_2_0 [label="GELU_0_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_0_2_0 [label="MLP_Linear2_0_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_0_2_1 [label="MLP_Linear1_0_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_0_2_1 [label="GELU_0_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_0_2_1 [label="MLP_Linear2_0_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_0_2_2 [label="MLP_Linear1_0_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_0_2_2 [label="GELU_0_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_0_2_2 [label="MLP_Linear2_0_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_0_2_3 [label="MLP_Linear1_0_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_0_2_3 [label="GELU_0_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_0_2_3 [label="MLP_Linear2_0_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp_allreduce_0_2 [label="MLP_AllReduce_0_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_0_3_0 [label="MLP_Linear1_0_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_0_3_0 [label="GELU_0_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_0_3_0 [label="MLP_Linear2_0_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_0_3_1 [label="MLP_Linear1_0_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_0_3_1 [label="GELU_0_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_0_3_1 [label="MLP_Linear2_0_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_0_3_2 [label="MLP_Linear1_0_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_0_3_2 [label="GELU_0_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_0_3_2 [label="MLP_Linear2_0_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_0_3_3 [label="MLP_Linear1_0_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_0_3_3 [label="GELU_0_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_0_3_3 [label="MLP_Linear2_0_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp_allreduce_0_3 [label="MLP_AllReduce_0_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_0_4_0 [label="MLP_Linear1_0_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_0_4_0 [label="GELU_0_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_0_4_0 [label="MLP_Linear2_0_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_0_4_1 [label="MLP_Linear1_0_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_0_4_1 [label="GELU_0_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_0_4_1 [label="MLP_Linear2_0_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_0_4_2 [label="MLP_Linear1_0_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_0_4_2 [label="GELU_0_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_0_4_2 [label="MLP_Linear2_0_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_0_4_3 [label="MLP_Linear1_0_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_0_4_3 [label="GELU_0_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_0_4_3 [label="MLP_Linear2_0_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp_allreduce_0_4 [label="MLP_AllReduce_0_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_0_5_0 [label="MLP_Linear1_0_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_0_5_0 [label="GELU_0_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_0_5_0 [label="MLP_Linear2_0_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_0_5_1 [label="MLP_Linear1_0_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_0_5_1 [label="GELU_0_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_0_5_1 [label="MLP_Linear2_0_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_0_5_2 [label="MLP_Linear1_0_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_0_5_2 [label="GELU_0_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_0_5_2 [label="MLP_Linear2_0_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_0_5_3 [label="MLP_Linear1_0_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_0_5_3 [label="GELU_0_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_0_5_3 [label="MLP_Linear2_0_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp_allreduce_0_5 [label="MLP_AllReduce_0_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_0_6_0 [label="MLP_Linear1_0_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_0_6_0 [label="GELU_0_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_0_6_0 [label="MLP_Linear2_0_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_0_6_1 [label="MLP_Linear1_0_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_0_6_1 [label="GELU_0_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_0_6_1 [label="MLP_Linear2_0_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_0_6_2 [label="MLP_Linear1_0_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_0_6_2 [label="GELU_0_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_0_6_2 [label="MLP_Linear2_0_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_0_6_3 [label="MLP_Linear1_0_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_0_6_3 [label="GELU_0_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_0_6_3 [label="MLP_Linear2_0_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp_allreduce_0_6 [label="MLP_AllReduce_0_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_0_7_0 [label="MLP_Linear1_0_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_0_7_0 [label="GELU_0_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_0_7_0 [label="MLP_Linear2_0_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_0_7_1 [label="MLP_Linear1_0_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_0_7_1 [label="GELU_0_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_0_7_1 [label="MLP_Linear2_0_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_0_7_2 [label="MLP_Linear1_0_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_0_7_2 [label="GELU_0_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_0_7_2 [label="MLP_Linear2_0_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_0_7_3 [label="MLP_Linear1_0_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_0_7_3 [label="GELU_0_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_0_7_3 [label="MLP_Linear2_0_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp_allreduce_0_7 [label="MLP_AllReduce_0_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_0_8_0 [label="MLP_Linear1_0_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_0_8_0 [label="GELU_0_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_0_8_0 [label="MLP_Linear2_0_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_0_8_1 [label="MLP_Linear1_0_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_0_8_1 [label="GELU_0_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_0_8_1 [label="MLP_Linear2_0_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_0_8_2 [label="MLP_Linear1_0_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_0_8_2 [label="GELU_0_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_0_8_2 [label="MLP_Linear2_0_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_0_8_3 [label="MLP_Linear1_0_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_0_8_3 [label="GELU_0_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_0_8_3 [label="MLP_Linear2_0_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp_allreduce_0_8 [label="MLP_AllReduce_0_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_0_9_0 [label="MLP_Linear1_0_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_0_9_0 [label="GELU_0_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_0_9_0 [label="MLP_Linear2_0_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_0_9_1 [label="MLP_Linear1_0_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_0_9_1 [label="GELU_0_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_0_9_1 [label="MLP_Linear2_0_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_0_9_2 [label="MLP_Linear1_0_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_0_9_2 [label="GELU_0_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_0_9_2 [label="MLP_Linear2_0_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_0_9_3 [label="MLP_Linear1_0_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_0_9_3 [label="GELU_0_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_0_9_3 [label="MLP_Linear2_0_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp_allreduce_0_9 [label="MLP_AllReduce_0_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_0_10_0 [label="MLP_Linear1_0_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_0_10_0 [label="GELU_0_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_0_10_0 [label="MLP_Linear2_0_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_0_10_1 [label="MLP_Linear1_0_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_0_10_1 [label="GELU_0_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_0_10_1 [label="MLP_Linear2_0_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_0_10_2 [label="MLP_Linear1_0_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_0_10_2 [label="GELU_0_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_0_10_2 [label="MLP_Linear2_0_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_0_10_3 [label="MLP_Linear1_0_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_0_10_3 [label="GELU_0_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_0_10_3 [label="MLP_Linear2_0_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp_allreduce_0_10 [label="MLP_AllReduce_0_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_0_11_0 [label="MLP_Linear1_0_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_0_11_0 [label="GELU_0_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_0_11_0 [label="MLP_Linear2_0_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_0_11_1 [label="MLP_Linear1_0_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_0_11_1 [label="GELU_0_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_0_11_1 [label="MLP_Linear2_0_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_0_11_2 [label="MLP_Linear1_0_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_0_11_2 [label="GELU_0_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_0_11_2 [label="MLP_Linear2_0_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_0_11_3 [label="MLP_Linear1_0_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_0_11_3 [label="GELU_0_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_0_11_3 [label="MLP_Linear2_0_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp_allreduce_0_11 [label="MLP_AllReduce_0_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_0_12_0 [label="MLP_Linear1_0_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_0_12_0 [label="GELU_0_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_0_12_0 [label="MLP_Linear2_0_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_0_12_1 [label="MLP_Linear1_0_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_0_12_1 [label="GELU_0_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_0_12_1 [label="MLP_Linear2_0_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_0_12_2 [label="MLP_Linear1_0_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_0_12_2 [label="GELU_0_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_0_12_2 [label="MLP_Linear2_0_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_0_12_3 [label="MLP_Linear1_0_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_0_12_3 [label="GELU_0_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_0_12_3 [label="MLP_Linear2_0_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp_allreduce_0_12 [label="MLP_AllReduce_0_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_0_13_0 [label="MLP_Linear1_0_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_0_13_0 [label="GELU_0_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_0_13_0 [label="MLP_Linear2_0_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_0_13_1 [label="MLP_Linear1_0_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_0_13_1 [label="GELU_0_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_0_13_1 [label="MLP_Linear2_0_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_0_13_2 [label="MLP_Linear1_0_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_0_13_2 [label="GELU_0_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_0_13_2 [label="MLP_Linear2_0_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_0_13_3 [label="MLP_Linear1_0_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_0_13_3 [label="GELU_0_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_0_13_3 [label="MLP_Linear2_0_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp_allreduce_0_13 [label="MLP_AllReduce_0_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_0_14_0 [label="MLP_Linear1_0_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_0_14_0 [label="GELU_0_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_0_14_0 [label="MLP_Linear2_0_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_0_14_1 [label="MLP_Linear1_0_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_0_14_1 [label="GELU_0_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_0_14_1 [label="MLP_Linear2_0_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_0_14_2 [label="MLP_Linear1_0_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_0_14_2 [label="GELU_0_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_0_14_2 [label="MLP_Linear2_0_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_0_14_3 [label="MLP_Linear1_0_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_0_14_3 [label="GELU_0_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_0_14_3 [label="MLP_Linear2_0_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp_allreduce_0_14 [label="MLP_AllReduce_0_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_0_15_0 [label="MLP_Linear1_0_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_0_15_0 [label="GELU_0_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_0_15_0 [label="MLP_Linear2_0_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_0_15_1 [label="MLP_Linear1_0_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_0_15_1 [label="GELU_0_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_0_15_1 [label="MLP_Linear2_0_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_0_15_2 [label="MLP_Linear1_0_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_0_15_2 [label="GELU_0_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_0_15_2 [label="MLP_Linear2_0_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_0_15_3 [label="MLP_Linear1_0_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_0_15_3 [label="GELU_0_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_0_15_3 [label="MLP_Linear2_0_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp_allreduce_0_15 [label="MLP_AllReduce_0_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	expert_route_0_0 [label="Expert_Route_0_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_0_1 [label="Expert_Route_0_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_0_2 [label="Expert_Route_0_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_0_3 [label="Expert_Route_0_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_0_4 [label="Expert_Route_0_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_0_5 [label="Expert_Route_0_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_0_6 [label="Expert_Route_0_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_0_7 [label="Expert_Route_0_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_0_8 [label="Expert_Route_0_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_0_9 [label="Expert_Route_0_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_0_10 [label="Expert_Route_0_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_0_11 [label="Expert_Route_0_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_0_12 [label="Expert_Route_0_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_0_13 [label="Expert_Route_0_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_0_14 [label="Expert_Route_0_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_0_15 [label="Expert_Route_0_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	qkv_1_0_0 [label="QKV_Proj_1_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_1_0_0 [label="Attention_1_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_1_0_0 [label="Attention_Output_1_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_1_0_1 [label="QKV_Proj_1_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_1_0_1 [label="Attention_1_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_1_0_1 [label="Attention_Output_1_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_1_0_2 [label="QKV_Proj_1_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_1_0_2 [label="Attention_1_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_1_0_2 [label="Attention_Output_1_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_1_0_3 [label="QKV_Proj_1_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_1_0_3 [label="Attention_1_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_1_0_3 [label="Attention_Output_1_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	attn_allreduce_1_0 [label="Attention_AllReduce_1_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_1_1_0 [label="QKV_Proj_1_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_1_1_0 [label="Attention_1_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_1_1_0 [label="Attention_Output_1_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_1_1_1 [label="QKV_Proj_1_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_1_1_1 [label="Attention_1_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_1_1_1 [label="Attention_Output_1_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_1_1_2 [label="QKV_Proj_1_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_1_1_2 [label="Attention_1_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_1_1_2 [label="Attention_Output_1_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_1_1_3 [label="QKV_Proj_1_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_1_1_3 [label="Attention_1_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_1_1_3 [label="Attention_Output_1_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	attn_allreduce_1_1 [label="Attention_AllReduce_1_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_1_2_0 [label="QKV_Proj_1_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_1_2_0 [label="Attention_1_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_1_2_0 [label="Attention_Output_1_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_1_2_1 [label="QKV_Proj_1_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_1_2_1 [label="Attention_1_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_1_2_1 [label="Attention_Output_1_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_1_2_2 [label="QKV_Proj_1_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_1_2_2 [label="Attention_1_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_1_2_2 [label="Attention_Output_1_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_1_2_3 [label="QKV_Proj_1_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_1_2_3 [label="Attention_1_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_1_2_3 [label="Attention_Output_1_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	attn_allreduce_1_2 [label="Attention_AllReduce_1_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_1_3_0 [label="QKV_Proj_1_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_1_3_0 [label="Attention_1_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_1_3_0 [label="Attention_Output_1_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_1_3_1 [label="QKV_Proj_1_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_1_3_1 [label="Attention_1_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_1_3_1 [label="Attention_Output_1_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_1_3_2 [label="QKV_Proj_1_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_1_3_2 [label="Attention_1_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_1_3_2 [label="Attention_Output_1_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_1_3_3 [label="QKV_Proj_1_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_1_3_3 [label="Attention_1_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_1_3_3 [label="Attention_Output_1_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	attn_allreduce_1_3 [label="Attention_AllReduce_1_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_1_4_0 [label="QKV_Proj_1_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_1_4_0 [label="Attention_1_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_1_4_0 [label="Attention_Output_1_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_1_4_1 [label="QKV_Proj_1_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_1_4_1 [label="Attention_1_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_1_4_1 [label="Attention_Output_1_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_1_4_2 [label="QKV_Proj_1_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_1_4_2 [label="Attention_1_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_1_4_2 [label="Attention_Output_1_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_1_4_3 [label="QKV_Proj_1_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_1_4_3 [label="Attention_1_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_1_4_3 [label="Attention_Output_1_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	attn_allreduce_1_4 [label="Attention_AllReduce_1_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_1_5_0 [label="QKV_Proj_1_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_1_5_0 [label="Attention_1_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_1_5_0 [label="Attention_Output_1_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_1_5_1 [label="QKV_Proj_1_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_1_5_1 [label="Attention_1_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_1_5_1 [label="Attention_Output_1_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_1_5_2 [label="QKV_Proj_1_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_1_5_2 [label="Attention_1_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_1_5_2 [label="Attention_Output_1_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_1_5_3 [label="QKV_Proj_1_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_1_5_3 [label="Attention_1_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_1_5_3 [label="Attention_Output_1_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	attn_allreduce_1_5 [label="Attention_AllReduce_1_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_1_6_0 [label="QKV_Proj_1_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_1_6_0 [label="Attention_1_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_1_6_0 [label="Attention_Output_1_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_1_6_1 [label="QKV_Proj_1_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_1_6_1 [label="Attention_1_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_1_6_1 [label="Attention_Output_1_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_1_6_2 [label="QKV_Proj_1_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_1_6_2 [label="Attention_1_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_1_6_2 [label="Attention_Output_1_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_1_6_3 [label="QKV_Proj_1_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_1_6_3 [label="Attention_1_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_1_6_3 [label="Attention_Output_1_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	attn_allreduce_1_6 [label="Attention_AllReduce_1_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_1_7_0 [label="QKV_Proj_1_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_1_7_0 [label="Attention_1_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_1_7_0 [label="Attention_Output_1_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_1_7_1 [label="QKV_Proj_1_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_1_7_1 [label="Attention_1_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_1_7_1 [label="Attention_Output_1_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_1_7_2 [label="QKV_Proj_1_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_1_7_2 [label="Attention_1_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_1_7_2 [label="Attention_Output_1_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_1_7_3 [label="QKV_Proj_1_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_1_7_3 [label="Attention_1_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_1_7_3 [label="Attention_Output_1_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	attn_allreduce_1_7 [label="Attention_AllReduce_1_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_1_8_0 [label="QKV_Proj_1_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_1_8_0 [label="Attention_1_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_1_8_0 [label="Attention_Output_1_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_1_8_1 [label="QKV_Proj_1_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_1_8_1 [label="Attention_1_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_1_8_1 [label="Attention_Output_1_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_1_8_2 [label="QKV_Proj_1_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_1_8_2 [label="Attention_1_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_1_8_2 [label="Attention_Output_1_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_1_8_3 [label="QKV_Proj_1_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_1_8_3 [label="Attention_1_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_1_8_3 [label="Attention_Output_1_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	attn_allreduce_1_8 [label="Attention_AllReduce_1_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_1_9_0 [label="QKV_Proj_1_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_1_9_0 [label="Attention_1_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_1_9_0 [label="Attention_Output_1_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_1_9_1 [label="QKV_Proj_1_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_1_9_1 [label="Attention_1_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_1_9_1 [label="Attention_Output_1_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_1_9_2 [label="QKV_Proj_1_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_1_9_2 [label="Attention_1_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_1_9_2 [label="Attention_Output_1_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_1_9_3 [label="QKV_Proj_1_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_1_9_3 [label="Attention_1_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_1_9_3 [label="Attention_Output_1_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	attn_allreduce_1_9 [label="Attention_AllReduce_1_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_1_10_0 [label="QKV_Proj_1_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_1_10_0 [label="Attention_1_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_1_10_0 [label="Attention_Output_1_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_1_10_1 [label="QKV_Proj_1_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_1_10_1 [label="Attention_1_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_1_10_1 [label="Attention_Output_1_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_1_10_2 [label="QKV_Proj_1_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_1_10_2 [label="Attention_1_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_1_10_2 [label="Attention_Output_1_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_1_10_3 [label="QKV_Proj_1_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_1_10_3 [label="Attention_1_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_1_10_3 [label="Attention_Output_1_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	attn_allreduce_1_10 [label="Attention_AllReduce_1_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_1_11_0 [label="QKV_Proj_1_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_1_11_0 [label="Attention_1_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_1_11_0 [label="Attention_Output_1_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_1_11_1 [label="QKV_Proj_1_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_1_11_1 [label="Attention_1_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_1_11_1 [label="Attention_Output_1_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_1_11_2 [label="QKV_Proj_1_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_1_11_2 [label="Attention_1_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_1_11_2 [label="Attention_Output_1_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_1_11_3 [label="QKV_Proj_1_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_1_11_3 [label="Attention_1_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_1_11_3 [label="Attention_Output_1_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	attn_allreduce_1_11 [label="Attention_AllReduce_1_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_1_12_0 [label="QKV_Proj_1_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_1_12_0 [label="Attention_1_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_1_12_0 [label="Attention_Output_1_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_1_12_1 [label="QKV_Proj_1_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_1_12_1 [label="Attention_1_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_1_12_1 [label="Attention_Output_1_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_1_12_2 [label="QKV_Proj_1_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_1_12_2 [label="Attention_1_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_1_12_2 [label="Attention_Output_1_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_1_12_3 [label="QKV_Proj_1_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_1_12_3 [label="Attention_1_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_1_12_3 [label="Attention_Output_1_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	attn_allreduce_1_12 [label="Attention_AllReduce_1_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_1_13_0 [label="QKV_Proj_1_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_1_13_0 [label="Attention_1_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_1_13_0 [label="Attention_Output_1_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_1_13_1 [label="QKV_Proj_1_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_1_13_1 [label="Attention_1_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_1_13_1 [label="Attention_Output_1_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_1_13_2 [label="QKV_Proj_1_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_1_13_2 [label="Attention_1_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_1_13_2 [label="Attention_Output_1_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_1_13_3 [label="QKV_Proj_1_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_1_13_3 [label="Attention_1_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_1_13_3 [label="Attention_Output_1_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	attn_allreduce_1_13 [label="Attention_AllReduce_1_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_1_14_0 [label="QKV_Proj_1_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_1_14_0 [label="Attention_1_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_1_14_0 [label="Attention_Output_1_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_1_14_1 [label="QKV_Proj_1_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_1_14_1 [label="Attention_1_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_1_14_1 [label="Attention_Output_1_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_1_14_2 [label="QKV_Proj_1_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_1_14_2 [label="Attention_1_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_1_14_2 [label="Attention_Output_1_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_1_14_3 [label="QKV_Proj_1_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_1_14_3 [label="Attention_1_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_1_14_3 [label="Attention_Output_1_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	attn_allreduce_1_14 [label="Attention_AllReduce_1_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_1_15_0 [label="QKV_Proj_1_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_1_15_0 [label="Attention_1_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_1_15_0 [label="Attention_Output_1_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_1_15_1 [label="QKV_Proj_1_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_1_15_1 [label="Attention_1_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_1_15_1 [label="Attention_Output_1_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_1_15_2 [label="QKV_Proj_1_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_1_15_2 [label="Attention_1_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_1_15_2 [label="Attention_Output_1_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_1_15_3 [label="QKV_Proj_1_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_1_15_3 [label="Attention_1_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_1_15_3 [label="Attention_Output_1_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	attn_allreduce_1_15 [label="Attention_AllReduce_1_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_1_0_0 [label="MLP_Linear1_1_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_1_0_0 [label="GELU_1_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_1_0_0 [label="MLP_Linear2_1_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_1_0_1 [label="MLP_Linear1_1_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_1_0_1 [label="GELU_1_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_1_0_1 [label="MLP_Linear2_1_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_1_0_2 [label="MLP_Linear1_1_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_1_0_2 [label="GELU_1_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_1_0_2 [label="MLP_Linear2_1_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_1_0_3 [label="MLP_Linear1_1_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_1_0_3 [label="GELU_1_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_1_0_3 [label="MLP_Linear2_1_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp_allreduce_1_0 [label="MLP_AllReduce_1_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_1_1_0 [label="MLP_Linear1_1_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_1_1_0 [label="GELU_1_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_1_1_0 [label="MLP_Linear2_1_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_1_1_1 [label="MLP_Linear1_1_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_1_1_1 [label="GELU_1_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_1_1_1 [label="MLP_Linear2_1_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_1_1_2 [label="MLP_Linear1_1_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_1_1_2 [label="GELU_1_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_1_1_2 [label="MLP_Linear2_1_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_1_1_3 [label="MLP_Linear1_1_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_1_1_3 [label="GELU_1_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_1_1_3 [label="MLP_Linear2_1_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp_allreduce_1_1 [label="MLP_AllReduce_1_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_1_2_0 [label="MLP_Linear1_1_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_1_2_0 [label="GELU_1_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_1_2_0 [label="MLP_Linear2_1_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_1_2_1 [label="MLP_Linear1_1_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_1_2_1 [label="GELU_1_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_1_2_1 [label="MLP_Linear2_1_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_1_2_2 [label="MLP_Linear1_1_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_1_2_2 [label="GELU_1_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_1_2_2 [label="MLP_Linear2_1_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_1_2_3 [label="MLP_Linear1_1_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_1_2_3 [label="GELU_1_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_1_2_3 [label="MLP_Linear2_1_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp_allreduce_1_2 [label="MLP_AllReduce_1_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_1_3_0 [label="MLP_Linear1_1_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_1_3_0 [label="GELU_1_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_1_3_0 [label="MLP_Linear2_1_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_1_3_1 [label="MLP_Linear1_1_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_1_3_1 [label="GELU_1_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_1_3_1 [label="MLP_Linear2_1_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_1_3_2 [label="MLP_Linear1_1_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_1_3_2 [label="GELU_1_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_1_3_2 [label="MLP_Linear2_1_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_1_3_3 [label="MLP_Linear1_1_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_1_3_3 [label="GELU_1_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_1_3_3 [label="MLP_Linear2_1_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp_allreduce_1_3 [label="MLP_AllReduce_1_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_1_4_0 [label="MLP_Linear1_1_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_1_4_0 [label="GELU_1_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_1_4_0 [label="MLP_Linear2_1_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_1_4_1 [label="MLP_Linear1_1_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_1_4_1 [label="GELU_1_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_1_4_1 [label="MLP_Linear2_1_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_1_4_2 [label="MLP_Linear1_1_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_1_4_2 [label="GELU_1_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_1_4_2 [label="MLP_Linear2_1_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_1_4_3 [label="MLP_Linear1_1_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_1_4_3 [label="GELU_1_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_1_4_3 [label="MLP_Linear2_1_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp_allreduce_1_4 [label="MLP_AllReduce_1_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_1_5_0 [label="MLP_Linear1_1_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_1_5_0 [label="GELU_1_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_1_5_0 [label="MLP_Linear2_1_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_1_5_1 [label="MLP_Linear1_1_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_1_5_1 [label="GELU_1_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_1_5_1 [label="MLP_Linear2_1_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_1_5_2 [label="MLP_Linear1_1_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_1_5_2 [label="GELU_1_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_1_5_2 [label="MLP_Linear2_1_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_1_5_3 [label="MLP_Linear1_1_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_1_5_3 [label="GELU_1_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_1_5_3 [label="MLP_Linear2_1_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp_allreduce_1_5 [label="MLP_AllReduce_1_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_1_6_0 [label="MLP_Linear1_1_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_1_6_0 [label="GELU_1_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_1_6_0 [label="MLP_Linear2_1_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_1_6_1 [label="MLP_Linear1_1_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_1_6_1 [label="GELU_1_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_1_6_1 [label="MLP_Linear2_1_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_1_6_2 [label="MLP_Linear1_1_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_1_6_2 [label="GELU_1_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_1_6_2 [label="MLP_Linear2_1_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_1_6_3 [label="MLP_Linear1_1_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_1_6_3 [label="GELU_1_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_1_6_3 [label="MLP_Linear2_1_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp_allreduce_1_6 [label="MLP_AllReduce_1_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_1_7_0 [label="MLP_Linear1_1_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_1_7_0 [label="GELU_1_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_1_7_0 [label="MLP_Linear2_1_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_1_7_1 [label="MLP_Linear1_1_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_1_7_1 [label="GELU_1_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_1_7_1 [label="MLP_Linear2_1_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_1_7_2 [label="MLP_Linear1_1_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_1_7_2 [label="GELU_1_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_1_7_2 [label="MLP_Linear2_1_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_1_7_3 [label="MLP_Linear1_1_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_1_7_3 [label="GELU_1_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_1_7_3 [label="MLP_Linear2_1_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp_allreduce_1_7 [label="MLP_AllReduce_1_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_1_8_0 [label="MLP_Linear1_1_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_1_8_0 [label="GELU_1_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_1_8_0 [label="MLP_Linear2_1_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_1_8_1 [label="MLP_Linear1_1_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_1_8_1 [label="GELU_1_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_1_8_1 [label="MLP_Linear2_1_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_1_8_2 [label="MLP_Linear1_1_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_1_8_2 [label="GELU_1_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_1_8_2 [label="MLP_Linear2_1_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_1_8_3 [label="MLP_Linear1_1_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_1_8_3 [label="GELU_1_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_1_8_3 [label="MLP_Linear2_1_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp_allreduce_1_8 [label="MLP_AllReduce_1_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_1_9_0 [label="MLP_Linear1_1_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_1_9_0 [label="GELU_1_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_1_9_0 [label="MLP_Linear2_1_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_1_9_1 [label="MLP_Linear1_1_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_1_9_1 [label="GELU_1_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_1_9_1 [label="MLP_Linear2_1_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_1_9_2 [label="MLP_Linear1_1_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_1_9_2 [label="GELU_1_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_1_9_2 [label="MLP_Linear2_1_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_1_9_3 [label="MLP_Linear1_1_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_1_9_3 [label="GELU_1_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_1_9_3 [label="MLP_Linear2_1_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp_allreduce_1_9 [label="MLP_AllReduce_1_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_1_10_0 [label="MLP_Linear1_1_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_1_10_0 [label="GELU_1_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_1_10_0 [label="MLP_Linear2_1_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_1_10_1 [label="MLP_Linear1_1_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_1_10_1 [label="GELU_1_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_1_10_1 [label="MLP_Linear2_1_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_1_10_2 [label="MLP_Linear1_1_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_1_10_2 [label="GELU_1_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_1_10_2 [label="MLP_Linear2_1_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_1_10_3 [label="MLP_Linear1_1_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_1_10_3 [label="GELU_1_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_1_10_3 [label="MLP_Linear2_1_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp_allreduce_1_10 [label="MLP_AllReduce_1_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_1_11_0 [label="MLP_Linear1_1_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_1_11_0 [label="GELU_1_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_1_11_0 [label="MLP_Linear2_1_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_1_11_1 [label="MLP_Linear1_1_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_1_11_1 [label="GELU_1_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_1_11_1 [label="MLP_Linear2_1_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_1_11_2 [label="MLP_Linear1_1_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_1_11_2 [label="GELU_1_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_1_11_2 [label="MLP_Linear2_1_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_1_11_3 [label="MLP_Linear1_1_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_1_11_3 [label="GELU_1_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_1_11_3 [label="MLP_Linear2_1_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp_allreduce_1_11 [label="MLP_AllReduce_1_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_1_12_0 [label="MLP_Linear1_1_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_1_12_0 [label="GELU_1_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_1_12_0 [label="MLP_Linear2_1_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_1_12_1 [label="MLP_Linear1_1_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_1_12_1 [label="GELU_1_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_1_12_1 [label="MLP_Linear2_1_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_1_12_2 [label="MLP_Linear1_1_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_1_12_2 [label="GELU_1_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_1_12_2 [label="MLP_Linear2_1_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_1_12_3 [label="MLP_Linear1_1_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_1_12_3 [label="GELU_1_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_1_12_3 [label="MLP_Linear2_1_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp_allreduce_1_12 [label="MLP_AllReduce_1_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_1_13_0 [label="MLP_Linear1_1_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_1_13_0 [label="GELU_1_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_1_13_0 [label="MLP_Linear2_1_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_1_13_1 [label="MLP_Linear1_1_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_1_13_1 [label="GELU_1_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_1_13_1 [label="MLP_Linear2_1_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_1_13_2 [label="MLP_Linear1_1_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_1_13_2 [label="GELU_1_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_1_13_2 [label="MLP_Linear2_1_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_1_13_3 [label="MLP_Linear1_1_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_1_13_3 [label="GELU_1_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_1_13_3 [label="MLP_Linear2_1_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp_allreduce_1_13 [label="MLP_AllReduce_1_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_1_14_0 [label="MLP_Linear1_1_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_1_14_0 [label="GELU_1_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_1_14_0 [label="MLP_Linear2_1_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_1_14_1 [label="MLP_Linear1_1_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_1_14_1 [label="GELU_1_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_1_14_1 [label="MLP_Linear2_1_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_1_14_2 [label="MLP_Linear1_1_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_1_14_2 [label="GELU_1_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_1_14_2 [label="MLP_Linear2_1_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_1_14_3 [label="MLP_Linear1_1_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_1_14_3 [label="GELU_1_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_1_14_3 [label="MLP_Linear2_1_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp_allreduce_1_14 [label="MLP_AllReduce_1_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_1_15_0 [label="MLP_Linear1_1_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_1_15_0 [label="GELU_1_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_1_15_0 [label="MLP_Linear2_1_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_1_15_1 [label="MLP_Linear1_1_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_1_15_1 [label="GELU_1_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_1_15_1 [label="MLP_Linear2_1_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_1_15_2 [label="MLP_Linear1_1_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_1_15_2 [label="GELU_1_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_1_15_2 [label="MLP_Linear2_1_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_1_15_3 [label="MLP_Linear1_1_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_1_15_3 [label="GELU_1_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_1_15_3 [label="MLP_Linear2_1_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp_allreduce_1_15 [label="MLP_AllReduce_1_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	expert_route_1_0 [label="Expert_Route_1_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_1_1 [label="Expert_Route_1_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_1_2 [label="Expert_Route_1_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_1_3 [label="Expert_Route_1_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_1_4 [label="Expert_Route_1_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_1_5 [label="Expert_Route_1_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_1_6 [label="Expert_Route_1_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_1_7 [label="Expert_Route_1_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_1_8 [label="Expert_Route_1_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_1_9 [label="Expert_Route_1_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_1_10 [label="Expert_Route_1_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_1_11 [label="Expert_Route_1_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_1_12 [label="Expert_Route_1_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_1_13 [label="Expert_Route_1_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_1_14 [label="Expert_Route_1_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_1_15 [label="Expert_Route_1_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	qkv_2_0_0 [label="QKV_Proj_2_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_2_0_0 [label="Attention_2_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_2_0_0 [label="Attention_Output_2_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_2_0_1 [label="QKV_Proj_2_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_2_0_1 [label="Attention_2_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_2_0_1 [label="Attention_Output_2_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_2_0_2 [label="QKV_Proj_2_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_2_0_2 [label="Attention_2_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_2_0_2 [label="Attention_Output_2_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_2_0_3 [label="QKV_Proj_2_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_2_0_3 [label="Attention_2_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_2_0_3 [label="Attention_Output_2_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	attn_allreduce_2_0 [label="Attention_AllReduce_2_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_2_1_0 [label="QKV_Proj_2_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_2_1_0 [label="Attention_2_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_2_1_0 [label="Attention_Output_2_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_2_1_1 [label="QKV_Proj_2_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_2_1_1 [label="Attention_2_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_2_1_1 [label="Attention_Output_2_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_2_1_2 [label="QKV_Proj_2_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_2_1_2 [label="Attention_2_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_2_1_2 [label="Attention_Output_2_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_2_1_3 [label="QKV_Proj_2_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_2_1_3 [label="Attention_2_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_2_1_3 [label="Attention_Output_2_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	attn_allreduce_2_1 [label="Attention_AllReduce_2_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_2_2_0 [label="QKV_Proj_2_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_2_2_0 [label="Attention_2_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_2_2_0 [label="Attention_Output_2_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_2_2_1 [label="QKV_Proj_2_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_2_2_1 [label="Attention_2_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_2_2_1 [label="Attention_Output_2_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_2_2_2 [label="QKV_Proj_2_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_2_2_2 [label="Attention_2_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_2_2_2 [label="Attention_Output_2_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_2_2_3 [label="QKV_Proj_2_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_2_2_3 [label="Attention_2_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_2_2_3 [label="Attention_Output_2_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	attn_allreduce_2_2 [label="Attention_AllReduce_2_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_2_3_0 [label="QKV_Proj_2_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_2_3_0 [label="Attention_2_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_2_3_0 [label="Attention_Output_2_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_2_3_1 [label="QKV_Proj_2_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_2_3_1 [label="Attention_2_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_2_3_1 [label="Attention_Output_2_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_2_3_2 [label="QKV_Proj_2_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_2_3_2 [label="Attention_2_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_2_3_2 [label="Attention_Output_2_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_2_3_3 [label="QKV_Proj_2_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_2_3_3 [label="Attention_2_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_2_3_3 [label="Attention_Output_2_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	attn_allreduce_2_3 [label="Attention_AllReduce_2_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_2_4_0 [label="QKV_Proj_2_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_2_4_0 [label="Attention_2_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_2_4_0 [label="Attention_Output_2_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_2_4_1 [label="QKV_Proj_2_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_2_4_1 [label="Attention_2_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_2_4_1 [label="Attention_Output_2_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_2_4_2 [label="QKV_Proj_2_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_2_4_2 [label="Attention_2_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_2_4_2 [label="Attention_Output_2_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_2_4_3 [label="QKV_Proj_2_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_2_4_3 [label="Attention_2_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_2_4_3 [label="Attention_Output_2_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	attn_allreduce_2_4 [label="Attention_AllReduce_2_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_2_5_0 [label="QKV_Proj_2_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_2_5_0 [label="Attention_2_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_2_5_0 [label="Attention_Output_2_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_2_5_1 [label="QKV_Proj_2_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_2_5_1 [label="Attention_2_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_2_5_1 [label="Attention_Output_2_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_2_5_2 [label="QKV_Proj_2_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_2_5_2 [label="Attention_2_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_2_5_2 [label="Attention_Output_2_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_2_5_3 [label="QKV_Proj_2_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_2_5_3 [label="Attention_2_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_2_5_3 [label="Attention_Output_2_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	attn_allreduce_2_5 [label="Attention_AllReduce_2_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_2_6_0 [label="QKV_Proj_2_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_2_6_0 [label="Attention_2_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_2_6_0 [label="Attention_Output_2_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_2_6_1 [label="QKV_Proj_2_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_2_6_1 [label="Attention_2_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_2_6_1 [label="Attention_Output_2_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_2_6_2 [label="QKV_Proj_2_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_2_6_2 [label="Attention_2_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_2_6_2 [label="Attention_Output_2_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_2_6_3 [label="QKV_Proj_2_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_2_6_3 [label="Attention_2_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_2_6_3 [label="Attention_Output_2_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	attn_allreduce_2_6 [label="Attention_AllReduce_2_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_2_7_0 [label="QKV_Proj_2_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_2_7_0 [label="Attention_2_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_2_7_0 [label="Attention_Output_2_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_2_7_1 [label="QKV_Proj_2_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_2_7_1 [label="Attention_2_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_2_7_1 [label="Attention_Output_2_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_2_7_2 [label="QKV_Proj_2_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_2_7_2 [label="Attention_2_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_2_7_2 [label="Attention_Output_2_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_2_7_3 [label="QKV_Proj_2_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_2_7_3 [label="Attention_2_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_2_7_3 [label="Attention_Output_2_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	attn_allreduce_2_7 [label="Attention_AllReduce_2_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_2_8_0 [label="QKV_Proj_2_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_2_8_0 [label="Attention_2_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_2_8_0 [label="Attention_Output_2_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_2_8_1 [label="QKV_Proj_2_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_2_8_1 [label="Attention_2_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_2_8_1 [label="Attention_Output_2_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_2_8_2 [label="QKV_Proj_2_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_2_8_2 [label="Attention_2_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_2_8_2 [label="Attention_Output_2_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_2_8_3 [label="QKV_Proj_2_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_2_8_3 [label="Attention_2_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_2_8_3 [label="Attention_Output_2_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	attn_allreduce_2_8 [label="Attention_AllReduce_2_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_2_9_0 [label="QKV_Proj_2_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_2_9_0 [label="Attention_2_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_2_9_0 [label="Attention_Output_2_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_2_9_1 [label="QKV_Proj_2_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_2_9_1 [label="Attention_2_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_2_9_1 [label="Attention_Output_2_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_2_9_2 [label="QKV_Proj_2_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_2_9_2 [label="Attention_2_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_2_9_2 [label="Attention_Output_2_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_2_9_3 [label="QKV_Proj_2_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_2_9_3 [label="Attention_2_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_2_9_3 [label="Attention_Output_2_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	attn_allreduce_2_9 [label="Attention_AllReduce_2_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_2_10_0 [label="QKV_Proj_2_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_2_10_0 [label="Attention_2_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_2_10_0 [label="Attention_Output_2_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_2_10_1 [label="QKV_Proj_2_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_2_10_1 [label="Attention_2_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_2_10_1 [label="Attention_Output_2_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_2_10_2 [label="QKV_Proj_2_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_2_10_2 [label="Attention_2_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_2_10_2 [label="Attention_Output_2_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_2_10_3 [label="QKV_Proj_2_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_2_10_3 [label="Attention_2_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_2_10_3 [label="Attention_Output_2_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	attn_allreduce_2_10 [label="Attention_AllReduce_2_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_2_11_0 [label="QKV_Proj_2_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_2_11_0 [label="Attention_2_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_2_11_0 [label="Attention_Output_2_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_2_11_1 [label="QKV_Proj_2_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_2_11_1 [label="Attention_2_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_2_11_1 [label="Attention_Output_2_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_2_11_2 [label="QKV_Proj_2_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_2_11_2 [label="Attention_2_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_2_11_2 [label="Attention_Output_2_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_2_11_3 [label="QKV_Proj_2_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_2_11_3 [label="Attention_2_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_2_11_3 [label="Attention_Output_2_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	attn_allreduce_2_11 [label="Attention_AllReduce_2_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_2_12_0 [label="QKV_Proj_2_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_2_12_0 [label="Attention_2_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_2_12_0 [label="Attention_Output_2_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_2_12_1 [label="QKV_Proj_2_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_2_12_1 [label="Attention_2_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_2_12_1 [label="Attention_Output_2_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_2_12_2 [label="QKV_Proj_2_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_2_12_2 [label="Attention_2_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_2_12_2 [label="Attention_Output_2_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_2_12_3 [label="QKV_Proj_2_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_2_12_3 [label="Attention_2_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_2_12_3 [label="Attention_Output_2_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	attn_allreduce_2_12 [label="Attention_AllReduce_2_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_2_13_0 [label="QKV_Proj_2_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_2_13_0 [label="Attention_2_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_2_13_0 [label="Attention_Output_2_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_2_13_1 [label="QKV_Proj_2_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_2_13_1 [label="Attention_2_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_2_13_1 [label="Attention_Output_2_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_2_13_2 [label="QKV_Proj_2_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_2_13_2 [label="Attention_2_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_2_13_2 [label="Attention_Output_2_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_2_13_3 [label="QKV_Proj_2_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_2_13_3 [label="Attention_2_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_2_13_3 [label="Attention_Output_2_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	attn_allreduce_2_13 [label="Attention_AllReduce_2_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_2_14_0 [label="QKV_Proj_2_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_2_14_0 [label="Attention_2_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_2_14_0 [label="Attention_Output_2_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_2_14_1 [label="QKV_Proj_2_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_2_14_1 [label="Attention_2_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_2_14_1 [label="Attention_Output_2_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_2_14_2 [label="QKV_Proj_2_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_2_14_2 [label="Attention_2_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_2_14_2 [label="Attention_Output_2_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_2_14_3 [label="QKV_Proj_2_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_2_14_3 [label="Attention_2_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_2_14_3 [label="Attention_Output_2_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	attn_allreduce_2_14 [label="Attention_AllReduce_2_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_2_15_0 [label="QKV_Proj_2_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_2_15_0 [label="Attention_2_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_2_15_0 [label="Attention_Output_2_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_2_15_1 [label="QKV_Proj_2_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_2_15_1 [label="Attention_2_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_2_15_1 [label="Attention_Output_2_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_2_15_2 [label="QKV_Proj_2_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_2_15_2 [label="Attention_2_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_2_15_2 [label="Attention_Output_2_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_2_15_3 [label="QKV_Proj_2_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_2_15_3 [label="Attention_2_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_2_15_3 [label="Attention_Output_2_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	attn_allreduce_2_15 [label="Attention_AllReduce_2_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_2_0_0 [label="MLP_Linear1_2_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_2_0_0 [label="GELU_2_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_2_0_0 [label="MLP_Linear2_2_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_2_0_1 [label="MLP_Linear1_2_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_2_0_1 [label="GELU_2_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_2_0_1 [label="MLP_Linear2_2_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_2_0_2 [label="MLP_Linear1_2_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_2_0_2 [label="GELU_2_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_2_0_2 [label="MLP_Linear2_2_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_2_0_3 [label="MLP_Linear1_2_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_2_0_3 [label="GELU_2_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_2_0_3 [label="MLP_Linear2_2_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp_allreduce_2_0 [label="MLP_AllReduce_2_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_2_1_0 [label="MLP_Linear1_2_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_2_1_0 [label="GELU_2_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_2_1_0 [label="MLP_Linear2_2_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_2_1_1 [label="MLP_Linear1_2_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_2_1_1 [label="GELU_2_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_2_1_1 [label="MLP_Linear2_2_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_2_1_2 [label="MLP_Linear1_2_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_2_1_2 [label="GELU_2_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_2_1_2 [label="MLP_Linear2_2_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_2_1_3 [label="MLP_Linear1_2_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_2_1_3 [label="GELU_2_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_2_1_3 [label="MLP_Linear2_2_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp_allreduce_2_1 [label="MLP_AllReduce_2_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_2_2_0 [label="MLP_Linear1_2_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_2_2_0 [label="GELU_2_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_2_2_0 [label="MLP_Linear2_2_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_2_2_1 [label="MLP_Linear1_2_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_2_2_1 [label="GELU_2_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_2_2_1 [label="MLP_Linear2_2_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_2_2_2 [label="MLP_Linear1_2_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_2_2_2 [label="GELU_2_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_2_2_2 [label="MLP_Linear2_2_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_2_2_3 [label="MLP_Linear1_2_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_2_2_3 [label="GELU_2_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_2_2_3 [label="MLP_Linear2_2_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp_allreduce_2_2 [label="MLP_AllReduce_2_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_2_3_0 [label="MLP_Linear1_2_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_2_3_0 [label="GELU_2_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_2_3_0 [label="MLP_Linear2_2_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_2_3_1 [label="MLP_Linear1_2_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_2_3_1 [label="GELU_2_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_2_3_1 [label="MLP_Linear2_2_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_2_3_2 [label="MLP_Linear1_2_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_2_3_2 [label="GELU_2_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_2_3_2 [label="MLP_Linear2_2_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_2_3_3 [label="MLP_Linear1_2_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_2_3_3 [label="GELU_2_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_2_3_3 [label="MLP_Linear2_2_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp_allreduce_2_3 [label="MLP_AllReduce_2_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_2_4_0 [label="MLP_Linear1_2_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_2_4_0 [label="GELU_2_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_2_4_0 [label="MLP_Linear2_2_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_2_4_1 [label="MLP_Linear1_2_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_2_4_1 [label="GELU_2_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_2_4_1 [label="MLP_Linear2_2_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_2_4_2 [label="MLP_Linear1_2_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_2_4_2 [label="GELU_2_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_2_4_2 [label="MLP_Linear2_2_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_2_4_3 [label="MLP_Linear1_2_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_2_4_3 [label="GELU_2_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_2_4_3 [label="MLP_Linear2_2_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp_allreduce_2_4 [label="MLP_AllReduce_2_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_2_5_0 [label="MLP_Linear1_2_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_2_5_0 [label="GELU_2_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_2_5_0 [label="MLP_Linear2_2_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_2_5_1 [label="MLP_Linear1_2_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_2_5_1 [label="GELU_2_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_2_5_1 [label="MLP_Linear2_2_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_2_5_2 [label="MLP_Linear1_2_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_2_5_2 [label="GELU_2_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_2_5_2 [label="MLP_Linear2_2_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_2_5_3 [label="MLP_Linear1_2_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_2_5_3 [label="GELU_2_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_2_5_3 [label="MLP_Linear2_2_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp_allreduce_2_5 [label="MLP_AllReduce_2_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_2_6_0 [label="MLP_Linear1_2_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_2_6_0 [label="GELU_2_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_2_6_0 [label="MLP_Linear2_2_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_2_6_1 [label="MLP_Linear1_2_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_2_6_1 [label="GELU_2_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_2_6_1 [label="MLP_Linear2_2_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_2_6_2 [label="MLP_Linear1_2_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_2_6_2 [label="GELU_2_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_2_6_2 [label="MLP_Linear2_2_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_2_6_3 [label="MLP_Linear1_2_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_2_6_3 [label="GELU_2_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_2_6_3 [label="MLP_Linear2_2_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp_allreduce_2_6 [label="MLP_AllReduce_2_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_2_7_0 [label="MLP_Linear1_2_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_2_7_0 [label="GELU_2_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_2_7_0 [label="MLP_Linear2_2_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_2_7_1 [label="MLP_Linear1_2_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_2_7_1 [label="GELU_2_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_2_7_1 [label="MLP_Linear2_2_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_2_7_2 [label="MLP_Linear1_2_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_2_7_2 [label="GELU_2_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_2_7_2 [label="MLP_Linear2_2_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_2_7_3 [label="MLP_Linear1_2_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_2_7_3 [label="GELU_2_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_2_7_3 [label="MLP_Linear2_2_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp_allreduce_2_7 [label="MLP_AllReduce_2_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_2_8_0 [label="MLP_Linear1_2_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_2_8_0 [label="GELU_2_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_2_8_0 [label="MLP_Linear2_2_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_2_8_1 [label="MLP_Linear1_2_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_2_8_1 [label="GELU_2_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_2_8_1 [label="MLP_Linear2_2_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_2_8_2 [label="MLP_Linear1_2_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_2_8_2 [label="GELU_2_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_2_8_2 [label="MLP_Linear2_2_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_2_8_3 [label="MLP_Linear1_2_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_2_8_3 [label="GELU_2_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_2_8_3 [label="MLP_Linear2_2_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp_allreduce_2_8 [label="MLP_AllReduce_2_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_2_9_0 [label="MLP_Linear1_2_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_2_9_0 [label="GELU_2_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_2_9_0 [label="MLP_Linear2_2_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_2_9_1 [label="MLP_Linear1_2_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_2_9_1 [label="GELU_2_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_2_9_1 [label="MLP_Linear2_2_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_2_9_2 [label="MLP_Linear1_2_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_2_9_2 [label="GELU_2_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_2_9_2 [label="MLP_Linear2_2_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_2_9_3 [label="MLP_Linear1_2_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_2_9_3 [label="GELU_2_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_2_9_3 [label="MLP_Linear2_2_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp_allreduce_2_9 [label="MLP_AllReduce_2_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_2_10_0 [label="MLP_Linear1_2_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_2_10_0 [label="GELU_2_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_2_10_0 [label="MLP_Linear2_2_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_2_10_1 [label="MLP_Linear1_2_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_2_10_1 [label="GELU_2_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_2_10_1 [label="MLP_Linear2_2_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_2_10_2 [label="MLP_Linear1_2_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_2_10_2 [label="GELU_2_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_2_10_2 [label="MLP_Linear2_2_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_2_10_3 [label="MLP_Linear1_2_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_2_10_3 [label="GELU_2_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_2_10_3 [label="MLP_Linear2_2_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp_allreduce_2_10 [label="MLP_AllReduce_2_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_2_11_0 [label="MLP_Linear1_2_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_2_11_0 [label="GELU_2_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_2_11_0 [label="MLP_Linear2_2_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_2_11_1 [label="MLP_Linear1_2_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_2_11_1 [label="GELU_2_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_2_11_1 [label="MLP_Linear2_2_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_2_11_2 [label="MLP_Linear1_2_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_2_11_2 [label="GELU_2_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_2_11_2 [label="MLP_Linear2_2_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_2_11_3 [label="MLP_Linear1_2_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_2_11_3 [label="GELU_2_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_2_11_3 [label="MLP_Linear2_2_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp_allreduce_2_11 [label="MLP_AllReduce_2_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_2_12_0 [label="MLP_Linear1_2_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_2_12_0 [label="GELU_2_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_2_12_0 [label="MLP_Linear2_2_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_2_12_1 [label="MLP_Linear1_2_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_2_12_1 [label="GELU_2_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_2_12_1 [label="MLP_Linear2_2_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_2_12_2 [label="MLP_Linear1_2_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_2_12_2 [label="GELU_2_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_2_12_2 [label="MLP_Linear2_2_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_2_12_3 [label="MLP_Linear1_2_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_2_12_3 [label="GELU_2_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_2_12_3 [label="MLP_Linear2_2_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp_allreduce_2_12 [label="MLP_AllReduce_2_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_2_13_0 [label="MLP_Linear1_2_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_2_13_0 [label="GELU_2_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_2_13_0 [label="MLP_Linear2_2_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_2_13_1 [label="MLP_Linear1_2_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_2_13_1 [label="GELU_2_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_2_13_1 [label="MLP_Linear2_2_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_2_13_2 [label="MLP_Linear1_2_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_2_13_2 [label="GELU_2_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_2_13_2 [label="MLP_Linear2_2_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_2_13_3 [label="MLP_Linear1_2_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_2_13_3 [label="GELU_2_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_2_13_3 [label="MLP_Linear2_2_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp_allreduce_2_13 [label="MLP_AllReduce_2_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_2_14_0 [label="MLP_Linear1_2_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_2_14_0 [label="GELU_2_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_2_14_0 [label="MLP_Linear2_2_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_2_14_1 [label="MLP_Linear1_2_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_2_14_1 [label="GELU_2_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_2_14_1 [label="MLP_Linear2_2_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_2_14_2 [label="MLP_Linear1_2_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_2_14_2 [label="GELU_2_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_2_14_2 [label="MLP_Linear2_2_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_2_14_3 [label="MLP_Linear1_2_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_2_14_3 [label="GELU_2_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_2_14_3 [label="MLP_Linear2_2_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp_allreduce_2_14 [label="MLP_AllReduce_2_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_2_15_0 [label="MLP_Linear1_2_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_2_15_0 [label="GELU_2_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_2_15_0 [label="MLP_Linear2_2_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_2_15_1 [label="MLP_Linear1_2_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_2_15_1 [label="GELU_2_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_2_15_1 [label="MLP_Linear2_2_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_2_15_2 [label="MLP_Linear1_2_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_2_15_2 [label="GELU_2_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_2_15_2 [label="MLP_Linear2_2_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_2_15_3 [label="MLP_Linear1_2_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_2_15_3 [label="GELU_2_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_2_15_3 [label="MLP_Linear2_2_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp_allreduce_2_15 [label="MLP_AllReduce_2_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	expert_route_2_0 [label="Expert_Route_2_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_2_1 [label="Expert_Route_2_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_2_2 [label="Expert_Route_2_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_2_3 [label="Expert_Route_2_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_2_4 [label="Expert_Route_2_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_2_5 [label="Expert_Route_2_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_2_6 [label="Expert_Route_2_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_2_7 [label="Expert_Route_2_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_2_8 [label="Expert_Route_2_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_2_9 [label="Expert_Route_2_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_2_10 [label="Expert_Route_2_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_2_11 [label="Expert_Route_2_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_2_12 [label="Expert_Route_2_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_2_13 [label="Expert_Route_2_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_2_14 [label="Expert_Route_2_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_2_15 [label="Expert_Route_2_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	qkv_3_0_0 [label="QKV_Proj_3_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_3_0_0 [label="Attention_3_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_3_0_0 [label="Attention_Output_3_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_3_0_1 [label="QKV_Proj_3_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_3_0_1 [label="Attention_3_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_3_0_1 [label="Attention_Output_3_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_3_0_2 [label="QKV_Proj_3_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_3_0_2 [label="Attention_3_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_3_0_2 [label="Attention_Output_3_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_3_0_3 [label="QKV_Proj_3_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_3_0_3 [label="Attention_3_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_3_0_3 [label="Attention_Output_3_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	attn_allreduce_3_0 [label="Attention_AllReduce_3_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_3_1_0 [label="QKV_Proj_3_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_3_1_0 [label="Attention_3_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_3_1_0 [label="Attention_Output_3_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_3_1_1 [label="QKV_Proj_3_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_3_1_1 [label="Attention_3_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_3_1_1 [label="Attention_Output_3_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_3_1_2 [label="QKV_Proj_3_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_3_1_2 [label="Attention_3_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_3_1_2 [label="Attention_Output_3_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_3_1_3 [label="QKV_Proj_3_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_3_1_3 [label="Attention_3_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_3_1_3 [label="Attention_Output_3_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	attn_allreduce_3_1 [label="Attention_AllReduce_3_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_3_2_0 [label="QKV_Proj_3_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_3_2_0 [label="Attention_3_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_3_2_0 [label="Attention_Output_3_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_3_2_1 [label="QKV_Proj_3_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_3_2_1 [label="Attention_3_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_3_2_1 [label="Attention_Output_3_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_3_2_2 [label="QKV_Proj_3_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_3_2_2 [label="Attention_3_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_3_2_2 [label="Attention_Output_3_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_3_2_3 [label="QKV_Proj_3_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_3_2_3 [label="Attention_3_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_3_2_3 [label="Attention_Output_3_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	attn_allreduce_3_2 [label="Attention_AllReduce_3_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_3_3_0 [label="QKV_Proj_3_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_3_3_0 [label="Attention_3_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_3_3_0 [label="Attention_Output_3_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_3_3_1 [label="QKV_Proj_3_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_3_3_1 [label="Attention_3_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_3_3_1 [label="Attention_Output_3_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_3_3_2 [label="QKV_Proj_3_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_3_3_2 [label="Attention_3_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_3_3_2 [label="Attention_Output_3_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_3_3_3 [label="QKV_Proj_3_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_3_3_3 [label="Attention_3_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_3_3_3 [label="Attention_Output_3_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	attn_allreduce_3_3 [label="Attention_AllReduce_3_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_3_4_0 [label="QKV_Proj_3_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_3_4_0 [label="Attention_3_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_3_4_0 [label="Attention_Output_3_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_3_4_1 [label="QKV_Proj_3_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_3_4_1 [label="Attention_3_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_3_4_1 [label="Attention_Output_3_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_3_4_2 [label="QKV_Proj_3_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_3_4_2 [label="Attention_3_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_3_4_2 [label="Attention_Output_3_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_3_4_3 [label="QKV_Proj_3_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_3_4_3 [label="Attention_3_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_3_4_3 [label="Attention_Output_3_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	attn_allreduce_3_4 [label="Attention_AllReduce_3_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_3_5_0 [label="QKV_Proj_3_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_3_5_0 [label="Attention_3_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_3_5_0 [label="Attention_Output_3_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_3_5_1 [label="QKV_Proj_3_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_3_5_1 [label="Attention_3_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_3_5_1 [label="Attention_Output_3_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_3_5_2 [label="QKV_Proj_3_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_3_5_2 [label="Attention_3_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_3_5_2 [label="Attention_Output_3_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_3_5_3 [label="QKV_Proj_3_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_3_5_3 [label="Attention_3_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_3_5_3 [label="Attention_Output_3_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	attn_allreduce_3_5 [label="Attention_AllReduce_3_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_3_6_0 [label="QKV_Proj_3_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_3_6_0 [label="Attention_3_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_3_6_0 [label="Attention_Output_3_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_3_6_1 [label="QKV_Proj_3_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_3_6_1 [label="Attention_3_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_3_6_1 [label="Attention_Output_3_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_3_6_2 [label="QKV_Proj_3_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_3_6_2 [label="Attention_3_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_3_6_2 [label="Attention_Output_3_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_3_6_3 [label="QKV_Proj_3_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_3_6_3 [label="Attention_3_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_3_6_3 [label="Attention_Output_3_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	attn_allreduce_3_6 [label="Attention_AllReduce_3_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_3_7_0 [label="QKV_Proj_3_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_3_7_0 [label="Attention_3_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_3_7_0 [label="Attention_Output_3_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_3_7_1 [label="QKV_Proj_3_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_3_7_1 [label="Attention_3_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_3_7_1 [label="Attention_Output_3_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_3_7_2 [label="QKV_Proj_3_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_3_7_2 [label="Attention_3_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_3_7_2 [label="Attention_Output_3_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_3_7_3 [label="QKV_Proj_3_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_3_7_3 [label="Attention_3_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_3_7_3 [label="Attention_Output_3_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	attn_allreduce_3_7 [label="Attention_AllReduce_3_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_3_8_0 [label="QKV_Proj_3_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_3_8_0 [label="Attention_3_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_3_8_0 [label="Attention_Output_3_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_3_8_1 [label="QKV_Proj_3_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_3_8_1 [label="Attention_3_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_3_8_1 [label="Attention_Output_3_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_3_8_2 [label="QKV_Proj_3_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_3_8_2 [label="Attention_3_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_3_8_2 [label="Attention_Output_3_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_3_8_3 [label="QKV_Proj_3_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_3_8_3 [label="Attention_3_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_3_8_3 [label="Attention_Output_3_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	attn_allreduce_3_8 [label="Attention_AllReduce_3_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_3_9_0 [label="QKV_Proj_3_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_3_9_0 [label="Attention_3_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_3_9_0 [label="Attention_Output_3_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_3_9_1 [label="QKV_Proj_3_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_3_9_1 [label="Attention_3_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_3_9_1 [label="Attention_Output_3_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_3_9_2 [label="QKV_Proj_3_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_3_9_2 [label="Attention_3_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_3_9_2 [label="Attention_Output_3_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_3_9_3 [label="QKV_Proj_3_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_3_9_3 [label="Attention_3_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_3_9_3 [label="Attention_Output_3_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	attn_allreduce_3_9 [label="Attention_AllReduce_3_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_3_10_0 [label="QKV_Proj_3_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_3_10_0 [label="Attention_3_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_3_10_0 [label="Attention_Output_3_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_3_10_1 [label="QKV_Proj_3_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_3_10_1 [label="Attention_3_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_3_10_1 [label="Attention_Output_3_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_3_10_2 [label="QKV_Proj_3_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_3_10_2 [label="Attention_3_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_3_10_2 [label="Attention_Output_3_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_3_10_3 [label="QKV_Proj_3_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_3_10_3 [label="Attention_3_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_3_10_3 [label="Attention_Output_3_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	attn_allreduce_3_10 [label="Attention_AllReduce_3_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_3_11_0 [label="QKV_Proj_3_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_3_11_0 [label="Attention_3_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_3_11_0 [label="Attention_Output_3_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_3_11_1 [label="QKV_Proj_3_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_3_11_1 [label="Attention_3_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_3_11_1 [label="Attention_Output_3_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_3_11_2 [label="QKV_Proj_3_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_3_11_2 [label="Attention_3_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_3_11_2 [label="Attention_Output_3_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_3_11_3 [label="QKV_Proj_3_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_3_11_3 [label="Attention_3_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_3_11_3 [label="Attention_Output_3_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	attn_allreduce_3_11 [label="Attention_AllReduce_3_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_3_12_0 [label="QKV_Proj_3_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_3_12_0 [label="Attention_3_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_3_12_0 [label="Attention_Output_3_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_3_12_1 [label="QKV_Proj_3_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_3_12_1 [label="Attention_3_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_3_12_1 [label="Attention_Output_3_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_3_12_2 [label="QKV_Proj_3_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_3_12_2 [label="Attention_3_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_3_12_2 [label="Attention_Output_3_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_3_12_3 [label="QKV_Proj_3_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_3_12_3 [label="Attention_3_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_3_12_3 [label="Attention_Output_3_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	attn_allreduce_3_12 [label="Attention_AllReduce_3_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_3_13_0 [label="QKV_Proj_3_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_3_13_0 [label="Attention_3_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_3_13_0 [label="Attention_Output_3_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_3_13_1 [label="QKV_Proj_3_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_3_13_1 [label="Attention_3_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_3_13_1 [label="Attention_Output_3_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_3_13_2 [label="QKV_Proj_3_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_3_13_2 [label="Attention_3_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_3_13_2 [label="Attention_Output_3_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_3_13_3 [label="QKV_Proj_3_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_3_13_3 [label="Attention_3_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_3_13_3 [label="Attention_Output_3_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	attn_allreduce_3_13 [label="Attention_AllReduce_3_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_3_14_0 [label="QKV_Proj_3_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_3_14_0 [label="Attention_3_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_3_14_0 [label="Attention_Output_3_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_3_14_1 [label="QKV_Proj_3_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_3_14_1 [label="Attention_3_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_3_14_1 [label="Attention_Output_3_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_3_14_2 [label="QKV_Proj_3_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_3_14_2 [label="Attention_3_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_3_14_2 [label="Attention_Output_3_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_3_14_3 [label="QKV_Proj_3_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_3_14_3 [label="Attention_3_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_3_14_3 [label="Attention_Output_3_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	attn_allreduce_3_14 [label="Attention_AllReduce_3_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_3_15_0 [label="QKV_Proj_3_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_3_15_0 [label="Attention_3_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_3_15_0 [label="Attention_Output_3_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_3_15_1 [label="QKV_Proj_3_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_3_15_1 [label="Attention_3_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_3_15_1 [label="Attention_Output_3_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_3_15_2 [label="QKV_Proj_3_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_3_15_2 [label="Attention_3_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_3_15_2 [label="Attention_Output_3_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_3_15_3 [label="QKV_Proj_3_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_3_15_3 [label="Attention_3_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_3_15_3 [label="Attention_Output_3_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	attn_allreduce_3_15 [label="Attention_AllReduce_3_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_3_0_0 [label="MLP_Linear1_3_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_3_0_0 [label="GELU_3_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_3_0_0 [label="MLP_Linear2_3_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_3_0_1 [label="MLP_Linear1_3_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_3_0_1 [label="GELU_3_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_3_0_1 [label="MLP_Linear2_3_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_3_0_2 [label="MLP_Linear1_3_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_3_0_2 [label="GELU_3_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_3_0_2 [label="MLP_Linear2_3_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_3_0_3 [label="MLP_Linear1_3_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_3_0_3 [label="GELU_3_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_3_0_3 [label="MLP_Linear2_3_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp_allreduce_3_0 [label="MLP_AllReduce_3_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_3_1_0 [label="MLP_Linear1_3_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_3_1_0 [label="GELU_3_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_3_1_0 [label="MLP_Linear2_3_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_3_1_1 [label="MLP_Linear1_3_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_3_1_1 [label="GELU_3_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_3_1_1 [label="MLP_Linear2_3_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_3_1_2 [label="MLP_Linear1_3_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_3_1_2 [label="GELU_3_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_3_1_2 [label="MLP_Linear2_3_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_3_1_3 [label="MLP_Linear1_3_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_3_1_3 [label="GELU_3_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_3_1_3 [label="MLP_Linear2_3_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp_allreduce_3_1 [label="MLP_AllReduce_3_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_3_2_0 [label="MLP_Linear1_3_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_3_2_0 [label="GELU_3_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_3_2_0 [label="MLP_Linear2_3_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_3_2_1 [label="MLP_Linear1_3_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_3_2_1 [label="GELU_3_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_3_2_1 [label="MLP_Linear2_3_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_3_2_2 [label="MLP_Linear1_3_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_3_2_2 [label="GELU_3_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_3_2_2 [label="MLP_Linear2_3_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_3_2_3 [label="MLP_Linear1_3_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_3_2_3 [label="GELU_3_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_3_2_3 [label="MLP_Linear2_3_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp_allreduce_3_2 [label="MLP_AllReduce_3_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_3_3_0 [label="MLP_Linear1_3_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_3_3_0 [label="GELU_3_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_3_3_0 [label="MLP_Linear2_3_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_3_3_1 [label="MLP_Linear1_3_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_3_3_1 [label="GELU_3_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_3_3_1 [label="MLP_Linear2_3_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_3_3_2 [label="MLP_Linear1_3_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_3_3_2 [label="GELU_3_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_3_3_2 [label="MLP_Linear2_3_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_3_3_3 [label="MLP_Linear1_3_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_3_3_3 [label="GELU_3_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_3_3_3 [label="MLP_Linear2_3_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp_allreduce_3_3 [label="MLP_AllReduce_3_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_3_4_0 [label="MLP_Linear1_3_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_3_4_0 [label="GELU_3_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_3_4_0 [label="MLP_Linear2_3_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_3_4_1 [label="MLP_Linear1_3_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_3_4_1 [label="GELU_3_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_3_4_1 [label="MLP_Linear2_3_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_3_4_2 [label="MLP_Linear1_3_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_3_4_2 [label="GELU_3_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_3_4_2 [label="MLP_Linear2_3_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_3_4_3 [label="MLP_Linear1_3_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_3_4_3 [label="GELU_3_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_3_4_3 [label="MLP_Linear2_3_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp_allreduce_3_4 [label="MLP_AllReduce_3_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_3_5_0 [label="MLP_Linear1_3_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_3_5_0 [label="GELU_3_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_3_5_0 [label="MLP_Linear2_3_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_3_5_1 [label="MLP_Linear1_3_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_3_5_1 [label="GELU_3_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_3_5_1 [label="MLP_Linear2_3_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_3_5_2 [label="MLP_Linear1_3_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_3_5_2 [label="GELU_3_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_3_5_2 [label="MLP_Linear2_3_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_3_5_3 [label="MLP_Linear1_3_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_3_5_3 [label="GELU_3_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_3_5_3 [label="MLP_Linear2_3_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp_allreduce_3_5 [label="MLP_AllReduce_3_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_3_6_0 [label="MLP_Linear1_3_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_3_6_0 [label="GELU_3_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_3_6_0 [label="MLP_Linear2_3_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_3_6_1 [label="MLP_Linear1_3_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_3_6_1 [label="GELU_3_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_3_6_1 [label="MLP_Linear2_3_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_3_6_2 [label="MLP_Linear1_3_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_3_6_2 [label="GELU_3_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_3_6_2 [label="MLP_Linear2_3_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_3_6_3 [label="MLP_Linear1_3_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_3_6_3 [label="GELU_3_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_3_6_3 [label="MLP_Linear2_3_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp_allreduce_3_6 [label="MLP_AllReduce_3_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_3_7_0 [label="MLP_Linear1_3_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_3_7_0 [label="GELU_3_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_3_7_0 [label="MLP_Linear2_3_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_3_7_1 [label="MLP_Linear1_3_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_3_7_1 [label="GELU_3_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_3_7_1 [label="MLP_Linear2_3_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_3_7_2 [label="MLP_Linear1_3_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_3_7_2 [label="GELU_3_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_3_7_2 [label="MLP_Linear2_3_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_3_7_3 [label="MLP_Linear1_3_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_3_7_3 [label="GELU_3_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_3_7_3 [label="MLP_Linear2_3_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp_allreduce_3_7 [label="MLP_AllReduce_3_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_3_8_0 [label="MLP_Linear1_3_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_3_8_0 [label="GELU_3_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_3_8_0 [label="MLP_Linear2_3_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_3_8_1 [label="MLP_Linear1_3_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_3_8_1 [label="GELU_3_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_3_8_1 [label="MLP_Linear2_3_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_3_8_2 [label="MLP_Linear1_3_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_3_8_2 [label="GELU_3_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_3_8_2 [label="MLP_Linear2_3_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_3_8_3 [label="MLP_Linear1_3_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_3_8_3 [label="GELU_3_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_3_8_3 [label="MLP_Linear2_3_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp_allreduce_3_8 [label="MLP_AllReduce_3_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_3_9_0 [label="MLP_Linear1_3_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_3_9_0 [label="GELU_3_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_3_9_0 [label="MLP_Linear2_3_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_3_9_1 [label="MLP_Linear1_3_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_3_9_1 [label="GELU_3_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_3_9_1 [label="MLP_Linear2_3_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_3_9_2 [label="MLP_Linear1_3_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_3_9_2 [label="GELU_3_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_3_9_2 [label="MLP_Linear2_3_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_3_9_3 [label="MLP_Linear1_3_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_3_9_3 [label="GELU_3_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_3_9_3 [label="MLP_Linear2_3_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp_allreduce_3_9 [label="MLP_AllReduce_3_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_3_10_0 [label="MLP_Linear1_3_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_3_10_0 [label="GELU_3_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_3_10_0 [label="MLP_Linear2_3_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_3_10_1 [label="MLP_Linear1_3_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_3_10_1 [label="GELU_3_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_3_10_1 [label="MLP_Linear2_3_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_3_10_2 [label="MLP_Linear1_3_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_3_10_2 [label="GELU_3_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_3_10_2 [label="MLP_Linear2_3_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_3_10_3 [label="MLP_Linear1_3_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_3_10_3 [label="GELU_3_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_3_10_3 [label="MLP_Linear2_3_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp_allreduce_3_10 [label="MLP_AllReduce_3_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_3_11_0 [label="MLP_Linear1_3_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_3_11_0 [label="GELU_3_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_3_11_0 [label="MLP_Linear2_3_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_3_11_1 [label="MLP_Linear1_3_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_3_11_1 [label="GELU_3_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_3_11_1 [label="MLP_Linear2_3_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_3_11_2 [label="MLP_Linear1_3_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_3_11_2 [label="GELU_3_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_3_11_2 [label="MLP_Linear2_3_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_3_11_3 [label="MLP_Linear1_3_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_3_11_3 [label="GELU_3_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_3_11_3 [label="MLP_Linear2_3_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp_allreduce_3_11 [label="MLP_AllReduce_3_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_3_12_0 [label="MLP_Linear1_3_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_3_12_0 [label="GELU_3_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_3_12_0 [label="MLP_Linear2_3_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_3_12_1 [label="MLP_Linear1_3_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_3_12_1 [label="GELU_3_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_3_12_1 [label="MLP_Linear2_3_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_3_12_2 [label="MLP_Linear1_3_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_3_12_2 [label="GELU_3_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_3_12_2 [label="MLP_Linear2_3_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_3_12_3 [label="MLP_Linear1_3_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_3_12_3 [label="GELU_3_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_3_12_3 [label="MLP_Linear2_3_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp_allreduce_3_12 [label="MLP_AllReduce_3_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_3_13_0 [label="MLP_Linear1_3_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_3_13_0 [label="GELU_3_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_3_13_0 [label="MLP_Linear2_3_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_3_13_1 [label="MLP_Linear1_3_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_3_13_1 [label="GELU_3_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_3_13_1 [label="MLP_Linear2_3_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_3_13_2 [label="MLP_Linear1_3_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_3_13_2 [label="GELU_3_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_3_13_2 [label="MLP_Linear2_3_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_3_13_3 [label="MLP_Linear1_3_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_3_13_3 [label="GELU_3_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_3_13_3 [label="MLP_Linear2_3_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp_allreduce_3_13 [label="MLP_AllReduce_3_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_3_14_0 [label="MLP_Linear1_3_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_3_14_0 [label="GELU_3_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_3_14_0 [label="MLP_Linear2_3_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_3_14_1 [label="MLP_Linear1_3_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_3_14_1 [label="GELU_3_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_3_14_1 [label="MLP_Linear2_3_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_3_14_2 [label="MLP_Linear1_3_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_3_14_2 [label="GELU_3_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_3_14_2 [label="MLP_Linear2_3_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_3_14_3 [label="MLP_Linear1_3_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_3_14_3 [label="GELU_3_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_3_14_3 [label="MLP_Linear2_3_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp_allreduce_3_14 [label="MLP_AllReduce_3_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_3_15_0 [label="MLP_Linear1_3_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_3_15_0 [label="GELU_3_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_3_15_0 [label="MLP_Linear2_3_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_3_15_1 [label="MLP_Linear1_3_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_3_15_1 [label="GELU_3_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_3_15_1 [label="MLP_Linear2_3_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_3_15_2 [label="MLP_Linear1_3_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_3_15_2 [label="GELU_3_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_3_15_2 [label="MLP_Linear2_3_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_3_15_3 [label="MLP_Linear1_3_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_3_15_3 [label="GELU_3_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_3_15_3 [label="MLP_Linear2_3_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp_allreduce_3_15 [label="MLP_AllReduce_3_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	expert_route_3_0 [label="Expert_Route_3_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_3_1 [label="Expert_Route_3_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_3_2 [label="Expert_Route_3_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_3_3 [label="Expert_Route_3_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_3_4 [label="Expert_Route_3_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_3_5 [label="Expert_Route_3_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_3_6 [label="Expert_Route_3_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_3_7 [label="Expert_Route_3_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_3_8 [label="Expert_Route_3_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_3_9 [label="Expert_Route_3_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_3_10 [label="Expert_Route_3_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_3_11 [label="Expert_Route_3_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_3_12 [label="Expert_Route_3_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_3_13 [label="Expert_Route_3_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_3_14 [label="Expert_Route_3_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_3_15 [label="Expert_Route_3_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	qkv_4_0_0 [label="QKV_Proj_4_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_4_0_0 [label="Attention_4_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_4_0_0 [label="Attention_Output_4_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_4_0_1 [label="QKV_Proj_4_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_4_0_1 [label="Attention_4_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_4_0_1 [label="Attention_Output_4_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_4_0_2 [label="QKV_Proj_4_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_4_0_2 [label="Attention_4_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_4_0_2 [label="Attention_Output_4_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_4_0_3 [label="QKV_Proj_4_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_4_0_3 [label="Attention_4_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_4_0_3 [label="Attention_Output_4_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	attn_allreduce_4_0 [label="Attention_AllReduce_4_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_4_1_0 [label="QKV_Proj_4_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_4_1_0 [label="Attention_4_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_4_1_0 [label="Attention_Output_4_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_4_1_1 [label="QKV_Proj_4_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_4_1_1 [label="Attention_4_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_4_1_1 [label="Attention_Output_4_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_4_1_2 [label="QKV_Proj_4_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_4_1_2 [label="Attention_4_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_4_1_2 [label="Attention_Output_4_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_4_1_3 [label="QKV_Proj_4_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_4_1_3 [label="Attention_4_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_4_1_3 [label="Attention_Output_4_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	attn_allreduce_4_1 [label="Attention_AllReduce_4_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_4_2_0 [label="QKV_Proj_4_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_4_2_0 [label="Attention_4_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_4_2_0 [label="Attention_Output_4_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_4_2_1 [label="QKV_Proj_4_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_4_2_1 [label="Attention_4_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_4_2_1 [label="Attention_Output_4_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_4_2_2 [label="QKV_Proj_4_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_4_2_2 [label="Attention_4_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_4_2_2 [label="Attention_Output_4_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_4_2_3 [label="QKV_Proj_4_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_4_2_3 [label="Attention_4_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_4_2_3 [label="Attention_Output_4_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	attn_allreduce_4_2 [label="Attention_AllReduce_4_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_4_3_0 [label="QKV_Proj_4_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_4_3_0 [label="Attention_4_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_4_3_0 [label="Attention_Output_4_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_4_3_1 [label="QKV_Proj_4_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_4_3_1 [label="Attention_4_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_4_3_1 [label="Attention_Output_4_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_4_3_2 [label="QKV_Proj_4_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_4_3_2 [label="Attention_4_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_4_3_2 [label="Attention_Output_4_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_4_3_3 [label="QKV_Proj_4_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_4_3_3 [label="Attention_4_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_4_3_3 [label="Attention_Output_4_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	attn_allreduce_4_3 [label="Attention_AllReduce_4_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_4_4_0 [label="QKV_Proj_4_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_4_4_0 [label="Attention_4_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_4_4_0 [label="Attention_Output_4_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_4_4_1 [label="QKV_Proj_4_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_4_4_1 [label="Attention_4_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_4_4_1 [label="Attention_Output_4_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_4_4_2 [label="QKV_Proj_4_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_4_4_2 [label="Attention_4_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_4_4_2 [label="Attention_Output_4_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_4_4_3 [label="QKV_Proj_4_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_4_4_3 [label="Attention_4_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_4_4_3 [label="Attention_Output_4_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	attn_allreduce_4_4 [label="Attention_AllReduce_4_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_4_5_0 [label="QKV_Proj_4_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_4_5_0 [label="Attention_4_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_4_5_0 [label="Attention_Output_4_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_4_5_1 [label="QKV_Proj_4_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_4_5_1 [label="Attention_4_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_4_5_1 [label="Attention_Output_4_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_4_5_2 [label="QKV_Proj_4_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_4_5_2 [label="Attention_4_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_4_5_2 [label="Attention_Output_4_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_4_5_3 [label="QKV_Proj_4_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_4_5_3 [label="Attention_4_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_4_5_3 [label="Attention_Output_4_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	attn_allreduce_4_5 [label="Attention_AllReduce_4_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_4_6_0 [label="QKV_Proj_4_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_4_6_0 [label="Attention_4_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_4_6_0 [label="Attention_Output_4_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_4_6_1 [label="QKV_Proj_4_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_4_6_1 [label="Attention_4_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_4_6_1 [label="Attention_Output_4_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_4_6_2 [label="QKV_Proj_4_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_4_6_2 [label="Attention_4_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_4_6_2 [label="Attention_Output_4_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_4_6_3 [label="QKV_Proj_4_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_4_6_3 [label="Attention_4_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_4_6_3 [label="Attention_Output_4_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	attn_allreduce_4_6 [label="Attention_AllReduce_4_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_4_7_0 [label="QKV_Proj_4_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_4_7_0 [label="Attention_4_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_4_7_0 [label="Attention_Output_4_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_4_7_1 [label="QKV_Proj_4_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_4_7_1 [label="Attention_4_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_4_7_1 [label="Attention_Output_4_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_4_7_2 [label="QKV_Proj_4_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_4_7_2 [label="Attention_4_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_4_7_2 [label="Attention_Output_4_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_4_7_3 [label="QKV_Proj_4_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_4_7_3 [label="Attention_4_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_4_7_3 [label="Attention_Output_4_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	attn_allreduce_4_7 [label="Attention_AllReduce_4_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_4_8_0 [label="QKV_Proj_4_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_4_8_0 [label="Attention_4_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_4_8_0 [label="Attention_Output_4_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_4_8_1 [label="QKV_Proj_4_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_4_8_1 [label="Attention_4_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_4_8_1 [label="Attention_Output_4_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_4_8_2 [label="QKV_Proj_4_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_4_8_2 [label="Attention_4_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_4_8_2 [label="Attention_Output_4_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_4_8_3 [label="QKV_Proj_4_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_4_8_3 [label="Attention_4_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_4_8_3 [label="Attention_Output_4_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	attn_allreduce_4_8 [label="Attention_AllReduce_4_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_4_9_0 [label="QKV_Proj_4_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_4_9_0 [label="Attention_4_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_4_9_0 [label="Attention_Output_4_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_4_9_1 [label="QKV_Proj_4_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_4_9_1 [label="Attention_4_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_4_9_1 [label="Attention_Output_4_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_4_9_2 [label="QKV_Proj_4_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_4_9_2 [label="Attention_4_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_4_9_2 [label="Attention_Output_4_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_4_9_3 [label="QKV_Proj_4_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_4_9_3 [label="Attention_4_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_4_9_3 [label="Attention_Output_4_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	attn_allreduce_4_9 [label="Attention_AllReduce_4_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_4_10_0 [label="QKV_Proj_4_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_4_10_0 [label="Attention_4_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_4_10_0 [label="Attention_Output_4_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_4_10_1 [label="QKV_Proj_4_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_4_10_1 [label="Attention_4_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_4_10_1 [label="Attention_Output_4_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_4_10_2 [label="QKV_Proj_4_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_4_10_2 [label="Attention_4_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_4_10_2 [label="Attention_Output_4_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_4_10_3 [label="QKV_Proj_4_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_4_10_3 [label="Attention_4_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_4_10_3 [label="Attention_Output_4_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	attn_allreduce_4_10 [label="Attention_AllReduce_4_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_4_11_0 [label="QKV_Proj_4_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_4_11_0 [label="Attention_4_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_4_11_0 [label="Attention_Output_4_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_4_11_1 [label="QKV_Proj_4_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_4_11_1 [label="Attention_4_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_4_11_1 [label="Attention_Output_4_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_4_11_2 [label="QKV_Proj_4_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_4_11_2 [label="Attention_4_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_4_11_2 [label="Attention_Output_4_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_4_11_3 [label="QKV_Proj_4_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_4_11_3 [label="Attention_4_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_4_11_3 [label="Attention_Output_4_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	attn_allreduce_4_11 [label="Attention_AllReduce_4_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_4_12_0 [label="QKV_Proj_4_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_4_12_0 [label="Attention_4_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_4_12_0 [label="Attention_Output_4_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_4_12_1 [label="QKV_Proj_4_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_4_12_1 [label="Attention_4_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_4_12_1 [label="Attention_Output_4_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_4_12_2 [label="QKV_Proj_4_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_4_12_2 [label="Attention_4_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_4_12_2 [label="Attention_Output_4_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_4_12_3 [label="QKV_Proj_4_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_4_12_3 [label="Attention_4_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_4_12_3 [label="Attention_Output_4_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	attn_allreduce_4_12 [label="Attention_AllReduce_4_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_4_13_0 [label="QKV_Proj_4_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_4_13_0 [label="Attention_4_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_4_13_0 [label="Attention_Output_4_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_4_13_1 [label="QKV_Proj_4_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_4_13_1 [label="Attention_4_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_4_13_1 [label="Attention_Output_4_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_4_13_2 [label="QKV_Proj_4_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_4_13_2 [label="Attention_4_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_4_13_2 [label="Attention_Output_4_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_4_13_3 [label="QKV_Proj_4_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_4_13_3 [label="Attention_4_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_4_13_3 [label="Attention_Output_4_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	attn_allreduce_4_13 [label="Attention_AllReduce_4_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_4_14_0 [label="QKV_Proj_4_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_4_14_0 [label="Attention_4_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_4_14_0 [label="Attention_Output_4_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_4_14_1 [label="QKV_Proj_4_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_4_14_1 [label="Attention_4_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_4_14_1 [label="Attention_Output_4_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_4_14_2 [label="QKV_Proj_4_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_4_14_2 [label="Attention_4_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_4_14_2 [label="Attention_Output_4_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_4_14_3 [label="QKV_Proj_4_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_4_14_3 [label="Attention_4_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_4_14_3 [label="Attention_Output_4_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	attn_allreduce_4_14 [label="Attention_AllReduce_4_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_4_15_0 [label="QKV_Proj_4_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_4_15_0 [label="Attention_4_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_4_15_0 [label="Attention_Output_4_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_4_15_1 [label="QKV_Proj_4_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_4_15_1 [label="Attention_4_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_4_15_1 [label="Attention_Output_4_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_4_15_2 [label="QKV_Proj_4_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_4_15_2 [label="Attention_4_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_4_15_2 [label="Attention_Output_4_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_4_15_3 [label="QKV_Proj_4_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_4_15_3 [label="Attention_4_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_4_15_3 [label="Attention_Output_4_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	attn_allreduce_4_15 [label="Attention_AllReduce_4_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_4_0_0 [label="MLP_Linear1_4_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_4_0_0 [label="GELU_4_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_4_0_0 [label="MLP_Linear2_4_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_4_0_1 [label="MLP_Linear1_4_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_4_0_1 [label="GELU_4_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_4_0_1 [label="MLP_Linear2_4_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_4_0_2 [label="MLP_Linear1_4_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_4_0_2 [label="GELU_4_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_4_0_2 [label="MLP_Linear2_4_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_4_0_3 [label="MLP_Linear1_4_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_4_0_3 [label="GELU_4_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_4_0_3 [label="MLP_Linear2_4_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp_allreduce_4_0 [label="MLP_AllReduce_4_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_4_1_0 [label="MLP_Linear1_4_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_4_1_0 [label="GELU_4_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_4_1_0 [label="MLP_Linear2_4_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_4_1_1 [label="MLP_Linear1_4_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_4_1_1 [label="GELU_4_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_4_1_1 [label="MLP_Linear2_4_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_4_1_2 [label="MLP_Linear1_4_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_4_1_2 [label="GELU_4_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_4_1_2 [label="MLP_Linear2_4_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_4_1_3 [label="MLP_Linear1_4_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_4_1_3 [label="GELU_4_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_4_1_3 [label="MLP_Linear2_4_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp_allreduce_4_1 [label="MLP_AllReduce_4_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_4_2_0 [label="MLP_Linear1_4_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_4_2_0 [label="GELU_4_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_4_2_0 [label="MLP_Linear2_4_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_4_2_1 [label="MLP_Linear1_4_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_4_2_1 [label="GELU_4_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_4_2_1 [label="MLP_Linear2_4_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_4_2_2 [label="MLP_Linear1_4_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_4_2_2 [label="GELU_4_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_4_2_2 [label="MLP_Linear2_4_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_4_2_3 [label="MLP_Linear1_4_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_4_2_3 [label="GELU_4_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_4_2_3 [label="MLP_Linear2_4_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp_allreduce_4_2 [label="MLP_AllReduce_4_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_4_3_0 [label="MLP_Linear1_4_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_4_3_0 [label="GELU_4_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_4_3_0 [label="MLP_Linear2_4_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_4_3_1 [label="MLP_Linear1_4_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_4_3_1 [label="GELU_4_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_4_3_1 [label="MLP_Linear2_4_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_4_3_2 [label="MLP_Linear1_4_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_4_3_2 [label="GELU_4_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_4_3_2 [label="MLP_Linear2_4_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_4_3_3 [label="MLP_Linear1_4_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_4_3_3 [label="GELU_4_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_4_3_3 [label="MLP_Linear2_4_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp_allreduce_4_3 [label="MLP_AllReduce_4_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_4_4_0 [label="MLP_Linear1_4_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_4_4_0 [label="GELU_4_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_4_4_0 [label="MLP_Linear2_4_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_4_4_1 [label="MLP_Linear1_4_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_4_4_1 [label="GELU_4_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_4_4_1 [label="MLP_Linear2_4_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_4_4_2 [label="MLP_Linear1_4_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_4_4_2 [label="GELU_4_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_4_4_2 [label="MLP_Linear2_4_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_4_4_3 [label="MLP_Linear1_4_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_4_4_3 [label="GELU_4_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_4_4_3 [label="MLP_Linear2_4_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp_allreduce_4_4 [label="MLP_AllReduce_4_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_4_5_0 [label="MLP_Linear1_4_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_4_5_0 [label="GELU_4_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_4_5_0 [label="MLP_Linear2_4_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_4_5_1 [label="MLP_Linear1_4_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_4_5_1 [label="GELU_4_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_4_5_1 [label="MLP_Linear2_4_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_4_5_2 [label="MLP_Linear1_4_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_4_5_2 [label="GELU_4_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_4_5_2 [label="MLP_Linear2_4_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_4_5_3 [label="MLP_Linear1_4_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_4_5_3 [label="GELU_4_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_4_5_3 [label="MLP_Linear2_4_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp_allreduce_4_5 [label="MLP_AllReduce_4_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_4_6_0 [label="MLP_Linear1_4_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_4_6_0 [label="GELU_4_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_4_6_0 [label="MLP_Linear2_4_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_4_6_1 [label="MLP_Linear1_4_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_4_6_1 [label="GELU_4_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_4_6_1 [label="MLP_Linear2_4_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_4_6_2 [label="MLP_Linear1_4_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_4_6_2 [label="GELU_4_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_4_6_2 [label="MLP_Linear2_4_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_4_6_3 [label="MLP_Linear1_4_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_4_6_3 [label="GELU_4_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_4_6_3 [label="MLP_Linear2_4_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp_allreduce_4_6 [label="MLP_AllReduce_4_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_4_7_0 [label="MLP_Linear1_4_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_4_7_0 [label="GELU_4_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_4_7_0 [label="MLP_Linear2_4_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_4_7_1 [label="MLP_Linear1_4_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_4_7_1 [label="GELU_4_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_4_7_1 [label="MLP_Linear2_4_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_4_7_2 [label="MLP_Linear1_4_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_4_7_2 [label="GELU_4_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_4_7_2 [label="MLP_Linear2_4_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_4_7_3 [label="MLP_Linear1_4_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_4_7_3 [label="GELU_4_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_4_7_3 [label="MLP_Linear2_4_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp_allreduce_4_7 [label="MLP_AllReduce_4_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_4_8_0 [label="MLP_Linear1_4_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_4_8_0 [label="GELU_4_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_4_8_0 [label="MLP_Linear2_4_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_4_8_1 [label="MLP_Linear1_4_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_4_8_1 [label="GELU_4_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_4_8_1 [label="MLP_Linear2_4_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_4_8_2 [label="MLP_Linear1_4_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_4_8_2 [label="GELU_4_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_4_8_2 [label="MLP_Linear2_4_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_4_8_3 [label="MLP_Linear1_4_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_4_8_3 [label="GELU_4_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_4_8_3 [label="MLP_Linear2_4_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp_allreduce_4_8 [label="MLP_AllReduce_4_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_4_9_0 [label="MLP_Linear1_4_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_4_9_0 [label="GELU_4_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_4_9_0 [label="MLP_Linear2_4_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_4_9_1 [label="MLP_Linear1_4_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_4_9_1 [label="GELU_4_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_4_9_1 [label="MLP_Linear2_4_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_4_9_2 [label="MLP_Linear1_4_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_4_9_2 [label="GELU_4_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_4_9_2 [label="MLP_Linear2_4_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_4_9_3 [label="MLP_Linear1_4_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_4_9_3 [label="GELU_4_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_4_9_3 [label="MLP_Linear2_4_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp_allreduce_4_9 [label="MLP_AllReduce_4_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_4_10_0 [label="MLP_Linear1_4_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_4_10_0 [label="GELU_4_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_4_10_0 [label="MLP_Linear2_4_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_4_10_1 [label="MLP_Linear1_4_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_4_10_1 [label="GELU_4_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_4_10_1 [label="MLP_Linear2_4_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_4_10_2 [label="MLP_Linear1_4_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_4_10_2 [label="GELU_4_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_4_10_2 [label="MLP_Linear2_4_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_4_10_3 [label="MLP_Linear1_4_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_4_10_3 [label="GELU_4_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_4_10_3 [label="MLP_Linear2_4_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp_allreduce_4_10 [label="MLP_AllReduce_4_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_4_11_0 [label="MLP_Linear1_4_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_4_11_0 [label="GELU_4_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_4_11_0 [label="MLP_Linear2_4_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_4_11_1 [label="MLP_Linear1_4_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_4_11_1 [label="GELU_4_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_4_11_1 [label="MLP_Linear2_4_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_4_11_2 [label="MLP_Linear1_4_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_4_11_2 [label="GELU_4_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_4_11_2 [label="MLP_Linear2_4_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_4_11_3 [label="MLP_Linear1_4_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_4_11_3 [label="GELU_4_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_4_11_3 [label="MLP_Linear2_4_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp_allreduce_4_11 [label="MLP_AllReduce_4_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_4_12_0 [label="MLP_Linear1_4_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_4_12_0 [label="GELU_4_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_4_12_0 [label="MLP_Linear2_4_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_4_12_1 [label="MLP_Linear1_4_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_4_12_1 [label="GELU_4_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_4_12_1 [label="MLP_Linear2_4_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_4_12_2 [label="MLP_Linear1_4_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_4_12_2 [label="GELU_4_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_4_12_2 [label="MLP_Linear2_4_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_4_12_3 [label="MLP_Linear1_4_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_4_12_3 [label="GELU_4_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_4_12_3 [label="MLP_Linear2_4_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp_allreduce_4_12 [label="MLP_AllReduce_4_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_4_13_0 [label="MLP_Linear1_4_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_4_13_0 [label="GELU_4_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_4_13_0 [label="MLP_Linear2_4_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_4_13_1 [label="MLP_Linear1_4_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_4_13_1 [label="GELU_4_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_4_13_1 [label="MLP_Linear2_4_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_4_13_2 [label="MLP_Linear1_4_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_4_13_2 [label="GELU_4_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_4_13_2 [label="MLP_Linear2_4_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_4_13_3 [label="MLP_Linear1_4_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_4_13_3 [label="GELU_4_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_4_13_3 [label="MLP_Linear2_4_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp_allreduce_4_13 [label="MLP_AllReduce_4_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_4_14_0 [label="MLP_Linear1_4_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_4_14_0 [label="GELU_4_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_4_14_0 [label="MLP_Linear2_4_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_4_14_1 [label="MLP_Linear1_4_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_4_14_1 [label="GELU_4_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_4_14_1 [label="MLP_Linear2_4_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_4_14_2 [label="MLP_Linear1_4_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_4_14_2 [label="GELU_4_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_4_14_2 [label="MLP_Linear2_4_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_4_14_3 [label="MLP_Linear1_4_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_4_14_3 [label="GELU_4_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_4_14_3 [label="MLP_Linear2_4_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp_allreduce_4_14 [label="MLP_AllReduce_4_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_4_15_0 [label="MLP_Linear1_4_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_4_15_0 [label="GELU_4_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_4_15_0 [label="MLP_Linear2_4_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_4_15_1 [label="MLP_Linear1_4_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_4_15_1 [label="GELU_4_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_4_15_1 [label="MLP_Linear2_4_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_4_15_2 [label="MLP_Linear1_4_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_4_15_2 [label="GELU_4_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_4_15_2 [label="MLP_Linear2_4_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_4_15_3 [label="MLP_Linear1_4_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_4_15_3 [label="GELU_4_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_4_15_3 [label="MLP_Linear2_4_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp_allreduce_4_15 [label="MLP_AllReduce_4_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	expert_route_4_0 [label="Expert_Route_4_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_4_1 [label="Expert_Route_4_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_4_2 [label="Expert_Route_4_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_4_3 [label="Expert_Route_4_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_4_4 [label="Expert_Route_4_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_4_5 [label="Expert_Route_4_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_4_6 [label="Expert_Route_4_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_4_7 [label="Expert_Route_4_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_4_8 [label="Expert_Route_4_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_4_9 [label="Expert_Route_4_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_4_10 [label="Expert_Route_4_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_4_11 [label="Expert_Route_4_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_4_12 [label="Expert_Route_4_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_4_13 [label="Expert_Route_4_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_4_14 [label="Expert_Route_4_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_4_15 [label="Expert_Route_4_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	qkv_5_0_0 [label="QKV_Proj_5_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_5_0_0 [label="Attention_5_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_5_0_0 [label="Attention_Output_5_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_5_0_1 [label="QKV_Proj_5_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_5_0_1 [label="Attention_5_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_5_0_1 [label="Attention_Output_5_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_5_0_2 [label="QKV_Proj_5_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_5_0_2 [label="Attention_5_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_5_0_2 [label="Attention_Output_5_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_5_0_3 [label="QKV_Proj_5_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_5_0_3 [label="Attention_5_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_5_0_3 [label="Attention_Output_5_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	attn_allreduce_5_0 [label="Attention_AllReduce_5_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_5_1_0 [label="QKV_Proj_5_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_5_1_0 [label="Attention_5_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_5_1_0 [label="Attention_Output_5_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_5_1_1 [label="QKV_Proj_5_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_5_1_1 [label="Attention_5_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_5_1_1 [label="Attention_Output_5_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_5_1_2 [label="QKV_Proj_5_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_5_1_2 [label="Attention_5_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_5_1_2 [label="Attention_Output_5_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_5_1_3 [label="QKV_Proj_5_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_5_1_3 [label="Attention_5_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_5_1_3 [label="Attention_Output_5_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	attn_allreduce_5_1 [label="Attention_AllReduce_5_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_5_2_0 [label="QKV_Proj_5_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_5_2_0 [label="Attention_5_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_5_2_0 [label="Attention_Output_5_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_5_2_1 [label="QKV_Proj_5_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_5_2_1 [label="Attention_5_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_5_2_1 [label="Attention_Output_5_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_5_2_2 [label="QKV_Proj_5_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_5_2_2 [label="Attention_5_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_5_2_2 [label="Attention_Output_5_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_5_2_3 [label="QKV_Proj_5_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_5_2_3 [label="Attention_5_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_5_2_3 [label="Attention_Output_5_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	attn_allreduce_5_2 [label="Attention_AllReduce_5_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_5_3_0 [label="QKV_Proj_5_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_5_3_0 [label="Attention_5_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_5_3_0 [label="Attention_Output_5_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_5_3_1 [label="QKV_Proj_5_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_5_3_1 [label="Attention_5_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_5_3_1 [label="Attention_Output_5_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_5_3_2 [label="QKV_Proj_5_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_5_3_2 [label="Attention_5_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_5_3_2 [label="Attention_Output_5_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_5_3_3 [label="QKV_Proj_5_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_5_3_3 [label="Attention_5_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_5_3_3 [label="Attention_Output_5_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	attn_allreduce_5_3 [label="Attention_AllReduce_5_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_5_4_0 [label="QKV_Proj_5_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_5_4_0 [label="Attention_5_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_5_4_0 [label="Attention_Output_5_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_5_4_1 [label="QKV_Proj_5_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_5_4_1 [label="Attention_5_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_5_4_1 [label="Attention_Output_5_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_5_4_2 [label="QKV_Proj_5_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_5_4_2 [label="Attention_5_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_5_4_2 [label="Attention_Output_5_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_5_4_3 [label="QKV_Proj_5_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_5_4_3 [label="Attention_5_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_5_4_3 [label="Attention_Output_5_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	attn_allreduce_5_4 [label="Attention_AllReduce_5_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_5_5_0 [label="QKV_Proj_5_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_5_5_0 [label="Attention_5_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_5_5_0 [label="Attention_Output_5_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_5_5_1 [label="QKV_Proj_5_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_5_5_1 [label="Attention_5_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_5_5_1 [label="Attention_Output_5_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_5_5_2 [label="QKV_Proj_5_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_5_5_2 [label="Attention_5_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_5_5_2 [label="Attention_Output_5_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_5_5_3 [label="QKV_Proj_5_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_5_5_3 [label="Attention_5_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_5_5_3 [label="Attention_Output_5_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	attn_allreduce_5_5 [label="Attention_AllReduce_5_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_5_6_0 [label="QKV_Proj_5_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_5_6_0 [label="Attention_5_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_5_6_0 [label="Attention_Output_5_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_5_6_1 [label="QKV_Proj_5_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_5_6_1 [label="Attention_5_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_5_6_1 [label="Attention_Output_5_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_5_6_2 [label="QKV_Proj_5_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_5_6_2 [label="Attention_5_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_5_6_2 [label="Attention_Output_5_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_5_6_3 [label="QKV_Proj_5_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_5_6_3 [label="Attention_5_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_5_6_3 [label="Attention_Output_5_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	attn_allreduce_5_6 [label="Attention_AllReduce_5_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_5_7_0 [label="QKV_Proj_5_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_5_7_0 [label="Attention_5_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_5_7_0 [label="Attention_Output_5_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_5_7_1 [label="QKV_Proj_5_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_5_7_1 [label="Attention_5_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_5_7_1 [label="Attention_Output_5_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_5_7_2 [label="QKV_Proj_5_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_5_7_2 [label="Attention_5_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_5_7_2 [label="Attention_Output_5_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_5_7_3 [label="QKV_Proj_5_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_5_7_3 [label="Attention_5_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_5_7_3 [label="Attention_Output_5_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	attn_allreduce_5_7 [label="Attention_AllReduce_5_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_5_8_0 [label="QKV_Proj_5_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_5_8_0 [label="Attention_5_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_5_8_0 [label="Attention_Output_5_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_5_8_1 [label="QKV_Proj_5_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_5_8_1 [label="Attention_5_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_5_8_1 [label="Attention_Output_5_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_5_8_2 [label="QKV_Proj_5_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_5_8_2 [label="Attention_5_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_5_8_2 [label="Attention_Output_5_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_5_8_3 [label="QKV_Proj_5_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_5_8_3 [label="Attention_5_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_5_8_3 [label="Attention_Output_5_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	attn_allreduce_5_8 [label="Attention_AllReduce_5_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_5_9_0 [label="QKV_Proj_5_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_5_9_0 [label="Attention_5_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_5_9_0 [label="Attention_Output_5_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_5_9_1 [label="QKV_Proj_5_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_5_9_1 [label="Attention_5_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_5_9_1 [label="Attention_Output_5_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_5_9_2 [label="QKV_Proj_5_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_5_9_2 [label="Attention_5_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_5_9_2 [label="Attention_Output_5_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_5_9_3 [label="QKV_Proj_5_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_5_9_3 [label="Attention_5_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_5_9_3 [label="Attention_Output_5_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	attn_allreduce_5_9 [label="Attention_AllReduce_5_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_5_10_0 [label="QKV_Proj_5_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_5_10_0 [label="Attention_5_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_5_10_0 [label="Attention_Output_5_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_5_10_1 [label="QKV_Proj_5_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_5_10_1 [label="Attention_5_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_5_10_1 [label="Attention_Output_5_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_5_10_2 [label="QKV_Proj_5_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_5_10_2 [label="Attention_5_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_5_10_2 [label="Attention_Output_5_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_5_10_3 [label="QKV_Proj_5_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_5_10_3 [label="Attention_5_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_5_10_3 [label="Attention_Output_5_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	attn_allreduce_5_10 [label="Attention_AllReduce_5_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_5_11_0 [label="QKV_Proj_5_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_5_11_0 [label="Attention_5_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_5_11_0 [label="Attention_Output_5_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_5_11_1 [label="QKV_Proj_5_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_5_11_1 [label="Attention_5_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_5_11_1 [label="Attention_Output_5_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_5_11_2 [label="QKV_Proj_5_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_5_11_2 [label="Attention_5_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_5_11_2 [label="Attention_Output_5_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_5_11_3 [label="QKV_Proj_5_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_5_11_3 [label="Attention_5_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_5_11_3 [label="Attention_Output_5_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	attn_allreduce_5_11 [label="Attention_AllReduce_5_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_5_12_0 [label="QKV_Proj_5_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_5_12_0 [label="Attention_5_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_5_12_0 [label="Attention_Output_5_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_5_12_1 [label="QKV_Proj_5_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_5_12_1 [label="Attention_5_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_5_12_1 [label="Attention_Output_5_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_5_12_2 [label="QKV_Proj_5_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_5_12_2 [label="Attention_5_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_5_12_2 [label="Attention_Output_5_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_5_12_3 [label="QKV_Proj_5_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_5_12_3 [label="Attention_5_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_5_12_3 [label="Attention_Output_5_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	attn_allreduce_5_12 [label="Attention_AllReduce_5_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_5_13_0 [label="QKV_Proj_5_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_5_13_0 [label="Attention_5_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_5_13_0 [label="Attention_Output_5_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_5_13_1 [label="QKV_Proj_5_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_5_13_1 [label="Attention_5_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_5_13_1 [label="Attention_Output_5_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_5_13_2 [label="QKV_Proj_5_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_5_13_2 [label="Attention_5_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_5_13_2 [label="Attention_Output_5_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_5_13_3 [label="QKV_Proj_5_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_5_13_3 [label="Attention_5_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_5_13_3 [label="Attention_Output_5_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	attn_allreduce_5_13 [label="Attention_AllReduce_5_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_5_14_0 [label="QKV_Proj_5_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_5_14_0 [label="Attention_5_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_5_14_0 [label="Attention_Output_5_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_5_14_1 [label="QKV_Proj_5_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_5_14_1 [label="Attention_5_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_5_14_1 [label="Attention_Output_5_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_5_14_2 [label="QKV_Proj_5_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_5_14_2 [label="Attention_5_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_5_14_2 [label="Attention_Output_5_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_5_14_3 [label="QKV_Proj_5_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_5_14_3 [label="Attention_5_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_5_14_3 [label="Attention_Output_5_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	attn_allreduce_5_14 [label="Attention_AllReduce_5_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_5_15_0 [label="QKV_Proj_5_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_5_15_0 [label="Attention_5_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_5_15_0 [label="Attention_Output_5_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_5_15_1 [label="QKV_Proj_5_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_5_15_1 [label="Attention_5_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_5_15_1 [label="Attention_Output_5_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_5_15_2 [label="QKV_Proj_5_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_5_15_2 [label="Attention_5_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_5_15_2 [label="Attention_Output_5_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_5_15_3 [label="QKV_Proj_5_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_5_15_3 [label="Attention_5_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_5_15_3 [label="Attention_Output_5_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	attn_allreduce_5_15 [label="Attention_AllReduce_5_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_5_0_0 [label="MLP_Linear1_5_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_5_0_0 [label="GELU_5_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_5_0_0 [label="MLP_Linear2_5_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_5_0_1 [label="MLP_Linear1_5_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_5_0_1 [label="GELU_5_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_5_0_1 [label="MLP_Linear2_5_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_5_0_2 [label="MLP_Linear1_5_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_5_0_2 [label="GELU_5_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_5_0_2 [label="MLP_Linear2_5_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_5_0_3 [label="MLP_Linear1_5_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_5_0_3 [label="GELU_5_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_5_0_3 [label="MLP_Linear2_5_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp_allreduce_5_0 [label="MLP_AllReduce_5_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_5_1_0 [label="MLP_Linear1_5_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_5_1_0 [label="GELU_5_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_5_1_0 [label="MLP_Linear2_5_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_5_1_1 [label="MLP_Linear1_5_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_5_1_1 [label="GELU_5_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_5_1_1 [label="MLP_Linear2_5_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_5_1_2 [label="MLP_Linear1_5_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_5_1_2 [label="GELU_5_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_5_1_2 [label="MLP_Linear2_5_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_5_1_3 [label="MLP_Linear1_5_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_5_1_3 [label="GELU_5_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_5_1_3 [label="MLP_Linear2_5_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp_allreduce_5_1 [label="MLP_AllReduce_5_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_5_2_0 [label="MLP_Linear1_5_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_5_2_0 [label="GELU_5_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_5_2_0 [label="MLP_Linear2_5_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_5_2_1 [label="MLP_Linear1_5_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_5_2_1 [label="GELU_5_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_5_2_1 [label="MLP_Linear2_5_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_5_2_2 [label="MLP_Linear1_5_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_5_2_2 [label="GELU_5_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_5_2_2 [label="MLP_Linear2_5_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_5_2_3 [label="MLP_Linear1_5_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_5_2_3 [label="GELU_5_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_5_2_3 [label="MLP_Linear2_5_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp_allreduce_5_2 [label="MLP_AllReduce_5_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_5_3_0 [label="MLP_Linear1_5_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_5_3_0 [label="GELU_5_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_5_3_0 [label="MLP_Linear2_5_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_5_3_1 [label="MLP_Linear1_5_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_5_3_1 [label="GELU_5_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_5_3_1 [label="MLP_Linear2_5_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_5_3_2 [label="MLP_Linear1_5_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_5_3_2 [label="GELU_5_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_5_3_2 [label="MLP_Linear2_5_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_5_3_3 [label="MLP_Linear1_5_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_5_3_3 [label="GELU_5_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_5_3_3 [label="MLP_Linear2_5_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp_allreduce_5_3 [label="MLP_AllReduce_5_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_5_4_0 [label="MLP_Linear1_5_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_5_4_0 [label="GELU_5_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_5_4_0 [label="MLP_Linear2_5_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_5_4_1 [label="MLP_Linear1_5_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_5_4_1 [label="GELU_5_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_5_4_1 [label="MLP_Linear2_5_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_5_4_2 [label="MLP_Linear1_5_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_5_4_2 [label="GELU_5_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_5_4_2 [label="MLP_Linear2_5_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_5_4_3 [label="MLP_Linear1_5_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_5_4_3 [label="GELU_5_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_5_4_3 [label="MLP_Linear2_5_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp_allreduce_5_4 [label="MLP_AllReduce_5_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_5_5_0 [label="MLP_Linear1_5_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_5_5_0 [label="GELU_5_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_5_5_0 [label="MLP_Linear2_5_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_5_5_1 [label="MLP_Linear1_5_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_5_5_1 [label="GELU_5_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_5_5_1 [label="MLP_Linear2_5_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_5_5_2 [label="MLP_Linear1_5_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_5_5_2 [label="GELU_5_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_5_5_2 [label="MLP_Linear2_5_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_5_5_3 [label="MLP_Linear1_5_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_5_5_3 [label="GELU_5_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_5_5_3 [label="MLP_Linear2_5_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp_allreduce_5_5 [label="MLP_AllReduce_5_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_5_6_0 [label="MLP_Linear1_5_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_5_6_0 [label="GELU_5_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_5_6_0 [label="MLP_Linear2_5_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_5_6_1 [label="MLP_Linear1_5_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_5_6_1 [label="GELU_5_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_5_6_1 [label="MLP_Linear2_5_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_5_6_2 [label="MLP_Linear1_5_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_5_6_2 [label="GELU_5_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_5_6_2 [label="MLP_Linear2_5_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_5_6_3 [label="MLP_Linear1_5_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_5_6_3 [label="GELU_5_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_5_6_3 [label="MLP_Linear2_5_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp_allreduce_5_6 [label="MLP_AllReduce_5_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_5_7_0 [label="MLP_Linear1_5_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_5_7_0 [label="GELU_5_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_5_7_0 [label="MLP_Linear2_5_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_5_7_1 [label="MLP_Linear1_5_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_5_7_1 [label="GELU_5_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_5_7_1 [label="MLP_Linear2_5_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_5_7_2 [label="MLP_Linear1_5_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_5_7_2 [label="GELU_5_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_5_7_2 [label="MLP_Linear2_5_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_5_7_3 [label="MLP_Linear1_5_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_5_7_3 [label="GELU_5_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_5_7_3 [label="MLP_Linear2_5_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp_allreduce_5_7 [label="MLP_AllReduce_5_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_5_8_0 [label="MLP_Linear1_5_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_5_8_0 [label="GELU_5_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_5_8_0 [label="MLP_Linear2_5_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_5_8_1 [label="MLP_Linear1_5_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_5_8_1 [label="GELU_5_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_5_8_1 [label="MLP_Linear2_5_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_5_8_2 [label="MLP_Linear1_5_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_5_8_2 [label="GELU_5_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_5_8_2 [label="MLP_Linear2_5_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_5_8_3 [label="MLP_Linear1_5_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_5_8_3 [label="GELU_5_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_5_8_3 [label="MLP_Linear2_5_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp_allreduce_5_8 [label="MLP_AllReduce_5_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_5_9_0 [label="MLP_Linear1_5_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_5_9_0 [label="GELU_5_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_5_9_0 [label="MLP_Linear2_5_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_5_9_1 [label="MLP_Linear1_5_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_5_9_1 [label="GELU_5_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_5_9_1 [label="MLP_Linear2_5_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_5_9_2 [label="MLP_Linear1_5_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_5_9_2 [label="GELU_5_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_5_9_2 [label="MLP_Linear2_5_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_5_9_3 [label="MLP_Linear1_5_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_5_9_3 [label="GELU_5_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_5_9_3 [label="MLP_Linear2_5_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp_allreduce_5_9 [label="MLP_AllReduce_5_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_5_10_0 [label="MLP_Linear1_5_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_5_10_0 [label="GELU_5_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_5_10_0 [label="MLP_Linear2_5_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_5_10_1 [label="MLP_Linear1_5_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_5_10_1 [label="GELU_5_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_5_10_1 [label="MLP_Linear2_5_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_5_10_2 [label="MLP_Linear1_5_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_5_10_2 [label="GELU_5_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_5_10_2 [label="MLP_Linear2_5_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_5_10_3 [label="MLP_Linear1_5_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_5_10_3 [label="GELU_5_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_5_10_3 [label="MLP_Linear2_5_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp_allreduce_5_10 [label="MLP_AllReduce_5_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_5_11_0 [label="MLP_Linear1_5_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_5_11_0 [label="GELU_5_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_5_11_0 [label="MLP_Linear2_5_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_5_11_1 [label="MLP_Linear1_5_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_5_11_1 [label="GELU_5_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_5_11_1 [label="MLP_Linear2_5_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_5_11_2 [label="MLP_Linear1_5_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_5_11_2 [label="GELU_5_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_5_11_2 [label="MLP_Linear2_5_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_5_11_3 [label="MLP_Linear1_5_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_5_11_3 [label="GELU_5_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_5_11_3 [label="MLP_Linear2_5_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp_allreduce_5_11 [label="MLP_AllReduce_5_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_5_12_0 [label="MLP_Linear1_5_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_5_12_0 [label="GELU_5_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_5_12_0 [label="MLP_Linear2_5_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_5_12_1 [label="MLP_Linear1_5_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_5_12_1 [label="GELU_5_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_5_12_1 [label="MLP_Linear2_5_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_5_12_2 [label="MLP_Linear1_5_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_5_12_2 [label="GELU_5_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_5_12_2 [label="MLP_Linear2_5_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_5_12_3 [label="MLP_Linear1_5_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_5_12_3 [label="GELU_5_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_5_12_3 [label="MLP_Linear2_5_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp_allreduce_5_12 [label="MLP_AllReduce_5_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_5_13_0 [label="MLP_Linear1_5_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_5_13_0 [label="GELU_5_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_5_13_0 [label="MLP_Linear2_5_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_5_13_1 [label="MLP_Linear1_5_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_5_13_1 [label="GELU_5_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_5_13_1 [label="MLP_Linear2_5_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_5_13_2 [label="MLP_Linear1_5_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_5_13_2 [label="GELU_5_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_5_13_2 [label="MLP_Linear2_5_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_5_13_3 [label="MLP_Linear1_5_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_5_13_3 [label="GELU_5_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_5_13_3 [label="MLP_Linear2_5_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp_allreduce_5_13 [label="MLP_AllReduce_5_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_5_14_0 [label="MLP_Linear1_5_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_5_14_0 [label="GELU_5_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_5_14_0 [label="MLP_Linear2_5_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_5_14_1 [label="MLP_Linear1_5_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_5_14_1 [label="GELU_5_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_5_14_1 [label="MLP_Linear2_5_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_5_14_2 [label="MLP_Linear1_5_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_5_14_2 [label="GELU_5_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_5_14_2 [label="MLP_Linear2_5_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_5_14_3 [label="MLP_Linear1_5_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_5_14_3 [label="GELU_5_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_5_14_3 [label="MLP_Linear2_5_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp_allreduce_5_14 [label="MLP_AllReduce_5_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_5_15_0 [label="MLP_Linear1_5_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_5_15_0 [label="GELU_5_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_5_15_0 [label="MLP_Linear2_5_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_5_15_1 [label="MLP_Linear1_5_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_5_15_1 [label="GELU_5_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_5_15_1 [label="MLP_Linear2_5_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_5_15_2 [label="MLP_Linear1_5_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_5_15_2 [label="GELU_5_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_5_15_2 [label="MLP_Linear2_5_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_5_15_3 [label="MLP_Linear1_5_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_5_15_3 [label="GELU_5_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_5_15_3 [label="MLP_Linear2_5_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp_allreduce_5_15 [label="MLP_AllReduce_5_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	expert_route_5_0 [label="Expert_Route_5_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_5_1 [label="Expert_Route_5_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_5_2 [label="Expert_Route_5_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_5_3 [label="Expert_Route_5_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_5_4 [label="Expert_Route_5_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_5_5 [label="Expert_Route_5_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_5_6 [label="Expert_Route_5_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_5_7 [label="Expert_Route_5_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_5_8 [label="Expert_Route_5_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_5_9 [label="Expert_Route_5_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_5_10 [label="Expert_Route_5_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_5_11 [label="Expert_Route_5_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_5_12 [label="Expert_Route_5_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_5_13 [label="Expert_Route_5_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_5_14 [label="Expert_Route_5_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_5_15 [label="Expert_Route_5_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	qkv_6_0_0 [label="QKV_Proj_6_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_6_0_0 [label="Attention_6_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_6_0_0 [label="Attention_Output_6_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_6_0_1 [label="QKV_Proj_6_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_6_0_1 [label="Attention_6_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_6_0_1 [label="Attention_Output_6_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_6_0_2 [label="QKV_Proj_6_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_6_0_2 [label="Attention_6_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_6_0_2 [label="Attention_Output_6_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_6_0_3 [label="QKV_Proj_6_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_6_0_3 [label="Attention_6_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_6_0_3 [label="Attention_Output_6_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	attn_allreduce_6_0 [label="Attention_AllReduce_6_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_6_1_0 [label="QKV_Proj_6_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_6_1_0 [label="Attention_6_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_6_1_0 [label="Attention_Output_6_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_6_1_1 [label="QKV_Proj_6_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_6_1_1 [label="Attention_6_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_6_1_1 [label="Attention_Output_6_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_6_1_2 [label="QKV_Proj_6_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_6_1_2 [label="Attention_6_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_6_1_2 [label="Attention_Output_6_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_6_1_3 [label="QKV_Proj_6_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_6_1_3 [label="Attention_6_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_6_1_3 [label="Attention_Output_6_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	attn_allreduce_6_1 [label="Attention_AllReduce_6_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_6_2_0 [label="QKV_Proj_6_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_6_2_0 [label="Attention_6_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_6_2_0 [label="Attention_Output_6_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_6_2_1 [label="QKV_Proj_6_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_6_2_1 [label="Attention_6_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_6_2_1 [label="Attention_Output_6_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_6_2_2 [label="QKV_Proj_6_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_6_2_2 [label="Attention_6_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_6_2_2 [label="Attention_Output_6_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_6_2_3 [label="QKV_Proj_6_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_6_2_3 [label="Attention_6_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_6_2_3 [label="Attention_Output_6_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	attn_allreduce_6_2 [label="Attention_AllReduce_6_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_6_3_0 [label="QKV_Proj_6_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_6_3_0 [label="Attention_6_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_6_3_0 [label="Attention_Output_6_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_6_3_1 [label="QKV_Proj_6_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_6_3_1 [label="Attention_6_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_6_3_1 [label="Attention_Output_6_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_6_3_2 [label="QKV_Proj_6_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_6_3_2 [label="Attention_6_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_6_3_2 [label="Attention_Output_6_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_6_3_3 [label="QKV_Proj_6_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_6_3_3 [label="Attention_6_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_6_3_3 [label="Attention_Output_6_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	attn_allreduce_6_3 [label="Attention_AllReduce_6_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_6_4_0 [label="QKV_Proj_6_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_6_4_0 [label="Attention_6_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_6_4_0 [label="Attention_Output_6_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_6_4_1 [label="QKV_Proj_6_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_6_4_1 [label="Attention_6_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_6_4_1 [label="Attention_Output_6_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_6_4_2 [label="QKV_Proj_6_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_6_4_2 [label="Attention_6_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_6_4_2 [label="Attention_Output_6_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_6_4_3 [label="QKV_Proj_6_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_6_4_3 [label="Attention_6_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_6_4_3 [label="Attention_Output_6_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	attn_allreduce_6_4 [label="Attention_AllReduce_6_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_6_5_0 [label="QKV_Proj_6_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_6_5_0 [label="Attention_6_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_6_5_0 [label="Attention_Output_6_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_6_5_1 [label="QKV_Proj_6_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_6_5_1 [label="Attention_6_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_6_5_1 [label="Attention_Output_6_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_6_5_2 [label="QKV_Proj_6_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_6_5_2 [label="Attention_6_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_6_5_2 [label="Attention_Output_6_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_6_5_3 [label="QKV_Proj_6_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_6_5_3 [label="Attention_6_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_6_5_3 [label="Attention_Output_6_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	attn_allreduce_6_5 [label="Attention_AllReduce_6_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_6_6_0 [label="QKV_Proj_6_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_6_6_0 [label="Attention_6_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_6_6_0 [label="Attention_Output_6_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_6_6_1 [label="QKV_Proj_6_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_6_6_1 [label="Attention_6_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_6_6_1 [label="Attention_Output_6_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_6_6_2 [label="QKV_Proj_6_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_6_6_2 [label="Attention_6_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_6_6_2 [label="Attention_Output_6_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_6_6_3 [label="QKV_Proj_6_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_6_6_3 [label="Attention_6_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_6_6_3 [label="Attention_Output_6_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	attn_allreduce_6_6 [label="Attention_AllReduce_6_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_6_7_0 [label="QKV_Proj_6_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_6_7_0 [label="Attention_6_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_6_7_0 [label="Attention_Output_6_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_6_7_1 [label="QKV_Proj_6_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_6_7_1 [label="Attention_6_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_6_7_1 [label="Attention_Output_6_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_6_7_2 [label="QKV_Proj_6_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_6_7_2 [label="Attention_6_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_6_7_2 [label="Attention_Output_6_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_6_7_3 [label="QKV_Proj_6_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_6_7_3 [label="Attention_6_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_6_7_3 [label="Attention_Output_6_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	attn_allreduce_6_7 [label="Attention_AllReduce_6_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_6_8_0 [label="QKV_Proj_6_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_6_8_0 [label="Attention_6_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_6_8_0 [label="Attention_Output_6_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_6_8_1 [label="QKV_Proj_6_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_6_8_1 [label="Attention_6_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_6_8_1 [label="Attention_Output_6_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_6_8_2 [label="QKV_Proj_6_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_6_8_2 [label="Attention_6_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_6_8_2 [label="Attention_Output_6_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_6_8_3 [label="QKV_Proj_6_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_6_8_3 [label="Attention_6_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_6_8_3 [label="Attention_Output_6_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	attn_allreduce_6_8 [label="Attention_AllReduce_6_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_6_9_0 [label="QKV_Proj_6_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_6_9_0 [label="Attention_6_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_6_9_0 [label="Attention_Output_6_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_6_9_1 [label="QKV_Proj_6_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_6_9_1 [label="Attention_6_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_6_9_1 [label="Attention_Output_6_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_6_9_2 [label="QKV_Proj_6_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_6_9_2 [label="Attention_6_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_6_9_2 [label="Attention_Output_6_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_6_9_3 [label="QKV_Proj_6_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_6_9_3 [label="Attention_6_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_6_9_3 [label="Attention_Output_6_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	attn_allreduce_6_9 [label="Attention_AllReduce_6_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_6_10_0 [label="QKV_Proj_6_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_6_10_0 [label="Attention_6_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_6_10_0 [label="Attention_Output_6_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_6_10_1 [label="QKV_Proj_6_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_6_10_1 [label="Attention_6_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_6_10_1 [label="Attention_Output_6_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_6_10_2 [label="QKV_Proj_6_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_6_10_2 [label="Attention_6_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_6_10_2 [label="Attention_Output_6_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_6_10_3 [label="QKV_Proj_6_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_6_10_3 [label="Attention_6_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_6_10_3 [label="Attention_Output_6_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	attn_allreduce_6_10 [label="Attention_AllReduce_6_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_6_11_0 [label="QKV_Proj_6_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_6_11_0 [label="Attention_6_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_6_11_0 [label="Attention_Output_6_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_6_11_1 [label="QKV_Proj_6_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_6_11_1 [label="Attention_6_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_6_11_1 [label="Attention_Output_6_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_6_11_2 [label="QKV_Proj_6_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_6_11_2 [label="Attention_6_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_6_11_2 [label="Attention_Output_6_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_6_11_3 [label="QKV_Proj_6_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_6_11_3 [label="Attention_6_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_6_11_3 [label="Attention_Output_6_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	attn_allreduce_6_11 [label="Attention_AllReduce_6_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_6_12_0 [label="QKV_Proj_6_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_6_12_0 [label="Attention_6_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_6_12_0 [label="Attention_Output_6_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_6_12_1 [label="QKV_Proj_6_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_6_12_1 [label="Attention_6_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_6_12_1 [label="Attention_Output_6_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_6_12_2 [label="QKV_Proj_6_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_6_12_2 [label="Attention_6_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_6_12_2 [label="Attention_Output_6_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_6_12_3 [label="QKV_Proj_6_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_6_12_3 [label="Attention_6_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_6_12_3 [label="Attention_Output_6_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	attn_allreduce_6_12 [label="Attention_AllReduce_6_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_6_13_0 [label="QKV_Proj_6_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_6_13_0 [label="Attention_6_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_6_13_0 [label="Attention_Output_6_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_6_13_1 [label="QKV_Proj_6_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_6_13_1 [label="Attention_6_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_6_13_1 [label="Attention_Output_6_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_6_13_2 [label="QKV_Proj_6_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_6_13_2 [label="Attention_6_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_6_13_2 [label="Attention_Output_6_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_6_13_3 [label="QKV_Proj_6_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_6_13_3 [label="Attention_6_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_6_13_3 [label="Attention_Output_6_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	attn_allreduce_6_13 [label="Attention_AllReduce_6_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_6_14_0 [label="QKV_Proj_6_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_6_14_0 [label="Attention_6_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_6_14_0 [label="Attention_Output_6_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_6_14_1 [label="QKV_Proj_6_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_6_14_1 [label="Attention_6_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_6_14_1 [label="Attention_Output_6_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_6_14_2 [label="QKV_Proj_6_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_6_14_2 [label="Attention_6_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_6_14_2 [label="Attention_Output_6_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_6_14_3 [label="QKV_Proj_6_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_6_14_3 [label="Attention_6_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_6_14_3 [label="Attention_Output_6_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	attn_allreduce_6_14 [label="Attention_AllReduce_6_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_6_15_0 [label="QKV_Proj_6_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_6_15_0 [label="Attention_6_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_6_15_0 [label="Attention_Output_6_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_6_15_1 [label="QKV_Proj_6_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_6_15_1 [label="Attention_6_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_6_15_1 [label="Attention_Output_6_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_6_15_2 [label="QKV_Proj_6_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_6_15_2 [label="Attention_6_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_6_15_2 [label="Attention_Output_6_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_6_15_3 [label="QKV_Proj_6_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_6_15_3 [label="Attention_6_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_6_15_3 [label="Attention_Output_6_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	attn_allreduce_6_15 [label="Attention_AllReduce_6_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_6_0_0 [label="MLP_Linear1_6_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_6_0_0 [label="GELU_6_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_6_0_0 [label="MLP_Linear2_6_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_6_0_1 [label="MLP_Linear1_6_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_6_0_1 [label="GELU_6_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_6_0_1 [label="MLP_Linear2_6_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_6_0_2 [label="MLP_Linear1_6_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_6_0_2 [label="GELU_6_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_6_0_2 [label="MLP_Linear2_6_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_6_0_3 [label="MLP_Linear1_6_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_6_0_3 [label="GELU_6_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_6_0_3 [label="MLP_Linear2_6_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp_allreduce_6_0 [label="MLP_AllReduce_6_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_6_1_0 [label="MLP_Linear1_6_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_6_1_0 [label="GELU_6_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_6_1_0 [label="MLP_Linear2_6_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_6_1_1 [label="MLP_Linear1_6_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_6_1_1 [label="GELU_6_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_6_1_1 [label="MLP_Linear2_6_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_6_1_2 [label="MLP_Linear1_6_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_6_1_2 [label="GELU_6_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_6_1_2 [label="MLP_Linear2_6_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_6_1_3 [label="MLP_Linear1_6_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_6_1_3 [label="GELU_6_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_6_1_3 [label="MLP_Linear2_6_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp_allreduce_6_1 [label="MLP_AllReduce_6_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_6_2_0 [label="MLP_Linear1_6_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_6_2_0 [label="GELU_6_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_6_2_0 [label="MLP_Linear2_6_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_6_2_1 [label="MLP_Linear1_6_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_6_2_1 [label="GELU_6_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_6_2_1 [label="MLP_Linear2_6_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_6_2_2 [label="MLP_Linear1_6_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_6_2_2 [label="GELU_6_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_6_2_2 [label="MLP_Linear2_6_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_6_2_3 [label="MLP_Linear1_6_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_6_2_3 [label="GELU_6_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_6_2_3 [label="MLP_Linear2_6_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp_allreduce_6_2 [label="MLP_AllReduce_6_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_6_3_0 [label="MLP_Linear1_6_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_6_3_0 [label="GELU_6_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_6_3_0 [label="MLP_Linear2_6_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_6_3_1 [label="MLP_Linear1_6_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_6_3_1 [label="GELU_6_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_6_3_1 [label="MLP_Linear2_6_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_6_3_2 [label="MLP_Linear1_6_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_6_3_2 [label="GELU_6_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_6_3_2 [label="MLP_Linear2_6_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_6_3_3 [label="MLP_Linear1_6_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_6_3_3 [label="GELU_6_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_6_3_3 [label="MLP_Linear2_6_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp_allreduce_6_3 [label="MLP_AllReduce_6_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_6_4_0 [label="MLP_Linear1_6_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_6_4_0 [label="GELU_6_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_6_4_0 [label="MLP_Linear2_6_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_6_4_1 [label="MLP_Linear1_6_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_6_4_1 [label="GELU_6_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_6_4_1 [label="MLP_Linear2_6_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_6_4_2 [label="MLP_Linear1_6_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_6_4_2 [label="GELU_6_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_6_4_2 [label="MLP_Linear2_6_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_6_4_3 [label="MLP_Linear1_6_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_6_4_3 [label="GELU_6_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_6_4_3 [label="MLP_Linear2_6_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp_allreduce_6_4 [label="MLP_AllReduce_6_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_6_5_0 [label="MLP_Linear1_6_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_6_5_0 [label="GELU_6_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_6_5_0 [label="MLP_Linear2_6_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_6_5_1 [label="MLP_Linear1_6_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_6_5_1 [label="GELU_6_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_6_5_1 [label="MLP_Linear2_6_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_6_5_2 [label="MLP_Linear1_6_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_6_5_2 [label="GELU_6_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_6_5_2 [label="MLP_Linear2_6_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_6_5_3 [label="MLP_Linear1_6_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_6_5_3 [label="GELU_6_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_6_5_3 [label="MLP_Linear2_6_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp_allreduce_6_5 [label="MLP_AllReduce_6_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_6_6_0 [label="MLP_Linear1_6_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_6_6_0 [label="GELU_6_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_6_6_0 [label="MLP_Linear2_6_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_6_6_1 [label="MLP_Linear1_6_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_6_6_1 [label="GELU_6_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_6_6_1 [label="MLP_Linear2_6_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_6_6_2 [label="MLP_Linear1_6_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_6_6_2 [label="GELU_6_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_6_6_2 [label="MLP_Linear2_6_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_6_6_3 [label="MLP_Linear1_6_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_6_6_3 [label="GELU_6_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_6_6_3 [label="MLP_Linear2_6_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp_allreduce_6_6 [label="MLP_AllReduce_6_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_6_7_0 [label="MLP_Linear1_6_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_6_7_0 [label="GELU_6_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_6_7_0 [label="MLP_Linear2_6_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_6_7_1 [label="MLP_Linear1_6_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_6_7_1 [label="GELU_6_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_6_7_1 [label="MLP_Linear2_6_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_6_7_2 [label="MLP_Linear1_6_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_6_7_2 [label="GELU_6_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_6_7_2 [label="MLP_Linear2_6_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_6_7_3 [label="MLP_Linear1_6_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_6_7_3 [label="GELU_6_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_6_7_3 [label="MLP_Linear2_6_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp_allreduce_6_7 [label="MLP_AllReduce_6_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_6_8_0 [label="MLP_Linear1_6_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_6_8_0 [label="GELU_6_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_6_8_0 [label="MLP_Linear2_6_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_6_8_1 [label="MLP_Linear1_6_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_6_8_1 [label="GELU_6_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_6_8_1 [label="MLP_Linear2_6_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_6_8_2 [label="MLP_Linear1_6_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_6_8_2 [label="GELU_6_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_6_8_2 [label="MLP_Linear2_6_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_6_8_3 [label="MLP_Linear1_6_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_6_8_3 [label="GELU_6_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_6_8_3 [label="MLP_Linear2_6_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp_allreduce_6_8 [label="MLP_AllReduce_6_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_6_9_0 [label="MLP_Linear1_6_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_6_9_0 [label="GELU_6_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_6_9_0 [label="MLP_Linear2_6_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_6_9_1 [label="MLP_Linear1_6_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_6_9_1 [label="GELU_6_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_6_9_1 [label="MLP_Linear2_6_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_6_9_2 [label="MLP_Linear1_6_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_6_9_2 [label="GELU_6_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_6_9_2 [label="MLP_Linear2_6_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_6_9_3 [label="MLP_Linear1_6_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_6_9_3 [label="GELU_6_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_6_9_3 [label="MLP_Linear2_6_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp_allreduce_6_9 [label="MLP_AllReduce_6_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_6_10_0 [label="MLP_Linear1_6_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_6_10_0 [label="GELU_6_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_6_10_0 [label="MLP_Linear2_6_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_6_10_1 [label="MLP_Linear1_6_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_6_10_1 [label="GELU_6_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_6_10_1 [label="MLP_Linear2_6_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_6_10_2 [label="MLP_Linear1_6_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_6_10_2 [label="GELU_6_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_6_10_2 [label="MLP_Linear2_6_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_6_10_3 [label="MLP_Linear1_6_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_6_10_3 [label="GELU_6_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_6_10_3 [label="MLP_Linear2_6_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp_allreduce_6_10 [label="MLP_AllReduce_6_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_6_11_0 [label="MLP_Linear1_6_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_6_11_0 [label="GELU_6_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_6_11_0 [label="MLP_Linear2_6_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_6_11_1 [label="MLP_Linear1_6_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_6_11_1 [label="GELU_6_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_6_11_1 [label="MLP_Linear2_6_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_6_11_2 [label="MLP_Linear1_6_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_6_11_2 [label="GELU_6_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_6_11_2 [label="MLP_Linear2_6_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_6_11_3 [label="MLP_Linear1_6_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_6_11_3 [label="GELU_6_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_6_11_3 [label="MLP_Linear2_6_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp_allreduce_6_11 [label="MLP_AllReduce_6_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_6_12_0 [label="MLP_Linear1_6_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_6_12_0 [label="GELU_6_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_6_12_0 [label="MLP_Linear2_6_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_6_12_1 [label="MLP_Linear1_6_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_6_12_1 [label="GELU_6_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_6_12_1 [label="MLP_Linear2_6_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_6_12_2 [label="MLP_Linear1_6_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_6_12_2 [label="GELU_6_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_6_12_2 [label="MLP_Linear2_6_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_6_12_3 [label="MLP_Linear1_6_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_6_12_3 [label="GELU_6_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_6_12_3 [label="MLP_Linear2_6_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp_allreduce_6_12 [label="MLP_AllReduce_6_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_6_13_0 [label="MLP_Linear1_6_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_6_13_0 [label="GELU_6_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_6_13_0 [label="MLP_Linear2_6_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_6_13_1 [label="MLP_Linear1_6_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_6_13_1 [label="GELU_6_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_6_13_1 [label="MLP_Linear2_6_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_6_13_2 [label="MLP_Linear1_6_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_6_13_2 [label="GELU_6_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_6_13_2 [label="MLP_Linear2_6_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_6_13_3 [label="MLP_Linear1_6_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_6_13_3 [label="GELU_6_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_6_13_3 [label="MLP_Linear2_6_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp_allreduce_6_13 [label="MLP_AllReduce_6_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_6_14_0 [label="MLP_Linear1_6_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_6_14_0 [label="GELU_6_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_6_14_0 [label="MLP_Linear2_6_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_6_14_1 [label="MLP_Linear1_6_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_6_14_1 [label="GELU_6_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_6_14_1 [label="MLP_Linear2_6_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_6_14_2 [label="MLP_Linear1_6_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_6_14_2 [label="GELU_6_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_6_14_2 [label="MLP_Linear2_6_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_6_14_3 [label="MLP_Linear1_6_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_6_14_3 [label="GELU_6_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_6_14_3 [label="MLP_Linear2_6_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp_allreduce_6_14 [label="MLP_AllReduce_6_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_6_15_0 [label="MLP_Linear1_6_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_6_15_0 [label="GELU_6_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_6_15_0 [label="MLP_Linear2_6_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_6_15_1 [label="MLP_Linear1_6_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_6_15_1 [label="GELU_6_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_6_15_1 [label="MLP_Linear2_6_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_6_15_2 [label="MLP_Linear1_6_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_6_15_2 [label="GELU_6_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_6_15_2 [label="MLP_Linear2_6_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_6_15_3 [label="MLP_Linear1_6_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_6_15_3 [label="GELU_6_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_6_15_3 [label="MLP_Linear2_6_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp_allreduce_6_15 [label="MLP_AllReduce_6_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	expert_route_6_0 [label="Expert_Route_6_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_6_1 [label="Expert_Route_6_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_6_2 [label="Expert_Route_6_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_6_3 [label="Expert_Route_6_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_6_4 [label="Expert_Route_6_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_6_5 [label="Expert_Route_6_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_6_6 [label="Expert_Route_6_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_6_7 [label="Expert_Route_6_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_6_8 [label="Expert_Route_6_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_6_9 [label="Expert_Route_6_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_6_10 [label="Expert_Route_6_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_6_11 [label="Expert_Route_6_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_6_12 [label="Expert_Route_6_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_6_13 [label="Expert_Route_6_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_6_14 [label="Expert_Route_6_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_6_15 [label="Expert_Route_6_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	qkv_7_0_0 [label="QKV_Proj_7_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_7_0_0 [label="Attention_7_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_7_0_0 [label="Attention_Output_7_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_7_0_1 [label="QKV_Proj_7_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_7_0_1 [label="Attention_7_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_7_0_1 [label="Attention_Output_7_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_7_0_2 [label="QKV_Proj_7_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_7_0_2 [label="Attention_7_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_7_0_2 [label="Attention_Output_7_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_7_0_3 [label="QKV_Proj_7_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_7_0_3 [label="Attention_7_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_7_0_3 [label="Attention_Output_7_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	attn_allreduce_7_0 [label="Attention_AllReduce_7_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_7_1_0 [label="QKV_Proj_7_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_7_1_0 [label="Attention_7_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_7_1_0 [label="Attention_Output_7_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_7_1_1 [label="QKV_Proj_7_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_7_1_1 [label="Attention_7_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_7_1_1 [label="Attention_Output_7_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_7_1_2 [label="QKV_Proj_7_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_7_1_2 [label="Attention_7_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_7_1_2 [label="Attention_Output_7_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_7_1_3 [label="QKV_Proj_7_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_7_1_3 [label="Attention_7_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_7_1_3 [label="Attention_Output_7_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	attn_allreduce_7_1 [label="Attention_AllReduce_7_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_7_2_0 [label="QKV_Proj_7_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_7_2_0 [label="Attention_7_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_7_2_0 [label="Attention_Output_7_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_7_2_1 [label="QKV_Proj_7_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_7_2_1 [label="Attention_7_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_7_2_1 [label="Attention_Output_7_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_7_2_2 [label="QKV_Proj_7_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_7_2_2 [label="Attention_7_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_7_2_2 [label="Attention_Output_7_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_7_2_3 [label="QKV_Proj_7_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_7_2_3 [label="Attention_7_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_7_2_3 [label="Attention_Output_7_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	attn_allreduce_7_2 [label="Attention_AllReduce_7_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_7_3_0 [label="QKV_Proj_7_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_7_3_0 [label="Attention_7_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_7_3_0 [label="Attention_Output_7_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_7_3_1 [label="QKV_Proj_7_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_7_3_1 [label="Attention_7_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_7_3_1 [label="Attention_Output_7_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_7_3_2 [label="QKV_Proj_7_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_7_3_2 [label="Attention_7_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_7_3_2 [label="Attention_Output_7_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_7_3_3 [label="QKV_Proj_7_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_7_3_3 [label="Attention_7_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_7_3_3 [label="Attention_Output_7_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	attn_allreduce_7_3 [label="Attention_AllReduce_7_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_7_4_0 [label="QKV_Proj_7_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_7_4_0 [label="Attention_7_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_7_4_0 [label="Attention_Output_7_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_7_4_1 [label="QKV_Proj_7_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_7_4_1 [label="Attention_7_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_7_4_1 [label="Attention_Output_7_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_7_4_2 [label="QKV_Proj_7_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_7_4_2 [label="Attention_7_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_7_4_2 [label="Attention_Output_7_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_7_4_3 [label="QKV_Proj_7_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_7_4_3 [label="Attention_7_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_7_4_3 [label="Attention_Output_7_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	attn_allreduce_7_4 [label="Attention_AllReduce_7_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_7_5_0 [label="QKV_Proj_7_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_7_5_0 [label="Attention_7_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_7_5_0 [label="Attention_Output_7_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_7_5_1 [label="QKV_Proj_7_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_7_5_1 [label="Attention_7_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_7_5_1 [label="Attention_Output_7_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_7_5_2 [label="QKV_Proj_7_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_7_5_2 [label="Attention_7_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_7_5_2 [label="Attention_Output_7_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_7_5_3 [label="QKV_Proj_7_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_7_5_3 [label="Attention_7_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_7_5_3 [label="Attention_Output_7_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	attn_allreduce_7_5 [label="Attention_AllReduce_7_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_7_6_0 [label="QKV_Proj_7_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_7_6_0 [label="Attention_7_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_7_6_0 [label="Attention_Output_7_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_7_6_1 [label="QKV_Proj_7_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_7_6_1 [label="Attention_7_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_7_6_1 [label="Attention_Output_7_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_7_6_2 [label="QKV_Proj_7_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_7_6_2 [label="Attention_7_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_7_6_2 [label="Attention_Output_7_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_7_6_3 [label="QKV_Proj_7_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_7_6_3 [label="Attention_7_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_7_6_3 [label="Attention_Output_7_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	attn_allreduce_7_6 [label="Attention_AllReduce_7_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_7_7_0 [label="QKV_Proj_7_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_7_7_0 [label="Attention_7_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_7_7_0 [label="Attention_Output_7_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_7_7_1 [label="QKV_Proj_7_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_7_7_1 [label="Attention_7_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_7_7_1 [label="Attention_Output_7_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_7_7_2 [label="QKV_Proj_7_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_7_7_2 [label="Attention_7_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_7_7_2 [label="Attention_Output_7_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_7_7_3 [label="QKV_Proj_7_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_7_7_3 [label="Attention_7_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_7_7_3 [label="Attention_Output_7_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	attn_allreduce_7_7 [label="Attention_AllReduce_7_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_7_8_0 [label="QKV_Proj_7_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_7_8_0 [label="Attention_7_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_7_8_0 [label="Attention_Output_7_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_7_8_1 [label="QKV_Proj_7_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_7_8_1 [label="Attention_7_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_7_8_1 [label="Attention_Output_7_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_7_8_2 [label="QKV_Proj_7_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_7_8_2 [label="Attention_7_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_7_8_2 [label="Attention_Output_7_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_7_8_3 [label="QKV_Proj_7_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_7_8_3 [label="Attention_7_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_7_8_3 [label="Attention_Output_7_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	attn_allreduce_7_8 [label="Attention_AllReduce_7_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_7_9_0 [label="QKV_Proj_7_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_7_9_0 [label="Attention_7_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_7_9_0 [label="Attention_Output_7_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_7_9_1 [label="QKV_Proj_7_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_7_9_1 [label="Attention_7_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_7_9_1 [label="Attention_Output_7_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_7_9_2 [label="QKV_Proj_7_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_7_9_2 [label="Attention_7_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_7_9_2 [label="Attention_Output_7_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_7_9_3 [label="QKV_Proj_7_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_7_9_3 [label="Attention_7_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_7_9_3 [label="Attention_Output_7_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	attn_allreduce_7_9 [label="Attention_AllReduce_7_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_7_10_0 [label="QKV_Proj_7_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_7_10_0 [label="Attention_7_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_7_10_0 [label="Attention_Output_7_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_7_10_1 [label="QKV_Proj_7_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_7_10_1 [label="Attention_7_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_7_10_1 [label="Attention_Output_7_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_7_10_2 [label="QKV_Proj_7_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_7_10_2 [label="Attention_7_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_7_10_2 [label="Attention_Output_7_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_7_10_3 [label="QKV_Proj_7_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_7_10_3 [label="Attention_7_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_7_10_3 [label="Attention_Output_7_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	attn_allreduce_7_10 [label="Attention_AllReduce_7_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_7_11_0 [label="QKV_Proj_7_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_7_11_0 [label="Attention_7_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_7_11_0 [label="Attention_Output_7_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_7_11_1 [label="QKV_Proj_7_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_7_11_1 [label="Attention_7_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_7_11_1 [label="Attention_Output_7_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_7_11_2 [label="QKV_Proj_7_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_7_11_2 [label="Attention_7_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_7_11_2 [label="Attention_Output_7_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_7_11_3 [label="QKV_Proj_7_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_7_11_3 [label="Attention_7_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_7_11_3 [label="Attention_Output_7_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	attn_allreduce_7_11 [label="Attention_AllReduce_7_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_7_12_0 [label="QKV_Proj_7_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_7_12_0 [label="Attention_7_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_7_12_0 [label="Attention_Output_7_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_7_12_1 [label="QKV_Proj_7_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_7_12_1 [label="Attention_7_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_7_12_1 [label="Attention_Output_7_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_7_12_2 [label="QKV_Proj_7_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_7_12_2 [label="Attention_7_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_7_12_2 [label="Attention_Output_7_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_7_12_3 [label="QKV_Proj_7_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_7_12_3 [label="Attention_7_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_7_12_3 [label="Attention_Output_7_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	attn_allreduce_7_12 [label="Attention_AllReduce_7_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_7_13_0 [label="QKV_Proj_7_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_7_13_0 [label="Attention_7_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_7_13_0 [label="Attention_Output_7_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_7_13_1 [label="QKV_Proj_7_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_7_13_1 [label="Attention_7_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_7_13_1 [label="Attention_Output_7_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_7_13_2 [label="QKV_Proj_7_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_7_13_2 [label="Attention_7_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_7_13_2 [label="Attention_Output_7_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_7_13_3 [label="QKV_Proj_7_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_7_13_3 [label="Attention_7_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_7_13_3 [label="Attention_Output_7_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	attn_allreduce_7_13 [label="Attention_AllReduce_7_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_7_14_0 [label="QKV_Proj_7_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_7_14_0 [label="Attention_7_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_7_14_0 [label="Attention_Output_7_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_7_14_1 [label="QKV_Proj_7_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_7_14_1 [label="Attention_7_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_7_14_1 [label="Attention_Output_7_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_7_14_2 [label="QKV_Proj_7_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_7_14_2 [label="Attention_7_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_7_14_2 [label="Attention_Output_7_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_7_14_3 [label="QKV_Proj_7_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_7_14_3 [label="Attention_7_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_7_14_3 [label="Attention_Output_7_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	attn_allreduce_7_14 [label="Attention_AllReduce_7_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_7_15_0 [label="QKV_Proj_7_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_7_15_0 [label="Attention_7_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_7_15_0 [label="Attention_Output_7_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_7_15_1 [label="QKV_Proj_7_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_7_15_1 [label="Attention_7_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_7_15_1 [label="Attention_Output_7_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_7_15_2 [label="QKV_Proj_7_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_7_15_2 [label="Attention_7_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_7_15_2 [label="Attention_Output_7_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_7_15_3 [label="QKV_Proj_7_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_7_15_3 [label="Attention_7_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_7_15_3 [label="Attention_Output_7_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	attn_allreduce_7_15 [label="Attention_AllReduce_7_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_7_0_0 [label="MLP_Linear1_7_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_7_0_0 [label="GELU_7_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_7_0_0 [label="MLP_Linear2_7_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_7_0_1 [label="MLP_Linear1_7_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_7_0_1 [label="GELU_7_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_7_0_1 [label="MLP_Linear2_7_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_7_0_2 [label="MLP_Linear1_7_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_7_0_2 [label="GELU_7_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_7_0_2 [label="MLP_Linear2_7_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_7_0_3 [label="MLP_Linear1_7_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_7_0_3 [label="GELU_7_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_7_0_3 [label="MLP_Linear2_7_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp_allreduce_7_0 [label="MLP_AllReduce_7_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_7_1_0 [label="MLP_Linear1_7_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_7_1_0 [label="GELU_7_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_7_1_0 [label="MLP_Linear2_7_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_7_1_1 [label="MLP_Linear1_7_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_7_1_1 [label="GELU_7_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_7_1_1 [label="MLP_Linear2_7_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_7_1_2 [label="MLP_Linear1_7_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_7_1_2 [label="GELU_7_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_7_1_2 [label="MLP_Linear2_7_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_7_1_3 [label="MLP_Linear1_7_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_7_1_3 [label="GELU_7_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_7_1_3 [label="MLP_Linear2_7_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp_allreduce_7_1 [label="MLP_AllReduce_7_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_7_2_0 [label="MLP_Linear1_7_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_7_2_0 [label="GELU_7_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_7_2_0 [label="MLP_Linear2_7_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_7_2_1 [label="MLP_Linear1_7_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_7_2_1 [label="GELU_7_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_7_2_1 [label="MLP_Linear2_7_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_7_2_2 [label="MLP_Linear1_7_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_7_2_2 [label="GELU_7_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_7_2_2 [label="MLP_Linear2_7_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_7_2_3 [label="MLP_Linear1_7_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_7_2_3 [label="GELU_7_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_7_2_3 [label="MLP_Linear2_7_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp_allreduce_7_2 [label="MLP_AllReduce_7_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_7_3_0 [label="MLP_Linear1_7_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_7_3_0 [label="GELU_7_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_7_3_0 [label="MLP_Linear2_7_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_7_3_1 [label="MLP_Linear1_7_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_7_3_1 [label="GELU_7_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_7_3_1 [label="MLP_Linear2_7_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_7_3_2 [label="MLP_Linear1_7_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_7_3_2 [label="GELU_7_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_7_3_2 [label="MLP_Linear2_7_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_7_3_3 [label="MLP_Linear1_7_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_7_3_3 [label="GELU_7_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_7_3_3 [label="MLP_Linear2_7_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp_allreduce_7_3 [label="MLP_AllReduce_7_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_7_4_0 [label="MLP_Linear1_7_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_7_4_0 [label="GELU_7_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_7_4_0 [label="MLP_Linear2_7_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_7_4_1 [label="MLP_Linear1_7_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_7_4_1 [label="GELU_7_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_7_4_1 [label="MLP_Linear2_7_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_7_4_2 [label="MLP_Linear1_7_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_7_4_2 [label="GELU_7_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_7_4_2 [label="MLP_Linear2_7_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_7_4_3 [label="MLP_Linear1_7_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_7_4_3 [label="GELU_7_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_7_4_3 [label="MLP_Linear2_7_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp_allreduce_7_4 [label="MLP_AllReduce_7_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_7_5_0 [label="MLP_Linear1_7_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_7_5_0 [label="GELU_7_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_7_5_0 [label="MLP_Linear2_7_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_7_5_1 [label="MLP_Linear1_7_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_7_5_1 [label="GELU_7_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_7_5_1 [label="MLP_Linear2_7_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_7_5_2 [label="MLP_Linear1_7_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_7_5_2 [label="GELU_7_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_7_5_2 [label="MLP_Linear2_7_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_7_5_3 [label="MLP_Linear1_7_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_7_5_3 [label="GELU_7_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_7_5_3 [label="MLP_Linear2_7_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp_allreduce_7_5 [label="MLP_AllReduce_7_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_7_6_0 [label="MLP_Linear1_7_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_7_6_0 [label="GELU_7_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_7_6_0 [label="MLP_Linear2_7_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_7_6_1 [label="MLP_Linear1_7_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_7_6_1 [label="GELU_7_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_7_6_1 [label="MLP_Linear2_7_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_7_6_2 [label="MLP_Linear1_7_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_7_6_2 [label="GELU_7_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_7_6_2 [label="MLP_Linear2_7_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_7_6_3 [label="MLP_Linear1_7_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_7_6_3 [label="GELU_7_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_7_6_3 [label="MLP_Linear2_7_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp_allreduce_7_6 [label="MLP_AllReduce_7_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_7_7_0 [label="MLP_Linear1_7_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_7_7_0 [label="GELU_7_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_7_7_0 [label="MLP_Linear2_7_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_7_7_1 [label="MLP_Linear1_7_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_7_7_1 [label="GELU_7_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_7_7_1 [label="MLP_Linear2_7_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_7_7_2 [label="MLP_Linear1_7_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_7_7_2 [label="GELU_7_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_7_7_2 [label="MLP_Linear2_7_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_7_7_3 [label="MLP_Linear1_7_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_7_7_3 [label="GELU_7_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_7_7_3 [label="MLP_Linear2_7_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp_allreduce_7_7 [label="MLP_AllReduce_7_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_7_8_0 [label="MLP_Linear1_7_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_7_8_0 [label="GELU_7_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_7_8_0 [label="MLP_Linear2_7_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_7_8_1 [label="MLP_Linear1_7_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_7_8_1 [label="GELU_7_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_7_8_1 [label="MLP_Linear2_7_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_7_8_2 [label="MLP_Linear1_7_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_7_8_2 [label="GELU_7_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_7_8_2 [label="MLP_Linear2_7_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_7_8_3 [label="MLP_Linear1_7_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_7_8_3 [label="GELU_7_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_7_8_3 [label="MLP_Linear2_7_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp_allreduce_7_8 [label="MLP_AllReduce_7_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_7_9_0 [label="MLP_Linear1_7_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_7_9_0 [label="GELU_7_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_7_9_0 [label="MLP_Linear2_7_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_7_9_1 [label="MLP_Linear1_7_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_7_9_1 [label="GELU_7_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_7_9_1 [label="MLP_Linear2_7_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_7_9_2 [label="MLP_Linear1_7_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_7_9_2 [label="GELU_7_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_7_9_2 [label="MLP_Linear2_7_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_7_9_3 [label="MLP_Linear1_7_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_7_9_3 [label="GELU_7_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_7_9_3 [label="MLP_Linear2_7_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp_allreduce_7_9 [label="MLP_AllReduce_7_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_7_10_0 [label="MLP_Linear1_7_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_7_10_0 [label="GELU_7_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_7_10_0 [label="MLP_Linear2_7_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_7_10_1 [label="MLP_Linear1_7_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_7_10_1 [label="GELU_7_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_7_10_1 [label="MLP_Linear2_7_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_7_10_2 [label="MLP_Linear1_7_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_7_10_2 [label="GELU_7_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_7_10_2 [label="MLP_Linear2_7_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_7_10_3 [label="MLP_Linear1_7_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_7_10_3 [label="GELU_7_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_7_10_3 [label="MLP_Linear2_7_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp_allreduce_7_10 [label="MLP_AllReduce_7_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_7_11_0 [label="MLP_Linear1_7_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_7_11_0 [label="GELU_7_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_7_11_0 [label="MLP_Linear2_7_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_7_11_1 [label="MLP_Linear1_7_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_7_11_1 [label="GELU_7_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_7_11_1 [label="MLP_Linear2_7_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_7_11_2 [label="MLP_Linear1_7_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_7_11_2 [label="GELU_7_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_7_11_2 [label="MLP_Linear2_7_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_7_11_3 [label="MLP_Linear1_7_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_7_11_3 [label="GELU_7_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_7_11_3 [label="MLP_Linear2_7_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp_allreduce_7_11 [label="MLP_AllReduce_7_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_7_12_0 [label="MLP_Linear1_7_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_7_12_0 [label="GELU_7_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_7_12_0 [label="MLP_Linear2_7_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_7_12_1 [label="MLP_Linear1_7_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_7_12_1 [label="GELU_7_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_7_12_1 [label="MLP_Linear2_7_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_7_12_2 [label="MLP_Linear1_7_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_7_12_2 [label="GELU_7_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_7_12_2 [label="MLP_Linear2_7_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_7_12_3 [label="MLP_Linear1_7_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_7_12_3 [label="GELU_7_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_7_12_3 [label="MLP_Linear2_7_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp_allreduce_7_12 [label="MLP_AllReduce_7_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_7_13_0 [label="MLP_Linear1_7_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_7_13_0 [label="GELU_7_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_7_13_0 [label="MLP_Linear2_7_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_7_13_1 [label="MLP_Linear1_7_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_7_13_1 [label="GELU_7_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_7_13_1 [label="MLP_Linear2_7_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_7_13_2 [label="MLP_Linear1_7_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_7_13_2 [label="GELU_7_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_7_13_2 [label="MLP_Linear2_7_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_7_13_3 [label="MLP_Linear1_7_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_7_13_3 [label="GELU_7_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_7_13_3 [label="MLP_Linear2_7_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp_allreduce_7_13 [label="MLP_AllReduce_7_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_7_14_0 [label="MLP_Linear1_7_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_7_14_0 [label="GELU_7_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_7_14_0 [label="MLP_Linear2_7_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_7_14_1 [label="MLP_Linear1_7_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_7_14_1 [label="GELU_7_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_7_14_1 [label="MLP_Linear2_7_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_7_14_2 [label="MLP_Linear1_7_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_7_14_2 [label="GELU_7_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_7_14_2 [label="MLP_Linear2_7_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_7_14_3 [label="MLP_Linear1_7_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_7_14_3 [label="GELU_7_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_7_14_3 [label="MLP_Linear2_7_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp_allreduce_7_14 [label="MLP_AllReduce_7_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_7_15_0 [label="MLP_Linear1_7_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_7_15_0 [label="GELU_7_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_7_15_0 [label="MLP_Linear2_7_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_7_15_1 [label="MLP_Linear1_7_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_7_15_1 [label="GELU_7_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_7_15_1 [label="MLP_Linear2_7_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_7_15_2 [label="MLP_Linear1_7_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_7_15_2 [label="GELU_7_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_7_15_2 [label="MLP_Linear2_7_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_7_15_3 [label="MLP_Linear1_7_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_7_15_3 [label="GELU_7_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_7_15_3 [label="MLP_Linear2_7_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp_allreduce_7_15 [label="MLP_AllReduce_7_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	expert_route_7_0 [label="Expert_Route_7_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_7_1 [label="Expert_Route_7_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_7_2 [label="Expert_Route_7_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_7_3 [label="Expert_Route_7_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_7_4 [label="Expert_Route_7_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_7_5 [label="Expert_Route_7_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_7_6 [label="Expert_Route_7_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_7_7 [label="Expert_Route_7_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_7_8 [label="Expert_Route_7_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_7_9 [label="Expert_Route_7_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_7_10 [label="Expert_Route_7_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_7_11 [label="Expert_Route_7_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_7_12 [label="Expert_Route_7_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_7_13 [label="Expert_Route_7_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_7_14 [label="Expert_Route_7_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_7_15 [label="Expert_Route_7_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	qkv_8_0_0 [label="QKV_Proj_8_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_8_0_0 [label="Attention_8_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_8_0_0 [label="Attention_Output_8_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_8_0_1 [label="QKV_Proj_8_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_8_0_1 [label="Attention_8_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_8_0_1 [label="Attention_Output_8_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_8_0_2 [label="QKV_Proj_8_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_8_0_2 [label="Attention_8_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_8_0_2 [label="Attention_Output_8_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_8_0_3 [label="QKV_Proj_8_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_8_0_3 [label="Attention_8_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_8_0_3 [label="Attention_Output_8_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	attn_allreduce_8_0 [label="Attention_AllReduce_8_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_8_1_0 [label="QKV_Proj_8_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_8_1_0 [label="Attention_8_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_8_1_0 [label="Attention_Output_8_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_8_1_1 [label="QKV_Proj_8_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_8_1_1 [label="Attention_8_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_8_1_1 [label="Attention_Output_8_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_8_1_2 [label="QKV_Proj_8_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_8_1_2 [label="Attention_8_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_8_1_2 [label="Attention_Output_8_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_8_1_3 [label="QKV_Proj_8_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_8_1_3 [label="Attention_8_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_8_1_3 [label="Attention_Output_8_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	attn_allreduce_8_1 [label="Attention_AllReduce_8_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_8_2_0 [label="QKV_Proj_8_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_8_2_0 [label="Attention_8_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_8_2_0 [label="Attention_Output_8_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_8_2_1 [label="QKV_Proj_8_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_8_2_1 [label="Attention_8_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_8_2_1 [label="Attention_Output_8_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_8_2_2 [label="QKV_Proj_8_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_8_2_2 [label="Attention_8_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_8_2_2 [label="Attention_Output_8_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_8_2_3 [label="QKV_Proj_8_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_8_2_3 [label="Attention_8_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_8_2_3 [label="Attention_Output_8_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	attn_allreduce_8_2 [label="Attention_AllReduce_8_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_8_3_0 [label="QKV_Proj_8_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_8_3_0 [label="Attention_8_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_8_3_0 [label="Attention_Output_8_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_8_3_1 [label="QKV_Proj_8_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_8_3_1 [label="Attention_8_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_8_3_1 [label="Attention_Output_8_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_8_3_2 [label="QKV_Proj_8_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_8_3_2 [label="Attention_8_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_8_3_2 [label="Attention_Output_8_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_8_3_3 [label="QKV_Proj_8_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_8_3_3 [label="Attention_8_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_8_3_3 [label="Attention_Output_8_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	attn_allreduce_8_3 [label="Attention_AllReduce_8_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_8_4_0 [label="QKV_Proj_8_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_8_4_0 [label="Attention_8_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_8_4_0 [label="Attention_Output_8_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_8_4_1 [label="QKV_Proj_8_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_8_4_1 [label="Attention_8_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_8_4_1 [label="Attention_Output_8_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_8_4_2 [label="QKV_Proj_8_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_8_4_2 [label="Attention_8_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_8_4_2 [label="Attention_Output_8_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_8_4_3 [label="QKV_Proj_8_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_8_4_3 [label="Attention_8_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_8_4_3 [label="Attention_Output_8_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	attn_allreduce_8_4 [label="Attention_AllReduce_8_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_8_5_0 [label="QKV_Proj_8_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_8_5_0 [label="Attention_8_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_8_5_0 [label="Attention_Output_8_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_8_5_1 [label="QKV_Proj_8_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_8_5_1 [label="Attention_8_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_8_5_1 [label="Attention_Output_8_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_8_5_2 [label="QKV_Proj_8_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_8_5_2 [label="Attention_8_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_8_5_2 [label="Attention_Output_8_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_8_5_3 [label="QKV_Proj_8_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_8_5_3 [label="Attention_8_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_8_5_3 [label="Attention_Output_8_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	attn_allreduce_8_5 [label="Attention_AllReduce_8_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_8_6_0 [label="QKV_Proj_8_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_8_6_0 [label="Attention_8_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_8_6_0 [label="Attention_Output_8_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_8_6_1 [label="QKV_Proj_8_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_8_6_1 [label="Attention_8_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_8_6_1 [label="Attention_Output_8_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_8_6_2 [label="QKV_Proj_8_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_8_6_2 [label="Attention_8_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_8_6_2 [label="Attention_Output_8_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_8_6_3 [label="QKV_Proj_8_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_8_6_3 [label="Attention_8_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_8_6_3 [label="Attention_Output_8_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	attn_allreduce_8_6 [label="Attention_AllReduce_8_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_8_7_0 [label="QKV_Proj_8_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_8_7_0 [label="Attention_8_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_8_7_0 [label="Attention_Output_8_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_8_7_1 [label="QKV_Proj_8_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_8_7_1 [label="Attention_8_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_8_7_1 [label="Attention_Output_8_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_8_7_2 [label="QKV_Proj_8_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_8_7_2 [label="Attention_8_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_8_7_2 [label="Attention_Output_8_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_8_7_3 [label="QKV_Proj_8_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_8_7_3 [label="Attention_8_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_8_7_3 [label="Attention_Output_8_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	attn_allreduce_8_7 [label="Attention_AllReduce_8_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_8_8_0 [label="QKV_Proj_8_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_8_8_0 [label="Attention_8_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_8_8_0 [label="Attention_Output_8_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_8_8_1 [label="QKV_Proj_8_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_8_8_1 [label="Attention_8_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_8_8_1 [label="Attention_Output_8_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_8_8_2 [label="QKV_Proj_8_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_8_8_2 [label="Attention_8_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_8_8_2 [label="Attention_Output_8_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_8_8_3 [label="QKV_Proj_8_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_8_8_3 [label="Attention_8_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_8_8_3 [label="Attention_Output_8_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	attn_allreduce_8_8 [label="Attention_AllReduce_8_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_8_9_0 [label="QKV_Proj_8_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_8_9_0 [label="Attention_8_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_8_9_0 [label="Attention_Output_8_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_8_9_1 [label="QKV_Proj_8_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_8_9_1 [label="Attention_8_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_8_9_1 [label="Attention_Output_8_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_8_9_2 [label="QKV_Proj_8_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_8_9_2 [label="Attention_8_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_8_9_2 [label="Attention_Output_8_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_8_9_3 [label="QKV_Proj_8_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_8_9_3 [label="Attention_8_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_8_9_3 [label="Attention_Output_8_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	attn_allreduce_8_9 [label="Attention_AllReduce_8_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_8_10_0 [label="QKV_Proj_8_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_8_10_0 [label="Attention_8_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_8_10_0 [label="Attention_Output_8_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_8_10_1 [label="QKV_Proj_8_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_8_10_1 [label="Attention_8_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_8_10_1 [label="Attention_Output_8_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_8_10_2 [label="QKV_Proj_8_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_8_10_2 [label="Attention_8_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_8_10_2 [label="Attention_Output_8_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_8_10_3 [label="QKV_Proj_8_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_8_10_3 [label="Attention_8_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_8_10_3 [label="Attention_Output_8_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	attn_allreduce_8_10 [label="Attention_AllReduce_8_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_8_11_0 [label="QKV_Proj_8_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_8_11_0 [label="Attention_8_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_8_11_0 [label="Attention_Output_8_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_8_11_1 [label="QKV_Proj_8_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_8_11_1 [label="Attention_8_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_8_11_1 [label="Attention_Output_8_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_8_11_2 [label="QKV_Proj_8_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_8_11_2 [label="Attention_8_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_8_11_2 [label="Attention_Output_8_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_8_11_3 [label="QKV_Proj_8_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_8_11_3 [label="Attention_8_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_8_11_3 [label="Attention_Output_8_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	attn_allreduce_8_11 [label="Attention_AllReduce_8_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_8_12_0 [label="QKV_Proj_8_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_8_12_0 [label="Attention_8_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_8_12_0 [label="Attention_Output_8_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_8_12_1 [label="QKV_Proj_8_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_8_12_1 [label="Attention_8_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_8_12_1 [label="Attention_Output_8_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_8_12_2 [label="QKV_Proj_8_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_8_12_2 [label="Attention_8_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_8_12_2 [label="Attention_Output_8_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_8_12_3 [label="QKV_Proj_8_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_8_12_3 [label="Attention_8_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_8_12_3 [label="Attention_Output_8_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	attn_allreduce_8_12 [label="Attention_AllReduce_8_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_8_13_0 [label="QKV_Proj_8_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_8_13_0 [label="Attention_8_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_8_13_0 [label="Attention_Output_8_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_8_13_1 [label="QKV_Proj_8_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_8_13_1 [label="Attention_8_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_8_13_1 [label="Attention_Output_8_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_8_13_2 [label="QKV_Proj_8_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_8_13_2 [label="Attention_8_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_8_13_2 [label="Attention_Output_8_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_8_13_3 [label="QKV_Proj_8_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_8_13_3 [label="Attention_8_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_8_13_3 [label="Attention_Output_8_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	attn_allreduce_8_13 [label="Attention_AllReduce_8_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_8_14_0 [label="QKV_Proj_8_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_8_14_0 [label="Attention_8_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_8_14_0 [label="Attention_Output_8_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_8_14_1 [label="QKV_Proj_8_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_8_14_1 [label="Attention_8_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_8_14_1 [label="Attention_Output_8_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_8_14_2 [label="QKV_Proj_8_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_8_14_2 [label="Attention_8_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_8_14_2 [label="Attention_Output_8_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_8_14_3 [label="QKV_Proj_8_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_8_14_3 [label="Attention_8_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_8_14_3 [label="Attention_Output_8_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	attn_allreduce_8_14 [label="Attention_AllReduce_8_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_8_15_0 [label="QKV_Proj_8_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_8_15_0 [label="Attention_8_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_8_15_0 [label="Attention_Output_8_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_8_15_1 [label="QKV_Proj_8_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_8_15_1 [label="Attention_8_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_8_15_1 [label="Attention_Output_8_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_8_15_2 [label="QKV_Proj_8_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_8_15_2 [label="Attention_8_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_8_15_2 [label="Attention_Output_8_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_8_15_3 [label="QKV_Proj_8_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_8_15_3 [label="Attention_8_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_8_15_3 [label="Attention_Output_8_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	attn_allreduce_8_15 [label="Attention_AllReduce_8_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_8_0_0 [label="MLP_Linear1_8_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_8_0_0 [label="GELU_8_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_8_0_0 [label="MLP_Linear2_8_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_8_0_1 [label="MLP_Linear1_8_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_8_0_1 [label="GELU_8_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_8_0_1 [label="MLP_Linear2_8_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_8_0_2 [label="MLP_Linear1_8_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_8_0_2 [label="GELU_8_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_8_0_2 [label="MLP_Linear2_8_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_8_0_3 [label="MLP_Linear1_8_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_8_0_3 [label="GELU_8_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_8_0_3 [label="MLP_Linear2_8_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp_allreduce_8_0 [label="MLP_AllReduce_8_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_8_1_0 [label="MLP_Linear1_8_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_8_1_0 [label="GELU_8_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_8_1_0 [label="MLP_Linear2_8_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_8_1_1 [label="MLP_Linear1_8_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_8_1_1 [label="GELU_8_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_8_1_1 [label="MLP_Linear2_8_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_8_1_2 [label="MLP_Linear1_8_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_8_1_2 [label="GELU_8_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_8_1_2 [label="MLP_Linear2_8_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_8_1_3 [label="MLP_Linear1_8_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_8_1_3 [label="GELU_8_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_8_1_3 [label="MLP_Linear2_8_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp_allreduce_8_1 [label="MLP_AllReduce_8_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_8_2_0 [label="MLP_Linear1_8_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_8_2_0 [label="GELU_8_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_8_2_0 [label="MLP_Linear2_8_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_8_2_1 [label="MLP_Linear1_8_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_8_2_1 [label="GELU_8_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_8_2_1 [label="MLP_Linear2_8_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_8_2_2 [label="MLP_Linear1_8_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_8_2_2 [label="GELU_8_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_8_2_2 [label="MLP_Linear2_8_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_8_2_3 [label="MLP_Linear1_8_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_8_2_3 [label="GELU_8_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_8_2_3 [label="MLP_Linear2_8_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp_allreduce_8_2 [label="MLP_AllReduce_8_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_8_3_0 [label="MLP_Linear1_8_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_8_3_0 [label="GELU_8_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_8_3_0 [label="MLP_Linear2_8_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_8_3_1 [label="MLP_Linear1_8_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_8_3_1 [label="GELU_8_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_8_3_1 [label="MLP_Linear2_8_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_8_3_2 [label="MLP_Linear1_8_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_8_3_2 [label="GELU_8_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_8_3_2 [label="MLP_Linear2_8_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_8_3_3 [label="MLP_Linear1_8_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_8_3_3 [label="GELU_8_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_8_3_3 [label="MLP_Linear2_8_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp_allreduce_8_3 [label="MLP_AllReduce_8_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_8_4_0 [label="MLP_Linear1_8_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_8_4_0 [label="GELU_8_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_8_4_0 [label="MLP_Linear2_8_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_8_4_1 [label="MLP_Linear1_8_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_8_4_1 [label="GELU_8_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_8_4_1 [label="MLP_Linear2_8_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_8_4_2 [label="MLP_Linear1_8_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_8_4_2 [label="GELU_8_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_8_4_2 [label="MLP_Linear2_8_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_8_4_3 [label="MLP_Linear1_8_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_8_4_3 [label="GELU_8_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_8_4_3 [label="MLP_Linear2_8_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp_allreduce_8_4 [label="MLP_AllReduce_8_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_8_5_0 [label="MLP_Linear1_8_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_8_5_0 [label="GELU_8_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_8_5_0 [label="MLP_Linear2_8_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_8_5_1 [label="MLP_Linear1_8_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_8_5_1 [label="GELU_8_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_8_5_1 [label="MLP_Linear2_8_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_8_5_2 [label="MLP_Linear1_8_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_8_5_2 [label="GELU_8_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_8_5_2 [label="MLP_Linear2_8_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_8_5_3 [label="MLP_Linear1_8_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_8_5_3 [label="GELU_8_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_8_5_3 [label="MLP_Linear2_8_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp_allreduce_8_5 [label="MLP_AllReduce_8_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_8_6_0 [label="MLP_Linear1_8_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_8_6_0 [label="GELU_8_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_8_6_0 [label="MLP_Linear2_8_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_8_6_1 [label="MLP_Linear1_8_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_8_6_1 [label="GELU_8_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_8_6_1 [label="MLP_Linear2_8_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_8_6_2 [label="MLP_Linear1_8_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_8_6_2 [label="GELU_8_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_8_6_2 [label="MLP_Linear2_8_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_8_6_3 [label="MLP_Linear1_8_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_8_6_3 [label="GELU_8_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_8_6_3 [label="MLP_Linear2_8_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp_allreduce_8_6 [label="MLP_AllReduce_8_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_8_7_0 [label="MLP_Linear1_8_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_8_7_0 [label="GELU_8_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_8_7_0 [label="MLP_Linear2_8_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_8_7_1 [label="MLP_Linear1_8_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_8_7_1 [label="GELU_8_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_8_7_1 [label="MLP_Linear2_8_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_8_7_2 [label="MLP_Linear1_8_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_8_7_2 [label="GELU_8_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_8_7_2 [label="MLP_Linear2_8_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_8_7_3 [label="MLP_Linear1_8_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_8_7_3 [label="GELU_8_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_8_7_3 [label="MLP_Linear2_8_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp_allreduce_8_7 [label="MLP_AllReduce_8_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_8_8_0 [label="MLP_Linear1_8_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_8_8_0 [label="GELU_8_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_8_8_0 [label="MLP_Linear2_8_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_8_8_1 [label="MLP_Linear1_8_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_8_8_1 [label="GELU_8_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_8_8_1 [label="MLP_Linear2_8_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_8_8_2 [label="MLP_Linear1_8_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_8_8_2 [label="GELU_8_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_8_8_2 [label="MLP_Linear2_8_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_8_8_3 [label="MLP_Linear1_8_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_8_8_3 [label="GELU_8_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_8_8_3 [label="MLP_Linear2_8_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp_allreduce_8_8 [label="MLP_AllReduce_8_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_8_9_0 [label="MLP_Linear1_8_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_8_9_0 [label="GELU_8_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_8_9_0 [label="MLP_Linear2_8_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_8_9_1 [label="MLP_Linear1_8_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_8_9_1 [label="GELU_8_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_8_9_1 [label="MLP_Linear2_8_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_8_9_2 [label="MLP_Linear1_8_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_8_9_2 [label="GELU_8_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_8_9_2 [label="MLP_Linear2_8_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_8_9_3 [label="MLP_Linear1_8_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_8_9_3 [label="GELU_8_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_8_9_3 [label="MLP_Linear2_8_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp_allreduce_8_9 [label="MLP_AllReduce_8_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_8_10_0 [label="MLP_Linear1_8_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_8_10_0 [label="GELU_8_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_8_10_0 [label="MLP_Linear2_8_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_8_10_1 [label="MLP_Linear1_8_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_8_10_1 [label="GELU_8_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_8_10_1 [label="MLP_Linear2_8_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_8_10_2 [label="MLP_Linear1_8_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_8_10_2 [label="GELU_8_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_8_10_2 [label="MLP_Linear2_8_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_8_10_3 [label="MLP_Linear1_8_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_8_10_3 [label="GELU_8_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_8_10_3 [label="MLP_Linear2_8_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp_allreduce_8_10 [label="MLP_AllReduce_8_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_8_11_0 [label="MLP_Linear1_8_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_8_11_0 [label="GELU_8_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_8_11_0 [label="MLP_Linear2_8_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_8_11_1 [label="MLP_Linear1_8_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_8_11_1 [label="GELU_8_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_8_11_1 [label="MLP_Linear2_8_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_8_11_2 [label="MLP_Linear1_8_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_8_11_2 [label="GELU_8_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_8_11_2 [label="MLP_Linear2_8_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_8_11_3 [label="MLP_Linear1_8_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_8_11_3 [label="GELU_8_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_8_11_3 [label="MLP_Linear2_8_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp_allreduce_8_11 [label="MLP_AllReduce_8_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_8_12_0 [label="MLP_Linear1_8_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_8_12_0 [label="GELU_8_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_8_12_0 [label="MLP_Linear2_8_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_8_12_1 [label="MLP_Linear1_8_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_8_12_1 [label="GELU_8_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_8_12_1 [label="MLP_Linear2_8_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_8_12_2 [label="MLP_Linear1_8_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_8_12_2 [label="GELU_8_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_8_12_2 [label="MLP_Linear2_8_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_8_12_3 [label="MLP_Linear1_8_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_8_12_3 [label="GELU_8_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_8_12_3 [label="MLP_Linear2_8_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp_allreduce_8_12 [label="MLP_AllReduce_8_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_8_13_0 [label="MLP_Linear1_8_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_8_13_0 [label="GELU_8_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_8_13_0 [label="MLP_Linear2_8_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_8_13_1 [label="MLP_Linear1_8_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_8_13_1 [label="GELU_8_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_8_13_1 [label="MLP_Linear2_8_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_8_13_2 [label="MLP_Linear1_8_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_8_13_2 [label="GELU_8_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_8_13_2 [label="MLP_Linear2_8_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_8_13_3 [label="MLP_Linear1_8_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_8_13_3 [label="GELU_8_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_8_13_3 [label="MLP_Linear2_8_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp_allreduce_8_13 [label="MLP_AllReduce_8_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_8_14_0 [label="MLP_Linear1_8_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_8_14_0 [label="GELU_8_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_8_14_0 [label="MLP_Linear2_8_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_8_14_1 [label="MLP_Linear1_8_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_8_14_1 [label="GELU_8_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_8_14_1 [label="MLP_Linear2_8_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_8_14_2 [label="MLP_Linear1_8_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_8_14_2 [label="GELU_8_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_8_14_2 [label="MLP_Linear2_8_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_8_14_3 [label="MLP_Linear1_8_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_8_14_3 [label="GELU_8_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_8_14_3 [label="MLP_Linear2_8_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp_allreduce_8_14 [label="MLP_AllReduce_8_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_8_15_0 [label="MLP_Linear1_8_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_8_15_0 [label="GELU_8_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_8_15_0 [label="MLP_Linear2_8_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_8_15_1 [label="MLP_Linear1_8_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_8_15_1 [label="GELU_8_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_8_15_1 [label="MLP_Linear2_8_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_8_15_2 [label="MLP_Linear1_8_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_8_15_2 [label="GELU_8_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_8_15_2 [label="MLP_Linear2_8_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_8_15_3 [label="MLP_Linear1_8_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_8_15_3 [label="GELU_8_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_8_15_3 [label="MLP_Linear2_8_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp_allreduce_8_15 [label="MLP_AllReduce_8_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	expert_route_8_0 [label="Expert_Route_8_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_8_1 [label="Expert_Route_8_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_8_2 [label="Expert_Route_8_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_8_3 [label="Expert_Route_8_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_8_4 [label="Expert_Route_8_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_8_5 [label="Expert_Route_8_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_8_6 [label="Expert_Route_8_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_8_7 [label="Expert_Route_8_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_8_8 [label="Expert_Route_8_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_8_9 [label="Expert_Route_8_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_8_10 [label="Expert_Route_8_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_8_11 [label="Expert_Route_8_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_8_12 [label="Expert_Route_8_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_8_13 [label="Expert_Route_8_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_8_14 [label="Expert_Route_8_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_8_15 [label="Expert_Route_8_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	qkv_9_0_0 [label="QKV_Proj_9_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_9_0_0 [label="Attention_9_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_9_0_0 [label="Attention_Output_9_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_9_0_1 [label="QKV_Proj_9_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_9_0_1 [label="Attention_9_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_9_0_1 [label="Attention_Output_9_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_9_0_2 [label="QKV_Proj_9_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_9_0_2 [label="Attention_9_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_9_0_2 [label="Attention_Output_9_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_9_0_3 [label="QKV_Proj_9_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_9_0_3 [label="Attention_9_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_9_0_3 [label="Attention_Output_9_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	attn_allreduce_9_0 [label="Attention_AllReduce_9_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_9_1_0 [label="QKV_Proj_9_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_9_1_0 [label="Attention_9_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_9_1_0 [label="Attention_Output_9_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_9_1_1 [label="QKV_Proj_9_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_9_1_1 [label="Attention_9_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_9_1_1 [label="Attention_Output_9_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_9_1_2 [label="QKV_Proj_9_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_9_1_2 [label="Attention_9_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_9_1_2 [label="Attention_Output_9_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_9_1_3 [label="QKV_Proj_9_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_9_1_3 [label="Attention_9_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_9_1_3 [label="Attention_Output_9_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	attn_allreduce_9_1 [label="Attention_AllReduce_9_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_9_2_0 [label="QKV_Proj_9_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_9_2_0 [label="Attention_9_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_9_2_0 [label="Attention_Output_9_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_9_2_1 [label="QKV_Proj_9_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_9_2_1 [label="Attention_9_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_9_2_1 [label="Attention_Output_9_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_9_2_2 [label="QKV_Proj_9_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_9_2_2 [label="Attention_9_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_9_2_2 [label="Attention_Output_9_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_9_2_3 [label="QKV_Proj_9_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_9_2_3 [label="Attention_9_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_9_2_3 [label="Attention_Output_9_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	attn_allreduce_9_2 [label="Attention_AllReduce_9_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_9_3_0 [label="QKV_Proj_9_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_9_3_0 [label="Attention_9_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_9_3_0 [label="Attention_Output_9_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_9_3_1 [label="QKV_Proj_9_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_9_3_1 [label="Attention_9_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_9_3_1 [label="Attention_Output_9_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_9_3_2 [label="QKV_Proj_9_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_9_3_2 [label="Attention_9_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_9_3_2 [label="Attention_Output_9_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_9_3_3 [label="QKV_Proj_9_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_9_3_3 [label="Attention_9_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_9_3_3 [label="Attention_Output_9_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	attn_allreduce_9_3 [label="Attention_AllReduce_9_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_9_4_0 [label="QKV_Proj_9_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_9_4_0 [label="Attention_9_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_9_4_0 [label="Attention_Output_9_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_9_4_1 [label="QKV_Proj_9_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_9_4_1 [label="Attention_9_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_9_4_1 [label="Attention_Output_9_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_9_4_2 [label="QKV_Proj_9_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_9_4_2 [label="Attention_9_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_9_4_2 [label="Attention_Output_9_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_9_4_3 [label="QKV_Proj_9_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_9_4_3 [label="Attention_9_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_9_4_3 [label="Attention_Output_9_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	attn_allreduce_9_4 [label="Attention_AllReduce_9_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_9_5_0 [label="QKV_Proj_9_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_9_5_0 [label="Attention_9_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_9_5_0 [label="Attention_Output_9_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_9_5_1 [label="QKV_Proj_9_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_9_5_1 [label="Attention_9_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_9_5_1 [label="Attention_Output_9_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_9_5_2 [label="QKV_Proj_9_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_9_5_2 [label="Attention_9_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_9_5_2 [label="Attention_Output_9_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_9_5_3 [label="QKV_Proj_9_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_9_5_3 [label="Attention_9_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_9_5_3 [label="Attention_Output_9_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	attn_allreduce_9_5 [label="Attention_AllReduce_9_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_9_6_0 [label="QKV_Proj_9_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_9_6_0 [label="Attention_9_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_9_6_0 [label="Attention_Output_9_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_9_6_1 [label="QKV_Proj_9_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_9_6_1 [label="Attention_9_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_9_6_1 [label="Attention_Output_9_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_9_6_2 [label="QKV_Proj_9_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_9_6_2 [label="Attention_9_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_9_6_2 [label="Attention_Output_9_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_9_6_3 [label="QKV_Proj_9_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_9_6_3 [label="Attention_9_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_9_6_3 [label="Attention_Output_9_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	attn_allreduce_9_6 [label="Attention_AllReduce_9_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_9_7_0 [label="QKV_Proj_9_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_9_7_0 [label="Attention_9_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_9_7_0 [label="Attention_Output_9_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_9_7_1 [label="QKV_Proj_9_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_9_7_1 [label="Attention_9_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_9_7_1 [label="Attention_Output_9_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_9_7_2 [label="QKV_Proj_9_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_9_7_2 [label="Attention_9_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_9_7_2 [label="Attention_Output_9_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_9_7_3 [label="QKV_Proj_9_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_9_7_3 [label="Attention_9_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_9_7_3 [label="Attention_Output_9_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	attn_allreduce_9_7 [label="Attention_AllReduce_9_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_9_8_0 [label="QKV_Proj_9_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_9_8_0 [label="Attention_9_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_9_8_0 [label="Attention_Output_9_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_9_8_1 [label="QKV_Proj_9_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_9_8_1 [label="Attention_9_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_9_8_1 [label="Attention_Output_9_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_9_8_2 [label="QKV_Proj_9_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_9_8_2 [label="Attention_9_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_9_8_2 [label="Attention_Output_9_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_9_8_3 [label="QKV_Proj_9_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_9_8_3 [label="Attention_9_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_9_8_3 [label="Attention_Output_9_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	attn_allreduce_9_8 [label="Attention_AllReduce_9_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_9_9_0 [label="QKV_Proj_9_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_9_9_0 [label="Attention_9_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_9_9_0 [label="Attention_Output_9_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_9_9_1 [label="QKV_Proj_9_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_9_9_1 [label="Attention_9_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_9_9_1 [label="Attention_Output_9_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_9_9_2 [label="QKV_Proj_9_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_9_9_2 [label="Attention_9_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_9_9_2 [label="Attention_Output_9_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_9_9_3 [label="QKV_Proj_9_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_9_9_3 [label="Attention_9_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_9_9_3 [label="Attention_Output_9_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	attn_allreduce_9_9 [label="Attention_AllReduce_9_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_9_10_0 [label="QKV_Proj_9_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_9_10_0 [label="Attention_9_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_9_10_0 [label="Attention_Output_9_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_9_10_1 [label="QKV_Proj_9_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_9_10_1 [label="Attention_9_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_9_10_1 [label="Attention_Output_9_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_9_10_2 [label="QKV_Proj_9_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_9_10_2 [label="Attention_9_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_9_10_2 [label="Attention_Output_9_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_9_10_3 [label="QKV_Proj_9_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_9_10_3 [label="Attention_9_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_9_10_3 [label="Attention_Output_9_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	attn_allreduce_9_10 [label="Attention_AllReduce_9_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_9_11_0 [label="QKV_Proj_9_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_9_11_0 [label="Attention_9_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_9_11_0 [label="Attention_Output_9_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_9_11_1 [label="QKV_Proj_9_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_9_11_1 [label="Attention_9_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_9_11_1 [label="Attention_Output_9_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_9_11_2 [label="QKV_Proj_9_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_9_11_2 [label="Attention_9_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_9_11_2 [label="Attention_Output_9_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_9_11_3 [label="QKV_Proj_9_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_9_11_3 [label="Attention_9_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_9_11_3 [label="Attention_Output_9_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	attn_allreduce_9_11 [label="Attention_AllReduce_9_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_9_12_0 [label="QKV_Proj_9_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_9_12_0 [label="Attention_9_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_9_12_0 [label="Attention_Output_9_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_9_12_1 [label="QKV_Proj_9_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_9_12_1 [label="Attention_9_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_9_12_1 [label="Attention_Output_9_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_9_12_2 [label="QKV_Proj_9_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_9_12_2 [label="Attention_9_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_9_12_2 [label="Attention_Output_9_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_9_12_3 [label="QKV_Proj_9_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_9_12_3 [label="Attention_9_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_9_12_3 [label="Attention_Output_9_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	attn_allreduce_9_12 [label="Attention_AllReduce_9_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_9_13_0 [label="QKV_Proj_9_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_9_13_0 [label="Attention_9_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_9_13_0 [label="Attention_Output_9_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_9_13_1 [label="QKV_Proj_9_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_9_13_1 [label="Attention_9_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_9_13_1 [label="Attention_Output_9_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_9_13_2 [label="QKV_Proj_9_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_9_13_2 [label="Attention_9_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_9_13_2 [label="Attention_Output_9_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_9_13_3 [label="QKV_Proj_9_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_9_13_3 [label="Attention_9_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_9_13_3 [label="Attention_Output_9_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	attn_allreduce_9_13 [label="Attention_AllReduce_9_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_9_14_0 [label="QKV_Proj_9_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_9_14_0 [label="Attention_9_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_9_14_0 [label="Attention_Output_9_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_9_14_1 [label="QKV_Proj_9_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_9_14_1 [label="Attention_9_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_9_14_1 [label="Attention_Output_9_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_9_14_2 [label="QKV_Proj_9_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_9_14_2 [label="Attention_9_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_9_14_2 [label="Attention_Output_9_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_9_14_3 [label="QKV_Proj_9_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_9_14_3 [label="Attention_9_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_9_14_3 [label="Attention_Output_9_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	attn_allreduce_9_14 [label="Attention_AllReduce_9_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_9_15_0 [label="QKV_Proj_9_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_9_15_0 [label="Attention_9_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_9_15_0 [label="Attention_Output_9_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_9_15_1 [label="QKV_Proj_9_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_9_15_1 [label="Attention_9_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_9_15_1 [label="Attention_Output_9_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_9_15_2 [label="QKV_Proj_9_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_9_15_2 [label="Attention_9_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_9_15_2 [label="Attention_Output_9_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_9_15_3 [label="QKV_Proj_9_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_9_15_3 [label="Attention_9_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_9_15_3 [label="Attention_Output_9_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	attn_allreduce_9_15 [label="Attention_AllReduce_9_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_9_0_0 [label="MLP_Linear1_9_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_9_0_0 [label="GELU_9_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_9_0_0 [label="MLP_Linear2_9_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_9_0_1 [label="MLP_Linear1_9_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_9_0_1 [label="GELU_9_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_9_0_1 [label="MLP_Linear2_9_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_9_0_2 [label="MLP_Linear1_9_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_9_0_2 [label="GELU_9_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_9_0_2 [label="MLP_Linear2_9_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_9_0_3 [label="MLP_Linear1_9_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_9_0_3 [label="GELU_9_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_9_0_3 [label="MLP_Linear2_9_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp_allreduce_9_0 [label="MLP_AllReduce_9_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_9_1_0 [label="MLP_Linear1_9_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_9_1_0 [label="GELU_9_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_9_1_0 [label="MLP_Linear2_9_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_9_1_1 [label="MLP_Linear1_9_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_9_1_1 [label="GELU_9_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_9_1_1 [label="MLP_Linear2_9_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_9_1_2 [label="MLP_Linear1_9_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_9_1_2 [label="GELU_9_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_9_1_2 [label="MLP_Linear2_9_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_9_1_3 [label="MLP_Linear1_9_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_9_1_3 [label="GELU_9_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_9_1_3 [label="MLP_Linear2_9_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp_allreduce_9_1 [label="MLP_AllReduce_9_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_9_2_0 [label="MLP_Linear1_9_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_9_2_0 [label="GELU_9_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_9_2_0 [label="MLP_Linear2_9_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_9_2_1 [label="MLP_Linear1_9_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_9_2_1 [label="GELU_9_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_9_2_1 [label="MLP_Linear2_9_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_9_2_2 [label="MLP_Linear1_9_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_9_2_2 [label="GELU_9_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_9_2_2 [label="MLP_Linear2_9_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_9_2_3 [label="MLP_Linear1_9_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_9_2_3 [label="GELU_9_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_9_2_3 [label="MLP_Linear2_9_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp_allreduce_9_2 [label="MLP_AllReduce_9_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_9_3_0 [label="MLP_Linear1_9_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_9_3_0 [label="GELU_9_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_9_3_0 [label="MLP_Linear2_9_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_9_3_1 [label="MLP_Linear1_9_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_9_3_1 [label="GELU_9_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_9_3_1 [label="MLP_Linear2_9_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_9_3_2 [label="MLP_Linear1_9_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_9_3_2 [label="GELU_9_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_9_3_2 [label="MLP_Linear2_9_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_9_3_3 [label="MLP_Linear1_9_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_9_3_3 [label="GELU_9_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_9_3_3 [label="MLP_Linear2_9_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp_allreduce_9_3 [label="MLP_AllReduce_9_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_9_4_0 [label="MLP_Linear1_9_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_9_4_0 [label="GELU_9_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_9_4_0 [label="MLP_Linear2_9_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_9_4_1 [label="MLP_Linear1_9_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_9_4_1 [label="GELU_9_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_9_4_1 [label="MLP_Linear2_9_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_9_4_2 [label="MLP_Linear1_9_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_9_4_2 [label="GELU_9_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_9_4_2 [label="MLP_Linear2_9_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_9_4_3 [label="MLP_Linear1_9_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_9_4_3 [label="GELU_9_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_9_4_3 [label="MLP_Linear2_9_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp_allreduce_9_4 [label="MLP_AllReduce_9_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_9_5_0 [label="MLP_Linear1_9_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_9_5_0 [label="GELU_9_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_9_5_0 [label="MLP_Linear2_9_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_9_5_1 [label="MLP_Linear1_9_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_9_5_1 [label="GELU_9_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_9_5_1 [label="MLP_Linear2_9_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_9_5_2 [label="MLP_Linear1_9_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_9_5_2 [label="GELU_9_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_9_5_2 [label="MLP_Linear2_9_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_9_5_3 [label="MLP_Linear1_9_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_9_5_3 [label="GELU_9_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_9_5_3 [label="MLP_Linear2_9_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp_allreduce_9_5 [label="MLP_AllReduce_9_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_9_6_0 [label="MLP_Linear1_9_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_9_6_0 [label="GELU_9_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_9_6_0 [label="MLP_Linear2_9_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_9_6_1 [label="MLP_Linear1_9_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_9_6_1 [label="GELU_9_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_9_6_1 [label="MLP_Linear2_9_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_9_6_2 [label="MLP_Linear1_9_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_9_6_2 [label="GELU_9_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_9_6_2 [label="MLP_Linear2_9_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_9_6_3 [label="MLP_Linear1_9_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_9_6_3 [label="GELU_9_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_9_6_3 [label="MLP_Linear2_9_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp_allreduce_9_6 [label="MLP_AllReduce_9_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_9_7_0 [label="MLP_Linear1_9_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_9_7_0 [label="GELU_9_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_9_7_0 [label="MLP_Linear2_9_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_9_7_1 [label="MLP_Linear1_9_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_9_7_1 [label="GELU_9_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_9_7_1 [label="MLP_Linear2_9_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_9_7_2 [label="MLP_Linear1_9_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_9_7_2 [label="GELU_9_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_9_7_2 [label="MLP_Linear2_9_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_9_7_3 [label="MLP_Linear1_9_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_9_7_3 [label="GELU_9_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_9_7_3 [label="MLP_Linear2_9_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp_allreduce_9_7 [label="MLP_AllReduce_9_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_9_8_0 [label="MLP_Linear1_9_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_9_8_0 [label="GELU_9_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_9_8_0 [label="MLP_Linear2_9_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_9_8_1 [label="MLP_Linear1_9_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_9_8_1 [label="GELU_9_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_9_8_1 [label="MLP_Linear2_9_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_9_8_2 [label="MLP_Linear1_9_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_9_8_2 [label="GELU_9_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_9_8_2 [label="MLP_Linear2_9_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_9_8_3 [label="MLP_Linear1_9_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_9_8_3 [label="GELU_9_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_9_8_3 [label="MLP_Linear2_9_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp_allreduce_9_8 [label="MLP_AllReduce_9_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_9_9_0 [label="MLP_Linear1_9_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_9_9_0 [label="GELU_9_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_9_9_0 [label="MLP_Linear2_9_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_9_9_1 [label="MLP_Linear1_9_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_9_9_1 [label="GELU_9_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_9_9_1 [label="MLP_Linear2_9_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_9_9_2 [label="MLP_Linear1_9_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_9_9_2 [label="GELU_9_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_9_9_2 [label="MLP_Linear2_9_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_9_9_3 [label="MLP_Linear1_9_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_9_9_3 [label="GELU_9_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_9_9_3 [label="MLP_Linear2_9_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp_allreduce_9_9 [label="MLP_AllReduce_9_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_9_10_0 [label="MLP_Linear1_9_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_9_10_0 [label="GELU_9_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_9_10_0 [label="MLP_Linear2_9_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_9_10_1 [label="MLP_Linear1_9_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_9_10_1 [label="GELU_9_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_9_10_1 [label="MLP_Linear2_9_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_9_10_2 [label="MLP_Linear1_9_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_9_10_2 [label="GELU_9_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_9_10_2 [label="MLP_Linear2_9_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_9_10_3 [label="MLP_Linear1_9_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_9_10_3 [label="GELU_9_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_9_10_3 [label="MLP_Linear2_9_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp_allreduce_9_10 [label="MLP_AllReduce_9_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_9_11_0 [label="MLP_Linear1_9_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_9_11_0 [label="GELU_9_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_9_11_0 [label="MLP_Linear2_9_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_9_11_1 [label="MLP_Linear1_9_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_9_11_1 [label="GELU_9_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_9_11_1 [label="MLP_Linear2_9_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_9_11_2 [label="MLP_Linear1_9_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_9_11_2 [label="GELU_9_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_9_11_2 [label="MLP_Linear2_9_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_9_11_3 [label="MLP_Linear1_9_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_9_11_3 [label="GELU_9_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_9_11_3 [label="MLP_Linear2_9_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp_allreduce_9_11 [label="MLP_AllReduce_9_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_9_12_0 [label="MLP_Linear1_9_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_9_12_0 [label="GELU_9_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_9_12_0 [label="MLP_Linear2_9_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_9_12_1 [label="MLP_Linear1_9_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_9_12_1 [label="GELU_9_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_9_12_1 [label="MLP_Linear2_9_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_9_12_2 [label="MLP_Linear1_9_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_9_12_2 [label="GELU_9_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_9_12_2 [label="MLP_Linear2_9_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_9_12_3 [label="MLP_Linear1_9_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_9_12_3 [label="GELU_9_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_9_12_3 [label="MLP_Linear2_9_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp_allreduce_9_12 [label="MLP_AllReduce_9_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_9_13_0 [label="MLP_Linear1_9_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_9_13_0 [label="GELU_9_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_9_13_0 [label="MLP_Linear2_9_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_9_13_1 [label="MLP_Linear1_9_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_9_13_1 [label="GELU_9_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_9_13_1 [label="MLP_Linear2_9_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_9_13_2 [label="MLP_Linear1_9_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_9_13_2 [label="GELU_9_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_9_13_2 [label="MLP_Linear2_9_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_9_13_3 [label="MLP_Linear1_9_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_9_13_3 [label="GELU_9_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_9_13_3 [label="MLP_Linear2_9_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp_allreduce_9_13 [label="MLP_AllReduce_9_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_9_14_0 [label="MLP_Linear1_9_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_9_14_0 [label="GELU_9_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_9_14_0 [label="MLP_Linear2_9_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_9_14_1 [label="MLP_Linear1_9_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_9_14_1 [label="GELU_9_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_9_14_1 [label="MLP_Linear2_9_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_9_14_2 [label="MLP_Linear1_9_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_9_14_2 [label="GELU_9_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_9_14_2 [label="MLP_Linear2_9_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_9_14_3 [label="MLP_Linear1_9_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_9_14_3 [label="GELU_9_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_9_14_3 [label="MLP_Linear2_9_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp_allreduce_9_14 [label="MLP_AllReduce_9_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_9_15_0 [label="MLP_Linear1_9_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_9_15_0 [label="GELU_9_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_9_15_0 [label="MLP_Linear2_9_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_9_15_1 [label="MLP_Linear1_9_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_9_15_1 [label="GELU_9_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_9_15_1 [label="MLP_Linear2_9_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_9_15_2 [label="MLP_Linear1_9_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_9_15_2 [label="GELU_9_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_9_15_2 [label="MLP_Linear2_9_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_9_15_3 [label="MLP_Linear1_9_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_9_15_3 [label="GELU_9_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_9_15_3 [label="MLP_Linear2_9_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp_allreduce_9_15 [label="MLP_AllReduce_9_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	expert_route_9_0 [label="Expert_Route_9_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_9_1 [label="Expert_Route_9_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_9_2 [label="Expert_Route_9_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_9_3 [label="Expert_Route_9_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_9_4 [label="Expert_Route_9_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_9_5 [label="Expert_Route_9_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_9_6 [label="Expert_Route_9_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_9_7 [label="Expert_Route_9_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_9_8 [label="Expert_Route_9_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_9_9 [label="Expert_Route_9_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_9_10 [label="Expert_Route_9_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_9_11 [label="Expert_Route_9_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_9_12 [label="Expert_Route_9_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_9_13 [label="Expert_Route_9_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_9_14 [label="Expert_Route_9_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_9_15 [label="Expert_Route_9_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	qkv_10_0_0 [label="QKV_Proj_10_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_10_0_0 [label="Attention_10_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_10_0_0 [label="Attention_Output_10_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_10_0_1 [label="QKV_Proj_10_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_10_0_1 [label="Attention_10_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_10_0_1 [label="Attention_Output_10_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_10_0_2 [label="QKV_Proj_10_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_10_0_2 [label="Attention_10_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_10_0_2 [label="Attention_Output_10_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_10_0_3 [label="QKV_Proj_10_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_10_0_3 [label="Attention_10_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_10_0_3 [label="Attention_Output_10_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	attn_allreduce_10_0 [label="Attention_AllReduce_10_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_10_1_0 [label="QKV_Proj_10_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_10_1_0 [label="Attention_10_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_10_1_0 [label="Attention_Output_10_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_10_1_1 [label="QKV_Proj_10_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_10_1_1 [label="Attention_10_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_10_1_1 [label="Attention_Output_10_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_10_1_2 [label="QKV_Proj_10_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_10_1_2 [label="Attention_10_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_10_1_2 [label="Attention_Output_10_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_10_1_3 [label="QKV_Proj_10_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_10_1_3 [label="Attention_10_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_10_1_3 [label="Attention_Output_10_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	attn_allreduce_10_1 [label="Attention_AllReduce_10_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_10_2_0 [label="QKV_Proj_10_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_10_2_0 [label="Attention_10_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_10_2_0 [label="Attention_Output_10_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_10_2_1 [label="QKV_Proj_10_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_10_2_1 [label="Attention_10_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_10_2_1 [label="Attention_Output_10_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_10_2_2 [label="QKV_Proj_10_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_10_2_2 [label="Attention_10_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_10_2_2 [label="Attention_Output_10_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_10_2_3 [label="QKV_Proj_10_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_10_2_3 [label="Attention_10_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_10_2_3 [label="Attention_Output_10_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	attn_allreduce_10_2 [label="Attention_AllReduce_10_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_10_3_0 [label="QKV_Proj_10_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_10_3_0 [label="Attention_10_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_10_3_0 [label="Attention_Output_10_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_10_3_1 [label="QKV_Proj_10_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_10_3_1 [label="Attention_10_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_10_3_1 [label="Attention_Output_10_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_10_3_2 [label="QKV_Proj_10_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_10_3_2 [label="Attention_10_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_10_3_2 [label="Attention_Output_10_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_10_3_3 [label="QKV_Proj_10_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_10_3_3 [label="Attention_10_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_10_3_3 [label="Attention_Output_10_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	attn_allreduce_10_3 [label="Attention_AllReduce_10_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_10_4_0 [label="QKV_Proj_10_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_10_4_0 [label="Attention_10_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_10_4_0 [label="Attention_Output_10_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_10_4_1 [label="QKV_Proj_10_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_10_4_1 [label="Attention_10_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_10_4_1 [label="Attention_Output_10_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_10_4_2 [label="QKV_Proj_10_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_10_4_2 [label="Attention_10_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_10_4_2 [label="Attention_Output_10_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_10_4_3 [label="QKV_Proj_10_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_10_4_3 [label="Attention_10_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_10_4_3 [label="Attention_Output_10_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	attn_allreduce_10_4 [label="Attention_AllReduce_10_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_10_5_0 [label="QKV_Proj_10_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_10_5_0 [label="Attention_10_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_10_5_0 [label="Attention_Output_10_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_10_5_1 [label="QKV_Proj_10_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_10_5_1 [label="Attention_10_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_10_5_1 [label="Attention_Output_10_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_10_5_2 [label="QKV_Proj_10_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_10_5_2 [label="Attention_10_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_10_5_2 [label="Attention_Output_10_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_10_5_3 [label="QKV_Proj_10_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_10_5_3 [label="Attention_10_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_10_5_3 [label="Attention_Output_10_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	attn_allreduce_10_5 [label="Attention_AllReduce_10_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_10_6_0 [label="QKV_Proj_10_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_10_6_0 [label="Attention_10_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_10_6_0 [label="Attention_Output_10_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_10_6_1 [label="QKV_Proj_10_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_10_6_1 [label="Attention_10_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_10_6_1 [label="Attention_Output_10_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_10_6_2 [label="QKV_Proj_10_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_10_6_2 [label="Attention_10_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_10_6_2 [label="Attention_Output_10_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_10_6_3 [label="QKV_Proj_10_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_10_6_3 [label="Attention_10_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_10_6_3 [label="Attention_Output_10_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	attn_allreduce_10_6 [label="Attention_AllReduce_10_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_10_7_0 [label="QKV_Proj_10_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_10_7_0 [label="Attention_10_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_10_7_0 [label="Attention_Output_10_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_10_7_1 [label="QKV_Proj_10_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_10_7_1 [label="Attention_10_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_10_7_1 [label="Attention_Output_10_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_10_7_2 [label="QKV_Proj_10_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_10_7_2 [label="Attention_10_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_10_7_2 [label="Attention_Output_10_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_10_7_3 [label="QKV_Proj_10_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_10_7_3 [label="Attention_10_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_10_7_3 [label="Attention_Output_10_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	attn_allreduce_10_7 [label="Attention_AllReduce_10_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_10_8_0 [label="QKV_Proj_10_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_10_8_0 [label="Attention_10_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_10_8_0 [label="Attention_Output_10_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_10_8_1 [label="QKV_Proj_10_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_10_8_1 [label="Attention_10_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_10_8_1 [label="Attention_Output_10_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_10_8_2 [label="QKV_Proj_10_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_10_8_2 [label="Attention_10_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_10_8_2 [label="Attention_Output_10_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_10_8_3 [label="QKV_Proj_10_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_10_8_3 [label="Attention_10_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_10_8_3 [label="Attention_Output_10_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	attn_allreduce_10_8 [label="Attention_AllReduce_10_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_10_9_0 [label="QKV_Proj_10_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_10_9_0 [label="Attention_10_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_10_9_0 [label="Attention_Output_10_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_10_9_1 [label="QKV_Proj_10_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_10_9_1 [label="Attention_10_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_10_9_1 [label="Attention_Output_10_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_10_9_2 [label="QKV_Proj_10_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_10_9_2 [label="Attention_10_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_10_9_2 [label="Attention_Output_10_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_10_9_3 [label="QKV_Proj_10_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_10_9_3 [label="Attention_10_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_10_9_3 [label="Attention_Output_10_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	attn_allreduce_10_9 [label="Attention_AllReduce_10_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_10_10_0 [label="QKV_Proj_10_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_10_10_0 [label="Attention_10_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_10_10_0 [label="Attention_Output_10_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_10_10_1 [label="QKV_Proj_10_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_10_10_1 [label="Attention_10_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_10_10_1 [label="Attention_Output_10_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_10_10_2 [label="QKV_Proj_10_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_10_10_2 [label="Attention_10_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_10_10_2 [label="Attention_Output_10_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_10_10_3 [label="QKV_Proj_10_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_10_10_3 [label="Attention_10_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_10_10_3 [label="Attention_Output_10_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	attn_allreduce_10_10 [label="Attention_AllReduce_10_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_10_11_0 [label="QKV_Proj_10_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_10_11_0 [label="Attention_10_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_10_11_0 [label="Attention_Output_10_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_10_11_1 [label="QKV_Proj_10_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_10_11_1 [label="Attention_10_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_10_11_1 [label="Attention_Output_10_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_10_11_2 [label="QKV_Proj_10_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_10_11_2 [label="Attention_10_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_10_11_2 [label="Attention_Output_10_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_10_11_3 [label="QKV_Proj_10_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_10_11_3 [label="Attention_10_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_10_11_3 [label="Attention_Output_10_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	attn_allreduce_10_11 [label="Attention_AllReduce_10_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_10_12_0 [label="QKV_Proj_10_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_10_12_0 [label="Attention_10_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_10_12_0 [label="Attention_Output_10_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_10_12_1 [label="QKV_Proj_10_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_10_12_1 [label="Attention_10_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_10_12_1 [label="Attention_Output_10_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_10_12_2 [label="QKV_Proj_10_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_10_12_2 [label="Attention_10_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_10_12_2 [label="Attention_Output_10_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_10_12_3 [label="QKV_Proj_10_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_10_12_3 [label="Attention_10_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_10_12_3 [label="Attention_Output_10_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	attn_allreduce_10_12 [label="Attention_AllReduce_10_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_10_13_0 [label="QKV_Proj_10_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_10_13_0 [label="Attention_10_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_10_13_0 [label="Attention_Output_10_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_10_13_1 [label="QKV_Proj_10_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_10_13_1 [label="Attention_10_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_10_13_1 [label="Attention_Output_10_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_10_13_2 [label="QKV_Proj_10_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_10_13_2 [label="Attention_10_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_10_13_2 [label="Attention_Output_10_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_10_13_3 [label="QKV_Proj_10_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_10_13_3 [label="Attention_10_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_10_13_3 [label="Attention_Output_10_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	attn_allreduce_10_13 [label="Attention_AllReduce_10_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_10_14_0 [label="QKV_Proj_10_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_10_14_0 [label="Attention_10_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_10_14_0 [label="Attention_Output_10_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_10_14_1 [label="QKV_Proj_10_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_10_14_1 [label="Attention_10_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_10_14_1 [label="Attention_Output_10_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_10_14_2 [label="QKV_Proj_10_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_10_14_2 [label="Attention_10_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_10_14_2 [label="Attention_Output_10_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_10_14_3 [label="QKV_Proj_10_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_10_14_3 [label="Attention_10_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_10_14_3 [label="Attention_Output_10_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	attn_allreduce_10_14 [label="Attention_AllReduce_10_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_10_15_0 [label="QKV_Proj_10_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_10_15_0 [label="Attention_10_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_10_15_0 [label="Attention_Output_10_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_10_15_1 [label="QKV_Proj_10_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_10_15_1 [label="Attention_10_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_10_15_1 [label="Attention_Output_10_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_10_15_2 [label="QKV_Proj_10_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_10_15_2 [label="Attention_10_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_10_15_2 [label="Attention_Output_10_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_10_15_3 [label="QKV_Proj_10_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_10_15_3 [label="Attention_10_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_10_15_3 [label="Attention_Output_10_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	attn_allreduce_10_15 [label="Attention_AllReduce_10_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_10_0_0 [label="MLP_Linear1_10_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_10_0_0 [label="GELU_10_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_10_0_0 [label="MLP_Linear2_10_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_10_0_1 [label="MLP_Linear1_10_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_10_0_1 [label="GELU_10_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_10_0_1 [label="MLP_Linear2_10_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_10_0_2 [label="MLP_Linear1_10_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_10_0_2 [label="GELU_10_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_10_0_2 [label="MLP_Linear2_10_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_10_0_3 [label="MLP_Linear1_10_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_10_0_3 [label="GELU_10_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_10_0_3 [label="MLP_Linear2_10_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp_allreduce_10_0 [label="MLP_AllReduce_10_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_10_1_0 [label="MLP_Linear1_10_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_10_1_0 [label="GELU_10_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_10_1_0 [label="MLP_Linear2_10_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_10_1_1 [label="MLP_Linear1_10_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_10_1_1 [label="GELU_10_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_10_1_1 [label="MLP_Linear2_10_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_10_1_2 [label="MLP_Linear1_10_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_10_1_2 [label="GELU_10_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_10_1_2 [label="MLP_Linear2_10_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_10_1_3 [label="MLP_Linear1_10_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_10_1_3 [label="GELU_10_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_10_1_3 [label="MLP_Linear2_10_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp_allreduce_10_1 [label="MLP_AllReduce_10_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_10_2_0 [label="MLP_Linear1_10_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_10_2_0 [label="GELU_10_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_10_2_0 [label="MLP_Linear2_10_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_10_2_1 [label="MLP_Linear1_10_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_10_2_1 [label="GELU_10_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_10_2_1 [label="MLP_Linear2_10_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_10_2_2 [label="MLP_Linear1_10_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_10_2_2 [label="GELU_10_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_10_2_2 [label="MLP_Linear2_10_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_10_2_3 [label="MLP_Linear1_10_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_10_2_3 [label="GELU_10_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_10_2_3 [label="MLP_Linear2_10_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp_allreduce_10_2 [label="MLP_AllReduce_10_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_10_3_0 [label="MLP_Linear1_10_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_10_3_0 [label="GELU_10_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_10_3_0 [label="MLP_Linear2_10_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_10_3_1 [label="MLP_Linear1_10_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_10_3_1 [label="GELU_10_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_10_3_1 [label="MLP_Linear2_10_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_10_3_2 [label="MLP_Linear1_10_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_10_3_2 [label="GELU_10_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_10_3_2 [label="MLP_Linear2_10_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_10_3_3 [label="MLP_Linear1_10_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_10_3_3 [label="GELU_10_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_10_3_3 [label="MLP_Linear2_10_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp_allreduce_10_3 [label="MLP_AllReduce_10_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_10_4_0 [label="MLP_Linear1_10_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_10_4_0 [label="GELU_10_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_10_4_0 [label="MLP_Linear2_10_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_10_4_1 [label="MLP_Linear1_10_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_10_4_1 [label="GELU_10_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_10_4_1 [label="MLP_Linear2_10_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_10_4_2 [label="MLP_Linear1_10_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_10_4_2 [label="GELU_10_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_10_4_2 [label="MLP_Linear2_10_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_10_4_3 [label="MLP_Linear1_10_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_10_4_3 [label="GELU_10_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_10_4_3 [label="MLP_Linear2_10_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp_allreduce_10_4 [label="MLP_AllReduce_10_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_10_5_0 [label="MLP_Linear1_10_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_10_5_0 [label="GELU_10_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_10_5_0 [label="MLP_Linear2_10_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_10_5_1 [label="MLP_Linear1_10_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_10_5_1 [label="GELU_10_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_10_5_1 [label="MLP_Linear2_10_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_10_5_2 [label="MLP_Linear1_10_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_10_5_2 [label="GELU_10_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_10_5_2 [label="MLP_Linear2_10_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_10_5_3 [label="MLP_Linear1_10_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_10_5_3 [label="GELU_10_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_10_5_3 [label="MLP_Linear2_10_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp_allreduce_10_5 [label="MLP_AllReduce_10_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_10_6_0 [label="MLP_Linear1_10_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_10_6_0 [label="GELU_10_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_10_6_0 [label="MLP_Linear2_10_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_10_6_1 [label="MLP_Linear1_10_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_10_6_1 [label="GELU_10_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_10_6_1 [label="MLP_Linear2_10_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_10_6_2 [label="MLP_Linear1_10_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_10_6_2 [label="GELU_10_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_10_6_2 [label="MLP_Linear2_10_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_10_6_3 [label="MLP_Linear1_10_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_10_6_3 [label="GELU_10_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_10_6_3 [label="MLP_Linear2_10_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp_allreduce_10_6 [label="MLP_AllReduce_10_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_10_7_0 [label="MLP_Linear1_10_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_10_7_0 [label="GELU_10_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_10_7_0 [label="MLP_Linear2_10_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_10_7_1 [label="MLP_Linear1_10_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_10_7_1 [label="GELU_10_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_10_7_1 [label="MLP_Linear2_10_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_10_7_2 [label="MLP_Linear1_10_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_10_7_2 [label="GELU_10_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_10_7_2 [label="MLP_Linear2_10_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_10_7_3 [label="MLP_Linear1_10_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_10_7_3 [label="GELU_10_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_10_7_3 [label="MLP_Linear2_10_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp_allreduce_10_7 [label="MLP_AllReduce_10_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_10_8_0 [label="MLP_Linear1_10_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_10_8_0 [label="GELU_10_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_10_8_0 [label="MLP_Linear2_10_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_10_8_1 [label="MLP_Linear1_10_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_10_8_1 [label="GELU_10_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_10_8_1 [label="MLP_Linear2_10_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_10_8_2 [label="MLP_Linear1_10_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_10_8_2 [label="GELU_10_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_10_8_2 [label="MLP_Linear2_10_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_10_8_3 [label="MLP_Linear1_10_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_10_8_3 [label="GELU_10_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_10_8_3 [label="MLP_Linear2_10_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp_allreduce_10_8 [label="MLP_AllReduce_10_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_10_9_0 [label="MLP_Linear1_10_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_10_9_0 [label="GELU_10_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_10_9_0 [label="MLP_Linear2_10_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_10_9_1 [label="MLP_Linear1_10_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_10_9_1 [label="GELU_10_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_10_9_1 [label="MLP_Linear2_10_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_10_9_2 [label="MLP_Linear1_10_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_10_9_2 [label="GELU_10_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_10_9_2 [label="MLP_Linear2_10_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_10_9_3 [label="MLP_Linear1_10_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_10_9_3 [label="GELU_10_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_10_9_3 [label="MLP_Linear2_10_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp_allreduce_10_9 [label="MLP_AllReduce_10_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_10_10_0 [label="MLP_Linear1_10_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_10_10_0 [label="GELU_10_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_10_10_0 [label="MLP_Linear2_10_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_10_10_1 [label="MLP_Linear1_10_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_10_10_1 [label="GELU_10_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_10_10_1 [label="MLP_Linear2_10_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_10_10_2 [label="MLP_Linear1_10_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_10_10_2 [label="GELU_10_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_10_10_2 [label="MLP_Linear2_10_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_10_10_3 [label="MLP_Linear1_10_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_10_10_3 [label="GELU_10_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_10_10_3 [label="MLP_Linear2_10_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp_allreduce_10_10 [label="MLP_AllReduce_10_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_10_11_0 [label="MLP_Linear1_10_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_10_11_0 [label="GELU_10_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_10_11_0 [label="MLP_Linear2_10_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_10_11_1 [label="MLP_Linear1_10_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_10_11_1 [label="GELU_10_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_10_11_1 [label="MLP_Linear2_10_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_10_11_2 [label="MLP_Linear1_10_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_10_11_2 [label="GELU_10_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_10_11_2 [label="MLP_Linear2_10_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_10_11_3 [label="MLP_Linear1_10_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_10_11_3 [label="GELU_10_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_10_11_3 [label="MLP_Linear2_10_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp_allreduce_10_11 [label="MLP_AllReduce_10_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_10_12_0 [label="MLP_Linear1_10_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_10_12_0 [label="GELU_10_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_10_12_0 [label="MLP_Linear2_10_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_10_12_1 [label="MLP_Linear1_10_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_10_12_1 [label="GELU_10_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_10_12_1 [label="MLP_Linear2_10_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_10_12_2 [label="MLP_Linear1_10_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_10_12_2 [label="GELU_10_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_10_12_2 [label="MLP_Linear2_10_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_10_12_3 [label="MLP_Linear1_10_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_10_12_3 [label="GELU_10_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_10_12_3 [label="MLP_Linear2_10_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp_allreduce_10_12 [label="MLP_AllReduce_10_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_10_13_0 [label="MLP_Linear1_10_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_10_13_0 [label="GELU_10_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_10_13_0 [label="MLP_Linear2_10_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_10_13_1 [label="MLP_Linear1_10_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_10_13_1 [label="GELU_10_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_10_13_1 [label="MLP_Linear2_10_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_10_13_2 [label="MLP_Linear1_10_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_10_13_2 [label="GELU_10_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_10_13_2 [label="MLP_Linear2_10_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_10_13_3 [label="MLP_Linear1_10_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_10_13_3 [label="GELU_10_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_10_13_3 [label="MLP_Linear2_10_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp_allreduce_10_13 [label="MLP_AllReduce_10_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_10_14_0 [label="MLP_Linear1_10_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_10_14_0 [label="GELU_10_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_10_14_0 [label="MLP_Linear2_10_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_10_14_1 [label="MLP_Linear1_10_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_10_14_1 [label="GELU_10_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_10_14_1 [label="MLP_Linear2_10_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_10_14_2 [label="MLP_Linear1_10_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_10_14_2 [label="GELU_10_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_10_14_2 [label="MLP_Linear2_10_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_10_14_3 [label="MLP_Linear1_10_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_10_14_3 [label="GELU_10_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_10_14_3 [label="MLP_Linear2_10_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp_allreduce_10_14 [label="MLP_AllReduce_10_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_10_15_0 [label="MLP_Linear1_10_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_10_15_0 [label="GELU_10_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_10_15_0 [label="MLP_Linear2_10_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_10_15_1 [label="MLP_Linear1_10_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_10_15_1 [label="GELU_10_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_10_15_1 [label="MLP_Linear2_10_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_10_15_2 [label="MLP_Linear1_10_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_10_15_2 [label="GELU_10_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_10_15_2 [label="MLP_Linear2_10_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_10_15_3 [label="MLP_Linear1_10_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_10_15_3 [label="GELU_10_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_10_15_3 [label="MLP_Linear2_10_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp_allreduce_10_15 [label="MLP_AllReduce_10_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	expert_route_10_0 [label="Expert_Route_10_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_10_1 [label="Expert_Route_10_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_10_2 [label="Expert_Route_10_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_10_3 [label="Expert_Route_10_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_10_4 [label="Expert_Route_10_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_10_5 [label="Expert_Route_10_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_10_6 [label="Expert_Route_10_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_10_7 [label="Expert_Route_10_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_10_8 [label="Expert_Route_10_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_10_9 [label="Expert_Route_10_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_10_10 [label="Expert_Route_10_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_10_11 [label="Expert_Route_10_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_10_12 [label="Expert_Route_10_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_10_13 [label="Expert_Route_10_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_10_14 [label="Expert_Route_10_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_10_15 [label="Expert_Route_10_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	qkv_11_0_0 [label="QKV_Proj_11_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_11_0_0 [label="Attention_11_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_11_0_0 [label="Attention_Output_11_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_11_0_1 [label="QKV_Proj_11_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_11_0_1 [label="Attention_11_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_11_0_1 [label="Attention_Output_11_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_11_0_2 [label="QKV_Proj_11_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_11_0_2 [label="Attention_11_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_11_0_2 [label="Attention_Output_11_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_11_0_3 [label="QKV_Proj_11_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_11_0_3 [label="Attention_11_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_11_0_3 [label="Attention_Output_11_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	attn_allreduce_11_0 [label="Attention_AllReduce_11_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_11_1_0 [label="QKV_Proj_11_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_11_1_0 [label="Attention_11_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_11_1_0 [label="Attention_Output_11_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_11_1_1 [label="QKV_Proj_11_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_11_1_1 [label="Attention_11_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_11_1_1 [label="Attention_Output_11_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_11_1_2 [label="QKV_Proj_11_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_11_1_2 [label="Attention_11_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_11_1_2 [label="Attention_Output_11_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_11_1_3 [label="QKV_Proj_11_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_11_1_3 [label="Attention_11_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_11_1_3 [label="Attention_Output_11_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	attn_allreduce_11_1 [label="Attention_AllReduce_11_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_11_2_0 [label="QKV_Proj_11_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_11_2_0 [label="Attention_11_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_11_2_0 [label="Attention_Output_11_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_11_2_1 [label="QKV_Proj_11_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_11_2_1 [label="Attention_11_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_11_2_1 [label="Attention_Output_11_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_11_2_2 [label="QKV_Proj_11_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_11_2_2 [label="Attention_11_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_11_2_2 [label="Attention_Output_11_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_11_2_3 [label="QKV_Proj_11_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_11_2_3 [label="Attention_11_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_11_2_3 [label="Attention_Output_11_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	attn_allreduce_11_2 [label="Attention_AllReduce_11_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_11_3_0 [label="QKV_Proj_11_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_11_3_0 [label="Attention_11_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_11_3_0 [label="Attention_Output_11_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_11_3_1 [label="QKV_Proj_11_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_11_3_1 [label="Attention_11_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_11_3_1 [label="Attention_Output_11_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_11_3_2 [label="QKV_Proj_11_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_11_3_2 [label="Attention_11_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_11_3_2 [label="Attention_Output_11_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_11_3_3 [label="QKV_Proj_11_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_11_3_3 [label="Attention_11_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_11_3_3 [label="Attention_Output_11_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	attn_allreduce_11_3 [label="Attention_AllReduce_11_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_11_4_0 [label="QKV_Proj_11_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_11_4_0 [label="Attention_11_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_11_4_0 [label="Attention_Output_11_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_11_4_1 [label="QKV_Proj_11_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_11_4_1 [label="Attention_11_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_11_4_1 [label="Attention_Output_11_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_11_4_2 [label="QKV_Proj_11_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_11_4_2 [label="Attention_11_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_11_4_2 [label="Attention_Output_11_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_11_4_3 [label="QKV_Proj_11_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_11_4_3 [label="Attention_11_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_11_4_3 [label="Attention_Output_11_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	attn_allreduce_11_4 [label="Attention_AllReduce_11_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_11_5_0 [label="QKV_Proj_11_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_11_5_0 [label="Attention_11_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_11_5_0 [label="Attention_Output_11_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_11_5_1 [label="QKV_Proj_11_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_11_5_1 [label="Attention_11_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_11_5_1 [label="Attention_Output_11_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_11_5_2 [label="QKV_Proj_11_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_11_5_2 [label="Attention_11_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_11_5_2 [label="Attention_Output_11_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_11_5_3 [label="QKV_Proj_11_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_11_5_3 [label="Attention_11_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_11_5_3 [label="Attention_Output_11_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	attn_allreduce_11_5 [label="Attention_AllReduce_11_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_11_6_0 [label="QKV_Proj_11_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_11_6_0 [label="Attention_11_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_11_6_0 [label="Attention_Output_11_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_11_6_1 [label="QKV_Proj_11_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_11_6_1 [label="Attention_11_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_11_6_1 [label="Attention_Output_11_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_11_6_2 [label="QKV_Proj_11_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_11_6_2 [label="Attention_11_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_11_6_2 [label="Attention_Output_11_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_11_6_3 [label="QKV_Proj_11_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_11_6_3 [label="Attention_11_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_11_6_3 [label="Attention_Output_11_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	attn_allreduce_11_6 [label="Attention_AllReduce_11_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_11_7_0 [label="QKV_Proj_11_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_11_7_0 [label="Attention_11_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_11_7_0 [label="Attention_Output_11_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_11_7_1 [label="QKV_Proj_11_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_11_7_1 [label="Attention_11_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_11_7_1 [label="Attention_Output_11_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_11_7_2 [label="QKV_Proj_11_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_11_7_2 [label="Attention_11_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_11_7_2 [label="Attention_Output_11_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_11_7_3 [label="QKV_Proj_11_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_11_7_3 [label="Attention_11_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_11_7_3 [label="Attention_Output_11_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	attn_allreduce_11_7 [label="Attention_AllReduce_11_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_11_8_0 [label="QKV_Proj_11_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_11_8_0 [label="Attention_11_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_11_8_0 [label="Attention_Output_11_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_11_8_1 [label="QKV_Proj_11_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_11_8_1 [label="Attention_11_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_11_8_1 [label="Attention_Output_11_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_11_8_2 [label="QKV_Proj_11_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_11_8_2 [label="Attention_11_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_11_8_2 [label="Attention_Output_11_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_11_8_3 [label="QKV_Proj_11_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_11_8_3 [label="Attention_11_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_11_8_3 [label="Attention_Output_11_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	attn_allreduce_11_8 [label="Attention_AllReduce_11_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_11_9_0 [label="QKV_Proj_11_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_11_9_0 [label="Attention_11_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_11_9_0 [label="Attention_Output_11_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_11_9_1 [label="QKV_Proj_11_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_11_9_1 [label="Attention_11_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_11_9_1 [label="Attention_Output_11_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_11_9_2 [label="QKV_Proj_11_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_11_9_2 [label="Attention_11_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_11_9_2 [label="Attention_Output_11_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_11_9_3 [label="QKV_Proj_11_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_11_9_3 [label="Attention_11_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_11_9_3 [label="Attention_Output_11_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	attn_allreduce_11_9 [label="Attention_AllReduce_11_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_11_10_0 [label="QKV_Proj_11_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_11_10_0 [label="Attention_11_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_11_10_0 [label="Attention_Output_11_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_11_10_1 [label="QKV_Proj_11_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_11_10_1 [label="Attention_11_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_11_10_1 [label="Attention_Output_11_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_11_10_2 [label="QKV_Proj_11_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_11_10_2 [label="Attention_11_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_11_10_2 [label="Attention_Output_11_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_11_10_3 [label="QKV_Proj_11_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_11_10_3 [label="Attention_11_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_11_10_3 [label="Attention_Output_11_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	attn_allreduce_11_10 [label="Attention_AllReduce_11_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_11_11_0 [label="QKV_Proj_11_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_11_11_0 [label="Attention_11_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_11_11_0 [label="Attention_Output_11_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_11_11_1 [label="QKV_Proj_11_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_11_11_1 [label="Attention_11_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_11_11_1 [label="Attention_Output_11_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_11_11_2 [label="QKV_Proj_11_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_11_11_2 [label="Attention_11_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_11_11_2 [label="Attention_Output_11_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_11_11_3 [label="QKV_Proj_11_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_11_11_3 [label="Attention_11_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_11_11_3 [label="Attention_Output_11_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	attn_allreduce_11_11 [label="Attention_AllReduce_11_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_11_12_0 [label="QKV_Proj_11_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_11_12_0 [label="Attention_11_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_11_12_0 [label="Attention_Output_11_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_11_12_1 [label="QKV_Proj_11_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_11_12_1 [label="Attention_11_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_11_12_1 [label="Attention_Output_11_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_11_12_2 [label="QKV_Proj_11_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_11_12_2 [label="Attention_11_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_11_12_2 [label="Attention_Output_11_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_11_12_3 [label="QKV_Proj_11_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_11_12_3 [label="Attention_11_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_11_12_3 [label="Attention_Output_11_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	attn_allreduce_11_12 [label="Attention_AllReduce_11_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_11_13_0 [label="QKV_Proj_11_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_11_13_0 [label="Attention_11_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_11_13_0 [label="Attention_Output_11_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_11_13_1 [label="QKV_Proj_11_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_11_13_1 [label="Attention_11_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_11_13_1 [label="Attention_Output_11_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_11_13_2 [label="QKV_Proj_11_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_11_13_2 [label="Attention_11_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_11_13_2 [label="Attention_Output_11_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_11_13_3 [label="QKV_Proj_11_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_11_13_3 [label="Attention_11_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_11_13_3 [label="Attention_Output_11_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	attn_allreduce_11_13 [label="Attention_AllReduce_11_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_11_14_0 [label="QKV_Proj_11_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_11_14_0 [label="Attention_11_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_11_14_0 [label="Attention_Output_11_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_11_14_1 [label="QKV_Proj_11_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_11_14_1 [label="Attention_11_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_11_14_1 [label="Attention_Output_11_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_11_14_2 [label="QKV_Proj_11_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_11_14_2 [label="Attention_11_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_11_14_2 [label="Attention_Output_11_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_11_14_3 [label="QKV_Proj_11_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_11_14_3 [label="Attention_11_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_11_14_3 [label="Attention_Output_11_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	attn_allreduce_11_14 [label="Attention_AllReduce_11_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_11_15_0 [label="QKV_Proj_11_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_11_15_0 [label="Attention_11_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_11_15_0 [label="Attention_Output_11_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_11_15_1 [label="QKV_Proj_11_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_11_15_1 [label="Attention_11_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_11_15_1 [label="Attention_Output_11_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_11_15_2 [label="QKV_Proj_11_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_11_15_2 [label="Attention_11_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_11_15_2 [label="Attention_Output_11_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_11_15_3 [label="QKV_Proj_11_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_11_15_3 [label="Attention_11_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_11_15_3 [label="Attention_Output_11_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	attn_allreduce_11_15 [label="Attention_AllReduce_11_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_11_0_0 [label="MLP_Linear1_11_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_11_0_0 [label="GELU_11_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_11_0_0 [label="MLP_Linear2_11_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_11_0_1 [label="MLP_Linear1_11_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_11_0_1 [label="GELU_11_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_11_0_1 [label="MLP_Linear2_11_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_11_0_2 [label="MLP_Linear1_11_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_11_0_2 [label="GELU_11_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_11_0_2 [label="MLP_Linear2_11_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_11_0_3 [label="MLP_Linear1_11_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_11_0_3 [label="GELU_11_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_11_0_3 [label="MLP_Linear2_11_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp_allreduce_11_0 [label="MLP_AllReduce_11_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_11_1_0 [label="MLP_Linear1_11_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_11_1_0 [label="GELU_11_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_11_1_0 [label="MLP_Linear2_11_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_11_1_1 [label="MLP_Linear1_11_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_11_1_1 [label="GELU_11_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_11_1_1 [label="MLP_Linear2_11_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_11_1_2 [label="MLP_Linear1_11_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_11_1_2 [label="GELU_11_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_11_1_2 [label="MLP_Linear2_11_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_11_1_3 [label="MLP_Linear1_11_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_11_1_3 [label="GELU_11_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_11_1_3 [label="MLP_Linear2_11_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp_allreduce_11_1 [label="MLP_AllReduce_11_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_11_2_0 [label="MLP_Linear1_11_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_11_2_0 [label="GELU_11_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_11_2_0 [label="MLP_Linear2_11_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_11_2_1 [label="MLP_Linear1_11_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_11_2_1 [label="GELU_11_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_11_2_1 [label="MLP_Linear2_11_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_11_2_2 [label="MLP_Linear1_11_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_11_2_2 [label="GELU_11_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_11_2_2 [label="MLP_Linear2_11_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_11_2_3 [label="MLP_Linear1_11_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_11_2_3 [label="GELU_11_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_11_2_3 [label="MLP_Linear2_11_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp_allreduce_11_2 [label="MLP_AllReduce_11_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_11_3_0 [label="MLP_Linear1_11_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_11_3_0 [label="GELU_11_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_11_3_0 [label="MLP_Linear2_11_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_11_3_1 [label="MLP_Linear1_11_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_11_3_1 [label="GELU_11_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_11_3_1 [label="MLP_Linear2_11_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_11_3_2 [label="MLP_Linear1_11_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_11_3_2 [label="GELU_11_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_11_3_2 [label="MLP_Linear2_11_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_11_3_3 [label="MLP_Linear1_11_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_11_3_3 [label="GELU_11_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_11_3_3 [label="MLP_Linear2_11_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp_allreduce_11_3 [label="MLP_AllReduce_11_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_11_4_0 [label="MLP_Linear1_11_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_11_4_0 [label="GELU_11_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_11_4_0 [label="MLP_Linear2_11_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_11_4_1 [label="MLP_Linear1_11_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_11_4_1 [label="GELU_11_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_11_4_1 [label="MLP_Linear2_11_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_11_4_2 [label="MLP_Linear1_11_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_11_4_2 [label="GELU_11_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_11_4_2 [label="MLP_Linear2_11_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_11_4_3 [label="MLP_Linear1_11_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_11_4_3 [label="GELU_11_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_11_4_3 [label="MLP_Linear2_11_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp_allreduce_11_4 [label="MLP_AllReduce_11_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_11_5_0 [label="MLP_Linear1_11_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_11_5_0 [label="GELU_11_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_11_5_0 [label="MLP_Linear2_11_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_11_5_1 [label="MLP_Linear1_11_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_11_5_1 [label="GELU_11_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_11_5_1 [label="MLP_Linear2_11_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_11_5_2 [label="MLP_Linear1_11_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_11_5_2 [label="GELU_11_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_11_5_2 [label="MLP_Linear2_11_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_11_5_3 [label="MLP_Linear1_11_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_11_5_3 [label="GELU_11_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_11_5_3 [label="MLP_Linear2_11_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp_allreduce_11_5 [label="MLP_AllReduce_11_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_11_6_0 [label="MLP_Linear1_11_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_11_6_0 [label="GELU_11_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_11_6_0 [label="MLP_Linear2_11_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_11_6_1 [label="MLP_Linear1_11_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_11_6_1 [label="GELU_11_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_11_6_1 [label="MLP_Linear2_11_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_11_6_2 [label="MLP_Linear1_11_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_11_6_2 [label="GELU_11_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_11_6_2 [label="MLP_Linear2_11_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_11_6_3 [label="MLP_Linear1_11_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_11_6_3 [label="GELU_11_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_11_6_3 [label="MLP_Linear2_11_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp_allreduce_11_6 [label="MLP_AllReduce_11_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_11_7_0 [label="MLP_Linear1_11_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_11_7_0 [label="GELU_11_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_11_7_0 [label="MLP_Linear2_11_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_11_7_1 [label="MLP_Linear1_11_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_11_7_1 [label="GELU_11_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_11_7_1 [label="MLP_Linear2_11_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_11_7_2 [label="MLP_Linear1_11_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_11_7_2 [label="GELU_11_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_11_7_2 [label="MLP_Linear2_11_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_11_7_3 [label="MLP_Linear1_11_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_11_7_3 [label="GELU_11_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_11_7_3 [label="MLP_Linear2_11_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp_allreduce_11_7 [label="MLP_AllReduce_11_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_11_8_0 [label="MLP_Linear1_11_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_11_8_0 [label="GELU_11_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_11_8_0 [label="MLP_Linear2_11_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_11_8_1 [label="MLP_Linear1_11_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_11_8_1 [label="GELU_11_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_11_8_1 [label="MLP_Linear2_11_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_11_8_2 [label="MLP_Linear1_11_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_11_8_2 [label="GELU_11_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_11_8_2 [label="MLP_Linear2_11_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_11_8_3 [label="MLP_Linear1_11_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_11_8_3 [label="GELU_11_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_11_8_3 [label="MLP_Linear2_11_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp_allreduce_11_8 [label="MLP_AllReduce_11_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_11_9_0 [label="MLP_Linear1_11_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_11_9_0 [label="GELU_11_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_11_9_0 [label="MLP_Linear2_11_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_11_9_1 [label="MLP_Linear1_11_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_11_9_1 [label="GELU_11_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_11_9_1 [label="MLP_Linear2_11_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_11_9_2 [label="MLP_Linear1_11_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_11_9_2 [label="GELU_11_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_11_9_2 [label="MLP_Linear2_11_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_11_9_3 [label="MLP_Linear1_11_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_11_9_3 [label="GELU_11_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_11_9_3 [label="MLP_Linear2_11_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp_allreduce_11_9 [label="MLP_AllReduce_11_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_11_10_0 [label="MLP_Linear1_11_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_11_10_0 [label="GELU_11_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_11_10_0 [label="MLP_Linear2_11_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_11_10_1 [label="MLP_Linear1_11_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_11_10_1 [label="GELU_11_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_11_10_1 [label="MLP_Linear2_11_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_11_10_2 [label="MLP_Linear1_11_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_11_10_2 [label="GELU_11_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_11_10_2 [label="MLP_Linear2_11_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_11_10_3 [label="MLP_Linear1_11_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_11_10_3 [label="GELU_11_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_11_10_3 [label="MLP_Linear2_11_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp_allreduce_11_10 [label="MLP_AllReduce_11_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_11_11_0 [label="MLP_Linear1_11_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_11_11_0 [label="GELU_11_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_11_11_0 [label="MLP_Linear2_11_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_11_11_1 [label="MLP_Linear1_11_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_11_11_1 [label="GELU_11_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_11_11_1 [label="MLP_Linear2_11_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_11_11_2 [label="MLP_Linear1_11_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_11_11_2 [label="GELU_11_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_11_11_2 [label="MLP_Linear2_11_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_11_11_3 [label="MLP_Linear1_11_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_11_11_3 [label="GELU_11_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_11_11_3 [label="MLP_Linear2_11_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp_allreduce_11_11 [label="MLP_AllReduce_11_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_11_12_0 [label="MLP_Linear1_11_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_11_12_0 [label="GELU_11_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_11_12_0 [label="MLP_Linear2_11_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_11_12_1 [label="MLP_Linear1_11_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_11_12_1 [label="GELU_11_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_11_12_1 [label="MLP_Linear2_11_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_11_12_2 [label="MLP_Linear1_11_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_11_12_2 [label="GELU_11_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_11_12_2 [label="MLP_Linear2_11_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_11_12_3 [label="MLP_Linear1_11_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_11_12_3 [label="GELU_11_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_11_12_3 [label="MLP_Linear2_11_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp_allreduce_11_12 [label="MLP_AllReduce_11_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_11_13_0 [label="MLP_Linear1_11_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_11_13_0 [label="GELU_11_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_11_13_0 [label="MLP_Linear2_11_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_11_13_1 [label="MLP_Linear1_11_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_11_13_1 [label="GELU_11_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_11_13_1 [label="MLP_Linear2_11_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_11_13_2 [label="MLP_Linear1_11_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_11_13_2 [label="GELU_11_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_11_13_2 [label="MLP_Linear2_11_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_11_13_3 [label="MLP_Linear1_11_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_11_13_3 [label="GELU_11_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_11_13_3 [label="MLP_Linear2_11_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp_allreduce_11_13 [label="MLP_AllReduce_11_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_11_14_0 [label="MLP_Linear1_11_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_11_14_0 [label="GELU_11_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_11_14_0 [label="MLP_Linear2_11_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_11_14_1 [label="MLP_Linear1_11_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_11_14_1 [label="GELU_11_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_11_14_1 [label="MLP_Linear2_11_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_11_14_2 [label="MLP_Linear1_11_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_11_14_2 [label="GELU_11_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_11_14_2 [label="MLP_Linear2_11_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_11_14_3 [label="MLP_Linear1_11_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_11_14_3 [label="GELU_11_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_11_14_3 [label="MLP_Linear2_11_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp_allreduce_11_14 [label="MLP_AllReduce_11_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_11_15_0 [label="MLP_Linear1_11_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_11_15_0 [label="GELU_11_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_11_15_0 [label="MLP_Linear2_11_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_11_15_1 [label="MLP_Linear1_11_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_11_15_1 [label="GELU_11_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_11_15_1 [label="MLP_Linear2_11_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_11_15_2 [label="MLP_Linear1_11_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_11_15_2 [label="GELU_11_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_11_15_2 [label="MLP_Linear2_11_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_11_15_3 [label="MLP_Linear1_11_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_11_15_3 [label="GELU_11_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_11_15_3 [label="MLP_Linear2_11_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp_allreduce_11_15 [label="MLP_AllReduce_11_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	expert_route_11_0 [label="Expert_Route_11_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_11_1 [label="Expert_Route_11_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_11_2 [label="Expert_Route_11_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_11_3 [label="Expert_Route_11_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_11_4 [label="Expert_Route_11_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_11_5 [label="Expert_Route_11_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_11_6 [label="Expert_Route_11_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_11_7 [label="Expert_Route_11_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_11_8 [label="Expert_Route_11_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_11_9 [label="Expert_Route_11_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_11_10 [label="Expert_Route_11_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_11_11 [label="Expert_Route_11_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_11_12 [label="Expert_Route_11_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_11_13 [label="Expert_Route_11_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_11_14 [label="Expert_Route_11_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_11_15 [label="Expert_Route_11_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	qkv_12_0_0 [label="QKV_Proj_12_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_12_0_0 [label="Attention_12_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_12_0_0 [label="Attention_Output_12_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_12_0_1 [label="QKV_Proj_12_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_12_0_1 [label="Attention_12_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_12_0_1 [label="Attention_Output_12_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_12_0_2 [label="QKV_Proj_12_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_12_0_2 [label="Attention_12_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_12_0_2 [label="Attention_Output_12_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_12_0_3 [label="QKV_Proj_12_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_12_0_3 [label="Attention_12_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_12_0_3 [label="Attention_Output_12_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	attn_allreduce_12_0 [label="Attention_AllReduce_12_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_12_1_0 [label="QKV_Proj_12_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_12_1_0 [label="Attention_12_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_12_1_0 [label="Attention_Output_12_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_12_1_1 [label="QKV_Proj_12_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_12_1_1 [label="Attention_12_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_12_1_1 [label="Attention_Output_12_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_12_1_2 [label="QKV_Proj_12_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_12_1_2 [label="Attention_12_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_12_1_2 [label="Attention_Output_12_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_12_1_3 [label="QKV_Proj_12_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_12_1_3 [label="Attention_12_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_12_1_3 [label="Attention_Output_12_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	attn_allreduce_12_1 [label="Attention_AllReduce_12_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_12_2_0 [label="QKV_Proj_12_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_12_2_0 [label="Attention_12_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_12_2_0 [label="Attention_Output_12_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_12_2_1 [label="QKV_Proj_12_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_12_2_1 [label="Attention_12_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_12_2_1 [label="Attention_Output_12_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_12_2_2 [label="QKV_Proj_12_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_12_2_2 [label="Attention_12_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_12_2_2 [label="Attention_Output_12_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_12_2_3 [label="QKV_Proj_12_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_12_2_3 [label="Attention_12_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_12_2_3 [label="Attention_Output_12_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	attn_allreduce_12_2 [label="Attention_AllReduce_12_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_12_3_0 [label="QKV_Proj_12_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_12_3_0 [label="Attention_12_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_12_3_0 [label="Attention_Output_12_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_12_3_1 [label="QKV_Proj_12_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_12_3_1 [label="Attention_12_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_12_3_1 [label="Attention_Output_12_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_12_3_2 [label="QKV_Proj_12_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_12_3_2 [label="Attention_12_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_12_3_2 [label="Attention_Output_12_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_12_3_3 [label="QKV_Proj_12_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_12_3_3 [label="Attention_12_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_12_3_3 [label="Attention_Output_12_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	attn_allreduce_12_3 [label="Attention_AllReduce_12_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_12_4_0 [label="QKV_Proj_12_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_12_4_0 [label="Attention_12_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_12_4_0 [label="Attention_Output_12_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_12_4_1 [label="QKV_Proj_12_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_12_4_1 [label="Attention_12_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_12_4_1 [label="Attention_Output_12_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_12_4_2 [label="QKV_Proj_12_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_12_4_2 [label="Attention_12_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_12_4_2 [label="Attention_Output_12_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_12_4_3 [label="QKV_Proj_12_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_12_4_3 [label="Attention_12_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_12_4_3 [label="Attention_Output_12_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	attn_allreduce_12_4 [label="Attention_AllReduce_12_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_12_5_0 [label="QKV_Proj_12_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_12_5_0 [label="Attention_12_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_12_5_0 [label="Attention_Output_12_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_12_5_1 [label="QKV_Proj_12_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_12_5_1 [label="Attention_12_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_12_5_1 [label="Attention_Output_12_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_12_5_2 [label="QKV_Proj_12_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_12_5_2 [label="Attention_12_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_12_5_2 [label="Attention_Output_12_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_12_5_3 [label="QKV_Proj_12_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_12_5_3 [label="Attention_12_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_12_5_3 [label="Attention_Output_12_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	attn_allreduce_12_5 [label="Attention_AllReduce_12_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_12_6_0 [label="QKV_Proj_12_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_12_6_0 [label="Attention_12_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_12_6_0 [label="Attention_Output_12_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_12_6_1 [label="QKV_Proj_12_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_12_6_1 [label="Attention_12_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_12_6_1 [label="Attention_Output_12_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_12_6_2 [label="QKV_Proj_12_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_12_6_2 [label="Attention_12_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_12_6_2 [label="Attention_Output_12_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_12_6_3 [label="QKV_Proj_12_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_12_6_3 [label="Attention_12_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_12_6_3 [label="Attention_Output_12_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	attn_allreduce_12_6 [label="Attention_AllReduce_12_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_12_7_0 [label="QKV_Proj_12_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_12_7_0 [label="Attention_12_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_12_7_0 [label="Attention_Output_12_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_12_7_1 [label="QKV_Proj_12_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_12_7_1 [label="Attention_12_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_12_7_1 [label="Attention_Output_12_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_12_7_2 [label="QKV_Proj_12_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_12_7_2 [label="Attention_12_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_12_7_2 [label="Attention_Output_12_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_12_7_3 [label="QKV_Proj_12_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_12_7_3 [label="Attention_12_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_12_7_3 [label="Attention_Output_12_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	attn_allreduce_12_7 [label="Attention_AllReduce_12_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_12_8_0 [label="QKV_Proj_12_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_12_8_0 [label="Attention_12_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_12_8_0 [label="Attention_Output_12_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_12_8_1 [label="QKV_Proj_12_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_12_8_1 [label="Attention_12_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_12_8_1 [label="Attention_Output_12_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_12_8_2 [label="QKV_Proj_12_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_12_8_2 [label="Attention_12_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_12_8_2 [label="Attention_Output_12_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_12_8_3 [label="QKV_Proj_12_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_12_8_3 [label="Attention_12_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_12_8_3 [label="Attention_Output_12_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	attn_allreduce_12_8 [label="Attention_AllReduce_12_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_12_9_0 [label="QKV_Proj_12_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_12_9_0 [label="Attention_12_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_12_9_0 [label="Attention_Output_12_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_12_9_1 [label="QKV_Proj_12_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_12_9_1 [label="Attention_12_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_12_9_1 [label="Attention_Output_12_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_12_9_2 [label="QKV_Proj_12_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_12_9_2 [label="Attention_12_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_12_9_2 [label="Attention_Output_12_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_12_9_3 [label="QKV_Proj_12_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_12_9_3 [label="Attention_12_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_12_9_3 [label="Attention_Output_12_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	attn_allreduce_12_9 [label="Attention_AllReduce_12_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_12_10_0 [label="QKV_Proj_12_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_12_10_0 [label="Attention_12_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_12_10_0 [label="Attention_Output_12_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_12_10_1 [label="QKV_Proj_12_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_12_10_1 [label="Attention_12_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_12_10_1 [label="Attention_Output_12_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_12_10_2 [label="QKV_Proj_12_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_12_10_2 [label="Attention_12_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_12_10_2 [label="Attention_Output_12_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_12_10_3 [label="QKV_Proj_12_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_12_10_3 [label="Attention_12_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_12_10_3 [label="Attention_Output_12_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	attn_allreduce_12_10 [label="Attention_AllReduce_12_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_12_11_0 [label="QKV_Proj_12_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_12_11_0 [label="Attention_12_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_12_11_0 [label="Attention_Output_12_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_12_11_1 [label="QKV_Proj_12_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_12_11_1 [label="Attention_12_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_12_11_1 [label="Attention_Output_12_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_12_11_2 [label="QKV_Proj_12_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_12_11_2 [label="Attention_12_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_12_11_2 [label="Attention_Output_12_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_12_11_3 [label="QKV_Proj_12_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_12_11_3 [label="Attention_12_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_12_11_3 [label="Attention_Output_12_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	attn_allreduce_12_11 [label="Attention_AllReduce_12_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_12_12_0 [label="QKV_Proj_12_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_12_12_0 [label="Attention_12_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_12_12_0 [label="Attention_Output_12_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_12_12_1 [label="QKV_Proj_12_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_12_12_1 [label="Attention_12_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_12_12_1 [label="Attention_Output_12_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_12_12_2 [label="QKV_Proj_12_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_12_12_2 [label="Attention_12_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_12_12_2 [label="Attention_Output_12_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_12_12_3 [label="QKV_Proj_12_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_12_12_3 [label="Attention_12_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_12_12_3 [label="Attention_Output_12_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	attn_allreduce_12_12 [label="Attention_AllReduce_12_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_12_13_0 [label="QKV_Proj_12_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_12_13_0 [label="Attention_12_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_12_13_0 [label="Attention_Output_12_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_12_13_1 [label="QKV_Proj_12_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_12_13_1 [label="Attention_12_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_12_13_1 [label="Attention_Output_12_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_12_13_2 [label="QKV_Proj_12_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_12_13_2 [label="Attention_12_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_12_13_2 [label="Attention_Output_12_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_12_13_3 [label="QKV_Proj_12_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_12_13_3 [label="Attention_12_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_12_13_3 [label="Attention_Output_12_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	attn_allreduce_12_13 [label="Attention_AllReduce_12_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_12_14_0 [label="QKV_Proj_12_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_12_14_0 [label="Attention_12_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_12_14_0 [label="Attention_Output_12_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_12_14_1 [label="QKV_Proj_12_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_12_14_1 [label="Attention_12_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_12_14_1 [label="Attention_Output_12_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_12_14_2 [label="QKV_Proj_12_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_12_14_2 [label="Attention_12_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_12_14_2 [label="Attention_Output_12_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_12_14_3 [label="QKV_Proj_12_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_12_14_3 [label="Attention_12_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_12_14_3 [label="Attention_Output_12_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	attn_allreduce_12_14 [label="Attention_AllReduce_12_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_12_15_0 [label="QKV_Proj_12_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_12_15_0 [label="Attention_12_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_12_15_0 [label="Attention_Output_12_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_12_15_1 [label="QKV_Proj_12_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_12_15_1 [label="Attention_12_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_12_15_1 [label="Attention_Output_12_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_12_15_2 [label="QKV_Proj_12_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_12_15_2 [label="Attention_12_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_12_15_2 [label="Attention_Output_12_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_12_15_3 [label="QKV_Proj_12_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_12_15_3 [label="Attention_12_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_12_15_3 [label="Attention_Output_12_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	attn_allreduce_12_15 [label="Attention_AllReduce_12_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_12_0_0 [label="MLP_Linear1_12_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_12_0_0 [label="GELU_12_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_12_0_0 [label="MLP_Linear2_12_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_12_0_1 [label="MLP_Linear1_12_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_12_0_1 [label="GELU_12_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_12_0_1 [label="MLP_Linear2_12_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_12_0_2 [label="MLP_Linear1_12_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_12_0_2 [label="GELU_12_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_12_0_2 [label="MLP_Linear2_12_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_12_0_3 [label="MLP_Linear1_12_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_12_0_3 [label="GELU_12_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_12_0_3 [label="MLP_Linear2_12_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp_allreduce_12_0 [label="MLP_AllReduce_12_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_12_1_0 [label="MLP_Linear1_12_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_12_1_0 [label="GELU_12_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_12_1_0 [label="MLP_Linear2_12_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_12_1_1 [label="MLP_Linear1_12_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_12_1_1 [label="GELU_12_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_12_1_1 [label="MLP_Linear2_12_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_12_1_2 [label="MLP_Linear1_12_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_12_1_2 [label="GELU_12_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_12_1_2 [label="MLP_Linear2_12_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_12_1_3 [label="MLP_Linear1_12_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_12_1_3 [label="GELU_12_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_12_1_3 [label="MLP_Linear2_12_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp_allreduce_12_1 [label="MLP_AllReduce_12_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_12_2_0 [label="MLP_Linear1_12_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_12_2_0 [label="GELU_12_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_12_2_0 [label="MLP_Linear2_12_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_12_2_1 [label="MLP_Linear1_12_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_12_2_1 [label="GELU_12_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_12_2_1 [label="MLP_Linear2_12_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_12_2_2 [label="MLP_Linear1_12_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_12_2_2 [label="GELU_12_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_12_2_2 [label="MLP_Linear2_12_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_12_2_3 [label="MLP_Linear1_12_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_12_2_3 [label="GELU_12_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_12_2_3 [label="MLP_Linear2_12_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp_allreduce_12_2 [label="MLP_AllReduce_12_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_12_3_0 [label="MLP_Linear1_12_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_12_3_0 [label="GELU_12_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_12_3_0 [label="MLP_Linear2_12_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_12_3_1 [label="MLP_Linear1_12_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_12_3_1 [label="GELU_12_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_12_3_1 [label="MLP_Linear2_12_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_12_3_2 [label="MLP_Linear1_12_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_12_3_2 [label="GELU_12_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_12_3_2 [label="MLP_Linear2_12_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_12_3_3 [label="MLP_Linear1_12_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_12_3_3 [label="GELU_12_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_12_3_3 [label="MLP_Linear2_12_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp_allreduce_12_3 [label="MLP_AllReduce_12_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_12_4_0 [label="MLP_Linear1_12_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_12_4_0 [label="GELU_12_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_12_4_0 [label="MLP_Linear2_12_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_12_4_1 [label="MLP_Linear1_12_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_12_4_1 [label="GELU_12_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_12_4_1 [label="MLP_Linear2_12_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_12_4_2 [label="MLP_Linear1_12_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_12_4_2 [label="GELU_12_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_12_4_2 [label="MLP_Linear2_12_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_12_4_3 [label="MLP_Linear1_12_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_12_4_3 [label="GELU_12_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_12_4_3 [label="MLP_Linear2_12_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp_allreduce_12_4 [label="MLP_AllReduce_12_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_12_5_0 [label="MLP_Linear1_12_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_12_5_0 [label="GELU_12_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_12_5_0 [label="MLP_Linear2_12_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_12_5_1 [label="MLP_Linear1_12_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_12_5_1 [label="GELU_12_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_12_5_1 [label="MLP_Linear2_12_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_12_5_2 [label="MLP_Linear1_12_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_12_5_2 [label="GELU_12_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_12_5_2 [label="MLP_Linear2_12_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_12_5_3 [label="MLP_Linear1_12_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_12_5_3 [label="GELU_12_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_12_5_3 [label="MLP_Linear2_12_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp_allreduce_12_5 [label="MLP_AllReduce_12_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_12_6_0 [label="MLP_Linear1_12_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_12_6_0 [label="GELU_12_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_12_6_0 [label="MLP_Linear2_12_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_12_6_1 [label="MLP_Linear1_12_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_12_6_1 [label="GELU_12_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_12_6_1 [label="MLP_Linear2_12_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_12_6_2 [label="MLP_Linear1_12_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_12_6_2 [label="GELU_12_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_12_6_2 [label="MLP_Linear2_12_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_12_6_3 [label="MLP_Linear1_12_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_12_6_3 [label="GELU_12_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_12_6_3 [label="MLP_Linear2_12_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp_allreduce_12_6 [label="MLP_AllReduce_12_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_12_7_0 [label="MLP_Linear1_12_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_12_7_0 [label="GELU_12_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_12_7_0 [label="MLP_Linear2_12_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_12_7_1 [label="MLP_Linear1_12_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_12_7_1 [label="GELU_12_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_12_7_1 [label="MLP_Linear2_12_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_12_7_2 [label="MLP_Linear1_12_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_12_7_2 [label="GELU_12_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_12_7_2 [label="MLP_Linear2_12_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_12_7_3 [label="MLP_Linear1_12_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_12_7_3 [label="GELU_12_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_12_7_3 [label="MLP_Linear2_12_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp_allreduce_12_7 [label="MLP_AllReduce_12_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_12_8_0 [label="MLP_Linear1_12_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_12_8_0 [label="GELU_12_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_12_8_0 [label="MLP_Linear2_12_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_12_8_1 [label="MLP_Linear1_12_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_12_8_1 [label="GELU_12_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_12_8_1 [label="MLP_Linear2_12_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_12_8_2 [label="MLP_Linear1_12_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_12_8_2 [label="GELU_12_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_12_8_2 [label="MLP_Linear2_12_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_12_8_3 [label="MLP_Linear1_12_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_12_8_3 [label="GELU_12_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_12_8_3 [label="MLP_Linear2_12_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp_allreduce_12_8 [label="MLP_AllReduce_12_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_12_9_0 [label="MLP_Linear1_12_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_12_9_0 [label="GELU_12_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_12_9_0 [label="MLP_Linear2_12_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_12_9_1 [label="MLP_Linear1_12_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_12_9_1 [label="GELU_12_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_12_9_1 [label="MLP_Linear2_12_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_12_9_2 [label="MLP_Linear1_12_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_12_9_2 [label="GELU_12_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_12_9_2 [label="MLP_Linear2_12_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_12_9_3 [label="MLP_Linear1_12_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_12_9_3 [label="GELU_12_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_12_9_3 [label="MLP_Linear2_12_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp_allreduce_12_9 [label="MLP_AllReduce_12_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_12_10_0 [label="MLP_Linear1_12_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_12_10_0 [label="GELU_12_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_12_10_0 [label="MLP_Linear2_12_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_12_10_1 [label="MLP_Linear1_12_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_12_10_1 [label="GELU_12_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_12_10_1 [label="MLP_Linear2_12_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_12_10_2 [label="MLP_Linear1_12_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_12_10_2 [label="GELU_12_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_12_10_2 [label="MLP_Linear2_12_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_12_10_3 [label="MLP_Linear1_12_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_12_10_3 [label="GELU_12_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_12_10_3 [label="MLP_Linear2_12_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp_allreduce_12_10 [label="MLP_AllReduce_12_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_12_11_0 [label="MLP_Linear1_12_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_12_11_0 [label="GELU_12_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_12_11_0 [label="MLP_Linear2_12_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_12_11_1 [label="MLP_Linear1_12_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_12_11_1 [label="GELU_12_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_12_11_1 [label="MLP_Linear2_12_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_12_11_2 [label="MLP_Linear1_12_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_12_11_2 [label="GELU_12_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_12_11_2 [label="MLP_Linear2_12_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_12_11_3 [label="MLP_Linear1_12_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_12_11_3 [label="GELU_12_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_12_11_3 [label="MLP_Linear2_12_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp_allreduce_12_11 [label="MLP_AllReduce_12_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_12_12_0 [label="MLP_Linear1_12_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_12_12_0 [label="GELU_12_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_12_12_0 [label="MLP_Linear2_12_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_12_12_1 [label="MLP_Linear1_12_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_12_12_1 [label="GELU_12_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_12_12_1 [label="MLP_Linear2_12_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_12_12_2 [label="MLP_Linear1_12_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_12_12_2 [label="GELU_12_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_12_12_2 [label="MLP_Linear2_12_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_12_12_3 [label="MLP_Linear1_12_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_12_12_3 [label="GELU_12_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_12_12_3 [label="MLP_Linear2_12_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp_allreduce_12_12 [label="MLP_AllReduce_12_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_12_13_0 [label="MLP_Linear1_12_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_12_13_0 [label="GELU_12_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_12_13_0 [label="MLP_Linear2_12_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_12_13_1 [label="MLP_Linear1_12_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_12_13_1 [label="GELU_12_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_12_13_1 [label="MLP_Linear2_12_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_12_13_2 [label="MLP_Linear1_12_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_12_13_2 [label="GELU_12_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_12_13_2 [label="MLP_Linear2_12_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_12_13_3 [label="MLP_Linear1_12_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_12_13_3 [label="GELU_12_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_12_13_3 [label="MLP_Linear2_12_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp_allreduce_12_13 [label="MLP_AllReduce_12_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_12_14_0 [label="MLP_Linear1_12_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_12_14_0 [label="GELU_12_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_12_14_0 [label="MLP_Linear2_12_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_12_14_1 [label="MLP_Linear1_12_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_12_14_1 [label="GELU_12_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_12_14_1 [label="MLP_Linear2_12_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_12_14_2 [label="MLP_Linear1_12_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_12_14_2 [label="GELU_12_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_12_14_2 [label="MLP_Linear2_12_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_12_14_3 [label="MLP_Linear1_12_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_12_14_3 [label="GELU_12_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_12_14_3 [label="MLP_Linear2_12_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp_allreduce_12_14 [label="MLP_AllReduce_12_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_12_15_0 [label="MLP_Linear1_12_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_12_15_0 [label="GELU_12_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_12_15_0 [label="MLP_Linear2_12_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_12_15_1 [label="MLP_Linear1_12_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_12_15_1 [label="GELU_12_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_12_15_1 [label="MLP_Linear2_12_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_12_15_2 [label="MLP_Linear1_12_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_12_15_2 [label="GELU_12_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_12_15_2 [label="MLP_Linear2_12_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_12_15_3 [label="MLP_Linear1_12_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_12_15_3 [label="GELU_12_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_12_15_3 [label="MLP_Linear2_12_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp_allreduce_12_15 [label="MLP_AllReduce_12_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	expert_route_12_0 [label="Expert_Route_12_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_12_1 [label="Expert_Route_12_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_12_2 [label="Expert_Route_12_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_12_3 [label="Expert_Route_12_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_12_4 [label="Expert_Route_12_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_12_5 [label="Expert_Route_12_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_12_6 [label="Expert_Route_12_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_12_7 [label="Expert_Route_12_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_12_8 [label="Expert_Route_12_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_12_9 [label="Expert_Route_12_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_12_10 [label="Expert_Route_12_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_12_11 [label="Expert_Route_12_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_12_12 [label="Expert_Route_12_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_12_13 [label="Expert_Route_12_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_12_14 [label="Expert_Route_12_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_12_15 [label="Expert_Route_12_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	qkv_13_0_0 [label="QKV_Proj_13_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_13_0_0 [label="Attention_13_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_13_0_0 [label="Attention_Output_13_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_13_0_1 [label="QKV_Proj_13_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_13_0_1 [label="Attention_13_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_13_0_1 [label="Attention_Output_13_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_13_0_2 [label="QKV_Proj_13_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_13_0_2 [label="Attention_13_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_13_0_2 [label="Attention_Output_13_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_13_0_3 [label="QKV_Proj_13_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_13_0_3 [label="Attention_13_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_13_0_3 [label="Attention_Output_13_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	attn_allreduce_13_0 [label="Attention_AllReduce_13_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_13_1_0 [label="QKV_Proj_13_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_13_1_0 [label="Attention_13_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_13_1_0 [label="Attention_Output_13_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_13_1_1 [label="QKV_Proj_13_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_13_1_1 [label="Attention_13_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_13_1_1 [label="Attention_Output_13_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_13_1_2 [label="QKV_Proj_13_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_13_1_2 [label="Attention_13_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_13_1_2 [label="Attention_Output_13_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_13_1_3 [label="QKV_Proj_13_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_13_1_3 [label="Attention_13_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_13_1_3 [label="Attention_Output_13_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	attn_allreduce_13_1 [label="Attention_AllReduce_13_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_13_2_0 [label="QKV_Proj_13_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_13_2_0 [label="Attention_13_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_13_2_0 [label="Attention_Output_13_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_13_2_1 [label="QKV_Proj_13_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_13_2_1 [label="Attention_13_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_13_2_1 [label="Attention_Output_13_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_13_2_2 [label="QKV_Proj_13_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_13_2_2 [label="Attention_13_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_13_2_2 [label="Attention_Output_13_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_13_2_3 [label="QKV_Proj_13_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_13_2_3 [label="Attention_13_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_13_2_3 [label="Attention_Output_13_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	attn_allreduce_13_2 [label="Attention_AllReduce_13_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_13_3_0 [label="QKV_Proj_13_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_13_3_0 [label="Attention_13_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_13_3_0 [label="Attention_Output_13_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_13_3_1 [label="QKV_Proj_13_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_13_3_1 [label="Attention_13_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_13_3_1 [label="Attention_Output_13_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_13_3_2 [label="QKV_Proj_13_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_13_3_2 [label="Attention_13_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_13_3_2 [label="Attention_Output_13_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_13_3_3 [label="QKV_Proj_13_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_13_3_3 [label="Attention_13_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_13_3_3 [label="Attention_Output_13_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	attn_allreduce_13_3 [label="Attention_AllReduce_13_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_13_4_0 [label="QKV_Proj_13_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_13_4_0 [label="Attention_13_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_13_4_0 [label="Attention_Output_13_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_13_4_1 [label="QKV_Proj_13_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_13_4_1 [label="Attention_13_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_13_4_1 [label="Attention_Output_13_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_13_4_2 [label="QKV_Proj_13_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_13_4_2 [label="Attention_13_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_13_4_2 [label="Attention_Output_13_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_13_4_3 [label="QKV_Proj_13_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_13_4_3 [label="Attention_13_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_13_4_3 [label="Attention_Output_13_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	attn_allreduce_13_4 [label="Attention_AllReduce_13_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_13_5_0 [label="QKV_Proj_13_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_13_5_0 [label="Attention_13_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_13_5_0 [label="Attention_Output_13_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_13_5_1 [label="QKV_Proj_13_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_13_5_1 [label="Attention_13_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_13_5_1 [label="Attention_Output_13_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_13_5_2 [label="QKV_Proj_13_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_13_5_2 [label="Attention_13_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_13_5_2 [label="Attention_Output_13_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_13_5_3 [label="QKV_Proj_13_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_13_5_3 [label="Attention_13_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_13_5_3 [label="Attention_Output_13_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	attn_allreduce_13_5 [label="Attention_AllReduce_13_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_13_6_0 [label="QKV_Proj_13_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_13_6_0 [label="Attention_13_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_13_6_0 [label="Attention_Output_13_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_13_6_1 [label="QKV_Proj_13_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_13_6_1 [label="Attention_13_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_13_6_1 [label="Attention_Output_13_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_13_6_2 [label="QKV_Proj_13_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_13_6_2 [label="Attention_13_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_13_6_2 [label="Attention_Output_13_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_13_6_3 [label="QKV_Proj_13_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_13_6_3 [label="Attention_13_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_13_6_3 [label="Attention_Output_13_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	attn_allreduce_13_6 [label="Attention_AllReduce_13_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_13_7_0 [label="QKV_Proj_13_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_13_7_0 [label="Attention_13_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_13_7_0 [label="Attention_Output_13_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_13_7_1 [label="QKV_Proj_13_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_13_7_1 [label="Attention_13_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_13_7_1 [label="Attention_Output_13_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_13_7_2 [label="QKV_Proj_13_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_13_7_2 [label="Attention_13_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_13_7_2 [label="Attention_Output_13_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_13_7_3 [label="QKV_Proj_13_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_13_7_3 [label="Attention_13_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_13_7_3 [label="Attention_Output_13_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	attn_allreduce_13_7 [label="Attention_AllReduce_13_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_13_8_0 [label="QKV_Proj_13_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_13_8_0 [label="Attention_13_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_13_8_0 [label="Attention_Output_13_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_13_8_1 [label="QKV_Proj_13_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_13_8_1 [label="Attention_13_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_13_8_1 [label="Attention_Output_13_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_13_8_2 [label="QKV_Proj_13_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_13_8_2 [label="Attention_13_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_13_8_2 [label="Attention_Output_13_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_13_8_3 [label="QKV_Proj_13_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_13_8_3 [label="Attention_13_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_13_8_3 [label="Attention_Output_13_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	attn_allreduce_13_8 [label="Attention_AllReduce_13_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_13_9_0 [label="QKV_Proj_13_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_13_9_0 [label="Attention_13_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_13_9_0 [label="Attention_Output_13_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_13_9_1 [label="QKV_Proj_13_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_13_9_1 [label="Attention_13_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_13_9_1 [label="Attention_Output_13_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_13_9_2 [label="QKV_Proj_13_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_13_9_2 [label="Attention_13_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_13_9_2 [label="Attention_Output_13_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_13_9_3 [label="QKV_Proj_13_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_13_9_3 [label="Attention_13_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_13_9_3 [label="Attention_Output_13_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	attn_allreduce_13_9 [label="Attention_AllReduce_13_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_13_10_0 [label="QKV_Proj_13_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_13_10_0 [label="Attention_13_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_13_10_0 [label="Attention_Output_13_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_13_10_1 [label="QKV_Proj_13_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_13_10_1 [label="Attention_13_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_13_10_1 [label="Attention_Output_13_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_13_10_2 [label="QKV_Proj_13_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_13_10_2 [label="Attention_13_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_13_10_2 [label="Attention_Output_13_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_13_10_3 [label="QKV_Proj_13_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_13_10_3 [label="Attention_13_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_13_10_3 [label="Attention_Output_13_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	attn_allreduce_13_10 [label="Attention_AllReduce_13_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_13_11_0 [label="QKV_Proj_13_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_13_11_0 [label="Attention_13_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_13_11_0 [label="Attention_Output_13_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_13_11_1 [label="QKV_Proj_13_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_13_11_1 [label="Attention_13_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_13_11_1 [label="Attention_Output_13_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_13_11_2 [label="QKV_Proj_13_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_13_11_2 [label="Attention_13_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_13_11_2 [label="Attention_Output_13_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_13_11_3 [label="QKV_Proj_13_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_13_11_3 [label="Attention_13_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_13_11_3 [label="Attention_Output_13_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	attn_allreduce_13_11 [label="Attention_AllReduce_13_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_13_12_0 [label="QKV_Proj_13_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_13_12_0 [label="Attention_13_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_13_12_0 [label="Attention_Output_13_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_13_12_1 [label="QKV_Proj_13_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_13_12_1 [label="Attention_13_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_13_12_1 [label="Attention_Output_13_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_13_12_2 [label="QKV_Proj_13_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_13_12_2 [label="Attention_13_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_13_12_2 [label="Attention_Output_13_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_13_12_3 [label="QKV_Proj_13_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_13_12_3 [label="Attention_13_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_13_12_3 [label="Attention_Output_13_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	attn_allreduce_13_12 [label="Attention_AllReduce_13_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_13_13_0 [label="QKV_Proj_13_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_13_13_0 [label="Attention_13_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_13_13_0 [label="Attention_Output_13_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_13_13_1 [label="QKV_Proj_13_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_13_13_1 [label="Attention_13_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_13_13_1 [label="Attention_Output_13_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_13_13_2 [label="QKV_Proj_13_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_13_13_2 [label="Attention_13_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_13_13_2 [label="Attention_Output_13_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_13_13_3 [label="QKV_Proj_13_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_13_13_3 [label="Attention_13_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_13_13_3 [label="Attention_Output_13_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	attn_allreduce_13_13 [label="Attention_AllReduce_13_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_13_14_0 [label="QKV_Proj_13_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_13_14_0 [label="Attention_13_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_13_14_0 [label="Attention_Output_13_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_13_14_1 [label="QKV_Proj_13_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_13_14_1 [label="Attention_13_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_13_14_1 [label="Attention_Output_13_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_13_14_2 [label="QKV_Proj_13_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_13_14_2 [label="Attention_13_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_13_14_2 [label="Attention_Output_13_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_13_14_3 [label="QKV_Proj_13_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_13_14_3 [label="Attention_13_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_13_14_3 [label="Attention_Output_13_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	attn_allreduce_13_14 [label="Attention_AllReduce_13_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_13_15_0 [label="QKV_Proj_13_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_13_15_0 [label="Attention_13_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_13_15_0 [label="Attention_Output_13_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_13_15_1 [label="QKV_Proj_13_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_13_15_1 [label="Attention_13_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_13_15_1 [label="Attention_Output_13_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_13_15_2 [label="QKV_Proj_13_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_13_15_2 [label="Attention_13_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_13_15_2 [label="Attention_Output_13_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_13_15_3 [label="QKV_Proj_13_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_13_15_3 [label="Attention_13_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_13_15_3 [label="Attention_Output_13_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	attn_allreduce_13_15 [label="Attention_AllReduce_13_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_13_0_0 [label="MLP_Linear1_13_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_13_0_0 [label="GELU_13_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_13_0_0 [label="MLP_Linear2_13_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_13_0_1 [label="MLP_Linear1_13_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_13_0_1 [label="GELU_13_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_13_0_1 [label="MLP_Linear2_13_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_13_0_2 [label="MLP_Linear1_13_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_13_0_2 [label="GELU_13_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_13_0_2 [label="MLP_Linear2_13_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_13_0_3 [label="MLP_Linear1_13_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_13_0_3 [label="GELU_13_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_13_0_3 [label="MLP_Linear2_13_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp_allreduce_13_0 [label="MLP_AllReduce_13_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_13_1_0 [label="MLP_Linear1_13_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_13_1_0 [label="GELU_13_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_13_1_0 [label="MLP_Linear2_13_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_13_1_1 [label="MLP_Linear1_13_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_13_1_1 [label="GELU_13_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_13_1_1 [label="MLP_Linear2_13_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_13_1_2 [label="MLP_Linear1_13_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_13_1_2 [label="GELU_13_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_13_1_2 [label="MLP_Linear2_13_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_13_1_3 [label="MLP_Linear1_13_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_13_1_3 [label="GELU_13_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_13_1_3 [label="MLP_Linear2_13_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp_allreduce_13_1 [label="MLP_AllReduce_13_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_13_2_0 [label="MLP_Linear1_13_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_13_2_0 [label="GELU_13_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_13_2_0 [label="MLP_Linear2_13_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_13_2_1 [label="MLP_Linear1_13_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_13_2_1 [label="GELU_13_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_13_2_1 [label="MLP_Linear2_13_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_13_2_2 [label="MLP_Linear1_13_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_13_2_2 [label="GELU_13_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_13_2_2 [label="MLP_Linear2_13_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_13_2_3 [label="MLP_Linear1_13_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_13_2_3 [label="GELU_13_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_13_2_3 [label="MLP_Linear2_13_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp_allreduce_13_2 [label="MLP_AllReduce_13_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_13_3_0 [label="MLP_Linear1_13_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_13_3_0 [label="GELU_13_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_13_3_0 [label="MLP_Linear2_13_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_13_3_1 [label="MLP_Linear1_13_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_13_3_1 [label="GELU_13_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_13_3_1 [label="MLP_Linear2_13_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_13_3_2 [label="MLP_Linear1_13_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_13_3_2 [label="GELU_13_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_13_3_2 [label="MLP_Linear2_13_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_13_3_3 [label="MLP_Linear1_13_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_13_3_3 [label="GELU_13_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_13_3_3 [label="MLP_Linear2_13_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp_allreduce_13_3 [label="MLP_AllReduce_13_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_13_4_0 [label="MLP_Linear1_13_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_13_4_0 [label="GELU_13_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_13_4_0 [label="MLP_Linear2_13_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_13_4_1 [label="MLP_Linear1_13_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_13_4_1 [label="GELU_13_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_13_4_1 [label="MLP_Linear2_13_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_13_4_2 [label="MLP_Linear1_13_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_13_4_2 [label="GELU_13_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_13_4_2 [label="MLP_Linear2_13_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_13_4_3 [label="MLP_Linear1_13_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_13_4_3 [label="GELU_13_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_13_4_3 [label="MLP_Linear2_13_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp_allreduce_13_4 [label="MLP_AllReduce_13_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_13_5_0 [label="MLP_Linear1_13_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_13_5_0 [label="GELU_13_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_13_5_0 [label="MLP_Linear2_13_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_13_5_1 [label="MLP_Linear1_13_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_13_5_1 [label="GELU_13_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_13_5_1 [label="MLP_Linear2_13_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_13_5_2 [label="MLP_Linear1_13_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_13_5_2 [label="GELU_13_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_13_5_2 [label="MLP_Linear2_13_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_13_5_3 [label="MLP_Linear1_13_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_13_5_3 [label="GELU_13_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_13_5_3 [label="MLP_Linear2_13_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp_allreduce_13_5 [label="MLP_AllReduce_13_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_13_6_0 [label="MLP_Linear1_13_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_13_6_0 [label="GELU_13_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_13_6_0 [label="MLP_Linear2_13_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_13_6_1 [label="MLP_Linear1_13_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_13_6_1 [label="GELU_13_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_13_6_1 [label="MLP_Linear2_13_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_13_6_2 [label="MLP_Linear1_13_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_13_6_2 [label="GELU_13_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_13_6_2 [label="MLP_Linear2_13_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_13_6_3 [label="MLP_Linear1_13_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_13_6_3 [label="GELU_13_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_13_6_3 [label="MLP_Linear2_13_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp_allreduce_13_6 [label="MLP_AllReduce_13_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_13_7_0 [label="MLP_Linear1_13_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_13_7_0 [label="GELU_13_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_13_7_0 [label="MLP_Linear2_13_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_13_7_1 [label="MLP_Linear1_13_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_13_7_1 [label="GELU_13_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_13_7_1 [label="MLP_Linear2_13_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_13_7_2 [label="MLP_Linear1_13_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_13_7_2 [label="GELU_13_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_13_7_2 [label="MLP_Linear2_13_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_13_7_3 [label="MLP_Linear1_13_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_13_7_3 [label="GELU_13_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_13_7_3 [label="MLP_Linear2_13_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp_allreduce_13_7 [label="MLP_AllReduce_13_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_13_8_0 [label="MLP_Linear1_13_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_13_8_0 [label="GELU_13_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_13_8_0 [label="MLP_Linear2_13_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_13_8_1 [label="MLP_Linear1_13_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_13_8_1 [label="GELU_13_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_13_8_1 [label="MLP_Linear2_13_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_13_8_2 [label="MLP_Linear1_13_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_13_8_2 [label="GELU_13_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_13_8_2 [label="MLP_Linear2_13_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_13_8_3 [label="MLP_Linear1_13_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_13_8_3 [label="GELU_13_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_13_8_3 [label="MLP_Linear2_13_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp_allreduce_13_8 [label="MLP_AllReduce_13_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_13_9_0 [label="MLP_Linear1_13_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_13_9_0 [label="GELU_13_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_13_9_0 [label="MLP_Linear2_13_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_13_9_1 [label="MLP_Linear1_13_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_13_9_1 [label="GELU_13_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_13_9_1 [label="MLP_Linear2_13_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_13_9_2 [label="MLP_Linear1_13_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_13_9_2 [label="GELU_13_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_13_9_2 [label="MLP_Linear2_13_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_13_9_3 [label="MLP_Linear1_13_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_13_9_3 [label="GELU_13_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_13_9_3 [label="MLP_Linear2_13_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp_allreduce_13_9 [label="MLP_AllReduce_13_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_13_10_0 [label="MLP_Linear1_13_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_13_10_0 [label="GELU_13_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_13_10_0 [label="MLP_Linear2_13_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_13_10_1 [label="MLP_Linear1_13_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_13_10_1 [label="GELU_13_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_13_10_1 [label="MLP_Linear2_13_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_13_10_2 [label="MLP_Linear1_13_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_13_10_2 [label="GELU_13_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_13_10_2 [label="MLP_Linear2_13_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_13_10_3 [label="MLP_Linear1_13_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_13_10_3 [label="GELU_13_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_13_10_3 [label="MLP_Linear2_13_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp_allreduce_13_10 [label="MLP_AllReduce_13_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_13_11_0 [label="MLP_Linear1_13_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_13_11_0 [label="GELU_13_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_13_11_0 [label="MLP_Linear2_13_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_13_11_1 [label="MLP_Linear1_13_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_13_11_1 [label="GELU_13_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_13_11_1 [label="MLP_Linear2_13_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_13_11_2 [label="MLP_Linear1_13_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_13_11_2 [label="GELU_13_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_13_11_2 [label="MLP_Linear2_13_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_13_11_3 [label="MLP_Linear1_13_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_13_11_3 [label="GELU_13_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_13_11_3 [label="MLP_Linear2_13_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp_allreduce_13_11 [label="MLP_AllReduce_13_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_13_12_0 [label="MLP_Linear1_13_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_13_12_0 [label="GELU_13_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_13_12_0 [label="MLP_Linear2_13_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_13_12_1 [label="MLP_Linear1_13_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_13_12_1 [label="GELU_13_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_13_12_1 [label="MLP_Linear2_13_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_13_12_2 [label="MLP_Linear1_13_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_13_12_2 [label="GELU_13_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_13_12_2 [label="MLP_Linear2_13_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_13_12_3 [label="MLP_Linear1_13_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_13_12_3 [label="GELU_13_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_13_12_3 [label="MLP_Linear2_13_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp_allreduce_13_12 [label="MLP_AllReduce_13_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_13_13_0 [label="MLP_Linear1_13_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_13_13_0 [label="GELU_13_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_13_13_0 [label="MLP_Linear2_13_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_13_13_1 [label="MLP_Linear1_13_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_13_13_1 [label="GELU_13_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_13_13_1 [label="MLP_Linear2_13_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_13_13_2 [label="MLP_Linear1_13_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_13_13_2 [label="GELU_13_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_13_13_2 [label="MLP_Linear2_13_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_13_13_3 [label="MLP_Linear1_13_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_13_13_3 [label="GELU_13_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_13_13_3 [label="MLP_Linear2_13_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp_allreduce_13_13 [label="MLP_AllReduce_13_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_13_14_0 [label="MLP_Linear1_13_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_13_14_0 [label="GELU_13_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_13_14_0 [label="MLP_Linear2_13_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_13_14_1 [label="MLP_Linear1_13_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_13_14_1 [label="GELU_13_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_13_14_1 [label="MLP_Linear2_13_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_13_14_2 [label="MLP_Linear1_13_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_13_14_2 [label="GELU_13_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_13_14_2 [label="MLP_Linear2_13_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_13_14_3 [label="MLP_Linear1_13_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_13_14_3 [label="GELU_13_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_13_14_3 [label="MLP_Linear2_13_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp_allreduce_13_14 [label="MLP_AllReduce_13_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_13_15_0 [label="MLP_Linear1_13_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_13_15_0 [label="GELU_13_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_13_15_0 [label="MLP_Linear2_13_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_13_15_1 [label="MLP_Linear1_13_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_13_15_1 [label="GELU_13_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_13_15_1 [label="MLP_Linear2_13_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_13_15_2 [label="MLP_Linear1_13_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_13_15_2 [label="GELU_13_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_13_15_2 [label="MLP_Linear2_13_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_13_15_3 [label="MLP_Linear1_13_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_13_15_3 [label="GELU_13_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_13_15_3 [label="MLP_Linear2_13_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp_allreduce_13_15 [label="MLP_AllReduce_13_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	expert_route_13_0 [label="Expert_Route_13_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_13_1 [label="Expert_Route_13_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_13_2 [label="Expert_Route_13_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_13_3 [label="Expert_Route_13_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_13_4 [label="Expert_Route_13_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_13_5 [label="Expert_Route_13_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_13_6 [label="Expert_Route_13_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_13_7 [label="Expert_Route_13_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_13_8 [label="Expert_Route_13_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_13_9 [label="Expert_Route_13_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_13_10 [label="Expert_Route_13_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_13_11 [label="Expert_Route_13_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_13_12 [label="Expert_Route_13_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_13_13 [label="Expert_Route_13_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_13_14 [label="Expert_Route_13_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_13_15 [label="Expert_Route_13_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	qkv_14_0_0 [label="QKV_Proj_14_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_14_0_0 [label="Attention_14_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_14_0_0 [label="Attention_Output_14_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_14_0_1 [label="QKV_Proj_14_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_14_0_1 [label="Attention_14_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_14_0_1 [label="Attention_Output_14_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_14_0_2 [label="QKV_Proj_14_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_14_0_2 [label="Attention_14_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_14_0_2 [label="Attention_Output_14_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_14_0_3 [label="QKV_Proj_14_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_14_0_3 [label="Attention_14_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_14_0_3 [label="Attention_Output_14_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	attn_allreduce_14_0 [label="Attention_AllReduce_14_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_14_1_0 [label="QKV_Proj_14_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_14_1_0 [label="Attention_14_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_14_1_0 [label="Attention_Output_14_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_14_1_1 [label="QKV_Proj_14_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_14_1_1 [label="Attention_14_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_14_1_1 [label="Attention_Output_14_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_14_1_2 [label="QKV_Proj_14_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_14_1_2 [label="Attention_14_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_14_1_2 [label="Attention_Output_14_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_14_1_3 [label="QKV_Proj_14_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_14_1_3 [label="Attention_14_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_14_1_3 [label="Attention_Output_14_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	attn_allreduce_14_1 [label="Attention_AllReduce_14_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_14_2_0 [label="QKV_Proj_14_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_14_2_0 [label="Attention_14_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_14_2_0 [label="Attention_Output_14_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_14_2_1 [label="QKV_Proj_14_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_14_2_1 [label="Attention_14_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_14_2_1 [label="Attention_Output_14_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_14_2_2 [label="QKV_Proj_14_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_14_2_2 [label="Attention_14_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_14_2_2 [label="Attention_Output_14_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_14_2_3 [label="QKV_Proj_14_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_14_2_3 [label="Attention_14_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_14_2_3 [label="Attention_Output_14_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	attn_allreduce_14_2 [label="Attention_AllReduce_14_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_14_3_0 [label="QKV_Proj_14_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_14_3_0 [label="Attention_14_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_14_3_0 [label="Attention_Output_14_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_14_3_1 [label="QKV_Proj_14_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_14_3_1 [label="Attention_14_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_14_3_1 [label="Attention_Output_14_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_14_3_2 [label="QKV_Proj_14_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_14_3_2 [label="Attention_14_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_14_3_2 [label="Attention_Output_14_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_14_3_3 [label="QKV_Proj_14_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_14_3_3 [label="Attention_14_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_14_3_3 [label="Attention_Output_14_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	attn_allreduce_14_3 [label="Attention_AllReduce_14_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_14_4_0 [label="QKV_Proj_14_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_14_4_0 [label="Attention_14_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_14_4_0 [label="Attention_Output_14_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_14_4_1 [label="QKV_Proj_14_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_14_4_1 [label="Attention_14_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_14_4_1 [label="Attention_Output_14_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_14_4_2 [label="QKV_Proj_14_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_14_4_2 [label="Attention_14_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_14_4_2 [label="Attention_Output_14_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_14_4_3 [label="QKV_Proj_14_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_14_4_3 [label="Attention_14_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_14_4_3 [label="Attention_Output_14_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	attn_allreduce_14_4 [label="Attention_AllReduce_14_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_14_5_0 [label="QKV_Proj_14_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_14_5_0 [label="Attention_14_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_14_5_0 [label="Attention_Output_14_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_14_5_1 [label="QKV_Proj_14_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_14_5_1 [label="Attention_14_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_14_5_1 [label="Attention_Output_14_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_14_5_2 [label="QKV_Proj_14_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_14_5_2 [label="Attention_14_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_14_5_2 [label="Attention_Output_14_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_14_5_3 [label="QKV_Proj_14_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_14_5_3 [label="Attention_14_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_14_5_3 [label="Attention_Output_14_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	attn_allreduce_14_5 [label="Attention_AllReduce_14_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_14_6_0 [label="QKV_Proj_14_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_14_6_0 [label="Attention_14_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_14_6_0 [label="Attention_Output_14_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_14_6_1 [label="QKV_Proj_14_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_14_6_1 [label="Attention_14_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_14_6_1 [label="Attention_Output_14_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_14_6_2 [label="QKV_Proj_14_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_14_6_2 [label="Attention_14_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_14_6_2 [label="Attention_Output_14_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_14_6_3 [label="QKV_Proj_14_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_14_6_3 [label="Attention_14_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_14_6_3 [label="Attention_Output_14_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	attn_allreduce_14_6 [label="Attention_AllReduce_14_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_14_7_0 [label="QKV_Proj_14_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_14_7_0 [label="Attention_14_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_14_7_0 [label="Attention_Output_14_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_14_7_1 [label="QKV_Proj_14_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_14_7_1 [label="Attention_14_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_14_7_1 [label="Attention_Output_14_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_14_7_2 [label="QKV_Proj_14_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_14_7_2 [label="Attention_14_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_14_7_2 [label="Attention_Output_14_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_14_7_3 [label="QKV_Proj_14_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_14_7_3 [label="Attention_14_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_14_7_3 [label="Attention_Output_14_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	attn_allreduce_14_7 [label="Attention_AllReduce_14_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_14_8_0 [label="QKV_Proj_14_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_14_8_0 [label="Attention_14_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_14_8_0 [label="Attention_Output_14_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_14_8_1 [label="QKV_Proj_14_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_14_8_1 [label="Attention_14_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_14_8_1 [label="Attention_Output_14_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_14_8_2 [label="QKV_Proj_14_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_14_8_2 [label="Attention_14_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_14_8_2 [label="Attention_Output_14_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_14_8_3 [label="QKV_Proj_14_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_14_8_3 [label="Attention_14_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_14_8_3 [label="Attention_Output_14_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	attn_allreduce_14_8 [label="Attention_AllReduce_14_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_14_9_0 [label="QKV_Proj_14_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_14_9_0 [label="Attention_14_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_14_9_0 [label="Attention_Output_14_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_14_9_1 [label="QKV_Proj_14_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_14_9_1 [label="Attention_14_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_14_9_1 [label="Attention_Output_14_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_14_9_2 [label="QKV_Proj_14_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_14_9_2 [label="Attention_14_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_14_9_2 [label="Attention_Output_14_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_14_9_3 [label="QKV_Proj_14_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_14_9_3 [label="Attention_14_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_14_9_3 [label="Attention_Output_14_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	attn_allreduce_14_9 [label="Attention_AllReduce_14_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_14_10_0 [label="QKV_Proj_14_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_14_10_0 [label="Attention_14_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_14_10_0 [label="Attention_Output_14_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_14_10_1 [label="QKV_Proj_14_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_14_10_1 [label="Attention_14_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_14_10_1 [label="Attention_Output_14_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_14_10_2 [label="QKV_Proj_14_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_14_10_2 [label="Attention_14_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_14_10_2 [label="Attention_Output_14_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_14_10_3 [label="QKV_Proj_14_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_14_10_3 [label="Attention_14_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_14_10_3 [label="Attention_Output_14_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	attn_allreduce_14_10 [label="Attention_AllReduce_14_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_14_11_0 [label="QKV_Proj_14_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_14_11_0 [label="Attention_14_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_14_11_0 [label="Attention_Output_14_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_14_11_1 [label="QKV_Proj_14_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_14_11_1 [label="Attention_14_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_14_11_1 [label="Attention_Output_14_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_14_11_2 [label="QKV_Proj_14_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_14_11_2 [label="Attention_14_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_14_11_2 [label="Attention_Output_14_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_14_11_3 [label="QKV_Proj_14_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_14_11_3 [label="Attention_14_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_14_11_3 [label="Attention_Output_14_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	attn_allreduce_14_11 [label="Attention_AllReduce_14_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_14_12_0 [label="QKV_Proj_14_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_14_12_0 [label="Attention_14_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_14_12_0 [label="Attention_Output_14_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_14_12_1 [label="QKV_Proj_14_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_14_12_1 [label="Attention_14_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_14_12_1 [label="Attention_Output_14_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_14_12_2 [label="QKV_Proj_14_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_14_12_2 [label="Attention_14_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_14_12_2 [label="Attention_Output_14_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_14_12_3 [label="QKV_Proj_14_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_14_12_3 [label="Attention_14_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_14_12_3 [label="Attention_Output_14_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	attn_allreduce_14_12 [label="Attention_AllReduce_14_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_14_13_0 [label="QKV_Proj_14_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_14_13_0 [label="Attention_14_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_14_13_0 [label="Attention_Output_14_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_14_13_1 [label="QKV_Proj_14_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_14_13_1 [label="Attention_14_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_14_13_1 [label="Attention_Output_14_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_14_13_2 [label="QKV_Proj_14_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_14_13_2 [label="Attention_14_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_14_13_2 [label="Attention_Output_14_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_14_13_3 [label="QKV_Proj_14_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_14_13_3 [label="Attention_14_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_14_13_3 [label="Attention_Output_14_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	attn_allreduce_14_13 [label="Attention_AllReduce_14_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_14_14_0 [label="QKV_Proj_14_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_14_14_0 [label="Attention_14_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_14_14_0 [label="Attention_Output_14_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_14_14_1 [label="QKV_Proj_14_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_14_14_1 [label="Attention_14_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_14_14_1 [label="Attention_Output_14_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_14_14_2 [label="QKV_Proj_14_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_14_14_2 [label="Attention_14_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_14_14_2 [label="Attention_Output_14_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_14_14_3 [label="QKV_Proj_14_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_14_14_3 [label="Attention_14_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_14_14_3 [label="Attention_Output_14_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	attn_allreduce_14_14 [label="Attention_AllReduce_14_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_14_15_0 [label="QKV_Proj_14_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_14_15_0 [label="Attention_14_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_14_15_0 [label="Attention_Output_14_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_14_15_1 [label="QKV_Proj_14_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_14_15_1 [label="Attention_14_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_14_15_1 [label="Attention_Output_14_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_14_15_2 [label="QKV_Proj_14_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_14_15_2 [label="Attention_14_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_14_15_2 [label="Attention_Output_14_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_14_15_3 [label="QKV_Proj_14_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_14_15_3 [label="Attention_14_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_14_15_3 [label="Attention_Output_14_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	attn_allreduce_14_15 [label="Attention_AllReduce_14_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_14_0_0 [label="MLP_Linear1_14_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_14_0_0 [label="GELU_14_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_14_0_0 [label="MLP_Linear2_14_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_14_0_1 [label="MLP_Linear1_14_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_14_0_1 [label="GELU_14_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_14_0_1 [label="MLP_Linear2_14_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_14_0_2 [label="MLP_Linear1_14_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_14_0_2 [label="GELU_14_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_14_0_2 [label="MLP_Linear2_14_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_14_0_3 [label="MLP_Linear1_14_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_14_0_3 [label="GELU_14_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_14_0_3 [label="MLP_Linear2_14_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp_allreduce_14_0 [label="MLP_AllReduce_14_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_14_1_0 [label="MLP_Linear1_14_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_14_1_0 [label="GELU_14_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_14_1_0 [label="MLP_Linear2_14_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_14_1_1 [label="MLP_Linear1_14_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_14_1_1 [label="GELU_14_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_14_1_1 [label="MLP_Linear2_14_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_14_1_2 [label="MLP_Linear1_14_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_14_1_2 [label="GELU_14_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_14_1_2 [label="MLP_Linear2_14_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_14_1_3 [label="MLP_Linear1_14_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_14_1_3 [label="GELU_14_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_14_1_3 [label="MLP_Linear2_14_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp_allreduce_14_1 [label="MLP_AllReduce_14_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_14_2_0 [label="MLP_Linear1_14_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_14_2_0 [label="GELU_14_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_14_2_0 [label="MLP_Linear2_14_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_14_2_1 [label="MLP_Linear1_14_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_14_2_1 [label="GELU_14_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_14_2_1 [label="MLP_Linear2_14_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_14_2_2 [label="MLP_Linear1_14_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_14_2_2 [label="GELU_14_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_14_2_2 [label="MLP_Linear2_14_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_14_2_3 [label="MLP_Linear1_14_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_14_2_3 [label="GELU_14_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_14_2_3 [label="MLP_Linear2_14_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp_allreduce_14_2 [label="MLP_AllReduce_14_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_14_3_0 [label="MLP_Linear1_14_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_14_3_0 [label="GELU_14_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_14_3_0 [label="MLP_Linear2_14_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_14_3_1 [label="MLP_Linear1_14_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_14_3_1 [label="GELU_14_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_14_3_1 [label="MLP_Linear2_14_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_14_3_2 [label="MLP_Linear1_14_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_14_3_2 [label="GELU_14_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_14_3_2 [label="MLP_Linear2_14_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_14_3_3 [label="MLP_Linear1_14_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_14_3_3 [label="GELU_14_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_14_3_3 [label="MLP_Linear2_14_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp_allreduce_14_3 [label="MLP_AllReduce_14_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_14_4_0 [label="MLP_Linear1_14_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_14_4_0 [label="GELU_14_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_14_4_0 [label="MLP_Linear2_14_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_14_4_1 [label="MLP_Linear1_14_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_14_4_1 [label="GELU_14_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_14_4_1 [label="MLP_Linear2_14_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_14_4_2 [label="MLP_Linear1_14_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_14_4_2 [label="GELU_14_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_14_4_2 [label="MLP_Linear2_14_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_14_4_3 [label="MLP_Linear1_14_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_14_4_3 [label="GELU_14_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_14_4_3 [label="MLP_Linear2_14_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp_allreduce_14_4 [label="MLP_AllReduce_14_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_14_5_0 [label="MLP_Linear1_14_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_14_5_0 [label="GELU_14_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_14_5_0 [label="MLP_Linear2_14_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_14_5_1 [label="MLP_Linear1_14_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_14_5_1 [label="GELU_14_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_14_5_1 [label="MLP_Linear2_14_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_14_5_2 [label="MLP_Linear1_14_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_14_5_2 [label="GELU_14_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_14_5_2 [label="MLP_Linear2_14_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_14_5_3 [label="MLP_Linear1_14_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_14_5_3 [label="GELU_14_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_14_5_3 [label="MLP_Linear2_14_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp_allreduce_14_5 [label="MLP_AllReduce_14_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_14_6_0 [label="MLP_Linear1_14_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_14_6_0 [label="GELU_14_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_14_6_0 [label="MLP_Linear2_14_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_14_6_1 [label="MLP_Linear1_14_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_14_6_1 [label="GELU_14_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_14_6_1 [label="MLP_Linear2_14_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_14_6_2 [label="MLP_Linear1_14_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_14_6_2 [label="GELU_14_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_14_6_2 [label="MLP_Linear2_14_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_14_6_3 [label="MLP_Linear1_14_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_14_6_3 [label="GELU_14_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_14_6_3 [label="MLP_Linear2_14_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp_allreduce_14_6 [label="MLP_AllReduce_14_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_14_7_0 [label="MLP_Linear1_14_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_14_7_0 [label="GELU_14_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_14_7_0 [label="MLP_Linear2_14_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_14_7_1 [label="MLP_Linear1_14_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_14_7_1 [label="GELU_14_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_14_7_1 [label="MLP_Linear2_14_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_14_7_2 [label="MLP_Linear1_14_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_14_7_2 [label="GELU_14_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_14_7_2 [label="MLP_Linear2_14_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_14_7_3 [label="MLP_Linear1_14_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_14_7_3 [label="GELU_14_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_14_7_3 [label="MLP_Linear2_14_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp_allreduce_14_7 [label="MLP_AllReduce_14_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_14_8_0 [label="MLP_Linear1_14_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_14_8_0 [label="GELU_14_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_14_8_0 [label="MLP_Linear2_14_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_14_8_1 [label="MLP_Linear1_14_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_14_8_1 [label="GELU_14_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_14_8_1 [label="MLP_Linear2_14_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_14_8_2 [label="MLP_Linear1_14_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_14_8_2 [label="GELU_14_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_14_8_2 [label="MLP_Linear2_14_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_14_8_3 [label="MLP_Linear1_14_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_14_8_3 [label="GELU_14_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_14_8_3 [label="MLP_Linear2_14_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp_allreduce_14_8 [label="MLP_AllReduce_14_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_14_9_0 [label="MLP_Linear1_14_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_14_9_0 [label="GELU_14_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_14_9_0 [label="MLP_Linear2_14_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_14_9_1 [label="MLP_Linear1_14_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_14_9_1 [label="GELU_14_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_14_9_1 [label="MLP_Linear2_14_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_14_9_2 [label="MLP_Linear1_14_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_14_9_2 [label="GELU_14_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_14_9_2 [label="MLP_Linear2_14_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_14_9_3 [label="MLP_Linear1_14_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_14_9_3 [label="GELU_14_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_14_9_3 [label="MLP_Linear2_14_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp_allreduce_14_9 [label="MLP_AllReduce_14_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_14_10_0 [label="MLP_Linear1_14_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_14_10_0 [label="GELU_14_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_14_10_0 [label="MLP_Linear2_14_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_14_10_1 [label="MLP_Linear1_14_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_14_10_1 [label="GELU_14_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_14_10_1 [label="MLP_Linear2_14_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_14_10_2 [label="MLP_Linear1_14_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_14_10_2 [label="GELU_14_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_14_10_2 [label="MLP_Linear2_14_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_14_10_3 [label="MLP_Linear1_14_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_14_10_3 [label="GELU_14_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_14_10_3 [label="MLP_Linear2_14_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp_allreduce_14_10 [label="MLP_AllReduce_14_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_14_11_0 [label="MLP_Linear1_14_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_14_11_0 [label="GELU_14_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_14_11_0 [label="MLP_Linear2_14_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_14_11_1 [label="MLP_Linear1_14_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_14_11_1 [label="GELU_14_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_14_11_1 [label="MLP_Linear2_14_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_14_11_2 [label="MLP_Linear1_14_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_14_11_2 [label="GELU_14_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_14_11_2 [label="MLP_Linear2_14_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_14_11_3 [label="MLP_Linear1_14_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_14_11_3 [label="GELU_14_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_14_11_3 [label="MLP_Linear2_14_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp_allreduce_14_11 [label="MLP_AllReduce_14_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_14_12_0 [label="MLP_Linear1_14_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_14_12_0 [label="GELU_14_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_14_12_0 [label="MLP_Linear2_14_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_14_12_1 [label="MLP_Linear1_14_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_14_12_1 [label="GELU_14_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_14_12_1 [label="MLP_Linear2_14_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_14_12_2 [label="MLP_Linear1_14_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_14_12_2 [label="GELU_14_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_14_12_2 [label="MLP_Linear2_14_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_14_12_3 [label="MLP_Linear1_14_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_14_12_3 [label="GELU_14_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_14_12_3 [label="MLP_Linear2_14_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp_allreduce_14_12 [label="MLP_AllReduce_14_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_14_13_0 [label="MLP_Linear1_14_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_14_13_0 [label="GELU_14_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_14_13_0 [label="MLP_Linear2_14_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_14_13_1 [label="MLP_Linear1_14_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_14_13_1 [label="GELU_14_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_14_13_1 [label="MLP_Linear2_14_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_14_13_2 [label="MLP_Linear1_14_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_14_13_2 [label="GELU_14_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_14_13_2 [label="MLP_Linear2_14_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_14_13_3 [label="MLP_Linear1_14_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_14_13_3 [label="GELU_14_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_14_13_3 [label="MLP_Linear2_14_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp_allreduce_14_13 [label="MLP_AllReduce_14_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_14_14_0 [label="MLP_Linear1_14_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_14_14_0 [label="GELU_14_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_14_14_0 [label="MLP_Linear2_14_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_14_14_1 [label="MLP_Linear1_14_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_14_14_1 [label="GELU_14_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_14_14_1 [label="MLP_Linear2_14_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_14_14_2 [label="MLP_Linear1_14_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_14_14_2 [label="GELU_14_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_14_14_2 [label="MLP_Linear2_14_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_14_14_3 [label="MLP_Linear1_14_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_14_14_3 [label="GELU_14_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_14_14_3 [label="MLP_Linear2_14_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp_allreduce_14_14 [label="MLP_AllReduce_14_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_14_15_0 [label="MLP_Linear1_14_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_14_15_0 [label="GELU_14_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_14_15_0 [label="MLP_Linear2_14_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_14_15_1 [label="MLP_Linear1_14_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_14_15_1 [label="GELU_14_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_14_15_1 [label="MLP_Linear2_14_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_14_15_2 [label="MLP_Linear1_14_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_14_15_2 [label="GELU_14_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_14_15_2 [label="MLP_Linear2_14_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_14_15_3 [label="MLP_Linear1_14_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_14_15_3 [label="GELU_14_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_14_15_3 [label="MLP_Linear2_14_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp_allreduce_14_15 [label="MLP_AllReduce_14_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	expert_route_14_0 [label="Expert_Route_14_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_14_1 [label="Expert_Route_14_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_14_2 [label="Expert_Route_14_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_14_3 [label="Expert_Route_14_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_14_4 [label="Expert_Route_14_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_14_5 [label="Expert_Route_14_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_14_6 [label="Expert_Route_14_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_14_7 [label="Expert_Route_14_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_14_8 [label="Expert_Route_14_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_14_9 [label="Expert_Route_14_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_14_10 [label="Expert_Route_14_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_14_11 [label="Expert_Route_14_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_14_12 [label="Expert_Route_14_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_14_13 [label="Expert_Route_14_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_14_14 [label="Expert_Route_14_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_14_15 [label="Expert_Route_14_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	qkv_15_0_0 [label="QKV_Proj_15_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_15_0_0 [label="Attention_15_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_15_0_0 [label="Attention_Output_15_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_15_0_1 [label="QKV_Proj_15_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_15_0_1 [label="Attention_15_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_15_0_1 [label="Attention_Output_15_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_15_0_2 [label="QKV_Proj_15_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_15_0_2 [label="Attention_15_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_15_0_2 [label="Attention_Output_15_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	qkv_15_0_3 [label="QKV_Proj_15_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcoral]
	attn_15_0_3 [label="Attention_15_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcoral]
	attn_out_15_0_3 [label="Attention_Output_15_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	attn_allreduce_15_0 [label="Attention_AllReduce_15_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_15_1_0 [label="QKV_Proj_15_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_15_1_0 [label="Attention_15_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_15_1_0 [label="Attention_Output_15_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_15_1_1 [label="QKV_Proj_15_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_15_1_1 [label="Attention_15_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_15_1_1 [label="Attention_Output_15_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_15_1_2 [label="QKV_Proj_15_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_15_1_2 [label="Attention_15_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_15_1_2 [label="Attention_Output_15_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	qkv_15_1_3 [label="QKV_Proj_15_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgreen]
	attn_15_1_3 [label="Attention_15_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgreen]
	attn_out_15_1_3 [label="Attention_Output_15_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	attn_allreduce_15_1 [label="Attention_AllReduce_15_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_15_2_0 [label="QKV_Proj_15_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_15_2_0 [label="Attention_15_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_15_2_0 [label="Attention_Output_15_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_15_2_1 [label="QKV_Proj_15_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_15_2_1 [label="Attention_15_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_15_2_1 [label="Attention_Output_15_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_15_2_2 [label="QKV_Proj_15_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_15_2_2 [label="Attention_15_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_15_2_2 [label="Attention_Output_15_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	qkv_15_2_3 [label="QKV_Proj_15_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightblue]
	attn_15_2_3 [label="Attention_15_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightblue]
	attn_out_15_2_3 [label="Attention_Output_15_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	attn_allreduce_15_2 [label="Attention_AllReduce_15_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_15_3_0 [label="QKV_Proj_15_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_15_3_0 [label="Attention_15_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_15_3_0 [label="Attention_Output_15_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_15_3_1 [label="QKV_Proj_15_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_15_3_1 [label="Attention_15_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_15_3_1 [label="Attention_Output_15_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_15_3_2 [label="QKV_Proj_15_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_15_3_2 [label="Attention_15_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_15_3_2 [label="Attention_Output_15_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	qkv_15_3_3 [label="QKV_Proj_15_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightyellow]
	attn_15_3_3 [label="Attention_15_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightyellow]
	attn_out_15_3_3 [label="Attention_Output_15_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	attn_allreduce_15_3 [label="Attention_AllReduce_15_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_15_4_0 [label="QKV_Proj_15_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_15_4_0 [label="Attention_15_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_15_4_0 [label="Attention_Output_15_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_15_4_1 [label="QKV_Proj_15_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_15_4_1 [label="Attention_15_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_15_4_1 [label="Attention_Output_15_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_15_4_2 [label="QKV_Proj_15_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_15_4_2 [label="Attention_15_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_15_4_2 [label="Attention_Output_15_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	qkv_15_4_3 [label="QKV_Proj_15_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightpink]
	attn_15_4_3 [label="Attention_15_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightpink]
	attn_out_15_4_3 [label="Attention_Output_15_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	attn_allreduce_15_4 [label="Attention_AllReduce_15_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_15_5_0 [label="QKV_Proj_15_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_15_5_0 [label="Attention_15_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_15_5_0 [label="Attention_Output_15_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_15_5_1 [label="QKV_Proj_15_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_15_5_1 [label="Attention_15_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_15_5_1 [label="Attention_Output_15_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_15_5_2 [label="QKV_Proj_15_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_15_5_2 [label="Attention_15_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_15_5_2 [label="Attention_Output_15_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	qkv_15_5_3 [label="QKV_Proj_15_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgray]
	attn_15_5_3 [label="Attention_15_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgray]
	attn_out_15_5_3 [label="Attention_Output_15_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	attn_allreduce_15_5 [label="Attention_AllReduce_15_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_15_6_0 [label="QKV_Proj_15_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_15_6_0 [label="Attention_15_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_15_6_0 [label="Attention_Output_15_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_15_6_1 [label="QKV_Proj_15_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_15_6_1 [label="Attention_15_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_15_6_1 [label="Attention_Output_15_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_15_6_2 [label="QKV_Proj_15_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_15_6_2 [label="Attention_15_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_15_6_2 [label="Attention_Output_15_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	qkv_15_6_3 [label="QKV_Proj_15_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsalmon]
	attn_15_6_3 [label="Attention_15_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsalmon]
	attn_out_15_6_3 [label="Attention_Output_15_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	attn_allreduce_15_6 [label="Attention_AllReduce_15_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_15_7_0 [label="QKV_Proj_15_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_15_7_0 [label="Attention_15_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_15_7_0 [label="Attention_Output_15_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_15_7_1 [label="QKV_Proj_15_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_15_7_1 [label="Attention_15_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_15_7_1 [label="Attention_Output_15_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_15_7_2 [label="QKV_Proj_15_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_15_7_2 [label="Attention_15_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_15_7_2 [label="Attention_Output_15_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	qkv_15_7_3 [label="QKV_Proj_15_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightseagreen]
	attn_15_7_3 [label="Attention_15_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightseagreen]
	attn_out_15_7_3 [label="Attention_Output_15_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	attn_allreduce_15_7 [label="Attention_AllReduce_15_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_15_8_0 [label="QKV_Proj_15_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_15_8_0 [label="Attention_15_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_15_8_0 [label="Attention_Output_15_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_15_8_1 [label="QKV_Proj_15_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_15_8_1 [label="Attention_15_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_15_8_1 [label="Attention_Output_15_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_15_8_2 [label="QKV_Proj_15_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_15_8_2 [label="Attention_15_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_15_8_2 [label="Attention_Output_15_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	qkv_15_8_3 [label="QKV_Proj_15_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightskyblue]
	attn_15_8_3 [label="Attention_15_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightskyblue]
	attn_out_15_8_3 [label="Attention_Output_15_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	attn_allreduce_15_8 [label="Attention_AllReduce_15_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_15_9_0 [label="QKV_Proj_15_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_15_9_0 [label="Attention_15_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_15_9_0 [label="Attention_Output_15_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_15_9_1 [label="QKV_Proj_15_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_15_9_1 [label="Attention_15_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_15_9_1 [label="Attention_Output_15_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_15_9_2 [label="QKV_Proj_15_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_15_9_2 [label="Attention_15_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_15_9_2 [label="Attention_Output_15_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	qkv_15_9_3 [label="QKV_Proj_15_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightsteelblue]
	attn_15_9_3 [label="Attention_15_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightsteelblue]
	attn_out_15_9_3 [label="Attention_Output_15_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	attn_allreduce_15_9 [label="Attention_AllReduce_15_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_15_10_0 [label="QKV_Proj_15_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_15_10_0 [label="Attention_15_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_15_10_0 [label="Attention_Output_15_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_15_10_1 [label="QKV_Proj_15_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_15_10_1 [label="Attention_15_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_15_10_1 [label="Attention_Output_15_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_15_10_2 [label="QKV_Proj_15_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_15_10_2 [label="Attention_15_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_15_10_2 [label="Attention_Output_15_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	qkv_15_10_3 [label="QKV_Proj_15_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightcyan]
	attn_15_10_3 [label="Attention_15_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightcyan]
	attn_out_15_10_3 [label="Attention_Output_15_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	attn_allreduce_15_10 [label="Attention_AllReduce_15_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_15_11_0 [label="QKV_Proj_15_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_15_11_0 [label="Attention_15_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_15_11_0 [label="Attention_Output_15_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_15_11_1 [label="QKV_Proj_15_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_15_11_1 [label="Attention_15_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_15_11_1 [label="Attention_Output_15_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_15_11_2 [label="QKV_Proj_15_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_15_11_2 [label="Attention_15_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_15_11_2 [label="Attention_Output_15_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	qkv_15_11_3 [label="QKV_Proj_15_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_15_11_3 [label="Attention_15_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=lightgoldenrodyellow]
	attn_out_15_11_3 [label="Attention_Output_15_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	attn_allreduce_15_11 [label="Attention_AllReduce_15_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_15_12_0 [label="QKV_Proj_15_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_15_12_0 [label="Attention_15_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_15_12_0 [label="Attention_Output_15_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_15_12_1 [label="QKV_Proj_15_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_15_12_1 [label="Attention_15_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_15_12_1 [label="Attention_Output_15_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_15_12_2 [label="QKV_Proj_15_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_15_12_2 [label="Attention_15_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_15_12_2 [label="Attention_Output_15_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	qkv_15_12_3 [label="QKV_Proj_15_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=plum]
	attn_15_12_3 [label="Attention_15_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=plum]
	attn_out_15_12_3 [label="Attention_Output_15_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	attn_allreduce_15_12 [label="Attention_AllReduce_15_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_15_13_0 [label="QKV_Proj_15_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_15_13_0 [label="Attention_15_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_15_13_0 [label="Attention_Output_15_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_15_13_1 [label="QKV_Proj_15_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_15_13_1 [label="Attention_15_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_15_13_1 [label="Attention_Output_15_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_15_13_2 [label="QKV_Proj_15_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_15_13_2 [label="Attention_15_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_15_13_2 [label="Attention_Output_15_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	qkv_15_13_3 [label="QKV_Proj_15_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=orange]
	attn_15_13_3 [label="Attention_15_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=orange]
	attn_out_15_13_3 [label="Attention_Output_15_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	attn_allreduce_15_13 [label="Attention_AllReduce_15_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_15_14_0 [label="QKV_Proj_15_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_15_14_0 [label="Attention_15_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_15_14_0 [label="Attention_Output_15_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_15_14_1 [label="QKV_Proj_15_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_15_14_1 [label="Attention_15_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_15_14_1 [label="Attention_Output_15_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_15_14_2 [label="QKV_Proj_15_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_15_14_2 [label="Attention_15_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_15_14_2 [label="Attention_Output_15_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	qkv_15_14_3 [label="QKV_Proj_15_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=purple]
	attn_15_14_3 [label="Attention_15_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=purple]
	attn_out_15_14_3 [label="Attention_Output_15_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	attn_allreduce_15_14 [label="Attention_AllReduce_15_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	qkv_15_15_0 [label="QKV_Proj_15_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_15_15_0 [label="Attention_15_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_15_15_0 [label="Attention_Output_15_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_15_15_1 [label="QKV_Proj_15_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_15_15_1 [label="Attention_15_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_15_15_1 [label="Attention_Output_15_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_15_15_2 [label="QKV_Proj_15_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_15_15_2 [label="Attention_15_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_15_15_2 [label="Attention_Output_15_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	qkv_15_15_3 [label="QKV_Proj_15_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, heads=8, d_k=64]" fillcolor=turquoise]
	attn_15_15_3 [label="Attention_15_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, heads=BG, d_k=64]" fillcolor=turquoise]
	attn_out_15_15_3 [label="Attention_Output_15_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, heads=8, d_k=64]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	attn_allreduce_15_15 [label="Attention_AllReduce_15_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_15_0_0 [label="MLP_Linear1_15_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_15_0_0 [label="GELU_15_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_15_0_0 [label="MLP_Linear2_15_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_15_0_1 [label="MLP_Linear1_15_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_15_0_1 [label="GELU_15_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_15_0_1 [label="MLP_Linear2_15_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_15_0_2 [label="MLP_Linear1_15_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_15_0_2 [label="GELU_15_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_15_0_2 [label="MLP_Linear2_15_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp1_15_0_3 [label="MLP_Linear1_15_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	gelu_15_0_3 [label="GELU_15_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcoral]
	mlp2_15_0_3 [label="MLP_Linear2_15_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	mlp_allreduce_15_0 [label="MLP_AllReduce_15_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_15_1_0 [label="MLP_Linear1_15_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_15_1_0 [label="GELU_15_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_15_1_0 [label="MLP_Linear2_15_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_15_1_1 [label="MLP_Linear1_15_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_15_1_1 [label="GELU_15_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_15_1_1 [label="MLP_Linear2_15_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_15_1_2 [label="MLP_Linear1_15_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_15_1_2 [label="GELU_15_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_15_1_2 [label="MLP_Linear2_15_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp1_15_1_3 [label="MLP_Linear1_15_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	gelu_15_1_3 [label="GELU_15_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgreen]
	mlp2_15_1_3 [label="MLP_Linear2_15_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	mlp_allreduce_15_1 [label="MLP_AllReduce_15_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_15_2_0 [label="MLP_Linear1_15_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_15_2_0 [label="GELU_15_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_15_2_0 [label="MLP_Linear2_15_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_15_2_1 [label="MLP_Linear1_15_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_15_2_1 [label="GELU_15_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_15_2_1 [label="MLP_Linear2_15_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_15_2_2 [label="MLP_Linear1_15_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_15_2_2 [label="GELU_15_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_15_2_2 [label="MLP_Linear2_15_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp1_15_2_3 [label="MLP_Linear1_15_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	gelu_15_2_3 [label="GELU_15_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightblue]
	mlp2_15_2_3 [label="MLP_Linear2_15_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	mlp_allreduce_15_2 [label="MLP_AllReduce_15_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_15_3_0 [label="MLP_Linear1_15_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_15_3_0 [label="GELU_15_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_15_3_0 [label="MLP_Linear2_15_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_15_3_1 [label="MLP_Linear1_15_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_15_3_1 [label="GELU_15_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_15_3_1 [label="MLP_Linear2_15_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_15_3_2 [label="MLP_Linear1_15_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_15_3_2 [label="GELU_15_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_15_3_2 [label="MLP_Linear2_15_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp1_15_3_3 [label="MLP_Linear1_15_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	gelu_15_3_3 [label="GELU_15_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightyellow]
	mlp2_15_3_3 [label="MLP_Linear2_15_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	mlp_allreduce_15_3 [label="MLP_AllReduce_15_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_15_4_0 [label="MLP_Linear1_15_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_15_4_0 [label="GELU_15_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_15_4_0 [label="MLP_Linear2_15_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_15_4_1 [label="MLP_Linear1_15_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_15_4_1 [label="GELU_15_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_15_4_1 [label="MLP_Linear2_15_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_15_4_2 [label="MLP_Linear1_15_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_15_4_2 [label="GELU_15_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_15_4_2 [label="MLP_Linear2_15_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp1_15_4_3 [label="MLP_Linear1_15_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	gelu_15_4_3 [label="GELU_15_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightpink]
	mlp2_15_4_3 [label="MLP_Linear2_15_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	mlp_allreduce_15_4 [label="MLP_AllReduce_15_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_15_5_0 [label="MLP_Linear1_15_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_15_5_0 [label="GELU_15_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_15_5_0 [label="MLP_Linear2_15_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_15_5_1 [label="MLP_Linear1_15_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_15_5_1 [label="GELU_15_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_15_5_1 [label="MLP_Linear2_15_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_15_5_2 [label="MLP_Linear1_15_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_15_5_2 [label="GELU_15_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_15_5_2 [label="MLP_Linear2_15_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp1_15_5_3 [label="MLP_Linear1_15_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	gelu_15_5_3 [label="GELU_15_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgray]
	mlp2_15_5_3 [label="MLP_Linear2_15_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	mlp_allreduce_15_5 [label="MLP_AllReduce_15_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_15_6_0 [label="MLP_Linear1_15_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_15_6_0 [label="GELU_15_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_15_6_0 [label="MLP_Linear2_15_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_15_6_1 [label="MLP_Linear1_15_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_15_6_1 [label="GELU_15_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_15_6_1 [label="MLP_Linear2_15_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_15_6_2 [label="MLP_Linear1_15_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_15_6_2 [label="GELU_15_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_15_6_2 [label="MLP_Linear2_15_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp1_15_6_3 [label="MLP_Linear1_15_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	gelu_15_6_3 [label="GELU_15_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsalmon]
	mlp2_15_6_3 [label="MLP_Linear2_15_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	mlp_allreduce_15_6 [label="MLP_AllReduce_15_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_15_7_0 [label="MLP_Linear1_15_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_15_7_0 [label="GELU_15_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_15_7_0 [label="MLP_Linear2_15_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_15_7_1 [label="MLP_Linear1_15_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_15_7_1 [label="GELU_15_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_15_7_1 [label="MLP_Linear2_15_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_15_7_2 [label="MLP_Linear1_15_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_15_7_2 [label="GELU_15_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_15_7_2 [label="MLP_Linear2_15_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp1_15_7_3 [label="MLP_Linear1_15_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	gelu_15_7_3 [label="GELU_15_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightseagreen]
	mlp2_15_7_3 [label="MLP_Linear2_15_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	mlp_allreduce_15_7 [label="MLP_AllReduce_15_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_15_8_0 [label="MLP_Linear1_15_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_15_8_0 [label="GELU_15_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_15_8_0 [label="MLP_Linear2_15_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_15_8_1 [label="MLP_Linear1_15_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_15_8_1 [label="GELU_15_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_15_8_1 [label="MLP_Linear2_15_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_15_8_2 [label="MLP_Linear1_15_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_15_8_2 [label="GELU_15_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_15_8_2 [label="MLP_Linear2_15_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp1_15_8_3 [label="MLP_Linear1_15_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	gelu_15_8_3 [label="GELU_15_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightskyblue]
	mlp2_15_8_3 [label="MLP_Linear2_15_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	mlp_allreduce_15_8 [label="MLP_AllReduce_15_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_15_9_0 [label="MLP_Linear1_15_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_15_9_0 [label="GELU_15_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_15_9_0 [label="MLP_Linear2_15_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_15_9_1 [label="MLP_Linear1_15_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_15_9_1 [label="GELU_15_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_15_9_1 [label="MLP_Linear2_15_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_15_9_2 [label="MLP_Linear1_15_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_15_9_2 [label="GELU_15_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_15_9_2 [label="MLP_Linear2_15_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp1_15_9_3 [label="MLP_Linear1_15_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	gelu_15_9_3 [label="GELU_15_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightsteelblue]
	mlp2_15_9_3 [label="MLP_Linear2_15_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	mlp_allreduce_15_9 [label="MLP_AllReduce_15_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_15_10_0 [label="MLP_Linear1_15_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_15_10_0 [label="GELU_15_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_15_10_0 [label="MLP_Linear2_15_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_15_10_1 [label="MLP_Linear1_15_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_15_10_1 [label="GELU_15_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_15_10_1 [label="MLP_Linear2_15_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_15_10_2 [label="MLP_Linear1_15_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_15_10_2 [label="GELU_15_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_15_10_2 [label="MLP_Linear2_15_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp1_15_10_3 [label="MLP_Linear1_15_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	gelu_15_10_3 [label="GELU_15_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightcyan]
	mlp2_15_10_3 [label="MLP_Linear2_15_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	mlp_allreduce_15_10 [label="MLP_AllReduce_15_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_15_11_0 [label="MLP_Linear1_15_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_15_11_0 [label="GELU_15_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_15_11_0 [label="MLP_Linear2_15_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_15_11_1 [label="MLP_Linear1_15_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_15_11_1 [label="GELU_15_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_15_11_1 [label="MLP_Linear2_15_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_15_11_2 [label="MLP_Linear1_15_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_15_11_2 [label="GELU_15_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_15_11_2 [label="MLP_Linear2_15_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp1_15_11_3 [label="MLP_Linear1_15_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	gelu_15_11_3 [label="GELU_15_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=lightgoldenrodyellow]
	mlp2_15_11_3 [label="MLP_Linear2_15_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	mlp_allreduce_15_11 [label="MLP_AllReduce_15_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_15_12_0 [label="MLP_Linear1_15_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_15_12_0 [label="GELU_15_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_15_12_0 [label="MLP_Linear2_15_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_15_12_1 [label="MLP_Linear1_15_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_15_12_1 [label="GELU_15_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_15_12_1 [label="MLP_Linear2_15_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_15_12_2 [label="MLP_Linear1_15_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_15_12_2 [label="GELU_15_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_15_12_2 [label="MLP_Linear2_15_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp1_15_12_3 [label="MLP_Linear1_15_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	gelu_15_12_3 [label="GELU_15_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=plum]
	mlp2_15_12_3 [label="MLP_Linear2_15_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	mlp_allreduce_15_12 [label="MLP_AllReduce_15_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_15_13_0 [label="MLP_Linear1_15_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_15_13_0 [label="GELU_15_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_15_13_0 [label="MLP_Linear2_15_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_15_13_1 [label="MLP_Linear1_15_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_15_13_1 [label="GELU_15_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_15_13_1 [label="MLP_Linear2_15_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_15_13_2 [label="MLP_Linear1_15_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_15_13_2 [label="GELU_15_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_15_13_2 [label="MLP_Linear2_15_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp1_15_13_3 [label="MLP_Linear1_15_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	gelu_15_13_3 [label="GELU_15_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=orange]
	mlp2_15_13_3 [label="MLP_Linear2_15_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	mlp_allreduce_15_13 [label="MLP_AllReduce_15_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_15_14_0 [label="MLP_Linear1_15_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_15_14_0 [label="GELU_15_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_15_14_0 [label="MLP_Linear2_15_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_15_14_1 [label="MLP_Linear1_15_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_15_14_1 [label="GELU_15_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_15_14_1 [label="MLP_Linear2_15_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_15_14_2 [label="MLP_Linear1_15_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_15_14_2 [label="GELU_15_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_15_14_2 [label="MLP_Linear2_15_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp1_15_14_3 [label="MLP_Linear1_15_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	gelu_15_14_3 [label="GELU_15_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=purple]
	mlp2_15_14_3 [label="MLP_Linear2_15_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	mlp_allreduce_15_14 [label="MLP_AllReduce_15_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	mlp1_15_15_0 [label="MLP_Linear1_15_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_15_15_0 [label="GELU_15_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_15_15_0 [label="MLP_Linear2_15_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_15_15_1 [label="MLP_Linear1_15_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_15_15_1 [label="GELU_15_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_15_15_1 [label="MLP_Linear2_15_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_15_15_2 [label="MLP_Linear1_15_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_15_15_2 [label="GELU_15_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_15_15_2 [label="MLP_Linear2_15_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp1_15_15_3 [label="MLP_Linear1_15_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	gelu_15_15_3 [label="GELU_15_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, ffn=512]" fillcolor=turquoise]
	mlp2_15_15_3 [label="MLP_Linear2_15_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, ffn=512]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	mlp_allreduce_15_15 [label="MLP_AllReduce_15_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=red penwidth=2 shape=ellipse style=filled]
	expert_route_15_0 [label="Expert_Route_15_0\nEP:0\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_15_1 [label="Expert_Route_15_1\nEP:1\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_15_2 [label="Expert_Route_15_2\nEP:2\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_15_3 [label="Expert_Route_15_3\nEP:3\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_15_4 [label="Expert_Route_15_4\nEP:4\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_15_5 [label="Expert_Route_15_5\nEP:5\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_15_6 [label="Expert_Route_15_6\nEP:6\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_15_7 [label="Expert_Route_15_7\nEP:7\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_15_8 [label="Expert_Route_15_8\nEP:8\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_15_9 [label="Expert_Route_15_9\nEP:9\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_15_10 [label="Expert_Route_15_10\nEP:10\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_15_11 [label="Expert_Route_15_11\nEP:11\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_15_12 [label="Expert_Route_15_12\nEP:12\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_15_13 [label="Expert_Route_15_13\nEP:13\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_15_14 [label="Expert_Route_15_14\nEP:14\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	expert_route_15_15 [label="Expert_Route_15_15\nEP:15\nInput: [batch_size=128, seq_len=128, hidden=512]\nOutput: [batch_size=128, seq_len=128, hidden=512]" fillcolor=orange penwidth=2 shape=ellipse style=filled]
	final_norm_0_0 [label="Final_Norm_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	final_norm_0_1 [label="Final_Norm_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	final_norm_0_2 [label="Final_Norm_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	final_norm_0_3 [label="Final_Norm_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcoral]
	final_norm_1_0 [label="Final_Norm_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	final_norm_1_1 [label="Final_Norm_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	final_norm_1_2 [label="Final_Norm_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	final_norm_1_3 [label="Final_Norm_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgreen]
	final_norm_2_0 [label="Final_Norm_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	final_norm_2_1 [label="Final_Norm_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	final_norm_2_2 [label="Final_Norm_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	final_norm_2_3 [label="Final_Norm_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightblue]
	final_norm_3_0 [label="Final_Norm_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	final_norm_3_1 [label="Final_Norm_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	final_norm_3_2 [label="Final_Norm_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	final_norm_3_3 [label="Final_Norm_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightyellow]
	final_norm_4_0 [label="Final_Norm_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	final_norm_4_1 [label="Final_Norm_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	final_norm_4_2 [label="Final_Norm_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	final_norm_4_3 [label="Final_Norm_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightpink]
	final_norm_5_0 [label="Final_Norm_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	final_norm_5_1 [label="Final_Norm_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	final_norm_5_2 [label="Final_Norm_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	final_norm_5_3 [label="Final_Norm_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgray]
	final_norm_6_0 [label="Final_Norm_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	final_norm_6_1 [label="Final_Norm_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	final_norm_6_2 [label="Final_Norm_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	final_norm_6_3 [label="Final_Norm_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsalmon]
	final_norm_7_0 [label="Final_Norm_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	final_norm_7_1 [label="Final_Norm_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	final_norm_7_2 [label="Final_Norm_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	final_norm_7_3 [label="Final_Norm_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightseagreen]
	final_norm_8_0 [label="Final_Norm_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	final_norm_8_1 [label="Final_Norm_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	final_norm_8_2 [label="Final_Norm_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	final_norm_8_3 [label="Final_Norm_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightskyblue]
	final_norm_9_0 [label="Final_Norm_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	final_norm_9_1 [label="Final_Norm_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	final_norm_9_2 [label="Final_Norm_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	final_norm_9_3 [label="Final_Norm_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightsteelblue]
	final_norm_10_0 [label="Final_Norm_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	final_norm_10_1 [label="Final_Norm_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	final_norm_10_2 [label="Final_Norm_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	final_norm_10_3 [label="Final_Norm_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightcyan]
	final_norm_11_0 [label="Final_Norm_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	final_norm_11_1 [label="Final_Norm_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	final_norm_11_2 [label="Final_Norm_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	final_norm_11_3 [label="Final_Norm_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=lightgoldenrodyellow]
	final_norm_12_0 [label="Final_Norm_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	final_norm_12_1 [label="Final_Norm_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	final_norm_12_2 [label="Final_Norm_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	final_norm_12_3 [label="Final_Norm_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=plum]
	final_norm_13_0 [label="Final_Norm_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	final_norm_13_1 [label="Final_Norm_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	final_norm_13_2 [label="Final_Norm_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	final_norm_13_3 [label="Final_Norm_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=orange]
	final_norm_14_0 [label="Final_Norm_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	final_norm_14_1 [label="Final_Norm_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	final_norm_14_2 [label="Final_Norm_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	final_norm_14_3 [label="Final_Norm_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=purple]
	final_norm_15_0 [label="Final_Norm_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	final_norm_15_1 [label="Final_Norm_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	final_norm_15_2 [label="Final_Norm_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	final_norm_15_3 [label="Final_Norm_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, hidden=128]" fillcolor=turquoise]
	output_proj_0_0 [label="Output_Proj_0_0\nGPU:0\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightcoral]
	output_proj_0_1 [label="Output_Proj_0_1\nGPU:1\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightcoral]
	output_proj_0_2 [label="Output_Proj_0_2\nGPU:2\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightcoral]
	output_proj_0_3 [label="Output_Proj_0_3\nGPU:3\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightcoral]
	output_proj_1_0 [label="Output_Proj_1_0\nGPU:4\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightgreen]
	output_proj_1_1 [label="Output_Proj_1_1\nGPU:5\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightgreen]
	output_proj_1_2 [label="Output_Proj_1_2\nGPU:6\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightgreen]
	output_proj_1_3 [label="Output_Proj_1_3\nGPU:7\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightgreen]
	output_proj_2_0 [label="Output_Proj_2_0\nGPU:8\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightblue]
	output_proj_2_1 [label="Output_Proj_2_1\nGPU:9\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightblue]
	output_proj_2_2 [label="Output_Proj_2_2\nGPU:10\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightblue]
	output_proj_2_3 [label="Output_Proj_2_3\nGPU:11\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightblue]
	output_proj_3_0 [label="Output_Proj_3_0\nGPU:12\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightyellow]
	output_proj_3_1 [label="Output_Proj_3_1\nGPU:13\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightyellow]
	output_proj_3_2 [label="Output_Proj_3_2\nGPU:14\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightyellow]
	output_proj_3_3 [label="Output_Proj_3_3\nGPU:15\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightyellow]
	output_proj_4_0 [label="Output_Proj_4_0\nGPU:16\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightpink]
	output_proj_4_1 [label="Output_Proj_4_1\nGPU:17\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightpink]
	output_proj_4_2 [label="Output_Proj_4_2\nGPU:18\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightpink]
	output_proj_4_3 [label="Output_Proj_4_3\nGPU:19\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightpink]
	output_proj_5_0 [label="Output_Proj_5_0\nGPU:20\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightgray]
	output_proj_5_1 [label="Output_Proj_5_1\nGPU:21\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightgray]
	output_proj_5_2 [label="Output_Proj_5_2\nGPU:22\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightgray]
	output_proj_5_3 [label="Output_Proj_5_3\nGPU:23\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightgray]
	output_proj_6_0 [label="Output_Proj_6_0\nGPU:24\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightsalmon]
	output_proj_6_1 [label="Output_Proj_6_1\nGPU:25\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightsalmon]
	output_proj_6_2 [label="Output_Proj_6_2\nGPU:26\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightsalmon]
	output_proj_6_3 [label="Output_Proj_6_3\nGPU:27\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightsalmon]
	output_proj_7_0 [label="Output_Proj_7_0\nGPU:28\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightseagreen]
	output_proj_7_1 [label="Output_Proj_7_1\nGPU:29\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightseagreen]
	output_proj_7_2 [label="Output_Proj_7_2\nGPU:30\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightseagreen]
	output_proj_7_3 [label="Output_Proj_7_3\nGPU:31\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightseagreen]
	output_proj_8_0 [label="Output_Proj_8_0\nGPU:32\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightskyblue]
	output_proj_8_1 [label="Output_Proj_8_1\nGPU:33\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightskyblue]
	output_proj_8_2 [label="Output_Proj_8_2\nGPU:34\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightskyblue]
	output_proj_8_3 [label="Output_Proj_8_3\nGPU:35\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightskyblue]
	output_proj_9_0 [label="Output_Proj_9_0\nGPU:36\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightsteelblue]
	output_proj_9_1 [label="Output_Proj_9_1\nGPU:37\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightsteelblue]
	output_proj_9_2 [label="Output_Proj_9_2\nGPU:38\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightsteelblue]
	output_proj_9_3 [label="Output_Proj_9_3\nGPU:39\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightsteelblue]
	output_proj_10_0 [label="Output_Proj_10_0\nGPU:40\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightcyan]
	output_proj_10_1 [label="Output_Proj_10_1\nGPU:41\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightcyan]
	output_proj_10_2 [label="Output_Proj_10_2\nGPU:42\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightcyan]
	output_proj_10_3 [label="Output_Proj_10_3\nGPU:43\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightcyan]
	output_proj_11_0 [label="Output_Proj_11_0\nGPU:44\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightgoldenrodyellow]
	output_proj_11_1 [label="Output_Proj_11_1\nGPU:45\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightgoldenrodyellow]
	output_proj_11_2 [label="Output_Proj_11_2\nGPU:46\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightgoldenrodyellow]
	output_proj_11_3 [label="Output_Proj_11_3\nGPU:47\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=lightgoldenrodyellow]
	output_proj_12_0 [label="Output_Proj_12_0\nGPU:48\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=plum]
	output_proj_12_1 [label="Output_Proj_12_1\nGPU:49\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=plum]
	output_proj_12_2 [label="Output_Proj_12_2\nGPU:50\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=plum]
	output_proj_12_3 [label="Output_Proj_12_3\nGPU:51\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=plum]
	output_proj_13_0 [label="Output_Proj_13_0\nGPU:52\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=orange]
	output_proj_13_1 [label="Output_Proj_13_1\nGPU:53\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=orange]
	output_proj_13_2 [label="Output_Proj_13_2\nGPU:54\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=orange]
	output_proj_13_3 [label="Output_Proj_13_3\nGPU:55\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=orange]
	output_proj_14_0 [label="Output_Proj_14_0\nGPU:56\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=purple]
	output_proj_14_1 [label="Output_Proj_14_1\nGPU:57\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=purple]
	output_proj_14_2 [label="Output_Proj_14_2\nGPU:58\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=purple]
	output_proj_14_3 [label="Output_Proj_14_3\nGPU:59\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=purple]
	output_proj_15_0 [label="Output_Proj_15_0\nGPU:60\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=turquoise]
	output_proj_15_1 [label="Output_Proj_15_1\nGPU:61\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=turquoise]
	output_proj_15_2 [label="Output_Proj_15_2\nGPU:62\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=turquoise]
	output_proj_15_3 [label="Output_Proj_15_3\nGPU:63\nInput: [batch_size=128, seq_len=128, hidden=128]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=turquoise]
	final_allreduce [label="Final_AllReduce\nAll GPUs\nInput: [batch_size=128, seq_len=128, vocab=32000]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=red penwidth=3 shape=ellipse style=filled]
	output [label="Output\nInput: [batch_size=128, seq_len=128, vocab=32000]\nOutput: [batch_size=128, seq_len=128, vocab=32000]" fillcolor=white penwidth=2 shape=ellipse style=filled]
	final_allreduce -> output
}
