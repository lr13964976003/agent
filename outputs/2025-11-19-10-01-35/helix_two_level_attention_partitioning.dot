digraph helix_two_level_attention_partitioning {
	graph [bgcolor=white margin=0.2 nodesep=0.5 pad=0.5 rankdir=TB ranksep=1.0]
	node [fontname=Courier fontsize=10 margin="0.1,0.05"]
	edge [fontname=Courier fontsize=8]
	model_input [label="model_input\nInput: [batch_size=128, seq_len=10000, vocab_size=50257]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 0" fillcolor=darkblue fontcolor=white shape=ellipse style=filled]
	embedding [label="embedding\nInput: [batch_size=128, seq_len=10000, vocab_size=50257]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 0" fillcolor=lightcyan shape=rectangle style=filled]
	model_input -> embedding
	layer_0_input [label="layer_0_input\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightblue shape=ellipse style=filled]
	layer_0_layer_norm_mha [label="layer_0_layer_norm_mha\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightyellow shape=rectangle style=filled]
	layer_0_input -> layer_0_layer_norm_mha
	layer_0_q_proj_0_0 [label="layer_0_q_proj_0_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 0" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_k_proj_0_0 [label="layer_0_k_proj_0_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 0" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_v_proj_0_0 [label="layer_0_v_proj_0_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 0" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_attention_0_0 [label="layer_0_attention_0_0\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 0" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_layer_norm_mha -> layer_0_q_proj_0_0
	layer_0_layer_norm_mha -> layer_0_k_proj_0_0
	layer_0_layer_norm_mha -> layer_0_v_proj_0_0
	layer_0_q_proj_0_0 -> layer_0_attention_0_0
	layer_0_k_proj_0_0 -> layer_0_attention_0_0
	layer_0_v_proj_0_0 -> layer_0_attention_0_0
	layer_0_q_proj_0_1 [label="layer_0_q_proj_0_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 1" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_k_proj_0_1 [label="layer_0_k_proj_0_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 1" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_v_proj_0_1 [label="layer_0_v_proj_0_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 1" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_attention_0_1 [label="layer_0_attention_0_1\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 1" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_layer_norm_mha -> layer_0_q_proj_0_1
	layer_0_layer_norm_mha -> layer_0_k_proj_0_1
	layer_0_layer_norm_mha -> layer_0_v_proj_0_1
	layer_0_q_proj_0_1 -> layer_0_attention_0_1
	layer_0_k_proj_0_1 -> layer_0_attention_0_1
	layer_0_v_proj_0_1 -> layer_0_attention_0_1
	layer_0_q_proj_0_2 [label="layer_0_q_proj_0_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 2" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_k_proj_0_2 [label="layer_0_k_proj_0_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 2" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_v_proj_0_2 [label="layer_0_v_proj_0_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 2" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_attention_0_2 [label="layer_0_attention_0_2\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 2" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_layer_norm_mha -> layer_0_q_proj_0_2
	layer_0_layer_norm_mha -> layer_0_k_proj_0_2
	layer_0_layer_norm_mha -> layer_0_v_proj_0_2
	layer_0_q_proj_0_2 -> layer_0_attention_0_2
	layer_0_k_proj_0_2 -> layer_0_attention_0_2
	layer_0_v_proj_0_2 -> layer_0_attention_0_2
	layer_0_q_proj_0_3 [label="layer_0_q_proj_0_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 3" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_k_proj_0_3 [label="layer_0_k_proj_0_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 3" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_v_proj_0_3 [label="layer_0_v_proj_0_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 3" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_attention_0_3 [label="layer_0_attention_0_3\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 3" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_layer_norm_mha -> layer_0_q_proj_0_3
	layer_0_layer_norm_mha -> layer_0_k_proj_0_3
	layer_0_layer_norm_mha -> layer_0_v_proj_0_3
	layer_0_q_proj_0_3 -> layer_0_attention_0_3
	layer_0_k_proj_0_3 -> layer_0_attention_0_3
	layer_0_v_proj_0_3 -> layer_0_attention_0_3
	layer_0_q_proj_1_0 [label="layer_0_q_proj_1_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 4" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_k_proj_1_0 [label="layer_0_k_proj_1_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 4" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_v_proj_1_0 [label="layer_0_v_proj_1_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 4" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_attention_1_0 [label="layer_0_attention_1_0\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 4" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_layer_norm_mha -> layer_0_q_proj_1_0
	layer_0_layer_norm_mha -> layer_0_k_proj_1_0
	layer_0_layer_norm_mha -> layer_0_v_proj_1_0
	layer_0_q_proj_1_0 -> layer_0_attention_1_0
	layer_0_k_proj_1_0 -> layer_0_attention_1_0
	layer_0_v_proj_1_0 -> layer_0_attention_1_0
	layer_0_q_proj_1_1 [label="layer_0_q_proj_1_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 5" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_k_proj_1_1 [label="layer_0_k_proj_1_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 5" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_v_proj_1_1 [label="layer_0_v_proj_1_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 5" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_attention_1_1 [label="layer_0_attention_1_1\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 5" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_layer_norm_mha -> layer_0_q_proj_1_1
	layer_0_layer_norm_mha -> layer_0_k_proj_1_1
	layer_0_layer_norm_mha -> layer_0_v_proj_1_1
	layer_0_q_proj_1_1 -> layer_0_attention_1_1
	layer_0_k_proj_1_1 -> layer_0_attention_1_1
	layer_0_v_proj_1_1 -> layer_0_attention_1_1
	layer_0_q_proj_1_2 [label="layer_0_q_proj_1_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 6" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_k_proj_1_2 [label="layer_0_k_proj_1_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 6" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_v_proj_1_2 [label="layer_0_v_proj_1_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 6" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_attention_1_2 [label="layer_0_attention_1_2\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 6" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_layer_norm_mha -> layer_0_q_proj_1_2
	layer_0_layer_norm_mha -> layer_0_k_proj_1_2
	layer_0_layer_norm_mha -> layer_0_v_proj_1_2
	layer_0_q_proj_1_2 -> layer_0_attention_1_2
	layer_0_k_proj_1_2 -> layer_0_attention_1_2
	layer_0_v_proj_1_2 -> layer_0_attention_1_2
	layer_0_q_proj_1_3 [label="layer_0_q_proj_1_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 7" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_k_proj_1_3 [label="layer_0_k_proj_1_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 7" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_v_proj_1_3 [label="layer_0_v_proj_1_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 7" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_attention_1_3 [label="layer_0_attention_1_3\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 7" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_layer_norm_mha -> layer_0_q_proj_1_3
	layer_0_layer_norm_mha -> layer_0_k_proj_1_3
	layer_0_layer_norm_mha -> layer_0_v_proj_1_3
	layer_0_q_proj_1_3 -> layer_0_attention_1_3
	layer_0_k_proj_1_3 -> layer_0_attention_1_3
	layer_0_v_proj_1_3 -> layer_0_attention_1_3
	layer_0_q_proj_2_0 [label="layer_0_q_proj_2_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 8" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_k_proj_2_0 [label="layer_0_k_proj_2_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 8" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_v_proj_2_0 [label="layer_0_v_proj_2_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 8" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_attention_2_0 [label="layer_0_attention_2_0\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 8" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_layer_norm_mha -> layer_0_q_proj_2_0
	layer_0_layer_norm_mha -> layer_0_k_proj_2_0
	layer_0_layer_norm_mha -> layer_0_v_proj_2_0
	layer_0_q_proj_2_0 -> layer_0_attention_2_0
	layer_0_k_proj_2_0 -> layer_0_attention_2_0
	layer_0_v_proj_2_0 -> layer_0_attention_2_0
	layer_0_q_proj_2_1 [label="layer_0_q_proj_2_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 9" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_k_proj_2_1 [label="layer_0_k_proj_2_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 9" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_v_proj_2_1 [label="layer_0_v_proj_2_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 9" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_attention_2_1 [label="layer_0_attention_2_1\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 9" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_layer_norm_mha -> layer_0_q_proj_2_1
	layer_0_layer_norm_mha -> layer_0_k_proj_2_1
	layer_0_layer_norm_mha -> layer_0_v_proj_2_1
	layer_0_q_proj_2_1 -> layer_0_attention_2_1
	layer_0_k_proj_2_1 -> layer_0_attention_2_1
	layer_0_v_proj_2_1 -> layer_0_attention_2_1
	layer_0_q_proj_2_2 [label="layer_0_q_proj_2_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 10" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_k_proj_2_2 [label="layer_0_k_proj_2_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 10" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_v_proj_2_2 [label="layer_0_v_proj_2_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 10" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_attention_2_2 [label="layer_0_attention_2_2\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 10" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_layer_norm_mha -> layer_0_q_proj_2_2
	layer_0_layer_norm_mha -> layer_0_k_proj_2_2
	layer_0_layer_norm_mha -> layer_0_v_proj_2_2
	layer_0_q_proj_2_2 -> layer_0_attention_2_2
	layer_0_k_proj_2_2 -> layer_0_attention_2_2
	layer_0_v_proj_2_2 -> layer_0_attention_2_2
	layer_0_q_proj_2_3 [label="layer_0_q_proj_2_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 11" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_k_proj_2_3 [label="layer_0_k_proj_2_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 11" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_v_proj_2_3 [label="layer_0_v_proj_2_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 11" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_attention_2_3 [label="layer_0_attention_2_3\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 11" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_layer_norm_mha -> layer_0_q_proj_2_3
	layer_0_layer_norm_mha -> layer_0_k_proj_2_3
	layer_0_layer_norm_mha -> layer_0_v_proj_2_3
	layer_0_q_proj_2_3 -> layer_0_attention_2_3
	layer_0_k_proj_2_3 -> layer_0_attention_2_3
	layer_0_v_proj_2_3 -> layer_0_attention_2_3
	layer_0_q_proj_3_0 [label="layer_0_q_proj_3_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 12" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_k_proj_3_0 [label="layer_0_k_proj_3_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 12" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_v_proj_3_0 [label="layer_0_v_proj_3_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 12" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_attention_3_0 [label="layer_0_attention_3_0\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 12" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_layer_norm_mha -> layer_0_q_proj_3_0
	layer_0_layer_norm_mha -> layer_0_k_proj_3_0
	layer_0_layer_norm_mha -> layer_0_v_proj_3_0
	layer_0_q_proj_3_0 -> layer_0_attention_3_0
	layer_0_k_proj_3_0 -> layer_0_attention_3_0
	layer_0_v_proj_3_0 -> layer_0_attention_3_0
	layer_0_q_proj_3_1 [label="layer_0_q_proj_3_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 13" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_k_proj_3_1 [label="layer_0_k_proj_3_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 13" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_v_proj_3_1 [label="layer_0_v_proj_3_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 13" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_attention_3_1 [label="layer_0_attention_3_1\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 13" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_layer_norm_mha -> layer_0_q_proj_3_1
	layer_0_layer_norm_mha -> layer_0_k_proj_3_1
	layer_0_layer_norm_mha -> layer_0_v_proj_3_1
	layer_0_q_proj_3_1 -> layer_0_attention_3_1
	layer_0_k_proj_3_1 -> layer_0_attention_3_1
	layer_0_v_proj_3_1 -> layer_0_attention_3_1
	layer_0_q_proj_3_2 [label="layer_0_q_proj_3_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 14" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_k_proj_3_2 [label="layer_0_k_proj_3_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 14" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_v_proj_3_2 [label="layer_0_v_proj_3_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 14" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_attention_3_2 [label="layer_0_attention_3_2\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 14" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_layer_norm_mha -> layer_0_q_proj_3_2
	layer_0_layer_norm_mha -> layer_0_k_proj_3_2
	layer_0_layer_norm_mha -> layer_0_v_proj_3_2
	layer_0_q_proj_3_2 -> layer_0_attention_3_2
	layer_0_k_proj_3_2 -> layer_0_attention_3_2
	layer_0_v_proj_3_2 -> layer_0_attention_3_2
	layer_0_q_proj_3_3 [label="layer_0_q_proj_3_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 15" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_k_proj_3_3 [label="layer_0_k_proj_3_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 15" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_v_proj_3_3 [label="layer_0_v_proj_3_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 15" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_attention_3_3 [label="layer_0_attention_3_3\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 15" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_layer_norm_mha -> layer_0_q_proj_3_3
	layer_0_layer_norm_mha -> layer_0_k_proj_3_3
	layer_0_layer_norm_mha -> layer_0_v_proj_3_3
	layer_0_q_proj_3_3 -> layer_0_attention_3_3
	layer_0_k_proj_3_3 -> layer_0_attention_3_3
	layer_0_v_proj_3_3 -> layer_0_attention_3_3
	layer_0_dim_aggregate_0 [label="layer_0_dim_aggregate_0\nInput: [4×[batch_size=128, seq_len=10000, heads=8, d_k=32]]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=128]\nGPU: all" fillcolor=lightgreen shape=parallelogram style=filled]
	layer_0_attention_0_0 -> layer_0_dim_aggregate_0
	layer_0_attention_0_1 -> layer_0_dim_aggregate_0
	layer_0_attention_0_2 -> layer_0_dim_aggregate_0
	layer_0_attention_0_3 -> layer_0_dim_aggregate_0
	layer_0_dim_aggregate_1 [label="layer_0_dim_aggregate_1\nInput: [4×[batch_size=128, seq_len=10000, heads=8, d_k=32]]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=128]\nGPU: all" fillcolor=lightgreen shape=parallelogram style=filled]
	layer_0_attention_1_0 -> layer_0_dim_aggregate_1
	layer_0_attention_1_1 -> layer_0_dim_aggregate_1
	layer_0_attention_1_2 -> layer_0_dim_aggregate_1
	layer_0_attention_1_3 -> layer_0_dim_aggregate_1
	layer_0_dim_aggregate_2 [label="layer_0_dim_aggregate_2\nInput: [4×[batch_size=128, seq_len=10000, heads=8, d_k=32]]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=128]\nGPU: all" fillcolor=lightgreen shape=parallelogram style=filled]
	layer_0_attention_2_0 -> layer_0_dim_aggregate_2
	layer_0_attention_2_1 -> layer_0_dim_aggregate_2
	layer_0_attention_2_2 -> layer_0_dim_aggregate_2
	layer_0_attention_2_3 -> layer_0_dim_aggregate_2
	layer_0_dim_aggregate_3 [label="layer_0_dim_aggregate_3\nInput: [4×[batch_size=128, seq_len=10000, heads=8, d_k=32]]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=128]\nGPU: all" fillcolor=lightgreen shape=parallelogram style=filled]
	layer_0_attention_3_0 -> layer_0_dim_aggregate_3
	layer_0_attention_3_1 -> layer_0_dim_aggregate_3
	layer_0_attention_3_2 -> layer_0_dim_aggregate_3
	layer_0_attention_3_3 -> layer_0_dim_aggregate_3
	layer_0_mha_aggregate [label="layer_0_mha_aggregate\nInput: [4×[batch_size=128, seq_len=10000, heads=8, d_k=128]]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightgreen shape=parallelogram style=filled]
	layer_0_dim_aggregate_0 -> layer_0_mha_aggregate
	layer_0_dim_aggregate_1 -> layer_0_mha_aggregate
	layer_0_dim_aggregate_2 -> layer_0_mha_aggregate
	layer_0_dim_aggregate_3 -> layer_0_mha_aggregate
	layer_0_residual_add_mha [label="layer_0_residual_add_mha\nInput1: [batch_size=128, seq_len=10000, hidden_size=4096]\nInput2: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightcoral shape=rectangle style=filled]
	layer_0_layer_norm_mha -> layer_0_residual_add_mha
	layer_0_mha_aggregate -> layer_0_residual_add_mha
	layer_0_layer_norm_ffn [label="layer_0_layer_norm_ffn\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightyellow shape=rectangle style=filled]
	layer_0_residual_add_mha -> layer_0_layer_norm_ffn
	layer_0_gate_proj [label="layer_0_gate_proj\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, intermediate_size=32768]\nGPU: all" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_up_proj [label="layer_0_up_proj\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, intermediate_size=32768]\nGPU: all" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_activation [label="layer_0_activation\nInput: [batch_size=128, seq_len=10000, intermediate_size=32768]\nOutput: [batch_size=128, seq_len=10000, intermediate_size=32768]\nGPU: all" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_elementwise_mul [label="layer_0_elementwise_mul\nInput1: [batch_size=128, seq_len=10000, intermediate_size=32768]\nInput2: [batch_size=128, seq_len=10000, intermediate_size=32768]\nOutput: [batch_size=128, seq_len=10000, intermediate_size=32768]\nGPU: all" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_down_proj [label="layer_0_down_proj\nInput: [batch_size=128, seq_len=10000, intermediate_size=32768]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_ffn_output [label="layer_0_ffn_output\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightgreen shape=ellipse style=filled]
	layer_0_layer_norm_ffn -> layer_0_gate_proj
	layer_0_layer_norm_ffn -> layer_0_up_proj
	layer_0_gate_proj -> layer_0_activation
	layer_0_activation -> layer_0_elementwise_mul
	layer_0_up_proj -> layer_0_elementwise_mul
	layer_0_elementwise_mul -> layer_0_down_proj
	layer_0_down_proj -> layer_0_ffn_output
	layer_0_residual_add_ffn [label="layer_0_residual_add_ffn\nInput1: [batch_size=128, seq_len=10000, hidden_size=4096]\nInput2: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightcoral shape=rectangle style=filled]
	layer_0_layer_norm_ffn -> layer_0_residual_add_ffn
	layer_0_ffn_output -> layer_0_residual_add_ffn
	layer_0_output [label="layer_0_output\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightgreen shape=ellipse style=filled]
	layer_0_residual_add_ffn -> layer_0_output
	embedding -> layer_0_input
	layer_1_input [label="layer_1_input\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightblue shape=ellipse style=filled]
	layer_1_layer_norm_mha [label="layer_1_layer_norm_mha\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightyellow shape=rectangle style=filled]
	layer_1_input -> layer_1_layer_norm_mha
	layer_1_q_proj_0_0 [label="layer_1_q_proj_0_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 0" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_k_proj_0_0 [label="layer_1_k_proj_0_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 0" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_v_proj_0_0 [label="layer_1_v_proj_0_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 0" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_attention_0_0 [label="layer_1_attention_0_0\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 0" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_layer_norm_mha -> layer_1_q_proj_0_0
	layer_1_layer_norm_mha -> layer_1_k_proj_0_0
	layer_1_layer_norm_mha -> layer_1_v_proj_0_0
	layer_1_q_proj_0_0 -> layer_1_attention_0_0
	layer_1_k_proj_0_0 -> layer_1_attention_0_0
	layer_1_v_proj_0_0 -> layer_1_attention_0_0
	layer_1_q_proj_0_1 [label="layer_1_q_proj_0_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 1" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_k_proj_0_1 [label="layer_1_k_proj_0_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 1" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_v_proj_0_1 [label="layer_1_v_proj_0_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 1" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_attention_0_1 [label="layer_1_attention_0_1\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 1" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_layer_norm_mha -> layer_1_q_proj_0_1
	layer_1_layer_norm_mha -> layer_1_k_proj_0_1
	layer_1_layer_norm_mha -> layer_1_v_proj_0_1
	layer_1_q_proj_0_1 -> layer_1_attention_0_1
	layer_1_k_proj_0_1 -> layer_1_attention_0_1
	layer_1_v_proj_0_1 -> layer_1_attention_0_1
	layer_1_q_proj_0_2 [label="layer_1_q_proj_0_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 2" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_k_proj_0_2 [label="layer_1_k_proj_0_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 2" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_v_proj_0_2 [label="layer_1_v_proj_0_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 2" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_attention_0_2 [label="layer_1_attention_0_2\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 2" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_layer_norm_mha -> layer_1_q_proj_0_2
	layer_1_layer_norm_mha -> layer_1_k_proj_0_2
	layer_1_layer_norm_mha -> layer_1_v_proj_0_2
	layer_1_q_proj_0_2 -> layer_1_attention_0_2
	layer_1_k_proj_0_2 -> layer_1_attention_0_2
	layer_1_v_proj_0_2 -> layer_1_attention_0_2
	layer_1_q_proj_0_3 [label="layer_1_q_proj_0_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 3" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_k_proj_0_3 [label="layer_1_k_proj_0_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 3" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_v_proj_0_3 [label="layer_1_v_proj_0_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 3" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_attention_0_3 [label="layer_1_attention_0_3\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 3" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_layer_norm_mha -> layer_1_q_proj_0_3
	layer_1_layer_norm_mha -> layer_1_k_proj_0_3
	layer_1_layer_norm_mha -> layer_1_v_proj_0_3
	layer_1_q_proj_0_3 -> layer_1_attention_0_3
	layer_1_k_proj_0_3 -> layer_1_attention_0_3
	layer_1_v_proj_0_3 -> layer_1_attention_0_3
	layer_1_q_proj_1_0 [label="layer_1_q_proj_1_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 4" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_k_proj_1_0 [label="layer_1_k_proj_1_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 4" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_v_proj_1_0 [label="layer_1_v_proj_1_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 4" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_attention_1_0 [label="layer_1_attention_1_0\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 4" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_layer_norm_mha -> layer_1_q_proj_1_0
	layer_1_layer_norm_mha -> layer_1_k_proj_1_0
	layer_1_layer_norm_mha -> layer_1_v_proj_1_0
	layer_1_q_proj_1_0 -> layer_1_attention_1_0
	layer_1_k_proj_1_0 -> layer_1_attention_1_0
	layer_1_v_proj_1_0 -> layer_1_attention_1_0
	layer_1_q_proj_1_1 [label="layer_1_q_proj_1_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 5" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_k_proj_1_1 [label="layer_1_k_proj_1_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 5" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_v_proj_1_1 [label="layer_1_v_proj_1_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 5" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_attention_1_1 [label="layer_1_attention_1_1\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 5" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_layer_norm_mha -> layer_1_q_proj_1_1
	layer_1_layer_norm_mha -> layer_1_k_proj_1_1
	layer_1_layer_norm_mha -> layer_1_v_proj_1_1
	layer_1_q_proj_1_1 -> layer_1_attention_1_1
	layer_1_k_proj_1_1 -> layer_1_attention_1_1
	layer_1_v_proj_1_1 -> layer_1_attention_1_1
	layer_1_q_proj_1_2 [label="layer_1_q_proj_1_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 6" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_k_proj_1_2 [label="layer_1_k_proj_1_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 6" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_v_proj_1_2 [label="layer_1_v_proj_1_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 6" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_attention_1_2 [label="layer_1_attention_1_2\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 6" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_layer_norm_mha -> layer_1_q_proj_1_2
	layer_1_layer_norm_mha -> layer_1_k_proj_1_2
	layer_1_layer_norm_mha -> layer_1_v_proj_1_2
	layer_1_q_proj_1_2 -> layer_1_attention_1_2
	layer_1_k_proj_1_2 -> layer_1_attention_1_2
	layer_1_v_proj_1_2 -> layer_1_attention_1_2
	layer_1_q_proj_1_3 [label="layer_1_q_proj_1_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 7" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_k_proj_1_3 [label="layer_1_k_proj_1_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 7" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_v_proj_1_3 [label="layer_1_v_proj_1_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 7" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_attention_1_3 [label="layer_1_attention_1_3\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 7" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_layer_norm_mha -> layer_1_q_proj_1_3
	layer_1_layer_norm_mha -> layer_1_k_proj_1_3
	layer_1_layer_norm_mha -> layer_1_v_proj_1_3
	layer_1_q_proj_1_3 -> layer_1_attention_1_3
	layer_1_k_proj_1_3 -> layer_1_attention_1_3
	layer_1_v_proj_1_3 -> layer_1_attention_1_3
	layer_1_q_proj_2_0 [label="layer_1_q_proj_2_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 8" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_k_proj_2_0 [label="layer_1_k_proj_2_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 8" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_v_proj_2_0 [label="layer_1_v_proj_2_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 8" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_attention_2_0 [label="layer_1_attention_2_0\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 8" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_layer_norm_mha -> layer_1_q_proj_2_0
	layer_1_layer_norm_mha -> layer_1_k_proj_2_0
	layer_1_layer_norm_mha -> layer_1_v_proj_2_0
	layer_1_q_proj_2_0 -> layer_1_attention_2_0
	layer_1_k_proj_2_0 -> layer_1_attention_2_0
	layer_1_v_proj_2_0 -> layer_1_attention_2_0
	layer_1_q_proj_2_1 [label="layer_1_q_proj_2_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 9" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_k_proj_2_1 [label="layer_1_k_proj_2_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 9" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_v_proj_2_1 [label="layer_1_v_proj_2_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 9" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_attention_2_1 [label="layer_1_attention_2_1\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 9" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_layer_norm_mha -> layer_1_q_proj_2_1
	layer_1_layer_norm_mha -> layer_1_k_proj_2_1
	layer_1_layer_norm_mha -> layer_1_v_proj_2_1
	layer_1_q_proj_2_1 -> layer_1_attention_2_1
	layer_1_k_proj_2_1 -> layer_1_attention_2_1
	layer_1_v_proj_2_1 -> layer_1_attention_2_1
	layer_1_q_proj_2_2 [label="layer_1_q_proj_2_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 10" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_k_proj_2_2 [label="layer_1_k_proj_2_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 10" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_v_proj_2_2 [label="layer_1_v_proj_2_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 10" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_attention_2_2 [label="layer_1_attention_2_2\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 10" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_layer_norm_mha -> layer_1_q_proj_2_2
	layer_1_layer_norm_mha -> layer_1_k_proj_2_2
	layer_1_layer_norm_mha -> layer_1_v_proj_2_2
	layer_1_q_proj_2_2 -> layer_1_attention_2_2
	layer_1_k_proj_2_2 -> layer_1_attention_2_2
	layer_1_v_proj_2_2 -> layer_1_attention_2_2
	layer_1_q_proj_2_3 [label="layer_1_q_proj_2_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 11" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_k_proj_2_3 [label="layer_1_k_proj_2_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 11" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_v_proj_2_3 [label="layer_1_v_proj_2_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 11" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_attention_2_3 [label="layer_1_attention_2_3\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 11" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_layer_norm_mha -> layer_1_q_proj_2_3
	layer_1_layer_norm_mha -> layer_1_k_proj_2_3
	layer_1_layer_norm_mha -> layer_1_v_proj_2_3
	layer_1_q_proj_2_3 -> layer_1_attention_2_3
	layer_1_k_proj_2_3 -> layer_1_attention_2_3
	layer_1_v_proj_2_3 -> layer_1_attention_2_3
	layer_1_q_proj_3_0 [label="layer_1_q_proj_3_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 12" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_k_proj_3_0 [label="layer_1_k_proj_3_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 12" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_v_proj_3_0 [label="layer_1_v_proj_3_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 12" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_attention_3_0 [label="layer_1_attention_3_0\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 12" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_layer_norm_mha -> layer_1_q_proj_3_0
	layer_1_layer_norm_mha -> layer_1_k_proj_3_0
	layer_1_layer_norm_mha -> layer_1_v_proj_3_0
	layer_1_q_proj_3_0 -> layer_1_attention_3_0
	layer_1_k_proj_3_0 -> layer_1_attention_3_0
	layer_1_v_proj_3_0 -> layer_1_attention_3_0
	layer_1_q_proj_3_1 [label="layer_1_q_proj_3_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 13" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_k_proj_3_1 [label="layer_1_k_proj_3_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 13" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_v_proj_3_1 [label="layer_1_v_proj_3_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 13" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_attention_3_1 [label="layer_1_attention_3_1\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 13" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_layer_norm_mha -> layer_1_q_proj_3_1
	layer_1_layer_norm_mha -> layer_1_k_proj_3_1
	layer_1_layer_norm_mha -> layer_1_v_proj_3_1
	layer_1_q_proj_3_1 -> layer_1_attention_3_1
	layer_1_k_proj_3_1 -> layer_1_attention_3_1
	layer_1_v_proj_3_1 -> layer_1_attention_3_1
	layer_1_q_proj_3_2 [label="layer_1_q_proj_3_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 14" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_k_proj_3_2 [label="layer_1_k_proj_3_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 14" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_v_proj_3_2 [label="layer_1_v_proj_3_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 14" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_attention_3_2 [label="layer_1_attention_3_2\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 14" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_layer_norm_mha -> layer_1_q_proj_3_2
	layer_1_layer_norm_mha -> layer_1_k_proj_3_2
	layer_1_layer_norm_mha -> layer_1_v_proj_3_2
	layer_1_q_proj_3_2 -> layer_1_attention_3_2
	layer_1_k_proj_3_2 -> layer_1_attention_3_2
	layer_1_v_proj_3_2 -> layer_1_attention_3_2
	layer_1_q_proj_3_3 [label="layer_1_q_proj_3_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 15" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_k_proj_3_3 [label="layer_1_k_proj_3_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 15" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_v_proj_3_3 [label="layer_1_v_proj_3_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 15" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_attention_3_3 [label="layer_1_attention_3_3\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 15" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_layer_norm_mha -> layer_1_q_proj_3_3
	layer_1_layer_norm_mha -> layer_1_k_proj_3_3
	layer_1_layer_norm_mha -> layer_1_v_proj_3_3
	layer_1_q_proj_3_3 -> layer_1_attention_3_3
	layer_1_k_proj_3_3 -> layer_1_attention_3_3
	layer_1_v_proj_3_3 -> layer_1_attention_3_3
	layer_1_dim_aggregate_0 [label="layer_1_dim_aggregate_0\nInput: [4×[batch_size=128, seq_len=10000, heads=8, d_k=32]]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=128]\nGPU: all" fillcolor=lightgreen shape=parallelogram style=filled]
	layer_1_attention_0_0 -> layer_1_dim_aggregate_0
	layer_1_attention_0_1 -> layer_1_dim_aggregate_0
	layer_1_attention_0_2 -> layer_1_dim_aggregate_0
	layer_1_attention_0_3 -> layer_1_dim_aggregate_0
	layer_1_dim_aggregate_1 [label="layer_1_dim_aggregate_1\nInput: [4×[batch_size=128, seq_len=10000, heads=8, d_k=32]]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=128]\nGPU: all" fillcolor=lightgreen shape=parallelogram style=filled]
	layer_1_attention_1_0 -> layer_1_dim_aggregate_1
	layer_1_attention_1_1 -> layer_1_dim_aggregate_1
	layer_1_attention_1_2 -> layer_1_dim_aggregate_1
	layer_1_attention_1_3 -> layer_1_dim_aggregate_1
	layer_1_dim_aggregate_2 [label="layer_1_dim_aggregate_2\nInput: [4×[batch_size=128, seq_len=10000, heads=8, d_k=32]]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=128]\nGPU: all" fillcolor=lightgreen shape=parallelogram style=filled]
	layer_1_attention_2_0 -> layer_1_dim_aggregate_2
	layer_1_attention_2_1 -> layer_1_dim_aggregate_2
	layer_1_attention_2_2 -> layer_1_dim_aggregate_2
	layer_1_attention_2_3 -> layer_1_dim_aggregate_2
	layer_1_dim_aggregate_3 [label="layer_1_dim_aggregate_3\nInput: [4×[batch_size=128, seq_len=10000, heads=8, d_k=32]]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=128]\nGPU: all" fillcolor=lightgreen shape=parallelogram style=filled]
	layer_1_attention_3_0 -> layer_1_dim_aggregate_3
	layer_1_attention_3_1 -> layer_1_dim_aggregate_3
	layer_1_attention_3_2 -> layer_1_dim_aggregate_3
	layer_1_attention_3_3 -> layer_1_dim_aggregate_3
	layer_1_mha_aggregate [label="layer_1_mha_aggregate\nInput: [4×[batch_size=128, seq_len=10000, heads=8, d_k=128]]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightgreen shape=parallelogram style=filled]
	layer_1_dim_aggregate_0 -> layer_1_mha_aggregate
	layer_1_dim_aggregate_1 -> layer_1_mha_aggregate
	layer_1_dim_aggregate_2 -> layer_1_mha_aggregate
	layer_1_dim_aggregate_3 -> layer_1_mha_aggregate
	layer_1_residual_add_mha [label="layer_1_residual_add_mha\nInput1: [batch_size=128, seq_len=10000, hidden_size=4096]\nInput2: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightcoral shape=rectangle style=filled]
	layer_1_layer_norm_mha -> layer_1_residual_add_mha
	layer_1_mha_aggregate -> layer_1_residual_add_mha
	layer_1_layer_norm_ffn [label="layer_1_layer_norm_ffn\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightyellow shape=rectangle style=filled]
	layer_1_residual_add_mha -> layer_1_layer_norm_ffn
	layer_1_gate_proj [label="layer_1_gate_proj\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, intermediate_size=32768]\nGPU: all" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_up_proj [label="layer_1_up_proj\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, intermediate_size=32768]\nGPU: all" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_activation [label="layer_1_activation\nInput: [batch_size=128, seq_len=10000, intermediate_size=32768]\nOutput: [batch_size=128, seq_len=10000, intermediate_size=32768]\nGPU: all" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_elementwise_mul [label="layer_1_elementwise_mul\nInput1: [batch_size=128, seq_len=10000, intermediate_size=32768]\nInput2: [batch_size=128, seq_len=10000, intermediate_size=32768]\nOutput: [batch_size=128, seq_len=10000, intermediate_size=32768]\nGPU: all" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_down_proj [label="layer_1_down_proj\nInput: [batch_size=128, seq_len=10000, intermediate_size=32768]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_ffn_output [label="layer_1_ffn_output\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightgreen shape=ellipse style=filled]
	layer_1_layer_norm_ffn -> layer_1_gate_proj
	layer_1_layer_norm_ffn -> layer_1_up_proj
	layer_1_gate_proj -> layer_1_activation
	layer_1_activation -> layer_1_elementwise_mul
	layer_1_up_proj -> layer_1_elementwise_mul
	layer_1_elementwise_mul -> layer_1_down_proj
	layer_1_down_proj -> layer_1_ffn_output
	layer_1_residual_add_ffn [label="layer_1_residual_add_ffn\nInput1: [batch_size=128, seq_len=10000, hidden_size=4096]\nInput2: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightcoral shape=rectangle style=filled]
	layer_1_layer_norm_ffn -> layer_1_residual_add_ffn
	layer_1_ffn_output -> layer_1_residual_add_ffn
	layer_1_output [label="layer_1_output\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightgreen shape=ellipse style=filled]
	layer_1_residual_add_ffn -> layer_1_output
	layer_0_output -> layer_1_input
	layer_2_input [label="layer_2_input\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightblue shape=ellipse style=filled]
	layer_2_layer_norm_mha [label="layer_2_layer_norm_mha\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightyellow shape=rectangle style=filled]
	layer_2_input -> layer_2_layer_norm_mha
	layer_2_q_proj_0_0 [label="layer_2_q_proj_0_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 0" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_k_proj_0_0 [label="layer_2_k_proj_0_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 0" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_v_proj_0_0 [label="layer_2_v_proj_0_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 0" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_attention_0_0 [label="layer_2_attention_0_0\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 0" fillcolor=lightpink shape=rectangle style=filled]
	layer_2_layer_norm_mha -> layer_2_q_proj_0_0
	layer_2_layer_norm_mha -> layer_2_k_proj_0_0
	layer_2_layer_norm_mha -> layer_2_v_proj_0_0
	layer_2_q_proj_0_0 -> layer_2_attention_0_0
	layer_2_k_proj_0_0 -> layer_2_attention_0_0
	layer_2_v_proj_0_0 -> layer_2_attention_0_0
	layer_2_q_proj_0_1 [label="layer_2_q_proj_0_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 1" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_k_proj_0_1 [label="layer_2_k_proj_0_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 1" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_v_proj_0_1 [label="layer_2_v_proj_0_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 1" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_attention_0_1 [label="layer_2_attention_0_1\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 1" fillcolor=lightpink shape=rectangle style=filled]
	layer_2_layer_norm_mha -> layer_2_q_proj_0_1
	layer_2_layer_norm_mha -> layer_2_k_proj_0_1
	layer_2_layer_norm_mha -> layer_2_v_proj_0_1
	layer_2_q_proj_0_1 -> layer_2_attention_0_1
	layer_2_k_proj_0_1 -> layer_2_attention_0_1
	layer_2_v_proj_0_1 -> layer_2_attention_0_1
	layer_2_q_proj_0_2 [label="layer_2_q_proj_0_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 2" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_k_proj_0_2 [label="layer_2_k_proj_0_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 2" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_v_proj_0_2 [label="layer_2_v_proj_0_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 2" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_attention_0_2 [label="layer_2_attention_0_2\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 2" fillcolor=lightpink shape=rectangle style=filled]
	layer_2_layer_norm_mha -> layer_2_q_proj_0_2
	layer_2_layer_norm_mha -> layer_2_k_proj_0_2
	layer_2_layer_norm_mha -> layer_2_v_proj_0_2
	layer_2_q_proj_0_2 -> layer_2_attention_0_2
	layer_2_k_proj_0_2 -> layer_2_attention_0_2
	layer_2_v_proj_0_2 -> layer_2_attention_0_2
	layer_2_q_proj_0_3 [label="layer_2_q_proj_0_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 3" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_k_proj_0_3 [label="layer_2_k_proj_0_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 3" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_v_proj_0_3 [label="layer_2_v_proj_0_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 3" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_attention_0_3 [label="layer_2_attention_0_3\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 3" fillcolor=lightpink shape=rectangle style=filled]
	layer_2_layer_norm_mha -> layer_2_q_proj_0_3
	layer_2_layer_norm_mha -> layer_2_k_proj_0_3
	layer_2_layer_norm_mha -> layer_2_v_proj_0_3
	layer_2_q_proj_0_3 -> layer_2_attention_0_3
	layer_2_k_proj_0_3 -> layer_2_attention_0_3
	layer_2_v_proj_0_3 -> layer_2_attention_0_3
	layer_2_q_proj_1_0 [label="layer_2_q_proj_1_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 4" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_k_proj_1_0 [label="layer_2_k_proj_1_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 4" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_v_proj_1_0 [label="layer_2_v_proj_1_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 4" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_attention_1_0 [label="layer_2_attention_1_0\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 4" fillcolor=lightpink shape=rectangle style=filled]
	layer_2_layer_norm_mha -> layer_2_q_proj_1_0
	layer_2_layer_norm_mha -> layer_2_k_proj_1_0
	layer_2_layer_norm_mha -> layer_2_v_proj_1_0
	layer_2_q_proj_1_0 -> layer_2_attention_1_0
	layer_2_k_proj_1_0 -> layer_2_attention_1_0
	layer_2_v_proj_1_0 -> layer_2_attention_1_0
	layer_2_q_proj_1_1 [label="layer_2_q_proj_1_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 5" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_k_proj_1_1 [label="layer_2_k_proj_1_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 5" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_v_proj_1_1 [label="layer_2_v_proj_1_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 5" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_attention_1_1 [label="layer_2_attention_1_1\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 5" fillcolor=lightpink shape=rectangle style=filled]
	layer_2_layer_norm_mha -> layer_2_q_proj_1_1
	layer_2_layer_norm_mha -> layer_2_k_proj_1_1
	layer_2_layer_norm_mha -> layer_2_v_proj_1_1
	layer_2_q_proj_1_1 -> layer_2_attention_1_1
	layer_2_k_proj_1_1 -> layer_2_attention_1_1
	layer_2_v_proj_1_1 -> layer_2_attention_1_1
	layer_2_q_proj_1_2 [label="layer_2_q_proj_1_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 6" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_k_proj_1_2 [label="layer_2_k_proj_1_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 6" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_v_proj_1_2 [label="layer_2_v_proj_1_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 6" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_attention_1_2 [label="layer_2_attention_1_2\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 6" fillcolor=lightpink shape=rectangle style=filled]
	layer_2_layer_norm_mha -> layer_2_q_proj_1_2
	layer_2_layer_norm_mha -> layer_2_k_proj_1_2
	layer_2_layer_norm_mha -> layer_2_v_proj_1_2
	layer_2_q_proj_1_2 -> layer_2_attention_1_2
	layer_2_k_proj_1_2 -> layer_2_attention_1_2
	layer_2_v_proj_1_2 -> layer_2_attention_1_2
	layer_2_q_proj_1_3 [label="layer_2_q_proj_1_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 7" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_k_proj_1_3 [label="layer_2_k_proj_1_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 7" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_v_proj_1_3 [label="layer_2_v_proj_1_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 7" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_attention_1_3 [label="layer_2_attention_1_3\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 7" fillcolor=lightpink shape=rectangle style=filled]
	layer_2_layer_norm_mha -> layer_2_q_proj_1_3
	layer_2_layer_norm_mha -> layer_2_k_proj_1_3
	layer_2_layer_norm_mha -> layer_2_v_proj_1_3
	layer_2_q_proj_1_3 -> layer_2_attention_1_3
	layer_2_k_proj_1_3 -> layer_2_attention_1_3
	layer_2_v_proj_1_3 -> layer_2_attention_1_3
	layer_2_q_proj_2_0 [label="layer_2_q_proj_2_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 8" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_k_proj_2_0 [label="layer_2_k_proj_2_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 8" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_v_proj_2_0 [label="layer_2_v_proj_2_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 8" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_attention_2_0 [label="layer_2_attention_2_0\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 8" fillcolor=lightpink shape=rectangle style=filled]
	layer_2_layer_norm_mha -> layer_2_q_proj_2_0
	layer_2_layer_norm_mha -> layer_2_k_proj_2_0
	layer_2_layer_norm_mha -> layer_2_v_proj_2_0
	layer_2_q_proj_2_0 -> layer_2_attention_2_0
	layer_2_k_proj_2_0 -> layer_2_attention_2_0
	layer_2_v_proj_2_0 -> layer_2_attention_2_0
	layer_2_q_proj_2_1 [label="layer_2_q_proj_2_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 9" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_k_proj_2_1 [label="layer_2_k_proj_2_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 9" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_v_proj_2_1 [label="layer_2_v_proj_2_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 9" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_attention_2_1 [label="layer_2_attention_2_1\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 9" fillcolor=lightpink shape=rectangle style=filled]
	layer_2_layer_norm_mha -> layer_2_q_proj_2_1
	layer_2_layer_norm_mha -> layer_2_k_proj_2_1
	layer_2_layer_norm_mha -> layer_2_v_proj_2_1
	layer_2_q_proj_2_1 -> layer_2_attention_2_1
	layer_2_k_proj_2_1 -> layer_2_attention_2_1
	layer_2_v_proj_2_1 -> layer_2_attention_2_1
	layer_2_q_proj_2_2 [label="layer_2_q_proj_2_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 10" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_k_proj_2_2 [label="layer_2_k_proj_2_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 10" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_v_proj_2_2 [label="layer_2_v_proj_2_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 10" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_attention_2_2 [label="layer_2_attention_2_2\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 10" fillcolor=lightpink shape=rectangle style=filled]
	layer_2_layer_norm_mha -> layer_2_q_proj_2_2
	layer_2_layer_norm_mha -> layer_2_k_proj_2_2
	layer_2_layer_norm_mha -> layer_2_v_proj_2_2
	layer_2_q_proj_2_2 -> layer_2_attention_2_2
	layer_2_k_proj_2_2 -> layer_2_attention_2_2
	layer_2_v_proj_2_2 -> layer_2_attention_2_2
	layer_2_q_proj_2_3 [label="layer_2_q_proj_2_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 11" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_k_proj_2_3 [label="layer_2_k_proj_2_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 11" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_v_proj_2_3 [label="layer_2_v_proj_2_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 11" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_attention_2_3 [label="layer_2_attention_2_3\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 11" fillcolor=lightpink shape=rectangle style=filled]
	layer_2_layer_norm_mha -> layer_2_q_proj_2_3
	layer_2_layer_norm_mha -> layer_2_k_proj_2_3
	layer_2_layer_norm_mha -> layer_2_v_proj_2_3
	layer_2_q_proj_2_3 -> layer_2_attention_2_3
	layer_2_k_proj_2_3 -> layer_2_attention_2_3
	layer_2_v_proj_2_3 -> layer_2_attention_2_3
	layer_2_q_proj_3_0 [label="layer_2_q_proj_3_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 12" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_k_proj_3_0 [label="layer_2_k_proj_3_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 12" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_v_proj_3_0 [label="layer_2_v_proj_3_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 12" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_attention_3_0 [label="layer_2_attention_3_0\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 12" fillcolor=lightpink shape=rectangle style=filled]
	layer_2_layer_norm_mha -> layer_2_q_proj_3_0
	layer_2_layer_norm_mha -> layer_2_k_proj_3_0
	layer_2_layer_norm_mha -> layer_2_v_proj_3_0
	layer_2_q_proj_3_0 -> layer_2_attention_3_0
	layer_2_k_proj_3_0 -> layer_2_attention_3_0
	layer_2_v_proj_3_0 -> layer_2_attention_3_0
	layer_2_q_proj_3_1 [label="layer_2_q_proj_3_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 13" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_k_proj_3_1 [label="layer_2_k_proj_3_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 13" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_v_proj_3_1 [label="layer_2_v_proj_3_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 13" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_attention_3_1 [label="layer_2_attention_3_1\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 13" fillcolor=lightpink shape=rectangle style=filled]
	layer_2_layer_norm_mha -> layer_2_q_proj_3_1
	layer_2_layer_norm_mha -> layer_2_k_proj_3_1
	layer_2_layer_norm_mha -> layer_2_v_proj_3_1
	layer_2_q_proj_3_1 -> layer_2_attention_3_1
	layer_2_k_proj_3_1 -> layer_2_attention_3_1
	layer_2_v_proj_3_1 -> layer_2_attention_3_1
	layer_2_q_proj_3_2 [label="layer_2_q_proj_3_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 14" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_k_proj_3_2 [label="layer_2_k_proj_3_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 14" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_v_proj_3_2 [label="layer_2_v_proj_3_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 14" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_attention_3_2 [label="layer_2_attention_3_2\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 14" fillcolor=lightpink shape=rectangle style=filled]
	layer_2_layer_norm_mha -> layer_2_q_proj_3_2
	layer_2_layer_norm_mha -> layer_2_k_proj_3_2
	layer_2_layer_norm_mha -> layer_2_v_proj_3_2
	layer_2_q_proj_3_2 -> layer_2_attention_3_2
	layer_2_k_proj_3_2 -> layer_2_attention_3_2
	layer_2_v_proj_3_2 -> layer_2_attention_3_2
	layer_2_q_proj_3_3 [label="layer_2_q_proj_3_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 15" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_k_proj_3_3 [label="layer_2_k_proj_3_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 15" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_v_proj_3_3 [label="layer_2_v_proj_3_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 15" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_attention_3_3 [label="layer_2_attention_3_3\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 15" fillcolor=lightpink shape=rectangle style=filled]
	layer_2_layer_norm_mha -> layer_2_q_proj_3_3
	layer_2_layer_norm_mha -> layer_2_k_proj_3_3
	layer_2_layer_norm_mha -> layer_2_v_proj_3_3
	layer_2_q_proj_3_3 -> layer_2_attention_3_3
	layer_2_k_proj_3_3 -> layer_2_attention_3_3
	layer_2_v_proj_3_3 -> layer_2_attention_3_3
	layer_2_dim_aggregate_0 [label="layer_2_dim_aggregate_0\nInput: [4×[batch_size=128, seq_len=10000, heads=8, d_k=32]]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=128]\nGPU: all" fillcolor=lightgreen shape=parallelogram style=filled]
	layer_2_attention_0_0 -> layer_2_dim_aggregate_0
	layer_2_attention_0_1 -> layer_2_dim_aggregate_0
	layer_2_attention_0_2 -> layer_2_dim_aggregate_0
	layer_2_attention_0_3 -> layer_2_dim_aggregate_0
	layer_2_dim_aggregate_1 [label="layer_2_dim_aggregate_1\nInput: [4×[batch_size=128, seq_len=10000, heads=8, d_k=32]]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=128]\nGPU: all" fillcolor=lightgreen shape=parallelogram style=filled]
	layer_2_attention_1_0 -> layer_2_dim_aggregate_1
	layer_2_attention_1_1 -> layer_2_dim_aggregate_1
	layer_2_attention_1_2 -> layer_2_dim_aggregate_1
	layer_2_attention_1_3 -> layer_2_dim_aggregate_1
	layer_2_dim_aggregate_2 [label="layer_2_dim_aggregate_2\nInput: [4×[batch_size=128, seq_len=10000, heads=8, d_k=32]]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=128]\nGPU: all" fillcolor=lightgreen shape=parallelogram style=filled]
	layer_2_attention_2_0 -> layer_2_dim_aggregate_2
	layer_2_attention_2_1 -> layer_2_dim_aggregate_2
	layer_2_attention_2_2 -> layer_2_dim_aggregate_2
	layer_2_attention_2_3 -> layer_2_dim_aggregate_2
	layer_2_dim_aggregate_3 [label="layer_2_dim_aggregate_3\nInput: [4×[batch_size=128, seq_len=10000, heads=8, d_k=32]]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=128]\nGPU: all" fillcolor=lightgreen shape=parallelogram style=filled]
	layer_2_attention_3_0 -> layer_2_dim_aggregate_3
	layer_2_attention_3_1 -> layer_2_dim_aggregate_3
	layer_2_attention_3_2 -> layer_2_dim_aggregate_3
	layer_2_attention_3_3 -> layer_2_dim_aggregate_3
	layer_2_mha_aggregate [label="layer_2_mha_aggregate\nInput: [4×[batch_size=128, seq_len=10000, heads=8, d_k=128]]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightgreen shape=parallelogram style=filled]
	layer_2_dim_aggregate_0 -> layer_2_mha_aggregate
	layer_2_dim_aggregate_1 -> layer_2_mha_aggregate
	layer_2_dim_aggregate_2 -> layer_2_mha_aggregate
	layer_2_dim_aggregate_3 -> layer_2_mha_aggregate
	layer_2_residual_add_mha [label="layer_2_residual_add_mha\nInput1: [batch_size=128, seq_len=10000, hidden_size=4096]\nInput2: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightcoral shape=rectangle style=filled]
	layer_2_layer_norm_mha -> layer_2_residual_add_mha
	layer_2_mha_aggregate -> layer_2_residual_add_mha
	layer_2_layer_norm_ffn [label="layer_2_layer_norm_ffn\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightyellow shape=rectangle style=filled]
	layer_2_residual_add_mha -> layer_2_layer_norm_ffn
	layer_2_gate_proj [label="layer_2_gate_proj\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, intermediate_size=32768]\nGPU: all" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_up_proj [label="layer_2_up_proj\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, intermediate_size=32768]\nGPU: all" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_activation [label="layer_2_activation\nInput: [batch_size=128, seq_len=10000, intermediate_size=32768]\nOutput: [batch_size=128, seq_len=10000, intermediate_size=32768]\nGPU: all" fillcolor=lightpink shape=rectangle style=filled]
	layer_2_elementwise_mul [label="layer_2_elementwise_mul\nInput1: [batch_size=128, seq_len=10000, intermediate_size=32768]\nInput2: [batch_size=128, seq_len=10000, intermediate_size=32768]\nOutput: [batch_size=128, seq_len=10000, intermediate_size=32768]\nGPU: all" fillcolor=lightpink shape=rectangle style=filled]
	layer_2_down_proj [label="layer_2_down_proj\nInput: [batch_size=128, seq_len=10000, intermediate_size=32768]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightcyan shape=rectangle style=filled]
	layer_2_ffn_output [label="layer_2_ffn_output\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightgreen shape=ellipse style=filled]
	layer_2_layer_norm_ffn -> layer_2_gate_proj
	layer_2_layer_norm_ffn -> layer_2_up_proj
	layer_2_gate_proj -> layer_2_activation
	layer_2_activation -> layer_2_elementwise_mul
	layer_2_up_proj -> layer_2_elementwise_mul
	layer_2_elementwise_mul -> layer_2_down_proj
	layer_2_down_proj -> layer_2_ffn_output
	layer_2_residual_add_ffn [label="layer_2_residual_add_ffn\nInput1: [batch_size=128, seq_len=10000, hidden_size=4096]\nInput2: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightcoral shape=rectangle style=filled]
	layer_2_layer_norm_ffn -> layer_2_residual_add_ffn
	layer_2_ffn_output -> layer_2_residual_add_ffn
	layer_2_output [label="layer_2_output\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightgreen shape=ellipse style=filled]
	layer_2_residual_add_ffn -> layer_2_output
	layer_1_output -> layer_2_input
	layer_3_input [label="layer_3_input\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightblue shape=ellipse style=filled]
	layer_3_layer_norm_mha [label="layer_3_layer_norm_mha\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightyellow shape=rectangle style=filled]
	layer_3_input -> layer_3_layer_norm_mha
	layer_3_q_proj_0_0 [label="layer_3_q_proj_0_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 0" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_k_proj_0_0 [label="layer_3_k_proj_0_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 0" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_v_proj_0_0 [label="layer_3_v_proj_0_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 0" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_attention_0_0 [label="layer_3_attention_0_0\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 0" fillcolor=lightpink shape=rectangle style=filled]
	layer_3_layer_norm_mha -> layer_3_q_proj_0_0
	layer_3_layer_norm_mha -> layer_3_k_proj_0_0
	layer_3_layer_norm_mha -> layer_3_v_proj_0_0
	layer_3_q_proj_0_0 -> layer_3_attention_0_0
	layer_3_k_proj_0_0 -> layer_3_attention_0_0
	layer_3_v_proj_0_0 -> layer_3_attention_0_0
	layer_3_q_proj_0_1 [label="layer_3_q_proj_0_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 1" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_k_proj_0_1 [label="layer_3_k_proj_0_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 1" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_v_proj_0_1 [label="layer_3_v_proj_0_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 1" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_attention_0_1 [label="layer_3_attention_0_1\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 1" fillcolor=lightpink shape=rectangle style=filled]
	layer_3_layer_norm_mha -> layer_3_q_proj_0_1
	layer_3_layer_norm_mha -> layer_3_k_proj_0_1
	layer_3_layer_norm_mha -> layer_3_v_proj_0_1
	layer_3_q_proj_0_1 -> layer_3_attention_0_1
	layer_3_k_proj_0_1 -> layer_3_attention_0_1
	layer_3_v_proj_0_1 -> layer_3_attention_0_1
	layer_3_q_proj_0_2 [label="layer_3_q_proj_0_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 2" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_k_proj_0_2 [label="layer_3_k_proj_0_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 2" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_v_proj_0_2 [label="layer_3_v_proj_0_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 2" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_attention_0_2 [label="layer_3_attention_0_2\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 2" fillcolor=lightpink shape=rectangle style=filled]
	layer_3_layer_norm_mha -> layer_3_q_proj_0_2
	layer_3_layer_norm_mha -> layer_3_k_proj_0_2
	layer_3_layer_norm_mha -> layer_3_v_proj_0_2
	layer_3_q_proj_0_2 -> layer_3_attention_0_2
	layer_3_k_proj_0_2 -> layer_3_attention_0_2
	layer_3_v_proj_0_2 -> layer_3_attention_0_2
	layer_3_q_proj_0_3 [label="layer_3_q_proj_0_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 3" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_k_proj_0_3 [label="layer_3_k_proj_0_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 3" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_v_proj_0_3 [label="layer_3_v_proj_0_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 3" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_attention_0_3 [label="layer_3_attention_0_3\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 3" fillcolor=lightpink shape=rectangle style=filled]
	layer_3_layer_norm_mha -> layer_3_q_proj_0_3
	layer_3_layer_norm_mha -> layer_3_k_proj_0_3
	layer_3_layer_norm_mha -> layer_3_v_proj_0_3
	layer_3_q_proj_0_3 -> layer_3_attention_0_3
	layer_3_k_proj_0_3 -> layer_3_attention_0_3
	layer_3_v_proj_0_3 -> layer_3_attention_0_3
	layer_3_q_proj_1_0 [label="layer_3_q_proj_1_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 4" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_k_proj_1_0 [label="layer_3_k_proj_1_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 4" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_v_proj_1_0 [label="layer_3_v_proj_1_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 4" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_attention_1_0 [label="layer_3_attention_1_0\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 4" fillcolor=lightpink shape=rectangle style=filled]
	layer_3_layer_norm_mha -> layer_3_q_proj_1_0
	layer_3_layer_norm_mha -> layer_3_k_proj_1_0
	layer_3_layer_norm_mha -> layer_3_v_proj_1_0
	layer_3_q_proj_1_0 -> layer_3_attention_1_0
	layer_3_k_proj_1_0 -> layer_3_attention_1_0
	layer_3_v_proj_1_0 -> layer_3_attention_1_0
	layer_3_q_proj_1_1 [label="layer_3_q_proj_1_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 5" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_k_proj_1_1 [label="layer_3_k_proj_1_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 5" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_v_proj_1_1 [label="layer_3_v_proj_1_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 5" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_attention_1_1 [label="layer_3_attention_1_1\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 5" fillcolor=lightpink shape=rectangle style=filled]
	layer_3_layer_norm_mha -> layer_3_q_proj_1_1
	layer_3_layer_norm_mha -> layer_3_k_proj_1_1
	layer_3_layer_norm_mha -> layer_3_v_proj_1_1
	layer_3_q_proj_1_1 -> layer_3_attention_1_1
	layer_3_k_proj_1_1 -> layer_3_attention_1_1
	layer_3_v_proj_1_1 -> layer_3_attention_1_1
	layer_3_q_proj_1_2 [label="layer_3_q_proj_1_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 6" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_k_proj_1_2 [label="layer_3_k_proj_1_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 6" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_v_proj_1_2 [label="layer_3_v_proj_1_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 6" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_attention_1_2 [label="layer_3_attention_1_2\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 6" fillcolor=lightpink shape=rectangle style=filled]
	layer_3_layer_norm_mha -> layer_3_q_proj_1_2
	layer_3_layer_norm_mha -> layer_3_k_proj_1_2
	layer_3_layer_norm_mha -> layer_3_v_proj_1_2
	layer_3_q_proj_1_2 -> layer_3_attention_1_2
	layer_3_k_proj_1_2 -> layer_3_attention_1_2
	layer_3_v_proj_1_2 -> layer_3_attention_1_2
	layer_3_q_proj_1_3 [label="layer_3_q_proj_1_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 7" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_k_proj_1_3 [label="layer_3_k_proj_1_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 7" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_v_proj_1_3 [label="layer_3_v_proj_1_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 7" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_attention_1_3 [label="layer_3_attention_1_3\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 7" fillcolor=lightpink shape=rectangle style=filled]
	layer_3_layer_norm_mha -> layer_3_q_proj_1_3
	layer_3_layer_norm_mha -> layer_3_k_proj_1_3
	layer_3_layer_norm_mha -> layer_3_v_proj_1_3
	layer_3_q_proj_1_3 -> layer_3_attention_1_3
	layer_3_k_proj_1_3 -> layer_3_attention_1_3
	layer_3_v_proj_1_3 -> layer_3_attention_1_3
	layer_3_q_proj_2_0 [label="layer_3_q_proj_2_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 8" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_k_proj_2_0 [label="layer_3_k_proj_2_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 8" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_v_proj_2_0 [label="layer_3_v_proj_2_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 8" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_attention_2_0 [label="layer_3_attention_2_0\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 8" fillcolor=lightpink shape=rectangle style=filled]
	layer_3_layer_norm_mha -> layer_3_q_proj_2_0
	layer_3_layer_norm_mha -> layer_3_k_proj_2_0
	layer_3_layer_norm_mha -> layer_3_v_proj_2_0
	layer_3_q_proj_2_0 -> layer_3_attention_2_0
	layer_3_k_proj_2_0 -> layer_3_attention_2_0
	layer_3_v_proj_2_0 -> layer_3_attention_2_0
	layer_3_q_proj_2_1 [label="layer_3_q_proj_2_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 9" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_k_proj_2_1 [label="layer_3_k_proj_2_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 9" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_v_proj_2_1 [label="layer_3_v_proj_2_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 9" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_attention_2_1 [label="layer_3_attention_2_1\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 9" fillcolor=lightpink shape=rectangle style=filled]
	layer_3_layer_norm_mha -> layer_3_q_proj_2_1
	layer_3_layer_norm_mha -> layer_3_k_proj_2_1
	layer_3_layer_norm_mha -> layer_3_v_proj_2_1
	layer_3_q_proj_2_1 -> layer_3_attention_2_1
	layer_3_k_proj_2_1 -> layer_3_attention_2_1
	layer_3_v_proj_2_1 -> layer_3_attention_2_1
	layer_3_q_proj_2_2 [label="layer_3_q_proj_2_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 10" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_k_proj_2_2 [label="layer_3_k_proj_2_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 10" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_v_proj_2_2 [label="layer_3_v_proj_2_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 10" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_attention_2_2 [label="layer_3_attention_2_2\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 10" fillcolor=lightpink shape=rectangle style=filled]
	layer_3_layer_norm_mha -> layer_3_q_proj_2_2
	layer_3_layer_norm_mha -> layer_3_k_proj_2_2
	layer_3_layer_norm_mha -> layer_3_v_proj_2_2
	layer_3_q_proj_2_2 -> layer_3_attention_2_2
	layer_3_k_proj_2_2 -> layer_3_attention_2_2
	layer_3_v_proj_2_2 -> layer_3_attention_2_2
	layer_3_q_proj_2_3 [label="layer_3_q_proj_2_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 11" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_k_proj_2_3 [label="layer_3_k_proj_2_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 11" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_v_proj_2_3 [label="layer_3_v_proj_2_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 11" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_attention_2_3 [label="layer_3_attention_2_3\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 11" fillcolor=lightpink shape=rectangle style=filled]
	layer_3_layer_norm_mha -> layer_3_q_proj_2_3
	layer_3_layer_norm_mha -> layer_3_k_proj_2_3
	layer_3_layer_norm_mha -> layer_3_v_proj_2_3
	layer_3_q_proj_2_3 -> layer_3_attention_2_3
	layer_3_k_proj_2_3 -> layer_3_attention_2_3
	layer_3_v_proj_2_3 -> layer_3_attention_2_3
	layer_3_q_proj_3_0 [label="layer_3_q_proj_3_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 12" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_k_proj_3_0 [label="layer_3_k_proj_3_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 12" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_v_proj_3_0 [label="layer_3_v_proj_3_0\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 12" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_attention_3_0 [label="layer_3_attention_3_0\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 12" fillcolor=lightpink shape=rectangle style=filled]
	layer_3_layer_norm_mha -> layer_3_q_proj_3_0
	layer_3_layer_norm_mha -> layer_3_k_proj_3_0
	layer_3_layer_norm_mha -> layer_3_v_proj_3_0
	layer_3_q_proj_3_0 -> layer_3_attention_3_0
	layer_3_k_proj_3_0 -> layer_3_attention_3_0
	layer_3_v_proj_3_0 -> layer_3_attention_3_0
	layer_3_q_proj_3_1 [label="layer_3_q_proj_3_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 13" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_k_proj_3_1 [label="layer_3_k_proj_3_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 13" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_v_proj_3_1 [label="layer_3_v_proj_3_1\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 13" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_attention_3_1 [label="layer_3_attention_3_1\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 13" fillcolor=lightpink shape=rectangle style=filled]
	layer_3_layer_norm_mha -> layer_3_q_proj_3_1
	layer_3_layer_norm_mha -> layer_3_k_proj_3_1
	layer_3_layer_norm_mha -> layer_3_v_proj_3_1
	layer_3_q_proj_3_1 -> layer_3_attention_3_1
	layer_3_k_proj_3_1 -> layer_3_attention_3_1
	layer_3_v_proj_3_1 -> layer_3_attention_3_1
	layer_3_q_proj_3_2 [label="layer_3_q_proj_3_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 14" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_k_proj_3_2 [label="layer_3_k_proj_3_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 14" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_v_proj_3_2 [label="layer_3_v_proj_3_2\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 14" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_attention_3_2 [label="layer_3_attention_3_2\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 14" fillcolor=lightpink shape=rectangle style=filled]
	layer_3_layer_norm_mha -> layer_3_q_proj_3_2
	layer_3_layer_norm_mha -> layer_3_k_proj_3_2
	layer_3_layer_norm_mha -> layer_3_v_proj_3_2
	layer_3_q_proj_3_2 -> layer_3_attention_3_2
	layer_3_k_proj_3_2 -> layer_3_attention_3_2
	layer_3_v_proj_3_2 -> layer_3_attention_3_2
	layer_3_q_proj_3_3 [label="layer_3_q_proj_3_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 15" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_k_proj_3_3 [label="layer_3_k_proj_3_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 15" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_v_proj_3_3 [label="layer_3_v_proj_3_3\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 15" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_attention_3_3 [label="layer_3_attention_3_3\nInput1: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput2: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nInput3: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=32]\nGPU: 15" fillcolor=lightpink shape=rectangle style=filled]
	layer_3_layer_norm_mha -> layer_3_q_proj_3_3
	layer_3_layer_norm_mha -> layer_3_k_proj_3_3
	layer_3_layer_norm_mha -> layer_3_v_proj_3_3
	layer_3_q_proj_3_3 -> layer_3_attention_3_3
	layer_3_k_proj_3_3 -> layer_3_attention_3_3
	layer_3_v_proj_3_3 -> layer_3_attention_3_3
	layer_3_dim_aggregate_0 [label="layer_3_dim_aggregate_0\nInput: [4×[batch_size=128, seq_len=10000, heads=8, d_k=32]]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=128]\nGPU: all" fillcolor=lightgreen shape=parallelogram style=filled]
	layer_3_attention_0_0 -> layer_3_dim_aggregate_0
	layer_3_attention_0_1 -> layer_3_dim_aggregate_0
	layer_3_attention_0_2 -> layer_3_dim_aggregate_0
	layer_3_attention_0_3 -> layer_3_dim_aggregate_0
	layer_3_dim_aggregate_1 [label="layer_3_dim_aggregate_1\nInput: [4×[batch_size=128, seq_len=10000, heads=8, d_k=32]]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=128]\nGPU: all" fillcolor=lightgreen shape=parallelogram style=filled]
	layer_3_attention_1_0 -> layer_3_dim_aggregate_1
	layer_3_attention_1_1 -> layer_3_dim_aggregate_1
	layer_3_attention_1_2 -> layer_3_dim_aggregate_1
	layer_3_attention_1_3 -> layer_3_dim_aggregate_1
	layer_3_dim_aggregate_2 [label="layer_3_dim_aggregate_2\nInput: [4×[batch_size=128, seq_len=10000, heads=8, d_k=32]]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=128]\nGPU: all" fillcolor=lightgreen shape=parallelogram style=filled]
	layer_3_attention_2_0 -> layer_3_dim_aggregate_2
	layer_3_attention_2_1 -> layer_3_dim_aggregate_2
	layer_3_attention_2_2 -> layer_3_dim_aggregate_2
	layer_3_attention_2_3 -> layer_3_dim_aggregate_2
	layer_3_dim_aggregate_3 [label="layer_3_dim_aggregate_3\nInput: [4×[batch_size=128, seq_len=10000, heads=8, d_k=32]]\nOutput: [batch_size=128, seq_len=10000, heads=8, d_k=128]\nGPU: all" fillcolor=lightgreen shape=parallelogram style=filled]
	layer_3_attention_3_0 -> layer_3_dim_aggregate_3
	layer_3_attention_3_1 -> layer_3_dim_aggregate_3
	layer_3_attention_3_2 -> layer_3_dim_aggregate_3
	layer_3_attention_3_3 -> layer_3_dim_aggregate_3
	layer_3_mha_aggregate [label="layer_3_mha_aggregate\nInput: [4×[batch_size=128, seq_len=10000, heads=8, d_k=128]]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightgreen shape=parallelogram style=filled]
	layer_3_dim_aggregate_0 -> layer_3_mha_aggregate
	layer_3_dim_aggregate_1 -> layer_3_mha_aggregate
	layer_3_dim_aggregate_2 -> layer_3_mha_aggregate
	layer_3_dim_aggregate_3 -> layer_3_mha_aggregate
	layer_3_residual_add_mha [label="layer_3_residual_add_mha\nInput1: [batch_size=128, seq_len=10000, hidden_size=4096]\nInput2: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightcoral shape=rectangle style=filled]
	layer_3_layer_norm_mha -> layer_3_residual_add_mha
	layer_3_mha_aggregate -> layer_3_residual_add_mha
	layer_3_layer_norm_ffn [label="layer_3_layer_norm_ffn\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightyellow shape=rectangle style=filled]
	layer_3_residual_add_mha -> layer_3_layer_norm_ffn
	layer_3_gate_proj [label="layer_3_gate_proj\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, intermediate_size=32768]\nGPU: all" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_up_proj [label="layer_3_up_proj\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, intermediate_size=32768]\nGPU: all" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_activation [label="layer_3_activation\nInput: [batch_size=128, seq_len=10000, intermediate_size=32768]\nOutput: [batch_size=128, seq_len=10000, intermediate_size=32768]\nGPU: all" fillcolor=lightpink shape=rectangle style=filled]
	layer_3_elementwise_mul [label="layer_3_elementwise_mul\nInput1: [batch_size=128, seq_len=10000, intermediate_size=32768]\nInput2: [batch_size=128, seq_len=10000, intermediate_size=32768]\nOutput: [batch_size=128, seq_len=10000, intermediate_size=32768]\nGPU: all" fillcolor=lightpink shape=rectangle style=filled]
	layer_3_down_proj [label="layer_3_down_proj\nInput: [batch_size=128, seq_len=10000, intermediate_size=32768]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightcyan shape=rectangle style=filled]
	layer_3_ffn_output [label="layer_3_ffn_output\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightgreen shape=ellipse style=filled]
	layer_3_layer_norm_ffn -> layer_3_gate_proj
	layer_3_layer_norm_ffn -> layer_3_up_proj
	layer_3_gate_proj -> layer_3_activation
	layer_3_activation -> layer_3_elementwise_mul
	layer_3_up_proj -> layer_3_elementwise_mul
	layer_3_elementwise_mul -> layer_3_down_proj
	layer_3_down_proj -> layer_3_ffn_output
	layer_3_residual_add_ffn [label="layer_3_residual_add_ffn\nInput1: [batch_size=128, seq_len=10000, hidden_size=4096]\nInput2: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightcoral shape=rectangle style=filled]
	layer_3_layer_norm_ffn -> layer_3_residual_add_ffn
	layer_3_ffn_output -> layer_3_residual_add_ffn
	layer_3_output [label="layer_3_output\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all" fillcolor=lightgreen shape=ellipse style=filled]
	layer_3_residual_add_ffn -> layer_3_output
	layer_2_output -> layer_3_input
	final_layer_norm [label="final_layer_norm\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 0" fillcolor=lightyellow shape=rectangle style=filled]
	layer_3_output -> final_layer_norm
	model_output [label="model_output\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, vocab_size=50257]\nGPU: 0" fillcolor=darkgreen fontcolor=white shape=ellipse style=filled]
	final_layer_norm -> model_output
}
