digraph baseline_tensor_pipeline {
	graph [bgcolor=white margin=0.2 nodesep=0.5 pad=0.5 rankdir=TB ranksep=1.0]
	node [fontname=Courier fontsize=10 margin="0.1,0.05"]
	edge [fontname=Courier fontsize=8]
	model_input [label="model_input\nInput: [batch_size=128, seq_len=10000, vocab_size=50257]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 0" fillcolor=darkblue fontcolor=white shape=ellipse style=filled]
	embedding [label="embedding\nInput: [batch_size=128, seq_len=10000, vocab_size=50257]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 0" fillcolor=lightcyan shape=rectangle style=filled]
	model_input -> embedding
	stage0_input [label="stage0_input\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 0-7" fillcolor=lightblue shape=ellipse style=filled]
	embedding -> stage0_input
	layer_0_input [label="layer_0_input\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 0-7" fillcolor=lightblue shape=ellipse style=filled]
	stage0_input -> layer_0_input
	layer_0_layer_norm_mha [label="layer_0_layer_norm_mha\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 0-7" fillcolor=lightyellow shape=rectangle style=filled]
	layer_0_input -> layer_0_layer_norm_mha
	layer_0_q_proj_0 [label="layer_0_q_proj_0\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 0" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_k_proj_0 [label="layer_0_k_proj_0\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 0" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_v_proj_0 [label="layer_0_v_proj_0\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 0" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_attention_0 [label="layer_0_attention_0\nInput1: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput2: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput3: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 0" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_mha_output_0 [label="layer_0_mha_output_0\nInput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 0" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_layer_norm_mha -> layer_0_q_proj_0
	layer_0_layer_norm_mha -> layer_0_k_proj_0
	layer_0_layer_norm_mha -> layer_0_v_proj_0
	layer_0_q_proj_0 -> layer_0_attention_0
	layer_0_k_proj_0 -> layer_0_attention_0
	layer_0_v_proj_0 -> layer_0_attention_0
	layer_0_attention_0 -> layer_0_mha_output_0
	layer_0_q_proj_1 [label="layer_0_q_proj_1\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 1" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_k_proj_1 [label="layer_0_k_proj_1\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 1" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_v_proj_1 [label="layer_0_v_proj_1\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 1" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_attention_1 [label="layer_0_attention_1\nInput1: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput2: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput3: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 1" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_mha_output_1 [label="layer_0_mha_output_1\nInput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 1" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_layer_norm_mha -> layer_0_q_proj_1
	layer_0_layer_norm_mha -> layer_0_k_proj_1
	layer_0_layer_norm_mha -> layer_0_v_proj_1
	layer_0_q_proj_1 -> layer_0_attention_1
	layer_0_k_proj_1 -> layer_0_attention_1
	layer_0_v_proj_1 -> layer_0_attention_1
	layer_0_attention_1 -> layer_0_mha_output_1
	layer_0_q_proj_2 [label="layer_0_q_proj_2\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 2" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_k_proj_2 [label="layer_0_k_proj_2\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 2" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_v_proj_2 [label="layer_0_v_proj_2\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 2" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_attention_2 [label="layer_0_attention_2\nInput1: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput2: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput3: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 2" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_mha_output_2 [label="layer_0_mha_output_2\nInput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 2" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_layer_norm_mha -> layer_0_q_proj_2
	layer_0_layer_norm_mha -> layer_0_k_proj_2
	layer_0_layer_norm_mha -> layer_0_v_proj_2
	layer_0_q_proj_2 -> layer_0_attention_2
	layer_0_k_proj_2 -> layer_0_attention_2
	layer_0_v_proj_2 -> layer_0_attention_2
	layer_0_attention_2 -> layer_0_mha_output_2
	layer_0_q_proj_3 [label="layer_0_q_proj_3\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 3" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_k_proj_3 [label="layer_0_k_proj_3\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 3" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_v_proj_3 [label="layer_0_v_proj_3\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 3" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_attention_3 [label="layer_0_attention_3\nInput1: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput2: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput3: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 3" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_mha_output_3 [label="layer_0_mha_output_3\nInput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 3" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_layer_norm_mha -> layer_0_q_proj_3
	layer_0_layer_norm_mha -> layer_0_k_proj_3
	layer_0_layer_norm_mha -> layer_0_v_proj_3
	layer_0_q_proj_3 -> layer_0_attention_3
	layer_0_k_proj_3 -> layer_0_attention_3
	layer_0_v_proj_3 -> layer_0_attention_3
	layer_0_attention_3 -> layer_0_mha_output_3
	layer_0_q_proj_4 [label="layer_0_q_proj_4\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 4" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_k_proj_4 [label="layer_0_k_proj_4\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 4" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_v_proj_4 [label="layer_0_v_proj_4\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 4" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_attention_4 [label="layer_0_attention_4\nInput1: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput2: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput3: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 4" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_mha_output_4 [label="layer_0_mha_output_4\nInput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 4" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_layer_norm_mha -> layer_0_q_proj_4
	layer_0_layer_norm_mha -> layer_0_k_proj_4
	layer_0_layer_norm_mha -> layer_0_v_proj_4
	layer_0_q_proj_4 -> layer_0_attention_4
	layer_0_k_proj_4 -> layer_0_attention_4
	layer_0_v_proj_4 -> layer_0_attention_4
	layer_0_attention_4 -> layer_0_mha_output_4
	layer_0_q_proj_5 [label="layer_0_q_proj_5\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 5" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_k_proj_5 [label="layer_0_k_proj_5\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 5" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_v_proj_5 [label="layer_0_v_proj_5\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 5" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_attention_5 [label="layer_0_attention_5\nInput1: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput2: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput3: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 5" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_mha_output_5 [label="layer_0_mha_output_5\nInput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 5" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_layer_norm_mha -> layer_0_q_proj_5
	layer_0_layer_norm_mha -> layer_0_k_proj_5
	layer_0_layer_norm_mha -> layer_0_v_proj_5
	layer_0_q_proj_5 -> layer_0_attention_5
	layer_0_k_proj_5 -> layer_0_attention_5
	layer_0_v_proj_5 -> layer_0_attention_5
	layer_0_attention_5 -> layer_0_mha_output_5
	layer_0_q_proj_6 [label="layer_0_q_proj_6\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 6" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_k_proj_6 [label="layer_0_k_proj_6\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 6" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_v_proj_6 [label="layer_0_v_proj_6\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 6" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_attention_6 [label="layer_0_attention_6\nInput1: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput2: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput3: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 6" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_mha_output_6 [label="layer_0_mha_output_6\nInput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 6" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_layer_norm_mha -> layer_0_q_proj_6
	layer_0_layer_norm_mha -> layer_0_k_proj_6
	layer_0_layer_norm_mha -> layer_0_v_proj_6
	layer_0_q_proj_6 -> layer_0_attention_6
	layer_0_k_proj_6 -> layer_0_attention_6
	layer_0_v_proj_6 -> layer_0_attention_6
	layer_0_attention_6 -> layer_0_mha_output_6
	layer_0_q_proj_7 [label="layer_0_q_proj_7\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 7" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_k_proj_7 [label="layer_0_k_proj_7\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 7" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_v_proj_7 [label="layer_0_v_proj_7\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 7" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_attention_7 [label="layer_0_attention_7\nInput1: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput2: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput3: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 7" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_mha_output_7 [label="layer_0_mha_output_7\nInput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 7" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_layer_norm_mha -> layer_0_q_proj_7
	layer_0_layer_norm_mha -> layer_0_k_proj_7
	layer_0_layer_norm_mha -> layer_0_v_proj_7
	layer_0_q_proj_7 -> layer_0_attention_7
	layer_0_k_proj_7 -> layer_0_attention_7
	layer_0_v_proj_7 -> layer_0_attention_7
	layer_0_attention_7 -> layer_0_mha_output_7
	layer_0_mha_all_reduce [label="layer_0_mha_all_reduce\nInput: [8Ã—[batch_size=16, seq_len=10000, hidden_size=512]]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 0-7" fillcolor=lightgreen shape=parallelogram style=filled]
	layer_0_mha_output_0 -> layer_0_mha_all_reduce
	layer_0_mha_output_1 -> layer_0_mha_all_reduce
	layer_0_mha_output_2 -> layer_0_mha_all_reduce
	layer_0_mha_output_3 -> layer_0_mha_all_reduce
	layer_0_mha_output_4 -> layer_0_mha_all_reduce
	layer_0_mha_output_5 -> layer_0_mha_all_reduce
	layer_0_mha_output_6 -> layer_0_mha_all_reduce
	layer_0_mha_output_7 -> layer_0_mha_all_reduce
	layer_0_residual_add_mha [label="layer_0_residual_add_mha\nInput1: [batch_size=128, seq_len=10000, hidden_size=4096]\nInput2: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 0-7" fillcolor=lightcoral shape=rectangle style=filled]
	layer_0_layer_norm_mha -> layer_0_residual_add_mha
	layer_0_mha_all_reduce -> layer_0_residual_add_mha
	layer_0_layer_norm_ffn [label="layer_0_layer_norm_ffn\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 0-7" fillcolor=lightyellow shape=rectangle style=filled]
	layer_0_residual_add_mha -> layer_0_layer_norm_ffn
	layer_0_gate_proj_0 [label="layer_0_gate_proj_0\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 0" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_up_proj_0 [label="layer_0_up_proj_0\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 0" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_activation_0 [label="layer_0_activation_0\nInput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 0" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_elementwise_mul_0 [label="layer_0_elementwise_mul_0\nInput1: [batch_size=16, seq_len=10000, intermediate_size=4096]\nInput2: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 0" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_ffn_down_proj_0 [label="layer_0_ffn_down_proj_0\nInput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 0" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_layer_norm_ffn -> layer_0_gate_proj_0
	layer_0_layer_norm_ffn -> layer_0_up_proj_0
	layer_0_gate_proj_0 -> layer_0_activation_0
	layer_0_activation_0 -> layer_0_elementwise_mul_0
	layer_0_up_proj_0 -> layer_0_elementwise_mul_0
	layer_0_elementwise_mul_0 -> layer_0_ffn_down_proj_0
	layer_0_gate_proj_1 [label="layer_0_gate_proj_1\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 1" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_up_proj_1 [label="layer_0_up_proj_1\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 1" fillcolor=