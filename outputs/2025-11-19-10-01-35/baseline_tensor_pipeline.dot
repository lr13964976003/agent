digraph baseline_tensor_pipeline {
	graph [bgcolor=white margin=0.2 nodesep=0.5 pad=0.5 rankdir=TB ranksep=1.0]
	node [fontname=Courier fontsize=10 margin="0.1,0.05"]
	edge [fontname=Courier fontsize=8]
	model_input [label="model_input\nInput: [batch_size=128, seq_len=10000, vocab_size=50257]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 0" fillcolor=darkblue fontcolor=white shape=ellipse style=filled]
	embedding [label="embedding\nInput: [batch_size=128, seq_len=10000, vocab_size=50257]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 0" fillcolor=lightcyan shape=rectangle style=filled]
	model_input -> embedding
	stage0_input [label="stage0_input\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 0-7" fillcolor=lightblue shape=ellipse style=filled]
	embedding -> stage0_input
	layer_0_input [label="layer_0_input\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 0-7" fillcolor=lightblue shape=ellipse style=filled]
	stage0_input -> layer_0_input
	layer_0_layer_norm_mha [label="layer_0_layer_norm_mha\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 0-7" fillcolor=lightyellow shape=rectangle style=filled]
	layer_0_input -> layer_0_layer_norm_mha
	layer_0_q_proj_0 [label="layer_0_q_proj_0\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 0" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_k_proj_0 [label="layer_0_k_proj_0\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 0" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_v_proj_0 [label="layer_0_v_proj_0\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 0" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_attention_0 [label="layer_0_attention_0\nInput1: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput2: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput3: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 0" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_mha_output_0 [label="layer_0_mha_output_0\nInput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 0" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_layer_norm_mha -> layer_0_q_proj_0
	layer_0_layer_norm_mha -> layer_0_k_proj_0
	layer_0_layer_norm_mha -> layer_0_v_proj_0
	layer_0_q_proj_0 -> layer_0_attention_0
	layer_0_k_proj_0 -> layer_0_attention_0
	layer_0_v_proj_0 -> layer_0_attention_0
	layer_0_attention_0 -> layer_0_mha_output_0
	layer_0_q_proj_1 [label="layer_0_q_proj_1\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 1" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_k_proj_1 [label="layer_0_k_proj_1\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 1" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_v_proj_1 [label="layer_0_v_proj_1\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 1" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_attention_1 [label="layer_0_attention_1\nInput1: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput2: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput3: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 1" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_mha_output_1 [label="layer_0_mha_output_1\nInput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 1" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_layer_norm_mha -> layer_0_q_proj_1
	layer_0_layer_norm_mha -> layer_0_k_proj_1
	layer_0_layer_norm_mha -> layer_0_v_proj_1
	layer_0_q_proj_1 -> layer_0_attention_1
	layer_0_k_proj_1 -> layer_0_attention_1
	layer_0_v_proj_1 -> layer_0_attention_1
	layer_0_attention_1 -> layer_0_mha_output_1
	layer_0_q_proj_2 [label="layer_0_q_proj_2\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 2" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_k_proj_2 [label="layer_0_k_proj_2\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 2" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_v_proj_2 [label="layer_0_v_proj_2\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 2" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_attention_2 [label="layer_0_attention_2\nInput1: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput2: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput3: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 2" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_mha_output_2 [label="layer_0_mha_output_2\nInput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 2" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_layer_norm_mha -> layer_0_q_proj_2
	layer_0_layer_norm_mha -> layer_0_k_proj_2
	layer_0_layer_norm_mha -> layer_0_v_proj_2
	layer_0_q_proj_2 -> layer_0_attention_2
	layer_0_k_proj_2 -> layer_0_attention_2
	layer_0_v_proj_2 -> layer_0_attention_2
	layer_0_attention_2 -> layer_0_mha_output_2
	layer_0_q_proj_3 [label="layer_0_q_proj_3\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 3" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_k_proj_3 [label="layer_0_k_proj_3\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 3" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_v_proj_3 [label="layer_0_v_proj_3\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 3" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_attention_3 [label="layer_0_attention_3\nInput1: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput2: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput3: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 3" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_mha_output_3 [label="layer_0_mha_output_3\nInput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 3" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_layer_norm_mha -> layer_0_q_proj_3
	layer_0_layer_norm_mha -> layer_0_k_proj_3
	layer_0_layer_norm_mha -> layer_0_v_proj_3
	layer_0_q_proj_3 -> layer_0_attention_3
	layer_0_k_proj_3 -> layer_0_attention_3
	layer_0_v_proj_3 -> layer_0_attention_3
	layer_0_attention_3 -> layer_0_mha_output_3
	layer_0_q_proj_4 [label="layer_0_q_proj_4\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 4" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_k_proj_4 [label="layer_0_k_proj_4\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 4" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_v_proj_4 [label="layer_0_v_proj_4\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 4" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_attention_4 [label="layer_0_attention_4\nInput1: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput2: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput3: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 4" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_mha_output_4 [label="layer_0_mha_output_4\nInput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 4" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_layer_norm_mha -> layer_0_q_proj_4
	layer_0_layer_norm_mha -> layer_0_k_proj_4
	layer_0_layer_norm_mha -> layer_0_v_proj_4
	layer_0_q_proj_4 -> layer_0_attention_4
	layer_0_k_proj_4 -> layer_0_attention_4
	layer_0_v_proj_4 -> layer_0_attention_4
	layer_0_attention_4 -> layer_0_mha_output_4
	layer_0_q_proj_5 [label="layer_0_q_proj_5\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 5" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_k_proj_5 [label="layer_0_k_proj_5\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 5" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_v_proj_5 [label="layer_0_v_proj_5\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 5" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_attention_5 [label="layer_0_attention_5\nInput1: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput2: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput3: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 5" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_mha_output_5 [label="layer_0_mha_output_5\nInput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 5" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_layer_norm_mha -> layer_0_q_proj_5
	layer_0_layer_norm_mha -> layer_0_k_proj_5
	layer_0_layer_norm_mha -> layer_0_v_proj_5
	layer_0_q_proj_5 -> layer_0_attention_5
	layer_0_k_proj_5 -> layer_0_attention_5
	layer_0_v_proj_5 -> layer_0_attention_5
	layer_0_attention_5 -> layer_0_mha_output_5
	layer_0_q_proj_6 [label="layer_0_q_proj_6\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 6" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_k_proj_6 [label="layer_0_k_proj_6\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 6" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_v_proj_6 [label="layer_0_v_proj_6\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 6" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_attention_6 [label="layer_0_attention_6\nInput1: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput2: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput3: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 6" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_mha_output_6 [label="layer_0_mha_output_6\nInput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 6" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_layer_norm_mha -> layer_0_q_proj_6
	layer_0_layer_norm_mha -> layer_0_k_proj_6
	layer_0_layer_norm_mha -> layer_0_v_proj_6
	layer_0_q_proj_6 -> layer_0_attention_6
	layer_0_k_proj_6 -> layer_0_attention_6
	layer_0_v_proj_6 -> layer_0_attention_6
	layer_0_attention_6 -> layer_0_mha_output_6
	layer_0_q_proj_7 [label="layer_0_q_proj_7\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 7" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_k_proj_7 [label="layer_0_k_proj_7\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 7" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_v_proj_7 [label="layer_0_v_proj_7\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 7" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_attention_7 [label="layer_0_attention_7\nInput1: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput2: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput3: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 7" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_mha_output_7 [label="layer_0_mha_output_7\nInput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 7" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_layer_norm_mha -> layer_0_q_proj_7
	layer_0_layer_norm_mha -> layer_0_k_proj_7
	layer_0_layer_norm_mha -> layer_0_v_proj_7
	layer_0_q_proj_7 -> layer_0_attention_7
	layer_0_k_proj_7 -> layer_0_attention_7
	layer_0_v_proj_7 -> layer_0_attention_7
	layer_0_attention_7 -> layer_0_mha_output_7
	layer_0_mha_all_reduce [label="layer_0_mha_all_reduce\nInput: [8×[batch_size=16, seq_len=10000, hidden_size=512]]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 0-7" fillcolor=lightgreen shape=parallelogram style=filled]
	layer_0_mha_output_7 -> layer_0_mha_all_reduce
	layer_0_residual_add_mha [label="layer_0_residual_add_mha\nInput1: [batch_size=128, seq_len=10000, hidden_size=4096]\nInput2: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 0-7" fillcolor=lightcoral shape=rectangle style=filled]
	layer_0_layer_norm_mha -> layer_0_residual_add_mha
	layer_0_mha_all_reduce -> layer_0_residual_add_mha
	layer_0_layer_norm_ffn [label="layer_0_layer_norm_ffn\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 0-7" fillcolor=lightyellow shape=rectangle style=filled]
	layer_0_residual_add_mha -> layer_0_layer_norm_ffn
	layer_0_gate_proj_0 [label="layer_0_gate_proj_0\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 0" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_up_proj_0 [label="layer_0_up_proj_0\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 0" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_activation_0 [label="layer_0_activation_0\nInput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 0" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_elementwise_mul_0 [label="layer_0_elementwise_mul_0\nInput1: [batch_size=16, seq_len=10000, intermediate_size=4096]\nInput2: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 0" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_ffn_down_proj_0 [label="layer_0_ffn_down_proj_0\nInput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 0" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_layer_norm_ffn -> layer_0_gate_proj_0
	layer_0_layer_norm_ffn -> layer_0_up_proj_0
	layer_0_gate_proj_0 -> layer_0_activation_0
	layer_0_activation_0 -> layer_0_elementwise_mul_0
	layer_0_up_proj_0 -> layer_0_elementwise_mul_0
	layer_0_elementwise_mul_0 -> layer_0_ffn_down_proj_0
	layer_0_gate_proj_1 [label="layer_0_gate_proj_1\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 1" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_up_proj_1 [label="layer_0_up_proj_1\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 1" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_activation_1 [label="layer_0_activation_1\nInput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 1" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_elementwise_mul_1 [label="layer_0_elementwise_mul_1\nInput1: [batch_size=16, seq_len=10000, intermediate_size=4096]\nInput2: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 1" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_ffn_down_proj_1 [label="layer_0_ffn_down_proj_1\nInput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 1" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_layer_norm_ffn -> layer_0_gate_proj_1
	layer_0_layer_norm_ffn -> layer_0_up_proj_1
	layer_0_gate_proj_1 -> layer_0_activation_1
	layer_0_activation_1 -> layer_0_elementwise_mul_1
	layer_0_up_proj_1 -> layer_0_elementwise_mul_1
	layer_0_elementwise_mul_1 -> layer_0_ffn_down_proj_1
	layer_0_gate_proj_2 [label="layer_0_gate_proj_2\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 2" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_up_proj_2 [label="layer_0_up_proj_2\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 2" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_activation_2 [label="layer_0_activation_2\nInput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 2" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_elementwise_mul_2 [label="layer_0_elementwise_mul_2\nInput1: [batch_size=16, seq_len=10000, intermediate_size=4096]\nInput2: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 2" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_ffn_down_proj_2 [label="layer_0_ffn_down_proj_2\nInput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 2" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_layer_norm_ffn -> layer_0_gate_proj_2
	layer_0_layer_norm_ffn -> layer_0_up_proj_2
	layer_0_gate_proj_2 -> layer_0_activation_2
	layer_0_activation_2 -> layer_0_elementwise_mul_2
	layer_0_up_proj_2 -> layer_0_elementwise_mul_2
	layer_0_elementwise_mul_2 -> layer_0_ffn_down_proj_2
	layer_0_gate_proj_3 [label="layer_0_gate_proj_3\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 3" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_up_proj_3 [label="layer_0_up_proj_3\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 3" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_activation_3 [label="layer_0_activation_3\nInput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 3" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_elementwise_mul_3 [label="layer_0_elementwise_mul_3\nInput1: [batch_size=16, seq_len=10000, intermediate_size=4096]\nInput2: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 3" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_ffn_down_proj_3 [label="layer_0_ffn_down_proj_3\nInput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 3" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_layer_norm_ffn -> layer_0_gate_proj_3
	layer_0_layer_norm_ffn -> layer_0_up_proj_3
	layer_0_gate_proj_3 -> layer_0_activation_3
	layer_0_activation_3 -> layer_0_elementwise_mul_3
	layer_0_up_proj_3 -> layer_0_elementwise_mul_3
	layer_0_elementwise_mul_3 -> layer_0_ffn_down_proj_3
	layer_0_gate_proj_4 [label="layer_0_gate_proj_4\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 4" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_up_proj_4 [label="layer_0_up_proj_4\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 4" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_activation_4 [label="layer_0_activation_4\nInput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 4" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_elementwise_mul_4 [label="layer_0_elementwise_mul_4\nInput1: [batch_size=16, seq_len=10000, intermediate_size=4096]\nInput2: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 4" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_ffn_down_proj_4 [label="layer_0_ffn_down_proj_4\nInput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 4" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_layer_norm_ffn -> layer_0_gate_proj_4
	layer_0_layer_norm_ffn -> layer_0_up_proj_4
	layer_0_gate_proj_4 -> layer_0_activation_4
	layer_0_activation_4 -> layer_0_elementwise_mul_4
	layer_0_up_proj_4 -> layer_0_elementwise_mul_4
	layer_0_elementwise_mul_4 -> layer_0_ffn_down_proj_4
	layer_0_gate_proj_5 [label="layer_0_gate_proj_5\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 5" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_up_proj_5 [label="layer_0_up_proj_5\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 5" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_activation_5 [label="layer_0_activation_5\nInput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 5" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_elementwise_mul_5 [label="layer_0_elementwise_mul_5\nInput1: [batch_size=16, seq_len=10000, intermediate_size=4096]\nInput2: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 5" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_ffn_down_proj_5 [label="layer_0_ffn_down_proj_5\nInput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 5" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_layer_norm_ffn -> layer_0_gate_proj_5
	layer_0_layer_norm_ffn -> layer_0_up_proj_5
	layer_0_gate_proj_5 -> layer_0_activation_5
	layer_0_activation_5 -> layer_0_elementwise_mul_5
	layer_0_up_proj_5 -> layer_0_elementwise_mul_5
	layer_0_elementwise_mul_5 -> layer_0_ffn_down_proj_5
	layer_0_gate_proj_6 [label="layer_0_gate_proj_6\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 6" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_up_proj_6 [label="layer_0_up_proj_6\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 6" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_activation_6 [label="layer_0_activation_6\nInput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 6" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_elementwise_mul_6 [label="layer_0_elementwise_mul_6\nInput1: [batch_size=16, seq_len=10000, intermediate_size=4096]\nInput2: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 6" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_ffn_down_proj_6 [label="layer_0_ffn_down_proj_6\nInput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 6" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_layer_norm_ffn -> layer_0_gate_proj_6
	layer_0_layer_norm_ffn -> layer_0_up_proj_6
	layer_0_gate_proj_6 -> layer_0_activation_6
	layer_0_activation_6 -> layer_0_elementwise_mul_6
	layer_0_up_proj_6 -> layer_0_elementwise_mul_6
	layer_0_elementwise_mul_6 -> layer_0_ffn_down_proj_6
	layer_0_gate_proj_7 [label="layer_0_gate_proj_7\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 7" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_up_proj_7 [label="layer_0_up_proj_7\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 7" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_activation_7 [label="layer_0_activation_7\nInput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 7" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_elementwise_mul_7 [label="layer_0_elementwise_mul_7\nInput1: [batch_size=16, seq_len=10000, intermediate_size=4096]\nInput2: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 7" fillcolor=lightpink shape=rectangle style=filled]
	layer_0_ffn_down_proj_7 [label="layer_0_ffn_down_proj_7\nInput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 7" fillcolor=lightcyan shape=rectangle style=filled]
	layer_0_layer_norm_ffn -> layer_0_gate_proj_7
	layer_0_layer_norm_ffn -> layer_0_up_proj_7
	layer_0_gate_proj_7 -> layer_0_activation_7
	layer_0_activation_7 -> layer_0_elementwise_mul_7
	layer_0_up_proj_7 -> layer_0_elementwise_mul_7
	layer_0_elementwise_mul_7 -> layer_0_ffn_down_proj_7
	layer_0_ffn_all_reduce [label="layer_0_ffn_all_reduce\nInput: [8×[batch_size=16, seq_len=10000, hidden_size=512]]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 0-7" fillcolor=lightgreen shape=parallelogram style=filled]
	layer_0_ffn_down_proj_7 -> layer_0_ffn_all_reduce
	layer_0_residual_add_ffn [label="layer_0_residual_add_ffn\nInput1: [batch_size=128, seq_len=10000, hidden_size=4096]\nInput2: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 0-7" fillcolor=lightcoral shape=rectangle style=filled]
	layer_0_layer_norm_ffn -> layer_0_residual_add_ffn
	layer_0_ffn_all_reduce -> layer_0_residual_add_ffn
	layer_0_output [label="layer_0_output\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 7" fillcolor=lightgreen shape=ellipse style=filled]
	layer_0_residual_add_ffn -> layer_0_output
	stage0_output [label="stage0_output\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 7" fillcolor=lightgreen shape=ellipse style=filled]
	layer_0_output -> stage0_output
	stage1_input [label="stage1_input\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 8-15" fillcolor=lightblue shape=ellipse style=filled]
	stage0_output -> stage1_input
	layer_1_input [label="layer_1_input\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 8-15" fillcolor=lightblue shape=ellipse style=filled]
	stage1_input -> layer_1_input
	layer_1_layer_norm_mha [label="layer_1_layer_norm_mha\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 8-15" fillcolor=lightyellow shape=rectangle style=filled]
	layer_1_input -> layer_1_layer_norm_mha
	layer_1_q_proj_0 [label="layer_1_q_proj_0\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 8" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_k_proj_0 [label="layer_1_k_proj_0\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 8" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_v_proj_0 [label="layer_1_v_proj_0\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 8" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_attention_0 [label="layer_1_attention_0\nInput1: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput2: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput3: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 8" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_mha_output_0 [label="layer_1_mha_output_0\nInput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 8" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_layer_norm_mha -> layer_1_q_proj_0
	layer_1_layer_norm_mha -> layer_1_k_proj_0
	layer_1_layer_norm_mha -> layer_1_v_proj_0
	layer_1_q_proj_0 -> layer_1_attention_0
	layer_1_k_proj_0 -> layer_1_attention_0
	layer_1_v_proj_0 -> layer_1_attention_0
	layer_1_attention_0 -> layer_1_mha_output_0
	layer_1_q_proj_1 [label="layer_1_q_proj_1\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 9" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_k_proj_1 [label="layer_1_k_proj_1\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 9" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_v_proj_1 [label="layer_1_v_proj_1\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 9" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_attention_1 [label="layer_1_attention_1\nInput1: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput2: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput3: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 9" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_mha_output_1 [label="layer_1_mha_output_1\nInput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 9" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_layer_norm_mha -> layer_1_q_proj_1
	layer_1_layer_norm_mha -> layer_1_k_proj_1
	layer_1_layer_norm_mha -> layer_1_v_proj_1
	layer_1_q_proj_1 -> layer_1_attention_1
	layer_1_k_proj_1 -> layer_1_attention_1
	layer_1_v_proj_1 -> layer_1_attention_1
	layer_1_attention_1 -> layer_1_mha_output_1
	layer_1_q_proj_2 [label="layer_1_q_proj_2\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 10" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_k_proj_2 [label="layer_1_k_proj_2\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 10" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_v_proj_2 [label="layer_1_v_proj_2\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 10" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_attention_2 [label="layer_1_attention_2\nInput1: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput2: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput3: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 10" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_mha_output_2 [label="layer_1_mha_output_2\nInput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 10" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_layer_norm_mha -> layer_1_q_proj_2
	layer_1_layer_norm_mha -> layer_1_k_proj_2
	layer_1_layer_norm_mha -> layer_1_v_proj_2
	layer_1_q_proj_2 -> layer_1_attention_2
	layer_1_k_proj_2 -> layer_1_attention_2
	layer_1_v_proj_2 -> layer_1_attention_2
	layer_1_attention_2 -> layer_1_mha_output_2
	layer_1_q_proj_3 [label="layer_1_q_proj_3\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 11" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_k_proj_3 [label="layer_1_k_proj_3\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 11" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_v_proj_3 [label="layer_1_v_proj_3\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 11" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_attention_3 [label="layer_1_attention_3\nInput1: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput2: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput3: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 11" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_mha_output_3 [label="layer_1_mha_output_3\nInput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 11" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_layer_norm_mha -> layer_1_q_proj_3
	layer_1_layer_norm_mha -> layer_1_k_proj_3
	layer_1_layer_norm_mha -> layer_1_v_proj_3
	layer_1_q_proj_3 -> layer_1_attention_3
	layer_1_k_proj_3 -> layer_1_attention_3
	layer_1_v_proj_3 -> layer_1_attention_3
	layer_1_attention_3 -> layer_1_mha_output_3
	layer_1_q_proj_4 [label="layer_1_q_proj_4\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 12" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_k_proj_4 [label="layer_1_k_proj_4\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 12" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_v_proj_4 [label="layer_1_v_proj_4\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 12" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_attention_4 [label="layer_1_attention_4\nInput1: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput2: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput3: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 12" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_mha_output_4 [label="layer_1_mha_output_4\nInput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 12" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_layer_norm_mha -> layer_1_q_proj_4
	layer_1_layer_norm_mha -> layer_1_k_proj_4
	layer_1_layer_norm_mha -> layer_1_v_proj_4
	layer_1_q_proj_4 -> layer_1_attention_4
	layer_1_k_proj_4 -> layer_1_attention_4
	layer_1_v_proj_4 -> layer_1_attention_4
	layer_1_attention_4 -> layer_1_mha_output_4
	layer_1_q_proj_5 [label="layer_1_q_proj_5\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 13" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_k_proj_5 [label="layer_1_k_proj_5\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 13" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_v_proj_5 [label="layer_1_v_proj_5\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 13" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_attention_5 [label="layer_1_attention_5\nInput1: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput2: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput3: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 13" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_mha_output_5 [label="layer_1_mha_output_5\nInput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 13" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_layer_norm_mha -> layer_1_q_proj_5
	layer_1_layer_norm_mha -> layer_1_k_proj_5
	layer_1_layer_norm_mha -> layer_1_v_proj_5
	layer_1_q_proj_5 -> layer_1_attention_5
	layer_1_k_proj_5 -> layer_1_attention_5
	layer_1_v_proj_5 -> layer_1_attention_5
	layer_1_attention_5 -> layer_1_mha_output_5
	layer_1_q_proj_6 [label="layer_1_q_proj_6\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 14" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_k_proj_6 [label="layer_1_k_proj_6\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 14" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_v_proj_6 [label="layer_1_v_proj_6\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 14" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_attention_6 [label="layer_1_attention_6\nInput1: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput2: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput3: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 14" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_mha_output_6 [label="layer_1_mha_output_6\nInput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 14" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_layer_norm_mha -> layer_1_q_proj_6
	layer_1_layer_norm_mha -> layer_1_k_proj_6
	layer_1_layer_norm_mha -> layer_1_v_proj_6
	layer_1_q_proj_6 -> layer_1_attention_6
	layer_1_k_proj_6 -> layer_1_attention_6
	layer_1_v_proj_6 -> layer_1_attention_6
	layer_1_attention_6 -> layer_1_mha_output_6
	layer_1_q_proj_7 [label="layer_1_q_proj_7\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 15" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_k_proj_7 [label="layer_1_k_proj_7\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 15" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_v_proj_7 [label="layer_1_v_proj_7\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 15" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_attention_7 [label="layer_1_attention_7\nInput1: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput2: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nInput3: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nGPU: 15" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_mha_output_7 [label="layer_1_mha_output_7\nInput: [batch_size=16, seq_len=10000, heads=4, d_k=128]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 15" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_layer_norm_mha -> layer_1_q_proj_7
	layer_1_layer_norm_mha -> layer_1_k_proj_7
	layer_1_layer_norm_mha -> layer_1_v_proj_7
	layer_1_q_proj_7 -> layer_1_attention_7
	layer_1_k_proj_7 -> layer_1_attention_7
	layer_1_v_proj_7 -> layer_1_attention_7
	layer_1_attention_7 -> layer_1_mha_output_7
	layer_1_mha_all_reduce [label="layer_1_mha_all_reduce\nInput: [8×[batch_size=16, seq_len=10000, hidden_size=512]]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 8-15" fillcolor=lightgreen shape=parallelogram style=filled]
	layer_1_mha_output_7 -> layer_1_mha_all_reduce
	layer_1_residual_add_mha [label="layer_1_residual_add_mha\nInput1: [batch_size=128, seq_len=10000, hidden_size=4096]\nInput2: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 8-15" fillcolor=lightcoral shape=rectangle style=filled]
	layer_1_layer_norm_mha -> layer_1_residual_add_mha
	layer_1_mha_all_reduce -> layer_1_residual_add_mha
	layer_1_layer_norm_ffn [label="layer_1_layer_norm_ffn\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 8-15" fillcolor=lightyellow shape=rectangle style=filled]
	layer_1_residual_add_mha -> layer_1_layer_norm_ffn
	layer_1_gate_proj_0 [label="layer_1_gate_proj_0\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 8" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_up_proj_0 [label="layer_1_up_proj_0\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 8" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_activation_0 [label="layer_1_activation_0\nInput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 8" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_elementwise_mul_0 [label="layer_1_elementwise_mul_0\nInput1: [batch_size=16, seq_len=10000, intermediate_size=4096]\nInput2: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 8" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_ffn_down_proj_0 [label="layer_1_ffn_down_proj_0\nInput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 8" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_layer_norm_ffn -> layer_1_gate_proj_0
	layer_1_layer_norm_ffn -> layer_1_up_proj_0
	layer_1_gate_proj_0 -> layer_1_activation_0
	layer_1_activation_0 -> layer_1_elementwise_mul_0
	layer_1_up_proj_0 -> layer_1_elementwise_mul_0
	layer_1_elementwise_mul_0 -> layer_1_ffn_down_proj_0
	layer_1_gate_proj_1 [label="layer_1_gate_proj_1\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 9" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_up_proj_1 [label="layer_1_up_proj_1\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 9" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_activation_1 [label="layer_1_activation_1\nInput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 9" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_elementwise_mul_1 [label="layer_1_elementwise_mul_1\nInput1: [batch_size=16, seq_len=10000, intermediate_size=4096]\nInput2: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 9" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_ffn_down_proj_1 [label="layer_1_ffn_down_proj_1\nInput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 9" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_layer_norm_ffn -> layer_1_gate_proj_1
	layer_1_layer_norm_ffn -> layer_1_up_proj_1
	layer_1_gate_proj_1 -> layer_1_activation_1
	layer_1_activation_1 -> layer_1_elementwise_mul_1
	layer_1_up_proj_1 -> layer_1_elementwise_mul_1
	layer_1_elementwise_mul_1 -> layer_1_ffn_down_proj_1
	layer_1_gate_proj_2 [label="layer_1_gate_proj_2\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 10" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_up_proj_2 [label="layer_1_up_proj_2\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 10" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_activation_2 [label="layer_1_activation_2\nInput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 10" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_elementwise_mul_2 [label="layer_1_elementwise_mul_2\nInput1: [batch_size=16, seq_len=10000, intermediate_size=4096]\nInput2: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 10" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_ffn_down_proj_2 [label="layer_1_ffn_down_proj_2\nInput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 10" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_layer_norm_ffn -> layer_1_gate_proj_2
	layer_1_layer_norm_ffn -> layer_1_up_proj_2
	layer_1_gate_proj_2 -> layer_1_activation_2
	layer_1_activation_2 -> layer_1_elementwise_mul_2
	layer_1_up_proj_2 -> layer_1_elementwise_mul_2
	layer_1_elementwise_mul_2 -> layer_1_ffn_down_proj_2
	layer_1_gate_proj_3 [label="layer_1_gate_proj_3\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 11" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_up_proj_3 [label="layer_1_up_proj_3\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 11" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_activation_3 [label="layer_1_activation_3\nInput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 11" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_elementwise_mul_3 [label="layer_1_elementwise_mul_3\nInput1: [batch_size=16, seq_len=10000, intermediate_size=4096]\nInput2: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 11" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_ffn_down_proj_3 [label="layer_1_ffn_down_proj_3\nInput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 11" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_layer_norm_ffn -> layer_1_gate_proj_3
	layer_1_layer_norm_ffn -> layer_1_up_proj_3
	layer_1_gate_proj_3 -> layer_1_activation_3
	layer_1_activation_3 -> layer_1_elementwise_mul_3
	layer_1_up_proj_3 -> layer_1_elementwise_mul_3
	layer_1_elementwise_mul_3 -> layer_1_ffn_down_proj_3
	layer_1_gate_proj_4 [label="layer_1_gate_proj_4\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 12" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_up_proj_4 [label="layer_1_up_proj_4\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 12" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_activation_4 [label="layer_1_activation_4\nInput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 12" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_elementwise_mul_4 [label="layer_1_elementwise_mul_4\nInput1: [batch_size=16, seq_len=10000, intermediate_size=4096]\nInput2: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 12" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_ffn_down_proj_4 [label="layer_1_ffn_down_proj_4\nInput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 12" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_layer_norm_ffn -> layer_1_gate_proj_4
	layer_1_layer_norm_ffn -> layer_1_up_proj_4
	layer_1_gate_proj_4 -> layer_1_activation_4
	layer_1_activation_4 -> layer_1_elementwise_mul_4
	layer_1_up_proj_4 -> layer_1_elementwise_mul_4
	layer_1_elementwise_mul_4 -> layer_1_ffn_down_proj_4
	layer_1_gate_proj_5 [label="layer_1_gate_proj_5\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 13" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_up_proj_5 [label="layer_1_up_proj_5\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 13" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_activation_5 [label="layer_1_activation_5\nInput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 13" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_elementwise_mul_5 [label="layer_1_elementwise_mul_5\nInput1: [batch_size=16, seq_len=10000, intermediate_size=4096]\nInput2: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 13" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_ffn_down_proj_5 [label="layer_1_ffn_down_proj_5\nInput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 13" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_layer_norm_ffn -> layer_1_gate_proj_5
	layer_1_layer_norm_ffn -> layer_1_up_proj_5
	layer_1_gate_proj_5 -> layer_1_activation_5
	layer_1_activation_5 -> layer_1_elementwise_mul_5
	layer_1_up_proj_5 -> layer_1_elementwise_mul_5
	layer_1_elementwise_mul_5 -> layer_1_ffn_down_proj_5
	layer_1_gate_proj_6 [label="layer_1_gate_proj_6\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 14" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_up_proj_6 [label="layer_1_up_proj_6\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 14" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_activation_6 [label="layer_1_activation_6\nInput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 14" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_elementwise_mul_6 [label="layer_1_elementwise_mul_6\nInput1: [batch_size=16, seq_len=10000, intermediate_size=4096]\nInput2: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 14" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_ffn_down_proj_6 [label="layer_1_ffn_down_proj_6\nInput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 14" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_layer_norm_ffn -> layer_1_gate_proj_6
	layer_1_layer_norm_ffn -> layer_1_up_proj_6
	layer_1_gate_proj_6 -> layer_1_activation_6
	layer_1_activation_6 -> layer_1_elementwise_mul_6
	layer_1_up_proj_6 -> layer_1_elementwise_mul_6
	layer_1_elementwise_mul_6 -> layer_1_ffn_down_proj_6
	layer_1_gate_proj_7 [label="layer_1_gate_proj_7\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 15" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_up_proj_7 [label="layer_1_up_proj_7\nInput: [batch_size=16, seq_len=10000, hidden_size=512]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 15" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_activation_7 [label="layer_1_activation_7\nInput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 15" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_elementwise_mul_7 [label="layer_1_elementwise_mul_7\nInput1: [batch_size=16, seq_len=10000, intermediate_size=4096]\nInput2: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nGPU: 15" fillcolor=lightpink shape=rectangle style=filled]
	layer_1_ffn_down_proj_7 [label="layer_1_ffn_down_proj_7\nInput: [batch_size=16, seq_len=10000, intermediate_size=4096]\nOutput: [batch_size=16, seq_len=10000, hidden_size=512]\nGPU: 15" fillcolor=lightcyan shape=rectangle style=filled]
	layer_1_layer_norm_ffn -> layer_1_gate_proj_7
	layer_1_layer_norm_ffn -> layer_1_up_proj_7
	layer_1_gate_proj_7 -> layer_1_activation_7
	layer_1_activation_7 -> layer_1_elementwise_mul_7
	layer_1_up_proj_7 -> layer_1_elementwise_mul_7
	layer_1_elementwise_mul_7 -> layer_1_ffn_down_proj_7
	layer_1_ffn_all_reduce [label="layer_1_ffn_all_reduce\nInput: [8×[batch_size=16, seq_len=10000, hidden_size=512]]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 8-15" fillcolor=lightgreen shape=parallelogram style=filled]
	layer_1_ffn_down_proj_7 -> layer_1_ffn_all_reduce
	layer_1_residual_add_ffn [label="layer_1_residual_add_ffn\nInput1: [batch_size=128, seq_len=10000, hidden_size=4096]\nInput2: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 8-15" fillcolor=lightcoral shape=rectangle style=filled]
	layer_1_layer_norm_ffn -> layer_1_residual_add_ffn
	layer_1_ffn_all_reduce -> layer_1_residual_add_ffn
	layer_1_output [label="layer_1_output\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 15" fillcolor=lightgreen shape=ellipse style=filled]
	layer_1_residual_add_ffn -> layer_1_output
	stage1_output [label="stage1_output\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 15" fillcolor=lightgreen shape=ellipse style=filled]
	layer_1_output -> stage1_output
	final_layer_norm [label="final_layer_norm\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 8" fillcolor=lightyellow shape=rectangle style=filled]
	stage1_output -> final_layer_norm
	model_output [label="model_output\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, vocab_size=50257]\nGPU: 8" fillcolor=darkgreen fontcolor=white shape=ellipse style=filled]
	final_layer_norm -> model_output
}
