// Layer 3 - MA Separation
digraph layer_3_ma {
	nodesep=0.3 rankdir=TB ranksep=0.8 splines=ortho
	node [fillcolor=lightblue shape=rectangle style=filled]
	layer3_input [label="Layer 3 Input
Input: [1024,2048,4096]
GPU: all GPUs" fillcolor=lightgreen shape=ellipse]
	subgraph cluster_attn_group_3 {
		color=red label="Attention Group (GPUs 0-7)" style=dashed
		l3_q_gpu0 [label="Q Projection GPU0
Input: [1024,2048,4096]
Output: [1024,2048,128]
GPU: 0" fillcolor=yellow]
		l3_k_gpu0 [label="K Projection GPU0
Input: [1024,2048,4096]
Output: [1024,2048,128]
GPU: 0" fillcolor=yellow]
		l3_v_gpu0 [label="V Projection GPU0
Input: [1024,2048,4096]
Output: [1024,2048,128]
GPU: 0" fillcolor=yellow]
		l3_kv_gather_gpu0 [label="Gather K,V
Input: [1024,2048,128]
Output: [1024,2048,1024]
GPU: 0" fillcolor=lightcyan shape=parallelogram]
		l3_attn_gpu0 [label="Multi-Head Attention GPU0
Input: Q=[1024,2048,128], K=[1024,2048,1024], V=[1024,2048,1024]
Output: [1024,2048,512]
GPU: 0" fillcolor=lightblue]
		l3_proj_gpu0 [label="Output Projection GPU0
Input: [1024,2048,512]
Output: [1024,2048,4096]
GPU: 0" fillcolor=yellow]
		l3_q_gpu1 [label="Q Projection GPU1
Input: [1024,2048,4096]
Output: [1024,2048,128]
GPU: 1" fillcolor=yellow]
		l3_k_gpu1 [label="K Projection GPU1
Input: [1024,2048,4096]
Output: [1024,2048,128]
GPU: 1" fillcolor=yellow]
		l3_v_gpu1 [label="V Projection GPU1
Input: [1024,2048,4096]
Output: [1024,2048,128]
GPU: 1" fillcolor=yellow]
		l3_kv_gather_gpu1 [label="Gather K,V
Input: [1024,2048,128]
Output: [1024,2048,1024]
GPU: 1" fillcolor=lightcyan shape=parallelogram]
		l3_attn_gpu1 [label="Multi-Head Attention GPU1
Input: Q=[1024,2048,128], K=[1024,2048,1024], V=[1024,2048,1024]
Output: [1024,2048,512]
GPU: 1" fillcolor=lightblue]
		l3_proj_gpu1 [label="Output Projection GPU1
Input: [1024,2048,512]
Output: [1024,2048,4096]
GPU: 1" fillcolor=yellow]
		l3_q_gpu2 [label="Q Projection GPU2
Input: [1024,2048,4096]
Output: [1024,2048,128]
GPU: 2" fillcolor=yellow]
		l3_k_gpu2 [label="K Projection GPU2
Input: [1024,2048,4096]
Output: [1024,2048,128]
GPU: 2" fillcolor=yellow]
		l3_v_gpu2 [label="V Projection GPU2
Input: [1024,2048,4096]
Output: [1024,2048,128]
GPU: 2" fillcolor=yellow]
		l3_kv_gather_gpu2 [label="Gather K,V
Input: [1024,2048,128]
Output: [1024,2048,1024]
GPU: 2" fillcolor=lightcyan shape=parallelogram]
		l3_attn_gpu2 [label="Multi-Head Attention GPU2
Input: Q=[1024,2048,128], K=[1024,2048,1024], V=[1024,2048,1024]
Output: [1024,2048,512]
GPU: 2" fillcolor=lightblue]
		l3_proj_gpu2 [label="Output Projection GPU2
Input: [1024,2048,512]
Output: [1024,2048,4096]
GPU: 2" fillcolor=yellow]
		l3_q_gpu3 [label="Q Projection GPU3
Input: [1024,2048,4096]
Output: [1024,2048,128]
GPU: 3" fillcolor=yellow]
		l3_k_gpu3 [label="K Projection GPU3
Input: [1024,2048,4096]
Output: [1024,2048,128]
GPU: 3" fillcolor=yellow]
		l3_v_gpu3 [label="V Projection GPU3
Input: [1024,2048,4096]
Output: [1024,2048,128]
GPU: 3" fillcolor=yellow]
		l3_kv_gather_gpu3 [label="Gather K,V
Input: [1024,2048,128]
Output: [1024,2048,1024]
GPU: 3" fillcolor=lightcyan shape=parallelogram]
		l3_attn_gpu3 [label="Multi-Head Attention GPU3
Input: Q=[1024,2048,128], K=[1024,2048,1024], V=[1024,2048,1024]
Output: [1024,2048,512]
GPU: 3" fillcolor=lightblue]
		l3_proj_gpu3 [label="Output Projection GPU3
Input: [1024,2048,512]
Output: [1024,2048,4096]
GPU: 3" fillcolor=yellow]
		l3_q_gpu4 [label="Q Projection GPU4
Input: [1024,2048,4096]
Output: [1024,2048,128]
GPU: 4" fillcolor=yellow]
		l3_k_gpu4 [label="K Projection GPU4
Input: [1024,2048,4096]
Output: [1024,2048,128]
GPU: 4" fillcolor=yellow]
		l3_v_gpu4 [label="V Projection GPU4
Input: [1024,2048,4096]
Output: [1024,2048,128]
GPU: 4" fillcolor=yellow]
		l3_kv_gather_gpu4 [label="Gather K,V
Input: [1024,2048,128]
Output: [1024,2048,1024]
GPU: 4" fillcolor=lightcyan shape=parallelogram]
		l3_attn_gpu4 [label="Multi-Head Attention GPU4
Input: Q=[1024,2048,128], K=[1024,2048,1024], V=[1024,2048,1024]
Output: [1024,2048,512]
GPU: 4" fillcolor=lightblue]
		l3_proj_gpu4 [label="Output Projection GPU4
Input: [1024,2048,512]
Output: [1024,2048,4096]
GPU: 4" fillcolor=yellow]
		l3_q_gpu5 [label="Q Projection GPU5
Input: [1024,2048,4096]
Output: [1024,2048,128]
GPU: 5" fillcolor=yellow]
		l3_k_gpu5 [label="K Projection GPU5
Input: [1024,2048,4096]
Output: [1024,2048,128]
GPU: 5" fillcolor=yellow]
		l3_v_gpu5 [label="V Projection GPU5
Input: [1024,2048,4096]
Output: [1024,2048,128]
GPU: 5" fillcolor=yellow]
		l3_kv_gather_gpu5 [label="Gather K,V
Input: [1024,2048,128]
Output: [1024,2048,1024]
GPU: 5" fillcolor=lightcyan shape=parallelogram]
		l3_attn_gpu5 [label="Multi-Head Attention GPU5
Input: Q=[1024,2048,128], K=[1024,2048,1024], V=[1024,2048,1024]
Output: [1024,2048,512]
GPU: 5" fillcolor=lightblue]
		l3_proj_gpu5 [label="Output Projection GPU5
Input: [1024,2048,512]
Output: [1024,2048,4096]
GPU: 5" fillcolor=yellow]
		l3_q_gpu6 [label="Q Projection GPU6
Input: [1024,2048,4096]
Output: [1024,2048,128]
GPU: 6" fillcolor=yellow]
		l3_k_gpu6 [label="K Projection GPU6
Input: [1024,2048,4096]
Output: [1024,2048,128]
GPU: 6" fillcolor=yellow]
		l3_v_gpu6 [label="V Projection GPU6
Input: [1024,2048,4096]
Output: [1024,2048,128]
GPU: 6" fillcolor=yellow]
		l3_kv_gather_gpu6 [label="Gather K,V
Input: [1024,2048,128]
Output: [1024,2048,1024]
GPU: 6" fillcolor=lightcyan shape=parallelogram]
		l3_attn_gpu6 [label="Multi-Head Attention GPU6
Input: Q=[1024,2048,128], K=[1024,2048,1024], V=[1024,2048,1024]
Output: [1024,2048,512]
GPU: 6" fillcolor=lightblue]
		l3_proj_gpu6 [label="Output Projection GPU6
Input: [1024,2048,512]
Output: [1024,2048,4096]
GPU: 6" fillcolor=yellow]
		l3_q_gpu7 [label="Q Projection GPU7
Input: [1024,2048,4096]
Output: [1024,2048,128]
GPU: 7" fillcolor=yellow]
		l3_k_gpu7 [label="K Projection GPU7
Input: [1024,2048,4096]
Output: [1024,2048,128]
GPU: 7" fillcolor=yellow]
		l3_v_gpu7 [label="V Projection GPU7
Input: [1024,2048,4096]
Output: [1024,2048,128]
GPU: 7" fillcolor=yellow]
		l3_kv_gather_gpu7 [label="Gather K,V
Input: [1024,2048,128]
Output: [1024,2048,1024]
GPU: 7" fillcolor=lightcyan shape=parallelogram]
		l3_attn_gpu7 [label="Multi-Head Attention GPU7
Input: Q=[1024,2048,128], K=[1024,2048,1024], V=[1024,2048,1024]
Output: [1024,2048,512]
GPU: 7" fillcolor=lightblue]
		l3_proj_gpu7 [label="Output Projection GPU7
Input: [1024,2048,512]
Output: [1024,2048,4096]
GPU: 7" fillcolor=yellow]
		l3_attn_allreduce [label="All-Reduce Attention
Input: [1024,2048,4096]×8
Output: [1024,2048,4096]
GPU: 0-7" fillcolor=lightcyan shape=parallelogram]
		l3_attn_res [label="Residual Add
Input: [1024,2048,4096], [1024,2048,4096]
Output: [1024,2048,4096]
GPU: 0-7" fillcolor=orange]
	}
	l3_attn_moe_comm [label="Broadcast to MoE
Input: [1024,2048,4096]
Output: [1024,2048,4096]×8
GPU: 0-7 → 8-15" fillcolor=gray shape=parallelogram]
	subgraph cluster_moe_group_3 {
		color=blue label="MoE Group (GPUs 8-15)" style=dashed
		l3_gate [label="Gate Network
Input: [1024,2048,4096]
Output: [1024,2048,16]
GPU: 8-15" fillcolor=lightcoral]
		l3_router [label="Top-2 Router
Input: [1024,2048,16]
Output: routing decisions
GPU: 8-15" fillcolor=lightgreen shape=parallelogram]
		l3_expert0_gpu8 [label="Expert 0
Input: [1024,2048,4096]
Output: [1024,2048,16384]
GPU: 8" fillcolor=lightpink]
		l3_expert1_gpu8 [label="Expert 1
Input: [1024,2048,4096]
Output: [1024,2048,16384]
GPU: 8" fillcolor=lightpink]
		l3_expert_down_gpu8 [label="Expert Down Proj GPU8
Input: [1024,2048,16384]
Output: [1024,2048,4096]
GPU: 8" fillcolor=lightpink]
		l3_expert2_gpu9 [label="Expert 2
Input: [1024,2048,4096]
Output: [1024,2048,16384]
GPU: 9" fillcolor=lightpink]
		l3_expert3_gpu9 [label="Expert 3
Input: [1024,2048,4096]
Output: [1024,2048,16384]
GPU: 9" fillcolor=lightpink]
		l3_expert_down_gpu9 [label="Expert Down Proj GPU9
Input: [1024,2048,16384]
Output: [1024,2048,4096]
GPU: 9" fillcolor=lightpink]
		l3_expert4_gpu10 [label="Expert 4
Input: [1024,2048,4096]
Output: [1024,2048,16384]
GPU: 10" fillcolor=lightpink]
		l3_expert5_gpu10 [label="Expert 5
Input: [1024,2048,4096]
Output: [1024,2048,16384]
GPU: 10" fillcolor=lightpink]
		l3_expert_down_gpu10 [label="Expert Down Proj GPU10
Input: [1024,2048,16384]
Output: [1024,2048,4096]
GPU: 10" fillcolor=lightpink]
		l3_expert6_gpu11 [label="Expert 6
Input: [1024,2048,4096]
Output: [1024,2048,16384]
GPU: 11" fillcolor=lightpink]
		l3_expert7_gpu11 [label="Expert 7
Input: [1024,2048,4096]
Output: [1024,2048,16384]
GPU: 11" fillcolor=lightpink]
		l3_expert_down_gpu11 [label="Expert Down Proj GPU11
Input: [1024,2048,16384]
Output: [1024,2048,4096]
GPU: 11" fillcolor=lightpink]
		l3_expert8_gpu12 [label="Expert 8
Input: [1024,2048,4096]
Output: [1024,2048,16384]
GPU: 12" fillcolor=lightpink]
		l3_expert9_gpu12 [label="Expert 9
Input: [1024,2048,4096]
Output: [1024,2048,16384]
GPU: 12" fillcolor=lightpink]
		l3_expert_down_gpu12 [label="Expert Down Proj GPU12
Input: [1024,2048,16384]
Output: [1024,2048,4096]
GPU: 12" fillcolor=lightpink]
		l3_expert10_gpu13 [label="Expert 10
Input: [1024,2048,4096]
Output: [1024,2048,16384]
GPU: 13" fillcolor=lightpink]
		l3_expert11_gpu13 [label="Expert 11
Input: [1024,2048,4096]
Output: [1024,2048,16384]
GPU: 13" fillcolor=lightpink]
		l3_expert_down_gpu13 [label="Expert Down Proj GPU13
Input: [1024,2048,16384]
Output: [1024,2048,4096]
GPU: 13" fillcolor=lightpink]
		l3_expert12_gpu14 [label="Expert 12
Input: [1024,2048,4096]
Output: [1024,2048,16384]
GPU: 14" fillcolor=lightpink]
		l3_expert13_gpu14 [label="Expert 13
Input: [1024,2048,4096]
Output: [1024,2048,16384]
GPU: 14" fillcolor=lightpink]
		l3_expert_down_gpu14 [label="Expert Down Proj GPU14
Input: [1024,2048,16384]
Output: [1024,2048,4096]
GPU: 14" fillcolor=lightpink]
		l3_expert14_gpu15 [label="Expert 14
Input: [1024,2048,4096]
Output: [1024,2048,16384]
GPU: 15" fillcolor=lightpink]
		l3_expert15_gpu15 [label="Expert 15
Input: [1024,2048,4096]
Output: [1024,2048,16384]
GPU: 15" fillcolor=lightpink]
		l3_expert_down_gpu15 [label="Expert Down Proj GPU15
Input: [1024,2048,16384]
Output: [1024,2048,4096]
GPU: 15" fillcolor=lightpink]
		l3_moe_agg [label="Expert Aggregation
Input: [1024,2048,4096]×2
Output: [1024,2048,4096]
GPU: 8-15" fillcolor=lightcyan shape=parallelogram]
		l3_moe_res [label="Residual Add
Input: [1024,2048,4096], [1024,2048,4096]
Output: [1024,2048,4096]
GPU: 8-15" fillcolor=orange]
	}
	layer3_input -> l3_q_gpu0
	layer3_input -> l3_q_gpu1
	layer3_input -> l3_q_gpu2
	layer3_input -> l3_q_gpu3
	layer3_input -> l3_q_gpu4
	layer3_input -> l3_q_gpu5
	layer3_input -> l3_q_gpu6
	layer3_input -> l3_q_gpu7
	layer3_input -> l3_k_gpu0
	layer3_input -> l3_v_gpu0
	l3_q_gpu0 -> l3_attn_gpu0
	l3_k_gpu0 -> l3_kv_gather_gpu0
	l3_v_gpu0 -> l3_kv_gather_gpu0
	l3_kv_gather_gpu0 -> l3_attn_gpu0
	l3_attn_gpu0 -> l3_proj_gpu0
	l3_proj_gpu0 -> l3_attn_allreduce
	layer3_input -> l3_k_gpu1
	layer3_input -> l3_v_gpu1
	l3_q_gpu1 -> l3_attn_gpu1
	l3_k_gpu1 -> l3_kv_gather_gpu1
	l3_v_gpu1 -> l3_kv_gather_gpu1
	l3_kv_gather_gpu1 -> l3_attn_gpu1
	l3_attn_gpu1 -> l3_proj_gpu1
	l3_proj_gpu1 -> l3_attn_allreduce
	layer3_input -> l3_k_gpu2
	layer3_input -> l3_v_gpu2
	l3_q_gpu2 -> l3_attn_gpu2
	l3_k_gpu2 -> l3_kv_gather_gpu2
	l3_v_gpu2 -> l3_kv_gather_gpu2
	l3_kv_gather_gpu2 -> l3_attn_gpu2
	l3_attn_gpu2 -> l3_proj_gpu2
	l3_proj_gpu2 -> l3_attn_allreduce
	layer3_input -> l3_k_gpu3
	layer3_input -> l3_v_gpu3
	l3_q_gpu3 -> l3_attn_gpu3
	l3_k_gpu3 -> l3_kv_gather_gpu3
	l3_v_gpu3 -> l3_kv_gather_gpu3
	l3_kv_gather_gpu3 -> l3_attn_gpu3
	l3_attn_gpu3 -> l3_proj_gpu3
	l3_proj_gpu3 -> l3_attn_allreduce
	layer3_input -> l3_k_gpu4
	layer3_input -> l3_v_gpu4
	l3_q_gpu4 -> l3_attn_gpu4
	l3_k_gpu4 -> l3_kv_gather_gpu4
	l3_v_gpu4 -> l3_kv_gather_gpu4
	l3_kv_gather_gpu4 -> l3_attn_gpu4
	l3_attn_gpu4 -> l3_proj_gpu4
	l3_proj_gpu4 -> l3_attn_allreduce
	layer3_input -> l3_k_gpu5
	layer3_input -> l3_v_gpu5
	l3_q_gpu5 -> l3_attn_gpu5
	l3_k_gpu5 -> l3_kv_gather_gpu5
	l3_v_gpu5 -> l3_kv_gather_gpu5
	l3_kv_gather_gpu5 -> l3_attn_gpu5
	l3_attn_gpu5 -> l3_proj_gpu5
	l3_proj_gpu5 -> l3_attn_allreduce
	layer3_input -> l3_k_gpu6
	layer3_input -> l3_v_gpu6
	l3_q_gpu6 -> l3_attn_gpu6
	l3_k_gpu6 -> l3_kv_gather_gpu6
	l3_v_gpu6 -> l3_kv_gather_gpu6
	l3_kv_gather_gpu6 -> l3_attn_gpu6
	l3_attn_gpu6 -> l3_proj_gpu6
	l3_proj_gpu6 -> l3_attn_allreduce
	layer3_input -> l3_k_gpu7
	layer3_input -> l3_v_gpu7
	l3_q_gpu7 -> l3_attn_gpu7
	l3_k_gpu7 -> l3_kv_gather_gpu7
	l3_v_gpu7 -> l3_kv_gather_gpu7
	l3_kv_gather_gpu7 -> l3_attn_gpu7
	l3_attn_gpu7 -> l3_proj_gpu7
	l3_proj_gpu7 -> l3_attn_allreduce
	l3_attn_allreduce -> l3_attn_res
	layer3_input -> l3_attn_res
	l3_attn_res -> l3_attn_moe_comm
	l3_attn_moe_comm -> l3_gate
	l3_attn_moe_comm -> l3_router
	l3_router -> "l3_expert-8_gpu8" [style=dashed]
	l3_router -> "l3_expert-7_gpu8" [style=dashed]
	l3_attn_moe_comm -> "l3_expert-8_gpu8"
	l3_attn_moe_comm -> "l3_expert-7_gpu8"
	"l3_expert-8_gpu8" -> l3_expert_down_gpu8
	"l3_expert-7_gpu8" -> l3_expert_down_gpu8
	l3_expert_down_gpu8 -> l3_moe_agg
	l3_router -> "l3_expert-7_gpu9" [style=dashed]
	l3_router -> "l3_expert-6_gpu9" [style=dashed]
	l3_attn_moe_comm -> "l3_expert-7_gpu9"
	l3_attn_moe_comm -> "l3_expert-6_gpu9"
	"l3_expert-7_gpu9" -> l3_expert_down_gpu9
	"l3_expert-6_gpu9" -> l3_expert_down_gpu9
	l3_expert_down_gpu9 -> l3_moe_agg
	l3_router -> "l3_expert-6_gpu10" [style=dashed]
	l3_router -> "l3_expert-5_gpu10" [style=dashed]
	l3_attn_moe_comm -> "l3_expert-6_gpu10"
	l3_attn_moe_comm -> "l3_expert-5_gpu10"
	"l3_expert-6_gpu10" -> l3_expert_down_gpu10
	"l3_expert-5_gpu10" -> l3_expert_down_gpu10
	l3_expert_down_gpu10 -> l3_moe_agg
	l3_router -> "l3_expert-5_gpu11" [style=dashed]
	l3_router -> "l3_expert-4_gpu11" [style=dashed]
	l3_attn_moe_comm -> "l3_expert-5_gpu11"
	l3_attn_moe_comm -> "l3_expert-4_gpu11"
	"l3_expert-5_gpu11" -> l3_expert_down_gpu11
	"l3_expert-4_gpu11" -> l3_expert_down_gpu11
	l3_expert_down_gpu11 -> l3_moe_agg
	l3_router -> "l3_expert-4_gpu12" [style=dashed]
	l3_router -> "l3_expert-3_gpu12" [style=dashed]
	l3_attn_moe_comm -> "l3_expert-4_gpu12"
	l3_attn_moe_comm -> "l3_expert-3_gpu12"
	"l3_expert-4_gpu12" -> l3_expert_down_gpu12
	"l3_expert-3_gpu12" -> l3_expert_down_gpu12
	l3_expert_down_gpu12 -> l3_moe_agg
	l3_router -> "l3_expert-3_gpu13" [style=dashed]
	l3_router -> "l3_expert-2_gpu13" [style=dashed]
	l3_attn_moe_comm -> "l3_expert-3_gpu13"
	l3_attn_moe_comm -> "l3_expert-2_gpu13"
	"l3_expert-3_gpu13" -> l3_expert_down_gpu13
	"l3_expert-2_gpu13" -> l3_expert_down_gpu13
	l3_expert_down_gpu13 -> l3_moe_agg
	l3_router -> "l3_expert-2_gpu14" [style=dashed]
	l3_router -> "l3_expert-1_gpu14" [style=dashed]
	l3_attn_moe_comm -> "l3_expert-2_gpu14"
	l3_attn_moe_comm -> "l3_expert-1_gpu14"
	"l3_expert-2_gpu14" -> l3_expert_down_gpu14
	"l3_expert-1_gpu14" -> l3_expert_down_gpu14
	l3_expert_down_gpu14 -> l3_moe_agg
	l3_router -> "l3_expert-1_gpu15" [style=dashed]
	l3_router -> l3_expert0_gpu15 [style=dashed]
	l3_attn_moe_comm -> "l3_expert-1_gpu15"
	l3_attn_moe_comm -> l3_expert0_gpu15
	"l3_expert-1_gpu15" -> l3_expert_down_gpu15
	l3_expert0_gpu15 -> l3_expert_down_gpu15
	l3_expert_down_gpu15 -> l3_moe_agg
	l3_moe_agg -> l3_moe_res
	l3_attn_moe_comm -> l3_moe_res
}
