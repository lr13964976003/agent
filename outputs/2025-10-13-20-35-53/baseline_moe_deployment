digraph baseline_moe_deployment {
	rankdir=TB splines=ortho
	node [fillcolor=lightblue shape=ellipse style=filled]
	input [label="Input\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]\nGPU: all GPUs" fillcolor=lightgreen shape=ellipse]
	node [fillcolor=lightcoral shape=rectangle]
	mha_qkv_l0_g0 [label="MHA QKV Linear Layer 0\nGPU 0\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nType: Column-parallel" fillcolor=lightcoral]
	mha_attn_l0_g0 [label="MHA Attention Layer 0\nGPU 0\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_out_l0_g0 [label="MHA Output Linear Layer 0\nGPU 0\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, dim=1024]\nType: Row-parallel" fillcolor=lightcoral]
	mha_qkv_l0_g1 [label="MHA QKV Linear Layer 0\nGPU 1\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nType: Column-parallel" fillcolor=lightcoral]
	mha_attn_l0_g1 [label="MHA Attention Layer 0\nGPU 1\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_out_l0_g1 [label="MHA Output Linear Layer 0\nGPU 1\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, dim=1024]\nType: Row-parallel" fillcolor=lightcoral]
	mha_qkv_l0_g2 [label="MHA QKV Linear Layer 0\nGPU 2\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nType: Column-parallel" fillcolor=lightcoral]
	mha_attn_l0_g2 [label="MHA Attention Layer 0\nGPU 2\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_out_l0_g2 [label="MHA Output Linear Layer 0\nGPU 2\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, dim=1024]\nType: Row-parallel" fillcolor=lightcoral]
	mha_qkv_l0_g3 [label="MHA QKV Linear Layer 0\nGPU 3\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nType: Column-parallel" fillcolor=lightcoral]
	mha_attn_l0_g3 [label="MHA Attention Layer 0\nGPU 3\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_out_l0_g3 [label="MHA Output Linear Layer 0\nGPU 3\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, dim=1024]\nType: Row-parallel" fillcolor=lightcoral]
	mha_qkv_l0_g4 [label="MHA QKV Linear Layer 0\nGPU 4\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nType: Column-parallel" fillcolor=lightcoral]
	mha_attn_l0_g4 [label="MHA Attention Layer 0\nGPU 4\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_out_l0_g4 [label="MHA Output Linear Layer 0\nGPU 4\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, dim=1024]\nType: Row-parallel" fillcolor=lightcoral]
	mha_qkv_l0_g5 [label="MHA QKV Linear Layer 0\nGPU 5\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nType: Column-parallel" fillcolor=lightcoral]
	mha_attn_l0_g5 [label="MHA Attention Layer 0\nGPU 5\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_out_l0_g5 [label="MHA Output Linear Layer 0\nGPU 5\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, dim=1024]\nType: Row-parallel" fillcolor=lightcoral]
	mha_qkv_l0_g6 [label="MHA QKV Linear Layer 0\nGPU 6\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nType: Column-parallel" fillcolor=lightcoral]
	mha_attn_l0_g6 [label="MHA Attention Layer 0\nGPU 6\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_out_l0_g6 [label="MHA Output Linear Layer 0\nGPU 6\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, dim=1024]\nType: Row-parallel" fillcolor=lightcoral]
	mha_qkv_l0_g7 [label="MHA QKV Linear Layer 0\nGPU 7\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nType: Column-parallel" fillcolor=lightcoral]
	mha_attn_l0_g7 [label="MHA Attention Layer 0\nGPU 7\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_out_l0_g7 [label="MHA Output Linear Layer 0\nGPU 7\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, dim=1024]\nType: Row-parallel" fillcolor=lightcoral]
	node [fillcolor=lightyellow shape=parallelogram]
	allreduce_l0_g0 [label="All-Reduce Sum\nLayer 0\nGPU 0\nInput: [batch_size=1024, seq_len=10000, dim=1024]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	residual_l0_g0 [label="Residual Add\nLayer 0\nGPU 0\nInput1: [batch_size=1024, seq_len=10000, dim=8192]\nInput2: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	allreduce_l0_g1 [label="All-Reduce Sum\nLayer 0\nGPU 1\nInput: [batch_size=1024, seq_len=10000, dim=1024]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	residual_l0_g1 [label="Residual Add\nLayer 0\nGPU 1\nInput1: [batch_size=1024, seq_len=10000, dim=8192]\nInput2: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	allreduce_l0_g2 [label="All-Reduce Sum\nLayer 0\nGPU 2\nInput: [batch_size=1024, seq_len=10000, dim=1024]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	residual_l0_g2 [label="Residual Add\nLayer 0\nGPU 2\nInput1: [batch_size=1024, seq_len=10000, dim=8192]\nInput2: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	allreduce_l0_g3 [label="All-Reduce Sum\nLayer 0\nGPU 3\nInput: [batch_size=1024, seq_len=10000, dim=1024]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	residual_l0_g3 [label="Residual Add\nLayer 0\nGPU 3\nInput1: [batch_size=1024, seq_len=10000, dim=8192]\nInput2: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	allreduce_l0_g4 [label="All-Reduce Sum\nLayer 0\nGPU 4\nInput: [batch_size=1024, seq_len=10000, dim=1024]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	residual_l0_g4 [label="Residual Add\nLayer 0\nGPU 4\nInput1: [batch_size=1024, seq_len=10000, dim=8192]\nInput2: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	allreduce_l0_g5 [label="All-Reduce Sum\nLayer 0\nGPU 5\nInput: [batch_size=1024, seq_len=10000, dim=1024]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	residual_l0_g5 [label="Residual Add\nLayer 0\nGPU 5\nInput1: [batch_size=1024, seq_len=10000, dim=8192]\nInput2: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	allreduce_l0_g6 [label="All-Reduce Sum\nLayer 0\nGPU 6\nInput: [batch_size=1024, seq_len=10000, dim=1024]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	residual_l0_g6 [label="Residual Add\nLayer 0\nGPU 6\nInput1: [batch_size=1024, seq_len=10000, dim=8192]\nInput2: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	allreduce_l0_g7 [label="All-Reduce Sum\nLayer 0\nGPU 7\nInput: [batch_size=1024, seq_len=10000, dim=1024]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	residual_l0_g7 [label="Residual Add\nLayer 0\nGPU 7\nInput1: [batch_size=1024, seq_len=10000, dim=8192]\nInput2: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	node [fillcolor=lightgreen shape=rectangle]
	gate_l0_g0 [label="Gating Network\nLayer 0\nGPU 0\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l0_e0_g0 [label="Expert 0\nLayer 0\nGPU 0\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l0_g1 [label="Gating Network\nLayer 0\nGPU 1\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l0_e1_g1 [label="Expert 1\nLayer 0\nGPU 1\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l0_g2 [label="Gating Network\nLayer 0\nGPU 2\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l0_e2_g2 [label="Expert 2\nLayer 0\nGPU 2\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l0_g3 [label="Gating Network\nLayer 0\nGPU 3\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l0_e3_g3 [label="Expert 3\nLayer 0\nGPU 3\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l0_g4 [label="Gating Network\nLayer 0\nGPU 4\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l0_e4_g4 [label="Expert 4\nLayer 0\nGPU 4\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l0_g5 [label="Gating Network\nLayer 0\nGPU 5\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l0_e5_g5 [label="Expert 5\nLayer 0\nGPU 5\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l0_g6 [label="Gating Network\nLayer 0\nGPU 6\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l0_e6_g6 [label="Expert 6\nLayer 0\nGPU 6\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l0_g7 [label="Gating Network\nLayer 0\nGPU 7\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l0_e7_g7 [label="Expert 7\nLayer 0\nGPU 7\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l0_g8 [label="Gating Network\nLayer 0\nGPU 8\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l0_e8_g8 [label="Expert 8\nLayer 0\nGPU 8\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l0_g9 [label="Gating Network\nLayer 0\nGPU 9\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l0_e9_g9 [label="Expert 9\nLayer 0\nGPU 9\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l0_g10 [label="Gating Network\nLayer 0\nGPU 10\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l0_e10_g10 [label="Expert 10\nLayer 0\nGPU 10\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l0_g11 [label="Gating Network\nLayer 0\nGPU 11\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l0_e11_g11 [label="Expert 11\nLayer 0\nGPU 11\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l0_g12 [label="Gating Network\nLayer 0\nGPU 12\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l0_e12_g12 [label="Expert 12\nLayer 0\nGPU 12\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l0_g13 [label="Gating Network\nLayer 0\nGPU 13\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l0_e13_g13 [label="Expert 13\nLayer 0\nGPU 13\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l0_g14 [label="Gating Network\nLayer 0\nGPU 14\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l0_e14_g14 [label="Expert 14\nLayer 0\nGPU 14\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l0_g15 [label="Gating Network\nLayer 0\nGPU 15\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l0_e15_g15 [label="Expert 15\nLayer 0\nGPU 15\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	node [fillcolor=lightyellow shape=parallelogram]
	aggregate_l0_g0 [label="Expert Aggregation\nLayer 0\nGPU 0\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l0_g1 [label="Expert Aggregation\nLayer 0\nGPU 1\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l0_g2 [label="Expert Aggregation\nLayer 0\nGPU 2\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l0_g3 [label="Expert Aggregation\nLayer 0\nGPU 3\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l0_g4 [label="Expert Aggregation\nLayer 0\nGPU 4\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l0_g5 [label="Expert Aggregation\nLayer 0\nGPU 5\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l0_g6 [label="Expert Aggregation\nLayer 0\nGPU 6\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l0_g7 [label="Expert Aggregation\nLayer 0\nGPU 7\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l0_g8 [label="Expert Aggregation\nLayer 0\nGPU 8\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l0_g9 [label="Expert Aggregation\nLayer 0\nGPU 9\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l0_g10 [label="Expert Aggregation\nLayer 0\nGPU 10\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l0_g11 [label="Expert Aggregation\nLayer 0\nGPU 11\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l0_g12 [label="Expert Aggregation\nLayer 0\nGPU 12\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l0_g13 [label="Expert Aggregation\nLayer 0\nGPU 13\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l0_g14 [label="Expert Aggregation\nLayer 0\nGPU 14\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l0_g15 [label="Expert Aggregation\nLayer 0\nGPU 15\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	node [fillcolor=lightcoral shape=rectangle]
	mha_qkv_l1_g0 [label="MHA QKV Linear Layer 1\nGPU 0\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_attn_l1_g0 [label="MHA Attention Layer 1\nGPU 0\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_out_l1_g0 [label="MHA Output Linear Layer 1\nGPU 0\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, dim=1024]" fillcolor=lightcoral]
	mha_qkv_l1_g1 [label="MHA QKV Linear Layer 1\nGPU 1\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_attn_l1_g1 [label="MHA Attention Layer 1\nGPU 1\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_out_l1_g1 [label="MHA Output Linear Layer 1\nGPU 1\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, dim=1024]" fillcolor=lightcoral]
	mha_qkv_l1_g2 [label="MHA QKV Linear Layer 1\nGPU 2\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_attn_l1_g2 [label="MHA Attention Layer 1\nGPU 2\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_out_l1_g2 [label="MHA Output Linear Layer 1\nGPU 2\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, dim=1024]" fillcolor=lightcoral]
	mha_qkv_l1_g3 [label="MHA QKV Linear Layer 1\nGPU 3\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_attn_l1_g3 [label="MHA Attention Layer 1\nGPU 3\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_out_l1_g3 [label="MHA Output Linear Layer 1\nGPU 3\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, dim=1024]" fillcolor=lightcoral]
	mha_qkv_l1_g4 [label="MHA QKV Linear Layer 1\nGPU 4\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_attn_l1_g4 [label="MHA Attention Layer 1\nGPU 4\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_out_l1_g4 [label="MHA Output Linear Layer 1\nGPU 4\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, dim=1024]" fillcolor=lightcoral]
	mha_qkv_l1_g5 [label="MHA QKV Linear Layer 1\nGPU 5\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_attn_l1_g5 [label="MHA Attention Layer 1\nGPU 5\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_out_l1_g5 [label="MHA Output Linear Layer 1\nGPU 5\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, dim=1024]" fillcolor=lightcoral]
	mha_qkv_l1_g6 [label="MHA QKV Linear Layer 1\nGPU 6\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_attn_l1_g6 [label="MHA Attention Layer 1\nGPU 6\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_out_l1_g6 [label="MHA Output Linear Layer 1\nGPU 6\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, dim=1024]" fillcolor=lightcoral]
	mha_qkv_l1_g7 [label="MHA QKV Linear Layer 1\nGPU 7\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_attn_l1_g7 [label="MHA Attention Layer 1\nGPU 7\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_out_l1_g7 [label="MHA Output Linear Layer 1\nGPU 7\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, dim=1024]" fillcolor=lightcoral]
	node [fillcolor=lightyellow shape=parallelogram]
	allreduce_l1_g0 [label="All-Reduce Sum\nLayer 1\nGPU 0\nInput: [batch_size=1024, seq_len=10000, dim=1024]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	residual_l1_g0 [label="Residual Add\nLayer 1\nGPU 0\nInput1: [batch_size=1024, seq_len=10000, dim=8192]\nInput2: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	allreduce_l1_g1 [label="All-Reduce Sum\nLayer 1\nGPU 1\nInput: [batch_size=1024, seq_len=10000, dim=1024]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	residual_l1_g1 [label="Residual Add\nLayer 1\nGPU 1\nInput1: [batch_size=1024, seq_len=10000, dim=8192]\nInput2: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	allreduce_l1_g2 [label="All-Reduce Sum\nLayer 1\nGPU 2\nInput: [batch_size=1024, seq_len=10000, dim=1024]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	residual_l1_g2 [label="Residual Add\nLayer 1\nGPU 2\nInput1: [batch_size=1024, seq_len=10000, dim=8192]\nInput2: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	allreduce_l1_g3 [label="All-Reduce Sum\nLayer 1\nGPU 3\nInput: [batch_size=1024, seq_len=10000, dim=1024]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	residual_l1_g3 [label="Residual Add\nLayer 1\nGPU 3\nInput1: [batch_size=1024, seq_len=10000, dim=8192]\nInput2: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	allreduce_l1_g4 [label="All-Reduce Sum\nLayer 1\nGPU 4\nInput: [batch_size=1024, seq_len=10000, dim=1024]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	residual_l1_g4 [label="Residual Add\nLayer 1\nGPU 4\nInput1: [batch_size=1024, seq_len=10000, dim=8192]\nInput2: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	allreduce_l1_g5 [label="All-Reduce Sum\nLayer 1\nGPU 5\nInput: [batch_size=1024, seq_len=10000, dim=1024]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	residual_l1_g5 [label="Residual Add\nLayer 1\nGPU 5\nInput1: [batch_size=1024, seq_len=10000, dim=8192]\nInput2: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	allreduce_l1_g6 [label="All-Reduce Sum\nLayer 1\nGPU 6\nInput: [batch_size=1024, seq_len=10000, dim=1024]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	residual_l1_g6 [label="Residual Add\nLayer 1\nGPU 6\nInput1: [batch_size=1024, seq_len=10000, dim=8192]\nInput2: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	allreduce_l1_g7 [label="All-Reduce Sum\nLayer 1\nGPU 7\nInput: [batch_size=1024, seq_len=10000, dim=1024]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	residual_l1_g7 [label="Residual Add\nLayer 1\nGPU 7\nInput1: [batch_size=1024, seq_len=10000, dim=8192]\nInput2: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	node [fillcolor=lightgreen shape=rectangle]
	gate_l1_g0 [label="Gating Network\nLayer 1\nGPU 0\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l1_e0_g0 [label="Expert 0\nLayer 1\nGPU 0\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l1_g1 [label="Gating Network\nLayer 1\nGPU 1\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l1_e1_g1 [label="Expert 1\nLayer 1\nGPU 1\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l1_g2 [label="Gating Network\nLayer 1\nGPU 2\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l1_e2_g2 [label="Expert 2\nLayer 1\nGPU 2\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l1_g3 [label="Gating Network\nLayer 1\nGPU 3\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l1_e3_g3 [label="Expert 3\nLayer 1\nGPU 3\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l1_g4 [label="Gating Network\nLayer 1\nGPU 4\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l1_e4_g4 [label="Expert 4\nLayer 1\nGPU 4\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l1_g5 [label="Gating Network\nLayer 1\nGPU 5\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l1_e5_g5 [label="Expert 5\nLayer 1\nGPU 5\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l1_g6 [label="Gating Network\nLayer 1\nGPU 6\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l1_e6_g6 [label="Expert 6\nLayer 1\nGPU 6\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l1_g7 [label="Gating Network\nLayer 1\nGPU 7\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l1_e7_g7 [label="Expert 7\nLayer 1\nGPU 7\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l1_g8 [label="Gating Network\nLayer 1\nGPU 8\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l1_e8_g8 [label="Expert 8\nLayer 1\nGPU 8\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l1_g9 [label="Gating Network\nLayer 1\nGPU 9\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l1_e9_g9 [label="Expert 9\nLayer 1\nGPU 9\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l1_g10 [label="Gating Network\nLayer 1\nGPU 10\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l1_e10_g10 [label="Expert 10\nLayer 1\nGPU 10\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l1_g11 [label="Gating Network\nLayer 1\nGPU 11\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l1_e11_g11 [label="Expert 11\nLayer 1\nGPU 11\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l1_g12 [label="Gating Network\nLayer 1\nGPU 12\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l1_e12_g12 [label="Expert 12\nLayer 1\nGPU 12\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l1_g13 [label="Gating Network\nLayer 1\nGPU 13\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l1_e13_g13 [label="Expert 13\nLayer 1\nGPU 13\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l1_g14 [label="Gating Network\nLayer 1\nGPU 14\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l1_e14_g14 [label="Expert 14\nLayer 1\nGPU 14\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l1_g15 [label="Gating Network\nLayer 1\nGPU 15\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l1_e15_g15 [label="Expert 15\nLayer 1\nGPU 15\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	node [fillcolor=lightyellow shape=parallelogram]
	aggregate_l1_g0 [label="Expert Aggregation\nLayer 1\nGPU 0\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l1_g1 [label="Expert Aggregation\nLayer 1\nGPU 1\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l1_g2 [label="Expert Aggregation\nLayer 1\nGPU 2\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l1_g3 [label="Expert Aggregation\nLayer 1\nGPU 3\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l1_g4 [label="Expert Aggregation\nLayer 1\nGPU 4\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l1_g5 [label="Expert Aggregation\nLayer 1\nGPU 5\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l1_g6 [label="Expert Aggregation\nLayer 1\nGPU 6\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l1_g7 [label="Expert Aggregation\nLayer 1\nGPU 7\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l1_g8 [label="Expert Aggregation\nLayer 1\nGPU 8\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l1_g9 [label="Expert Aggregation\nLayer 1\nGPU 9\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l1_g10 [label="Expert Aggregation\nLayer 1\nGPU 10\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l1_g11 [label="Expert Aggregation\nLayer 1\nGPU 11\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l1_g12 [label="Expert Aggregation\nLayer 1\nGPU 12\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l1_g13 [label="Expert Aggregation\nLayer 1\nGPU 13\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l1_g14 [label="Expert Aggregation\nLayer 1\nGPU 14\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l1_g15 [label="Expert Aggregation\nLayer 1\nGPU 15\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	node [fillcolor=lightcoral shape=rectangle]
	mha_qkv_l2_g0 [label="MHA QKV Linear Layer 2\nGPU 0\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_attn_l2_g0 [label="MHA Attention Layer 2\nGPU 0\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_out_l2_g0 [label="MHA Output Linear Layer 2\nGPU 0\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, dim=1024]" fillcolor=lightcoral]
	mha_qkv_l2_g1 [label="MHA QKV Linear Layer 2\nGPU 1\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_attn_l2_g1 [label="MHA Attention Layer 2\nGPU 1\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_out_l2_g1 [label="MHA Output Linear Layer 2\nGPU 1\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, dim=1024]" fillcolor=lightcoral]
	mha_qkv_l2_g2 [label="MHA QKV Linear Layer 2\nGPU 2\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_attn_l2_g2 [label="MHA Attention Layer 2\nGPU 2\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_out_l2_g2 [label="MHA Output Linear Layer 2\nGPU 2\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, dim=1024]" fillcolor=lightcoral]
	mha_qkv_l2_g3 [label="MHA QKV Linear Layer 2\nGPU 3\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_attn_l2_g3 [label="MHA Attention Layer 2\nGPU 3\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_out_l2_g3 [label="MHA Output Linear Layer 2\nGPU 3\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, dim=1024]" fillcolor=lightcoral]
	mha_qkv_l2_g4 [label="MHA QKV Linear Layer 2\nGPU 4\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_attn_l2_g4 [label="MHA Attention Layer 2\nGPU 4\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_out_l2_g4 [label="MHA Output Linear Layer 2\nGPU 4\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, dim=1024]" fillcolor=lightcoral]
	mha_qkv_l2_g5 [label="MHA QKV Linear Layer 2\nGPU 5\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_attn_l2_g5 [label="MHA Attention Layer 2\nGPU 5\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_out_l2_g5 [label="MHA Output Linear Layer 2\nGPU 5\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, dim=1024]" fillcolor=lightcoral]
	mha_qkv_l2_g6 [label="MHA QKV Linear Layer 2\nGPU 6\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_attn_l2_g6 [label="MHA Attention Layer 2\nGPU 6\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_out_l2_g6 [label="MHA Output Linear Layer 2\nGPU 6\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, dim=1024]" fillcolor=lightcoral]
	mha_qkv_l2_g7 [label="MHA QKV Linear Layer 2\nGPU 7\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_attn_l2_g7 [label="MHA Attention Layer 2\nGPU 7\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_out_l2_g7 [label="MHA Output Linear Layer 2\nGPU 7\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, dim=1024]" fillcolor=lightcoral]
	node [fillcolor=lightyellow shape=parallelogram]
	allreduce_l2_g0 [label="All-Reduce Sum\nLayer 2\nGPU 0\nInput: [batch_size=1024, seq_len=10000, dim=1024]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	residual_l2_g0 [label="Residual Add\nLayer 2\nGPU 0\nInput1: [batch_size=1024, seq_len=10000, dim=8192]\nInput2: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	allreduce_l2_g1 [label="All-Reduce Sum\nLayer 2\nGPU 1\nInput: [batch_size=1024, seq_len=10000, dim=1024]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	residual_l2_g1 [label="Residual Add\nLayer 2\nGPU 1\nInput1: [batch_size=1024, seq_len=10000, dim=8192]\nInput2: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	allreduce_l2_g2 [label="All-Reduce Sum\nLayer 2\nGPU 2\nInput: [batch_size=1024, seq_len=10000, dim=1024]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	residual_l2_g2 [label="Residual Add\nLayer 2\nGPU 2\nInput1: [batch_size=1024, seq_len=10000, dim=8192]\nInput2: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	allreduce_l2_g3 [label="All-Reduce Sum\nLayer 2\nGPU 3\nInput: [batch_size=1024, seq_len=10000, dim=1024]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	residual_l2_g3 [label="Residual Add\nLayer 2\nGPU 3\nInput1: [batch_size=1024, seq_len=10000, dim=8192]\nInput2: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	allreduce_l2_g4 [label="All-Reduce Sum\nLayer 2\nGPU 4\nInput: [batch_size=1024, seq_len=10000, dim=1024]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	residual_l2_g4 [label="Residual Add\nLayer 2\nGPU 4\nInput1: [batch_size=1024, seq_len=10000, dim=8192]\nInput2: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	allreduce_l2_g5 [label="All-Reduce Sum\nLayer 2\nGPU 5\nInput: [batch_size=1024, seq_len=10000, dim=1024]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	residual_l2_g5 [label="Residual Add\nLayer 2\nGPU 5\nInput1: [batch_size=1024, seq_len=10000, dim=8192]\nInput2: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	allreduce_l2_g6 [label="All-Reduce Sum\nLayer 2\nGPU 6\nInput: [batch_size=1024, seq_len=10000, dim=1024]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	residual_l2_g6 [label="Residual Add\nLayer 2\nGPU 6\nInput1: [batch_size=1024, seq_len=10000, dim=8192]\nInput2: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	allreduce_l2_g7 [label="All-Reduce Sum\nLayer 2\nGPU 7\nInput: [batch_size=1024, seq_len=10000, dim=1024]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	residual_l2_g7 [label="Residual Add\nLayer 2\nGPU 7\nInput1: [batch_size=1024, seq_len=10000, dim=8192]\nInput2: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	node [fillcolor=lightgreen shape=rectangle]
	gate_l2_g0 [label="Gating Network\nLayer 2\nGPU 0\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l2_e0_g0 [label="Expert 0\nLayer 2\nGPU 0\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l2_g1 [label="Gating Network\nLayer 2\nGPU 1\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l2_e1_g1 [label="Expert 1\nLayer 2\nGPU 1\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l2_g2 [label="Gating Network\nLayer 2\nGPU 2\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l2_e2_g2 [label="Expert 2\nLayer 2\nGPU 2\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l2_g3 [label="Gating Network\nLayer 2\nGPU 3\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l2_e3_g3 [label="Expert 3\nLayer 2\nGPU 3\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l2_g4 [label="Gating Network\nLayer 2\nGPU 4\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l2_e4_g4 [label="Expert 4\nLayer 2\nGPU 4\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l2_g5 [label="Gating Network\nLayer 2\nGPU 5\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l2_e5_g5 [label="Expert 5\nLayer 2\nGPU 5\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l2_g6 [label="Gating Network\nLayer 2\nGPU 6\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l2_e6_g6 [label="Expert 6\nLayer 2\nGPU 6\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l2_g7 [label="Gating Network\nLayer 2\nGPU 7\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l2_e7_g7 [label="Expert 7\nLayer 2\nGPU 7\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l2_g8 [label="Gating Network\nLayer 2\nGPU 8\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l2_e8_g8 [label="Expert 8\nLayer 2\nGPU 8\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l2_g9 [label="Gating Network\nLayer 2\nGPU 9\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l2_e9_g9 [label="Expert 9\nLayer 2\nGPU 9\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l2_g10 [label="Gating Network\nLayer 2\nGPU 10\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l2_e10_g10 [label="Expert 10\nLayer 2\nGPU 10\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l2_g11 [label="Gating Network\nLayer 2\nGPU 11\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l2_e11_g11 [label="Expert 11\nLayer 2\nGPU 11\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l2_g12 [label="Gating Network\nLayer 2\nGPU 12\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l2_e12_g12 [label="Expert 12\nLayer 2\nGPU 12\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l2_g13 [label="Gating Network\nLayer 2\nGPU 13\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l2_e13_g13 [label="Expert 13\nLayer 2\nGPU 13\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l2_g14 [label="Gating Network\nLayer 2\nGPU 14\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l2_e14_g14 [label="Expert 14\nLayer 2\nGPU 14\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l2_g15 [label="Gating Network\nLayer 2\nGPU 15\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l2_e15_g15 [label="Expert 15\nLayer 2\nGPU 15\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	node [fillcolor=lightyellow shape=parallelogram]
	aggregate_l2_g0 [label="Expert Aggregation\nLayer 2\nGPU 0\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l2_g1 [label="Expert Aggregation\nLayer 2\nGPU 1\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l2_g2 [label="Expert Aggregation\nLayer 2\nGPU 2\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l2_g3 [label="Expert Aggregation\nLayer 2\nGPU 3\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l2_g4 [label="Expert Aggregation\nLayer 2\nGPU 4\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l2_g5 [label="Expert Aggregation\nLayer 2\nGPU 5\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l2_g6 [label="Expert Aggregation\nLayer 2\nGPU 6\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l2_g7 [label="Expert Aggregation\nLayer 2\nGPU 7\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l2_g8 [label="Expert Aggregation\nLayer 2\nGPU 8\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l2_g9 [label="Expert Aggregation\nLayer 2\nGPU 9\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l2_g10 [label="Expert Aggregation\nLayer 2\nGPU 10\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l2_g11 [label="Expert Aggregation\nLayer 2\nGPU 11\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l2_g12 [label="Expert Aggregation\nLayer 2\nGPU 12\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l2_g13 [label="Expert Aggregation\nLayer 2\nGPU 13\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l2_g14 [label="Expert Aggregation\nLayer 2\nGPU 14\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l2_g15 [label="Expert Aggregation\nLayer 2\nGPU 15\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	node [fillcolor=lightcoral shape=rectangle]
	mha_qkv_l3_g0 [label="MHA QKV Linear Layer 3\nGPU 0\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_attn_l3_g0 [label="MHA Attention Layer 3\nGPU 0\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_out_l3_g0 [label="MHA Output Linear Layer 3\nGPU 0\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, dim=1024]" fillcolor=lightcoral]
	mha_qkv_l3_g1 [label="MHA QKV Linear Layer 3\nGPU 1\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_attn_l3_g1 [label="MHA Attention Layer 3\nGPU 1\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_out_l3_g1 [label="MHA Output Linear Layer 3\nGPU 1\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, dim=1024]" fillcolor=lightcoral]
	mha_qkv_l3_g2 [label="MHA QKV Linear Layer 3\nGPU 2\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_attn_l3_g2 [label="MHA Attention Layer 3\nGPU 2\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_out_l3_g2 [label="MHA Output Linear Layer 3\nGPU 2\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, dim=1024]" fillcolor=lightcoral]
	mha_qkv_l3_g3 [label="MHA QKV Linear Layer 3\nGPU 3\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_attn_l3_g3 [label="MHA Attention Layer 3\nGPU 3\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_out_l3_g3 [label="MHA Output Linear Layer 3\nGPU 3\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, dim=1024]" fillcolor=lightcoral]
	mha_qkv_l3_g4 [label="MHA QKV Linear Layer 3\nGPU 4\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_attn_l3_g4 [label="MHA Attention Layer 3\nGPU 4\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_out_l3_g4 [label="MHA Output Linear Layer 3\nGPU 4\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, dim=1024]" fillcolor=lightcoral]
	mha_qkv_l3_g5 [label="MHA QKV Linear Layer 3\nGPU 5\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_attn_l3_g5 [label="MHA Attention Layer 3\nGPU 5\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_out_l3_g5 [label="MHA Output Linear Layer 3\nGPU 5\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, dim=1024]" fillcolor=lightcoral]
	mha_qkv_l3_g6 [label="MHA QKV Linear Layer 3\nGPU 6\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_attn_l3_g6 [label="MHA Attention Layer 3\nGPU 6\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_out_l3_g6 [label="MHA Output Linear Layer 3\nGPU 6\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, dim=1024]" fillcolor=lightcoral]
	mha_qkv_l3_g7 [label="MHA QKV Linear Layer 3\nGPU 7\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_attn_l3_g7 [label="MHA Attention Layer 3\nGPU 7\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]" fillcolor=lightcoral]
	mha_out_l3_g7 [label="MHA Output Linear Layer 3\nGPU 7\nInput: [batch_size=1024, seq_len=10000, heads=2, d_k=512]\nOutput: [batch_size=1024, seq_len=10000, dim=1024]" fillcolor=lightcoral]
	node [fillcolor=lightyellow shape=parallelogram]
	allreduce_l3_g0 [label="All-Reduce Sum\nLayer 3\nGPU 0\nInput: [batch_size=1024, seq_len=10000, dim=1024]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	residual_l3_g0 [label="Residual Add\nLayer 3\nGPU 0\nInput1: [batch_size=1024, seq_len=10000, dim=8192]\nInput2: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	allreduce_l3_g1 [label="All-Reduce Sum\nLayer 3\nGPU 1\nInput: [batch_size=1024, seq_len=10000, dim=1024]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	residual_l3_g1 [label="Residual Add\nLayer 3\nGPU 1\nInput1: [batch_size=1024, seq_len=10000, dim=8192]\nInput2: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	allreduce_l3_g2 [label="All-Reduce Sum\nLayer 3\nGPU 2\nInput: [batch_size=1024, seq_len=10000, dim=1024]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	residual_l3_g2 [label="Residual Add\nLayer 3\nGPU 2\nInput1: [batch_size=1024, seq_len=10000, dim=8192]\nInput2: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	allreduce_l3_g3 [label="All-Reduce Sum\nLayer 3\nGPU 3\nInput: [batch_size=1024, seq_len=10000, dim=1024]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	residual_l3_g3 [label="Residual Add\nLayer 3\nGPU 3\nInput1: [batch_size=1024, seq_len=10000, dim=8192]\nInput2: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	allreduce_l3_g4 [label="All-Reduce Sum\nLayer 3\nGPU 4\nInput: [batch_size=1024, seq_len=10000, dim=1024]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	residual_l3_g4 [label="Residual Add\nLayer 3\nGPU 4\nInput1: [batch_size=1024, seq_len=10000, dim=8192]\nInput2: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	allreduce_l3_g5 [label="All-Reduce Sum\nLayer 3\nGPU 5\nInput: [batch_size=1024, seq_len=10000, dim=1024]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	residual_l3_g5 [label="Residual Add\nLayer 3\nGPU 5\nInput1: [batch_size=1024, seq_len=10000, dim=8192]\nInput2: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	allreduce_l3_g6 [label="All-Reduce Sum\nLayer 3\nGPU 6\nInput: [batch_size=1024, seq_len=10000, dim=1024]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	residual_l3_g6 [label="Residual Add\nLayer 3\nGPU 6\nInput1: [batch_size=1024, seq_len=10000, dim=8192]\nInput2: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	allreduce_l3_g7 [label="All-Reduce Sum\nLayer 3\nGPU 7\nInput: [batch_size=1024, seq_len=10000, dim=1024]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	residual_l3_g7 [label="Residual Add\nLayer 3\nGPU 7\nInput1: [batch_size=1024, seq_len=10000, dim=8192]\nInput2: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	node [fillcolor=lightgreen shape=rectangle]
	gate_l3_g0 [label="Gating Network\nLayer 3\nGPU 0\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l3_e0_g0 [label="Expert 0\nLayer 3\nGPU 0\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l3_g1 [label="Gating Network\nLayer 3\nGPU 1\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l3_e1_g1 [label="Expert 1\nLayer 3\nGPU 1\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l3_g2 [label="Gating Network\nLayer 3\nGPU 2\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l3_e2_g2 [label="Expert 2\nLayer 3\nGPU 2\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l3_g3 [label="Gating Network\nLayer 3\nGPU 3\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l3_e3_g3 [label="Expert 3\nLayer 3\nGPU 3\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l3_g4 [label="Gating Network\nLayer 3\nGPU 4\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l3_e4_g4 [label="Expert 4\nLayer 3\nGPU 4\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l3_g5 [label="Gating Network\nLayer 3\nGPU 5\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l3_e5_g5 [label="Expert 5\nLayer 3\nGPU 5\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l3_g6 [label="Gating Network\nLayer 3\nGPU 6\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l3_e6_g6 [label="Expert 6\nLayer 3\nGPU 6\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l3_g7 [label="Gating Network\nLayer 3\nGPU 7\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l3_e7_g7 [label="Expert 7\nLayer 3\nGPU 7\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l3_g8 [label="Gating Network\nLayer 3\nGPU 8\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l3_e8_g8 [label="Expert 8\nLayer 3\nGPU 8\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l3_g9 [label="Gating Network\nLayer 3\nGPU 9\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l3_e9_g9 [label="Expert 9\nLayer 3\nGPU 9\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l3_g10 [label="Gating Network\nLayer 3\nGPU 10\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l3_e10_g10 [label="Expert 10\nLayer 3\nGPU 10\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l3_g11 [label="Gating Network\nLayer 3\nGPU 11\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l3_e11_g11 [label="Expert 11\nLayer 3\nGPU 11\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l3_g12 [label="Gating Network\nLayer 3\nGPU 12\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l3_e12_g12 [label="Expert 12\nLayer 3\nGPU 12\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l3_g13 [label="Gating Network\nLayer 3\nGPU 13\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l3_e13_g13 [label="Expert 13\nLayer 3\nGPU 13\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l3_g14 [label="Gating Network\nLayer 3\nGPU 14\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l3_e14_g14 [label="Expert 14\nLayer 3\nGPU 14\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	gate_l3_g15 [label="Gating Network\nLayer 3\nGPU 15\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, num_experts=16]" fillcolor=lightgreen]
	expert_l3_e15_g15 [label="Expert 15\nLayer 3\nGPU 15\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=variable, seq_len=variable, dim=8192]\nType: MLP [8192→32768→8192]" fillcolor=lightgreen]
	node [fillcolor=lightyellow shape=parallelogram]
	aggregate_l3_g0 [label="Expert Aggregation\nLayer 3\nGPU 0\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l3_g1 [label="Expert Aggregation\nLayer 3\nGPU 1\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l3_g2 [label="Expert Aggregation\nLayer 3\nGPU 2\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l3_g3 [label="Expert Aggregation\nLayer 3\nGPU 3\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l3_g4 [label="Expert Aggregation\nLayer 3\nGPU 4\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l3_g5 [label="Expert Aggregation\nLayer 3\nGPU 5\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l3_g6 [label="Expert Aggregation\nLayer 3\nGPU 6\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l3_g7 [label="Expert Aggregation\nLayer 3\nGPU 7\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l3_g8 [label="Expert Aggregation\nLayer 3\nGPU 8\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l3_g9 [label="Expert Aggregation\nLayer 3\nGPU 9\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l3_g10 [label="Expert Aggregation\nLayer 3\nGPU 10\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l3_g11 [label="Expert Aggregation\nLayer 3\nGPU 11\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l3_g12 [label="Expert Aggregation\nLayer 3\nGPU 12\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l3_g13 [label="Expert Aggregation\nLayer 3\nGPU 13\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l3_g14 [label="Expert Aggregation\nLayer 3\nGPU 14\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	aggregate_l3_g15 [label="Expert Aggregation\nLayer 3\nGPU 15\nInput: [batch_size=variable, seq_len=variable, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]" fillcolor=lightyellow]
	output [label="Output\nInput: [batch_size=1024, seq_len=10000, dim=8192]\nOutput: [batch_size=1024, seq_len=10000, dim=8192]\nGPU: all GPUs" fillcolor=lightgreen shape=ellipse]
	input -> mha_qkv_l0_g0
	mha_qkv_l0_g0 -> mha_attn_l0_g0
	mha_attn_l0_g0 -> mha_out_l0_g0
	mha_out_l0_g0 -> allreduce_l0_g0
	input -> residual_l0_g0
	allreduce_l0_g0 -> residual_l0_g0
	input -> mha_qkv_l0_g1
	mha_qkv_l0_g1 -> mha_attn_l0_g1
	mha_attn_l0_g1 -> mha_out_l0_g1
	mha_out_l0_g1 -> allreduce_l0_g1
	input -> residual_l0_g1
	allreduce_l0_g1 -> residual_l0_g1
	input -> mha_qkv_l0_g2
	mha_qkv_l0_g2 -> mha_attn_l0_g2
	mha_attn_l0_g2 -> mha_out_l0_g2
	mha_out_l0_g2 -> allreduce_l0_g2
	input -> residual_l0_g2
	allreduce_l0_g2 -> residual_l0_g2
	input -> mha_qkv_l0_g3
	mha_qkv_l0_g3 -> mha_attn_l0_g3
	mha_attn_l0_g3 -> mha_out_l0_g3
	mha_out_l0_g3 -> allreduce_l0_g3
	input -> residual_l0_g3
	allreduce_l0_g3 -> residual_l0_g3
	input -> mha_qkv_l0_g4
	mha_qkv_l0_g4 -> mha_attn_l0_g4
	mha_attn_l0_g4 -> mha_out_l0_g4
	mha_out_l0_g4 -> allreduce_l0_g4
	input -> residual_l0_g4
	allreduce_l0_g4 -> residual_l0_g4
	input -> mha_qkv_l0_g5
	mha_qkv_l0_g5 -> mha_attn_l0_g5
	mha_attn_l0_g5 -> mha_out_l0_g5
	mha_out_l0_g5 -> allreduce_l0_g5
	input -> residual_l0_g5
	allreduce_l0_g5 -> residual_l0_g5
	input -> mha_qkv_l0_g6
	mha_qkv_l0_g6 -> mha_attn_l0_g6
	mha_attn_l0_g6 -> mha_out_l0_g6
	mha_out_l0_g6 -> allreduce_l0_g6
	input -> residual_l0_g6
	allreduce_l0_g6 -> residual_l0_g6
	input -> mha_qkv_l0_g7
	mha_qkv_l0_g7 -> mha_attn_l0_g7
	mha_attn_l0_g7 -> mha_out_l0_g7
	mha_out_l0_g7 -> allreduce_l0_g7
	input -> residual_l0_g7
	allreduce_l0_g7 -> residual_l0_g7
	residual_l0_g0 -> gate_l0_g0
	gate_l0_g0 -> expert_l0_e0_g0 [style=dashed]
	expert_l0_e0_g0 -> aggregate_l0_g0
	residual_l0_g0 -> aggregate_l0_g0
	residual_l0_g1 -> gate_l0_g1
	gate_l0_g1 -> expert_l0_e1_g1 [style=dashed]
	expert_l0_e1_g1 -> aggregate_l0_g1
	residual_l0_g1 -> aggregate_l0_g1
	residual_l0_g2 -> gate_l0_g2
	gate_l0_g2 -> expert_l0_e2_g2 [style=dashed]
	expert_l0_e2_g2 -> aggregate_l0_g2
	residual_l0_g2 -> aggregate_l0_g2
	residual_l0_g3 -> gate_l0_g3
	gate_l0_g3 -> expert_l0_e3_g3 [style=dashed]
	expert_l0_e3_g3 -> aggregate_l0_g3
	residual_l0_g3 -> aggregate_l0_g3
	residual_l0_g4 -> gate_l0_g4
	gate_l0_g4 -> expert_l0_e4_g4 [style=dashed]
	expert_l0_e4_g4 -> aggregate_l0_g4
	residual_l0_g4 -> aggregate_l0_g4
	residual_l0_g5 -> gate_l0_g5
	gate_l0_g5 -> expert_l0_e5_g5 [style=dashed]
	expert_l0_e5_g5 -> aggregate_l0_g5
	residual_l0_g5 -> aggregate_l0_g5
	residual_l0_g6 -> gate_l0_g6
	gate_l0_g6 -> expert_l0_e6_g6 [style=dashed]
	expert_l0_e6_g6 -> aggregate_l0_g6
	residual_l0_g6 -> aggregate_l0_g6
	residual_l0_g7 -> gate_l0_g7
	gate_l0_g7 -> expert_l0_e7_g7 [style=dashed]
	expert_l0_e7_g7 -> aggregate_l0_g7
	residual_l0_g7 -> aggregate_l0_g7
	residual_l0_g0 -> gate_l0_g8
	gate_l0_g8 -> expert_l0_e8_g8 [style=dashed]
	expert_l0_e8_g8 -> aggregate_l0_g8
	residual_l0_g0 -> aggregate_l0_g8
	residual_l0_g1 -> gate_l0_g9
	gate_l0_g9 -> expert_l0_e9_g9 [style=dashed]
	expert_l0_e9_g9 -> aggregate_l0_g9
	residual_l0_g1 -> aggregate_l0_g9
	residual_l0_g2 -> gate_l0_g10
	gate_l0_g10 -> expert_l0_e10_g10 [style=dashed]
	expert_l0_e10_g10 -> aggregate_l0_g10
	residual_l0_g2 -> aggregate_l0_g10
	residual_l0_g3 -> gate_l0_g11
	gate_l0_g11 -> expert_l0_e11_g11 [style=dashed]
	expert_l0_e11_g11 -> aggregate_l0_g11
	residual_l0_g3 -> aggregate_l0_g11
	residual_l0_g4 -> gate_l0_g12
	gate_l0_g12 -> expert_l0_e12_g12 [style=dashed]
	expert_l0_e12_g12 -> aggregate_l0_g12
	residual_l0_g4 -> aggregate_l0_g12
	residual_l0_g5 -> gate_l0_g13
	gate_l0_g13 -> expert_l0_e13_g13 [style=dashed]
	expert_l0_e13_g13 -> aggregate_l0_g13
	residual_l0_g5 -> aggregate_l0_g13
	residual_l0_g6 -> gate_l0_g14
	gate_l0_g14 -> expert_l0_e14_g14 [style=dashed]
	expert_l0_e14_g14 -> aggregate_l0_g14
	residual_l0_g6 -> aggregate_l0_g14
	residual_l0_g7 -> gate_l0_g15
	gate_l0_g15 -> expert_l0_e15_g15 [style=dashed]
	expert_l0_e15_g15 -> aggregate_l0_g15
	residual_l0_g7 -> aggregate_l0_g15
	aggregate_l0_g0 -> mha_qkv_l1_g0
	aggregate_l0_g8 -> mha_qkv_l1_g0
	aggregate_l0_g1 -> mha_qkv_l1_g1
	aggregate_l0_g9 -> mha_qkv_l1_g1
	aggregate_l0_g2 -> mha_qkv_l1_g2
	aggregate_l0_g10 -> mha_qkv_l1_g2
	aggregate_l0_g3 -> mha_qkv_l1_g3
	aggregate_l0_g11 -> mha_qkv_l1_g3
	aggregate_l0_g4 -> mha_qkv_l1_g4
	aggregate_l0_g12 -> mha_qkv_l1_g4
	aggregate_l0_g5 -> mha_qkv_l1_g5
	aggregate_l0_g13 -> mha_qkv_l1_g5
	aggregate_l0_g6 -> mha_qkv_l1_g6
	aggregate_l0_g14 -> mha_qkv_l1_g6
	aggregate_l0_g7 -> mha_qkv_l1_g7
	aggregate_l0_g15 -> mha_qkv_l1_g7
	mha_qkv_l1_g0 -> mha_attn_l1_g0
	mha_attn_l1_g0 -> mha_out_l1_g0
	mha_out_l1_g0 -> allreduce_l1_g0
	aggregate_l0_g0 -> residual_l1_g0
	aggregate_l0_g8 -> residual_l1_g0
	allreduce_l1_g0 -> residual_l1_g0
	mha_qkv_l1_g1 -> mha_attn_l1_g1
	mha_attn_l1_g1 -> mha_out_l1_g1
	mha_out_l1_g1 -> allreduce_l1_g1
	aggregate_l0_g1 -> residual_l1_g1
	aggregate_l0_g9 -> residual_l1_g1
	allreduce_l1_g1 -> residual_l1_g1
	mha_qkv_l1_g2 -> mha_attn_l1_g2
	mha_attn_l1_g2 -> mha_out_l1_g2
	mha_out_l1_g2 -> allreduce_l1_g2
	aggregate_l0_g2 -> residual_l1_g2
	aggregate_l0_g10 -> residual_l1_g2
	allreduce_l1_g2 -> residual_l1_g2
	mha_qkv_l1_g3 -> mha_attn_l1_g3
	mha_attn_l1_g3 -> mha_out_l1_g3
	mha_out_l1_g3 -> allreduce_l1_g3
	aggregate_l0_g3 -> residual_l1_g3
	aggregate_l0_g11 -> residual_l1_g3
	allreduce_l1_g3 -> residual_l1_g3
	mha_qkv_l1_g4 -> mha_attn_l1_g4
	mha_attn_l1_g4 -> mha_out_l1_g4
	mha_out_l1_g4 -> allreduce_l1_g4
	aggregate_l0_g4 -> residual_l1_g4
	aggregate_l0_g12 -> residual_l1_g4
	allreduce_l1_g4 -> residual_l1_g4
	mha_qkv_l1_g5 -> mha_attn_l1_g5
	mha_attn_l1_g5 -> mha_out_l1_g5
	mha_out_l1_g5 -> allreduce_l1_g5
	aggregate_l0_g5 -> residual_l1_g5
	aggregate_l0_g13 -> residual_l1_g5
	allreduce_l1_g5 -> residual_l1_g5
	mha_qkv_l1_g6 -> mha_attn_l1_g6
	mha_attn_l1_g6 -> mha_out_l1_g6
	mha_out_l1_g6 -> allreduce_l1_g6
	aggregate_l0_g6 -> residual_l1_g6
	aggregate_l0_g14 -> residual_l1_g6
	allreduce_l1_g6 -> residual_l1_g6
	mha_qkv_l1_g7 -> mha_attn_l1_g7
	mha_attn_l1_g7 -> mha_out_l1_g7
	mha_out_l1_g7 -> allreduce_l1_g7
	aggregate_l0_g7 -> residual_l1_g7
	aggregate_l0_g15 -> residual_l1_g7
	allreduce_l1_g7 -> residual_l1_g7
	residual_l1_g0 -> gate_l1_g0
	gate_l1_g0 -> expert_l1_e0_g0 [style=dashed]
	expert_l1_e0_g0 -> aggregate_l1_g0
	residual_l1_g0 -> aggregate_l1_g0
	residual_l1_g1 -> gate_l1_g1
	gate_l1_g1 -> expert_l1_e1_g1 [style=dashed]
	expert_l1_e1_g1 -> aggregate_l1_g1
	residual_l1_g1 -> aggregate_l1_g1
	residual_l1_g2 -> gate_l1_g2
	gate_l1_g2 -> expert_l1_e2_g2 [style=dashed]
	expert_l1_e2_g2 -> aggregate_l1_g2
	residual_l1_g2 -> aggregate_l1_g2
	residual_l1_g3 -> gate_l1_g3
	gate_l1_g3 -> expert_l1_e3_g3 [style=dashed]
	expert_l1_e3_g3 -> aggregate_l1_g3
	residual_l1_g3 -> aggregate_l1_g3
	residual_l1_g4 -> gate_l1_g4
	gate_l1_g4 -> expert_l1_e4_g4 [style=dashed]
	expert_l1_e4_g4 -> aggregate_l1_g4
	residual_l1_g4 -> aggregate_l1_g4
	residual_l1_g5 -> gate_l1_g5
	gate_l1_g5 -> expert_l1_e5_g5 [style=dashed]
	expert_l1_e5_g5 -> aggregate_l1_g5
	residual_l1_g5 -> aggregate_l1_g5
	residual_l1_g6 -> gate_l1_g6
	gate_l1_g6 -> expert_l1_e6_g6 [style=dashed]
	expert_l1_e6_g6 -> aggregate_l1_g6
	residual_l1_g6 -> aggregate_l1_g6
	residual_l1_g7 -> gate_l1_g7
	gate_l1_g7 -> expert_l1_e7_g7 [style=dashed]
	expert_l1_e7_g7 -> aggregate_l1_g7
	residual_l1_g7 -> aggregate_l1_g7
	residual_l1_g0 -> gate_l1_g8
	gate_l1_g8 -> expert_l1_e8_g8 [style=dashed]
	expert_l1_e8_g8 -> aggregate_l1_g8
	residual_l1_g0 -> aggregate_l1_g8
	residual_l1_g1 -> gate_l1_g9
	gate_l1_g9 -> expert_l1_e9_g9 [style=dashed]
	expert_l1_e9_g9 -> aggregate_l1_g9
	residual_l1_g1 -> aggregate_l1_g9
	residual_l1_g2 -> gate_l1_g10
	gate_l1_g10 -> expert_l1_e10_g10 [style=dashed]
	expert_l1_e10_g10 -> aggregate_l1_g10
	residual_l1_g2 -> aggregate_l1_g10
	residual_l1_g3 -> gate_l1_g11
	gate_l1_g11 -> expert_l1_e11_g11 [style=dashed]
	expert_l1_e11_g11 -> aggregate_l1_g11
	residual_l1_g3 -> aggregate_l1_g11
	residual_l1_g4 -> gate_l1_g12
	gate_l1_g12 -> expert_l1_e12_g12 [style=dashed]
	expert_l1_e12_g12 -> aggregate_l1_g12
	residual_l1_g4 -> aggregate_l1_g12
	residual_l1_g5 -> gate_l1_g13
	gate_l1_g13 -> expert_l1_e13_g13 [style=dashed]
	expert_l1_e13_g13 -> aggregate_l1_g13
	residual_l1_g5 -> aggregate_l1_g13
	residual_l1_g6 -> gate_l1_g14
	gate_l1_g14 -> expert_l1_e14_g14 [style=dashed]
	expert_l1_e14_g14 -> aggregate_l1_g14
	residual_l1_g6 -> aggregate_l1_g14
	residual_l1_g7 -> gate_l1_g15
	gate_l1_g15 -> expert_l1_e15_g15 [style=dashed]
	expert_l1_e15_g15 -> aggregate_l1_g15
	residual_l1_g7 -> aggregate_l1_g15
	aggregate_l1_g0 -> mha_qkv_l2_g0
	aggregate_l1_g8 -> mha_qkv_l2_g0
	aggregate_l1_g1 -> mha_qkv_l2_g1
	aggregate_l1_g9 -> mha_qkv_l2_g1
	aggregate_l1_g2 -> mha_qkv_l2_g2
	aggregate_l1_g10 -> mha_qkv_l2_g2
	aggregate_l1_g3 -> mha_qkv_l2_g3
	aggregate_l1_g11 -> mha_qkv_l2_g3
	aggregate_l1_g4 -> mha_qkv_l2_g4
	aggregate_l1_g12 -> mha_qkv_l2_g4
	aggregate_l1_g5 -> mha_qkv_l2_g5
	aggregate_l1_g13 -> mha_qkv_l2_g5
	aggregate_l1_g6 -> mha_qkv_l2_g6
	aggregate_l1_g14 -> mha_qkv_l2_g6
	aggregate_l1_g7 -> mha_qkv_l2_g7
	aggregate_l1_g15 -> mha_qkv_l2_g7
	mha_qkv_l2_g0 -> mha_attn_l2_g0
	mha_attn_l2_g0 -> mha_out_l2_g0
	mha_out_l2_g0 -> allreduce_l2_g0
	aggregate_l1_g0 -> residual_l2_g0
	aggregate_l1_g8 -> residual_l2_g0
	allreduce_l2_g0 -> residual_l2_g0
	mha_qkv_l2_g1 -> mha_attn_l2_g1
	mha_attn_l2_g1 -> mha_out_l2_g1
	mha_out_l2_g1 -> allreduce_l2_g1
	aggregate_l1_g1 -> residual_l2_g1
	aggregate_l1_g9 -> residual_l2_g1
	allreduce_l2_g1 -> residual_l2_g1
	mha_qkv_l2_g2 -> mha_attn_l2_g2
	mha_attn_l2_g2 -> mha_out_l2_g2
	mha_out_l2_g2 -> allreduce_l2_g2
	aggregate_l1_g2 -> residual_l2_g2
	aggregate_l1_g10 -> residual_l2_g2
	allreduce_l2_g2 -> residual_l2_g2
	mha_qkv_l2_g3 -> mha_attn_l2_g3
	mha_attn_l2_g3 -> mha_out_l2_g3
	mha_out_l2_g3 -> allreduce_l2_g3
	aggregate_l1_g3 -> residual_l2_g3
	aggregate_l1_g11 -> residual_l2_g3
	allreduce_l2_g3 -> residual_l2_g3
	mha_qkv_l2_g4 -> mha_attn_l2_g4
	mha_attn_l2_g4 -> mha_out_l2_g4
	mha_out_l2_g4 -> allreduce_l2_g4
	aggregate_l1_g4 -> residual_l2_g4
	aggregate_l1_g12 -> residual_l2_g4
	allreduce_l2_g4 -> residual_l2_g4
	mha_qkv_l2_g5 -> mha_attn_l2_g5
	mha_attn_l2_g5 -> mha_out_l2_g5
	mha_out_l2_g5 -> allreduce_l2_g5
	aggregate_l1_g5 -> residual_l2_g5
	aggregate_l1_g13 -> residual_l2_g5
	allreduce_l2_g5 -> residual_l2_g5
	mha_qkv_l2_g6 -> mha_attn_l2_g6
	mha_attn_l2_g6 -> mha_out_l2_g6
	mha_out_l2_g6 -> allreduce_l2_g6
	aggregate_l1_g6 -> residual_l2_g6
	aggregate_l1_g14 -> residual_l2_g6
	allreduce_l2_g6 -> residual_l2_g6
	mha_qkv_l2_g7 -> mha_attn_l2_g7
	mha_attn_l2_g7 -> mha_out_l2_g7
	mha_out_l2_g7 -> allreduce_l2_g7
	aggregate_l1_g7 -> residual_l2_g7
	aggregate_l1_g15 -> residual_l2_g7
	allreduce_l2_g7 -> residual_l2_g7
	residual_l2_g0 -> gate_l2_g0
	gate_l2_g0 -> expert_l2_e0_g0 [style=dashed]
	expert_l2_e0_g0 -> aggregate_l2_g0
	residual_l2_g0 -> aggregate_l2_g0
	residual_l2_g1 -> gate_l2_g1
	gate_l2_g1 -> expert_l2_e1_g1 [style=dashed]
	expert_l2_e1_g1 -> aggregate_l2_g1
	residual_l2_g1 -> aggregate_l2_g1
	residual_l2_g2 -> gate_l2_g2
	gate_l2_g2 -> expert_l2_e2_g2 [style=dashed]
	expert_l2_e2_g2 -> aggregate_l2_g2
	residual_l2_g2 -> aggregate_l2_g2
	residual_l2_g3 -> gate_l2_g3
	gate_l2_g3 -> expert_l2_e3_g3 [style=dashed]
	expert_l2_e3_g3 -> aggregate_l2_g3
	residual_l2_g3 -> aggregate_l2_g3
	residual_l2_g4 -> gate_l2_g4
	gate_l2_g4 -> expert_l2_e4_g4 [style=dashed]
	expert_l2_e4_g4 -> aggregate_l2_g4
	residual_l2_g4 -> aggregate_l2_g4
	residual_l2_g5 -> gate_l2_g5
	gate_l2_g5 -> expert_l2_e5_g5 [style=dashed]
	expert_l2_e5_g5 -> aggregate_l2_g5
	residual_l2_g5 -> aggregate_l2_g5
	residual_l2_g6 -> gate_l2_g6
	gate_l2_g6 -> expert_l2_e6_g6 [style=dashed]
	expert_l2_e6_g6 -> aggregate_l2_g6
	residual_l2_g6 -> aggregate_l2_g6
	residual_l2_g7 -> gate_l2_g7
	gate_l2_g7 -> expert_l2_e7_g7 [style=dashed]
	expert_l2_e7_g7 -> aggregate_l2_g7
	residual_l2_g7 -> aggregate_l2_g7
	residual_l2_g0 -> gate_l2_g8
	gate_l2_g8 -> expert_l2_e8_g8 [style=dashed]
	expert_l2_e8_g8 -> aggregate_l2_g8
	residual_l2_g0 -> aggregate_l2_g8
	residual_l2_g1 -> gate_l2_g9
	gate_l2_g9 -> expert_l2_e9_g9 [style=dashed]
	expert_l2_e9_g9 -> aggregate_l2_g9
	residual_l2_g1 -> aggregate_l2_g9
	residual_l2_g2 -> gate_l2_g10
	gate_l2_g10 -> expert_l2_e10_g10 [style=dashed]
	expert_l2_e10_g10 -> aggregate_l2_g10
	residual_l2_g2 -> aggregate_l2_g10
	residual_l2_g3 -> gate_l2_g11
	gate_l2_g11 -> expert_l2_e11_g11 [style=dashed]
	expert_l2_e11_g11 -> aggregate_l2_g11
	residual_l2_g3 -> aggregate_l2_g11
	residual_l2_g4 -> gate_l2_g12
	gate_l2_g12 -> expert_l2_e12_g12 [style=dashed]
	expert_l2_e12_g12 -> aggregate_l2_g12
	residual_l2_g4 -> aggregate_l2_g12
	residual_l2_g5 -> gate_l2_g13
	gate_l2_g13 -> expert_l2_e13_g13 [style=dashed]
	expert_l2_e13_g13 -> aggregate_l2_g13
	residual_l2_g5 -> aggregate_l2_g13
	residual_l2_g6 -> gate_l2_g14
	gate_l2_g14 -> expert_l2_e14_g14 [style=dashed]
	expert_l2_e14_g14 -> aggregate_l2_g14
	residual_l2_g6 -> aggregate_l2_g14
	residual_l2_g7 -> gate_l2_g15
	gate_l2_g15 -> expert_l2_e15_g15 [style=dashed]
	expert_l2_e15_g15 -> aggregate_l2_g15
	residual_l2_g7 -> aggregate_l2_g15
	aggregate_l2_g0 -> mha_qkv_l3_g0
	aggregate_l2_g8 -> mha_qkv_l3_g0
	aggregate_l2_g1 -> mha_qkv_l3_g1
	aggregate_l2_g9 -> mha_qkv_l3_g1
	aggregate_l2_g2 -> mha_qkv_l3_g2
	aggregate_l2_g10 -> mha_qkv_l3_g2
	aggregate_l2_g3 -> mha_qkv_l3_g3
	aggregate_l2_g11 -> mha_qkv_l3_g3
	aggregate_l2_g4 -> mha_qkv_l3_g4
	aggregate_l2_g12 -> mha_qkv_l3_g4
	aggregate_l2_g5 -> mha_qkv_l3_g5
	aggregate_l2_g13 -> mha_qkv_l3_g5
	aggregate_l2_g6 -> mha_qkv_l3_g6
	aggregate_l2_g14 -> mha_qkv_l3_g6
	aggregate_l2_g7 -> mha_qkv_l3_g7
	aggregate_l2_g15 -> mha_qkv_l3_g7
	mha_qkv_l3_g0 -> mha_attn_l3_g0
	mha_attn_l3_g0 -> mha_out_l3_g0
	mha_out_l3_g0 -> allreduce_l3_g0
	aggregate_l2_g0 -> residual_l3_g0
	aggregate_l2_g8 -> residual_l3_g0
	allreduce_l3_g0 -> residual_l3_g0
	mha_qkv_l3_g1 -> mha_attn_l3_g1
	mha_attn_l3_g1 -> mha_out_l3_g1
	mha_out_l3_g1 -> allreduce_l3_g1
	aggregate_l2_g1 -> residual_l3_g1
	aggregate_l2_g9 -> residual_l3_g1
	allreduce_l3_g1 -> residual_l3_g1
	mha_qkv_l3_g2 -> mha_attn_l3_g2
	mha_attn_l3_g2 -> mha_out_l3_g2
	mha_out_l3_g2 -> allreduce_l3_g2
	aggregate_l2_g2 -> residual_l3_g2
	aggregate_l2_g10 -> residual_l3_g2
	allreduce_l3_g2 -> residual_l3_g2
	mha_qkv_l3_g3 -> mha_attn_l3_g3
	mha_attn_l3_g3 -> mha_out_l3_g3
	mha_out_l3_g3 -> allreduce_l3_g3
	aggregate_l2_g3 -> residual_l3_g3
	aggregate_l2_g11 -> residual_l3_g3
	allreduce_l3_g3 -> residual_l3_g3
	mha_qkv_l3_g4 -> mha_attn_l3_g4
	mha_attn_l3_g4 -> mha_out_l3_g4
	mha_out_l3_g4 -> allreduce_l3_g4
	aggregate_l2_g4 -> residual_l3_g4
	aggregate_l2_g12 -> residual_l3_g4
	allreduce_l3_g4 -> residual_l3_g4
	mha_qkv_l3_g5 -> mha_attn_l3_g5
	mha_attn_l3_g5 -> mha_out_l3_g5
	mha_out_l3_g5 -> allreduce_l3_g5
	aggregate_l2_g5 -> residual_l3_g5
	aggregate_l2_g13 -> residual_l3_g5
	allreduce_l3_g5 -> residual_l3_g5
	mha_qkv_l3_g6 -> mha_attn_l3_g6
	mha_attn_l3_g6 -> mha_out_l3_g6
	mha_out_l3_g6 -> allreduce_l3_g6
	aggregate_l2_g6 -> residual_l3_g6
	aggregate_l2_g14 -> residual_l3_g6
	allreduce_l3_g6 -> residual_l3_g6
	mha_qkv_l3_g7 -> mha_attn_l3_g7
	mha_attn_l3_g7 -> mha_out_l3_g7
	mha_out_l3_g7 -> allreduce_l3_g7
	aggregate_l2_g7 -> residual_l3_g7
	aggregate_l2_g15 -> residual_l3_g7
	allreduce_l3_g7 -> residual_l3_g7
	residual_l3_g0 -> gate_l3_g0
	gate_l3_g0 -> expert_l3_e0_g0 [style=dashed]
	expert_l3_e0_g0 -> aggregate_l3_g0
	residual_l3_g0 -> aggregate_l3_g0
	residual_l3_g1 -> gate_l3_g1
	gate_l3_g1 -> expert_l3_e1_g1 [style=dashed]
	expert_l3_e1_g1 -> aggregate_l3_g1
	residual_l3_g1 -> aggregate_l3_g1
	residual_l3_g2 -> gate_l3_g2
	gate_l3_g2 -> expert_l3_e2_g2 [style=dashed]
	expert_l3_e2_g2 -> aggregate_l3_g2
	residual_l3_g2 -> aggregate_l3_g2
	residual_l3_g3 -> gate_l3_g3
	gate_l3_g3 -> expert_l3_e3_g3 [style=dashed]
	expert_l3_e3_g3 -> aggregate_l3_g3
	residual_l3_g3 -> aggregate_l3_g3
	residual_l3_g4 -> gate_l3_g4
	gate_l3_g4 -> expert_l3_e4_g4 [style=dashed]
	expert_l3_e4_g4 -> aggregate_l3_g4
	residual_l3_g4 -> aggregate_l3_g4
	residual_l3_g5 -> gate_l3_g5
	gate_l3_g5 -> expert_l3_e5_g5 [style=dashed]
	expert_l3_e5_g5 -> aggregate_l3_g5
	residual_l3_g5 -> aggregate_l3_g5
	residual_l3_g6 -> gate_l3_g6
	gate_l3_g6 -> expert_l3_e6_g6 [style=dashed]
	expert_l3_e6_g6 -> aggregate_l3_g6
	residual_l3_g6 -> aggregate_l3_g6
	residual_l3_g7 -> gate_l3_g7
	gate_l3_g7 -> expert_l3_e7_g7 [style=dashed]
	expert_l3_e7_g7 -> aggregate_l3_g7
	residual_l3_g7 -> aggregate_l3_g7
	residual_l3_g0 -> gate_l3_g8
	gate_l3_g8 -> expert_l3_e8_g8 [style=dashed]
	expert_l3_e8_g8 -> aggregate_l3_g8
	residual_l3_g0 -> aggregate_l3_g8
	residual_l3_g1 -> gate_l3_g9
	gate_l3_g9 -> expert_l3_e9_g9 [style=dashed]
	expert_l3_e9_g9 -> aggregate_l3_g9
	residual_l3_g1 -> aggregate_l3_g9
	residual_l3_g2 -> gate_l3_g10
	gate_l3_g10 -> expert_l3_e10_g10 [style=dashed]
	expert_l3_e10_g10 -> aggregate_l3_g10
	residual_l3_g2 -> aggregate_l3_g10
	residual_l3_g3 -> gate_l3_g11
	gate_l3_g11 -> expert_l3_e11_g11 [style=dashed]
	expert_l3_e11_g11 -> aggregate_l3_g11
	residual_l3_g3 -> aggregate_l3_g11
	residual_l3_g4 -> gate_l3_g12
	gate_l3_g12 -> expert_l3_e12_g12 [style=dashed]
	expert_l3_e12_g12 -> aggregate_l3_g12
	residual_l3_g4 -> aggregate_l3_g12
	residual_l3_g5 -> gate_l3_g13
	gate_l3_g13 -> expert_l3_e13_g13 [style=dashed]
	expert_l3_e13_g13 -> aggregate_l3_g13
	residual_l3_g5 -> aggregate_l3_g13
	residual_l3_g6 -> gate_l3_g14
	gate_l3_g14 -> expert_l3_e14_g14 [style=dashed]
	expert_l3_e14_g14 -> aggregate_l3_g14
	residual_l3_g6 -> aggregate_l3_g14
	residual_l3_g7 -> gate_l3_g15
	gate_l3_g15 -> expert_l3_e15_g15 [style=dashed]
	expert_l3_e15_g15 -> aggregate_l3_g15
	residual_l3_g7 -> aggregate_l3_g15
	aggregate_l3_g0 -> output
	aggregate_l3_g1 -> output
	aggregate_l3_g2 -> output
	aggregate_l3_g3 -> output
	aggregate_l3_g4 -> output
	aggregate_l3_g5 -> output
	aggregate_l3_g6 -> output
	aggregate_l3_g7 -> output
	aggregate_l3_g8 -> output
	aggregate_l3_g9 -> output
	aggregate_l3_g10 -> output
	aggregate_l3_g11 -> output
	aggregate_l3_g12 -> output
	aggregate_l3_g13 -> output
	aggregate_l3_g14 -> output
	aggregate_l3_g15 -> output
}
