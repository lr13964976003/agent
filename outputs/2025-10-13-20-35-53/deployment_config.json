{
  "deployment_configurations": {
    "baseline": {
      "name": "Baseline_TP8_PP2",
      "parallel_strategy": {
        "tensor_parallelism": {
          "degree": 8,
          "type": "column_row_parallel"
        },
        "pipeline_parallelism": {
          "degree": 2,
          "type": "sequential_pipeline"
        },
        "expert_parallelism": {
          "degree": 1,
          "type": "colocated_experts"
        }
      },
      "model_modules": {
        "layers": {
          "count": 4,
          "type": "moe_layer"
        },
        "experts_per_layer": 16,
        "experts_per_gpu": 8,
        "expert_type": "mlp",
        "expert_parameters": {
          "input_dimension": 8192,
          "hidden_dimension": 32768,
          "output_dimension": 8192,
          "precision": "FP16"
        },
        "attention_parameters": {
          "num_heads": 16,
          "head_dimension": 512,
          "total_dimension": 8192
        }
      },
      "device_mapping": {
        "total_gpus": 16,
        "gpu_assignments": [
          {
            "gpu_id": 0,
            "node_id": 0,
            "modules": [
              "tensor_shard_0_layer_0",
              "tensor_shard_0_layer_1",
              "tensor_shard_0_layer_2",
              "tensor_shard_0_layer_3",
              "experts_0_to_7_layer_0",
              "experts_0_to_7_layer_1",
              "experts_0_to_7_layer_2",
              "experts_0_to_7_layer_3"
            ]
          },
          {
            "gpu_id": 1,
            "node_id": 0,
            "modules": [
              "tensor_shard_1_layer_0",
              "tensor_shard_1_layer_1",
              "tensor_shard_1_layer_2",
              "tensor_shard_1_layer_3",
              "experts_0_to_7_layer_0",
              "experts_0_to_7_layer_1",
              "experts_0_to_7_layer_2",
              "experts_0_to_7_layer_3"
            ]
          },
          {
            "gpu_id": 2,
            "node_id": 0,
            "modules": [
              "tensor_shard_2_layer_0",
              "tensor_shard_2_layer_1",
              "tensor_shard_2_layer_2",
              "tensor_shard_2_layer_3",
              "experts_0_to_7_layer_0",
              "experts_0_to_7_layer_1",
              "experts_0_to_7_layer_2",
              "experts_0_to_7_layer_3"
            ]
          },
          {
            "gpu_id": 3,
            "node_id": 0,
            "modules": [
              "tensor_shard_3_layer_0",
              "tensor_shard_3_layer_1",
              "tensor_shard_3_layer_2",
              "tensor_shard_3_layer_3",
              "experts_0_to_7_layer_0",
              "experts_0_to_7_layer_1",
              "experts_0_to_7_layer_2",
              "experts_0_to_7_layer_3"
            ]
          },
          {
            "gpu_id": 4,
            "node_id": 0,
            "modules": [
              "tensor_shard_4_layer_0",
              "tensor_shard_4_layer_1",
              "tensor_shard_4_layer_2",
              "tensor_shard_4_layer_3",
              "experts_0_to_7_layer_0",
              "experts_0_to_7_layer_1",
              "experts_0_to_7_layer_2",
              "experts_0_to_7_layer_3"
            ]
          },
          {
            "gpu_id": 5,
            "node_id": 0,
            "modules": [
              "tensor_shard_5_layer_0",
              "tensor_shard_5_layer_1",
              "tensor_shard_5_layer_2",
              "tensor_shard_5_layer_3",
              "experts_0_to_7_layer_0",
              "experts_0_to_7_layer_1",
              "experts_0_to_7_layer_2",
              "experts_0_to_7_layer_3"
            ]
          },
          {
            "gpu_id": 6,
            "node_id": 0,
            "modules": [
              "tensor_shard_6_layer_0",
              "tensor_shard_6_layer_1",
              "tensor_shard_6_layer_2",
              "tensor_shard_6_layer_3",
              "experts_0_to_7_layer_0",
              "experts_0_to_7_layer_1",
              "experts_0_to_7_layer_2",
              "experts_0_to_7_layer_3"
            ]
          },
          {
            "gpu_id": 7,
            "node_id": 0,
            "modules": [
              "tensor_shard_7_layer_0",
              "tensor_shard_7_layer_1",
              "tensor_shard_7_layer_2",
              "tensor_shard_7_layer_3",
              "experts_0_to_7_layer_0",
              "experts_0_to_7_layer_1",
              "experts_0_to_7_layer_2",
              "experts_0_to_7_layer_3"
            ]
          },
          {
            "gpu_id": 8,
            "node_id": 1,
            "modules": [
              "tensor_shard_0_layer_0",
              "tensor_shard_0_layer_1",
              "tensor_shard_0_layer_2",
              "tensor_shard_0_layer_3",
              "experts_8_to_15_layer_0",
              "experts_8_to_15_layer_1",
              "experts_8_to_15_layer_2",
              "experts_8_to_15_layer_3"
            ]
          },
          {
            "gpu_id": 9,
            "node_id": 1,
            "modules": [
              "tensor_shard_1_layer_0",
              "tensor_shard_1_layer_1",
              "tensor_shard_1_layer_2",
              "tensor_shard_1_layer_3",
              "experts_8_to_15_layer_0",
              "experts_8_to_15_layer_1",
              "experts_8_to_15_layer_2",
              "experts_8_to_15_layer_3"
            ]
          },
          {
            "gpu_id": 10,
            "node_id": 1,
            "modules": [
              "tensor_shard_2_layer_0",
              "tensor_shard_2_layer_1",
              "tensor_shard_2_layer_2",
              "tensor_shard_2_layer_3",
              "experts_8_to_15_layer_0",
              "experts_8_to_15_layer_1",
              "experts_8_to_15_layer_2",
              "experts_8_to_15_layer_3"
            ]
          },
          {
            "gpu_id": 11,
            "node_id": 1,
            "modules": [
              "tensor_shard_3_layer_0",
              "tensor_shard_3_layer_1",
              "tensor_shard_3_layer_2",
              "tensor_shard_3_layer_3",
              "experts_8_to_15_layer_0",
              "experts_8_to_15_layer_1",
              "experts_8_to_15_layer_2",
              "experts_8_to_15_layer_3"
            ]
          },
          {
            "gpu_id": 12,
            "node_id": 1,
            "modules": [
              "tensor_shard_4_layer_0",
              "tensor_shard_4_layer_1",
              "tensor_shard_4_layer_2",
              "tensor_shard_4_layer_3",
              "experts_8_to_15_layer_0",
              "experts_8_to_15_layer_1",
              "experts_8_to_15_layer_2",
              "experts_8_to_15_layer_3"
            ]
          },
          {
            "gpu_id": 13,
            "node_id": 1,
            "modules": [
              "tensor_shard_5_layer_0",
              "tensor_shard_5_layer_1",
              "tensor_shard_5_layer_2",
              "tensor_shard_5_layer_3",
              "experts_8_to_15_layer_0",
              "experts_8_to_15_layer_1",
              "experts_8_to_15_layer_2",
              "experts_8_to_15_layer_3"
            ]
          },
          {
            "gpu_id": 14,
            "node_id": 1,
            "modules": [
              "tensor_shard_6_layer_0",
              "tensor_shard_6_layer_1",
              "tensor_shard_6_layer_2",
              "tensor_shard_6_layer_3",
              "experts_8_to_15_layer_0",
              "experts_8_to_15_layer_1",
              "experts_8_to_15_layer_2",
              "experts_8_to_15_layer_3"
            ]
          },
          {
            "gpu_id": 15,
            "node_id": 1,
            "modules": [
              "tensor_shard_7_layer_0",
              "tensor_shard_7_layer_1",
              "tensor_shard_7_layer_2",
              "tensor_shard_7_layer_3",
              "experts_8_to_15_layer_0",
              "experts_8_to_15_layer_1",
              "experts_8_to_15_layer_2",
              "experts_8_to_15_layer_3"
            ]
          }
        ]
      }
    },
    "proposed": {
      "name": "Cross_Node_Expert_Parallelism_EP16",
      "parallel_strategy": {
        "expert_parallelism": {
          "degree": 16,
          "type": "one_expert_per_gpu",
          "cross_node": true,
          "topology_aware": true
        },
        "tensor_parallelism": {
          "degree": 1,
          "type": "none"
        },
        "pipeline_parallelism": {
          "degree": 1,
          "type": "none"
        }
      },
      "model_modules": {
        "layers": {
          "count": 4,
          "type": "moe_layer"
        },
        "experts_per_layer": 16,
        "experts_per_gpu": 1,
        "expert_type": "mlp",
        "expert_parameters": {
          "input_dimension": 8192,
          "hidden_dimension": 32768,
          "output_dimension": 8192,
          "precision": "FP16"
        },
        "attention_parameters": {
          "num_heads": 16,
          "head_dimension": 512,
          "total_dimension": 8192
        },
        "communication_strategy": {
          "type": "asynchronous_routing",
          "token_batching": true,
          "overlap_compute_communication": true,
          "load_balancing": "dynamic_gating"
        }
      },
      "device_mapping": {
        "total_gpus": 16,
        "gpu_assignments": [
          {
            "gpu_id": 0,
            "node_id": 0,
            "modules": [
              "expert_0_layer_0",
              "expert_0_layer_1",
              "expert_0_layer_2",
              "expert_0_layer_3"
            ]
          },
          {
            "gpu_id": 1,
            "node_id": 0,
            "modules": [
              "expert_1_layer_0",
              "expert_1_layer_1",
              "expert_1_layer_2",
              "expert_1_layer_3"
            ]
          },
          {
            "gpu_id": 2,
            "node_id": 0,
            "modules": [
              "expert_2_layer_0",
              "expert_2_layer_1",
              "expert_2_layer_2",
              "expert_2_layer_3"
            ]
          },
          {
            "gpu_id": 3,
            "node_id": 0,
            "modules": [
              "expert_3_layer_0",
              "expert_3_layer_1",
              "expert_3_layer_2",
              "expert_3_layer_3"
            ]
          },
          {
            "gpu_id": 4,
            "node_id": 1,
            "modules": [
              "expert_4_layer_0",
              "expert_4_layer_1",
              "expert_4_layer_2",
              "expert_4_layer_3"
            ]
          },
          {
            "gpu_id": 5,
            "node_id": 1,
            "modules": [
              "expert_5_layer_0",
              "expert_5_layer_1",
              "expert_5_layer_2",
              "expert_5_layer_3"
            ]
          },
          {
            "gpu_id": 6,
            "node_id": 1,
            "modules": [
              "expert_6_layer_0",
              "expert_6_layer_1",
              "expert_6_layer_2",
              "expert_6_layer_3"
            ]
          },
          {
            "gpu_id": 7,
            "node_id": 1,
            "modules": [
              "expert_7_layer_0",
              "expert_7_layer_1",
              "expert_7_layer_2",
              "expert_7_layer_3"
            ]
          },
          {
            "gpu_id": 8,
            "node_id": 2,
            "modules": [
              "expert_8_layer_0",
              "expert_8_layer_1",
              "expert_8_layer_2",
              "expert_8_layer_3"
            ]
          },
          {
            "gpu_id": 9,
            "node_id": 2,
            "modules": [
              "expert_9_layer_0",
              "expert_9_layer_1",
              "expert_9_layer_2",
              "expert_9_layer_3"
            ]
          },
          {
            "gpu_id": 10,
            "node_id": 2,
            "modules": [
              "expert_10_layer_0",
              "expert_10_layer_1",
              "expert_10_layer_2",
              "expert_10_layer_3"
            ]
          },
          {
            "gpu_id": 11,
            "node_id": 2,
            "modules": [
              "expert_11_layer_0",
              "expert_11_layer_1",
              "expert_11_layer_2",
              "expert_11_layer_3"
            ]
          },
          {
            "gpu_id": 12,
            "node_id": 3,
            "modules": [
              "expert_12_layer_0",
              "expert_12_layer_1",
              "expert_12_layer_2",
              "expert_12_layer_3"
            ]
          },
          {
            "gpu_id": 13,
            "node_id": 3,
            "modules": [
              "expert_13_layer_0",
              "expert_13_layer_1",
              "expert_13_layer_2",
              "expert_13_layer_3"
            ]
          },
          {
            "gpu_id": 14,
            "node_id": 3,
            "modules": [
              "expert_14_layer_0",
              "expert_14_layer_1",
              "expert_14_layer_2",
              "expert_14_layer_3"
            ]
          },
          {
            "gpu_id": 15,
            "node_id": 3,
            "modules": [
              "expert_15_layer_0",
              "expert_15_layer_1",
              "expert_15_layer_2",
              "expert_15_layer_3"
            ]
          }
        ]
      },
      "communication_topology": {
        "intra_node_bandwidth": "NVLink",
        "inter_node_bandwidth": "InfiniBand",
        "routing_strategy": "topology_aware",
        "token_batching": {
          "enabled": true,
          "batch_size": "dynamic",
          "destination_grouping": true
        },
        "asynchronous_transfer": {
          "enabled": true,
          "overlap_factor": "maximal",
          "library": "NCCL"
        }
      }
    }
  },
  "batch_configuration": {
    "sequences_per_batch": 1024,
    "tokens_per_sequence": 10000,
    "total_tokens_per_batch": 10240000,
    "precision": "FP16"
  },
  "model_dimensions": {
    "token_dimension": 8192,
    "mlp_hidden_dimension": 32768,
    "attention_heads": 16,
    "attention_head_dimension": 512
  }
}