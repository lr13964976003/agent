digraph {
	graph [bb="0,0,5131.9,22276",
		fontname=Arial,
		rankdir=TB,
		size="25,20"
	];
	node [label="\N"];
	subgraph cluster_legend {
		graph [bb="2681,22182,3581,22257",
			color=gray,
			label=Legend,
			lheight=0.21,
			lp="3131,22246",
			lwidth=0.64,
			style=dashed
		];
		legend_compute	[color=lightblue,
			height=0.5,
			label=Computation,
			pos="3518,22208",
			shape=rectangle,
			style=filled,
			width=1.5139];
		legend_comm	[color=lightgreen,
			height=0.5,
			label=Communication,
			pos="3362,22208",
			shape=ellipse,
			style=filled,
			width=2.3109];
		legend_route	[color=lightyellow,
			height=0.5,
			label="Routing/Aggregation",
			pos="3104,22208",
			shape=parallelogram,
			style=filled,
			width=4.3676];
		legend_split	[color=orange,
			height=0.5,
			label=Split,
			pos="2881,22208",
			shape=parallelogram,
			style=filled,
			width=1.3235];
		legend_gather	[color=purple,
			height=0.5,
			label=Gather,
			pos="2752,22208",
			shape=parallelogram,
			style=filled,
			width=1.7471];
	}
	subgraph cluster_gpu0 {
		graph [bb="4013,20863,4885,22132",
			color=color1,
			label="GPU-0 (Layer 0)",
			lheight=0.21,
			lp="4449,22121",
			lwidth=1.39,
			style=rounded
		];
		mha_q_0	[color=lightblue,
			height=0.94444,
			label="GPU0_Layer0_MHA_Q
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-0",
			pos="4653,22067",
			shape=rectangle,
			style=filled,
			width=5.6806];
		attn_score_0	[color=lightblue,
			height=1.1528,
			label="GPU0_Layer0_Attn_Score
Input1: [batch=128, seq=10000, heads=32, d_k=128]
Input2: [batch=128, seq=10000, heads=32, d_k=128]
Output: [\
batch=128, seq=10000, heads=32, seq=10000]
Device: GPU-0",
			pos="4235,21956",
			shape=rectangle,
			style=filled,
			width=5.9444];
		mha_q_0 -> attn_score_0	[pos="e,4389.9,21997 4527,22033 4487,22023 4442.1,22011 4399.8,22000"];
		mha_k_0	[color=lightblue,
			height=0.94444,
			label="GPU0_Layer0_MHA_K
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-0",
			pos="4226,22067",
			shape=rectangle,
			style=filled,
			width=5.6806];
		mha_k_0 -> attn_score_0	[pos="e,4231.6,21998 4228.7,22033 4229.4,22025 4230.1,22016 4230.8,22008"];
		mha_v_0	[color=lightblue,
			height=0.94444,
			label="GPU0_Layer0_MHA_V
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-0",
			pos="4672,21956",
			shape=rectangle,
			style=filled,
			width=5.6806];
		attn_out_0	[color=lightblue,
			height=1.1528,
			label="GPU0_Layer0_Attn_Out
Input1: [batch=128, seq=10000, heads=32, seq=10000]
Input2: [batch=128, seq=10000, heads=32, d_k=128]
Output: [\
batch=128, seq=10000, hidden=4096]
Device: GPU-0",
			pos="4502,21837",
			shape=rectangle,
			style=filled,
			width=5.9028];
		mha_v_0 -> attn_out_0	[pos="e,4561,21878 4623.7,21922 4606.8,21910 4587.4,21897 4569.2,21884"];
		attn_score_0 -> attn_out_0	[pos="e,4409.5,21878 4327.6,21914 4351,21904 4376.3,21893 4400.1,21882"];
		attn_residual_0	[color=lightyellow,
			height=2.3056,
			label="GPU0_Layer0_Attn_Residual
Input1: [batch=128, seq=10000, hidden=4096]
Input2: [batch=128, seq=10000, hidden=4096]
Output: [batch=\
128, seq=10000, hidden=4096]
Device: GPU-0",
			pos="4502,21676",
			shape=parallelogram,
			style=filled,
			width=10.425];
		attn_out_0 -> attn_residual_0	[pos="e,4502,21760 4502,21795 4502,21787 4502,21778 4502,21770"];
		layernorm1_0	[color=lightblue,
			height=0.94444,
			label="GPU0_Layer0_LayerNorm1
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-0",
			pos="4533,21523",
			shape=rectangle,
			style=filled,
			width=5.0278];
		attn_residual_0 -> layernorm1_0	[pos="e,4526.2,21558 4518.9,21593 4520.7,21584 4522.5,21576 4524.1,21567"];
		ffn_up_0	[color=lightblue,
			height=0.94444,
			label="GPU0_Layer0_FFN_Up
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-0",
			pos="4196,21419",
			shape=rectangle,
			style=filled,
			width=4.8611];
		layernorm1_0 -> ffn_up_0	[pos="e,4305.2,21453 4423.6,21489 4388.9,21479 4350.4,21467 4315,21456"];
		ffn_gate_0	[color=lightblue,
			height=0.94444,
			label="GPU0_Layer0_FFN_Gate
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-0",
			pos="4564,21419",
			shape=rectangle,
			style=filled,
			width=4.8611];
		layernorm1_0 -> ffn_gate_0	[pos="e,4553.9,21454 4543.1,21489 4545.6,21481 4548.3,21472 4551,21463"];
		ffn_residual_0	[color=lightyellow,
			height=2.3056,
			label="GPU0_Layer0_FFN_Residual
Input1: [batch=128, seq=10000, hidden=4096]
Input2: [batch=128, seq=10000, hidden=4096]
Output: [batch=\
128, seq=10000, hidden=4096]
Device: GPU-0",
			pos="4502,21058",
			shape=parallelogram,
			style=filled,
			width=10.425];
		layernorm1_0 -> ffn_residual_0	[pos="e,4657.9,21141 4707.2,21489 4723,21480 4737.1,21468 4748,21453 4765.8,21429 4752,21415 4748,21385 4735.4,21290 4749.1,21254 4692,\
21177 4684.2,21167 4675.3,21157 4665.5,21148"];
		ffn_act_0	[color=lightblue,
			height=0.94444,
			label="GPU0_Layer0_FFN_Act
Input: [batch=128, seq=10000, ffn=16384]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-0",
			pos="4502,21315",
			shape=rectangle,
			style=filled,
			width=4.7361];
		ffn_up_0 -> ffn_act_0	[pos="e,4402.9,21349 4295.3,21385 4326.6,21375 4361.2,21363 4393.1,21353"];
		ffn_gate_0 -> ffn_act_0	[pos="e,4522.2,21350 4543.9,21385 4538.7,21377 4533,21367 4527.6,21358"];
		ffn_down_0	[color=lightblue,
			height=0.94444,
			label="GPU0_Layer0_FFN_Down
Input: [batch=128, seq=10000, ffn=16384]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-0",
			pos="4502,21211",
			shape=rectangle,
			style=filled,
			width=5.0278];
		ffn_act_0 -> ffn_down_0	[pos="e,4502,21246 4502,21281 4502,21273 4502,21264 4502,21256"];
		ffn_down_0 -> ffn_residual_0	[pos="e,4502,21142 4502,21177 4502,21169 4502,21161 4502,21152"];
		layernorm2_0	[color=lightblue,
			height=0.94444,
			label="GPU0_Layer0_LayerNorm2
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-0",
			pos="4502,20905",
			shape=rectangle,
			style=filled,
			width=5.0278];
		ffn_residual_0 -> layernorm2_0	[pos="e,4502,20940 4502,20975 4502,20966 4502,20958 4502,20950"];
	}
	subgraph cluster_gpu1 {
		graph [bb="3746,19483,4618,20752",
			color=color2,
			label="GPU-1 (Layer 1)",
			lheight=0.21,
			lp="4182,20741",
			lwidth=1.39,
			style=rounded
		];
		mha_q_1	[color=lightblue,
			height=0.94444,
			label="GPU1_Layer1_MHA_Q
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-1",
			pos="4386,20687",
			shape=rectangle,
			style=filled,
			width=5.6806];
		attn_score_1	[color=lightblue,
			height=1.1528,
			label="GPU1_Layer1_Attn_Score
Input1: [batch=128, seq=10000, heads=32, d_k=128]
Input2: [batch=128, seq=10000, heads=32, d_k=128]
Output: [\
batch=128, seq=10000, heads=32, seq=10000]
Device: GPU-1",
			pos="3968,20576",
			shape=rectangle,
			style=filled,
			width=5.9444];
		mha_q_1 -> attn_score_1	[pos="e,4122.9,20617 4260,20653 4220,20643 4175.1,20631 4132.8,20620"];
		mha_k_1	[color=lightblue,
			height=0.94444,
			label="GPU1_Layer1_MHA_K
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-1",
			pos="3959,20687",
			shape=rectangle,
			style=filled,
			width=5.6806];
		mha_k_1 -> attn_score_1	[pos="e,3964.6,20618 3961.7,20653 3962.4,20645 3963.1,20636 3963.8,20628"];
		mha_v_1	[color=lightblue,
			height=0.94444,
			label="GPU1_Layer1_MHA_V
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-1",
			pos="4405,20576",
			shape=rectangle,
			style=filled,
			width=5.6806];
		attn_out_1	[color=lightblue,
			height=1.1528,
			label="GPU1_Layer1_Attn_Out
Input1: [batch=128, seq=10000, heads=32, seq=10000]
Input2: [batch=128, seq=10000, heads=32, d_k=128]
Output: [\
batch=128, seq=10000, hidden=4096]
Device: GPU-1",
			pos="4235,20457",
			shape=rectangle,
			style=filled,
			width=5.9028];
		mha_v_1 -> attn_out_1	[pos="e,4294,20498 4356.7,20542 4339.8,20530 4320.4,20517 4302.2,20504"];
		attn_score_1 -> attn_out_1	[pos="e,4142.5,20498 4060.6,20534 4084,20524 4109.3,20513 4133.1,20502"];
		attn_residual_1	[color=lightyellow,
			height=2.3056,
			label="GPU1_Layer1_Attn_Residual
Input1: [batch=128, seq=10000, hidden=4096]
Input2: [batch=128, seq=10000, hidden=4096]
Output: [batch=\
128, seq=10000, hidden=4096]
Device: GPU-1",
			pos="4235,20296",
			shape=parallelogram,
			style=filled,
			width=10.425];
		attn_out_1 -> attn_residual_1	[pos="e,4235,20380 4235,20415 4235,20407 4235,20398 4235,20390"];
		layernorm1_1	[color=lightblue,
			height=0.94444,
			label="GPU1_Layer1_LayerNorm1
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-1",
			pos="4266,20143",
			shape=rectangle,
			style=filled,
			width=5.0278];
		attn_residual_1 -> layernorm1_1	[pos="e,4259.2,20178 4251.9,20213 4253.7,20204 4255.5,20196 4257.1,20188"];
		ffn_up_1	[color=lightblue,
			height=0.94444,
			label="GPU1_Layer1_FFN_Up
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-1",
			pos="3929,20039",
			shape=rectangle,
			style=filled,
			width=4.8611];
		layernorm1_1 -> ffn_up_1	[pos="e,4038.2,20073 4156.6,20109 4121.9,20099 4083.4,20087 4048,20076"];
		ffn_gate_1	[color=lightblue,
			height=0.94444,
			label="GPU1_Layer1_FFN_Gate
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-1",
			pos="4297,20039",
			shape=rectangle,
			style=filled,
			width=4.8611];
		layernorm1_1 -> ffn_gate_1	[pos="e,4286.9,20074 4276.1,20109 4278.6,20101 4281.3,20092 4284,20083"];
		ffn_residual_1	[color=lightyellow,
			height=2.3056,
			label="GPU1_Layer1_FFN_Residual
Input1: [batch=128, seq=10000, hidden=4096]
Input2: [batch=128, seq=10000, hidden=4096]
Output: [batch=\
128, seq=10000, hidden=4096]
Device: GPU-1",
			pos="4235,19678",
			shape=parallelogram,
			style=filled,
			width=10.425];
		layernorm1_1 -> ffn_residual_1	[pos="e,4390.9,19761 4440.2,20109 4456,20100 4470.1,20088 4481,20073 4498.8,20049 4485,20035 4481,20005 4468.4,19910 4482.1,19874 4425,\
19797 4417.2,19787 4408.3,19777 4398.5,19768"];
		ffn_act_1	[color=lightblue,
			height=0.94444,
			label="GPU1_Layer1_FFN_Act
Input: [batch=128, seq=10000, ffn=16384]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-1",
			pos="4235,19935",
			shape=rectangle,
			style=filled,
			width=4.7361];
		ffn_up_1 -> ffn_act_1	[pos="e,4135.9,19969 4028.3,20005 4059.6,19995 4094.2,19983 4126.1,19973"];
		ffn_gate_1 -> ffn_act_1	[pos="e,4255.2,19970 4276.9,20005 4271.7,19997 4266,19987 4260.6,19978"];
		ffn_down_1	[color=lightblue,
			height=0.94444,
			label="GPU1_Layer1_FFN_Down
Input: [batch=128, seq=10000, ffn=16384]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-1",
			pos="4235,19831",
			shape=rectangle,
			style=filled,
			width=5.0278];
		ffn_act_1 -> ffn_down_1	[pos="e,4235,19866 4235,19901 4235,19893 4235,19884 4235,19876"];
		ffn_down_1 -> ffn_residual_1	[pos="e,4235,19762 4235,19797 4235,19789 4235,19781 4235,19772"];
		layernorm2_1	[color=lightblue,
			height=0.94444,
			label="GPU1_Layer1_LayerNorm2
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-1",
			pos="4235,19525",
			shape=rectangle,
			style=filled,
			width=5.0278];
		ffn_residual_1 -> layernorm2_1	[pos="e,4235,19560 4235,19595 4235,19586 4235,19578 4235,19570"];
	}
	subgraph cluster_gpu2 {
		graph [bb="3479,18103,4351,19372",
			color=color3,
			label="GPU-2 (Layer 2)",
			lheight=0.21,
			lp="3915,19361",
			lwidth=1.39,
			style=rounded
		];
		mha_q_2	[color=lightblue,
			height=0.94444,
			label="GPU2_Layer2_MHA_Q
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-2",
			pos="4119,19307",
			shape=rectangle,
			style=filled,
			width=5.6806];
		attn_score_2	[color=lightblue,
			height=1.1528,
			label="GPU2_Layer2_Attn_Score
Input1: [batch=128, seq=10000, heads=32, d_k=128]
Input2: [batch=128, seq=10000, heads=32, d_k=128]
Output: [\
batch=128, seq=10000, heads=32, seq=10000]
Device: GPU-2",
			pos="3701,19196",
			shape=rectangle,
			style=filled,
			width=5.9444];
		mha_q_2 -> attn_score_2	[pos="e,3855.9,19237 3993,19273 3953,19263 3908.1,19251 3865.8,19240"];
		mha_k_2	[color=lightblue,
			height=0.94444,
			label="GPU2_Layer2_MHA_K
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-2",
			pos="3692,19307",
			shape=rectangle,
			style=filled,
			width=5.6806];
		mha_k_2 -> attn_score_2	[pos="e,3697.6,19238 3694.7,19273 3695.4,19265 3696.1,19256 3696.8,19248"];
		mha_v_2	[color=lightblue,
			height=0.94444,
			label="GPU2_Layer2_MHA_V
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-2",
			pos="4138,19196",
			shape=rectangle,
			style=filled,
			width=5.6806];
		attn_out_2	[color=lightblue,
			height=1.1528,
			label="GPU2_Layer2_Attn_Out
Input1: [batch=128, seq=10000, heads=32, seq=10000]
Input2: [batch=128, seq=10000, heads=32, d_k=128]
Output: [\
batch=128, seq=10000, hidden=4096]
Device: GPU-2",
			pos="3968,19077",
			shape=rectangle,
			style=filled,
			width=5.9028];
		mha_v_2 -> attn_out_2	[pos="e,4027,19118 4089.7,19162 4072.8,19150 4053.4,19137 4035.2,19124"];
		attn_score_2 -> attn_out_2	[pos="e,3875.5,19118 3793.6,19154 3817,19144 3842.3,19133 3866.1,19123"];
		attn_residual_2	[color=lightyellow,
			height=2.3056,
			label="GPU2_Layer2_Attn_Residual
Input1: [batch=128, seq=10000, hidden=4096]
Input2: [batch=128, seq=10000, hidden=4096]
Output: [batch=\
128, seq=10000, hidden=4096]
Device: GPU-2",
			pos="3968,18916",
			shape=parallelogram,
			style=filled,
			width=10.425];
		attn_out_2 -> attn_residual_2	[pos="e,3968,19000 3968,19035 3968,19027 3968,19019 3968,19010"];
		layernorm1_2	[color=lightblue,
			height=0.94444,
			label="GPU2_Layer2_LayerNorm1
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-2",
			pos="3999,18763",
			shape=rectangle,
			style=filled,
			width=5.0278];
		attn_residual_2 -> layernorm1_2	[pos="e,3992.2,18798 3984.9,18833 3986.7,18824 3988.5,18816 3990.1,18808"];
		ffn_up_2	[color=lightblue,
			height=0.94444,
			label="GPU2_Layer2_FFN_Up
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-2",
			pos="3662,18659",
			shape=rectangle,
			style=filled,
			width=4.8611];
		layernorm1_2 -> ffn_up_2	[pos="e,3771.2,18693 3889.6,18729 3854.9,18719 3816.4,18707 3781,18696"];
		ffn_gate_2	[color=lightblue,
			height=0.94444,
			label="GPU2_Layer2_FFN_Gate
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-2",
			pos="4030,18659",
			shape=rectangle,
			style=filled,
			width=4.8611];
		layernorm1_2 -> ffn_gate_2	[pos="e,4019.9,18694 4009.1,18729 4011.6,18721 4014.3,18712 4017,18703"];
		ffn_residual_2	[color=lightyellow,
			height=2.3056,
			label="GPU2_Layer2_FFN_Residual
Input1: [batch=128, seq=10000, hidden=4096]
Input2: [batch=128, seq=10000, hidden=4096]
Output: [batch=\
128, seq=10000, hidden=4096]
Device: GPU-2",
			pos="3968,18298",
			shape=parallelogram,
			style=filled,
			width=10.425];
		layernorm1_2 -> ffn_residual_2	[pos="e,4123.9,18381 4173.2,18729 4189,18720 4203.1,18708 4214,18693 4231.8,18669 4218,18655 4214,18625 4201.4,18530 4215.1,18494 4158,\
18417 4150.2,18407 4141.3,18397 4131.5,18388"];
		ffn_act_2	[color=lightblue,
			height=0.94444,
			label="GPU2_Layer2_FFN_Act
Input: [batch=128, seq=10000, ffn=16384]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-2",
			pos="3968,18555",
			shape=rectangle,
			style=filled,
			width=4.7361];
		ffn_up_2 -> ffn_act_2	[pos="e,3868.9,18589 3761.3,18625 3792.6,18615 3827.2,18603 3859.1,18593"];
		ffn_gate_2 -> ffn_act_2	[pos="e,3988.2,18590 4009.9,18625 4004.7,18617 3999,18607 3993.6,18598"];
		ffn_down_2	[color=lightblue,
			height=0.94444,
			label="GPU2_Layer2_FFN_Down
Input: [batch=128, seq=10000, ffn=16384]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-2",
			pos="3968,18451",
			shape=rectangle,
			style=filled,
			width=5.0278];
		ffn_act_2 -> ffn_down_2	[pos="e,3968,18486 3968,18521 3968,18513 3968,18504 3968,18496"];
		ffn_down_2 -> ffn_residual_2	[pos="e,3968,18382 3968,18417 3968,18409 3968,18401 3968,18392"];
		layernorm2_2	[color=lightblue,
			height=0.94444,
			label="GPU2_Layer2_LayerNorm2
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-2",
			pos="3968,18145",
			shape=rectangle,
			style=filled,
			width=5.0278];
		ffn_residual_2 -> layernorm2_2	[pos="e,3968,18180 3968,18215 3968,18207 3968,18198 3968,18190"];
	}
	subgraph cluster_gpu3 {
		graph [bb="3212,16723,4084,17992",
			color=color4,
			label="GPU-3 (Layer 3)",
			lheight=0.21,
			lp="3648,17981",
			lwidth=1.39,
			style=rounded
		];
		mha_q_3	[color=lightblue,
			height=0.94444,
			label="GPU3_Layer3_MHA_Q
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-3",
			pos="3852,17927",
			shape=rectangle,
			style=filled,
			width=5.6806];
		attn_score_3	[color=lightblue,
			height=1.1528,
			label="GPU3_Layer3_Attn_Score
Input1: [batch=128, seq=10000, heads=32, d_k=128]
Input2: [batch=128, seq=10000, heads=32, d_k=128]
Output: [\
batch=128, seq=10000, heads=32, seq=10000]
Device: GPU-3",
			pos="3434,17816",
			shape=rectangle,
			style=filled,
			width=5.9444];
		mha_q_3 -> attn_score_3	[pos="e,3588.9,17858 3726,17893 3686,17883 3641.1,17871 3598.8,17860"];
		mha_k_3	[color=lightblue,
			height=0.94444,
			label="GPU3_Layer3_MHA_K
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-3",
			pos="3425,17927",
			shape=rectangle,
			style=filled,
			width=5.6806];
		mha_k_3 -> attn_score_3	[pos="e,3430.6,17858 3427.7,17893 3428.4,17885 3429.1,17876 3429.8,17868"];
		mha_v_3	[color=lightblue,
			height=0.94444,
			label="GPU3_Layer3_MHA_V
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-3",
			pos="3871,17816",
			shape=rectangle,
			style=filled,
			width=5.6806];
		attn_out_3	[color=lightblue,
			height=1.1528,
			label="GPU3_Layer3_Attn_Out
Input1: [batch=128, seq=10000, heads=32, seq=10000]
Input2: [batch=128, seq=10000, heads=32, d_k=128]
Output: [\
batch=128, seq=10000, hidden=4096]
Device: GPU-3",
			pos="3701,17697",
			shape=rectangle,
			style=filled,
			width=5.9028];
		mha_v_3 -> attn_out_3	[pos="e,3760,17739 3822.7,17782 3805.8,17770 3786.4,17757 3768.2,17744"];
		attn_score_3 -> attn_out_3	[pos="e,3608.5,17738 3526.6,17774 3550,17764 3575.3,17753 3599.1,17743"];
		attn_residual_3	[color=lightyellow,
			height=2.3056,
			label="GPU3_Layer3_Attn_Residual
Input1: [batch=128, seq=10000, hidden=4096]
Input2: [batch=128, seq=10000, hidden=4096]
Output: [batch=\
128, seq=10000, hidden=4096]
Device: GPU-3",
			pos="3701,17536",
			shape=parallelogram,
			style=filled,
			width=10.425];
		attn_out_3 -> attn_residual_3	[pos="e,3701,17620 3701,17655 3701,17647 3701,17639 3701,17630"];
		layernorm1_3	[color=lightblue,
			height=0.94444,
			label="GPU3_Layer3_LayerNorm1
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-3",
			pos="3732,17383",
			shape=rectangle,
			style=filled,
			width=5.0278];
		attn_residual_3 -> layernorm1_3	[pos="e,3725.2,17418 3717.9,17453 3719.7,17444 3721.5,17436 3723.1,17428"];
		ffn_up_3	[color=lightblue,
			height=0.94444,
			label="GPU3_Layer3_FFN_Up
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-3",
			pos="3395,17279",
			shape=rectangle,
			style=filled,
			width=4.8611];
		layernorm1_3 -> ffn_up_3	[pos="e,3504.2,17313 3622.6,17349 3587.9,17339 3549.4,17327 3514,17316"];
		ffn_gate_3	[color=lightblue,
			height=0.94444,
			label="GPU3_Layer3_FFN_Gate
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-3",
			pos="3763,17279",
			shape=rectangle,
			style=filled,
			width=4.8611];
		layernorm1_3 -> ffn_gate_3	[pos="e,3752.9,17314 3742.1,17349 3744.6,17341 3747.3,17332 3750,17323"];
		ffn_residual_3	[color=lightyellow,
			height=2.3056,
			label="GPU3_Layer3_FFN_Residual
Input1: [batch=128, seq=10000, hidden=4096]
Input2: [batch=128, seq=10000, hidden=4096]
Output: [batch=\
128, seq=10000, hidden=4096]
Device: GPU-3",
			pos="3701,16918",
			shape=parallelogram,
			style=filled,
			width=10.425];
		layernorm1_3 -> ffn_residual_3	[pos="e,3856.9,17002 3906.2,17349 3922,17340 3936.1,17328 3947,17313 3964.8,17289 3951,17275 3947,17245 3934.4,17151 3948.1,17114 3891,\
17037 3883.2,17027 3874.3,17017 3864.5,17008"];
		ffn_act_3	[color=lightblue,
			height=0.94444,
			label="GPU3_Layer3_FFN_Act
Input: [batch=128, seq=10000, ffn=16384]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-3",
			pos="3701,17175",
			shape=rectangle,
			style=filled,
			width=4.7361];
		ffn_up_3 -> ffn_act_3	[pos="e,3601.9,17209 3494.3,17245 3525.6,17235 3560.2,17223 3592.1,17213"];
		ffn_gate_3 -> ffn_act_3	[pos="e,3721.2,17210 3742.9,17245 3737.7,17237 3732,17227 3726.6,17219"];
		ffn_down_3	[color=lightblue,
			height=0.94444,
			label="GPU3_Layer3_FFN_Down
Input: [batch=128, seq=10000, ffn=16384]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-3",
			pos="3701,17071",
			shape=rectangle,
			style=filled,
			width=5.0278];
		ffn_act_3 -> ffn_down_3	[pos="e,3701,17106 3701,17141 3701,17133 3701,17124 3701,17116"];
		ffn_down_3 -> ffn_residual_3	[pos="e,3701,17002 3701,17037 3701,17030 3701,17021 3701,17012"];
		layernorm2_3	[color=lightblue,
			height=0.94444,
			label="GPU3_Layer3_LayerNorm2
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-3",
			pos="3701,16765",
			shape=rectangle,
			style=filled,
			width=5.0278];
		ffn_residual_3 -> layernorm2_3	[pos="e,3701,16800 3701,16835 3701,16827 3701,16818 3701,16810"];
	}
	subgraph cluster_gpu4 {
		graph [bb="2945,15343,3817,16612",
			color=color5,
			label="GPU-4 (Layer 4)",
			lheight=0.21,
			lp="3381,16601",
			lwidth=1.39,
			style=rounded
		];
		mha_q_4	[color=lightblue,
			height=0.94444,
			label="GPU4_Layer4_MHA_Q
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-4",
			pos="3585,16547",
			shape=rectangle,
			style=filled,
			width=5.6806];
		attn_score_4	[color=lightblue,
			height=1.1528,
			label="GPU4_Layer4_Attn_Score
Input1: [batch=128, seq=10000, heads=32, d_k=128]
Input2: [batch=128, seq=10000, heads=32, d_k=128]
Output: [\
batch=128, seq=10000, heads=32, seq=10000]
Device: GPU-4",
			pos="3167,16436",
			shape=rectangle,
			style=filled,
			width=5.9444];
		mha_q_4 -> attn_score_4	[pos="e,3321.9,16478 3459,16513 3419,16503 3374.1,16491 3331.8,16480"];
		mha_k_4	[color=lightblue,
			height=0.94444,
			label="GPU4_Layer4_MHA_K
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-4",
			pos="3158,16547",
			shape=rectangle,
			style=filled,
			width=5.6806];
		mha_k_4 -> attn_score_4	[pos="e,3163.6,16478 3160.7,16513 3161.4,16505 3162.1,16496 3162.8,16488"];
		mha_v_4	[color=lightblue,
			height=0.94444,
			label="GPU4_Layer4_MHA_V
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-4",
			pos="3604,16436",
			shape=rectangle,
			style=filled,
			width=5.6806];
		attn_out_4	[color=lightblue,
			height=1.1528,
			label="GPU4_Layer4_Attn_Out
Input1: [batch=128, seq=10000, heads=32, seq=10000]
Input2: [batch=128, seq=10000, heads=32, d_k=128]
Output: [\
batch=128, seq=10000, hidden=4096]
Device: GPU-4",
			pos="3434,16317",
			shape=rectangle,
			style=filled,
			width=5.9028];
		mha_v_4 -> attn_out_4	[pos="e,3493,16359 3555.7,16402 3538.8,16390 3519.4,16377 3501.2,16364"];
		attn_score_4 -> attn_out_4	[pos="e,3341.5,16359 3259.6,16394 3283,16384 3308.3,16373 3332.1,16363"];
		attn_residual_4	[color=lightyellow,
			height=2.3056,
			label="GPU4_Layer4_Attn_Residual
Input1: [batch=128, seq=10000, hidden=4096]
Input2: [batch=128, seq=10000, hidden=4096]
Output: [batch=\
128, seq=10000, hidden=4096]
Device: GPU-4",
			pos="3434,16156",
			shape=parallelogram,
			style=filled,
			width=10.425];
		attn_out_4 -> attn_residual_4	[pos="e,3434,16240 3434,16275 3434,16267 3434,16259 3434,16250"];
		layernorm1_4	[color=lightblue,
			height=0.94444,
			label="GPU4_Layer4_LayerNorm1
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-4",
			pos="3465,16003",
			shape=rectangle,
			style=filled,
			width=5.0278];
		attn_residual_4 -> layernorm1_4	[pos="e,3458.2,16038 3450.9,16073 3452.7,16065 3454.5,16056 3456.1,16048"];
		ffn_up_4	[color=lightblue,
			height=0.94444,
			label="GPU4_Layer4_FFN_Up
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-4",
			pos="3128,15899",
			shape=rectangle,
			style=filled,
			width=4.8611];
		layernorm1_4 -> ffn_up_4	[pos="e,3237.2,15934 3355.6,15969 3320.9,15959 3282.4,15947 3247,15937"];
		ffn_gate_4	[color=lightblue,
			height=0.94444,
			label="GPU4_Layer4_FFN_Gate
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-4",
			pos="3496,15899",
			shape=rectangle,
			style=filled,
			width=4.8611];
		layernorm1_4 -> ffn_gate_4	[pos="e,3485.9,15934 3475.1,15969 3477.6,15961 3480.3,15952 3483,15943"];
		ffn_residual_4	[color=lightyellow,
			height=2.3056,
			label="GPU4_Layer4_FFN_Residual
Input1: [batch=128, seq=10000, hidden=4096]
Input2: [batch=128, seq=10000, hidden=4096]
Output: [batch=\
128, seq=10000, hidden=4096]
Device: GPU-4",
			pos="3434,15538",
			shape=parallelogram,
			style=filled,
			width=10.425];
		layernorm1_4 -> ffn_residual_4	[pos="e,3589.9,15622 3639.2,15969 3655,15960 3669.1,15948 3680,15933 3697.8,15909 3684,15895 3680,15865 3667.4,15771 3681.1,15734 3624,\
15657 3616.2,15647 3607.3,15637 3597.5,15628"];
		ffn_act_4	[color=lightblue,
			height=0.94444,
			label="GPU4_Layer4_FFN_Act
Input: [batch=128, seq=10000, ffn=16384]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-4",
			pos="3434,15795",
			shape=rectangle,
			style=filled,
			width=4.7361];
		ffn_up_4 -> ffn_act_4	[pos="e,3334.9,15830 3227.3,15865 3258.6,15855 3293.2,15843 3325.1,15833"];
		ffn_gate_4 -> ffn_act_4	[pos="e,3454.2,15830 3475.9,15865 3470.7,15857 3465,15847 3459.6,15839"];
		ffn_down_4	[color=lightblue,
			height=0.94444,
			label="GPU4_Layer4_FFN_Down
Input: [batch=128, seq=10000, ffn=16384]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-4",
			pos="3434,15691",
			shape=rectangle,
			style=filled,
			width=5.0278];
		ffn_act_4 -> ffn_down_4	[pos="e,3434,15726 3434,15761 3434,15753 3434,15744 3434,15736"];
		ffn_down_4 -> ffn_residual_4	[pos="e,3434,15622 3434,15657 3434,15650 3434,15641 3434,15632"];
		layernorm2_4	[color=lightblue,
			height=0.94444,
			label="GPU4_Layer4_LayerNorm2
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-4",
			pos="3434,15385",
			shape=rectangle,
			style=filled,
			width=5.0278];
		ffn_residual_4 -> layernorm2_4	[pos="e,3434,15420 3434,15455 3434,15447 3434,15438 3434,15430"];
	}
	subgraph cluster_gpu5 {
		graph [bb="2678,13964,3550,15233",
			color=color6,
			label="GPU-5 (Layer 5)",
			lheight=0.21,
			lp="3114,15221",
			lwidth=1.39,
			style=rounded
		];
		mha_q_5	[color=lightblue,
			height=0.94444,
			label="GPU5_Layer5_MHA_Q
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-5",
			pos="3318,15168",
			shape=rectangle,
			style=filled,
			width=5.6806];
		attn_score_5	[color=lightblue,
			height=1.1528,
			label="GPU5_Layer5_Attn_Score
Input1: [batch=128, seq=10000, heads=32, d_k=128]
Input2: [batch=128, seq=10000, heads=32, d_k=128]
Output: [\
batch=128, seq=10000, heads=32, seq=10000]
Device: GPU-5",
			pos="2900,15056",
			shape=rectangle,
			style=filled,
			width=5.9444];
		mha_q_5 -> attn_score_5	[pos="e,3054.9,15098 3192,15134 3152,15123 3107.1,15111 3064.8,15100"];
		mha_k_5	[color=lightblue,
			height=0.94444,
			label="GPU5_Layer5_MHA_K
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-5",
			pos="2891,15168",
			shape=rectangle,
			style=filled,
			width=5.6806];
		mha_k_5 -> attn_score_5	[pos="e,2896.6,15098 2893.7,15133 2894.4,15125 2895.1,15117 2895.8,15108"];
		mha_v_5	[color=lightblue,
			height=0.94444,
			label="GPU5_Layer5_MHA_V
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-5",
			pos="3337,15056",
			shape=rectangle,
			style=filled,
			width=5.6806];
		attn_out_5	[color=lightblue,
			height=1.1528,
			label="GPU5_Layer5_Attn_Out
Input1: [batch=128, seq=10000, heads=32, seq=10000]
Input2: [batch=128, seq=10000, heads=32, d_k=128]
Output: [\
batch=128, seq=10000, hidden=4096]
Device: GPU-5",
			pos="3167,14937",
			shape=rectangle,
			style=filled,
			width=5.9028];
		mha_v_5 -> attn_out_5	[pos="e,3226,14979 3288.7,15022 3271.8,15010 3252.4,14997 3234.2,14984"];
		attn_score_5 -> attn_out_5	[pos="e,3074.5,14979 2992.6,15014 3016,15004 3041.3,14993 3065.1,14983"];
		attn_residual_5	[color=lightyellow,
			height=2.3056,
			label="GPU5_Layer5_Attn_Residual
Input1: [batch=128, seq=10000, hidden=4096]
Input2: [batch=128, seq=10000, hidden=4096]
Output: [batch=\
128, seq=10000, hidden=4096]
Device: GPU-5",
			pos="3167,14777",
			shape=parallelogram,
			style=filled,
			width=10.425];
		attn_out_5 -> attn_residual_5	[pos="e,3167,14860 3167,14895 3167,14887 3167,14879 3167,14870"];
		layernorm1_5	[color=lightblue,
			height=0.94444,
			label="GPU5_Layer5_LayerNorm1
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-5",
			pos="3198,14624",
			shape=rectangle,
			style=filled,
			width=5.0278];
		attn_residual_5 -> layernorm1_5	[pos="e,3191.2,14658 3183.9,14693 3185.7,14685 3187.5,14676 3189.1,14668"];
		ffn_up_5	[color=lightblue,
			height=0.94444,
			label="GPU5_Layer5_FFN_Up
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-5",
			pos="2861,14520",
			shape=rectangle,
			style=filled,
			width=4.8611];
		layernorm1_5 -> ffn_up_5	[pos="e,2970.2,14554 3088.6,14589 3053.9,14579 3015.4,14567 2980,14557"];
		ffn_gate_5	[color=lightblue,
			height=0.94444,
			label="GPU5_Layer5_FFN_Gate
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-5",
			pos="3229,14520",
			shape=rectangle,
			style=filled,
			width=4.8611];
		layernorm1_5 -> ffn_gate_5	[pos="e,3218.9,14554 3208.1,14589 3210.6,14581 3213.3,14572 3216,14563"];
		ffn_residual_5	[color=lightyellow,
			height=2.3056,
			label="GPU5_Layer5_FFN_Residual
Input1: [batch=128, seq=10000, hidden=4096]
Input2: [batch=128, seq=10000, hidden=4096]
Output: [batch=\
128, seq=10000, hidden=4096]
Device: GPU-5",
			pos="3167,14159",
			shape=parallelogram,
			style=filled,
			width=10.425];
		layernorm1_5 -> ffn_residual_5	[pos="e,3322.9,14242 3372.2,14589 3388,14580 3402.1,14568 3413,14554 3430.8,14529 3417,14515 3413,14486 3400.4,14391 3414.1,14354 3357,\
14278 3349.2,14267 3340.3,14257 3330.5,14248"];
		ffn_act_5	[color=lightblue,
			height=0.94444,
			label="GPU5_Layer5_FFN_Act
Input: [batch=128, seq=10000, ffn=16384]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-5",
			pos="3167,14416",
			shape=rectangle,
			style=filled,
			width=4.7361];
		ffn_up_5 -> ffn_act_5	[pos="e,3067.9,14450 2960.3,14485 2991.6,14475 3026.2,14463 3058.1,14453"];
		ffn_gate_5 -> ffn_act_5	[pos="e,3187.2,14450 3208.9,14485 3203.7,14477 3198,14468 3192.6,14459"];
		ffn_down_5	[color=lightblue,
			height=0.94444,
			label="GPU5_Layer5_FFN_Down
Input: [batch=128, seq=10000, ffn=16384]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-5",
			pos="3167,14312",
			shape=rectangle,
			style=filled,
			width=5.0278];
		ffn_act_5 -> ffn_down_5	[pos="e,3167,14346 3167,14381 3167,14373 3167,14365 3167,14356"];
		ffn_down_5 -> ffn_residual_5	[pos="e,3167,14242 3167,14277 3167,14270 3167,14261 3167,14252"];
		layernorm2_5	[color=lightblue,
			height=0.94444,
			label="GPU5_Layer5_LayerNorm2
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-5",
			pos="3167,14006",
			shape=rectangle,
			style=filled,
			width=5.0278];
		ffn_residual_5 -> layernorm2_5	[pos="e,3167,14040 3167,14075 3167,14067 3167,14058 3167,14050"];
	}
	subgraph cluster_gpu6 {
		graph [bb="2411,12584,3283,13853",
			color=color7,
			label="GPU-6 (Layer 6)",
			lheight=0.21,
			lp="2847,13841",
			lwidth=1.39,
			style=rounded
		];
		mha_q_6	[color=lightblue,
			height=0.94444,
			label="GPU6_Layer6_MHA_Q
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-6",
			pos="3051,13788",
			shape=rectangle,
			style=filled,
			width=5.6806];
		attn_score_6	[color=lightblue,
			height=1.1528,
			label="GPU6_Layer6_Attn_Score
Input1: [batch=128, seq=10000, heads=32, d_k=128]
Input2: [batch=128, seq=10000, heads=32, d_k=128]
Output: [\
batch=128, seq=10000, heads=32, seq=10000]
Device: GPU-6",
			pos="2633,13676",
			shape=rectangle,
			style=filled,
			width=5.9444];
		mha_q_6 -> attn_score_6	[pos="e,2787.9,13718 2925,13754 2885,13743 2840.1,13731 2797.8,13720"];
		mha_k_6	[color=lightblue,
			height=0.94444,
			label="GPU6_Layer6_MHA_K
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-6",
			pos="2624,13788",
			shape=rectangle,
			style=filled,
			width=5.6806];
		mha_k_6 -> attn_score_6	[pos="e,2629.6,13718 2626.7,13753 2627.4,13745 2628.1,13737 2628.8,13728"];
		mha_v_6	[color=lightblue,
			height=0.94444,
			label="GPU6_Layer6_MHA_V
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-6",
			pos="3070,13676",
			shape=rectangle,
			style=filled,
			width=5.6806];
		attn_out_6	[color=lightblue,
			height=1.1528,
			label="GPU6_Layer6_Attn_Out
Input1: [batch=128, seq=10000, heads=32, seq=10000]
Input2: [batch=128, seq=10000, heads=32, d_k=128]
Output: [\
batch=128, seq=10000, hidden=4096]
Device: GPU-6",
			pos="2900,13557",
			shape=rectangle,
			style=filled,
			width=5.9028];
		mha_v_6 -> attn_out_6	[pos="e,2959,13599 3021.7,13642 3004.8,13630 2985.4,13617 2967.2,13604"];
		attn_score_6 -> attn_out_6	[pos="e,2807.5,13599 2725.6,13634 2749,13624 2774.3,13613 2798.1,13603"];
		attn_residual_6	[color=lightyellow,
			height=2.3056,
			label="GPU6_Layer6_Attn_Residual
Input1: [batch=128, seq=10000, hidden=4096]
Input2: [batch=128, seq=10000, hidden=4096]
Output: [batch=\
128, seq=10000, hidden=4096]
Device: GPU-6",
			pos="2900,13397",
			shape=parallelogram,
			style=filled,
			width=10.425];
		attn_out_6 -> attn_residual_6	[pos="e,2900,13480 2900,13515 2900,13507 2900,13499 2900,13490"];
		layernorm1_6	[color=lightblue,
			height=0.94444,
			label="GPU6_Layer6_LayerNorm1
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-6",
			pos="2931,13244",
			shape=rectangle,
			style=filled,
			width=5.0278];
		attn_residual_6 -> layernorm1_6	[pos="e,2924.2,13278 2916.9,13313 2918.7,13305 2920.5,13296 2922.1,13288"];
		ffn_up_6	[color=lightblue,
			height=0.94444,
			label="GPU6_Layer6_FFN_Up
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-6",
			pos="2594,13140",
			shape=rectangle,
			style=filled,
			width=4.8611];
		layernorm1_6 -> ffn_up_6	[pos="e,2703.2,13174 2821.6,13209 2786.9,13199 2748.4,13187 2713,13177"];
		ffn_gate_6	[color=lightblue,
			height=0.94444,
			label="GPU6_Layer6_FFN_Gate
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-6",
			pos="2962,13140",
			shape=rectangle,
			style=filled,
			width=4.8611];
		layernorm1_6 -> ffn_gate_6	[pos="e,2951.9,13174 2941.1,13209 2943.6,13201 2946.3,13192 2949,13183"];
		ffn_residual_6	[color=lightyellow,
			height=2.3056,
			label="GPU6_Layer6_FFN_Residual
Input1: [batch=128, seq=10000, hidden=4096]
Input2: [batch=128, seq=10000, hidden=4096]
Output: [batch=\
128, seq=10000, hidden=4096]
Device: GPU-6",
			pos="2900,12779",
			shape=parallelogram,
			style=filled,
			width=10.425];
		layernorm1_6 -> ffn_residual_6	[pos="e,3055.9,12862 3105.2,13209 3121,13200 3135.1,13188 3146,13174 3163.8,13149 3150,13136 3146,13106 3133.4,13011 3147.1,12974 3090,\
12898 3082.2,12887 3073.3,12877 3063.5,12868"];
		ffn_act_6	[color=lightblue,
			height=0.94444,
			label="GPU6_Layer6_FFN_Act
Input: [batch=128, seq=10000, ffn=16384]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-6",
			pos="2900,13036",
			shape=rectangle,
			style=filled,
			width=4.7361];
		ffn_up_6 -> ffn_act_6	[pos="e,2800.9,13070 2693.3,13105 2724.6,13095 2759.2,13084 2791.1,13073"];
		ffn_gate_6 -> ffn_act_6	[pos="e,2920.2,13070 2941.9,13105 2936.7,13097 2931,13088 2925.6,13079"];
		ffn_down_6	[color=lightblue,
			height=0.94444,
			label="GPU6_Layer6_FFN_Down
Input: [batch=128, seq=10000, ffn=16384]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-6",
			pos="2900,12932",
			shape=rectangle,
			style=filled,
			width=5.0278];
		ffn_act_6 -> ffn_down_6	[pos="e,2900,12966 2900,13001 2900,12993 2900,12985 2900,12976"];
		ffn_down_6 -> ffn_residual_6	[pos="e,2900,12862 2900,12897 2900,12890 2900,12881 2900,12872"];
		layernorm2_6	[color=lightblue,
			height=0.94444,
			label="GPU6_Layer6_LayerNorm2
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-6",
			pos="2900,12626",
			shape=rectangle,
			style=filled,
			width=5.0278];
		ffn_residual_6 -> layernorm2_6	[pos="e,2900,12660 2900,12695 2900,12687 2900,12678 2900,12670"];
	}
	subgraph cluster_gpu7 {
		graph [bb="2144,11204,3016,12473",
			color=color8,
			label="GPU-7 (Layer 7)",
			lheight=0.21,
			lp="2580,12461",
			lwidth=1.39,
			style=rounded
		];
		mha_q_7	[color=lightblue,
			height=0.94444,
			label="GPU7_Layer7_MHA_Q
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-7",
			pos="2784,12408",
			shape=rectangle,
			style=filled,
			width=5.6806];
		attn_score_7	[color=lightblue,
			height=1.1528,
			label="GPU7_Layer7_Attn_Score
Input1: [batch=128, seq=10000, heads=32, d_k=128]
Input2: [batch=128, seq=10000, heads=32, d_k=128]
Output: [\
batch=128, seq=10000, heads=32, seq=10000]
Device: GPU-7",
			pos="2366,12296",
			shape=rectangle,
			style=filled,
			width=5.9444];
		mha_q_7 -> attn_score_7	[pos="e,2520.9,12338 2658,12374 2618,12363 2573.1,12351 2530.8,12340"];
		mha_k_7	[color=lightblue,
			height=0.94444,
			label="GPU7_Layer7_MHA_K
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-7",
			pos="2357,12408",
			shape=rectangle,
			style=filled,
			width=5.6806];
		mha_k_7 -> attn_score_7	[pos="e,2362.6,12338 2359.7,12373 2360.4,12365 2361.1,12357 2361.8,12348"];
		mha_v_7	[color=lightblue,
			height=0.94444,
			label="GPU7_Layer7_MHA_V
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-7",
			pos="2803,12296",
			shape=rectangle,
			style=filled,
			width=5.6806];
		attn_out_7	[color=lightblue,
			height=1.1528,
			label="GPU7_Layer7_Attn_Out
Input1: [batch=128, seq=10000, heads=32, seq=10000]
Input2: [batch=128, seq=10000, heads=32, d_k=128]
Output: [\
batch=128, seq=10000, hidden=4096]
Device: GPU-7",
			pos="2633,12177",
			shape=rectangle,
			style=filled,
			width=5.9028];
		mha_v_7 -> attn_out_7	[pos="e,2692,12219 2754.7,12262 2737.8,12250 2718.4,12237 2700.2,12224"];
		attn_score_7 -> attn_out_7	[pos="e,2540.5,12219 2458.6,12255 2482,12244 2507.3,12233 2531.1,12223"];
		attn_residual_7	[color=lightyellow,
			height=2.3056,
			label="GPU7_Layer7_Attn_Residual
Input1: [batch=128, seq=10000, hidden=4096]
Input2: [batch=128, seq=10000, hidden=4096]
Output: [batch=\
128, seq=10000, hidden=4096]
Device: GPU-7",
			pos="2633,12017",
			shape=parallelogram,
			style=filled,
			width=10.425];
		attn_out_7 -> attn_residual_7	[pos="e,2633,12100 2633,12135 2633,12127 2633,12119 2633,12110"];
		layernorm1_7	[color=lightblue,
			height=0.94444,
			label="GPU7_Layer7_LayerNorm1
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-7",
			pos="2664,11864",
			shape=rectangle,
			style=filled,
			width=5.0278];
		attn_residual_7 -> layernorm1_7	[pos="e,2657.2,11898 2649.9,11933 2651.7,11925 2653.5,11916 2655.1,11908"];
		ffn_up_7	[color=lightblue,
			height=0.94444,
			label="GPU7_Layer7_FFN_Up
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-7",
			pos="2327,11760",
			shape=rectangle,
			style=filled,
			width=4.8611];
		layernorm1_7 -> ffn_up_7	[pos="e,2436.2,11794 2554.6,11830 2519.9,11819 2481.4,11807 2446,11797"];
		ffn_gate_7	[color=lightblue,
			height=0.94444,
			label="GPU7_Layer7_FFN_Gate
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-7",
			pos="2695,11760",
			shape=rectangle,
			style=filled,
			width=4.8611];
		layernorm1_7 -> ffn_gate_7	[pos="e,2684.9,11794 2674.1,11830 2676.6,11821 2679.3,11812 2682,11804"];
		ffn_residual_7	[color=lightyellow,
			height=2.3056,
			label="GPU7_Layer7_FFN_Residual
Input1: [batch=128, seq=10000, hidden=4096]
Input2: [batch=128, seq=10000, hidden=4096]
Output: [batch=\
128, seq=10000, hidden=4096]
Device: GPU-7",
			pos="2633,11399",
			shape=parallelogram,
			style=filled,
			width=10.425];
		layernorm1_7 -> ffn_residual_7	[pos="e,2788.9,11482 2838.2,11830 2854,11820 2868.1,11809 2879,11794 2896.8,11769 2883,11756 2879,11726 2866.4,11631 2880.1,11594 2823,\
11518 2815.2,11507 2806.3,11497 2796.5,11488"];
		ffn_act_7	[color=lightblue,
			height=0.94444,
			label="GPU7_Layer7_FFN_Act
Input: [batch=128, seq=10000, ffn=16384]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-7",
			pos="2633,11656",
			shape=rectangle,
			style=filled,
			width=4.7361];
		ffn_up_7 -> ffn_act_7	[pos="e,2533.9,11690 2426.3,11726 2457.6,11715 2492.2,11704 2524.1,11693"];
		ffn_gate_7 -> ffn_act_7	[pos="e,2653.2,11690 2674.9,11726 2669.7,11717 2664,11708 2658.6,11699"];
		ffn_down_7	[color=lightblue,
			height=0.94444,
			label="GPU7_Layer7_FFN_Down
Input: [batch=128, seq=10000, ffn=16384]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-7",
			pos="2633,11552",
			shape=rectangle,
			style=filled,
			width=5.0278];
		ffn_act_7 -> ffn_down_7	[pos="e,2633,11586 2633,11622 2633,11613 2633,11605 2633,11596"];
		ffn_down_7 -> ffn_residual_7	[pos="e,2633,11482 2633,11517 2633,11510 2633,11501 2633,11492"];
		layernorm2_7	[color=lightblue,
			height=0.94444,
			label="GPU7_Layer7_LayerNorm2
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-7",
			pos="2633,11246",
			shape=rectangle,
			style=filled,
			width=5.0278];
		ffn_residual_7 -> layernorm2_7	[pos="e,2633,11280 2633,11315 2633,11307 2633,11298 2633,11290"];
	}
	subgraph cluster_gpu8 {
		graph [bb="1877,9823.7,2749,11093",
			color=color1,
			label="GPU-8 (Layer 8)",
			lheight=0.21,
			lp="2313,11081",
			lwidth=1.39,
			style=rounded
		];
		mha_q_8	[color=lightblue,
			height=0.94444,
			label="GPU8_Layer8_MHA_Q
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-8",
			pos="2517,11028",
			shape=rectangle,
			style=filled,
			width=5.6806];
		attn_score_8	[color=lightblue,
			height=1.1528,
			label="GPU8_Layer8_Attn_Score
Input1: [batch=128, seq=10000, heads=32, d_k=128]
Input2: [batch=128, seq=10000, heads=32, d_k=128]
Output: [\
batch=128, seq=10000, heads=32, seq=10000]
Device: GPU-8",
			pos="2099,10916",
			shape=rectangle,
			style=filled,
			width=5.9444];
		mha_q_8 -> attn_score_8	[pos="e,2253.9,10958 2391,10994 2351,10983 2306.1,10971 2263.8,10960"];
		mha_k_8	[color=lightblue,
			height=0.94444,
			label="GPU8_Layer8_MHA_K
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-8",
			pos="2090,11028",
			shape=rectangle,
			style=filled,
			width=5.6806];
		mha_k_8 -> attn_score_8	[pos="e,2095.6,10958 2092.7,10994 2093.4,10985 2094.1,10977 2094.8,10968"];
		mha_v_8	[color=lightblue,
			height=0.94444,
			label="GPU8_Layer8_MHA_V
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-8",
			pos="2536,10916",
			shape=rectangle,
			style=filled,
			width=5.6806];
		attn_out_8	[color=lightblue,
			height=1.1528,
			label="GPU8_Layer8_Attn_Out
Input1: [batch=128, seq=10000, heads=32, seq=10000]
Input2: [batch=128, seq=10000, heads=32, d_k=128]
Output: [\
batch=128, seq=10000, hidden=4096]
Device: GPU-8",
			pos="2366,10797",
			shape=rectangle,
			style=filled,
			width=5.9028];
		mha_v_8 -> attn_out_8	[pos="e,2425,10839 2487.7,10882 2470.8,10870 2451.4,10857 2433.2,10844"];
		attn_score_8 -> attn_out_8	[pos="e,2273.5,10839 2191.6,10875 2215,10864 2240.3,10853 2264.1,10843"];
		attn_residual_8	[color=lightyellow,
			height=2.3056,
			label="GPU8_Layer8_Attn_Residual
Input1: [batch=128, seq=10000, hidden=4096]
Input2: [batch=128, seq=10000, hidden=4096]
Output: [batch=\
128, seq=10000, hidden=4096]
Device: GPU-8",
			pos="2366,10637",
			shape=parallelogram,
			style=filled,
			width=10.425];
		attn_out_8 -> attn_residual_8	[pos="e,2366,10720 2366,10755 2366,10747 2366,10739 2366,10730"];
		layernorm1_8	[color=lightblue,
			height=0.94444,
			label="GPU8_Layer8_LayerNorm1
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-8",
			pos="2397,10484",
			shape=rectangle,
			style=filled,
			width=5.0278];
		attn_residual_8 -> layernorm1_8	[pos="e,2390.2,10518 2382.9,10554 2384.7,10545 2386.5,10536 2388.1,10528"];
		ffn_up_8	[color=lightblue,
			height=0.94444,
			label="GPU8_Layer8_FFN_Up
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-8",
			pos="2060,10380",
			shape=rectangle,
			style=filled,
			width=4.8611];
		layernorm1_8 -> ffn_up_8	[pos="e,2169.2,10414 2287.6,10450 2252.9,10439 2214.4,10427 2179,10417"];
		ffn_gate_8	[color=lightblue,
			height=0.94444,
			label="GPU8_Layer8_FFN_Gate
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-8",
			pos="2428,10380",
			shape=rectangle,
			style=filled,
			width=4.8611];
		layernorm1_8 -> ffn_gate_8	[pos="e,2417.9,10414 2407.1,10450 2409.6,10441 2412.3,10432 2415,10424"];
		ffn_residual_8	[color=lightyellow,
			height=2.3056,
			label="GPU8_Layer8_FFN_Residual
Input1: [batch=128, seq=10000, hidden=4096]
Input2: [batch=128, seq=10000, hidden=4096]
Output: [batch=\
128, seq=10000, hidden=4096]
Device: GPU-8",
			pos="2366,10019",
			shape=parallelogram,
			style=filled,
			width=10.425];
		layernorm1_8 -> ffn_residual_8	[pos="e,2521.9,10102 2571.2,10450 2587,10440 2601.1,10429 2612,10414 2629.8,10389 2616,10376 2612,10346 2599.4,10251 2613.1,10215 2556,\
10138 2548.2,10127 2539.3,10118 2529.5,10109"];
		ffn_act_8	[color=lightblue,
			height=0.94444,
			label="GPU8_Layer8_FFN_Act
Input: [batch=128, seq=10000, ffn=16384]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-8",
			pos="2366,10276",
			shape=rectangle,
			style=filled,
			width=4.7361];
		ffn_up_8 -> ffn_act_8	[pos="e,2266.9,10310 2159.3,10346 2190.6,10335 2225.2,10324 2257.1,10313"];
		ffn_gate_8 -> ffn_act_8	[pos="e,2386.2,10310 2407.9,10346 2402.7,10337 2397,10328 2391.6,10319"];
		ffn_down_8	[color=lightblue,
			height=0.94444,
			label="GPU8_Layer8_FFN_Down
Input: [batch=128, seq=10000, ffn=16384]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-8",
			pos="2366,10172",
			shape=rectangle,
			style=filled,
			width=5.0278];
		ffn_act_8 -> ffn_down_8	[pos="e,2366,10206 2366,10242 2366,10233 2366,10225 2366,10216"];
		ffn_down_8 -> ffn_residual_8	[pos="e,2366,10102 2366,10138 2366,10130 2366,10121 2366,10112"];
		layernorm2_8	[color=lightblue,
			height=0.94444,
			label="GPU8_Layer8_LayerNorm2
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-8",
			pos="2366,9865.7",
			shape=rectangle,
			style=filled,
			width=5.0278];
		ffn_residual_8 -> layernorm2_8	[pos="e,2366,9899.9 2366,9935.5 2366,9926.8 2366,9918.2 2366,9910.1"];
	}
	subgraph cluster_gpu9 {
		graph [bb="1610,8443.7,2482,9712.7",
			color=color2,
			label="GPU-9 (Layer 9)",
			lheight=0.21,
			lp="2046,9701.2",
			lwidth=1.39,
			style=rounded
		];
		mha_q_9	[color=lightblue,
			height=0.94444,
			label="GPU9_Layer9_MHA_Q
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-9",
			pos="2250,9647.7",
			shape=rectangle,
			style=filled,
			width=5.6806];
		attn_score_9	[color=lightblue,
			height=1.1528,
			label="GPU9_Layer9_Attn_Score
Input1: [batch=128, seq=10000, heads=32, d_k=128]
Input2: [batch=128, seq=10000, heads=32, d_k=128]
Output: [\
batch=128, seq=10000, heads=32, seq=10000]
Device: GPU-9",
			pos="1832,9536.2",
			shape=rectangle,
			style=filled,
			width=5.9444];
		mha_q_9 -> attn_score_9	[pos="e,1986.9,9577.8 2124,9613.7 2084,9603.2 2039.1,9591.5 1996.8,9580.4"];
		mha_k_9	[color=lightblue,
			height=0.94444,
			label="GPU9_Layer9_MHA_K
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-9",
			pos="1823,9647.7",
			shape=rectangle,
			style=filled,
			width=5.6806];
		mha_k_9 -> attn_score_9	[pos="e,1828.6,9578 1825.7,9613.6 1826.4,9605.5 1827.1,9596.7 1827.8,9588.1"];
		mha_v_9	[color=lightblue,
			height=0.94444,
			label="GPU9_Layer9_MHA_V
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-9",
			pos="2269,9536.2",
			shape=rectangle,
			style=filled,
			width=5.6806];
		attn_out_9	[color=lightblue,
			height=1.1528,
			label="GPU9_Layer9_Attn_Out
Input1: [batch=128, seq=10000, heads=32, seq=10000]
Input2: [batch=128, seq=10000, heads=32, d_k=128]
Output: [\
batch=128, seq=10000, hidden=4096]
Device: GPU-9",
			pos="2099,9417.2",
			shape=rectangle,
			style=filled,
			width=5.9028];
		mha_v_9 -> attn_out_9	[pos="e,2158,9458.8 2220.7,9502 2203.8,9490.3 2184.4,9477 2166.2,9464.5"];
		attn_score_9 -> attn_out_9	[pos="e,2006.5,9458.7 1924.6,9494.6 1948,9484.4 1973.3,9473.3 1997.1,9462.9"];
		attn_residual_9	[color=lightyellow,
			height=2.3056,
			label="GPU9_Layer9_Attn_Residual
Input1: [batch=128, seq=10000, hidden=4096]
Input2: [batch=128, seq=10000, hidden=4096]
Output: [batch=\
128, seq=10000, hidden=4096]
Device: GPU-9",
			pos="2099,9256.7",
			shape=parallelogram,
			style=filled,
			width=10.425];
		attn_out_9 -> attn_residual_9	[pos="e,2099,9340 2099,9375.4 2099,9367.5 2099,9358.9 2099,9350"];
		layernorm1_9	[color=lightblue,
			height=0.94444,
			label="GPU9_Layer9_LayerNorm1
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-9",
			pos="2130,9103.7",
			shape=rectangle,
			style=filled,
			width=5.0278];
		attn_residual_9 -> layernorm1_9	[pos="e,2123.2,9138 2115.9,9173.6 2117.7,9164.7 2119.5,9156 2121.1,9147.9"];
		ffn_up_9	[color=lightblue,
			height=0.94444,
			label="GPU9_Layer9_FFN_Up
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-9",
			pos="1793,8999.7",
			shape=rectangle,
			style=filled,
			width=4.8611];
		layernorm1_9 -> ffn_up_9	[pos="e,1902.2,9033.8 2020.6,9069.6 1985.9,9059.1 1947.4,9047.4 1912,9036.7"];
		ffn_gate_9	[color=lightblue,
			height=0.94444,
			label="GPU9_Layer9_FFN_Gate
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-9",
			pos="2161,8999.7",
			shape=rectangle,
			style=filled,
			width=4.8611];
		layernorm1_9 -> ffn_gate_9	[pos="e,2150.9,9034 2140.1,9069.6 2142.6,9061.3 2145.3,9052.3 2148,9043.6"];
		ffn_residual_9	[color=lightyellow,
			height=2.3056,
			label="GPU9_Layer9_FFN_Residual
Input1: [batch=128, seq=10000, hidden=4096]
Input2: [batch=128, seq=10000, hidden=4096]
Output: [batch=\
128, seq=10000, hidden=4096]
Device: GPU-9",
			pos="2099,8638.7",
			shape=parallelogram,
			style=filled,
			width=10.425];
		layernorm1_9 -> ffn_residual_9	[pos="e,2254.9,8721.8 2304.2,9069.6 2320,9060.4 2334.1,9048.6 2345,9033.7 2362.8,9009.3 2349,8995.7 2345,8965.7 2332.4,8870.8 2346.1,8834.6 \
2289,8757.7 2281.2,8747.3 2272.3,8737.6 2262.5,8728.5"];
		ffn_act_9	[color=lightblue,
			height=0.94444,
			label="GPU9_Layer9_FFN_Act
Input: [batch=128, seq=10000, ffn=16384]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-9",
			pos="2099,8895.7",
			shape=rectangle,
			style=filled,
			width=4.7361];
		ffn_up_9 -> ffn_act_9	[pos="e,1999.9,8929.8 1892.3,8965.6 1923.6,8955.2 1958.2,8943.6 1990.1,8933"];
		ffn_gate_9 -> ffn_act_9	[pos="e,2119.2,8930 2140.9,8965.6 2135.7,8957.1 2130,8947.7 2124.6,8938.8"];
		ffn_down_9	[color=lightblue,
			height=0.94444,
			label="GPU9_Layer9_FFN_Down
Input: [batch=128, seq=10000, ffn=16384]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-9",
			pos="2099,8791.7",
			shape=rectangle,
			style=filled,
			width=5.0278];
		ffn_act_9 -> ffn_down_9	[pos="e,2099,8826 2099,8861.6 2099,8853.5 2099,8844.7 2099,8836.2"];
		ffn_down_9 -> ffn_residual_9	[pos="e,2099,8722 2099,8757.6 2099,8749.8 2099,8741.2 2099,8732.2"];
		layernorm2_9	[color=lightblue,
			height=0.94444,
			label="GPU9_Layer9_LayerNorm2
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-9",
			pos="2099,8485.7",
			shape=rectangle,
			style=filled,
			width=5.0278];
		ffn_residual_9 -> layernorm2_9	[pos="e,2099,8520 2099,8555.6 2099,8546.8 2099,8538.2 2099,8530.2"];
	}
	subgraph cluster_gpu10 {
		graph [bb="1343,7063.8,2215,8332.8",
			color=color3,
			label="GPU-10 (Layer 10)",
			lheight=0.21,
			lp="1779,8321.3",
			lwidth=1.60,
			style=rounded
		];
		mha_q_10	[color=lightblue,
			height=0.94444,
			label="GPU10_Layer10_MHA_Q
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-10",
			pos="1983,8267.8",
			shape=rectangle,
			style=filled,
			width=5.6806];
		attn_score_10	[color=lightblue,
			height=1.1528,
			label="GPU10_Layer10_Attn_Score
Input1: [batch=128, seq=10000, heads=32, d_k=128]
Input2: [batch=128, seq=10000, heads=32, d_k=128]
Output: [\
batch=128, seq=10000, heads=32, seq=10000]
Device: GPU-10",
			pos="1565,8156.3",
			shape=rectangle,
			style=filled,
			width=5.9444];
		mha_q_10 -> attn_score_10	[pos="e,1719.9,8197.8 1857,8233.8 1817,8223.3 1772.1,8211.5 1729.8,8200.4"];
		mha_k_10	[color=lightblue,
			height=0.94444,
			label="GPU10_Layer10_MHA_K
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-10",
			pos="1556,8267.8",
			shape=rectangle,
			style=filled,
			width=5.6806];
		mha_k_10 -> attn_score_10	[pos="e,1561.6,8198 1558.7,8233.6 1559.4,8225.6 1560.1,8216.8 1560.8,8208.1"];
		mha_v_10	[color=lightblue,
			height=0.94444,
			label="GPU10_Layer10_MHA_V
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-10",
			pos="2002,8156.3",
			shape=rectangle,
			style=filled,
			width=5.6806];
		attn_out_10	[color=lightblue,
			height=1.1528,
			label="GPU10_Layer10_Attn_Out
Input1: [batch=128, seq=10000, heads=32, seq=10000]
Input2: [batch=128, seq=10000, heads=32, d_k=128]
Output: [\
batch=128, seq=10000, hidden=4096]
Device: GPU-10",
			pos="1832,8037.3",
			shape=rectangle,
			style=filled,
			width=5.9028];
		mha_v_10 -> attn_out_10	[pos="e,1891,8078.8 1953.7,8122.1 1936.8,8110.4 1917.4,8097.1 1899.2,8084.5"];
		attn_score_10 -> attn_out_10	[pos="e,1739.5,8078.8 1657.6,8114.7 1681,8104.4 1706.3,8093.4 1730.1,8082.9"];
		attn_residual_10	[color=lightyellow,
			height=2.3056,
			label="GPU10_Layer10_Attn_Residual
Input1: [batch=128, seq=10000, hidden=4096]
Input2: [batch=128, seq=10000, hidden=4096]
Output: [batch=\
128, seq=10000, hidden=4096]
Device: GPU-10",
			pos="1832,7876.8",
			shape=parallelogram,
			style=filled,
			width=10.425];
		attn_out_10 -> attn_residual_10	[pos="e,1832,7960 1832,7995.4 1832,7987.5 1832,7978.9 1832,7970.1"];
		layernorm1_10	[color=lightblue,
			height=0.94444,
			label="GPU10_Layer10_LayerNorm1
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-10",
			pos="1863,7723.8",
			shape=rectangle,
			style=filled,
			width=5.0278];
		attn_residual_10 -> layernorm1_10	[pos="e,1856.2,7758 1848.9,7793.6 1850.7,7784.8 1852.5,7776.1 1854.1,7767.9"];
		ffn_up_10	[color=lightblue,
			height=0.94444,
			label="GPU10_Layer10_FFN_Up
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-10",
			pos="1526,7619.8",
			shape=rectangle,
			style=filled,
			width=4.8611];
		layernorm1_10 -> ffn_up_10	[pos="e,1635.2,7653.8 1753.6,7689.7 1718.9,7679.1 1680.4,7667.5 1645,7656.8"];
		ffn_gate_10	[color=lightblue,
			height=0.94444,
			label="GPU10_Layer10_FFN_Gate
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-10",
			pos="1894,7619.8",
			shape=rectangle,
			style=filled,
			width=4.8611];
		layernorm1_10 -> ffn_gate_10	[pos="e,1883.9,7654.1 1873.1,7689.7 1875.6,7681.4 1878.3,7672.4 1881,7663.7"];
		ffn_residual_10	[color=lightyellow,
			height=2.3056,
			label="GPU10_Layer10_FFN_Residual
Input1: [batch=128, seq=10000, hidden=4096]
Input2: [batch=128, seq=10000, hidden=4096]
Output: [batch=\
128, seq=10000, hidden=4096]
Device: GPU-10",
			pos="1832,7258.8",
			shape=parallelogram,
			style=filled,
			width=10.425];
		layernorm1_10 -> ffn_residual_10	[pos="e,1987.9,7341.8 2037.2,7689.7 2053,7680.4 2067.1,7668.7 2078,7653.8 2095.8,7629.3 2082,7615.7 2078,7585.8 2065.4,7490.9 2079.1,7454.6 \
2022,7377.8 2014.2,7367.3 2005.3,7357.6 1995.5,7348.6"];
		ffn_act_10	[color=lightblue,
			height=0.94444,
			label="GPU10_Layer10_FFN_Act
Input: [batch=128, seq=10000, ffn=16384]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-10",
			pos="1832,7515.8",
			shape=rectangle,
			style=filled,
			width=4.7361];
		ffn_up_10 -> ffn_act_10	[pos="e,1732.9,7549.8 1625.3,7585.7 1656.6,7575.2 1691.2,7563.7 1723.1,7553.1"];
		ffn_gate_10 -> ffn_act_10	[pos="e,1852.2,7550.1 1873.9,7585.7 1868.7,7577.1 1863,7567.8 1857.6,7558.8"];
		ffn_down_10	[color=lightblue,
			height=0.94444,
			label="GPU10_Layer10_FFN_Down
Input: [batch=128, seq=10000, ffn=16384]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-10",
			pos="1832,7411.8",
			shape=rectangle,
			style=filled,
			width=5.0278];
		ffn_act_10 -> ffn_down_10	[pos="e,1832,7446.1 1832,7481.7 1832,7473.5 1832,7464.7 1832,7456.2"];
		ffn_down_10 -> ffn_residual_10	[pos="e,1832,7342 1832,7377.6 1832,7369.9 1832,7361.2 1832,7352.3"];
		layernorm2_10	[color=lightblue,
			height=0.94444,
			label="GPU10_Layer10_LayerNorm2
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-10",
			pos="1832,7105.8",
			shape=rectangle,
			style=filled,
			width=5.0278];
		ffn_residual_10 -> layernorm2_10	[pos="e,1832,7140 1832,7175.6 1832,7166.9 1832,7158.3 1832,7150.2"];
	}
	subgraph cluster_gpu11 {
		graph [bb="1076,5683.8,1948,6952.8",
			color=color4,
			label="GPU-11 (Layer 11)",
			lheight=0.21,
			lp="1512,6941.3",
			lwidth=1.60,
			style=rounded
		];
		mha_q_11	[color=lightblue,
			height=0.94444,
			label="GPU11_Layer11_MHA_Q
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-11",
			pos="1716,6887.8",
			shape=rectangle,
			style=filled,
			width=5.6806];
		attn_score_11	[color=lightblue,
			height=1.1528,
			label="GPU11_Layer11_Attn_Score
Input1: [batch=128, seq=10000, heads=32, d_k=128]
Input2: [batch=128, seq=10000, heads=32, d_k=128]
Output: [\
batch=128, seq=10000, heads=32, seq=10000]
Device: GPU-11",
			pos="1298,6776.3",
			shape=rectangle,
			style=filled,
			width=5.9444];
		mha_q_11 -> attn_score_11	[pos="e,1452.9,6817.9 1590,6853.8 1550,6843.3 1505.1,6831.6 1462.8,6820.5"];
		mha_k_11	[color=lightblue,
			height=0.94444,
			label="GPU11_Layer11_MHA_K
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-11",
			pos="1289,6887.8",
			shape=rectangle,
			style=filled,
			width=5.6806];
		mha_k_11 -> attn_score_11	[pos="e,1294.6,6818.1 1291.7,6853.7 1292.4,6845.6 1293.1,6836.8 1293.8,6828.1"];
		mha_v_11	[color=lightblue,
			height=0.94444,
			label="GPU11_Layer11_MHA_V
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-11",
			pos="1735,6776.3",
			shape=rectangle,
			style=filled,
			width=5.6806];
		attn_out_11	[color=lightblue,
			height=1.1528,
			label="GPU11_Layer11_Attn_Out
Input1: [batch=128, seq=10000, heads=32, seq=10000]
Input2: [batch=128, seq=10000, heads=32, d_k=128]
Output: [\
batch=128, seq=10000, hidden=4096]
Device: GPU-11",
			pos="1565,6657.3",
			shape=rectangle,
			style=filled,
			width=5.9028];
		mha_v_11 -> attn_out_11	[pos="e,1624,6698.9 1686.7,6742.1 1669.8,6730.4 1650.4,6717.1 1632.2,6704.6"];
		attn_score_11 -> attn_out_11	[pos="e,1472.5,6698.8 1390.6,6734.7 1414,6724.5 1439.3,6713.4 1463.1,6703"];
		attn_residual_11	[color=lightyellow,
			height=2.3056,
			label="GPU11_Layer11_Attn_Residual
Input1: [batch=128, seq=10000, hidden=4096]
Input2: [batch=128, seq=10000, hidden=4096]
Output: [batch=\
128, seq=10000, hidden=4096]
Device: GPU-11",
			pos="1565,6496.8",
			shape=parallelogram,
			style=filled,
			width=10.425];
		attn_out_11 -> attn_residual_11	[pos="e,1565,6580.1 1565,6615.5 1565,6607.6 1565,6599 1565,6590.1"];
		layernorm1_11	[color=lightblue,
			height=0.94444,
			label="GPU11_Layer11_LayerNorm1
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-11",
			pos="1596,6343.8",
			shape=rectangle,
			style=filled,
			width=5.0278];
		attn_residual_11 -> layernorm1_11	[pos="e,1589.2,6378.1 1581.9,6413.7 1583.7,6404.8 1585.5,6396.1 1587.1,6388"];
		ffn_up_11	[color=lightblue,
			height=0.94444,
			label="GPU11_Layer11_FFN_Up
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-11",
			pos="1259,6239.8",
			shape=rectangle,
			style=filled,
			width=4.8611];
		layernorm1_11 -> ffn_up_11	[pos="e,1368.2,6273.9 1486.6,6309.7 1451.9,6299.2 1413.4,6287.5 1378,6276.8"];
		ffn_gate_11	[color=lightblue,
			height=0.94444,
			label="GPU11_Layer11_FFN_Gate
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-11",
			pos="1627,6239.8",
			shape=rectangle,
			style=filled,
			width=4.8611];
		layernorm1_11 -> ffn_gate_11	[pos="e,1616.9,6274.1 1606.1,6309.7 1608.6,6301.4 1611.3,6292.4 1614,6283.7"];
		ffn_residual_11	[color=lightyellow,
			height=2.3056,
			label="GPU11_Layer11_FFN_Residual
Input1: [batch=128, seq=10000, hidden=4096]
Input2: [batch=128, seq=10000, hidden=4096]
Output: [batch=\
128, seq=10000, hidden=4096]
Device: GPU-11",
			pos="1565,5878.8",
			shape=parallelogram,
			style=filled,
			width=10.425];
		layernorm1_11 -> ffn_residual_11	[pos="e,1720.9,5961.9 1770.2,6309.7 1786,6300.4 1800.1,6288.7 1811,6273.8 1828.8,6249.4 1815,6235.8 1811,6205.8 1798.4,6110.9 1812.1,6074.7 \
1755,5997.8 1747.2,5987.4 1738.3,5977.7 1728.5,5968.6"];
		ffn_act_11	[color=lightblue,
			height=0.94444,
			label="GPU11_Layer11_FFN_Act
Input: [batch=128, seq=10000, ffn=16384]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-11",
			pos="1565,6135.8",
			shape=rectangle,
			style=filled,
			width=4.7361];
		ffn_up_11 -> ffn_act_11	[pos="e,1465.9,6169.9 1358.3,6205.7 1389.6,6195.3 1424.2,6183.7 1456.1,6173.1"];
		ffn_gate_11 -> ffn_act_11	[pos="e,1585.2,6170.1 1606.9,6205.7 1601.7,6197.1 1596,6187.8 1590.6,6178.9"];
		ffn_down_11	[color=lightblue,
			height=0.94444,
			label="GPU11_Layer11_FFN_Down
Input: [batch=128, seq=10000, ffn=16384]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-11",
			pos="1565,6031.8",
			shape=rectangle,
			style=filled,
			width=5.0278];
		ffn_act_11 -> ffn_down_11	[pos="e,1565,6066.1 1565,6101.7 1565,6093.6 1565,6084.8 1565,6076.3"];
		ffn_down_11 -> ffn_residual_11	[pos="e,1565,5962 1565,5997.7 1565,5989.9 1565,5981.3 1565,5972.3"];
		layernorm2_11	[color=lightblue,
			height=0.94444,
			label="GPU11_Layer11_LayerNorm2
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-11",
			pos="1565,5725.8",
			shape=rectangle,
			style=filled,
			width=5.0278];
		ffn_residual_11 -> layernorm2_11	[pos="e,1565,5760.1 1565,5795.7 1565,5786.9 1565,5778.3 1565,5770.3"];
	}
	subgraph cluster_gpu12 {
		graph [bb="809,4303.9,1681,5572.9",
			color=color5,
			label="GPU-12 (Layer 12)",
			lheight=0.21,
			lp="1245,5561.4",
			lwidth=1.60,
			style=rounded
		];
		mha_q_12	[color=lightblue,
			height=0.94444,
			label="GPU12_Layer12_MHA_Q
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-12",
			pos="1449,5507.9",
			shape=rectangle,
			style=filled,
			width=5.6806];
		attn_score_12	[color=lightblue,
			height=1.1528,
			label="GPU12_Layer12_Attn_Score
Input1: [batch=128, seq=10000, heads=32, d_k=128]
Input2: [batch=128, seq=10000, heads=32, d_k=128]
Output: [\
batch=128, seq=10000, heads=32, seq=10000]
Device: GPU-12",
			pos="1031,5396.4",
			shape=rectangle,
			style=filled,
			width=5.9444];
		mha_q_12 -> attn_score_12	[pos="e,1185.9,5437.9 1323,5473.9 1283,5463.4 1238.1,5451.6 1195.8,5440.5"];
		mha_k_12	[color=lightblue,
			height=0.94444,
			label="GPU12_Layer12_MHA_K
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-12",
			pos="1022,5507.9",
			shape=rectangle,
			style=filled,
			width=5.6806];
		mha_k_12 -> attn_score_12	[pos="e,1027.6,5438.1 1024.7,5473.7 1025.4,5465.7 1026.1,5456.9 1026.8,5448.2"];
		mha_v_12	[color=lightblue,
			height=0.94444,
			label="GPU12_Layer12_MHA_V
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-12",
			pos="1468,5396.4",
			shape=rectangle,
			style=filled,
			width=5.6806];
		attn_out_12	[color=lightblue,
			height=1.1528,
			label="GPU12_Layer12_Attn_Out
Input1: [batch=128, seq=10000, heads=32, seq=10000]
Input2: [batch=128, seq=10000, heads=32, d_k=128]
Output: [\
batch=128, seq=10000, hidden=4096]
Device: GPU-12",
			pos="1298,5277.4",
			shape=rectangle,
			style=filled,
			width=5.9028];
		mha_v_12 -> attn_out_12	[pos="e,1357,5318.9 1419.7,5362.1 1402.8,5350.5 1383.4,5337.2 1365.2,5324.6"];
		attn_score_12 -> attn_out_12	[pos="e,1205.5,5318.9 1123.6,5354.8 1147,5344.5 1172.3,5333.4 1196.1,5323"];
		attn_residual_12	[color=lightyellow,
			height=2.3056,
			label="GPU12_Layer12_Attn_Residual
Input1: [batch=128, seq=10000, hidden=4096]
Input2: [batch=128, seq=10000, hidden=4096]
Output: [batch=\
128, seq=10000, hidden=4096]
Device: GPU-12",
			pos="1298,5116.9",
			shape=parallelogram,
			style=filled,
			width=10.425];
		attn_out_12 -> attn_residual_12	[pos="e,1298,5200.1 1298,5235.5 1298,5227.6 1298,5219 1298,5210.2"];
		layernorm1_12	[color=lightblue,
			height=0.94444,
			label="GPU12_Layer12_LayerNorm1
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-12",
			pos="1329,4963.9",
			shape=rectangle,
			style=filled,
			width=5.0278];
		attn_residual_12 -> layernorm1_12	[pos="e,1322.2,4998.1 1314.9,5033.7 1316.7,5024.9 1318.5,5016.2 1320.1,5008"];
		ffn_up_12	[color=lightblue,
			height=0.94444,
			label="GPU12_Layer12_FFN_Up
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-12",
			pos="992,4859.9",
			shape=rectangle,
			style=filled,
			width=4.8611];
		layernorm1_12 -> ffn_up_12	[pos="e,1101.2,4893.9 1219.6,4929.7 1184.9,4919.2 1146.4,4907.6 1111,4896.9"];
		ffn_gate_12	[color=lightblue,
			height=0.94444,
			label="GPU12_Layer12_FFN_Gate
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-12",
			pos="1360,4859.9",
			shape=rectangle,
			style=filled,
			width=4.8611];
		layernorm1_12 -> ffn_gate_12	[pos="e,1349.9,4894.2 1339.1,4929.7 1341.6,4921.5 1344.3,4912.5 1347,4903.8"];
		ffn_residual_12	[color=lightyellow,
			height=2.3056,
			label="GPU12_Layer12_FFN_Residual
Input1: [batch=128, seq=10000, hidden=4096]
Input2: [batch=128, seq=10000, hidden=4096]
Output: [batch=\
128, seq=10000, hidden=4096]
Device: GPU-12",
			pos="1298,4498.9",
			shape=parallelogram,
			style=filled,
			width=10.425];
		layernorm1_12 -> ffn_residual_12	[pos="e,1453.9,4581.9 1503.2,4929.7 1519,4920.5 1533.1,4908.7 1544,4893.9 1561.8,4869.4 1548,4855.8 1544,4825.9 1531.4,4731 1545.1,4694.7 \
1488,4617.9 1480.2,4607.4 1471.3,4597.7 1461.5,4588.7"];
		ffn_act_12	[color=lightblue,
			height=0.94444,
			label="GPU12_Layer12_FFN_Act
Input: [batch=128, seq=10000, ffn=16384]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-12",
			pos="1298,4755.9",
			shape=rectangle,
			style=filled,
			width=4.7361];
		ffn_up_12 -> ffn_act_12	[pos="e,1198.9,4789.9 1091.3,4825.7 1122.6,4815.3 1157.2,4803.8 1189.1,4793.2"];
		ffn_gate_12 -> ffn_act_12	[pos="e,1318.2,4790.2 1339.9,4825.7 1334.7,4817.2 1329,4807.9 1323.6,4798.9"];
		ffn_down_12	[color=lightblue,
			height=0.94444,
			label="GPU12_Layer12_FFN_Down
Input: [batch=128, seq=10000, ffn=16384]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-12",
			pos="1298,4651.9",
			shape=rectangle,
			style=filled,
			width=5.0278];
		ffn_act_12 -> ffn_down_12	[pos="e,1298,4686.2 1298,4721.7 1298,4713.6 1298,4704.8 1298,4696.3"];
		ffn_down_12 -> ffn_residual_12	[pos="e,1298,4582.1 1298,4617.7 1298,4610 1298,4601.3 1298,4592.3"];
		layernorm2_12	[color=lightblue,
			height=0.94444,
			label="GPU12_Layer12_LayerNorm2
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-12",
			pos="1298,4345.9",
			shape=rectangle,
			style=filled,
			width=5.0278];
		ffn_residual_12 -> layernorm2_12	[pos="e,1298,4380.1 1298,4415.7 1298,4407 1298,4398.3 1298,4390.3"];
	}
	subgraph cluster_gpu13 {
		graph [bb="542,2923.9,1414,4192.9",
			color=color6,
			label="GPU-13 (Layer 13)",
			lheight=0.21,
			lp="978,4181.4",
			lwidth=1.60,
			style=rounded
		];
		mha_q_13	[color=lightblue,
			height=0.94444,
			label="GPU13_Layer13_MHA_Q
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-13",
			pos="1182,4127.9",
			shape=rectangle,
			style=filled,
			width=5.6806];
		attn_score_13	[color=lightblue,
			height=1.1528,
			label="GPU13_Layer13_Attn_Score
Input1: [batch=128, seq=10000, heads=32, d_k=128]
Input2: [batch=128, seq=10000, heads=32, d_k=128]
Output: [\
batch=128, seq=10000, heads=32, seq=10000]
Device: GPU-13",
			pos="764,4016.4",
			shape=rectangle,
			style=filled,
			width=5.9444];
		mha_q_13 -> attn_score_13	[pos="e,918.92,4058 1056,4093.9 1016,4083.4 971.11,4071.7 928.76,4060.6"];
		mha_k_13	[color=lightblue,
			height=0.94444,
			label="GPU13_Layer13_MHA_K
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-13",
			pos="755,4127.9",
			shape=rectangle,
			style=filled,
			width=5.6806];
		mha_k_13 -> attn_score_13	[pos="e,760.65,4058.2 757.72,4093.8 758.39,4085.7 759.11,4076.9 759.82,4068.2"];
		mha_v_13	[color=lightblue,
			height=0.94444,
			label="GPU13_Layer13_MHA_V
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-13",
			pos="1201,4016.4",
			shape=rectangle,
			style=filled,
			width=5.6806];
		attn_out_13	[color=lightblue,
			height=1.1528,
			label="GPU13_Layer13_Attn_Out
Input1: [batch=128, seq=10000, heads=32, seq=10000]
Input2: [batch=128, seq=10000, heads=32, d_k=128]
Output: [\
batch=128, seq=10000, hidden=4096]
Device: GPU-13",
			pos="1031,3897.4",
			shape=rectangle,
			style=filled,
			width=5.9028];
		mha_v_13 -> attn_out_13	[pos="e,1090,3939 1152.7,3982.2 1135.8,3970.5 1116.4,3957.2 1098.2,3944.7"];
		attn_score_13 -> attn_out_13	[pos="e,938.53,3938.9 856.63,3974.8 880.04,3964.6 905.29,3953.5 929.12,3943"];
		attn_residual_13	[color=lightyellow,
			height=2.3056,
			label="GPU13_Layer13_Attn_Residual
Input1: [batch=128, seq=10000, hidden=4096]
Input2: [batch=128, seq=10000, hidden=4096]
Output: [batch=\
128, seq=10000, hidden=4096]
Device: GPU-13",
			pos="1031,3736.9",
			shape=parallelogram,
			style=filled,
			width=10.425];
		attn_out_13 -> attn_residual_13	[pos="e,1031,3820.2 1031,3855.6 1031,3847.7 1031,3839.1 1031,3830.2"];
		layernorm1_13	[color=lightblue,
			height=0.94444,
			label="GPU13_Layer13_LayerNorm1
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-13",
			pos="1062,3583.9",
			shape=rectangle,
			style=filled,
			width=5.0278];
		attn_residual_13 -> layernorm1_13	[pos="e,1055.2,3618.2 1047.9,3653.8 1049.7,3644.9 1051.5,3636.2 1053.1,3628.1"];
		ffn_up_13	[color=lightblue,
			height=0.94444,
			label="GPU13_Layer13_FFN_Up
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-13",
			pos="725,3479.9",
			shape=rectangle,
			style=filled,
			width=4.8611];
		layernorm1_13 -> ffn_up_13	[pos="e,834.15,3513.9 952.59,3549.8 917.89,3539.3 879.37,3527.6 844.03,3516.9"];
		ffn_gate_13	[color=lightblue,
			height=0.94444,
			label="GPU13_Layer13_FFN_Gate
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-13",
			pos="1093,3479.9",
			shape=rectangle,
			style=filled,
			width=4.8611];
		layernorm1_13 -> ffn_gate_13	[pos="e,1082.9,3514.2 1072.1,3549.8 1074.6,3541.5 1077.3,3532.5 1080,3523.8"];
		ffn_residual_13	[color=lightyellow,
			height=2.3056,
			label="GPU13_Layer13_FFN_Residual
Input1: [batch=128, seq=10000, hidden=4096]
Input2: [batch=128, seq=10000, hidden=4096]
Output: [batch=\
128, seq=10000, hidden=4096]
Device: GPU-13",
			pos="1031,3118.9",
			shape=parallelogram,
			style=filled,
			width=10.425];
		layernorm1_13 -> ffn_residual_13	[pos="e,1186.9,3202 1236.2,3549.8 1252,3540.5 1266.1,3528.8 1277,3513.9 1294.8,3489.5 1281,3475.9 1277,3445.9 1264.4,3351 1278.1,3314.8 \
1221,3237.9 1213.2,3227.5 1204.3,3217.8 1194.5,3208.7"];
		ffn_act_13	[color=lightblue,
			height=0.94444,
			label="GPU13_Layer13_FFN_Act
Input: [batch=128, seq=10000, ffn=16384]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-13",
			pos="1031,3375.9",
			shape=rectangle,
			style=filled,
			width=4.7361];
		ffn_up_13 -> ffn_act_13	[pos="e,931.89,3409.9 824.35,3445.8 855.58,3435.4 890.23,3423.8 922.1,3413.2"];
		ffn_gate_13 -> ffn_act_13	[pos="e,1051.2,3410.2 1072.9,3445.8 1067.7,3437.2 1062,3427.9 1056.6,3419"];
		ffn_down_13	[color=lightblue,
			height=0.94444,
			label="GPU13_Layer13_FFN_Down
Input: [batch=128, seq=10000, ffn=16384]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-13",
			pos="1031,3271.9",
			shape=rectangle,
			style=filled,
			width=5.0278];
		ffn_act_13 -> ffn_down_13	[pos="e,1031,3306.2 1031,3341.8 1031,3333.7 1031,3324.9 1031,3316.4"];
		ffn_down_13 -> ffn_residual_13	[pos="e,1031,3202.1 1031,3237.8 1031,3230 1031,3221.4 1031,3212.4"];
		layernorm2_13	[color=lightblue,
			height=0.94444,
			label="GPU13_Layer13_LayerNorm2
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-13",
			pos="1031,2965.9",
			shape=rectangle,
			style=filled,
			width=5.0278];
		ffn_residual_13 -> layernorm2_13	[pos="e,1031,3000.2 1031,3035.8 1031,3027 1031,3018.4 1031,3010.4"];
	}
	subgraph cluster_gpu14 {
		graph [bb="275,1544,1147,2813",
			color=color7,
			label="GPU-14 (Layer 14)",
			lheight=0.21,
			lp="711,2801.5",
			lwidth=1.60,
			style=rounded
		];
		mha_q_14	[color=lightblue,
			height=0.94444,
			label="GPU14_Layer14_MHA_Q
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-14",
			pos="915,2748",
			shape=rectangle,
			style=filled,
			width=5.6806];
		attn_score_14	[color=lightblue,
			height=1.1528,
			label="GPU14_Layer14_Attn_Score
Input1: [batch=128, seq=10000, heads=32, d_k=128]
Input2: [batch=128, seq=10000, heads=32, d_k=128]
Output: [\
batch=128, seq=10000, heads=32, seq=10000]
Device: GPU-14",
			pos="497,2636.5",
			shape=rectangle,
			style=filled,
			width=5.9444];
		mha_q_14 -> attn_score_14	[pos="e,651.92,2678 789.02,2714 748.99,2703.5 704.11,2691.7 661.76,2680.6"];
		mha_k_14	[color=lightblue,
			height=0.94444,
			label="GPU14_Layer14_MHA_K
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-14",
			pos="488,2748",
			shape=rectangle,
			style=filled,
			width=5.6806];
		mha_k_14 -> attn_score_14	[pos="e,493.65,2678.2 490.72,2713.8 491.39,2705.7 492.11,2697 492.82,2688.3"];
		mha_v_14	[color=lightblue,
			height=0.94444,
			label="GPU14_Layer14_MHA_V
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-14",
			pos="934,2636.5",
			shape=rectangle,
			style=filled,
			width=5.6806];
		attn_out_14	[color=lightblue,
			height=1.1528,
			label="GPU14_Layer14_Attn_Out
Input1: [batch=128, seq=10000, heads=32, seq=10000]
Input2: [batch=128, seq=10000, heads=32, d_k=128]
Output: [\
batch=128, seq=10000, hidden=4096]
Device: GPU-14",
			pos="764,2517.5",
			shape=rectangle,
			style=filled,
			width=5.9028];
		mha_v_14 -> attn_out_14	[pos="e,822.96,2559 885.74,2602.2 868.8,2590.6 849.45,2577.3 831.24,2564.7"];
		attn_score_14 -> attn_out_14	[pos="e,671.53,2559 589.63,2594.9 613.04,2584.6 638.29,2573.5 662.12,2563.1"];
		attn_residual_14	[color=lightyellow,
			height=2.3056,
			label="GPU14_Layer14_Attn_Residual
Input1: [batch=128, seq=10000, hidden=4096]
Input2: [batch=128, seq=10000, hidden=4096]
Output: [batch=\
128, seq=10000, hidden=4096]
Device: GPU-14",
			pos="764,2357",
			shape=parallelogram,
			style=filled,
			width=10.425];
		attn_out_14 -> attn_residual_14	[pos="e,764,2440.2 764,2475.6 764,2467.7 764,2459.1 764,2450.3"];
		layernorm1_14	[color=lightblue,
			height=0.94444,
			label="GPU14_Layer14_LayerNorm1
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-14",
			pos="795,2204",
			shape=rectangle,
			style=filled,
			width=5.0278];
		attn_residual_14 -> layernorm1_14	[pos="e,788.17,2238.2 780.86,2273.8 782.68,2265 784.47,2256.2 786.14,2248.1"];
		ffn_up_14	[color=lightblue,
			height=0.94444,
			label="GPU14_Layer14_FFN_Up
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-14",
			pos="458,2100",
			shape=rectangle,
			style=filled,
			width=4.8611];
		layernorm1_14 -> ffn_up_14	[pos="e,567.15,2134 685.59,2169.8 650.89,2159.3 612.37,2147.7 577.03,2137"];
		ffn_gate_14	[color=lightblue,
			height=0.94444,
			label="GPU14_Layer14_FFN_Gate
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-14",
			pos="826,2100",
			shape=rectangle,
			style=filled,
			width=4.8611];
		layernorm1_14 -> ffn_gate_14	[pos="e,815.88,2134.3 805.06,2169.8 807.58,2161.6 810.32,2152.5 812.96,2143.9"];
		ffn_residual_14	[color=lightyellow,
			height=2.3056,
			label="GPU14_Layer14_FFN_Residual
Input1: [batch=128, seq=10000, hidden=4096]
Input2: [batch=128, seq=10000, hidden=4096]
Output: [batch=\
128, seq=10000, hidden=4096]
Device: GPU-14",
			pos="764,1739",
			shape=parallelogram,
			style=filled,
			width=10.425];
		layernorm1_14 -> ffn_residual_14	[pos="e,919.95,1822 969.21,2169.8 985.03,2160.6 999.14,2148.8 1010,2134 1027.8,2109.5 1014,2095.9 1010,2066 997.45,1971 1011.1,1934.8 \
954,1858 946.25,1847.5 937.28,1837.8 927.54,1828.8"];
		ffn_act_14	[color=lightblue,
			height=0.94444,
			label="GPU14_Layer14_FFN_Act
Input: [batch=128, seq=10000, ffn=16384]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-14",
			pos="764,1996",
			shape=rectangle,
			style=filled,
			width=4.7361];
		ffn_up_14 -> ffn_act_14	[pos="e,664.89,2030 557.35,2065.8 588.58,2055.4 623.23,2043.9 655.1,2033.3"];
		ffn_gate_14 -> ffn_act_14	[pos="e,784.24,2030.3 805.87,2065.8 800.67,2057.3 795.01,2048 789.57,2039"];
		ffn_down_14	[color=lightblue,
			height=0.94444,
			label="GPU14_Layer14_FFN_Down
Input: [batch=128, seq=10000, ffn=16384]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-14",
			pos="764,1892",
			shape=rectangle,
			style=filled,
			width=5.0278];
		ffn_act_14 -> ffn_down_14	[pos="e,764,1926.3 764,1961.8 764,1953.7 764,1944.9 764,1936.4"];
		ffn_down_14 -> ffn_residual_14	[pos="e,764,1822.2 764,1857.8 764,1850.1 764,1841.4 764,1832.4"];
		layernorm2_14	[color=lightblue,
			height=0.94444,
			label="GPU14_Layer14_LayerNorm2
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-14",
			pos="764,1586",
			shape=rectangle,
			style=filled,
			width=5.0278];
		ffn_residual_14 -> layernorm2_14	[pos="e,764,1620.2 764,1655.8 764,1647.1 764,1638.4 764,1630.4"];
	}
	subgraph cluster_gpu15 {
		graph [bb="8,164,880,1433",
			color=color8,
			label="GPU-15 (Layer 15)",
			lheight=0.21,
			lp="444,1421.5",
			lwidth=1.60,
			style=rounded
		];
		mha_q_15	[color=lightblue,
			height=0.94444,
			label="GPU15_Layer15_MHA_Q
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-15",
			pos="648,1368",
			shape=rectangle,
			style=filled,
			width=5.6806];
		attn_score_15	[color=lightblue,
			height=1.1528,
			label="GPU15_Layer15_Attn_Score
Input1: [batch=128, seq=10000, heads=32, d_k=128]
Input2: [batch=128, seq=10000, heads=32, d_k=128]
Output: [\
batch=128, seq=10000, heads=32, seq=10000]
Device: GPU-15",
			pos="230,1256.5",
			shape=rectangle,
			style=filled,
			width=5.9444];
		mha_q_15 -> attn_score_15	[pos="e,384.92,1298.1 522.02,1334 481.99,1323.5 437.11,1311.8 394.76,1300.7"];
		mha_k_15	[color=lightblue,
			height=0.94444,
			label="GPU15_Layer15_MHA_K
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-15",
			pos="221,1368",
			shape=rectangle,
			style=filled,
			width=5.6806];
		mha_k_15 -> attn_score_15	[pos="e,226.65,1298.3 223.72,1333.8 224.39,1325.8 225.11,1317 225.82,1308.3"];
		mha_v_15	[color=lightblue,
			height=0.94444,
			label="GPU15_Layer15_MHA_V
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, heads=32, d_k=128]
Device: GPU-15",
			pos="667,1256.5",
			shape=rectangle,
			style=filled,
			width=5.6806];
		attn_out_15	[color=lightblue,
			height=1.1528,
			label="GPU15_Layer15_Attn_Out
Input1: [batch=128, seq=10000, heads=32, seq=10000]
Input2: [batch=128, seq=10000, heads=32, d_k=128]
Output: [\
batch=128, seq=10000, hidden=4096]
Device: GPU-15",
			pos="497,1137.5",
			shape=rectangle,
			style=filled,
			width=5.9028];
		mha_v_15 -> attn_out_15	[pos="e,555.96,1179.1 618.74,1222.3 601.8,1210.6 582.45,1197.3 564.24,1184.8"];
		attn_score_15 -> attn_out_15	[pos="e,404.53,1179 322.63,1214.9 346.04,1204.7 371.29,1193.6 395.12,1183.1"];
		attn_residual_15	[color=lightyellow,
			height=2.3056,
			label="GPU15_Layer15_Attn_Residual
Input1: [batch=128, seq=10000, hidden=4096]
Input2: [batch=128, seq=10000, hidden=4096]
Output: [batch=\
128, seq=10000, hidden=4096]
Device: GPU-15",
			pos="497,977",
			shape=parallelogram,
			style=filled,
			width=10.425];
		attn_out_15 -> attn_residual_15	[pos="e,497,1060.3 497,1095.7 497,1087.8 497,1079.1 497,1070.3"];
		layernorm1_15	[color=lightblue,
			height=0.94444,
			label="GPU15_Layer15_LayerNorm1
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-15",
			pos="528,824",
			shape=rectangle,
			style=filled,
			width=5.0278];
		attn_residual_15 -> layernorm1_15	[pos="e,521.17,858.26 513.86,893.87 515.68,885.02 517.47,876.29 519.14,868.18"];
		ffn_up_15	[color=lightblue,
			height=0.94444,
			label="GPU15_Layer15_FFN_Up
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-15",
			pos="191,720",
			shape=rectangle,
			style=filled,
			width=4.8611];
		layernorm1_15 -> ffn_up_15	[pos="e,300.15,754.04 418.59,789.88 383.89,779.38 345.37,767.72 310.03,757.03"];
		ffn_gate_15	[color=lightblue,
			height=0.94444,
			label="GPU15_Layer15_FFN_Gate
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-15",
			pos="559,720",
			shape=rectangle,
			style=filled,
			width=4.8611];
		layernorm1_15 -> ffn_gate_15	[pos="e,548.88,754.3 538.06,789.88 540.58,781.6 543.32,772.6 545.96,763.91"];
		ffn_residual_15	[color=lightyellow,
			height=2.3056,
			label="GPU15_Layer15_FFN_Residual
Input1: [batch=128, seq=10000, hidden=4096]
Input2: [batch=128, seq=10000, hidden=4096]
Output: [batch=\
128, seq=10000, hidden=4096]
Device: GPU-15",
			pos="497,359",
			shape=parallelogram,
			style=filled,
			width=10.425];
		layernorm1_15 -> ffn_residual_15	[pos="e,652.95,442.07 702.21,789.89 718.03,780.63 732.14,768.89 743,754 760.81,729.58 746.96,715.96 743,686 730.45,591.09 744.1,554.85 \
687,478 679.25,467.57 670.28,457.85 660.54,448.83"];
		ffn_act_15	[color=lightblue,
			height=0.94444,
			label="GPU15_Layer15_FFN_Act
Input: [batch=128, seq=10000, ffn=16384]
Output: [batch=128, seq=10000, ffn=16384]
Device: GPU-15",
			pos="497,616",
			shape=rectangle,
			style=filled,
			width=4.7361];
		ffn_up_15 -> ffn_act_15	[pos="e,397.89,650.04 290.35,685.88 321.58,675.47 356.23,663.92 388.1,653.3"];
		ffn_gate_15 -> ffn_act_15	[pos="e,517.24,650.3 538.87,685.88 533.67,677.33 528.01,668.01 522.57,659.07"];
		ffn_down_15	[color=lightblue,
			height=0.94444,
			label="GPU15_Layer15_FFN_Down
Input: [batch=128, seq=10000, ffn=16384]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-15",
			pos="497,512",
			shape=rectangle,
			style=filled,
			width=5.0278];
		ffn_act_15 -> ffn_down_15	[pos="e,497,546.3 497,581.88 497,573.78 497,564.98 497,556.47"];
		ffn_down_15 -> ffn_residual_15	[pos="e,497,442.23 497,477.86 497,470.1 497,461.46 497,452.48"];
		layernorm2_15	[color=lightblue,
			height=0.94444,
			label="GPU15_Layer15_LayerNorm2
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, hidden=4096]
Device: GPU-15",
			pos="497,206",
			shape=rectangle,
			style=filled,
			width=5.0278];
		ffn_residual_15 -> layernorm2_15	[pos="e,497,240.26 497,275.87 497,267.12 497,258.48 497,250.45"];
	}
	input	[color=lightyellow,
		height=1.8889,
		label="Input Embedding
Input: [batch=128, seq=10000, hidden=4096]
Device: GPU-0
Layer: Embedding+Pre-process",
		pos="4769,22208",
		shape=parallelogram,
		style=filled,
		width=10.08];
	input -> mha_q_0	[pos="e,4680.7,22101 4713,22140 4704.3,22130 4695.4,22119 4687.3,22109"];
	input -> mha_k_0	[pos="e,4330.7,22101 4469.7,22140 4459.4,22138 4449.1,22135 4439,22132 4406.9,22124 4372.2,22114 4340.5,22104"];
	input -> mha_v_0	[pos="e,4816.3,21990 4862.6,22140 4864.2,22138 4865.7,22135 4867,22132 4886.5,22093 4891.8,22070 4867,22033 4856.2,22017 4841.5,22005 \
4825.1,21995"];
	input -> attn_residual_0	[pos="e,4720.4,21759 4884.1,22140 4885.9,22138 4887.5,22135 4889,22132 4895.6,22120 4888.8,21920 4886,21914 4852.2,21850 4792.1,21801 \
4729.3,21764"];
	comm_0	[color=lightgreen,
		height=1.041,
		label="GPU0_to_GPU1
Transfer: [batch=128, seq=10000, hidden=4096]
Bandwidth: NVLink 900GB/s",
		pos="4502,20798",
		shape=ellipse,
		style=filled,
		width=7.3068];
	layernorm2_0 -> comm_0	[pos="e,4502,20835 4502,20871 4502,20863 4502,20854 4502,20845"];
	comm_1	[color=lightgreen,
		height=1.041,
		label="GPU1_to_GPU2
Transfer: [batch=128, seq=10000, hidden=4096]
Bandwidth: NVLink 900GB/s",
		pos="4235,19418",
		shape=ellipse,
		style=filled,
		width=7.3068];
	layernorm2_1 -> comm_1	[pos="e,4235,19456 4235,19491 4235,19483 4235,19474 4235,19466"];
	comm_2	[color=lightgreen,
		height=1.041,
		label="GPU2_to_GPU3
Transfer: [batch=128, seq=10000, hidden=4096]
Bandwidth: NVLink 900GB/s",
		pos="3968,18038",
		shape=ellipse,
		style=filled,
		width=7.3068];
	layernorm2_2 -> comm_2	[pos="e,3968,18076 3968,18111 3968,18103 3968,18094 3968,18086"];
	comm_3	[color=lightgreen,
		height=1.041,
		label="GPU3_to_GPU4
Transfer: [batch=128, seq=10000, hidden=4096]
Bandwidth: NVLink 900GB/s",
		pos="3701,16658",
		shape=ellipse,
		style=filled,
		width=7.3068];
	layernorm2_3 -> comm_3	[pos="e,3701,16696 3701,16731 3701,16723 3701,16714 3701,16706"];
	comm_4	[color=lightgreen,
		height=1.041,
		label="GPU4_to_GPU5
Transfer: [batch=128, seq=10000, hidden=4096]
Bandwidth: NVLink 900GB/s",
		pos="3434,15278",
		shape=ellipse,
		style=filled,
		width=7.3068];
	layernorm2_4 -> comm_4	[pos="e,3434,15316 3434,15351 3434,15343 3434,15334 3434,15326"];
	comm_5	[color=lightgreen,
		height=1.041,
		label="GPU5_to_GPU6
Transfer: [batch=128, seq=10000, hidden=4096]
Bandwidth: NVLink 900GB/s",
		pos="3167,13898",
		shape=ellipse,
		style=filled,
		width=7.3068];
	layernorm2_5 -> comm_5	[pos="e,3167,13936 3167,13971 3167,13963 3167,13954 3167,13946"];
	comm_6	[color=lightgreen,
		height=1.041,
		label="GPU6_to_GPU7
Transfer: [batch=128, seq=10000, hidden=4096]
Bandwidth: NVLink 900GB/s",
		pos="2900,12518",
		shape=ellipse,
		style=filled,
		width=7.3068];
	layernorm2_6 -> comm_6	[pos="e,2900,12556 2900,12591 2900,12583 2900,12574 2900,12566"];
	comm_7	[color=lightgreen,
		height=1.041,
		label="GPU7_to_GPU8
Transfer: [batch=128, seq=10000, hidden=4096]
Bandwidth: NVLink 900GB/s",
		pos="2633,11138",
		shape=ellipse,
		style=filled,
		width=7.3068];
	layernorm2_7 -> comm_7	[pos="e,2633,11176 2633,11212 2633,11203 2633,11194 2633,11186"];
	comm_8	[color=lightgreen,
		height=1.041,
		label="GPU8_to_GPU9
Transfer: [batch=128, seq=10000, hidden=4096]
Bandwidth: NVLink 900GB/s",
		pos="2366,9758.2",
		shape=ellipse,
		style=filled,
		width=7.3068];
	layernorm2_8 -> comm_8	[pos="e,2366,9795.8 2366,9831.6 2366,9823.4 2366,9814.5 2366,9805.9"];
	comm_9	[color=lightgreen,
		height=1.041,
		label="GPU9_to_GPU10
Transfer: [batch=128, seq=10000, hidden=4096]
Bandwidth: NVLink 900GB/s",
		pos="2099,8378.2",
		shape=ellipse,
		style=filled,
		width=7.3068];
	layernorm2_9 -> comm_9	[pos="e,2099,8415.9 2099,8451.6 2099,8443.5 2099,8434.6 2099,8425.9"];
	comm_10	[color=lightgreen,
		height=1.041,
		label="GPU10_to_GPU11
Transfer: [batch=128, seq=10000, hidden=4096]
Bandwidth: NVLink 900GB/s",
		pos="1832,6998.3",
		shape=ellipse,
		style=filled,
		width=7.3068];
	layernorm2_10 -> comm_10	[pos="e,1832,7035.9 1832,7071.7 1832,7063.5 1832,7054.6 1832,7045.9"];
	comm_11	[color=lightgreen,
		height=1.041,
		label="GPU11_to_GPU12
Transfer: [batch=128, seq=10000, hidden=4096]
Bandwidth: NVLink 900GB/s",
		pos="1565,5618.3",
		shape=ellipse,
		style=filled,
		width=7.3068];
	layernorm2_11 -> comm_11	[pos="e,1565,5656 1565,5691.7 1565,5683.6 1565,5674.7 1565,5666"];
	comm_12	[color=lightgreen,
		height=1.041,
		label="GPU12_to_GPU13
Transfer: [batch=128, seq=10000, hidden=4096]
Bandwidth: NVLink 900GB/s",
		pos="1298,4238.4",
		shape=ellipse,
		style=filled,
		width=7.3068];
	layernorm2_12 -> comm_12	[pos="e,1298,4276 1298,4311.8 1298,4303.6 1298,4294.7 1298,4286"];
	comm_13	[color=lightgreen,
		height=1.041,
		label="GPU13_to_GPU14
Transfer: [batch=128, seq=10000, hidden=4096]
Bandwidth: NVLink 900GB/s",
		pos="1031,2858.4",
		shape=ellipse,
		style=filled,
		width=7.3068];
	layernorm2_13 -> comm_13	[pos="e,1031,2896.1 1031,2931.8 1031,2923.7 1031,2914.8 1031,2906.1"];
	comm_14	[color=lightgreen,
		height=1.041,
		label="GPU14_to_GPU15
Transfer: [batch=128, seq=10000, hidden=4096]
Bandwidth: NVLink 900GB/s",
		pos="764,1478.5",
		shape=ellipse,
		style=filled,
		width=7.3068];
	layernorm2_14 -> comm_14	[pos="e,764,1516.1 764,1551.9 764,1543.7 764,1534.8 764,1526.1"];
	output	[color=purple,
		height=1.8889,
		label="Final Output Projection
Input: [batch=128, seq=10000, hidden=4096]
Output: [batch=128, seq=10000, vocab_size=128256]
Device: GPU-15",
		pos="497,68",
		shape=parallelogram,
		style=filled,
		width=11.721];
	layernorm2_15 -> output	[pos="e,497,136.26 497,171.73 497,163.9 497,155.24 497,146.35"];
	comm_0 -> mha_q_1	[pos="e,4421.3,20721 4463.4,20761 4452.2,20750 4440,20739 4428.7,20728"];
	comm_0 -> mha_k_1	[pos="e,4057.3,20721 4296.9,20774 4255.4,20768 4212.1,20761 4172,20752 4137.5,20745 4100.4,20735 4067.1,20724"];
	comm_0 -> mha_v_1	[pos="e,4548.6,20610 4591.1,20762 4594,20759 4596.7,20756 4599,20752 4622.8,20715 4623.8,20690 4599,20653 4588.2,20638 4573.7,20625 4557.3,\
20615"];
	comm_0 -> attn_residual_1	[pos="e,4451.4,20379 4613.4,20763 4617,20760 4620.2,20756 4623,20752 4632,20739 4620.3,20539 4618,20534 4583.6,20470 4523.1,20421 4460.3,\
20384"];
	comm_1 -> mha_q_2	[pos="e,4154.3,19341 4196.4,19381 4185.2,19370 4173,19359 4161.7,19348"];
	comm_1 -> mha_k_2	[pos="e,3790.3,19341 4029.9,19394 3988.4,19388 3945.1,19381 3905,19372 3870.5,19365 3833.4,19355 3800.1,19344"];
	comm_1 -> mha_v_2	[pos="e,4281.6,19230 4324.1,19382 4327,19379 4329.7,19376 4332,19372 4355.8,19335 4356.8,19310 4332,19273 4321.2,19258 4306.7,19245 4290.3,\
19235"];
	comm_1 -> attn_residual_2	[pos="e,4184.4,19000 4346.4,19383 4350,19380 4353.2,19376 4356,19372 4365,19359 4353.3,19159 4351,19154 4316.6,19090 4256.1,19041 4193.3,\
19005"];
	comm_2 -> mha_q_3	[pos="e,3887.3,17961 3929.4,18001 3918.2,17990 3906,17979 3894.7,17968"];
	comm_2 -> mha_k_3	[pos="e,3523.3,17962 3762.9,18014 3721.4,18008 3678.1,18001 3638,17992 3603.5,17985 3566.4,17975 3533.1,17965"];
	comm_2 -> mha_v_3	[pos="e,4014.6,17850 4057.1,18002 4060,17999 4062.7,17996 4065,17992 4088.8,17955 4089.8,17930 4065,17893 4054.2,17878 4039.7,17865 4023.3,\
17855"];
	comm_2 -> attn_residual_3	[pos="e,3917.4,17620 4079.4,18003 4083,18000 4086.2,17996 4089,17992 4098,17980 4086.3,17779 4084,17774 4049.6,17710 3989.1,17661 3926.3,\
17625"];
	comm_3 -> mha_q_4	[pos="e,3620.3,16582 3662.4,16621 3651.2,16610 3639,16599 3627.7,16588"];
	comm_3 -> mha_k_4	[pos="e,3256.3,16582 3495.9,16634 3454.4,16628 3411.1,16621 3371,16612 3336.5,16605 3299.4,16595 3266.1,16585"];
	comm_3 -> mha_v_4	[pos="e,3747.6,16470 3790.1,16622 3793,16619 3795.7,16616 3798,16612 3821.8,16575 3822.8,16550 3798,16513 3787.2,16498 3772.7,16485 3756.3,\
16475"];
	comm_3 -> attn_residual_4	[pos="e,3650.4,16240 3812.4,16624 3816,16620 3819.2,16617 3822,16612 3831,16600 3819.3,16399 3817,16394 3782.6,16330 3722.1,16281 3659.3,\
16245"];
	comm_4 -> mha_q_5	[pos="e,3353.3,15202 3395.4,15241 3384.2,15230 3372,15219 3360.7,15208"];
	comm_4 -> mha_k_5	[pos="e,2989.3,15202 3228.9,15254 3187.4,15248 3144.1,15241 3104,15233 3069.5,15225 3032.4,15215 2999.1,15205"];
	comm_4 -> mha_v_5	[pos="e,3480.6,15090 3523.1,15242 3526,15239 3528.7,15236 3531,15233 3554.8,15195 3555.8,15170 3531,15134 3520.2,15118 3505.7,15105 3489.3,\
15095"];
	comm_4 -> attn_residual_5	[pos="e,3383.4,14860 3545.4,15244 3549,15240 3552.2,15237 3555,15233 3564,15220 3552.3,15019 3550,15015 3515.6,14950 3455.1,14901 3392.3,\
14865"];
	comm_5 -> mha_q_6	[pos="e,3086.3,13822 3128.4,13861 3117.2,13851 3105,13839 3093.7,13828"];
	comm_5 -> mha_k_6	[pos="e,2722.3,13822 2961.9,13875 2920.4,13869 2877.1,13861 2837,13853 2802.5,13845 2765.4,13835 2732.1,13825"];
	comm_5 -> mha_v_6	[pos="e,3213.6,13710 3256.1,13863 3259,13859 3261.7,13856 3264,13853 3287.8,13816 3288.8,13790 3264,13754 3253.2,13738 3238.7,13725 3222.3,\
13715"];
	comm_5 -> attn_residual_6	[pos="e,3116.4,13480 3278.4,13864 3282,13860 3285.2,13857 3288,13853 3297,13840 3285.3,13639 3283,13635 3248.6,13570 3188.1,13521 3125.3,\
13485"];
	comm_6 -> mha_q_7	[pos="e,2819.3,12442 2861.4,12481 2850.2,12471 2838,12459 2826.7,12449"];
	comm_6 -> mha_k_7	[pos="e,2455.3,12442 2694.9,12495 2653.4,12489 2610.1,12481 2570,12473 2535.5,12465 2498.4,12455 2465.1,12445"];
	comm_6 -> mha_v_7	[pos="e,2946.6,12330 2989.1,12483 2992,12480 2994.7,12476 2997,12473 3020.8,12436 3021.8,12410 2997,12374 2986.2,12358 2971.7,12345 2955.3,\
12335"];
	comm_6 -> attn_residual_7	[pos="e,2849.4,12100 3011.4,12484 3015,12480 3018.2,12477 3021,12473 3030,12460 3018.3,12259 3016,12255 2981.6,12190 2921.1,12141 2858.3,\
12105"];
	comm_7 -> mha_q_8	[pos="e,2552.3,11062 2594.4,11101 2583.2,11091 2571,11079 2559.7,11069"];
	comm_7 -> mha_k_8	[pos="e,2188.3,11062 2427.9,11115 2386.4,11109 2343.1,11101 2303,11093 2268.5,11085 2231.4,11075 2198.1,11065"];
	comm_7 -> mha_v_8	[pos="e,2679.6,10950 2722.1,11103 2725,11100 2727.7,11096 2730,11093 2753.8,11056 2754.8,11030 2730,10994 2719.2,10978 2704.7,10965 2688.3,\
10955"];
	comm_7 -> attn_residual_8	[pos="e,2582.4,10720 2744.4,11104 2748,11100 2751.2,11097 2754,11093 2763,11080 2751.3,10879 2749,10875 2714.6,10810 2654.1,10761 2591.3,\
10725"];
	comm_8 -> mha_q_9	[pos="e,2285.3,9681.8 2327.4,9721.1 2316.2,9710.7 2304,9699.2 2292.7,9688.6"];
	comm_8 -> mha_k_9	[pos="e,1921.3,9681.8 2160.9,9734.7 2119.4,9728.7 2076.1,9721.4 2036,9712.7 2001.5,9705.3 1964.4,9695 1931.1,9684.8"];
	comm_8 -> mha_v_9	[pos="e,2412.6,9570.5 2455.1,9722.6 2458,9719.6 2460.7,9716.3 2463,9712.7 2486.8,9675.7 2487.8,9650.1 2463,9613.7 2452.2,9597.9 2437.7,\
9585.4 2421.3,9575.4"];
	comm_8 -> attn_residual_9	[pos="e,2315.4,9339.8 2477.4,9723.8 2481,9720.4 2484.2,9716.8 2487,9712.7 2496,9699.8 2484.3,9499.1 2482,9494.7 2447.6,9430.1 2387.1,9381.1 \
2324.3,9344.9"];
	comm_9 -> mha_q_10	[pos="e,2018.3,8301.8 2060.4,8341.1 2049.2,8330.7 2037,8319.3 2025.7,8308.7"];
	comm_9 -> mha_k_10	[pos="e,1654.3,8301.8 1893.9,8354.7 1852.4,8348.7 1809.1,8341.4 1769,8332.8 1734.5,8325.3 1697.4,8315 1664.1,8304.8"];
	comm_9 -> mha_v_10	[pos="e,2145.6,8190.5 2188.1,8342.7 2191,8339.7 2193.7,8336.4 2196,8332.8 2219.8,8295.7 2220.8,8270.1 2196,8233.8 2185.2,8218 2170.7,8205.4 \
2154.3,8195.5"];
	comm_9 -> attn_residual_10	[pos="e,2048.4,7959.9 2210.4,8343.8 2214,8340.5 2217.2,8336.8 2220,8332.8 2229,8319.9 2217.3,8119.1 2215,8114.8 2180.6,8050.2 2120.1,8001.1 \
2057.3,7964.9"];
	comm_10 -> mha_q_11	[pos="e,1751.3,6921.9 1793.4,6961.2 1782.2,6950.8 1770,6939.3 1758.7,6928.7"];
	comm_10 -> mha_k_11	[pos="e,1387.3,6921.9 1626.9,6974.8 1585.4,6968.8 1542.1,6961.5 1502,6952.8 1467.5,6945.3 1430.4,6935 1397.1,6924.9"];
	comm_10 -> mha_v_11	[pos="e,1878.6,6810.6 1921.1,6962.7 1924,6959.7 1926.7,6956.4 1929,6952.8 1952.8,6915.8 1953.8,6890.2 1929,6853.8 1918.2,6838 1903.7,6825.5 \
1887.3,6815.5"];
	comm_10 -> attn_residual_11	[pos="e,1781.4,6579.9 1943.4,6963.9 1947,6960.5 1950.2,6956.9 1953,6952.8 1962,6939.9 1950.3,6739.2 1948,6734.8 1913.6,6670.2 1853.1,6621.2 \
1790.3,6585"];
	comm_11 -> mha_q_12	[pos="e,1484.3,5541.9 1526.4,5581.2 1515.2,5570.8 1503,5559.4 1491.7,5548.7"];
	comm_11 -> mha_k_12	[pos="e,1120.3,5541.9 1359.9,5594.8 1318.4,5588.8 1275.1,5581.5 1235,5572.9 1200.5,5565.4 1163.4,5555.1 1130.1,5544.9"];
	comm_11 -> mha_v_12	[pos="e,1611.6,5430.6 1654.1,5582.8 1657,5579.7 1659.7,5576.4 1662,5572.9 1685.8,5535.8 1686.8,5510.2 1662,5473.9 1651.2,5458.1 1636.7,\
5445.5 1620.3,5435.6"];
	comm_11 -> attn_residual_12	[pos="e,1514.4,5200 1676.4,5583.9 1680,5580.6 1683.2,5576.9 1686,5572.9 1695,5560 1683.3,5359.2 1681,5354.9 1646.6,5290.3 1586.1,5241.2 \
1523.3,5205"];
	comm_12 -> mha_q_13	[pos="e,1217.3,4161.9 1259.4,4201.3 1248.2,4190.8 1236,4179.4 1224.7,4168.8"];
	comm_12 -> mha_k_13	[pos="e,853.31,4162 1092.9,4214.9 1051.4,4208.9 1008.1,4201.6 968,4192.9 933.48,4185.4 896.43,4175.1 863.08,4165"];
	comm_12 -> mha_v_13	[pos="e,1344.6,4050.6 1387.1,4202.8 1390,4199.8 1392.7,4196.5 1395,4192.9 1418.8,4155.9 1419.8,4130.3 1395,4093.9 1384.2,4078.1 1369.7,\
4065.6 1353.3,4055.6"];
	comm_12 -> attn_residual_13	[pos="e,1247.4,3820 1409.4,4204 1413,4200.6 1416.2,4196.9 1419,4192.9 1428,4180 1416.3,3979.3 1414,3974.9 1379.6,3910.3 1319.1,3861.3 \
1256.3,3825"];
	comm_13 -> mha_q_14	[pos="e,950.33,2782 992.37,2821.3 981.24,2810.9 969.02,2799.5 957.66,2788.8"];
	comm_13 -> mha_k_14	[pos="e,586.31,2782 825.92,2834.9 784.37,2828.9 741.12,2821.6 701,2813 666.48,2805.5 629.43,2795.2 596.08,2785"];
	comm_13 -> mha_v_14	[pos="e,1077.6,2670.7 1120.1,2822.9 1123,2819.8 1125.7,2816.5 1128,2813 1151.8,2775.9 1152.8,2750.3 1128,2714 1117.2,2698.2 1102.7,2685.6 \
1086.3,2675.7"];
	comm_13 -> attn_residual_14	[pos="e,980.41,2440.1 1142.4,2824 1146,2820.7 1149.2,2817 1152,2813 1161,2800.1 1149.3,2599.3 1147,2595 1112.6,2530.4 1052.1,2481.3 989.29,\
2445.1"];
	comm_14 -> mha_q_15	[pos="e,683.33,1402 725.37,1441.4 714.24,1430.9 702.02,1419.5 690.66,1408.9"];
	comm_14 -> mha_k_15	[pos="e,319.31,1402.1 558.92,1455 517.37,1449 474.12,1441.7 434,1433 399.48,1425.5 362.43,1415.2 329.08,1405.1"];
	comm_14 -> mha_v_15	[pos="e,810.62,1290.7 853.07,1442.9 856.03,1439.9 858.7,1436.6 861,1433 884.76,1396 885.76,1370.4 861,1334 850.24,1318.2 835.67,1305.7 \
819.32,1295.7"];
	comm_14 -> attn_residual_15	[pos="e,713.41,1060.1 875.41,1444 878.96,1440.7 882.18,1437 885,1433 894,1420.1 882.32,1219.3 880,1215 845.58,1150.4 785.13,1101.4 722.29,\
1065.1"];
}
