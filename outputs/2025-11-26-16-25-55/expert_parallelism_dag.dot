digraph Expert_Parallelism_DAG {
	mha_input [label="MHA Input\n[batch_size=32, seq_len=2048, heads=128, d_k=128]\nGPU: 0" fillcolor=lightblue shape=ellipse style=filled]
	gate [label="Expert Gate\n[batch_size=32, seq_len=2048, token_dim=7168]\nGPU: 0" fillcolor=orange shape=parallelogram style=filled]
	token_split [label="Token Split\n[batch_size=32, seq_len=2048, token_dim=7168] -> [batch_size=32, tokens_per_expert, token_dim=7168]\nGPU: 0" fillcolor=yellow shape=parallelogram style=filled]
	expert_0_linear1 [label="Expert 0 Linear 1\n[batch_size=32, tokens_per_expert, token_dim=7168] -> [batch_size=32, tokens_per_expert, hidden=2048]\nGPU: 0" fillcolor=lightblue shape=rectangle style=filled]
	expert_0_gelu [label="Expert 0 GELU\n[batch_size=32, tokens_per_expert, hidden=2048] -> [batch_size=32, tokens_per_expert, hidden=2048]\nGPU: 0" fillcolor=lightgreen shape=rectangle style=filled]
	expert_0_linear2 [label="Expert 0 Linear 2\n[batch_size=32, tokens_per_expert, hidden=2048] -> [batch_size=32, tokens_per_expert, token_dim=7168]\nGPU: 0" fillcolor=lightblue shape=rectangle style=filled]
	expert_1_linear1 [label="Expert 1 Linear 1\n[batch_size=32, tokens_per_expert, token_dim=7168] -> [batch_size=32, tokens_per_expert, hidden=2048]\nGPU: 1" fillcolor=lightblue shape=rectangle style=filled]
	expert_1_gelu [label="Expert 1 GELU\n[batch_size=32, tokens_per_expert, hidden=2048] -> [batch_size=32, tokens_per_expert, hidden=2048]\nGPU: 1" fillcolor=lightgreen shape=rectangle style=filled]
	expert_1_linear2 [label="Expert 1 Linear 2\n[batch_size=32, tokens_per_expert, hidden=2048] -> [batch_size=32, tokens_per_expert, token_dim=7168]\nGPU: 1" fillcolor=lightblue shape=rectangle style=filled]
	expert_2_linear1 [label="Expert 2 Linear 1\n[batch_size=32, tokens_per_expert, token_dim=7168] -> [batch_size=32, tokens_per_expert, hidden=2048]\nGPU: 2" fillcolor=lightblue shape=rectangle style=filled]
	expert_2_gelu [label="Expert 2 GELU\n[batch_size=32, tokens_per_expert, hidden=2048] -> [batch_size=32, tokens_per_expert, hidden=2048]\nGPU: 2" fillcolor=lightgreen shape=rectangle style=filled]
	expert_2_linear2 [label="Expert 2 Linear 2\n[batch_size=32, tokens_per_expert, hidden=2048] -> [batch_size=32, tokens_per_expert, token_dim=7168]\nGPU: 2" fillcolor=lightblue shape=rectangle style=filled]
	expert_3_linear1 [label="Expert 3 Linear 1\n[batch_size=32, tokens_per_expert, token_dim=7168] -> [batch_size=32, tokens_per_expert, hidden=2048]\nGPU: 3" fillcolor=lightblue shape=rectangle style=filled]
	expert_3_gelu [label="Expert 3 GELU\n[batch_size=32, tokens_per_expert, hidden=2048] -> [batch_size=32, tokens_per_expert, hidden=2048]\nGPU: 3" fillcolor=lightgreen shape=rectangle style=filled]
	expert_3_linear2 [label="Expert 3 Linear 2\n[batch_size=32, tokens_per_expert, hidden=2048] -> [batch_size=32, tokens_per_expert, token_dim=7168]\nGPU: 3" fillcolor=lightblue shape=rectangle style=filled]
	expert_4_linear1 [label="Expert 4 Linear 1\n[batch_size=32, tokens_per_expert, token_dim=7168] -> [batch_size=32, tokens_per_expert, hidden=2048]\nGPU: 4" fillcolor=lightblue shape=rectangle style=filled]
	expert_4_gelu [label="Expert 4 GELU\n[batch_size=32, tokens_per_expert, hidden=2048] -> [batch_size=32, tokens_per_expert, hidden=2048]\nGPU: 4" fillcolor=lightgreen shape=rectangle style=filled]
	expert_4_linear2 [label="Expert 4 Linear 2\n[batch_size=32, tokens_per_expert, hidden=2048] -> [batch_size=32, tokens_per_expert, token_dim=7168]\nGPU: 4" fillcolor=lightblue shape=rectangle style=filled]
	expert_5_linear1 [label="Expert 5 Linear 1\n[batch_size=32, tokens_per_expert, token_dim=7168] -> [batch_size=32, tokens_per_expert, hidden=2048]\nGPU: 5" fillcolor=lightblue shape=rectangle style=filled]
	expert_5_gelu [label="Expert 5 GELU\n[batch_size=32, tokens_per_expert, hidden=2048] -> [batch_size=32, tokens_per_expert, hidden=2048]\nGPU: 5" fillcolor=lightgreen shape=rectangle style=filled]
	expert_5_linear2 [label="Expert 5 Linear 2\n[batch_size=32, tokens_per_expert, hidden=2048] -> [batch_size=32, tokens_per_expert, token_dim=7168]\nGPU: 5" fillcolor=lightblue shape=rectangle style=filled]
	expert_6_linear1 [label="Expert 6 Linear 1\n[batch_size=32, tokens_per_expert, token_dim=7168] -> [batch_size=32, tokens_per_expert, hidden=2048]\nGPU: 6" fillcolor=lightblue shape=rectangle style=filled]
	expert_6_gelu [label="Expert 6 GELU\n[batch_size=32, tokens_per_expert, hidden=2048] -> [batch_size=32, tokens_per_expert, hidden=2048]\nGPU: 6" fillcolor=lightgreen shape=rectangle style=filled]
	expert_6_linear2 [label="Expert 6 Linear 2\n[batch_size=32, tokens_per_expert, hidden=2048] -> [batch_size=32, tokens_per_expert, token_dim=7168]\nGPU: 6" fillcolor=lightblue shape=rectangle style=filled]
	expert_7_linear1 [label="Expert 7 Linear 1\n[batch_size=32, tokens_per_expert, token_dim=7168] -> [batch_size=32, tokens_per_expert, hidden=2048]\nGPU: 7" fillcolor=lightblue shape=rectangle style=filled]
	expert_7_gelu [label="Expert 7 GELU\n[batch_size=32, tokens_per_expert, hidden=2048] -> [batch_size=32, tokens_per_expert, hidden=2048]\nGPU: 7" fillcolor=lightgreen shape=rectangle style=filled]
	expert_7_linear2 [label="Expert 7 Linear 2\n[batch_size=32, tokens_per_expert, hidden=2048] -> [batch_size=32, tokens_per_expert, token_dim=7168]\nGPU: 7" fillcolor=lightblue shape=rectangle style=filled]
	expert_8_linear1 [label="Expert 8 Linear 1\n[batch_size=32, tokens_per_expert, token_dim=7168] -> [batch_size=32, tokens_per_expert, hidden=2048]\nGPU: 8" fillcolor=lightblue shape=rectangle style=filled]
	expert_8_gelu [label="Expert 8 GELU\n[batch_size=32, tokens_per_expert, hidden=2048] -> [batch_size=32, tokens_per_expert, hidden=2048]\nGPU: 8" fillcolor=lightgreen shape=rectangle style=filled]
	expert_8_linear2 [label="Expert 8 Linear 2\n[batch_size=32, tokens_per_expert, hidden=2048] -> [batch_size=32, tokens_per_expert, token_dim=7168]\nGPU: 8" fillcolor=lightblue shape=rectangle style=filled]
	expert_9_linear1 [label="Expert 9 Linear 1\n[batch_size=32, tokens_per_expert, token_dim=7168] -> [batch_size=32, tokens_per_expert, hidden=2048]\nGPU: 9" fillcolor=lightblue shape=rectangle style=filled]
	expert_9_gelu [label="Expert 9 GELU\n[batch_size=32, tokens_per_expert, hidden=2048] -> [batch_size=32, tokens_per_expert, hidden=2048]\nGPU: 9" fillcolor=lightgreen shape=rectangle style=filled]
	expert_9_linear2 [label="Expert 9 Linear 2\n[batch_size=32, tokens_per_expert, hidden=2048] -> [batch_size=32, tokens_per_expert, token_dim=7168]\nGPU: 9" fillcolor=lightblue shape=rectangle style=filled]
	expert_10_linear1 [label="Expert 10 Linear 1\n[batch_size=32, tokens_per_expert, token_dim=7168] -> [batch_size=32, tokens_per_expert, hidden=2048]\nGPU: 10" fillcolor=lightblue shape=rectangle style=filled]
	expert_10_gelu [label="Expert 10 GELU\n[batch_size=32, tokens_per_expert, hidden=2048] -> [batch_size=32, tokens_per_expert, hidden=2048]\nGPU: 10" fillcolor=lightgreen shape=rectangle style=filled]
	expert_10_linear2 [label="Expert 10 Linear 2\n[batch_size=32, tokens_per_expert, hidden=2048] -> [batch_size=32, tokens_per_expert, token_dim=7168]\nGPU: 10" fillcolor=lightblue shape=rectangle style=filled]
	expert_11_linear1 [label="Expert 11 Linear 1\n[batch_size=32, tokens_per_expert, token_dim=7168] -> [batch_size=32, tokens_per_expert, hidden=2048]\nGPU: 11" fillcolor=lightblue shape=rectangle style=filled]
	expert_11_gelu [label="Expert 11 GELU\n[batch_size=32, tokens_per_expert, hidden=2048] -> [batch_size=32, tokens_per_expert, hidden=2048]\nGPU: 11" fillcolor=lightgreen shape=rectangle style=filled]
	expert_11_linear2 [label="Expert 11 Linear 2\n[batch_size=32, tokens_per_expert, hidden=2048] -> [batch_size=32, tokens_per_expert, token_dim=7168]\nGPU: 11" fillcolor=lightblue shape=rectangle style=filled]
	expert_12_linear1 [label="Expert 12 Linear 1\n[batch_size=32, tokens_per_expert, token_dim=7168] -> [batch_size=32, tokens_per_expert, hidden=2048]\nGPU: 12" fillcolor=lightblue shape=rectangle style=filled]
	expert_12_gelu [label="Expert 12 GELU\n[batch_size=32, tokens_per_expert, hidden=2048] -> [batch_size=32, tokens_per_expert, hidden=2048]\nGPU: 12" fillcolor=lightgreen shape=rectangle style=filled]
	expert_12_linear2 [label="Expert 12 Linear 2\n[batch_size=32, tokens_per_expert, hidden=2048] -> [batch_size=32, tokens_per_expert, token_dim=7168]\nGPU: 12" fillcolor=lightblue shape=rectangle style=filled]
	expert_13_linear1 [label="Expert 13 Linear 1\n[batch_size=32, tokens_per_expert, token_dim=7168] -> [batch_size=32, tokens_per_expert, hidden=2048]\nGPU: 13" fillcolor=lightblue shape=rectangle style=filled]
	expert_13_gelu [label="Expert 13 GELU\n[batch_size=32, tokens_per_expert, hidden=2048] -> [batch_size=32, tokens_per_expert, hidden=2048]\nGPU: 13" fillcolor=lightgreen shape=rectangle style=filled]
	expert_13_linear2 [label="Expert 13 Linear 2\n[batch_size=32, tokens_per_expert, hidden=2048] -> [batch_size=32, tokens_per_expert, token_dim=7168]\nGPU: 13" fillcolor=lightblue shape=rectangle style=filled]
	expert_14_linear1 [label="Expert 14 Linear 1\n[batch_size=32, tokens_per_expert, token_dim=7168] -> [batch_size=32, tokens_per_expert, hidden=2048]\nGPU: 14" fillcolor=lightblue shape=rectangle style=filled]
	expert_14_gelu [label="Expert 14 GELU\n[batch_size=32, tokens_per_expert, hidden=2048] -> [batch_size=32, tokens_per_expert, hidden=2048]\nGPU: 14" fillcolor=lightgreen shape=rectangle style=filled]
	expert_14_linear2 [label="Expert 14 Linear 2\n[batch_size=32, tokens_per_expert, hidden=2048] -> [batch_size=32, tokens_per_expert, token_dim=7168]\nGPU: 14" fillcolor=lightblue shape=rectangle style=filled]
	expert_15_linear1 [label="Expert 15 Linear 1\n[batch_size=32, tokens_per_expert, token_dim=7168] -> [batch_size=32, tokens_per_expert, hidden=2048]\nGPU: 15" fillcolor=lightblue shape=rectangle style=filled]
	expert_15_gelu [label="Expert 15 GELU\n[batch_size=32, tokens_per_expert, hidden=2048] -> [batch_size=32, tokens_per_expert, hidden=2048]\nGPU: 15" fillcolor=lightgreen shape=rectangle style=filled]
	expert_15_linear2 [label="Expert 15 Linear 2\n[batch_size=32, tokens_per_expert, hidden=2048] -> [batch_size=32, tokens_per_expert, token_dim=7168]\nGPU: 15" fillcolor=lightblue shape=rectangle style=filled]
	expert_aggregate [label="Expert Aggregate\n[batch_size=32, tokens_per_expert, token_dim=7168] -> [batch_size=32, seq_len=2048, token_dim=7168]\nGPU: 0" fillcolor=yellow shape=parallelogram style=dashed]
	mha_output [label="MHA Output\n[batch_size=32, seq_len=2048, heads=128, d_k=128]\nGPU: 0" fillcolor=lightgreen shape=ellipse style=filled]
	mha_input -> gate
	gate -> token_split
	token_split -> expert_0_linear1 [label="send to GPU 0" style=dashed]
	expert_0_linear1 -> expert_0_gelu
	expert_0_gelu -> expert_0_linear2
	expert_0_linear2 -> expert_aggregate [label="recv from GPU 0" style=dashed]
	token_split -> expert_1_linear1 [label="send to GPU 1" style=dashed]
	expert_1_linear1 -> expert_1_gelu
	expert_1_gelu -> expert_1_linear2
	expert_1_linear2 -> expert_aggregate [label="recv from GPU 1" style=dashed]
	token_split -> expert_2_linear1 [label="send to GPU 2" style=dashed]
	expert_2_linear1 -> expert_2_gelu
	expert_2_gelu -> expert_2_linear2
	expert_2_linear2 -> expert_aggregate [label="recv from GPU 2" style=dashed]
	token_split -> expert_3_linear1 [label="send to GPU 3" style=dashed]
	expert_3_linear1 -> expert_3_gelu
	expert_3_gelu -> expert_3_linear2
	expert_3_linear2 -> expert_aggregate [label="recv from GPU 3" style=dashed]
	token_split -> expert_4_linear1 [label="send to GPU 4" style=dashed]
	expert_4_linear1 -> expert_4_gelu
	expert_4_gelu -> expert_4_linear2
	expert_4_linear2 -> expert_aggregate [label="recv from GPU 4" style=dashed]
	token_split -> expert_5_linear1 [label="send to GPU 5" style=dashed]
	expert_5_linear1 -> expert_5_gelu
	expert_5_gelu -> expert_5_linear2
	expert_5_linear2 -> expert_aggregate [label="recv from GPU 5" style=dashed]
	token_split -> expert_6_linear1 [label="send to GPU 6" style=dashed]
	expert_6_linear1 -> expert_6_gelu
	expert_6_gelu -> expert_6_linear2
	expert_6_linear2 -> expert_aggregate [label="recv from GPU 6" style=dashed]
	token_split -> expert_7_linear1 [label="send to GPU 7" style=dashed]
	expert_7_linear1 -> expert_7_gelu
	expert_7_gelu -> expert_7_linear2
	expert_7_linear2 -> expert_aggregate [label="recv from GPU 7" style=dashed]
	token_split -> expert_8_linear1 [label="send to GPU 8" style=dashed]
	expert_8_linear1 -> expert_8_gelu
	expert_8_gelu -> expert_8_linear2
	expert_8_linear2 -> expert_aggregate [label="recv from GPU 8" style=dashed]
	token_split -> expert_9_linear1 [label="send to GPU 9" style=dashed]
	expert_9_linear1 -> expert_9_gelu
	expert_9_gelu -> expert_9_linear2
	expert_9_linear2 -> expert_aggregate [label="recv from GPU 9" style=dashed]
	token_split -> expert_10_linear1 [label="send to GPU 10" style=dashed]
	expert_10_linear1 -> expert_10_gelu
	expert_10_gelu -> expert_10_linear2
	expert_10_linear2 -> expert_aggregate [label="recv from GPU 10" style=dashed]
	token_split -> expert_11_linear1 [label="send to GPU 11" style=dashed]
	expert_11_linear1 -> expert_11_gelu
	expert_11_gelu -> expert_11_linear2
	expert_11_linear2 -> expert_aggregate [label="recv from GPU 11" style=dashed]
	token_split -> expert_12_linear1 [label="send to GPU 12" style=dashed]
	expert_12_linear1 -> expert_12_gelu
	expert_12_gelu -> expert_12_linear2
	expert_12_linear2 -> expert_aggregate [label="recv from GPU 12" style=dashed]
	token_split -> expert_13_linear1 [label="send to GPU 13" style=dashed]
	expert_13_linear1 -> expert_13_gelu
	expert_13_gelu -> expert_13_linear2
	expert_13_linear2 -> expert_aggregate [label="recv from GPU 13" style=dashed]
	token_split -> expert_14_linear1 [label="send to GPU 14" style=dashed]
	expert_14_linear1 -> expert_14_gelu
	expert_14_gelu -> expert_14_linear2
	expert_14_linear2 -> expert_aggregate [label="recv from GPU 14" style=dashed]
	token_split -> expert_15_linear1 [label="send to GPU 15" style=dashed]
	expert_15_linear1 -> expert_15_gelu
	expert_15_gelu -> expert_15_linear2
	expert_15_linear2 -> expert_aggregate [label="recv from GPU 15" style=dashed]
	expert_aggregate -> mha_output
}
