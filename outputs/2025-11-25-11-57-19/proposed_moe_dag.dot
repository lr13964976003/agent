// Fixed Proposed MoE with EP=16, distributed experts
// Expert Parallelism (EP=16) with one expert per GPU
// Complete 16-layer model with proper connectivity

digraph proposed_moe_dag {
	rankdir=TB
	splines=ortho
	node [shape=rectangle, style=filled, fillcolor=lightblue]
	
	// Input
	input [label="Total Input\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: All", fillcolor=lightgreen, shape=ellipse]
	
	// Output
	output [label="Total Output\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: All", fillcolor=lightgreen, shape=ellipse]
	
	// Layer 0 (representative layer)
	layer_0_qkv [label="QKV Linear\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,heads=32,d_k=128]\nGPU: 0 (TP=16)"]
	layer_0_attn [label="MHA\nInput: [batch=128,seq=10000,heads=32,d_k=128]\nOutput: [batch=128,seq=10000,heads=32,d_k=128]\nGPU: 0 (TP=16)"]
	layer_0_proj [label="Projection\nInput: [batch=128,seq=10000,heads=32,d_k=128]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 0 (TP=16)"]
	layer_0_add_norm1 [label="Add+Norm\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 0 (TP=16)"]
	layer_0_gate [label="Gating\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,topk=2]\nGPU: 0", fillcolor=yellow, shape=parallelogram]
	layer_0_scatter [label="Token Scatter\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: All 16", fillcolor=lightgray, shape=ellipse]
	layer_0_gather [label="Token Gather\nInput: [tokens_per_expert,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: All 16", fillcolor=lightgray, shape=ellipse]
	layer_0_add_norm2 [label="Add+Norm\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 0 (TP=16)"]
	
	// Experts - one per GPU, 16 total
	layer_0_expert_0 [label="Expert 0\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 0"]
	layer_0_expert_1 [label="Expert 1\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 1"]
	layer_0_expert_2 [label="Expert 2\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 2"]
	layer_0_expert_3 [label="Expert 3\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 3"]
	layer_0_expert_4 [label="Expert 4\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 4"]
	layer_0_expert_5 [label="Expert 5\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 5"]
	layer_0_expert_6 [label="Expert 6\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 6"]
	layer_0_expert_7 [label="Expert 7\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 7"]
	layer_0_expert_8 [label="Expert 8\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 8"]
	layer_0_expert_9 [label="Expert 9\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 9"]
	layer_0_expert_10 [label="Expert 10\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 10"]
	layer_0_expert_11 [label="Expert 11\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 11"]
	layer_0_expert_12 [label="Expert 12\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 12"]
	layer_0_expert_13 [label="Expert 13\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 13"]
	layer_0_expert_14 [label="Expert 14\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 14"]
	layer_0_expert_15 [label="Expert 15\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 15"]
	
	// Layer 1
	layer_1_qkv [label="QKV Linear\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,heads=32,d_k=128]\nGPU: 16 (TP=16)"]
	layer_1_attn [label="MHA\nInput: [batch=128,seq=10000,heads=32,d_k=128]\nOutput: [batch=128,seq=10000,heads=32,d_k=128]\nGPU: 16 (TP=16)"]
	layer_1_proj [label="Projection\nInput: [batch=128,seq=10000,heads=32,d_k=128]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 16 (TP=16)"]
	layer_1_add_norm1 [label="Add+Norm\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 16 (TP=16)"]
	layer_1_gate [label="Gating\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,topk=2]\nGPU: 16", fillcolor=yellow, shape=parallelogram]
	layer_1_scatter [label="Token Scatter\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: All 16", fillcolor=lightgray, shape=ellipse]
	layer_1_gather [label="Token Gather\nInput: [tokens_per_expert,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: All 16", fillcolor=lightgray, shape=ellipse]
	layer_1_add_norm2 [label="Add+Norm\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 16 (TP=16)"]
	
	// Layer 1 experts
	layer_1_expert_0 [label="Expert 0\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 16"]
	layer_1_expert_1 [label="Expert 1\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 17"]
	layer_1_expert_2 [label="Expert 2\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 18"]
	layer_1_expert_3 [label="Expert 3\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 19"]
	layer_1_expert_4 [label="Expert 4\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 20"]
	layer_1_expert_5 [label="Expert 5\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 21"]
	layer_1_expert_6 [label="Expert 6\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 22"]
	layer_1_expert_7 [label="Expert 7\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 23"]
	layer_1_expert_8 [label="Expert 8\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 24"]
	layer_1_expert_9 [label="Expert 9\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 25"]
	layer_1_expert_10 [label="Expert 10\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 26"]
	layer_1_expert_11 [label="Expert 11\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 27"]
	layer_1_expert_12 [label="Expert 12\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 28"]
	layer_1_expert_13 [label="Expert 13\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 29"]
	layer_1_expert_14 [label="Expert 14\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 30"]
	layer_1_expert_15 [label="Expert 15\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 31"]
	
	// Layer 2
	layer_2_qkv [label="QKV Linear\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,heads=32,d_k=128]\nGPU: 32 (TP=16)"]
	layer_2_attn [label="MHA\nInput: [batch=128,seq=10000,heads=32,d_k=128]\nOutput: [batch=128,seq=10000,heads=32,d_k=128]\nGPU: 32 (TP=16)"]
	layer_2_proj [label="Projection\nInput: [batch=128,seq=10000,heads=32,d_k=128]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 32 (TP=16)"]
	layer_2_add_norm1 [label="Add+Norm\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 32 (TP=16)"]
	layer_2_gate [label="Gating\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,topk=2]\nGPU: 32", fillcolor=yellow, shape=parallelogram]
	layer_2_scatter [label="Token Scatter\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: All 16", fillcolor=lightgray, shape=ellipse]
	layer_2_gather [label="Token Gather\nInput: [tokens_per_expert,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: All 16", fillcolor=lightgray, shape=ellipse]
	layer_2_add_norm2 [label="Add+Norm\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 32 (TP=16)"]
	
	// Layer 2 experts
	layer_2_expert_0 [label="Expert 0\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 32"]
	layer_2_expert_1 [label="Expert 1\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 33"]
	layer_2_expert_2 [label="Expert 2\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 34"]
	layer_2_expert_3 [label="Expert 3\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 35"]
	layer_2_expert_4 [label="Expert 4\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 36"]
	layer_2_expert_5 [label="Expert 5\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 37"]
	layer_2_expert_6 [label="Expert 6\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 38"]
	layer_2_expert_7 [label="Expert 7\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 39"]
	layer_2_expert_8 [label="Expert 8\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 40"]
	layer_2_expert_9 [label="Expert 9\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 41"]
	layer_2_expert_10 [label="Expert 10\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 42"]
	layer_2_expert_11 [label="Expert 11\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 43"]
	layer_2_expert_12 [label="Expert 12\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 44"]
	layer_2_expert_13 [label="Expert 13\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 45"]
	layer_2_expert_14 [label="Expert 14\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 46"]
	layer_2_expert_15 [label="Expert 15\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 47"]
	
	// Layer 3
	layer_3_qkv [label="QKV Linear\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,heads=32,d_k=128]\nGPU: 48 (TP=16)"]
	layer_3_attn [label="MHA\nInput: [batch=128,seq=10000,heads=32,d_k=128]\nOutput: [batch=128,seq=10000,heads=32,d_k=128]\nGPU: 48 (TP=16)"]
	layer_3_proj [label="Projection\nInput: [batch=128,seq=10000,heads=32,d_k=128]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 48 (TP=16)"]
	layer_3_add_norm1 [label="Add+Norm\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 48 (TP=16)"]
	layer_3_gate [label="Gating\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,topk=2]\nGPU: 48", fillcolor=yellow, shape=parallelogram]
	layer_3_scatter [label="Token Scatter\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: All 16", fillcolor=lightgray, shape=ellipse]
	layer_3_gather [label="Token Gather\nInput: [tokens_per_expert,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: All 16", fillcolor=lightgray, shape=ellipse]
	layer_3_add_norm2 [label="Add+Norm\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 48 (TP=16)"]
	
	// Layer 3 experts
	layer_3_expert_0 [label="Expert 0\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 48"]
	layer_3_expert_1 [label="Expert 1\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 49"]
	layer_3_expert_2 [label="Expert 2\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 50"]
	layer_3_expert_3 [label="Expert 3\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 51"]
	layer_3_expert_4 [label="Expert 4\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 52"]
	layer_3_expert_5 [label="Expert 5\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 53"]
	layer_3_expert_6 [label="Expert 6\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 54"]
	layer_3_expert_7 [label="Expert 7\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 55"]
	layer_3_expert_8 [label="Expert 8\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 56"]
	layer_3_expert_9 [label="Expert 9\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 57"]
	layer_3_expert_10 [label="Expert 10\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 58"]
	layer_3_expert_11 [label="Expert 11\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 59"]
	layer_3_expert_12 [label="Expert 12\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 60"]
	layer_3_expert_13 [label="Expert 13\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 61"]
	layer_3_expert_14 [label="Expert 14\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 62"]
	layer_3_expert_15 [label="Expert 15\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 63"]
	
	// Layer 4
	layer_4_qkv [label="QKV Linear\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,heads=32,d_k=128]\nGPU: 64 (TP=16)"]
	layer_4_attn [label="MHA\nInput: [batch=128,seq=10000,heads=32,d_k=128]\nOutput: [batch=128,seq=10000,heads=32,d_k=128]\nGPU: 64 (TP=16)"]
	layer_4_proj [label="Projection\nInput: [batch=128,seq=10000,heads=32,d_k=128]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 64 (TP=16)"]
	layer_4_add_norm1 [label="Add+Norm\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 64 (TP=16)"]
	layer_4_gate [label="Gating\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,topk=2]\nGPU: 64", fillcolor=yellow, shape=parallelogram]
	layer_4_scatter [label="Token Scatter\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: All 16", fillcolor=lightgray, shape=ellipse]
	layer_4_gather [label="Token Gather\nInput: [tokens_per_expert,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: All 16", fillcolor=lightgray, shape=ellipse]
	layer_4_add_norm2 [label="Add+Norm\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 64 (TP=16)"]
	
	// Layer 4 experts
	layer_4_expert_0 [label="Expert 0\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 64"]
	layer_4_expert_1 [label="Expert 1\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 65"]
	layer_4_expert_2 [label="Expert 2\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 66"]
	layer_4_expert_3 [label="Expert 3\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 67"]
	layer_4_expert_4 [label="Expert 4\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 68"]
	layer_4_expert_5 [label="Expert 5\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 69"]
	layer_4_expert_6 [label="Expert 6\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 70"]
	layer_4_expert_7 [label="Expert 7\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 71"]
	layer_4_expert_8 [label="Expert 8\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 72"]
	layer_4_expert_9 [label="Expert 9\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 73"]
	layer_4_expert_10 [label="Expert 10\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 74"]
	layer_4_expert_11 [label="Expert 11\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 75"]
	layer_4_expert_12 [label="Expert 12\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 76"]
	layer_4_expert_13 [label="Expert 13\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 77"]
	layer_4_expert_14 [label="Expert 14\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 78"]
	layer_4_expert_15 [label="Expert 15\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 79"]
	
	// Layer 5
	layer_5_qkv [label="QKV Linear\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,heads=32,d_k=128]\nGPU: 80 (TP=16)"]
	layer_5_attn [label="MHA\nInput: [batch=128,seq=10000,heads=32,d_k=128]\nOutput: [batch=128,seq=10000,heads=32,d_k=128]\nGPU: 80 (TP=16)"]
	layer_5_proj [label="Projection\nInput: [batch=128,seq=10000,heads=32,d_k=128]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 80 (TP=16)"]
	layer_5_add_norm1 [label="Add+Norm\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 80 (TP=16)"]
	layer_5_gate [label="Gating\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,topk=2]\nGPU: 80", fillcolor=yellow, shape=parallelogram]
	layer_5_scatter [label="Token Scatter\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: All 16", fillcolor=lightgray, shape=ellipse]
	layer_5_gather [label="Token Gather\nInput: [tokens_per_expert,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: All 16", fillcolor=lightgray, shape=ellipse]
	layer_5_add_norm2 [label="Add+Norm\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 80 (TP=16)"]
	
	// Layer 5 experts
	layer_5_expert_0 [label="Expert 0\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 80"]
	layer_5_expert_1 [label="Expert 1\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 81"]
	layer_5_expert_2 [label="Expert 2\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 82"]
	layer_5_expert_3 [label="Expert 3\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 83"]
	layer_5_expert_4 [label="Expert 4\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 84"]
	layer_5_expert_5 [label="Expert 5\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 85"]
	layer_5_expert_6 [label="Expert 6\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 86"]
	layer_5_expert_7 [label="Expert 7\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 87"]
	layer_5_expert_8 [label="Expert 8\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 88"]
	layer_5_expert_9 [label="Expert 9\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 89"]
	layer_5_expert_10 [label="Expert 10\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 90"]
	layer_5_expert_11 [label="Expert 11\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 91"]
	layer_5_expert_12 [label="Expert 12\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 92"]
	layer_5_expert_13 [label="Expert 13\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 93"]
	layer_5_expert_14 [label="Expert 14\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 94"]
	layer_5_expert_15 [label="Expert 15\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 95"]
	
	// Layer 6
	layer_6_qkv [label="QKV Linear\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,heads=32,d_k=128]\nGPU: 96 (TP=16)"]
	layer_6_attn [label="MHA\nInput: [batch=128,seq=10000,heads=32,d_k=128]\nOutput: [batch=128,seq=10000,heads=32,d_k=128]\nGPU: 96 (TP=16)"]
	layer_6_proj [label="Projection\nInput: [batch=128,seq=10000,heads=32,d_k=128]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 96 (TP=16)"]
	layer_6_add_norm1 [label="Add+Norm\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 96 (TP=16)"]
	layer_6_gate [label="Gating\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,topk=2]\nGPU: 96", fillcolor=yellow, shape=parallelogram]
	layer_6_scatter [label="Token Scatter\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: All 16", fillcolor=lightgray, shape=ellipse]
	layer_6_gather [label="Token Gather\nInput: [tokens_per_expert,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: All 16", fillcolor=lightgray, shape=ellipse]
	layer_6_add_norm2 [label="Add+Norm\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 96 (TP=16)"]
	
	// Layer 6 experts
	layer_6_expert_0 [label="Expert 0\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 96"]
	layer_6_expert_1 [label="Expert 1\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 97"]
	layer_6_expert_2 [label="Expert 2\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 98"]
	layer_6_expert_3 [label="Expert 3\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 99"]
	layer_6_expert_4 [label="Expert 4\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 100"]
	layer_6_expert_5 [label="Expert 5\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 101"]
	layer_6_expert_6 [label="Expert 6\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 102"]
	layer_6_expert_7 [label="Expert 7\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 103"]
	layer_6_expert_8 [label="Expert 8\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 104"]
	layer_6_expert_9 [label="Expert 9\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 105"]
	layer_6_expert_10 [label="Expert 10\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 106"]
	layer_6_expert_11 [label="Expert 11\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 107"]
	layer_6_expert_12 [label="Expert 12\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 108"]
	layer_6_expert_13 [label="Expert 13\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 109"]
	layer_6_expert_14 [label="Expert 14\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 110"]
	layer_6_expert_15 [label="Expert 15\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 111"]
	
	// Layer 7
	layer_7_qkv [label="QKV Linear\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,heads=32,d_k=128]\nGPU: 112 (TP=16)"]
	layer_7_attn [label="MHA\nInput: [batch=128,seq=10000,heads=32,d_k=128]\nOutput: [batch=128,seq=10000,heads=32,d_k=128]\nGPU: 112 (TP=16)"]
	layer_7_proj [label="Projection\nInput: [batch=128,seq=10000,heads=32,d_k=128]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 112 (TP=16)"]
	layer_7_add_norm1 [label="Add+Norm\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 112 (TP=16)"]
	layer_7_gate [label="Gating\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,topk=2]\nGPU: 112", fillcolor=yellow, shape=parallelogram]
	layer_7_scatter [label="Token Scatter\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: All 16", fillcolor=lightgray, shape=ellipse]
	layer_7_gather [label="Token Gather\nInput: [tokens_per_expert,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: All 16", fillcolor=lightgray, shape=ellipse]
	layer_7_add_norm2 [label="Add+Norm\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 112 (TP=16)"]
	
	// Layer 7 experts
	layer_7_expert_0 [label="Expert 0\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 112"]
	layer_7_expert_1 [label="Expert 1\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 113"]
	layer_7_expert_2 [label="Expert 2\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 114"]
	layer_7_expert_3 [label="Expert 3\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 115"]
	layer_7_expert_4 [label="Expert 4\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 116"]
	layer_7_expert_5 [label="Expert 5\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 117"]
	layer_7_expert_6 [label="Expert 6\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 118"]
	layer_7_expert_7 [label="Expert 7\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 119"]
	layer_7_expert_8 [label="Expert 8\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 120"]
	layer_7_expert_9 [label="Expert 9\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 121"]
	layer_7_expert_10 [label="Expert 10\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 122"]
	layer_7_expert_11 [label="Expert 11\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 123"]
	layer_7_expert_12 [label="Expert 12\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 124"]
	layer_7_expert_13 [label="Expert 13\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 125"]
	layer_7_expert_14 [label="Expert 14\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 126"]
	layer_7_expert_15 [label="Expert 15\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 127"]
	
	// Layer 8
	layer_8_qkv [label="QKV Linear\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,heads=32,d_k=128]\nGPU: 128 (TP=16)"]
	layer_8_attn [label="MHA\nInput: [batch=128,seq=10000,heads=32,d_k=128]\nOutput: [batch=128,seq=10000,heads=32,d_k=128]\nGPU: 128 (TP=16)"]
	layer_8_proj [label="Projection\nInput: [batch=128,seq=10000,heads=32,d_k=128]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 128 (TP=16)"]
	layer_8_add_norm1 [label="Add+Norm\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 128 (TP=16)"]
	layer_8_gate [label="Gating\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,topk=2]\nGPU: 128", fillcolor=yellow, shape=parallelogram]
	layer_8_scatter [label="Token Scatter\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: All 16", fillcolor=lightgray, shape=ellipse]
	layer_8_gather [label="Token Gather\nInput: [tokens_per_expert,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: All 16", fillcolor=lightgray, shape=ellipse]
	layer_8_add_norm2 [label="Add+Norm\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 128 (TP=16)"]
	
	// Layer 8 experts
	layer_8_expert_0 [label="Expert 0\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 128"]
	layer_8_expert_1 [label="Expert 1\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 129"]
	layer_8_expert_2 [label="Expert 2\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 130"]
	layer_8_expert_3 [label="Expert 3\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 131"]
	layer_8_expert_4 [label="Expert 4\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 132"]
	layer_8_expert_5 [label="Expert 5\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 133"]
	layer_8_expert_6 [label="Expert 6\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 134"]
	layer_8_expert_7 [label="Expert 7\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 135"]
	layer_8_expert_8 [label="Expert 8\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 136"]
	layer_8_expert_9 [label="Expert 9\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 137"]
	layer_8_expert_10 [label="Expert 10\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 138"]
	layer_8_expert_11 [label="Expert 11\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 139"]
	layer_8_expert_12 [label="Expert 12\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 140"]
	layer_8_expert_13 [label="Expert 13\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 141"]
	layer_8_expert_14 [label="Expert 14\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 142"]
	layer_8_expert_15 [label="Expert 15\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 143"]
	
	// Layer 9
	layer_9_qkv [label="QKV Linear\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,heads=32,d_k=128]\nGPU: 144 (TP=16)"]
	layer_9_attn [label="MHA\nInput: [batch=128,seq=10000,heads=32,d_k=128]\nOutput: [batch=128,seq=10000,heads=32,d_k=128]\nGPU: 144 (TP=16)"]
	layer_9_proj [label="Projection\nInput: [batch=128,seq=10000,heads=32,d_k=128]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 144 (TP=16)"]
	layer_9_add_norm1 [label="Add+Norm\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 144 (TP=16)"]
	layer_9_gate [label="Gating\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,topk=2]\nGPU: 144", fillcolor=yellow, shape=parallelogram]
	layer_9_scatter [label="Token Scatter\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: All 16", fillcolor=lightgray, shape=ellipse]
	layer_9_gather [label="Token Gather\nInput: [tokens_per_expert,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: All 16", fillcolor=lightgray, shape=ellipse]
	layer_9_add_norm2 [label="Add+Norm\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 144 (TP=16)"]
	
	// Layer 9 experts
	layer_9_expert_0 [label="Expert 0\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 144"]
	layer_9_expert_1 [label="Expert 1\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 145"]
	layer_9_expert_2 [label="Expert 2\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 146"]
	layer_9_expert_3 [label="Expert 3\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 147"]
	layer_9_expert_4 [label="Expert 4\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 148"]
	layer_9_expert_5 [label="Expert 5\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 149"]
	layer_9_expert_6 [label="Expert 6\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 150"]
	layer_9_expert_7 [label="Expert 7\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 151"]
	layer_9_expert_8 [label="Expert 8\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 152"]
	layer_9_expert_9 [label="Expert 9\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 153"]
	layer_9_expert_10 [label="Expert 10\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 154"]
	layer_9_expert_11 [label="Expert 11\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 155"]
	layer_9_expert_12 [label="Expert 12\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 156"]
	layer_9_expert_13 [label="Expert 13\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 157"]
	layer_9_expert_14 [label="Expert 14\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 158"]
	layer_9_expert_15 [label="Expert 15\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 159"]
	
	// Layer 10
	layer_10_qkv [label="QKV Linear\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,heads=32,d_k=128]\nGPU: 160 (TP=16)"]
	layer_10_attn [label="MHA\nInput: [batch=128,seq=10000,heads=32,d_k=128]\nOutput: [batch=128,seq=10000,heads=32,d_k=128]\nGPU: 160 (TP=16)"]
	layer_10_proj [label="Projection\nInput: [batch=128,seq=10000,heads=32,d_k=128]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 160 (TP=16)"]
	layer_10_add_norm1 [label="Add+Norm\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 160 (TP=16)"]
	layer_10_gate [label="Gating\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,topk=2]\nGPU: 160", fillcolor=yellow, shape=parallelogram]
	layer_10_scatter [label="Token Scatter\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: All 16", fillcolor=lightgray, shape=ellipse]
	layer_10_gather [label="Token Gather\nInput: [tokens_per_expert,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: All 16", fillcolor=lightgray, shape=ellipse]
	layer_10_add_norm2 [label="Add+Norm\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 160 (TP=16)"]
	
	// Layer 10 experts
	layer_10_expert_0 [label="Expert 0\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 160"]
	layer_10_expert_1 [label="Expert 1\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 161"]
	layer_10_expert_2 [label="Expert 2\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 162"]
	layer_10_expert_3 [label="Expert 3\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 163"]
	layer_10_expert_4 [label="Expert 4\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 164"]
	layer_10_expert_5 [label="Expert 5\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 165"]
	layer_10_expert_6 [label="Expert 6\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 166"]
	layer_10_expert_7 [label="Expert 7\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 167"]
	layer_10_expert_8 [label="Expert 8\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 168"]
	layer_10_expert_9 [label="Expert 9\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 169"]
	layer_10_expert_10 [label="Expert 10\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 170"]
	layer_10_expert_11 [label="Expert 11\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 171"]
	layer_10_expert_12 [label="Expert 12\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 172"]
	layer_10_expert_13 [label="Expert 13\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 173"]
	layer_10_expert_14 [label="Expert 14\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 174"]
	layer_10_expert_15 [label="Expert 15\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 175"]
	
	// Layer 11
	layer_11_qkv [label="QKV Linear\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,heads=32,d_k=128]\nGPU: 176 (TP=16)"]
	layer_11_attn [label="MHA\nInput: [batch=128,seq=10000,heads=32,d_k=128]\nOutput: [batch=128,seq=10000,heads=32,d_k=128]\nGPU: 176 (TP=16)"]
	layer_11_proj [label="Projection\nInput: [batch=128,seq=10000,heads=32,d_k=128]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 176 (TP=16)"]
	layer_11_add_norm1 [label="Add+Norm\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 176 (TP=16)"]
	layer_11_gate [label="Gating\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,topk=2]\nGPU: 176", fillcolor=yellow, shape=parallelogram]
	layer_11_scatter [label="Token Scatter\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: All 16", fillcolor=lightgray, shape=ellipse]
	layer_11_gather [label="Token Gather\nInput: [tokens_per_expert,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: All 16", fillcolor=lightgray, shape=ellipse]
	layer_11_add_norm2 [label="Add+Norm\nInput: [batch=128,seq=10000,hidden=4096]\nOutput: [batch=128,seq=10000,hidden=4096]\nGPU: 176 (TP=16)"]
	
	// Layer 11 experts
	layer_11_expert_0 [label="Expert 0\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 176"]
	layer_11_expert_1 [label="Expert 1\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 177"]
	layer_11_expert_2 [label="Expert 2\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 178"]
	layer_11_expert_3 [label="Expert 3\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 179"]
	layer_11_expert_4 [label="Expert 4\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 180"]
	layer_11_expert_5 [label="Expert 5\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 181"]
	layer_11_expert_6 [label="Expert 6\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 182"]
	layer_11_expert_7 [label="Expert 7\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 183"]
	layer_11_expert_8 [label="Expert 8\nInput: [tokens_per_expert,hidden=4096]\nOutput: [tokens_per_expert,hidden=4096]\nGPU: 184"]
	layer_11_expert_9 [label="Expert 9\nInput: [tokens_per_expert,