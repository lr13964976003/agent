digraph fa_pool_model_dag {
	graph [bb="0,0,3.0837e+05,779",
		rankdir=TB,
		size="40,50",
		splines=ortho
	];
	node [fillcolor=lightcoral,
		fontname=Arial,
		fontsize=10,
		label="\N",
		shape=hexagon,
		style=filled
	];
	subgraph cluster_base_layer {
		graph [bb="9070,281,14396,490",
			color=blue,
			fontsize=14,
			label="Base Layer (8 GPUs - Static)",
			lheight=0.21,
			lp="11733,478.5",
			lwidth=2.83,
			style=rounded
		];
		subgraph cluster_base_embedding {
			graph [bb="9078,386,14388,459",
				fontsize=12,
				label="Token Embedding",
				lheight=0.18,
				lp="11733,448.5",
				lwidth=1.51,
				style=rounded
			];
			base_embed_0	[fillcolor=lightgreen,
				height=0.5,
				label="<b>Token Embedding</b><br/>GPU: base_gpu_0<br/>Input: [batch=1024, seq=?, vocab=32000]<br/>Output: [batch=1024, seq=?, hidden=512]",
				pos="14057,412",
				shape=rectangle,
				width=8.9722];
			base_embed_1	[fillcolor=lightgreen,
				height=0.5,
				label="<b>Token Embedding</b><br/>GPU: base_gpu_1<br/>Input: [batch=1024, seq=?, vocab=32000]<br/>Output: [batch=1024, seq=?, hidden=512]",
				pos="13393,412",
				shape=rectangle,
				width=8.9722];
			base_embed_2	[fillcolor=lightgreen,
				height=0.5,
				label="<b>Token Embedding</b><br/>GPU: base_gpu_2<br/>Input: [batch=1024, seq=?, vocab=32000]<br/>Output: [batch=1024, seq=?, hidden=512]",
				pos="12729,412",
				shape=rectangle,
				width=8.9722];
			base_embed_3	[fillcolor=lightgreen,
				height=0.5,
				label="<b>Token Embedding</b><br/>GPU: base_gpu_3<br/>Input: [batch=1024, seq=?, vocab=32000]<br/>Output: [batch=1024, seq=?, hidden=512]",
				pos="11401,412",
				shape=rectangle,
				width=8.9722];
			base_embed_4	[fillcolor=lightgreen,
				height=0.5,
				label="<b>Token Embedding</b><br/>GPU: base_gpu_4<br/>Input: [batch=1024, seq=?, vocab=32000]<br/>Output: [batch=1024, seq=?, hidden=512]",
				pos="12065,412",
				shape=rectangle,
				width=8.9722];
			base_embed_5	[fillcolor=lightgreen,
				height=0.5,
				label="<b>Token Embedding</b><br/>GPU: base_gpu_5<br/>Input: [batch=1024, seq=?, vocab=32000]<br/>Output: [batch=1024, seq=?, hidden=512]",
				pos="10737,412",
				shape=rectangle,
				width=8.9722];
			base_embed_6	[fillcolor=lightgreen,
				height=0.5,
				label="<b>Token Embedding</b><br/>GPU: base_gpu_6<br/>Input: [batch=1024, seq=?, vocab=32000]<br/>Output: [batch=1024, seq=?, hidden=512]",
				pos="10073,412",
				shape=rectangle,
				width=8.9722];
			base_embed_7	[fillcolor=lightgreen,
				height=0.5,
				label="<b>Token Embedding</b><br/>GPU: base_gpu_7<br/>Input: [batch=1024, seq=?, vocab=32000]<br/>Output: [batch=1024, seq=?, hidden=512]",
				pos="9409,412",
				shape=rectangle,
				width=8.9722];
		}
		subgraph cluster_base_pos {
			graph [bb="9078,289,14388,362",
				fontsize=12,
				label="Positional Encoding",
				lheight=0.18,
				lp="11733,351.5",
				lwidth=1.68,
				style=rounded
			];
			base_pos_0	[fillcolor=lightgreen,
				height=0.5,
				label="<b>Positional Encoding</b><br/>GPU: base_gpu_0<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
				pos="14057,315",
				shape=rectangle,
				width=8.9722];
			base_pos_1	[fillcolor=lightgreen,
				height=0.5,
				label="<b>Positional Encoding</b><br/>GPU: base_gpu_1<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
				pos="13393,315",
				shape=rectangle,
				width=8.9722];
			base_pos_2	[fillcolor=lightgreen,
				height=0.5,
				label="<b>Positional Encoding</b><br/>GPU: base_gpu_2<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
				pos="12729,315",
				shape=rectangle,
				width=8.9722];
			base_pos_3	[fillcolor=lightgreen,
				height=0.5,
				label="<b>Positional Encoding</b><br/>GPU: base_gpu_3<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
				pos="11401,315",
				shape=rectangle,
				width=8.9722];
			base_pos_4	[fillcolor=lightgreen,
				height=0.5,
				label="<b>Positional Encoding</b><br/>GPU: base_gpu_4<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
				pos="12065,315",
				shape=rectangle,
				width=8.9722];
			base_pos_5	[fillcolor=lightgreen,
				height=0.5,
				label="<b>Positional Encoding</b><br/>GPU: base_gpu_5<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
				pos="10073,315",
				shape=rectangle,
				width=8.9722];
			base_pos_6	[fillcolor=lightgreen,
				height=0.5,
				label="<b>Positional Encoding</b><br/>GPU: base_gpu_6<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
				pos="9409,315",
				shape=rectangle,
				width=8.9722];
			base_pos_7	[fillcolor=lightgreen,
				height=0.5,
				label="<b>Positional Encoding</b><br/>GPU: base_gpu_7<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
				pos="10737,315",
				shape=rectangle,
				width=8.9722];
		}
		base_embed_0 -> base_pos_0	[pos="e,13949,333.16 13949,393.76 13949,393.76 13949,343.16 13949,343.16"];
		base_embed_1 -> base_pos_1	[pos="e,13285,333.16 13285,393.76 13285,393.76 13285,343.16 13285,343.16"];
		base_embed_2 -> base_pos_2	[pos="e,12729,333.16 12729,393.76 12729,393.76 12729,343.16 12729,343.16"];
		base_embed_3 -> base_pos_3	[pos="e,11401,333.16 11401,393.76 11401,393.76 11401,343.16 11401,343.16"];
		base_embed_4 -> base_pos_4	[pos="e,12065,333.16 12065,393.76 12065,393.76 12065,343.16 12065,343.16"];
		base_embed_5 -> base_pos_5	[pos="e,10396,315 10414,412 10408,412 10405,412 10405,412 10405,412 10405,315 10405,315 10405,315 10404,315 10404,315"];
		base_embed_6 -> base_pos_6	[pos="e,9732.1,315 9749.9,412 9744.2,412 9741,412 9741,412 9741,412 9741,315 9741,315 9741,315 9740.1,315 9740.1,315"];
		base_embed_7 -> base_pos_7	[pos="e,10737,333.18 9409,393.91 9409,370.87 9409,334 9409,334 9409,334 10737,334 10737,334 10737,334 10737,333.92 10737,333.92"];
	}
	subgraph cluster_attention_pool {
		graph [bb="24526,370,2.8923e+05,633",
			color=red,
			fontsize=14,
			label="Dynamic Attention Pool (0-32 GPUs)",
			lheight=0.21,
			lp="1.5688e+05,621.5",
			lwidth=3.60,
			style=rounded
		];
		subgraph cluster_pool_0 {
			graph [bb="2.2794e+05,498,2.8922e+05,602",
				fontsize=10,
				label="Use base GPUs for <4096 tokens",
				lheight=0.15,
				lp="2.5858e+05,592.5",
				lwidth=2.33,
				style=dashed
			];
			subgraph cluster_layer0_0 {
				graph [bb="2.739e+05,506,2.8921e+05,575",
					fontsize=8,
					label="Layer 0 Attention",
					lheight=0.12,
					lp="2.8156e+05,566.5",
					lwidth=0.97
				];
				attn_block_0_0_0	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: base_gpu_0<br/>Block: 1/8<br/>Input: [batch=1024, block_seq=ceil(seq/0), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/0), hidden=4096]",
					pos="2.8878e+05,532",
					shape=rectangle,
					width=11.681];
				kv_cache_0_0_0	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: base_gpu_0<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.8783e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.409];
				attn_block_0_1_0	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: base_gpu_1<br/>Block: 2/8<br/>Input: [batch=1024, block_seq=ceil(seq/0), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/0), hidden=4096]",
					pos="2.8687e+05,532",
					shape=rectangle,
					width=11.681];
				kv_cache_0_1_0	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: base_gpu_1<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.8591e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.409];
				attn_block_0_2_0	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: base_gpu_2<br/>Block: 3/8<br/>Input: [batch=1024, block_seq=ceil(seq/0), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/0), hidden=4096]",
					pos="2.8496e+05,532",
					shape=rectangle,
					width=11.681];
				kv_cache_0_2_0	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: base_gpu_2<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.84e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.409];
				attn_block_0_3_0	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: base_gpu_3<br/>Block: 4/8<br/>Input: [batch=1024, block_seq=ceil(seq/0), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/0), hidden=4096]",
					pos="2.8304e+05,532",
					shape=rectangle,
					width=11.681];
				kv_cache_0_3_0	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: base_gpu_3<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.8209e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.409];
				attn_block_0_4_0	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: base_gpu_4<br/>Block: 5/8<br/>Input: [batch=1024, block_seq=ceil(seq/0), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/0), hidden=4096]",
					pos="2.8113e+05,532",
					shape=rectangle,
					width=11.681];
				kv_cache_0_4_0	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: base_gpu_4<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.8017e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.409];
				attn_block_0_5_0	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: base_gpu_5<br/>Block: 6/8<br/>Input: [batch=1024, block_seq=ceil(seq/0), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/0), hidden=4096]",
					pos="2.7922e+05,532",
					shape=rectangle,
					width=11.681];
				kv_cache_0_5_0	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: base_gpu_5<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.7826e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.409];
				attn_block_0_6_0	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: base_gpu_6<br/>Block: 7/8<br/>Input: [batch=1024, block_seq=ceil(seq/0), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/0), hidden=4096]",
					pos="2.773e+05,532",
					shape=rectangle,
					width=11.681];
				kv_cache_0_6_0	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: base_gpu_6<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.7634e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.409];
				attn_block_0_7_0	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: base_gpu_7<br/>Block: 8/8<br/>Input: [batch=1024, block_seq=ceil(seq/0), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/0), hidden=4096]",
					pos="2.7539e+05,532",
					shape=rectangle,
					width=11.681];
				kv_cache_0_7_0	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: base_gpu_7<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.7443e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.409];
			}
			subgraph cluster_layer1_0 {
				graph [bb="2.5858e+05,506,2.739e+05,575",
					fontsize=8,
					label="Layer 1 Attention",
					lheight=0.12,
					lp="2.6624e+05,566.5",
					lwidth=0.97
				];
				attn_block_1_0_0	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: base_gpu_0<br/>Block: 1/8<br/>Input: [batch=1024, block_seq=ceil(seq/0), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/0), hidden=4096]",
					pos="2.7347e+05,532",
					shape=rectangle,
					width=11.681];
				kv_cache_1_0_0	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: base_gpu_0<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.7251e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.409];
				attn_block_1_1_0	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: base_gpu_1<br/>Block: 2/8<br/>Input: [batch=1024, block_seq=ceil(seq/0), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/0), hidden=4096]",
					pos="2.7155e+05,532",
					shape=rectangle,
					width=11.681];
				kv_cache_1_1_0	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: base_gpu_1<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.706e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.409];
				attn_block_1_2_0	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: base_gpu_2<br/>Block: 3/8<br/>Input: [batch=1024, block_seq=ceil(seq/0), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/0), hidden=4096]",
					pos="2.6964e+05,532",
					shape=rectangle,
					width=11.681];
				kv_cache_1_2_0	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: base_gpu_2<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.6868e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.409];
				attn_block_1_3_0	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: base_gpu_3<br/>Block: 4/8<br/>Input: [batch=1024, block_seq=ceil(seq/0), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/0), hidden=4096]",
					pos="2.6772e+05,532",
					shape=rectangle,
					width=11.681];
				kv_cache_1_3_0	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: base_gpu_3<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.6677e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.409];
				attn_block_1_4_0	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: base_gpu_4<br/>Block: 5/8<br/>Input: [batch=1024, block_seq=ceil(seq/0), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/0), hidden=4096]",
					pos="2.6581e+05,532",
					shape=rectangle,
					width=11.681];
				kv_cache_1_4_0	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: base_gpu_4<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.6485e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.409];
				attn_block_1_5_0	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: base_gpu_5<br/>Block: 6/8<br/>Input: [batch=1024, block_seq=ceil(seq/0), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/0), hidden=4096]",
					pos="2.639e+05,532",
					shape=rectangle,
					width=11.681];
				kv_cache_1_5_0	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: base_gpu_5<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.6294e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.409];
				attn_block_1_6_0	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: base_gpu_6<br/>Block: 7/8<br/>Input: [batch=1024, block_seq=ceil(seq/0), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/0), hidden=4096]",
					pos="2.6198e+05,532",
					shape=rectangle,
					width=11.681];
				kv_cache_1_6_0	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: base_gpu_6<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.6102e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.409];
				attn_block_1_7_0	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: base_gpu_7<br/>Block: 8/8<br/>Input: [batch=1024, block_seq=ceil(seq/0), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/0), hidden=4096]",
					pos="2.6007e+05,532",
					shape=rectangle,
					width=11.681];
				kv_cache_1_7_0	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: base_gpu_7<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.5911e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.409];
			}
			subgraph cluster_layer2_0 {
				graph [bb="2.4326e+05,506,2.5858e+05,575",
					fontsize=8,
					label="Layer 2 Attention",
					lheight=0.12,
					lp="2.5092e+05,566.5",
					lwidth=0.97
				];
				attn_block_2_0_0	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: base_gpu_0<br/>Block: 1/8<br/>Input: [batch=1024, block_seq=ceil(seq/0), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/0), hidden=4096]",
					pos="2.5815e+05,532",
					shape=rectangle,
					width=11.681];
				kv_cache_2_0_0	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: base_gpu_0<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.5719e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.409];
				attn_block_2_1_0	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: base_gpu_1<br/>Block: 2/8<br/>Input: [batch=1024, block_seq=ceil(seq/0), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/0), hidden=4096]",
					pos="2.5623e+05,532",
					shape=rectangle,
					width=11.681];
				kv_cache_2_1_0	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: base_gpu_1<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.5528e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.409];
				attn_block_2_2_0	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: base_gpu_2<br/>Block: 3/8<br/>Input: [batch=1024, block_seq=ceil(seq/0), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/0), hidden=4096]",
					pos="2.5432e+05,532",
					shape=rectangle,
					width=11.681];
				kv_cache_2_2_0	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: base_gpu_2<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.5336e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.409];
				attn_block_2_3_0	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: base_gpu_3<br/>Block: 4/8<br/>Input: [batch=1024, block_seq=ceil(seq/0), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/0), hidden=4096]",
					pos="2.524e+05,532",
					shape=rectangle,
					width=11.681];
				kv_cache_2_3_0	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: base_gpu_3<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.5145e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.409];
				attn_block_2_4_0	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: base_gpu_4<br/>Block: 5/8<br/>Input: [batch=1024, block_seq=ceil(seq/0), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/0), hidden=4096]",
					pos="2.5049e+05,532",
					shape=rectangle,
					width=11.681];
				kv_cache_2_4_0	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: base_gpu_4<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.4953e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.409];
				attn_block_2_5_0	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: base_gpu_5<br/>Block: 6/8<br/>Input: [batch=1024, block_seq=ceil(seq/0), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/0), hidden=4096]",
					pos="2.4858e+05,532",
					shape=rectangle,
					width=11.681];
				kv_cache_2_5_0	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: base_gpu_5<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.4762e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.409];
				attn_block_2_6_0	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: base_gpu_6<br/>Block: 7/8<br/>Input: [batch=1024, block_seq=ceil(seq/0), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/0), hidden=4096]",
					pos="2.4666e+05,532",
					shape=rectangle,
					width=11.681];
				kv_cache_2_6_0	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: base_gpu_6<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.4571e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.409];
				attn_block_2_7_0	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: base_gpu_7<br/>Block: 8/8<br/>Input: [batch=1024, block_seq=ceil(seq/0), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/0), hidden=4096]",
					pos="2.4475e+05,532",
					shape=rectangle,
					width=11.681];
				kv_cache_2_7_0	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: base_gpu_7<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.4379e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.409];
			}
			subgraph cluster_layer3_0 {
				graph [bb="2.2795e+05,506,2.4326e+05,575",
					fontsize=8,
					label="Layer 3 Attention",
					lheight=0.12,
					lp="2.356e+05,566.5",
					lwidth=0.97
				];
				attn_block_3_0_0	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: base_gpu_0<br/>Block: 1/8<br/>Input: [batch=1024, block_seq=ceil(seq/0), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/0), hidden=4096]",
					pos="2.4283e+05,532",
					shape=rectangle,
					width=11.681];
				kv_cache_3_0_0	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: base_gpu_0<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.4187e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.409];
				attn_block_3_1_0	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: base_gpu_1<br/>Block: 2/8<br/>Input: [batch=1024, block_seq=ceil(seq/0), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/0), hidden=4096]",
					pos="2.4091e+05,532",
					shape=rectangle,
					width=11.681];
				kv_cache_3_1_0	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: base_gpu_1<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.3996e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.409];
				attn_block_3_2_0	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: base_gpu_2<br/>Block: 3/8<br/>Input: [batch=1024, block_seq=ceil(seq/0), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/0), hidden=4096]",
					pos="2.39e+05,532",
					shape=rectangle,
					width=11.681];
				kv_cache_3_2_0	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: base_gpu_2<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.3804e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.409];
				attn_block_3_3_0	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: base_gpu_3<br/>Block: 4/8<br/>Input: [batch=1024, block_seq=ceil(seq/0), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/0), hidden=4096]",
					pos="2.3709e+05,532",
					shape=rectangle,
					width=11.681];
				kv_cache_3_3_0	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: base_gpu_3<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.3613e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.409];
				attn_block_3_4_0	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: base_gpu_4<br/>Block: 5/8<br/>Input: [batch=1024, block_seq=ceil(seq/0), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/0), hidden=4096]",
					pos="2.3517e+05,532",
					shape=rectangle,
					width=11.681];
				kv_cache_3_4_0	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: base_gpu_4<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.3422e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.409];
				attn_block_3_5_0	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: base_gpu_5<br/>Block: 6/8<br/>Input: [batch=1024, block_seq=ceil(seq/0), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/0), hidden=4096]",
					pos="2.3326e+05,532",
					shape=rectangle,
					width=11.681];
				kv_cache_3_5_0	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: base_gpu_5<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.323e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.409];
				attn_block_3_6_0	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: base_gpu_6<br/>Block: 7/8<br/>Input: [batch=1024, block_seq=ceil(seq/0), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/0), hidden=4096]",
					pos="2.3134e+05,532",
					shape=rectangle,
					width=11.681];
				kv_cache_3_6_0	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: base_gpu_6<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.3039e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.409];
				attn_block_3_7_0	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: base_gpu_7<br/>Block: 8/8<br/>Input: [batch=1024, block_seq=ceil(seq/0), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/0), hidden=4096]",
					pos="2.2943e+05,532",
					shape=rectangle,
					width=11.681];
				kv_cache_3_7_0	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: base_gpu_7<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.2847e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.409];
			}
		}
		subgraph cluster_pool_8 {
			graph [bb="92954,378,1.2659e+05,602",
				fontsize=10,
				label="8 pool GPUs for 4096-8192 tokens",
				lheight=0.15,
				lp="1.0977e+05,592.5",
				lwidth=2.39,
				style=dashed
			];
			subgraph cluster_layer0_8 {
				graph [bb="92962,386,1.0136e+05,575",
					fontsize=8,
					label="Layer 0 Attention",
					lheight=0.12,
					lp="97161,566.5",
					lwidth=0.97
				];
				attn_block_0_0_8	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_0<br/>Block: 1/8<br/>Input: [batch=1024, block_seq=ceil(seq/8), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/8), hidden=4096]",
					pos="94414,412",
					shape=rectangle,
					width=11.639];
				kv_cache_0_0_8	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_0<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="94536,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_0_0_8 -> attn_block_0_0_8	[pos="e,94426,430 94426,513.77 94426,513.77 94426,440 94426,440"];
				attn_block_0_1_8	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_1<br/>Block: 2/8<br/>Input: [batch=1024, block_seq=ceil(seq/8), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/8), hidden=4096]",
					pos="93437,412",
					shape=rectangle,
					width=11.639];
				kv_cache_0_1_8	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_1<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="93486,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_0_1_8 -> attn_block_0_1_8	[pos="e,93437,430 93437,513.77 93437,513.77 93437,440 93437,440"];
				attn_block_0_2_8	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_2<br/>Block: 3/8<br/>Input: [batch=1024, block_seq=ceil(seq/8), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/8), hidden=4096]",
					pos="1.0064e+05,412",
					shape=rectangle,
					width=11.639];
				kv_cache_0_2_8	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_2<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.0084e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_0_2_8 -> attn_block_0_2_8	[pos="e,1.0069e+05,430 1.0069e+05,513.77 1.0069e+05,513.77 1.0069e+05,440 1.0069e+05,440"];
				attn_block_0_3_8	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_3<br/>Block: 4/8<br/>Input: [batch=1024, block_seq=ceil(seq/8), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/8), hidden=4096]",
					pos="99594,412",
					shape=rectangle,
					width=11.639];
				kv_cache_0_3_8	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_3<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="99786,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_0_3_8 -> attn_block_0_3_8	[pos="e,99641,430 99641,513.77 99641,513.77 99641,440 99641,440"];
				attn_block_0_4_8	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_4<br/>Block: 5/8<br/>Input: [batch=1024, block_seq=ceil(seq/8), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/8), hidden=4096]",
					pos="98546,412",
					shape=rectangle,
					width=11.639];
				kv_cache_0_4_8	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_4<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="98736,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_0_4_8 -> attn_block_0_4_8	[pos="e,98592,430 98592,513.77 98592,513.77 98592,440 98592,440"];
				attn_block_0_5_8	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_5<br/>Block: 6/8<br/>Input: [batch=1024, block_seq=ceil(seq/8), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/8), hidden=4096]",
					pos="97501,412",
					shape=rectangle,
					width=11.639];
				kv_cache_0_5_8	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_5<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="97686,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_0_5_8 -> attn_block_0_5_8	[pos="e,97545,430 97545,513.77 97545,513.77 97545,440 97545,440"];
				attn_block_0_6_8	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_6<br/>Block: 7/8<br/>Input: [batch=1024, block_seq=ceil(seq/8), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/8), hidden=4096]",
					pos="96460,412",
					shape=rectangle,
					width=11.639];
				kv_cache_0_6_8	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_6<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="96636,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_0_6_8 -> attn_block_0_6_8	[pos="e,96499,430 96499,513.77 96499,513.77 96499,440 96499,440"];
				attn_block_0_7_8	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_7<br/>Block: 8/8<br/>Input: [batch=1024, block_seq=ceil(seq/8), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/8), hidden=4096]",
					pos="95428,412",
					shape=rectangle,
					width=11.639];
				kv_cache_0_7_8	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_7<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="95586,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_0_7_8 -> attn_block_0_7_8	[pos="e,95458,430 95458,513.77 95458,513.77 95458,440 95458,440"];
			}
			subgraph cluster_layer1_8 {
				graph [bb="1.0137e+05,386,1.0977e+05,575",
					fontsize=8,
					label="Layer 1 Attention",
					lheight=0.12,
					lp="1.0557e+05,566.5",
					lwidth=0.97
				];
				attn_block_1_0_8	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_0<br/>Block: 1/8<br/>Input: [batch=1024, block_seq=ceil(seq/8), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/8), hidden=4096]",
					pos="1.0282e+05,412",
					shape=rectangle,
					width=11.639];
				kv_cache_1_0_8	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_0<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.0294e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_1_0_8 -> attn_block_1_0_8	[pos="e,1.0283e+05,430 1.0283e+05,513.77 1.0283e+05,513.77 1.0283e+05,440 1.0283e+05,440"];
				attn_block_1_1_8	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_1<br/>Block: 2/8<br/>Input: [batch=1024, block_seq=ceil(seq/8), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/8), hidden=4096]",
					pos="1.0184e+05,412",
					shape=rectangle,
					width=11.639];
				kv_cache_1_1_8	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_1<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.0189e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_1_1_8 -> attn_block_1_1_8	[pos="e,1.0184e+05,430 1.0184e+05,513.77 1.0184e+05,513.77 1.0184e+05,440 1.0184e+05,440"];
				attn_block_1_2_8	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_2<br/>Block: 3/8<br/>Input: [batch=1024, block_seq=ceil(seq/8), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/8), hidden=4096]",
					pos="1.0905e+05,412",
					shape=rectangle,
					width=11.639];
				kv_cache_1_2_8	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_2<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.0924e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_1_2_8 -> attn_block_1_2_8	[pos="e,1.091e+05,430 1.091e+05,513.77 1.091e+05,513.77 1.091e+05,440 1.091e+05,440"];
				attn_block_1_3_8	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_3<br/>Block: 4/8<br/>Input: [batch=1024, block_seq=ceil(seq/8), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/8), hidden=4096]",
					pos="1.08e+05,412",
					shape=rectangle,
					width=11.639];
				kv_cache_1_3_8	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_3<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.0819e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_1_3_8 -> attn_block_1_3_8	[pos="e,1.0805e+05,430 1.0805e+05,513.77 1.0805e+05,513.77 1.0805e+05,440 1.0805e+05,440"];
				attn_block_1_4_8	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_4<br/>Block: 5/8<br/>Input: [batch=1024, block_seq=ceil(seq/8), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/8), hidden=4096]",
					pos="1.0695e+05,412",
					shape=rectangle,
					width=11.639];
				kv_cache_1_4_8	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_4<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.0714e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_1_4_8 -> attn_block_1_4_8	[pos="e,1.07e+05,430 1.07e+05,513.77 1.07e+05,513.77 1.07e+05,440 1.07e+05,440"];
				attn_block_1_5_8	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_5<br/>Block: 6/8<br/>Input: [batch=1024, block_seq=ceil(seq/8), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/8), hidden=4096]",
					pos="1.0591e+05,412",
					shape=rectangle,
					width=11.639];
				kv_cache_1_5_8	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_5<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.0609e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_1_5_8 -> attn_block_1_5_8	[pos="e,1.0595e+05,430 1.0595e+05,513.77 1.0595e+05,513.77 1.0595e+05,440 1.0595e+05,440"];
				attn_block_1_6_8	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_6<br/>Block: 7/8<br/>Input: [batch=1024, block_seq=ceil(seq/8), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/8), hidden=4096]",
					pos="1.0487e+05,412",
					shape=rectangle,
					width=11.639];
				kv_cache_1_6_8	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_6<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.0504e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_1_6_8 -> attn_block_1_6_8	[pos="e,1.0491e+05,430 1.0491e+05,513.77 1.0491e+05,513.77 1.0491e+05,440 1.0491e+05,440"];
				attn_block_1_7_8	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_7<br/>Block: 8/8<br/>Input: [batch=1024, block_seq=ceil(seq/8), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/8), hidden=4096]",
					pos="1.0383e+05,412",
					shape=rectangle,
					width=11.639];
				kv_cache_1_7_8	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_7<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.0399e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_1_7_8 -> attn_block_1_7_8	[pos="e,1.0386e+05,430 1.0386e+05,513.77 1.0386e+05,513.77 1.0386e+05,440 1.0386e+05,440"];
			}
			subgraph cluster_layer2_8 {
				graph [bb="1.0977e+05,386,1.1817e+05,575",
					fontsize=8,
					label="Layer 2 Attention",
					lheight=0.12,
					lp="1.1397e+05,566.5",
					lwidth=0.97
				];
				attn_block_2_0_8	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_0<br/>Block: 1/8<br/>Input: [batch=1024, block_seq=ceil(seq/8), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/8), hidden=4096]",
					pos="1.1144e+05,412",
					shape=rectangle,
					width=11.639];
				kv_cache_2_0_8	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_0<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.1135e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_2_0_8 -> attn_block_2_0_8	[pos="e,1.1144e+05,430 1.1144e+05,513.77 1.1144e+05,513.77 1.1144e+05,440 1.1144e+05,440"];
				attn_block_2_1_8	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_1<br/>Block: 2/8<br/>Input: [batch=1024, block_seq=ceil(seq/8), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/8), hidden=4096]",
					pos="1.1044e+05,412",
					shape=rectangle,
					width=11.639];
				kv_cache_2_1_8	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_1<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.103e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_2_1_8 -> attn_block_2_1_8	[pos="e,1.1042e+05,430 1.1042e+05,513.77 1.1042e+05,513.77 1.1042e+05,440 1.1042e+05,440"];
				attn_block_2_2_8	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_2<br/>Block: 3/8<br/>Input: [batch=1024, block_seq=ceil(seq/8), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/8), hidden=4096]",
					pos="1.177e+05,412",
					shape=rectangle,
					width=11.639];
				kv_cache_2_2_8	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_2<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.1765e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_2_2_8 -> attn_block_2_2_8	[pos="e,1.177e+05,430 1.177e+05,513.77 1.177e+05,513.77 1.177e+05,440 1.177e+05,440"];
				attn_block_2_3_8	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_3<br/>Block: 4/8<br/>Input: [batch=1024, block_seq=ceil(seq/8), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/8), hidden=4096]",
					pos="1.1672e+05,412",
					shape=rectangle,
					width=11.639];
				kv_cache_2_3_8	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_3<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.166e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_2_3_8 -> attn_block_2_3_8	[pos="e,1.1671e+05,430 1.1671e+05,513.77 1.1671e+05,513.77 1.1671e+05,440 1.1671e+05,440"];
				attn_block_2_4_8	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_4<br/>Block: 5/8<br/>Input: [batch=1024, block_seq=ceil(seq/8), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/8), hidden=4096]",
					pos="1.1577e+05,412",
					shape=rectangle,
					width=11.639];
				kv_cache_2_4_8	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_4<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.1555e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_2_4_8 -> attn_block_2_4_8	[pos="e,1.1571e+05,430 1.1571e+05,513.77 1.1571e+05,513.77 1.1571e+05,440 1.1571e+05,440"];
				attn_block_2_5_8	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_5<br/>Block: 6/8<br/>Input: [batch=1024, block_seq=ceil(seq/8), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/8), hidden=4096]",
					pos="1.1472e+05,412",
					shape=rectangle,
					width=11.639];
				kv_cache_2_5_8	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_5<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.145e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_2_5_8 -> attn_block_2_5_8	[pos="e,1.1466e+05,430 1.1466e+05,513.77 1.1466e+05,513.77 1.1466e+05,440 1.1466e+05,440"];
				attn_block_2_6_8	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_6<br/>Block: 7/8<br/>Input: [batch=1024, block_seq=ceil(seq/8), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/8), hidden=4096]",
					pos="1.1365e+05,412",
					shape=rectangle,
					width=11.639];
				kv_cache_2_6_8	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_6<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.1345e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_2_6_8 -> attn_block_2_6_8	[pos="e,1.136e+05,430 1.136e+05,513.77 1.136e+05,513.77 1.136e+05,440 1.136e+05,440"];
				attn_block_2_7_8	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_7<br/>Block: 8/8<br/>Input: [batch=1024, block_seq=ceil(seq/8), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/8), hidden=4096]",
					pos="1.126e+05,412",
					shape=rectangle,
					width=11.639];
				kv_cache_2_7_8	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_7<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.124e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_2_7_8 -> attn_block_2_7_8	[pos="e,1.1255e+05,430 1.1255e+05,513.77 1.1255e+05,513.77 1.1255e+05,440 1.1255e+05,440"];
			}
			subgraph cluster_layer3_8 {
				graph [bb="1.1818e+05,386,1.2658e+05,575",
					fontsize=8,
					label="Layer 3 Attention",
					lheight=0.12,
					lp="1.2238e+05,566.5",
					lwidth=0.97
				];
				attn_block_3_0_8	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_0<br/>Block: 1/8<br/>Input: [batch=1024, block_seq=ceil(seq/8), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/8), hidden=4096]",
					pos="1.1985e+05,412",
					shape=rectangle,
					width=11.639];
				kv_cache_3_0_8	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_0<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.1975e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_3_0_8 -> attn_block_3_0_8	[pos="e,1.1985e+05,430 1.1985e+05,513.77 1.1985e+05,513.77 1.1985e+05,440 1.1985e+05,440"];
				attn_block_3_1_8	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_1<br/>Block: 2/8<br/>Input: [batch=1024, block_seq=ceil(seq/8), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/8), hidden=4096]",
					pos="1.1885e+05,412",
					shape=rectangle,
					width=11.639];
				kv_cache_3_1_8	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_1<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.187e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_3_1_8 -> attn_block_3_1_8	[pos="e,1.1883e+05,430 1.1883e+05,513.77 1.1883e+05,513.77 1.1883e+05,440 1.1883e+05,440"];
				attn_block_3_2_8	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_2<br/>Block: 3/8<br/>Input: [batch=1024, block_seq=ceil(seq/8), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/8), hidden=4096]",
					pos="1.261e+05,412",
					shape=rectangle,
					width=11.639];
				kv_cache_3_2_8	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_2<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.2605e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_3_2_8 -> attn_block_3_2_8	[pos="e,1.261e+05,430 1.261e+05,513.77 1.261e+05,513.77 1.261e+05,440 1.261e+05,440"];
				attn_block_3_3_8	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_3<br/>Block: 4/8<br/>Input: [batch=1024, block_seq=ceil(seq/8), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/8), hidden=4096]",
					pos="1.2512e+05,412",
					shape=rectangle,
					width=11.639];
				kv_cache_3_3_8	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_3<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.25e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_3_3_8 -> attn_block_3_3_8	[pos="e,1.2511e+05,430 1.2511e+05,513.77 1.2511e+05,513.77 1.2511e+05,440 1.2511e+05,440"];
				attn_block_3_4_8	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_4<br/>Block: 5/8<br/>Input: [batch=1024, block_seq=ceil(seq/8), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/8), hidden=4096]",
					pos="1.242e+05,412",
					shape=rectangle,
					width=11.639];
				kv_cache_3_4_8	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_4<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.2395e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_3_4_8 -> attn_block_3_4_8	[pos="e,1.2412e+05,430 1.2412e+05,513.77 1.2412e+05,513.77 1.2412e+05,440 1.2412e+05,440"];
				attn_block_3_5_8	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_5<br/>Block: 6/8<br/>Input: [batch=1024, block_seq=ceil(seq/8), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/8), hidden=4096]",
					pos="1.232e+05,412",
					shape=rectangle,
					width=11.639];
				kv_cache_3_5_8	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_5<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.229e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_3_5_8 -> attn_block_3_5_8	[pos="e,1.231e+05,430 1.231e+05,513.77 1.231e+05,513.77 1.231e+05,440 1.231e+05,440"];
				attn_block_3_6_8	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_6<br/>Block: 7/8<br/>Input: [batch=1024, block_seq=ceil(seq/8), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/8), hidden=4096]",
					pos="1.2205e+05,412",
					shape=rectangle,
					width=11.639];
				kv_cache_3_6_8	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_6<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.2185e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_3_6_8 -> attn_block_3_6_8	[pos="e,1.22e+05,430 1.22e+05,513.77 1.22e+05,513.77 1.22e+05,440 1.22e+05,440"];
				attn_block_3_7_8	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_7<br/>Block: 8/8<br/>Input: [batch=1024, block_seq=ceil(seq/8), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/8), hidden=4096]",
					pos="1.21e+05,412",
					shape=rectangle,
					width=11.639];
				kv_cache_3_7_8	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_7<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.208e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_3_7_8 -> attn_block_3_7_8	[pos="e,1.2095e+05,430 1.2095e+05,513.77 1.2095e+05,513.77 1.2095e+05,440 1.2095e+05,440"];
			}
		}
		subgraph cluster_pool_16 {
			graph [bb="24534,378,91982,602",
				fontsize=10,
				label="16 pool GPUs for 8192-16384 tokens",
				lheight=0.15,
				lp="58258,592.5",
				lwidth=2.56,
				style=dashed
			];
			subgraph cluster_layer0_16 {
				graph [bb="58262,386,75114,575",
					fontsize=8,
					label="Layer 0 Attention",
					lheight=0.12,
					lp="66688,566.5",
					lwidth=0.97
				];
				attn_block_0_0_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_0<br/>Block: 1/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="68104,412",
					shape=rectangle,
					width=11.861];
				kv_cache_0_0_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_0<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="68236,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_0_0_16 -> attn_block_0_0_16	[pos="e,68125,430 68125,513.77 68125,513.77 68125,440 68125,440"];
				attn_block_0_1_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_1<br/>Block: 2/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="67057,412",
					shape=rectangle,
					width=11.861];
				kv_cache_0_1_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_1<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="67186,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_0_1_16 -> attn_block_0_1_16	[pos="e,67077,430 67077,513.77 67077,513.77 67077,440 67077,440"];
				attn_block_0_2_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_2<br/>Block: 3/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="66013,412",
					shape=rectangle,
					width=11.861];
				kv_cache_0_2_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_2<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="66136,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_0_2_16 -> attn_block_0_2_16	[pos="e,66030,430 66030,513.77 66030,513.77 66030,440 66030,440"];
				attn_block_0_3_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_3<br/>Block: 4/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="64974,412",
					shape=rectangle,
					width=11.861];
				kv_cache_0_3_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_3<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="65086,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_0_3_16 -> attn_block_0_3_16	[pos="e,64985,430 64985,513.77 64985,513.77 64985,440 64985,440"];
				attn_block_0_4_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_4<br/>Block: 5/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="63946,412",
					shape=rectangle,
					width=11.861];
				kv_cache_0_4_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_4<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="64036,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_0_4_16 -> attn_block_0_4_16	[pos="e,63946,430 63946,513.77 63946,513.77 63946,440 63946,440"];
				attn_block_0_5_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_5<br/>Block: 6/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="62941,412",
					shape=rectangle,
					width=11.861];
				kv_cache_0_5_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_5<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="62986,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_0_5_16 -> attn_block_0_5_16	[pos="e,62941,430 62941,513.77 62941,513.77 62941,440 62941,440"];
				attn_block_0_6_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_6<br/>Block: 7/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="61980,412",
					shape=rectangle,
					width=11.861];
				kv_cache_0_6_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_6<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="61936,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_0_6_16 -> attn_block_0_6_16	[pos="e,61980,430 61980,513.77 61980,513.77 61980,440 61980,440"];
				attn_block_0_7_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_7<br/>Block: 8/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="60997,412",
					shape=rectangle,
					width=11.861];
				kv_cache_0_7_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_7<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="60886,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_0_7_16 -> attn_block_0_7_16	[pos="e,60986,430 60986,513.77 60986,513.77 60986,440 60986,440"];
				attn_block_0_8_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_8<br/>Block: 9/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="60037,412",
					shape=rectangle,
					width=11.861];
				kv_cache_0_8_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_8<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="59836,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_0_8_16 -> attn_block_0_8_16	[pos="e,59981,430 59981,513.77 59981,513.77 59981,440 59981,440"];
				attn_block_0_9_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_9<br/>Block: 10/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="58986,412",
					shape=rectangle,
					width=11.931];
				kv_cache_0_9_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_9<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="58786,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_0_9_16 -> attn_block_0_9_16	[pos="e,58929,430 58929,513.77 58929,513.77 58929,440 58929,440"];
				attn_block_0_10_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_10<br/>Block: 11/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="74453,412",
					shape=rectangle,
					width=12];
				kv_cache_0_10_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_10<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="74586,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_0_10_16 -> attn_block_0_10_16	[pos="e,74475,430 74475,513.77 74475,513.77 74475,440 74475,440"];
				attn_block_0_11_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_11<br/>Block: 12/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="73394,412",
					shape=rectangle,
					width=12];
				kv_cache_0_11_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_11<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="73527,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_0_11_16 -> attn_block_0_11_16	[pos="e,73416,430 73416,513.77 73416,513.77 73416,440 73416,440"];
				attn_block_0_12_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_12<br/>Block: 13/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="72335,412",
					shape=rectangle,
					width=12];
				kv_cache_0_12_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_12<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="72468,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_0_12_16 -> attn_block_0_12_16	[pos="e,72357,430 72357,513.77 72357,513.77 72357,440 72357,440"];
				attn_block_0_13_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_13<br/>Block: 14/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="71276,412",
					shape=rectangle,
					width=12];
				kv_cache_0_13_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_13<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="71409,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_0_13_16 -> attn_block_0_13_16	[pos="e,71298,430 71298,513.77 71298,513.77 71298,440 71298,440"];
				attn_block_0_14_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_14<br/>Block: 15/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="70217,412",
					shape=rectangle,
					width=12];
				kv_cache_0_14_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_14<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="70350,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_0_14_16 -> attn_block_0_14_16	[pos="e,70239,430 70239,513.77 70239,513.77 70239,440 70239,440"];
				attn_block_0_15_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_15<br/>Block: 16/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="69158,412",
					shape=rectangle,
					width=12];
				kv_cache_0_15_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_15<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="69291,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_0_15_16 -> attn_block_0_15_16	[pos="e,69180,430 69180,513.77 69180,513.77 69180,440 69180,440"];
			}
			subgraph cluster_layer1_16 {
				graph [bb="75122,386,91974,575",
					fontsize=8,
					label="Layer 1 Attention",
					lheight=0.12,
					lp="83548,566.5",
					lwidth=0.97
				];
				attn_block_1_0_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_0<br/>Block: 1/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="84964,412",
					shape=rectangle,
					width=11.861];
				kv_cache_1_0_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_0<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="85096,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_1_0_16 -> attn_block_1_0_16	[pos="e,84985,430 84985,513.77 84985,513.77 84985,440 84985,440"];
				attn_block_1_1_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_1<br/>Block: 2/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="83917,412",
					shape=rectangle,
					width=11.861];
				kv_cache_1_1_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_1<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="84046,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_1_1_16 -> attn_block_1_1_16	[pos="e,83937,430 83937,513.77 83937,513.77 83937,440 83937,440"];
				attn_block_1_2_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_2<br/>Block: 3/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="82873,412",
					shape=rectangle,
					width=11.861];
				kv_cache_1_2_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_2<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="82996,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_1_2_16 -> attn_block_1_2_16	[pos="e,82890,430 82890,513.77 82890,513.77 82890,440 82890,440"];
				attn_block_1_3_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_3<br/>Block: 4/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="81834,412",
					shape=rectangle,
					width=11.861];
				kv_cache_1_3_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_3<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="81946,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_1_3_16 -> attn_block_1_3_16	[pos="e,81845,430 81845,513.77 81845,513.77 81845,440 81845,440"];
				attn_block_1_4_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_4<br/>Block: 5/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="80806,412",
					shape=rectangle,
					width=11.861];
				kv_cache_1_4_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_4<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="80896,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_1_4_16 -> attn_block_1_4_16	[pos="e,80806,430 80806,513.77 80806,513.77 80806,440 80806,440"];
				attn_block_1_5_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_5<br/>Block: 6/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="79801,412",
					shape=rectangle,
					width=11.861];
				kv_cache_1_5_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_5<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="79846,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_1_5_16 -> attn_block_1_5_16	[pos="e,79801,430 79801,513.77 79801,513.77 79801,440 79801,440"];
				attn_block_1_6_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_6<br/>Block: 7/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="78840,412",
					shape=rectangle,
					width=11.861];
				kv_cache_1_6_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_6<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="78796,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_1_6_16 -> attn_block_1_6_16	[pos="e,78840,430 78840,513.77 78840,513.77 78840,440 78840,440"];
				attn_block_1_7_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_7<br/>Block: 8/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="77857,412",
					shape=rectangle,
					width=11.861];
				kv_cache_1_7_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_7<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="77746,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_1_7_16 -> attn_block_1_7_16	[pos="e,77846,430 77846,513.77 77846,513.77 77846,440 77846,440"];
				attn_block_1_8_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_8<br/>Block: 9/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="76896,412",
					shape=rectangle,
					width=11.861];
				kv_cache_1_8_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_8<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="76696,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_1_8_16 -> attn_block_1_8_16	[pos="e,76841,430 76841,513.77 76841,513.77 76841,440 76841,440"];
				attn_block_1_9_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_9<br/>Block: 10/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="75833,412",
					shape=rectangle,
					width=11.931];
				kv_cache_1_9_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_9<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="75646,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_1_9_16 -> attn_block_1_9_16	[pos="e,75783,430 75783,513.77 75783,513.77 75783,440 75783,440"];
				attn_block_1_10_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_10<br/>Block: 11/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="91313,412",
					shape=rectangle,
					width=12];
				kv_cache_1_10_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_10<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="91446,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_1_10_16 -> attn_block_1_10_16	[pos="e,91335,430 91335,513.77 91335,513.77 91335,440 91335,440"];
				attn_block_1_11_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_11<br/>Block: 12/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="90254,412",
					shape=rectangle,
					width=12];
				kv_cache_1_11_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_11<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="90387,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_1_11_16 -> attn_block_1_11_16	[pos="e,90276,430 90276,513.77 90276,513.77 90276,440 90276,440"];
				attn_block_1_12_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_12<br/>Block: 13/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="89195,412",
					shape=rectangle,
					width=12];
				kv_cache_1_12_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_12<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="89328,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_1_12_16 -> attn_block_1_12_16	[pos="e,89217,430 89217,513.77 89217,513.77 89217,440 89217,440"];
				attn_block_1_13_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_13<br/>Block: 14/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="88136,412",
					shape=rectangle,
					width=12];
				kv_cache_1_13_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_13<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="88269,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_1_13_16 -> attn_block_1_13_16	[pos="e,88158,430 88158,513.77 88158,513.77 88158,440 88158,440"];
				attn_block_1_14_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_14<br/>Block: 15/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="87077,412",
					shape=rectangle,
					width=12];
				kv_cache_1_14_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_14<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="87210,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_1_14_16 -> attn_block_1_14_16	[pos="e,87099,430 87099,513.77 87099,513.77 87099,440 87099,440"];
				attn_block_1_15_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_15<br/>Block: 16/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="86018,412",
					shape=rectangle,
					width=12];
				kv_cache_1_15_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_15<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="86151,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_1_15_16 -> attn_block_1_15_16	[pos="e,86040,430 86040,513.77 86040,513.77 86040,440 86040,440"];
			}
			subgraph cluster_layer2_16 {
				graph [bb="24542,386,41394,575",
					fontsize=8,
					label="Layer 2 Attention",
					lheight=0.12,
					lp="32968,566.5",
					lwidth=0.97
				];
				attn_block_2_0_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_0<br/>Block: 1/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="34737,412",
					shape=rectangle,
					width=11.861];
				kv_cache_2_0_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_0<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="34516,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_2_0_16 -> attn_block_2_0_16	[pos="e,34551,430 34551,513.77 34551,513.77 34551,440 34551,440"];
				attn_block_2_1_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_1<br/>Block: 2/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="33732,412",
					shape=rectangle,
					width=11.861];
				kv_cache_2_1_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_1<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="33466,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_2_1_16 -> attn_block_2_1_16	[pos="e,33531,430 33531,513.77 33531,513.77 33531,440 33531,440"];
				attn_block_2_2_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_2<br/>Block: 3/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="32593,412",
					shape=rectangle,
					width=11.861];
				kv_cache_2_2_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_2<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="32416,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_2_2_16 -> attn_block_2_2_16	[pos="e,32421,430 32421,513.77 32421,513.77 32421,440 32421,440"];
				attn_block_2_3_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_3<br/>Block: 4/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="31488,412",
					shape=rectangle,
					width=11.861];
				kv_cache_2_3_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_3<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="31366,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_2_3_16 -> attn_block_2_3_16	[pos="e,31472,430 31472,513.77 31472,513.77 31472,440 31472,440"];
				attn_block_2_4_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_4<br/>Block: 5/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="30466,412",
					shape=rectangle,
					width=11.861];
				kv_cache_2_4_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_4<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="30316,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_2_4_16 -> attn_block_2_4_16	[pos="e,30303,430 30303,513.77 30303,513.77 30303,440 30303,440"];
				attn_block_2_5_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_5<br/>Block: 6/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="29430,412",
					shape=rectangle,
					width=11.861];
				kv_cache_2_5_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_5<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="29266,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_2_5_16 -> attn_block_2_5_16	[pos="e,29263,430 29263,513.77 29263,513.77 29263,440 29263,440"];
				attn_block_2_6_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_6<br/>Block: 7/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="28469,412",
					shape=rectangle,
					width=11.861];
				kv_cache_2_6_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_6<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="28216,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_2_6_16 -> attn_block_2_6_16	[pos="e,28387,430 28387,513.77 28387,513.77 28387,440 28387,440"];
				attn_block_2_7_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_7<br/>Block: 8/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="27381,412",
					shape=rectangle,
					width=11.861];
				kv_cache_2_7_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_7<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="27166,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_2_7_16 -> attn_block_2_7_16	[pos="e,27318,430 27318,513.77 27318,513.77 27318,440 27318,440"];
				attn_block_2_8_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_8<br/>Block: 9/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="26312,412",
					shape=rectangle,
					width=11.861];
				kv_cache_2_8_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_8<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="26116,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_2_8_16 -> attn_block_2_8_16	[pos="e,26259,430 26259,513.77 26259,513.77 26259,440 26259,440"];
				attn_block_2_9_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_9<br/>Block: 10/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="25251,412",
					shape=rectangle,
					width=11.931];
				kv_cache_2_9_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_9<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="25066,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_2_9_16 -> attn_block_2_9_16	[pos="e,25202,430 25202,513.77 25202,513.77 25202,440 25202,440"];
				attn_block_2_10_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_10<br/>Block: 11/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="40744,412",
					shape=rectangle,
					width=12];
				kv_cache_2_10_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_10<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="40866,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_2_10_16 -> attn_block_2_10_16	[pos="e,40761,430 40761,513.77 40761,513.77 40761,440 40761,440"];
				attn_block_2_11_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_11<br/>Block: 12/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="39696,412",
					shape=rectangle,
					width=12];
				kv_cache_2_11_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_11<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="39807,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_2_11_16 -> attn_block_2_11_16	[pos="e,39707,430 39707,513.77 39707,513.77 39707,440 39707,440"];
				attn_block_2_12_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_12<br/>Block: 13/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="38659,412",
					shape=rectangle,
					width=12];
				kv_cache_2_12_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_12<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="38748,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_2_12_16 -> attn_block_2_12_16	[pos="e,38659,430 38659,513.77 38659,513.77 38659,440 38659,440"];
				attn_block_2_13_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_13<br/>Block: 14/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="37644,412",
					shape=rectangle,
					width=12];
				kv_cache_2_13_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_13<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="37689,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_2_13_16 -> attn_block_2_13_16	[pos="e,37644,430 37644,513.77 37644,513.77 37644,440 37644,440"];
				attn_block_2_14_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_14<br/>Block: 15/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="36674,412",
					shape=rectangle,
					width=12];
				kv_cache_2_14_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_14<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="36630,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_2_14_16 -> attn_block_2_14_16	[pos="e,36674,430 36674,513.77 36674,513.77 36674,440 36674,440"];
				attn_block_2_15_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_15<br/>Block: 16/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="35681,412",
					shape=rectangle,
					width=12];
				kv_cache_2_15_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_15<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="35571,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_2_15_16 -> attn_block_2_15_16	[pos="e,35670,430 35670,513.77 35670,513.77 35670,440 35670,440"];
			}
			subgraph cluster_layer3_16 {
				graph [bb="41402,386,58254,575",
					fontsize=8,
					label="Layer 3 Attention",
					lheight=0.12,
					lp="49828,566.5",
					lwidth=0.97
				];
				attn_block_3_0_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_0<br/>Block: 1/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="51597,412",
					shape=rectangle,
					width=11.861];
				kv_cache_3_0_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_0<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="51376,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_3_0_16 -> attn_block_3_0_16	[pos="e,51531,430 51531,513.77 51531,513.77 51531,440 51531,440"];
				attn_block_3_1_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_1<br/>Block: 2/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="50592,412",
					shape=rectangle,
					width=11.861];
				kv_cache_3_1_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_1<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="50326,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_3_1_16 -> attn_block_3_1_16	[pos="e,50504,430 50504,513.77 50504,513.77 50504,440 50504,440"];
				attn_block_3_2_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_2<br/>Block: 3/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="49453,412",
					shape=rectangle,
					width=11.861];
				kv_cache_3_2_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_2<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="49276,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_3_2_16 -> attn_block_3_2_16	[pos="e,49409,430 49409,513.77 49409,513.77 49409,440 49409,440"];
				attn_block_3_3_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_3<br/>Block: 4/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="48348,412",
					shape=rectangle,
					width=11.861];
				kv_cache_3_3_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_3<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="48226,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_3_3_16 -> attn_block_3_3_16	[pos="e,48332,430 48332,513.77 48332,513.77 48332,440 48332,440"];
				attn_block_3_4_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_4<br/>Block: 5/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="47326,412",
					shape=rectangle,
					width=11.861];
				kv_cache_3_4_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_4<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="47176,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_3_4_16 -> attn_block_3_4_16	[pos="e,47296,430 47296,513.77 47296,513.77 47296,440 47296,440"];
				attn_block_3_5_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_5<br/>Block: 6/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="46290,412",
					shape=rectangle,
					width=11.861];
				kv_cache_3_5_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_5<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="46126,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_3_5_16 -> attn_block_3_5_16	[pos="e,46253,430 46253,513.77 46253,513.77 46253,440 46253,440"];
				attn_block_3_6_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_6<br/>Block: 7/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="45247,412",
					shape=rectangle,
					width=11.861];
				kv_cache_3_6_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_6<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="45076,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_3_6_16 -> attn_block_3_6_16	[pos="e,45206,430 45206,513.77 45206,513.77 45206,440 45206,440"];
				attn_block_3_7_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_7<br/>Block: 8/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="44200,412",
					shape=rectangle,
					width=11.861];
				kv_cache_3_7_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_7<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="44026,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_3_7_16 -> attn_block_3_7_16	[pos="e,44158,430 44158,513.77 44158,513.77 44158,440 44158,440"];
				attn_block_3_8_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_8<br/>Block: 9/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="43152,412",
					shape=rectangle,
					width=11.861];
				kv_cache_3_8_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_8<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="42976,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_3_8_16 -> attn_block_3_8_16	[pos="e,43109,430 43109,513.77 43109,513.77 43109,440 43109,440"];
				attn_block_3_9_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_9<br/>Block: 10/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="42101,412",
					shape=rectangle,
					width=11.931];
				kv_cache_3_9_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_9<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="41926,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_3_9_16 -> attn_block_3_9_16	[pos="e,42057,430 42057,513.77 42057,513.77 42057,440 42057,440"];
				attn_block_3_10_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_10<br/>Block: 11/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="57604,412",
					shape=rectangle,
					width=12];
				kv_cache_3_10_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_10<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="57726,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_3_10_16 -> attn_block_3_10_16	[pos="e,57621,430 57621,513.77 57621,513.77 57621,440 57621,440"];
				attn_block_3_11_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_11<br/>Block: 12/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="56556,412",
					shape=rectangle,
					width=12];
				kv_cache_3_11_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_11<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="56667,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_3_11_16 -> attn_block_3_11_16	[pos="e,56567,430 56567,513.77 56567,513.77 56567,440 56567,440"];
				attn_block_3_12_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_12<br/>Block: 13/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="55519,412",
					shape=rectangle,
					width=12];
				kv_cache_3_12_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_12<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="55608,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_3_12_16 -> attn_block_3_12_16	[pos="e,55519,430 55519,513.77 55519,513.77 55519,440 55519,440"];
				attn_block_3_13_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_13<br/>Block: 14/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="54504,412",
					shape=rectangle,
					width=12];
				kv_cache_3_13_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_13<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="54549,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_3_13_16 -> attn_block_3_13_16	[pos="e,54504,430 54504,513.77 54504,513.77 54504,440 54504,440"];
				attn_block_3_14_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_14<br/>Block: 15/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="53534,412",
					shape=rectangle,
					width=12];
				kv_cache_3_14_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_14<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="53490,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_3_14_16 -> attn_block_3_14_16	[pos="e,53534,430 53534,513.77 53534,513.77 53534,440 53534,440"];
				attn_block_3_15_16	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_15<br/>Block: 16/16<br/>Input: [batch=1024, block_seq=ceil(seq/16), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/16), hidden=4096]",
					pos="52541,412",
					shape=rectangle,
					width=12];
				kv_cache_3_15_16	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_15<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="52431,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_3_15_16 -> attn_block_3_15_16	[pos="e,52530,430 52530,513.77 52530,513.77 52530,440 52530,440"];
			}
		}
		subgraph cluster_pool_24 {
			graph [bb="1.2659e+05,378,2.2793e+05,602",
				fontsize=10,
				label="24 pool GPUs for >16384 tokens",
				lheight=0.15,
				lp="1.7726e+05,592.5",
				lwidth=2.28,
				style=dashed
			];
			subgraph cluster_layer0_24 {
				graph [bb="1.7727e+05,386,2.0259e+05,575",
					fontsize=8,
					label="Layer 0 Attention",
					lheight=0.12,
					lp="1.8993e+05,566.5",
					lwidth=0.97
				];
				attn_block_0_0_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_0<br/>Block: 1/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.9553e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_0_0_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_0<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.9571e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_0_0_24 -> attn_block_0_0_24	[pos="e,1.9558e+05,430 1.9558e+05,513.77 1.9558e+05,513.77 1.9558e+05,440 1.9558e+05,440"];
				attn_block_0_1_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_1<br/>Block: 2/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.9448e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_0_1_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_1<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.9466e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_0_1_24 -> attn_block_0_1_24	[pos="e,1.9453e+05,430 1.9453e+05,513.77 1.9453e+05,513.77 1.9453e+05,440 1.9453e+05,440"];
				attn_block_0_2_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_2<br/>Block: 3/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.9344e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_0_2_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_2<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.9361e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_0_2_24 -> attn_block_0_2_24	[pos="e,1.9348e+05,430 1.9348e+05,513.77 1.9348e+05,513.77 1.9348e+05,440 1.9348e+05,440"];
				attn_block_0_3_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_3<br/>Block: 4/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.9239e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_0_3_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_3<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.9256e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_0_3_24 -> attn_block_0_3_24	[pos="e,1.9243e+05,430 1.9243e+05,513.77 1.9243e+05,513.77 1.9243e+05,440 1.9243e+05,440"];
				attn_block_0_4_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_4<br/>Block: 5/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.9134e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_0_4_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_4<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.9151e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_0_4_24 -> attn_block_0_4_24	[pos="e,1.9138e+05,430 1.9138e+05,513.77 1.9138e+05,513.77 1.9138e+05,440 1.9138e+05,440"];
				attn_block_0_5_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_5<br/>Block: 6/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.903e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_0_5_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_5<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.9046e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_0_5_24 -> attn_block_0_5_24	[pos="e,1.9033e+05,430 1.9033e+05,513.77 1.9033e+05,513.77 1.9033e+05,440 1.9033e+05,440"];
				attn_block_0_6_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_6<br/>Block: 7/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.8926e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_0_6_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_6<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.8941e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_0_6_24 -> attn_block_0_6_24	[pos="e,1.8929e+05,430 1.8929e+05,513.77 1.8929e+05,513.77 1.8929e+05,440 1.8929e+05,440"];
				attn_block_0_7_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_7<br/>Block: 8/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.8823e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_0_7_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_7<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.8836e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_0_7_24 -> attn_block_0_7_24	[pos="e,1.8825e+05,430 1.8825e+05,513.77 1.8825e+05,513.77 1.8825e+05,440 1.8825e+05,440"];
				attn_block_0_8_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_8<br/>Block: 9/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.8722e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_0_8_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_8<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.8731e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_0_8_24 -> attn_block_0_8_24	[pos="e,1.8722e+05,430 1.8722e+05,513.77 1.8722e+05,513.77 1.8722e+05,440 1.8722e+05,440"];
				attn_block_0_9_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_9<br/>Block: 10/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.8626e+05,412",
					shape=rectangle,
					width=11.931];
				kv_cache_0_9_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_9<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.8626e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_0_9_24 -> attn_block_0_9_24	[pos="e,1.8626e+05,430 1.8626e+05,513.77 1.8626e+05,513.77 1.8626e+05,440 1.8626e+05,440"];
				attn_block_0_10_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_10<br/>Block: 11/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.8529e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_0_10_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_10<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.8521e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_0_10_24 -> attn_block_0_10_24	[pos="e,1.8529e+05,430 1.8529e+05,513.77 1.8529e+05,513.77 1.8529e+05,440 1.8529e+05,440"];
				attn_block_0_11_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_11<br/>Block: 12/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.8428e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_0_11_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_11<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.8415e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_0_11_24 -> attn_block_0_11_24	[pos="e,1.8426e+05,430 1.8426e+05,513.77 1.8426e+05,513.77 1.8426e+05,440 1.8426e+05,440"];
				attn_block_0_12_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_12<br/>Block: 13/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.8324e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_0_12_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_12<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.8309e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_0_12_24 -> attn_block_0_12_24	[pos="e,1.8321e+05,430 1.8321e+05,513.77 1.8321e+05,513.77 1.8321e+05,440 1.8321e+05,440"];
				attn_block_0_13_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_13<br/>Block: 14/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.822e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_0_13_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_13<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.8203e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_0_13_24 -> attn_block_0_13_24	[pos="e,1.8216e+05,430 1.8216e+05,513.77 1.8216e+05,513.77 1.8216e+05,440 1.8216e+05,440"];
				attn_block_0_14_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_14<br/>Block: 15/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.8114e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_0_14_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_14<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.8097e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_0_14_24 -> attn_block_0_14_24	[pos="e,1.811e+05,430 1.811e+05,513.77 1.811e+05,513.77 1.811e+05,440 1.811e+05,440"];
				attn_block_0_15_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_15<br/>Block: 16/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.8009e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_0_15_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_15<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.7991e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_0_15_24 -> attn_block_0_15_24	[pos="e,1.8004e+05,430 1.8004e+05,513.77 1.8004e+05,513.77 1.8004e+05,440 1.8004e+05,440"];
				attn_block_0_16_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_16<br/>Block: 17/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.7903e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_0_16_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_16<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.7885e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_0_16_24 -> attn_block_0_16_24	[pos="e,1.7898e+05,430 1.7898e+05,513.77 1.7898e+05,513.77 1.7898e+05,440 1.7898e+05,440"];
				attn_block_0_17_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_17<br/>Block: 18/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.7797e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_0_17_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_17<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.7779e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_0_17_24 -> attn_block_0_17_24	[pos="e,1.7793e+05,430 1.7793e+05,513.77 1.7793e+05,513.77 1.7793e+05,440 1.7793e+05,440"];
				attn_block_0_18_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_18<br/>Block: 19/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="2.0188e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_0_18_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_18<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.0206e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_0_18_24 -> attn_block_0_18_24	[pos="e,2.0193e+05,430 2.0193e+05,513.77 2.0193e+05,513.77 2.0193e+05,440 2.0193e+05,440"];
				attn_block_0_19_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_19<br/>Block: 20/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="2.0082e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_0_19_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_19<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.01e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_0_19_24 -> attn_block_0_19_24	[pos="e,2.0087e+05,430 2.0087e+05,513.77 2.0087e+05,513.77 2.0087e+05,440 2.0087e+05,440"];
				attn_block_0_20_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_20<br/>Block: 21/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.9977e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_0_20_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_20<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.9994e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_0_20_24 -> attn_block_0_20_24	[pos="e,1.9981e+05,430 1.9981e+05,513.77 1.9981e+05,513.77 1.9981e+05,440 1.9981e+05,440"];
				attn_block_0_21_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_21<br/>Block: 22/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.9871e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_0_21_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_21<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.9888e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_0_21_24 -> attn_block_0_21_24	[pos="e,1.9875e+05,430 1.9875e+05,513.77 1.9875e+05,513.77 1.9875e+05,440 1.9875e+05,440"];
				attn_block_0_22_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_22<br/>Block: 23/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.9765e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_0_22_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_22<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.9783e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_0_22_24 -> attn_block_0_22_24	[pos="e,1.9769e+05,430 1.9769e+05,513.77 1.9769e+05,513.77 1.9769e+05,440 1.9769e+05,440"];
				attn_block_0_23_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_23<br/>Block: 24/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.9659e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_0_23_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_23<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.9677e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_0_23_24 -> attn_block_0_23_24	[pos="e,1.9663e+05,430 1.9663e+05,513.77 1.9663e+05,513.77 1.9663e+05,440 1.9663e+05,440"];
			}
			subgraph cluster_layer1_24 {
				graph [bb="2.026e+05,386,2.2792e+05,575",
					fontsize=8,
					label="Layer 1 Attention",
					lheight=0.12,
					lp="2.1526e+05,566.5",
					lwidth=0.97
				];
				attn_block_1_0_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_0<br/>Block: 1/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="2.2087e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_1_0_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_0<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.2104e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_1_0_24 -> attn_block_1_0_24	[pos="e,2.2091e+05,430 2.2091e+05,513.77 2.2091e+05,513.77 2.2091e+05,440 2.2091e+05,440"];
				attn_block_1_1_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_1<br/>Block: 2/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="2.1982e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_1_1_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_1<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.1999e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_1_1_24 -> attn_block_1_1_24	[pos="e,2.1986e+05,430 2.1986e+05,513.77 2.1986e+05,513.77 2.1986e+05,440 2.1986e+05,440"];
				attn_block_1_2_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_2<br/>Block: 3/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="2.1877e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_1_2_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_2<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.1894e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_1_2_24 -> attn_block_1_2_24	[pos="e,2.1881e+05,430 2.1881e+05,513.77 2.1881e+05,513.77 2.1881e+05,440 2.1881e+05,440"];
				attn_block_1_3_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_3<br/>Block: 4/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="2.1772e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_1_3_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_3<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.1789e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_1_3_24 -> attn_block_1_3_24	[pos="e,2.1776e+05,430 2.1776e+05,513.77 2.1776e+05,513.77 2.1776e+05,440 2.1776e+05,440"];
				attn_block_1_4_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_4<br/>Block: 5/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="2.1667e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_1_4_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_4<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.1684e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_1_4_24 -> attn_block_1_4_24	[pos="e,2.1671e+05,430 2.1671e+05,513.77 2.1671e+05,513.77 2.1671e+05,440 2.1671e+05,440"];
				attn_block_1_5_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_5<br/>Block: 6/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="2.1563e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_1_5_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_5<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.1579e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_1_5_24 -> attn_block_1_5_24	[pos="e,2.1567e+05,430 2.1567e+05,513.77 2.1567e+05,513.77 2.1567e+05,440 2.1567e+05,440"];
				attn_block_1_6_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_6<br/>Block: 7/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="2.1459e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_1_6_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_6<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.1474e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_1_6_24 -> attn_block_1_6_24	[pos="e,2.1462e+05,430 2.1462e+05,513.77 2.1462e+05,513.77 2.1462e+05,440 2.1462e+05,440"];
				attn_block_1_7_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_7<br/>Block: 8/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="2.1356e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_1_7_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_7<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.1369e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_1_7_24 -> attn_block_1_7_24	[pos="e,2.1358e+05,430 2.1358e+05,513.77 2.1358e+05,513.77 2.1358e+05,440 2.1358e+05,440"];
				attn_block_1_8_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_8<br/>Block: 9/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="2.1256e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_1_8_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_8<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.1264e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_1_8_24 -> attn_block_1_8_24	[pos="e,2.1256e+05,430 2.1256e+05,513.77 2.1256e+05,513.77 2.1256e+05,440 2.1256e+05,440"];
				attn_block_1_9_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_9<br/>Block: 10/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="2.1159e+05,412",
					shape=rectangle,
					width=11.931];
				kv_cache_1_9_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_9<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.1159e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_1_9_24 -> attn_block_1_9_24	[pos="e,2.1159e+05,430 2.1159e+05,513.77 2.1159e+05,513.77 2.1159e+05,440 2.1159e+05,440"];
				attn_block_1_10_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_10<br/>Block: 11/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="2.1063e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_1_10_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_10<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.1054e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_1_10_24 -> attn_block_1_10_24	[pos="e,2.1063e+05,430 2.1063e+05,513.77 2.1063e+05,513.77 2.1063e+05,440 2.1063e+05,440"];
				attn_block_1_11_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_11<br/>Block: 12/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="2.0961e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_1_11_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_11<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.0948e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_1_11_24 -> attn_block_1_11_24	[pos="e,2.0959e+05,430 2.0959e+05,513.77 2.0959e+05,513.77 2.0959e+05,440 2.0959e+05,440"];
				attn_block_1_12_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_12<br/>Block: 13/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="2.0864e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_1_12_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_12<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.0842e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_1_12_24 -> attn_block_1_12_24	[pos="e,2.0858e+05,430 2.0858e+05,513.77 2.0858e+05,513.77 2.0858e+05,440 2.0858e+05,440"];
				attn_block_1_13_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_13<br/>Block: 14/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="2.0756e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_1_13_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_13<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.0736e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_1_13_24 -> attn_block_1_13_24	[pos="e,2.0751e+05,430 2.0751e+05,513.77 2.0751e+05,513.77 2.0751e+05,440 2.0751e+05,440"];
				attn_block_1_14_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_14<br/>Block: 15/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="2.0649e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_1_14_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_14<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.063e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_1_14_24 -> attn_block_1_14_24	[pos="e,2.0644e+05,430 2.0644e+05,513.77 2.0644e+05,513.77 2.0644e+05,440 2.0644e+05,440"];
				attn_block_1_15_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_15<br/>Block: 16/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="2.0543e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_1_15_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_15<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.0524e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_1_15_24 -> attn_block_1_15_24	[pos="e,2.0538e+05,430 2.0538e+05,513.77 2.0538e+05,513.77 2.0538e+05,440 2.0538e+05,440"];
				attn_block_1_16_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_16<br/>Block: 17/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="2.0436e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_1_16_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_16<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.0418e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_1_16_24 -> attn_block_1_16_24	[pos="e,2.0432e+05,430 2.0432e+05,513.77 2.0432e+05,513.77 2.0432e+05,440 2.0432e+05,440"];
				attn_block_1_17_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_17<br/>Block: 18/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="2.033e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_1_17_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_17<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.0313e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_1_17_24 -> attn_block_1_17_24	[pos="e,2.0326e+05,430 2.0326e+05,513.77 2.0326e+05,513.77 2.0326e+05,440 2.0326e+05,440"];
				attn_block_1_18_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_18<br/>Block: 19/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="2.2722e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_1_18_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_18<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.2739e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_1_18_24 -> attn_block_1_18_24	[pos="e,2.2726e+05,430 2.2726e+05,513.77 2.2726e+05,513.77 2.2726e+05,440 2.2726e+05,440"];
				attn_block_1_19_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_19<br/>Block: 20/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="2.2616e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_1_19_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_19<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.2634e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_1_19_24 -> attn_block_1_19_24	[pos="e,2.262e+05,430 2.262e+05,513.77 2.262e+05,513.77 2.262e+05,440 2.262e+05,440"];
				attn_block_1_20_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_20<br/>Block: 21/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="2.251e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_1_20_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_20<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.2528e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_1_20_24 -> attn_block_1_20_24	[pos="e,2.2514e+05,430 2.2514e+05,513.77 2.2514e+05,513.77 2.2514e+05,440 2.2514e+05,440"];
				attn_block_1_21_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_21<br/>Block: 22/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="2.2404e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_1_21_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_21<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.2422e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_1_21_24 -> attn_block_1_21_24	[pos="e,2.2408e+05,430 2.2408e+05,513.77 2.2408e+05,513.77 2.2408e+05,440 2.2408e+05,440"];
				attn_block_1_22_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_22<br/>Block: 23/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="2.2298e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_1_22_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_22<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.2316e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_1_22_24 -> attn_block_1_22_24	[pos="e,2.2302e+05,430 2.2302e+05,513.77 2.2302e+05,513.77 2.2302e+05,440 2.2302e+05,440"];
				attn_block_1_23_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_23<br/>Block: 24/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="2.2192e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_1_23_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_23<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="2.221e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_1_23_24 -> attn_block_1_23_24	[pos="e,2.2197e+05,430 2.2197e+05,513.77 2.2197e+05,513.77 2.2197e+05,440 2.2197e+05,440"];
			}
			subgraph cluster_layer2_24 {
				graph [bb="1.266e+05,386,1.5193e+05,575",
					fontsize=8,
					label="Layer 2 Attention",
					lheight=0.12,
					lp="1.3926e+05,566.5",
					lwidth=0.97
				];
				attn_block_2_0_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_0<br/>Block: 1/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.4496e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_2_0_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_0<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.4505e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_2_0_24 -> attn_block_2_0_24	[pos="e,1.4496e+05,430 1.4496e+05,513.77 1.4496e+05,513.77 1.4496e+05,440 1.4496e+05,440"];
				attn_block_2_1_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_1<br/>Block: 2/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.44e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_2_1_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_1<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.44e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_2_1_24 -> attn_block_2_1_24	[pos="e,1.44e+05,430 1.44e+05,513.77 1.44e+05,513.77 1.44e+05,440 1.44e+05,440"];
				attn_block_2_2_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_2<br/>Block: 3/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.4304e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_2_2_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_2<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.4295e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_2_2_24 -> attn_block_2_2_24	[pos="e,1.4304e+05,430 1.4304e+05,513.77 1.4304e+05,513.77 1.4304e+05,440 1.4304e+05,440"];
				attn_block_2_3_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_3<br/>Block: 4/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.421e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_2_3_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_3<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.419e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_2_3_24 -> attn_block_2_3_24	[pos="e,1.4204e+05,430 1.4204e+05,513.77 1.4204e+05,513.77 1.4204e+05,440 1.4204e+05,440"];
				attn_block_2_4_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_4<br/>Block: 5/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.4109e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_2_4_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_4<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.4085e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_2_4_24 -> attn_block_2_4_24	[pos="e,1.4102e+05,430 1.4102e+05,513.77 1.4102e+05,513.77 1.4102e+05,440 1.4102e+05,440"];
				attn_block_2_5_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_5<br/>Block: 6/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.3995e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_2_5_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_5<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.398e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_2_5_24 -> attn_block_2_5_24	[pos="e,1.3992e+05,430 1.3992e+05,513.77 1.3992e+05,513.77 1.3992e+05,440 1.3992e+05,440"];
				attn_block_2_6_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_6<br/>Block: 7/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.3892e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_2_6_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_6<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.3875e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_2_6_24 -> attn_block_2_6_24	[pos="e,1.3888e+05,430 1.3888e+05,513.77 1.3888e+05,513.77 1.3888e+05,440 1.3888e+05,440"];
				attn_block_2_7_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_7<br/>Block: 8/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.3795e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_2_7_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_7<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.377e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_2_7_24 -> attn_block_2_7_24	[pos="e,1.3787e+05,430 1.3787e+05,513.77 1.3787e+05,513.77 1.3787e+05,440 1.3787e+05,440"];
				attn_block_2_8_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_8<br/>Block: 9/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.3686e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_2_8_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_8<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.3665e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_2_8_24 -> attn_block_2_8_24	[pos="e,1.368e+05,430 1.368e+05,513.77 1.368e+05,513.77 1.368e+05,440 1.368e+05,440"];
				attn_block_2_9_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_9<br/>Block: 10/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.3579e+05,412",
					shape=rectangle,
					width=11.931];
				kv_cache_2_9_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_9<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.356e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_2_9_24 -> attn_block_2_9_24	[pos="e,1.3574e+05,430 1.3574e+05,513.77 1.3574e+05,513.77 1.3574e+05,440 1.3574e+05,440"];
				attn_block_2_10_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_10<br/>Block: 11/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.3473e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_2_10_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_10<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.3454e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_2_10_24 -> attn_block_2_10_24	[pos="e,1.3468e+05,430 1.3468e+05,513.77 1.3468e+05,513.77 1.3468e+05,440 1.3468e+05,440"];
				attn_block_2_11_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_11<br/>Block: 12/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.3366e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_2_11_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_11<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.3348e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_2_11_24 -> attn_block_2_11_24	[pos="e,1.3362e+05,430 1.3362e+05,513.77 1.3362e+05,513.77 1.3362e+05,440 1.3362e+05,440"];
				attn_block_2_12_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_12<br/>Block: 13/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.326e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_2_12_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_12<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.3242e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_2_12_24 -> attn_block_2_12_24	[pos="e,1.3256e+05,430 1.3256e+05,513.77 1.3256e+05,513.77 1.3256e+05,440 1.3256e+05,440"];
				attn_block_2_13_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_13<br/>Block: 14/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.3154e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_2_13_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_13<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.3137e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_2_13_24 -> attn_block_2_13_24	[pos="e,1.315e+05,430 1.315e+05,513.77 1.315e+05,513.77 1.315e+05,440 1.315e+05,440"];
				attn_block_2_14_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_14<br/>Block: 15/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.3048e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_2_14_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_14<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.3031e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_2_14_24 -> attn_block_2_14_24	[pos="e,1.3044e+05,430 1.3044e+05,513.77 1.3044e+05,513.77 1.3044e+05,440 1.3044e+05,440"];
				attn_block_2_15_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_15<br/>Block: 16/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.2942e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_2_15_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_15<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.2925e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_2_15_24 -> attn_block_2_15_24	[pos="e,1.2938e+05,430 1.2938e+05,513.77 1.2938e+05,513.77 1.2938e+05,440 1.2938e+05,440"];
				attn_block_2_16_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_16<br/>Block: 17/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.2837e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_2_16_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_16<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.2819e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_2_16_24 -> attn_block_2_16_24	[pos="e,1.2832e+05,430 1.2832e+05,513.77 1.2832e+05,513.77 1.2832e+05,440 1.2832e+05,440"];
				attn_block_2_17_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_17<br/>Block: 18/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.2731e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_2_17_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_17<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.2713e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_2_17_24 -> attn_block_2_17_24	[pos="e,1.2726e+05,430 1.2726e+05,513.77 1.2726e+05,513.77 1.2726e+05,440 1.2726e+05,440"];
				attn_block_2_18_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_18<br/>Block: 19/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.5122e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_2_18_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_18<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.514e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_2_18_24 -> attn_block_2_18_24	[pos="e,1.5127e+05,430 1.5127e+05,513.77 1.5127e+05,513.77 1.5127e+05,440 1.5127e+05,440"];
				attn_block_2_19_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_19<br/>Block: 20/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.5016e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_2_19_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_19<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.5034e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_2_19_24 -> attn_block_2_19_24	[pos="e,1.5021e+05,430 1.5021e+05,513.77 1.5021e+05,513.77 1.5021e+05,440 1.5021e+05,440"];
				attn_block_2_20_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_20<br/>Block: 21/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.4911e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_2_20_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_20<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.4928e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_2_20_24 -> attn_block_2_20_24	[pos="e,1.4915e+05,430 1.4915e+05,513.77 1.4915e+05,513.77 1.4915e+05,440 1.4915e+05,440"];
				attn_block_2_21_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_21<br/>Block: 22/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.4805e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_2_21_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_21<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.4822e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_2_21_24 -> attn_block_2_21_24	[pos="e,1.4809e+05,430 1.4809e+05,513.77 1.4809e+05,513.77 1.4809e+05,440 1.4809e+05,440"];
				attn_block_2_22_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_22<br/>Block: 23/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.4701e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_2_22_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_22<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.4716e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_2_22_24 -> attn_block_2_22_24	[pos="e,1.4704e+05,430 1.4704e+05,513.77 1.4704e+05,513.77 1.4704e+05,440 1.4704e+05,440"];
				attn_block_2_23_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_23<br/>Block: 24/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.4597e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_2_23_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_23<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.461e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_2_23_24 -> attn_block_2_23_24	[pos="e,1.4599e+05,430 1.4599e+05,513.77 1.4599e+05,513.77 1.4599e+05,440 1.4599e+05,440"];
			}
			subgraph cluster_layer3_24 {
				graph [bb="1.5193e+05,386,1.7726e+05,575",
					fontsize=8,
					label="Layer 3 Attention",
					lheight=0.12,
					lp="1.646e+05,566.5",
					lwidth=0.97
				];
				attn_block_3_0_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_0<br/>Block: 1/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.7029e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_3_0_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_0<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.7038e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_3_0_24 -> attn_block_3_0_24	[pos="e,1.7029e+05,430 1.7029e+05,513.77 1.7029e+05,513.77 1.7029e+05,440 1.7029e+05,440"];
				attn_block_3_1_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_1<br/>Block: 2/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.6933e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_3_1_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_1<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.6933e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_3_1_24 -> attn_block_3_1_24	[pos="e,1.6933e+05,430 1.6933e+05,513.77 1.6933e+05,513.77 1.6933e+05,440 1.6933e+05,440"];
				attn_block_3_2_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_2<br/>Block: 3/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.6837e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_3_2_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_2<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.6828e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_3_2_24 -> attn_block_3_2_24	[pos="e,1.6837e+05,430 1.6837e+05,513.77 1.6837e+05,513.77 1.6837e+05,440 1.6837e+05,440"];
				attn_block_3_3_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_3<br/>Block: 4/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.6741e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_3_3_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_3<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.6723e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_3_3_24 -> attn_block_3_3_24	[pos="e,1.6736e+05,430 1.6736e+05,513.77 1.6736e+05,513.77 1.6736e+05,440 1.6736e+05,440"];
				attn_block_3_4_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_4<br/>Block: 5/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.6636e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_3_4_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_4<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.6618e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_3_4_24 -> attn_block_3_4_24	[pos="e,1.6631e+05,430 1.6631e+05,513.77 1.6631e+05,513.77 1.6631e+05,440 1.6631e+05,440"];
				attn_block_3_5_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_5<br/>Block: 6/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.6531e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_3_5_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_5<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.6513e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_3_5_24 -> attn_block_3_5_24	[pos="e,1.6526e+05,430 1.6526e+05,513.77 1.6526e+05,513.77 1.6526e+05,440 1.6526e+05,440"];
				attn_block_3_6_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_6<br/>Block: 7/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.6435e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_3_6_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_6<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.6408e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_3_6_24 -> attn_block_3_6_24	[pos="e,1.6426e+05,430 1.6426e+05,513.77 1.6426e+05,513.77 1.6426e+05,440 1.6426e+05,440"];
				attn_block_3_7_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_7<br/>Block: 8/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.6325e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_3_7_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_7<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.6303e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_3_7_24 -> attn_block_3_7_24	[pos="e,1.6319e+05,430 1.6319e+05,513.77 1.6319e+05,513.77 1.6319e+05,440 1.6319e+05,440"];
				attn_block_3_8_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_8<br/>Block: 9/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.6218e+05,412",
					shape=rectangle,
					width=11.861];
				kv_cache_3_8_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_8<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.6198e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_3_8_24 -> attn_block_3_8_24	[pos="e,1.6212e+05,430 1.6212e+05,513.77 1.6212e+05,513.77 1.6212e+05,440 1.6212e+05,440"];
				attn_block_3_9_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_9<br/>Block: 10/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.6112e+05,412",
					shape=rectangle,
					width=11.931];
				kv_cache_3_9_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_9<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.6093e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.337];
				kv_cache_3_9_24 -> attn_block_3_9_24	[pos="e,1.6107e+05,430 1.6107e+05,513.77 1.6107e+05,513.77 1.6107e+05,440 1.6107e+05,440"];
				attn_block_3_10_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_10<br/>Block: 11/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.6006e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_3_10_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_10<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.5988e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_3_10_24 -> attn_block_3_10_24	[pos="e,1.6001e+05,430 1.6001e+05,513.77 1.6001e+05,513.77 1.6001e+05,440 1.6001e+05,440"];
				attn_block_3_11_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_11<br/>Block: 12/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.59e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_3_11_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_11<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.5882e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_3_11_24 -> attn_block_3_11_24	[pos="e,1.5895e+05,430 1.5895e+05,513.77 1.5895e+05,513.77 1.5895e+05,440 1.5895e+05,440"];
				attn_block_3_12_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_12<br/>Block: 13/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.5794e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_3_12_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_12<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.5776e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_3_12_24 -> attn_block_3_12_24	[pos="e,1.5789e+05,430 1.5789e+05,513.77 1.5789e+05,513.77 1.5789e+05,440 1.5789e+05,440"];
				attn_block_3_13_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_13<br/>Block: 14/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.5688e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_3_13_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_13<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.567e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_3_13_24 -> attn_block_3_13_24	[pos="e,1.5683e+05,430 1.5683e+05,513.77 1.5683e+05,513.77 1.5683e+05,440 1.5683e+05,440"];
				attn_block_3_14_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_14<br/>Block: 15/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.5582e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_3_14_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_14<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.5564e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_3_14_24 -> attn_block_3_14_24	[pos="e,1.5577e+05,430 1.5577e+05,513.77 1.5577e+05,513.77 1.5577e+05,440 1.5577e+05,440"];
				attn_block_3_15_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_15<br/>Block: 16/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.5476e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_3_15_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_15<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.5458e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_3_15_24 -> attn_block_3_15_24	[pos="e,1.5471e+05,430 1.5471e+05,513.77 1.5471e+05,513.77 1.5471e+05,440 1.5471e+05,440"];
				attn_block_3_16_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_16<br/>Block: 17/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.537e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_3_16_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_16<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.5352e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_3_16_24 -> attn_block_3_16_24	[pos="e,1.5365e+05,430 1.5365e+05,513.77 1.5365e+05,513.77 1.5365e+05,440 1.5365e+05,440"];
				attn_block_3_17_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_17<br/>Block: 18/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.5264e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_3_17_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_17<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.5246e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_3_17_24 -> attn_block_3_17_24	[pos="e,1.5259e+05,430 1.5259e+05,513.77 1.5259e+05,513.77 1.5259e+05,440 1.5259e+05,440"];
				attn_block_3_18_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_18<br/>Block: 19/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.7655e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_3_18_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_18<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.7673e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_3_18_24 -> attn_block_3_18_24	[pos="e,1.766e+05,430 1.766e+05,513.77 1.766e+05,513.77 1.766e+05,440 1.766e+05,440"];
				attn_block_3_19_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_19<br/>Block: 20/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.755e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_3_19_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_19<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.7567e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_3_19_24 -> attn_block_3_19_24	[pos="e,1.7554e+05,430 1.7554e+05,513.77 1.7554e+05,513.77 1.7554e+05,440 1.7554e+05,440"];
				attn_block_3_20_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_20<br/>Block: 21/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.7444e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_3_20_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_20<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.7461e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_3_20_24 -> attn_block_3_20_24	[pos="e,1.7448e+05,430 1.7448e+05,513.77 1.7448e+05,513.77 1.7448e+05,440 1.7448e+05,440"];
				attn_block_3_21_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_21<br/>Block: 22/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.7339e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_3_21_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_21<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.7355e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_3_21_24 -> attn_block_3_21_24	[pos="e,1.7343e+05,430 1.7343e+05,513.77 1.7343e+05,513.77 1.7343e+05,440 1.7343e+05,440"];
				attn_block_3_22_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_22<br/>Block: 23/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.7234e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_3_22_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_22<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.7249e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_3_22_24 -> attn_block_3_22_24	[pos="e,1.7237e+05,430 1.7237e+05,513.77 1.7237e+05,513.77 1.7237e+05,440 1.7237e+05,440"];
				attn_block_3_23_24	[fillcolor=lightgreen,
					height=0.5,
					label="<b>Attention Block</b><br/>GPU: pool_gpu_23<br/>Block: 24/24<br/>Input: [batch=1024, block_seq=ceil(seq/24), hidden=4096]<br/>Output: [\
batch=1024, block_seq=ceil(seq/24), hidden=4096]",
					pos="1.713e+05,412",
					shape=rectangle,
					width=12];
				kv_cache_3_23_24	[fillcolor=lightyellow,
					height=0.5,
					label="<b>KV Cache Share</b><br/>GPU: pool_gpu_23<br/>Replicates K,V across all GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
					pos="1.7144e+05,532",
					shape=parallelogram,
					style=dashed,
					width=14.457];
				kv_cache_3_23_24 -> attn_block_3_23_24	[pos="e,1.7132e+05,430 1.7132e+05,513.77 1.7132e+05,513.77 1.7132e+05,440 1.7132e+05,440"];
			}
		}
		seq_router	[fillcolor=lightyellow,
			height=0.5,
			label="<b>Sequence Router</b><br/>Routes attention based on sequence length<br/>Short: base GPUs<br/>Long: attention pool",
			pos="92468,532",
			shape=parallelogram,
			width=13.282];
	}
	subgraph cluster_layer0_ffn {
		graph [bb="8,217,9062,579",
			fontsize=12,
			label="Layer 0 FFN (Base GPUs)",
			lheight=0.18,
			lp="4535,568.5",
			lwidth=2.18,
			style=rounded
		];
		l0_ffn_up_0	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Up Projection</b><br/>GPU: base_gpu_0<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, ffn_dim=\
2048]",
			pos="8687,532",
			shape=rectangle,
			width=9.0278];
		l0_ffn_down_0	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Down Projection</b><br/>GPU: base_gpu_0<br/>Input: [batch=1024, seq=?, ffn_dim=2048]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="8646,412",
			shape=rectangle,
			width=9.1944];
		l0_ffn_up_0 -> l0_ffn_down_0	[pos="e,8485,430 8485,513.77 8485,513.77 8485,440 8485,440"];
		l0_ffn_up_0 -> l0_ffn_down_0	[pos="e,8608,430 8608,513.77 8608,513.77 8608,440 8608,440"];
		l0_ffn_up_0 -> l0_ffn_down_0	[pos="e,8731,430 8731,513.77 8731,513.77 8731,440 8731,440"];
		l0_ffn_up_0 -> l0_ffn_down_0	[pos="e,8854,430 8854,513.77 8854,513.77 8854,440 8854,440"];
		l0_ffn_res_0	[fillcolor=lightgray,
			height=0.5,
			label="<b>FFN Residual Add</b><br/>GPU: base_gpu_0<br/>Input: [batch=1024, seq=?, hidden=512] × 2<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="8487,315",
			shape=diamond,
			width=15.193];
		l0_ffn_down_0 -> l0_ffn_res_0	[pos="e,8447.4,331.86 8447.4,393.76 8447.4,393.76 8447.4,341.86 8447.4,341.86"];
		l0_ffn_down_0 -> l0_ffn_res_0	[pos="e,8579.8,329.98 8579.8,393.76 8579.8,393.76 8579.8,339.98 8579.8,339.98"];
		l0_ffn_down_0 -> l0_ffn_res_0	[pos="e,8712.2,325.66 8712.2,393.76 8712.2,393.76 8712.2,335.66 8712.2,335.66"];
		l0_ffn_down_0 -> l0_ffn_res_0	[pos="e,8844.6,321.51 8844.6,393.76 8844.6,393.76 8844.6,331.51 8844.6,331.51"];
		l0_ffn_ln_0	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Layer Norm</b><br/>GPU: base_gpu_0<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=512]",
			pos="8612,243",
			shape=rectangle,
			width=8.7917];
		l0_ffn_res_0 -> l0_ffn_ln_0	[pos="e,8353,261.2 8353,301.12 8353,301.12 8353,271.2 8353,271.2"];
		l0_ffn_res_0 -> l0_ffn_ln_0	[pos="e,8410.6,261.13 8410.6,299.38 8410.6,299.38 8410.6,271.13 8410.6,271.13"];
		l0_ffn_res_0 -> l0_ffn_ln_0	[pos="e,8468.1,261.02 8468.1,297.57 8468.1,297.57 8468.1,271.02 8468.1,271.02"];
		l0_ffn_res_0 -> l0_ffn_ln_0	[pos="e,8525.7,261.2 8525.7,297.94 8525.7,297.94 8525.7,271.2 8525.7,271.2"];
		l0_ffn_ln_0 -> l0_ffn_up_0	[pos="e,9012,518 8928.8,246 8994.6,246 9044.4,246 9044.4,246 9044.4,246 9044.4,518 9044.4,518 9044.4,518 9022,518 9022,518"];
		l0_ffn_ln_0 -> l0_ffn_up_0	[pos="e,9012.2,522 8928.8,243 8999.9,243 9054.8,243 9054.8,243 9054.8,243 9054.8,522 9054.8,522 9054.8,522 9022.2,522 9022.2,522"];
		l0_ffn_ln_0 -> l0_ffn_up_0	[pos="e,9012.2,526 8928.6,239 9005.1,239 9065.2,239 9065.2,239 9065.2,239 9065.2,526 9065.2,526 9065.2,526 9022.2,526 9022.2,526"];
		l0_ffn_ln_0 -> l0_ffn_up_0	[pos="e,9012.3,530 8928.6,235 9010.2,235 9075.6,235 9075.6,235 9075.6,235 9075.6,530 9075.6,530 9075.6,530 9022.3,530 9022.3,530"];
		l0_ffn_ln_0 -> l0_ffn_res_0	[pos="e,8583.2,299.99 8583.2,261.17 8583.2,261.17 8583.2,289.99 8583.2,289.99"];
		l0_ffn_ln_0 -> l0_ffn_res_0	[pos="e,8640.8,301.84 8640.8,261.17 8640.8,261.17 8640.8,291.84 8640.8,291.84"];
		l0_ffn_ln_0 -> l0_ffn_res_0	[pos="e,8698.3,303.59 8698.3,261.17 8698.3,261.17 8698.3,293.59 8698.3,293.59"];
		l0_ffn_ln_0 -> l0_ffn_res_0	[pos="e,8755.9,305.65 8755.9,261.17 8755.9,261.17 8755.9,295.65 8755.9,295.65"];
		l0_ffn_up_1	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Up Projection</b><br/>GPU: base_gpu_1<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, ffn_dim=\
2048]",
			pos="3110,532",
			shape=rectangle,
			width=9.0278];
		l0_ffn_down_1	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Down Projection</b><br/>GPU: base_gpu_1<br/>Input: [batch=1024, seq=?, ffn_dim=2048]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="2935,412",
			shape=rectangle,
			width=9.1944];
		l0_ffn_up_1 -> l0_ffn_down_1	[pos="e,2881.2,430 2881.2,513.77 2881.2,513.77 2881.2,440 2881.2,440"];
		l0_ffn_up_1 -> l0_ffn_down_1	[pos="e,2977.4,430 2977.4,513.77 2977.4,513.77 2977.4,440 2977.4,440"];
		l0_ffn_up_1 -> l0_ffn_down_1	[pos="e,3073.6,430 3073.6,513.77 3073.6,513.77 3073.6,440 3073.6,440"];
		l0_ffn_up_1 -> l0_ffn_down_1	[pos="e,3169.8,430 3169.8,513.77 3169.8,513.77 3169.8,440 3169.8,440"];
		l0_ffn_res_1	[fillcolor=lightgray,
			height=0.5,
			label="<b>FFN Residual Add</b><br/>GPU: base_gpu_1<br/>Input: [batch=1024, seq=?, hidden=512] × 2<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="2827,315",
			shape=diamond,
			width=15.193];
		l0_ffn_down_1 -> l0_ffn_res_1	[pos="e,2736.4,330.29 2736.4,393.76 2736.4,393.76 2736.4,340.29 2736.4,340.29"];
		l0_ffn_down_1 -> l0_ffn_res_1	[pos="e,2868.8,331.86 2868.8,393.76 2868.8,393.76 2868.8,341.86 2868.8,341.86"];
		l0_ffn_down_1 -> l0_ffn_res_1	[pos="e,3001.2,327.32 3001.2,393.76 3001.2,393.76 3001.2,337.32 3001.2,337.32"];
		l0_ffn_down_1 -> l0_ffn_res_1	[pos="e,3133.6,323.35 3133.6,393.76 3133.6,393.76 3133.6,333.35 3133.6,333.35"];
		l0_ffn_ln_1	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Layer Norm</b><br/>GPU: base_gpu_1<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=512]",
			pos="3110,243",
			shape=rectangle,
			width=8.7917];
		l0_ffn_res_1 -> l0_ffn_ln_1	[pos="e,2858,261.2 2858,297.94 2858,297.94 2858,271.2 2858,271.2"];
		l0_ffn_res_1 -> l0_ffn_ln_1	[pos="e,2922.5,261.22 2922.5,300.08 2922.5,300.08 2922.5,271.22 2922.5,271.22"];
		l0_ffn_res_1 -> l0_ffn_ln_1	[pos="e,2987,261.17 2987,302.13 2987,302.13 2987,271.17 2987,271.17"];
		l0_ffn_res_1 -> l0_ffn_ln_1	[pos="e,3051.5,261.21 3051.5,304.38 3051.5,304.38 3051.5,271.21 3051.5,271.21"];
		l0_ffn_ln_1 -> l0_ffn_up_1	[pos="e,3379.4,513.93 3379.4,261.08 3379.4,261.08 3379.4,503.93 3379.4,503.93"];
		l0_ffn_ln_1 -> l0_ffn_up_1	[pos="e,3384.8,513.93 3384.8,261.08 3384.8,261.08 3384.8,503.93 3384.8,503.93"];
		l0_ffn_ln_1 -> l0_ffn_up_1	[pos="e,3390.3,513.93 3390.3,261.08 3390.3,261.08 3390.3,503.93 3390.3,503.93"];
		l0_ffn_ln_1 -> l0_ffn_up_1	[pos="e,3395.7,513.93 3395.7,261.08 3395.7,261.08 3395.7,503.93 3395.7,503.93"];
		l0_ffn_ln_1 -> l0_ffn_res_1	[pos="e,3116,306.43 3116,261.17 3116,261.17 3116,296.43 3116,296.43"];
		l0_ffn_ln_1 -> l0_ffn_res_1	[pos="e,3180.5,308.6 3180.5,261.17 3180.5,261.17 3180.5,298.6 3180.5,298.6"];
		l0_ffn_ln_1 -> l0_ffn_res_1	[pos="e,3245,310.5 3245,261.17 3245,261.17 3245,300.5 3245,300.5"];
		l0_ffn_ln_1 -> l0_ffn_res_1	[pos="e,3309.5,312.79 3309.5,261.17 3309.5,261.17 3309.5,302.79 3309.5,302.79"];
		l0_ffn_up_2	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Up Projection</b><br/>GPU: base_gpu_2<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, ffn_dim=\
2048]",
			pos="402,532",
			shape=rectangle,
			width=9.0278];
		l0_ffn_down_2	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Down Projection</b><br/>GPU: base_gpu_2<br/>Input: [batch=1024, seq=?, ffn_dim=2048]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="523,412",
			shape=rectangle,
			width=9.1944];
		l0_ffn_up_2 -> l0_ffn_down_2	[pos="e,299,430 299,513.77 299,513.77 299,440 299,440"];
		l0_ffn_up_2 -> l0_ffn_down_2	[pos="e,406,430 406,513.77 406,513.77 406,440 406,440"];
		l0_ffn_up_2 -> l0_ffn_down_2	[pos="e,513,430 513,513.77 513,513.77 513,440 513,440"];
		l0_ffn_up_2 -> l0_ffn_down_2	[pos="e,620,430 620,513.77 620,513.77 620,440 620,440"];
		l0_ffn_res_2	[fillcolor=lightgray,
			height=0.5,
			label="<b>FFN Residual Add</b><br/>GPU: base_gpu_2<br/>Input: [batch=1024, seq=?, hidden=512] × 2<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="583,315",
			shape=diamond,
			width=15.193];
		l0_ffn_down_2 -> l0_ffn_res_2	[pos="e,324.4,324.61 324.4,393.76 324.4,393.76 324.4,334.61 324.4,334.61"];
		l0_ffn_down_2 -> l0_ffn_res_2	[pos="e,456.8,329.07 456.8,393.76 456.8,393.76 456.8,339.07 456.8,339.07"];
		l0_ffn_down_2 -> l0_ffn_res_2	[pos="e,589.2,332.84 589.2,393.76 589.2,393.76 589.2,342.84 589.2,342.84"];
		l0_ffn_down_2 -> l0_ffn_res_2	[pos="e,721.6,328.48 721.6,393.76 721.6,393.76 721.6,338.48 721.6,338.48"];
		l0_ffn_ln_2	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Layer Norm</b><br/>GPU: base_gpu_2<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=512]",
			pos="583,243",
			shape=rectangle,
			width=8.7917];
		l0_ffn_res_2 -> l0_ffn_ln_2	[pos="e,319.25,261.28 319.25,305.59 319.25,305.59 319.25,271.28 319.25,271.28"];
		l0_ffn_res_2 -> l0_ffn_ln_2	[pos="e,372,261.17 372,303.75 372,303.75 372,271.17 372,271.17"];
		l0_ffn_res_2 -> l0_ffn_ln_2	[pos="e,424.75,261.17 424.75,302.13 424.75,302.13 424.75,271.17 424.75,271.17"];
		l0_ffn_res_2 -> l0_ffn_ln_2	[pos="e,477.5,261.13 477.5,300.43 477.5,300.43 477.5,271.13 477.5,271.13"];
		l0_ffn_ln_2 -> l0_ffn_up_2	[pos="e,76.87,521 266.27,253 142.14,253 28.851,253 28.851,253 28.851,253 28.851,521 28.851,521 28.851,521 66.87,521 66.87,521"];
		l0_ffn_ln_2 -> l0_ffn_up_2	[pos="e,76.957,528 266.23,246 138.9,246 21.651,246 21.651,246 21.651,246 21.651,528 21.651,528 21.651,528 66.957,528 66.957,528"];
		l0_ffn_ln_2 -> l0_ffn_up_2	[pos="e,76.717,535 266.31,239 135.76,239 14.451,239 14.451,239 14.451,239 14.451,535 14.451,535 14.451,535 66.717,535 66.717,535"];
		l0_ffn_ln_2 -> l0_ffn_up_2	[pos="e,76.915,542 266.49,232 132.71,232 7.2507,232 7.2507,232 7.2507,232 7.2507,542 7.2507,542 7.2507,542 66.915,542 66.915,542"];
		l0_ffn_ln_2 -> l0_ffn_res_2	[pos="e,530.25,298.56 530.25,261.17 530.25,261.17 530.25,288.56 530.25,288.56"];
		l0_ffn_ln_2 -> l0_ffn_res_2	[pos="e,583,296.59 583,261.17 583,261.17 583,286.59 583,286.59"];
		l0_ffn_ln_2 -> l0_ffn_res_2	[pos="e,635.75,298.56 635.75,261.17 635.75,261.17 635.75,288.56 635.75,288.56"];
		l0_ffn_ln_2 -> l0_ffn_res_2	[pos="e,688.5,300.46 688.5,261.17 688.5,261.17 688.5,290.46 688.5,290.46"];
		l0_ffn_up_3	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Up Projection</b><br/>GPU: base_gpu_3<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, ffn_dim=\
2048]",
			pos="4869,532",
			shape=rectangle,
			width=9.0278];
		l0_ffn_down_3	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Down Projection</b><br/>GPU: base_gpu_3<br/>Input: [batch=1024, seq=?, ffn_dim=2048]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="5003,412",
			shape=rectangle,
			width=9.1944];
		l0_ffn_up_3 -> l0_ffn_down_3	[pos="e,4776.4,430 4776.4,513.77 4776.4,513.77 4776.4,440 4776.4,440"];
		l0_ffn_up_3 -> l0_ffn_down_3	[pos="e,4880.8,430 4880.8,513.77 4880.8,513.77 4880.8,440 4880.8,440"];
		l0_ffn_up_3 -> l0_ffn_down_3	[pos="e,4985.2,430 4985.2,513.77 4985.2,513.77 4985.2,440 4985.2,440"];
		l0_ffn_up_3 -> l0_ffn_down_3	[pos="e,5089.6,430 5089.6,513.77 5089.6,513.77 5089.6,440 5089.6,440"];
		l0_ffn_res_3	[fillcolor=lightgray,
			height=0.5,
			label="<b>FFN Residual Add</b><br/>GPU: base_gpu_3<br/>Input: [batch=1024, seq=?, hidden=512] × 2<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="5111,315",
			shape=diamond,
			width=15.193];
		l0_ffn_down_3 -> l0_ffn_res_3	[pos="e,4804.4,323.35 4804.4,393.76 4804.4,393.76 4804.4,333.35 4804.4,333.35"];
		l0_ffn_down_3 -> l0_ffn_res_3	[pos="e,4936.8,327.32 4936.8,393.76 4936.8,393.76 4936.8,337.32 4936.8,337.32"];
		l0_ffn_down_3 -> l0_ffn_res_3	[pos="e,5069.2,331.86 5069.2,393.76 5069.2,393.76 5069.2,341.86 5069.2,341.86"];
		l0_ffn_down_3 -> l0_ffn_res_3	[pos="e,5201.6,330.29 5201.6,393.76 5201.6,393.76 5201.6,340.29 5201.6,340.29"];
		l0_ffn_ln_3	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Layer Norm</b><br/>GPU: base_gpu_3<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=512]",
			pos="5111,243",
			shape=rectangle,
			width=8.7917];
		l0_ffn_res_3 -> l0_ffn_ln_3	[pos="e,4852,261.12 4852,305.29 4852,305.29 4852,271.12 4852,271.12"];
		l0_ffn_res_3 -> l0_ffn_ln_3	[pos="e,4909.6,261.01 4909.6,303.43 4909.6,303.43 4909.6,271.01 4909.6,271.01"];
		l0_ffn_res_3 -> l0_ffn_ln_3	[pos="e,4967.1,261.1 4967.1,301.46 4967.1,301.46 4967.1,271.1 4967.1,271.1"];
		l0_ffn_res_3 -> l0_ffn_ln_3	[pos="e,5024.7,261.05 5024.7,299.73 5024.7,299.73 5024.7,271.05 5024.7,271.05"];
		l0_ffn_ln_3 -> l0_ffn_up_3	[pos="e,4560,513.69 4794.5,253 4671.7,253 4560,253 4560,253 4560,253 4560,503.69 4560,503.69"];
		l0_ffn_ln_3 -> l0_ffn_up_3	[pos="e,4556,513.67 4794.2,246 4669.7,246 4556,246 4556,246 4556,246 4556,503.67 4556,503.67"];
		l0_ffn_ln_3 -> l0_ffn_up_3	[pos="e,4552,513.67 4794.4,239 4668,239 4552,239 4552,239 4552,239 4552,503.67 4552,503.67"];
		l0_ffn_ln_3 -> l0_ffn_up_3	[pos="e,4548,513.69 4794.1,232 4666.1,232 4548,232 4548,232 4548,232 4548,503.69 4548,503.69"];
		l0_ffn_ln_3 -> l0_ffn_res_3	[pos="e,5082.2,297.58 5082.2,261.17 5082.2,261.17 5082.2,287.58 5082.2,287.58"];
		l0_ffn_ln_3 -> l0_ffn_res_3	[pos="e,5139.8,297.58 5139.8,261.17 5139.8,261.17 5139.8,287.58 5139.8,287.58"];
		l0_ffn_ln_3 -> l0_ffn_res_3	[pos="e,5197.3,299.52 5197.3,261.17 5197.3,261.17 5197.3,289.52 5197.3,289.52"];
		l0_ffn_ln_3 -> l0_ffn_res_3	[pos="e,5254.9,301.38 5254.9,261.17 5254.9,261.17 5254.9,291.38 5254.9,291.38"];
		l0_ffn_up_4	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Up Projection</b><br/>GPU: base_gpu_4<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, ffn_dim=\
2048]",
			pos="6560,532",
			shape=rectangle,
			width=9.0278];
		l0_ffn_down_4	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Down Projection</b><br/>GPU: base_gpu_4<br/>Input: [batch=1024, seq=?, ffn_dim=2048]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="6331,412",
			shape=rectangle,
			width=9.1944];
		l0_ffn_up_4 -> l0_ffn_down_4	[pos="e,6320.4,430 6320.4,513.77 6320.4,513.77 6320.4,440 6320.4,440"];
		l0_ffn_up_4 -> l0_ffn_down_4	[pos="e,6405.8,430 6405.8,513.77 6405.8,513.77 6405.8,440 6405.8,440"];
		l0_ffn_up_4 -> l0_ffn_down_4	[pos="e,6491.2,430 6491.2,513.77 6491.2,513.77 6491.2,440 6491.2,440"];
		l0_ffn_up_4 -> l0_ffn_down_4	[pos="e,6576.6,430 6576.6,513.77 6576.6,513.77 6576.6,440 6576.6,440"];
		l0_ffn_res_4	[fillcolor=lightgray,
			height=0.5,
			label="<b>FFN Residual Add</b><br/>GPU: base_gpu_4<br/>Input: [batch=1024, seq=?, hidden=512] × 2<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="6223,315",
			shape=diamond,
			width=15.193];
		l0_ffn_down_4 -> l0_ffn_res_4	[pos="e,6132.4,330.29 6132.4,393.76 6132.4,393.76 6132.4,340.29 6132.4,340.29"];
		l0_ffn_down_4 -> l0_ffn_res_4	[pos="e,6264.8,331.86 6264.8,393.76 6264.8,393.76 6264.8,341.86 6264.8,341.86"];
		l0_ffn_down_4 -> l0_ffn_res_4	[pos="e,6397.2,327.32 6397.2,393.76 6397.2,393.76 6397.2,337.32 6397.2,337.32"];
		l0_ffn_down_4 -> l0_ffn_res_4	[pos="e,6529.6,323.35 6529.6,393.76 6529.6,393.76 6529.6,333.35 6529.6,333.35"];
		l0_ffn_ln_4	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Layer Norm</b><br/>GPU: base_gpu_4<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=512]",
			pos="6506,243",
			shape=rectangle,
			width=8.7917];
		l0_ffn_res_4 -> l0_ffn_ln_4	[pos="e,6254,261.2 6254,297.94 6254,297.94 6254,271.2 6254,271.2"];
		l0_ffn_res_4 -> l0_ffn_ln_4	[pos="e,6318.5,261.22 6318.5,300.08 6318.5,300.08 6318.5,271.22 6318.5,271.22"];
		l0_ffn_res_4 -> l0_ffn_ln_4	[pos="e,6383,261.17 6383,302.13 6383,302.13 6383,271.17 6383,271.17"];
		l0_ffn_res_4 -> l0_ffn_ln_4	[pos="e,6447.5,261.21 6447.5,304.38 6447.5,304.38 6447.5,271.21 6447.5,271.21"];
		l0_ffn_ln_4 -> l0_ffn_up_4	[pos="e,6775.4,513.93 6775.4,261.08 6775.4,261.08 6775.4,503.93 6775.4,503.93"];
		l0_ffn_ln_4 -> l0_ffn_up_4	[pos="e,6780.8,513.93 6780.8,261.08 6780.8,261.08 6780.8,503.93 6780.8,503.93"];
		l0_ffn_ln_4 -> l0_ffn_up_4	[pos="e,6786.3,513.93 6786.3,261.08 6786.3,261.08 6786.3,503.93 6786.3,503.93"];
		l0_ffn_ln_4 -> l0_ffn_up_4	[pos="e,6791.7,513.93 6791.7,261.08 6791.7,261.08 6791.7,503.93 6791.7,503.93"];
		l0_ffn_ln_4 -> l0_ffn_res_4	[pos="e,6512,306.43 6512,261.17 6512,261.17 6512,296.43 6512,296.43"];
		l0_ffn_ln_4 -> l0_ffn_res_4	[pos="e,6576.5,308.6 6576.5,261.17 6576.5,261.17 6576.5,298.6 6576.5,298.6"];
		l0_ffn_ln_4 -> l0_ffn_res_4	[pos="e,6641,310.5 6641,261.17 6641,261.17 6641,300.5 6641,300.5"];
		l0_ffn_ln_4 -> l0_ffn_res_4	[pos="e,6705.5,312.79 6705.5,261.17 6705.5,261.17 6705.5,302.79 6705.5,302.79"];
		l0_ffn_up_5	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Up Projection</b><br/>GPU: base_gpu_5<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, ffn_dim=\
2048]",
			pos="4134,532",
			shape=rectangle,
			width=9.0278];
		l0_ffn_down_5	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Down Projection</b><br/>GPU: base_gpu_5<br/>Input: [batch=1024, seq=?, ffn_dim=2048]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="4067,412",
			shape=rectangle,
			width=9.1944];
		l0_ffn_up_5 -> l0_ffn_down_5	[pos="e,3926.8,430 3926.8,513.77 3926.8,513.77 3926.8,440 3926.8,440"];
		l0_ffn_up_5 -> l0_ffn_down_5	[pos="e,4044.6,430 4044.6,513.77 4044.6,513.77 4044.6,440 4044.6,440"];
		l0_ffn_up_5 -> l0_ffn_down_5	[pos="e,4162.4,430 4162.4,513.77 4162.4,513.77 4162.4,440 4162.4,440"];
		l0_ffn_up_5 -> l0_ffn_down_5	[pos="e,4280.2,430 4280.2,513.77 4280.2,513.77 4280.2,440 4280.2,440"];
		l0_ffn_res_5	[fillcolor=lightgray,
			height=0.5,
			label="<b>FFN Residual Add</b><br/>GPU: base_gpu_5<br/>Input: [batch=1024, seq=?, hidden=512] × 2<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="3959,315",
			shape=diamond,
			width=15.193];
		l0_ffn_down_5 -> l0_ffn_res_5	[pos="e,3868.4,330.29 3868.4,393.76 3868.4,393.76 3868.4,340.29 3868.4,340.29"];
		l0_ffn_down_5 -> l0_ffn_res_5	[pos="e,4000.8,331.86 4000.8,393.76 4000.8,393.76 4000.8,341.86 4000.8,341.86"];
		l0_ffn_down_5 -> l0_ffn_res_5	[pos="e,4133.2,327.32 4133.2,393.76 4133.2,393.76 4133.2,337.32 4133.2,337.32"];
		l0_ffn_down_5 -> l0_ffn_res_5	[pos="e,4265.6,323.35 4265.6,393.76 4265.6,393.76 4265.6,333.35 4265.6,333.35"];
		l0_ffn_ln_5	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Layer Norm</b><br/>GPU: base_gpu_5<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=512]",
			pos="4210,243",
			shape=rectangle,
			width=8.7917];
		l0_ffn_res_5 -> l0_ffn_ln_5	[pos="e,3961.5,261.41 3961.5,296.83 3961.5,296.83 3961.5,271.41 3961.5,271.41"];
		l0_ffn_res_5 -> l0_ffn_ln_5	[pos="e,4029.6,261.22 4029.6,299.02 4029.6,299.02 4029.6,271.22 4029.6,271.22"];
		l0_ffn_res_5 -> l0_ffn_ln_5	[pos="e,4097.6,261.1 4097.6,301.46 4097.6,301.46 4097.6,271.1 4097.6,271.1"];
		l0_ffn_res_5 -> l0_ffn_ln_5	[pos="e,4165.7,261.17 4165.7,303.75 4165.7,303.75 4165.7,271.17 4165.7,271.17"];
		l0_ffn_ln_5 -> l0_ffn_up_5	[pos="e,4459.3,521 4508.2,261.24 4508.2,323.09 4508.2,521 4508.2,521 4508.2,521 4469.3,521 4469.3,521"];
		l0_ffn_ln_5 -> l0_ffn_up_5	[pos="e,4459.3,528 4510.5,261.26 4510.5,324.16 4510.5,528 4510.5,528 4510.5,528 4469.3,528 4469.3,528"];
		l0_ffn_ln_5 -> l0_ffn_up_5	[pos="e,4459.3,535 4512.8,261.27 4512.8,325.19 4512.8,535 4512.8,535 4512.8,535 4469.3,535 4469.3,535"];
		l0_ffn_ln_5 -> l0_ffn_up_5	[pos="e,4459.3,542 4515.1,261.25 4515.1,326.17 4515.1,542 4515.1,542 4515.1,542 4469.3,542 4469.3,542"];
		l0_ffn_ln_5 -> l0_ffn_res_5	[pos="e,4233.7,305.65 4233.7,261.17 4233.7,261.17 4233.7,295.65 4233.7,295.65"];
		l0_ffn_ln_5 -> l0_ffn_res_5	[pos="e,4301.8,308.26 4301.8,261.17 4301.8,261.17 4301.8,298.26 4301.8,298.26"];
		l0_ffn_ln_5 -> l0_ffn_res_5	[pos="e,4369.8,310.5 4369.8,261.17 4369.8,261.17 4369.8,300.5 4369.8,300.5"];
		l0_ffn_ln_5 -> l0_ffn_res_5	[pos="e,4437.9,312.34 4437.9,261.17 4437.9,261.17 4437.9,302.34 4437.9,302.34"];
		l0_ffn_up_6	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Up Projection</b><br/>GPU: base_gpu_6<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, ffn_dim=\
2048]",
			pos="2032,532",
			shape=rectangle,
			width=9.0278];
		l0_ffn_down_6	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Down Projection</b><br/>GPU: base_gpu_6<br/>Input: [batch=1024, seq=?, ffn_dim=2048]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="1803,412",
			shape=rectangle,
			width=9.1944];
		l0_ffn_up_6 -> l0_ffn_down_6	[pos="e,1792.4,430 1792.4,513.77 1792.4,513.77 1792.4,440 1792.4,440"];
		l0_ffn_up_6 -> l0_ffn_down_6	[pos="e,1877.8,430 1877.8,513.77 1877.8,513.77 1877.8,440 1877.8,440"];
		l0_ffn_up_6 -> l0_ffn_down_6	[pos="e,1963.2,430 1963.2,513.77 1963.2,513.77 1963.2,440 1963.2,440"];
		l0_ffn_up_6 -> l0_ffn_down_6	[pos="e,2048.6,430 2048.6,513.77 2048.6,513.77 2048.6,440 2048.6,440"];
		l0_ffn_res_6	[fillcolor=lightgray,
			height=0.5,
			label="<b>FFN Residual Add</b><br/>GPU: base_gpu_6<br/>Input: [batch=1024, seq=?, hidden=512] × 2<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="1695,315",
			shape=diamond,
			width=15.193];
		l0_ffn_down_6 -> l0_ffn_res_6	[pos="e,1604.4,330.29 1604.4,393.76 1604.4,393.76 1604.4,340.29 1604.4,340.29"];
		l0_ffn_down_6 -> l0_ffn_res_6	[pos="e,1736.8,331.86 1736.8,393.76 1736.8,393.76 1736.8,341.86 1736.8,341.86"];
		l0_ffn_down_6 -> l0_ffn_res_6	[pos="e,1869.2,327.32 1869.2,393.76 1869.2,393.76 1869.2,337.32 1869.2,337.32"];
		l0_ffn_down_6 -> l0_ffn_res_6	[pos="e,2001.6,323.35 2001.6,393.76 2001.6,393.76 2001.6,333.35 2001.6,333.35"];
		l0_ffn_ln_6	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Layer Norm</b><br/>GPU: base_gpu_6<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=512]",
			pos="1978,243",
			shape=rectangle,
			width=8.7917];
		l0_ffn_res_6 -> l0_ffn_ln_6	[pos="e,1726,261.2 1726,297.94 1726,297.94 1726,271.2 1726,271.2"];
		l0_ffn_res_6 -> l0_ffn_ln_6	[pos="e,1790.5,261.22 1790.5,300.08 1790.5,300.08 1790.5,271.22 1790.5,271.22"];
		l0_ffn_res_6 -> l0_ffn_ln_6	[pos="e,1855,261.17 1855,302.13 1855,302.13 1855,271.17 1855,271.17"];
		l0_ffn_res_6 -> l0_ffn_ln_6	[pos="e,1919.5,261.21 1919.5,304.38 1919.5,304.38 1919.5,271.21 1919.5,271.21"];
		l0_ffn_ln_6 -> l0_ffn_up_6	[pos="e,2247.4,513.93 2247.4,261.08 2247.4,261.08 2247.4,503.93 2247.4,503.93"];
		l0_ffn_ln_6 -> l0_ffn_up_6	[pos="e,2252.8,513.93 2252.8,261.08 2252.8,261.08 2252.8,503.93 2252.8,503.93"];
		l0_ffn_ln_6 -> l0_ffn_up_6	[pos="e,2258.3,513.93 2258.3,261.08 2258.3,261.08 2258.3,503.93 2258.3,503.93"];
		l0_ffn_ln_6 -> l0_ffn_up_6	[pos="e,2263.7,513.93 2263.7,261.08 2263.7,261.08 2263.7,503.93 2263.7,503.93"];
		l0_ffn_ln_6 -> l0_ffn_res_6	[pos="e,1984,306.43 1984,261.17 1984,261.17 1984,296.43 1984,296.43"];
		l0_ffn_ln_6 -> l0_ffn_res_6	[pos="e,2048.5,308.6 2048.5,261.17 2048.5,261.17 2048.5,298.6 2048.5,298.6"];
		l0_ffn_ln_6 -> l0_ffn_res_6	[pos="e,2113,310.5 2113,261.17 2113,261.17 2113,300.5 2113,300.5"];
		l0_ffn_ln_6 -> l0_ffn_res_6	[pos="e,2177.5,312.79 2177.5,261.17 2177.5,261.17 2177.5,302.79 2177.5,302.79"];
		l0_ffn_up_7	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Up Projection</b><br/>GPU: base_gpu_7<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, ffn_dim=\
2048]",
			pos="7692,532",
			shape=rectangle,
			width=9.0278];
		l0_ffn_down_7	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Down Projection</b><br/>GPU: base_gpu_7<br/>Input: [batch=1024, seq=?, ffn_dim=2048]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="7463,412",
			shape=rectangle,
			width=9.1944];
		l0_ffn_up_7 -> l0_ffn_down_7	[pos="e,7452.4,430 7452.4,513.77 7452.4,513.77 7452.4,440 7452.4,440"];
		l0_ffn_up_7 -> l0_ffn_down_7	[pos="e,7537.8,430 7537.8,513.77 7537.8,513.77 7537.8,440 7537.8,440"];
		l0_ffn_up_7 -> l0_ffn_down_7	[pos="e,7623.2,430 7623.2,513.77 7623.2,513.77 7623.2,440 7623.2,440"];
		l0_ffn_up_7 -> l0_ffn_down_7	[pos="e,7708.6,430 7708.6,513.77 7708.6,513.77 7708.6,440 7708.6,440"];
		l0_ffn_res_7	[fillcolor=lightgray,
			height=0.5,
			label="<b>FFN Residual Add</b><br/>GPU: base_gpu_7<br/>Input: [batch=1024, seq=?, hidden=512] × 2<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="7355,315",
			shape=diamond,
			width=15.193];
		l0_ffn_down_7 -> l0_ffn_res_7	[pos="e,7264.4,330.29 7264.4,393.76 7264.4,393.76 7264.4,340.29 7264.4,340.29"];
		l0_ffn_down_7 -> l0_ffn_res_7	[pos="e,7396.8,331.86 7396.8,393.76 7396.8,393.76 7396.8,341.86 7396.8,341.86"];
		l0_ffn_down_7 -> l0_ffn_res_7	[pos="e,7529.2,327.32 7529.2,393.76 7529.2,393.76 7529.2,337.32 7529.2,337.32"];
		l0_ffn_down_7 -> l0_ffn_res_7	[pos="e,7661.6,323.35 7661.6,393.76 7661.6,393.76 7661.6,333.35 7661.6,333.35"];
		l0_ffn_ln_7	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Layer Norm</b><br/>GPU: base_gpu_7<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=512]",
			pos="7721,243",
			shape=rectangle,
			width=8.7917];
		l0_ffn_res_7 -> l0_ffn_ln_7	[pos="e,7459.8,261.13 7459.8,300.43 7459.8,300.43 7459.8,271.13 7459.8,271.13"];
		l0_ffn_res_7 -> l0_ffn_ln_7	[pos="e,7515,261.17 7515,302.13 7515,302.13 7515,271.17 7515,271.17"];
		l0_ffn_res_7 -> l0_ffn_ln_7	[pos="e,7570.3,261.05 7570.3,304.06 7570.3,304.06 7570.3,271.05 7570.3,271.05"];
		l0_ffn_res_7 -> l0_ffn_ln_7	[pos="e,7625.6,261.15 7625.6,305.88 7625.6,305.88 7625.6,271.15 7625.6,271.15"];
		l0_ffn_ln_7 -> l0_ffn_up_7	[pos="e,7907.4,513.93 7907.4,261.08 7907.4,261.08 7907.4,503.93 7907.4,503.93"];
		l0_ffn_ln_7 -> l0_ffn_up_7	[pos="e,7912.8,513.93 7912.8,261.08 7912.8,261.08 7912.8,503.93 7912.8,503.93"];
		l0_ffn_ln_7 -> l0_ffn_up_7	[pos="e,7918.3,513.93 7918.3,261.08 7918.3,261.08 7918.3,503.93 7918.3,503.93"];
		l0_ffn_ln_7 -> l0_ffn_up_7	[pos="e,7923.7,513.93 7923.7,261.08 7923.7,261.08 7923.7,503.93 7923.7,503.93"];
		l0_ffn_ln_7 -> l0_ffn_res_7	[pos="e,7680.9,307.55 7680.9,261.17 7680.9,261.17 7680.9,297.55 7680.9,297.55"];
		l0_ffn_ln_7 -> l0_ffn_res_7	[pos="e,7736.1,309.27 7736.1,261.17 7736.1,261.17 7736.1,299.27 7736.1,299.27"];
		l0_ffn_ln_7 -> l0_ffn_res_7	[pos="e,7791.4,311.34 7791.4,261.17 7791.4,261.17 7791.4,301.34 7791.4,301.34"];
		l0_ffn_ln_7 -> l0_ffn_res_7	[pos="e,7846.7,312.79 7846.7,261.17 7846.7,261.17 7846.7,302.79 7846.7,302.79"];
	}
	subgraph cluster_layer1_ffn {
		graph [bb="15464,217,24518,579",
			fontsize=12,
			label="Layer 1 FFN (Base GPUs)",
			lheight=0.18,
			lp="19991,568.5",
			lwidth=2.18,
			style=rounded
		];
		l1_ffn_up_0	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Up Projection</b><br/>GPU: base_gpu_0<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, ffn_dim=\
2048]",
			pos="23538,532",
			shape=rectangle,
			width=9.0278];
		l1_ffn_down_0	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Down Projection</b><br/>GPU: base_gpu_0<br/>Input: [batch=1024, seq=?, ffn_dim=2048]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="23855,412",
			shape=rectangle,
			width=9.1944];
		l1_ffn_up_0 -> l1_ffn_down_0	[pos="e,23592,430 23592,513.77 23592,513.77 23592,440 23592,440"];
		l1_ffn_up_0 -> l1_ffn_down_0	[pos="e,23660,430 23660,513.77 23660,513.77 23660,440 23660,440"];
		l1_ffn_up_0 -> l1_ffn_down_0	[pos="e,23727,430 23727,513.77 23727,513.77 23727,440 23727,440"];
		l1_ffn_up_0 -> l1_ffn_down_0	[pos="e,23795,430 23795,513.77 23795,513.77 23795,440 23795,440"];
		l1_ffn_res_0	[fillcolor=lightgray,
			height=0.5,
			label="<b>FFN Residual Add</b><br/>GPU: base_gpu_0<br/>Input: [batch=1024, seq=?, hidden=512] × 2<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="23963,315",
			shape=diamond,
			width=15.193];
		l1_ffn_down_0 -> l1_ffn_res_0	[pos="e,23656,323.35 23656,393.76 23656,393.76 23656,333.35 23656,333.35"];
		l1_ffn_down_0 -> l1_ffn_res_0	[pos="e,23789,327.32 23789,393.76 23789,393.76 23789,337.32 23789,337.32"];
		l1_ffn_down_0 -> l1_ffn_res_0	[pos="e,23921,331.86 23921,393.76 23921,393.76 23921,341.86 23921,341.86"];
		l1_ffn_down_0 -> l1_ffn_res_0	[pos="e,24054,330.29 24054,393.76 24054,393.76 24054,340.29 24054,340.29"];
		l1_ffn_ln_0	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Layer Norm</b><br/>GPU: base_gpu_0<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=512]",
			pos="23963,243",
			shape=rectangle,
			width=8.7917];
		l1_ffn_res_0 -> l1_ffn_ln_0	[pos="e,23773,261.12 23773,303.11 23773,303.11 23773,271.12 23773,271.12"];
		l1_ffn_res_0 -> l1_ffn_ln_0	[pos="e,23836,261.2 23836,301.12 23836,301.12 23836,271.2 23836,271.2"];
		l1_ffn_res_0 -> l1_ffn_ln_0	[pos="e,23900,261.22 23900,299.02 23900,299.02 23900,271.22 23900,271.22"];
		l1_ffn_res_0 -> l1_ffn_ln_0	[pos="e,23963,261.41 23963,296.83 23963,296.83 23963,271.41 23963,271.41"];
		l1_ffn_ln_0 -> l1_ffn_up_0	[pos="e,23410,513.87 23646,249 23523,249 23410,249 23410,249 23410,249 23410,503.87 23410,503.87"];
		l1_ffn_ln_0 -> l1_ffn_up_0	[pos="e,23403,513.92 23646,243 23520,243 23403,243 23403,243 23403,243 23403,503.92 23403,503.92"];
		l1_ffn_ln_0 -> l1_ffn_up_0	[pos="e,23397,513.99 23646,237 23517,237 23397,237 23397,237 23397,237 23397,503.99 23397,503.99"];
		l1_ffn_ln_0 -> l1_ffn_up_0	[pos="e,23391,513.62 23646,231 23514,231 23391,231 23391,231 23391,231 23391,503.62 23391,503.62"];
		l1_ffn_ln_0 -> l1_ffn_res_0	[pos="e,24026,299.04 24026,261.17 24026,261.17 24026,289.04 24026,289.04"];
		l1_ffn_ln_0 -> l1_ffn_res_0	[pos="e,24090,300.93 24090,261.17 24090,261.17 24090,290.93 24090,290.93"];
		l1_ffn_ln_0 -> l1_ffn_res_0	[pos="e,24153,303.16 24153,261.17 24153,261.17 24153,293.16 24153,293.16"];
		l1_ffn_ln_0 -> l1_ffn_res_0	[pos="e,24216,305.25 24216,261.17 24216,261.17 24216,295.25 24216,295.25"];
		l1_ffn_up_1	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Up Projection</b><br/>GPU: base_gpu_1<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, ffn_dim=\
2048]",
			pos="22638,532",
			shape=rectangle,
			width=9.0278];
		l1_ffn_down_1	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Down Projection</b><br/>GPU: base_gpu_1<br/>Input: [batch=1024, seq=?, ffn_dim=2048]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="22780,412",
			shape=rectangle,
			width=9.1944];
		l1_ffn_up_1 -> l1_ffn_down_1	[pos="e,22552,430 22552,513.77 22552,513.77 22552,440 22552,440"];
		l1_ffn_up_1 -> l1_ffn_down_1	[pos="e,22655,430 22655,513.77 22655,513.77 22655,440 22655,440"];
		l1_ffn_up_1 -> l1_ffn_down_1	[pos="e,22757,430 22757,513.77 22757,513.77 22757,440 22757,440"];
		l1_ffn_up_1 -> l1_ffn_down_1	[pos="e,22860,430 22860,513.77 22860,513.77 22860,440 22860,440"];
		l1_ffn_res_1	[fillcolor=lightgray,
			height=0.5,
			label="<b>FFN Residual Add</b><br/>GPU: base_gpu_1<br/>Input: [batch=1024, seq=?, hidden=512] × 2<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="22831,315",
			shape=diamond,
			width=15.193];
		l1_ffn_down_1 -> l1_ffn_res_1	[pos="e,22581,324.87 22581,393.76 22581,393.76 22581,334.87 22581,334.87"];
		l1_ffn_down_1 -> l1_ffn_res_1	[pos="e,22714,329.37 22714,393.76 22714,393.76 22714,339.37 22714,339.37"];
		l1_ffn_down_1 -> l1_ffn_res_1	[pos="e,22846,332.51 22846,393.76 22846,393.76 22846,342.51 22846,342.51"];
		l1_ffn_down_1 -> l1_ffn_res_1	[pos="e,22979,328.19 22979,393.76 22979,393.76 22979,338.19 22979,338.19"];
		l1_ffn_ln_1	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Layer Norm</b><br/>GPU: base_gpu_1<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=512]",
			pos="22831,243",
			shape=rectangle,
			width=8.7917];
		l1_ffn_res_1 -> l1_ffn_ln_1	[pos="e,22620,261.17 22620,303.75 22620,303.75 22620,271.17 22620,271.17"];
		l1_ffn_res_1 -> l1_ffn_ln_1	[pos="e,22673,261.17 22673,302.13 22673,302.13 22673,271.17 22673,271.17"];
		l1_ffn_res_1 -> l1_ffn_ln_1	[pos="e,22726,261.13 22726,300.43 22726,300.43 22726,271.13 22726,271.13"];
		l1_ffn_res_1 -> l1_ffn_ln_1	[pos="e,22778,261.04 22778,298.66 22778,298.66 22778,271.04 22778,271.04"];
		l1_ffn_ln_1 -> l1_ffn_up_1	[pos="e,22313,521 22514,249 22388,249 22271,249 22271,249 22271,249 22271,521 22271,521 22271,521 22303,521 22303,521"];
		l1_ffn_ln_1 -> l1_ffn_up_1	[pos="e,22313,528 22514,243 22385,243 22265,243 22265,243 22265,243 22265,528 22265,528 22265,528 22303,528 22303,528"];
		l1_ffn_ln_1 -> l1_ffn_up_1	[pos="e,22313,535 22514,237 22382,237 22259,237 22259,237 22259,237 22259,535 22259,535 22259,535 22303,535 22303,535"];
		l1_ffn_ln_1 -> l1_ffn_up_1	[pos="e,22313,542 22514,231 22379,231 22252,231 22252,231 22252,231 22252,542 22252,542 22252,542 22303,542 22303,542"];
		l1_ffn_ln_1 -> l1_ffn_res_1	[pos="e,22831,296.59 22831,261.17 22831,261.17 22831,286.59 22831,286.59"];
		l1_ffn_ln_1 -> l1_ffn_res_1	[pos="e,22884,298.56 22884,261.17 22884,261.17 22884,288.56 22884,288.56"];
		l1_ffn_ln_1 -> l1_ffn_res_1	[pos="e,22936,300.46 22936,261.17 22936,261.17 22936,290.46 22936,290.46"];
		l1_ffn_ln_1 -> l1_ffn_res_1	[pos="e,22989,301.84 22989,261.17 22989,261.17 22989,291.84 22989,291.84"];
		l1_ffn_up_2	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Up Projection</b><br/>GPU: base_gpu_2<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, ffn_dim=\
2048]",
			pos="21362,532",
			shape=rectangle,
			width=9.0278];
		l1_ffn_down_2	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Down Projection</b><br/>GPU: base_gpu_2<br/>Input: [batch=1024, seq=?, ffn_dim=2048]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="21591,412",
			shape=rectangle,
			width=9.1944];
		l1_ffn_up_2 -> l1_ffn_down_2	[pos="e,21345,430 21345,513.77 21345,513.77 21345,440 21345,440"];
		l1_ffn_up_2 -> l1_ffn_down_2	[pos="e,21431,430 21431,513.77 21431,513.77 21431,440 21431,440"];
		l1_ffn_up_2 -> l1_ffn_down_2	[pos="e,21516,430 21516,513.77 21516,513.77 21516,440 21516,440"];
		l1_ffn_up_2 -> l1_ffn_down_2	[pos="e,21602,430 21602,513.77 21602,513.77 21602,440 21602,440"];
		l1_ffn_res_2	[fillcolor=lightgray,
			height=0.5,
			label="<b>FFN Residual Add</b><br/>GPU: base_gpu_2<br/>Input: [batch=1024, seq=?, hidden=512] × 2<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="21699,315",
			shape=diamond,
			width=15.193];
		l1_ffn_down_2 -> l1_ffn_res_2	[pos="e,21392,323.35 21392,393.76 21392,393.76 21392,333.35 21392,333.35"];
		l1_ffn_down_2 -> l1_ffn_res_2	[pos="e,21525,327.32 21525,393.76 21525,393.76 21525,337.32 21525,337.32"];
		l1_ffn_down_2 -> l1_ffn_res_2	[pos="e,21657,331.86 21657,393.76 21657,393.76 21657,341.86 21657,341.86"];
		l1_ffn_down_2 -> l1_ffn_res_2	[pos="e,21790,330.29 21790,393.76 21790,393.76 21790,340.29 21790,340.29"];
		l1_ffn_ln_2	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Layer Norm</b><br/>GPU: base_gpu_2<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=512]",
			pos="21699,243",
			shape=rectangle,
			width=8.7917];
		l1_ffn_res_2 -> l1_ffn_ln_2	[pos="e,21488,261.17 21488,303.75 21488,303.75 21488,271.17 21488,271.17"];
		l1_ffn_res_2 -> l1_ffn_ln_2	[pos="e,21541,261.17 21541,302.13 21541,302.13 21541,271.17 21541,271.17"];
		l1_ffn_res_2 -> l1_ffn_ln_2	[pos="e,21594,261.13 21594,300.43 21594,300.43 21594,271.13 21594,271.13"];
		l1_ffn_res_2 -> l1_ffn_ln_2	[pos="e,21646,261.04 21646,298.66 21646,298.66 21646,271.04 21646,271.04"];
		l1_ffn_ln_2 -> l1_ffn_up_2	[pos="e,21146,513.87 21382,249 21259,249 21146,249 21146,249 21146,249 21146,503.87 21146,503.87"];
		l1_ffn_ln_2 -> l1_ffn_up_2	[pos="e,21139,513.92 21382,243 21256,243 21139,243 21139,243 21139,243 21139,503.92 21139,503.92"];
		l1_ffn_ln_2 -> l1_ffn_up_2	[pos="e,21133,513.99 21382,237 21253,237 21133,237 21133,237 21133,237 21133,503.99 21133,503.99"];
		l1_ffn_ln_2 -> l1_ffn_up_2	[pos="e,21127,513.62 21382,231 21250,231 21127,231 21127,231 21127,231 21127,503.62 21127,503.62"];
		l1_ffn_ln_2 -> l1_ffn_res_2	[pos="e,21699,296.59 21699,261.17 21699,261.17 21699,286.59 21699,286.59"];
		l1_ffn_ln_2 -> l1_ffn_res_2	[pos="e,21752,298.56 21752,261.17 21752,261.17 21752,288.56 21752,288.56"];
		l1_ffn_ln_2 -> l1_ffn_res_2	[pos="e,21804,300.46 21804,261.17 21804,261.17 21804,290.46 21804,290.46"];
		l1_ffn_ln_2 -> l1_ffn_res_2	[pos="e,21857,301.84 21857,261.17 21857,261.17 21857,291.84 21857,291.84"];
		l1_ffn_up_3	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Up Projection</b><br/>GPU: base_gpu_3<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, ffn_dim=\
2048]",
			pos="19556,532",
			shape=rectangle,
			width=9.0278];
		l1_ffn_down_3	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Down Projection</b><br/>GPU: base_gpu_3<br/>Input: [batch=1024, seq=?, ffn_dim=2048]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="19509,412",
			shape=rectangle,
			width=9.1944];
		l1_ffn_up_3 -> l1_ffn_down_3	[pos="e,19353,430 19353,513.77 19353,513.77 19353,440 19353,440"];
		l1_ffn_up_3 -> l1_ffn_down_3	[pos="e,19475,430 19475,513.77 19475,513.77 19475,440 19475,440"];
		l1_ffn_up_3 -> l1_ffn_down_3	[pos="e,19596,430 19596,513.77 19596,513.77 19596,440 19596,440"];
		l1_ffn_up_3 -> l1_ffn_down_3	[pos="e,19718,430 19718,513.77 19718,513.77 19718,440 19718,440"];
		l1_ffn_res_3	[fillcolor=lightgray,
			height=0.5,
			label="<b>FFN Residual Add</b><br/>GPU: base_gpu_3<br/>Input: [batch=1024, seq=?, hidden=512] × 2<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="19415,315",
			shape=diamond,
			width=15.193];
		l1_ffn_down_3 -> l1_ffn_res_3	[pos="e,19310,329.68 19310,393.76 19310,393.76 19310,339.68 19310,339.68"];
		l1_ffn_down_3 -> l1_ffn_res_3	[pos="e,19443,332.19 19443,393.76 19443,393.76 19443,342.19 19443,342.19"];
		l1_ffn_down_3 -> l1_ffn_res_3	[pos="e,19575,327.89 19575,393.76 19575,393.76 19575,337.89 19575,337.89"];
		l1_ffn_down_3 -> l1_ffn_res_3	[pos="e,19708,323.6 19708,393.76 19708,393.76 19708,333.6 19708,333.6"];
		l1_ffn_ln_3	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Layer Norm</b><br/>GPU: base_gpu_3<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=512]",
			pos="19415,243",
			shape=rectangle,
			width=8.7917];
		l1_ffn_res_3 -> l1_ffn_ln_3	[pos="e,19214,261.01 19214,303.43 19214,303.43 19214,271.01 19214,271.01"];
		l1_ffn_res_3 -> l1_ffn_ln_3	[pos="e,19271,261.1 19271,301.46 19271,301.46 19271,271.1 19271,271.1"];
		l1_ffn_res_3 -> l1_ffn_ln_3	[pos="e,19329,261.05 19329,299.73 19329,299.73 19329,271.05 19329,271.05"];
		l1_ffn_res_3 -> l1_ffn_ln_3	[pos="e,19386,261.2 19386,297.94 19386,297.94 19386,271.2 19386,271.2"];
		l1_ffn_ln_3 -> l1_ffn_up_3	[pos="e,19231,521 19098,253 18976,253 18864,253 18864,253 18864,253 18864,521 18864,521 18864,521 19221,521 19221,521"];
		l1_ffn_ln_3 -> l1_ffn_up_3	[pos="e,19231,528 19098,246 18974,246 18861,246 18861,246 18861,246 18861,528 18861,528 18861,528 19221,528 19221,528"];
		l1_ffn_ln_3 -> l1_ffn_up_3	[pos="e,19231,535 19098,239 18972,239 18857,239 18857,239 18857,239 18857,535 18857,535 18857,535 19221,535 19221,535"];
		l1_ffn_ln_3 -> l1_ffn_up_3	[pos="e,19231,542 19098,232 18971,232 18854,232 18854,232 18854,232 18854,542 18854,542 18854,542 19221,542 19221,542"];
		l1_ffn_ln_3 -> l1_ffn_res_3	[pos="e,19444,297.58 19444,261.17 19444,261.17 19444,287.58 19444,287.58"];
		l1_ffn_ln_3 -> l1_ffn_res_3	[pos="e,19501,299.52 19501,261.17 19501,261.17 19501,289.52 19501,289.52"];
		l1_ffn_ln_3 -> l1_ffn_res_3	[pos="e,19559,301.38 19559,261.17 19559,261.17 19559,291.38 19559,291.38"];
		l1_ffn_ln_3 -> l1_ffn_res_3	[pos="e,19616,303.59 19616,261.17 19616,261.17 19616,293.59 19616,293.59"];
		l1_ffn_up_4	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Up Projection</b><br/>GPU: base_gpu_4<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, ffn_dim=\
2048]",
			pos="20271,532",
			shape=rectangle,
			width=9.0278];
		l1_ffn_down_4	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Down Projection</b><br/>GPU: base_gpu_4<br/>Input: [batch=1024, seq=?, ffn_dim=2048]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="20459,412",
			shape=rectangle,
			width=9.1944];
		l1_ffn_up_4 -> l1_ffn_down_4	[pos="e,20222,430 20222,513.77 20222,513.77 20222,440 20222,440"];
		l1_ffn_up_4 -> l1_ffn_down_4	[pos="e,20315,430 20315,513.77 20315,513.77 20315,440 20315,440"];
		l1_ffn_up_4 -> l1_ffn_down_4	[pos="e,20409,430 20409,513.77 20409,513.77 20409,440 20409,440"];
		l1_ffn_up_4 -> l1_ffn_down_4	[pos="e,20502,430 20502,513.77 20502,513.77 20502,440 20502,440"];
		l1_ffn_res_4	[fillcolor=lightgray,
			height=0.5,
			label="<b>FFN Residual Add</b><br/>GPU: base_gpu_4<br/>Input: [batch=1024, seq=?, hidden=512] × 2<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="20567,315",
			shape=diamond,
			width=15.193];
		l1_ffn_down_4 -> l1_ffn_res_4	[pos="e,20260,323.35 20260,393.76 20260,393.76 20260,333.35 20260,333.35"];
		l1_ffn_down_4 -> l1_ffn_res_4	[pos="e,20393,327.32 20393,393.76 20393,393.76 20393,337.32 20393,337.32"];
		l1_ffn_down_4 -> l1_ffn_res_4	[pos="e,20525,331.86 20525,393.76 20525,393.76 20525,341.86 20525,341.86"];
		l1_ffn_down_4 -> l1_ffn_res_4	[pos="e,20658,330.29 20658,393.76 20658,393.76 20658,340.29 20658,340.29"];
		l1_ffn_ln_4	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Layer Norm</b><br/>GPU: base_gpu_4<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=512]",
			pos="20567,243",
			shape=rectangle,
			width=8.7917];
		l1_ffn_res_4 -> l1_ffn_ln_4	[pos="e,20366,261.01 20366,303.43 20366,303.43 20366,271.01 20366,271.01"];
		l1_ffn_res_4 -> l1_ffn_ln_4	[pos="e,20423,261.1 20423,301.46 20423,301.46 20423,271.1 20423,271.1"];
		l1_ffn_res_4 -> l1_ffn_ln_4	[pos="e,20481,261.05 20481,299.73 20481,299.73 20481,271.05 20481,271.05"];
		l1_ffn_res_4 -> l1_ffn_ln_4	[pos="e,20538,261.2 20538,297.94 20538,297.94 20538,271.2 20538,271.2"];
		l1_ffn_ln_4 -> l1_ffn_up_4	[pos="e,19995,513.61 20250,245 20118,245 19995,245 19995,245 19995,245 19995,503.61 19995,503.61"];
		l1_ffn_ln_4 -> l1_ffn_up_4	[pos="e,19987,513.73 20250,240 20115,240 19987,240 19987,240 19987,240 19987,503.73 19987,503.73"];
		l1_ffn_ln_4 -> l1_ffn_up_4	[pos="e,19979,513.87 20250,235 20111,235 19979,235 19979,235 19979,235 19979,503.87 19979,503.87"];
		l1_ffn_ln_4 -> l1_ffn_up_4	[pos="e,19970,513.56 20250,230 20107,230 19970,230 19970,230 19970,230 19970,503.56 19970,503.56"];
		l1_ffn_ln_4 -> l1_ffn_res_4	[pos="e,20596,297.58 20596,261.17 20596,261.17 20596,287.58 20596,287.58"];
		l1_ffn_ln_4 -> l1_ffn_res_4	[pos="e,20653,299.52 20653,261.17 20653,261.17 20653,289.52 20653,289.52"];
		l1_ffn_ln_4 -> l1_ffn_res_4	[pos="e,20711,301.38 20711,261.17 20711,261.17 20711,291.38 20711,291.38"];
		l1_ffn_ln_4 -> l1_ffn_res_4	[pos="e,20768,303.59 20768,261.17 20768,261.17 20768,293.59 20768,293.59"];
		l1_ffn_up_5	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Up Projection</b><br/>GPU: base_gpu_5<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, ffn_dim=\
2048]",
			pos="17966,532",
			shape=rectangle,
			width=9.0278];
		l1_ffn_down_5	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Down Projection</b><br/>GPU: base_gpu_5<br/>Input: [batch=1024, seq=?, ffn_dim=2048]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="18195,412",
			shape=rectangle,
			width=9.1944];
		l1_ffn_up_5 -> l1_ffn_down_5	[pos="e,17949,430 17949,513.77 17949,513.77 17949,440 17949,440"];
		l1_ffn_up_5 -> l1_ffn_down_5	[pos="e,18035,430 18035,513.77 18035,513.77 18035,440 18035,440"];
		l1_ffn_up_5 -> l1_ffn_down_5	[pos="e,18120,430 18120,513.77 18120,513.77 18120,440 18120,440"];
		l1_ffn_up_5 -> l1_ffn_down_5	[pos="e,18206,430 18206,513.77 18206,513.77 18206,440 18206,440"];
		l1_ffn_res_5	[fillcolor=lightgray,
			height=0.5,
			label="<b>FFN Residual Add</b><br/>GPU: base_gpu_5<br/>Input: [batch=1024, seq=?, hidden=512] × 2<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="18303,315",
			shape=diamond,
			width=15.193];
		l1_ffn_down_5 -> l1_ffn_res_5	[pos="e,17996,323.35 17996,393.76 17996,393.76 17996,333.35 17996,333.35"];
		l1_ffn_down_5 -> l1_ffn_res_5	[pos="e,18129,327.32 18129,393.76 18129,393.76 18129,337.32 18129,337.32"];
		l1_ffn_down_5 -> l1_ffn_res_5	[pos="e,18261,331.86 18261,393.76 18261,393.76 18261,341.86 18261,341.86"];
		l1_ffn_down_5 -> l1_ffn_res_5	[pos="e,18394,330.29 18394,393.76 18394,393.76 18394,340.29 18394,340.29"];
		l1_ffn_ln_5	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Layer Norm</b><br/>GPU: base_gpu_5<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=512]",
			pos="18303,243",
			shape=rectangle,
			width=8.7917];
		l1_ffn_res_5 -> l1_ffn_ln_5	[pos="e,18102,261.01 18102,303.43 18102,303.43 18102,271.01 18102,271.01"];
		l1_ffn_res_5 -> l1_ffn_ln_5	[pos="e,18159,261.1 18159,301.46 18159,301.46 18159,271.1 18159,271.1"];
		l1_ffn_res_5 -> l1_ffn_ln_5	[pos="e,18217,261.05 18217,299.73 18217,299.73 18217,271.05 18217,271.05"];
		l1_ffn_res_5 -> l1_ffn_ln_5	[pos="e,18274,261.2 18274,297.94 18274,297.94 18274,271.2 18274,271.2"];
		l1_ffn_ln_5 -> l1_ffn_up_5	[pos="e,17750,513.87 17986,249 17863,249 17750,249 17750,249 17750,249 17750,503.87 17750,503.87"];
		l1_ffn_ln_5 -> l1_ffn_up_5	[pos="e,17743,513.92 17986,243 17860,243 17743,243 17743,243 17743,243 17743,503.92 17743,503.92"];
		l1_ffn_ln_5 -> l1_ffn_up_5	[pos="e,17737,513.99 17986,237 17857,237 17737,237 17737,237 17737,237 17737,503.99 17737,503.99"];
		l1_ffn_ln_5 -> l1_ffn_up_5	[pos="e,17731,513.62 17986,231 17854,231 17731,231 17731,231 17731,231 17731,503.62 17731,503.62"];
		l1_ffn_ln_5 -> l1_ffn_res_5	[pos="e,18332,297.58 18332,261.17 18332,261.17 18332,287.58 18332,287.58"];
		l1_ffn_ln_5 -> l1_ffn_res_5	[pos="e,18389,299.52 18389,261.17 18389,261.17 18389,289.52 18389,289.52"];
		l1_ffn_ln_5 -> l1_ffn_res_5	[pos="e,18447,301.38 18447,261.17 18447,261.17 18447,291.38 18447,291.38"];
		l1_ffn_ln_5 -> l1_ffn_res_5	[pos="e,18504,303.59 18504,261.17 18504,261.17 18504,293.59 18504,293.59"];
		l1_ffn_up_6	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Up Projection</b><br/>GPU: base_gpu_6<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, ffn_dim=\
2048]",
			pos="16834,532",
			shape=rectangle,
			width=9.0278];
		l1_ffn_down_6	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Down Projection</b><br/>GPU: base_gpu_6<br/>Input: [batch=1024, seq=?, ffn_dim=2048]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="17063,412",
			shape=rectangle,
			width=9.1944];
		l1_ffn_up_6 -> l1_ffn_down_6	[pos="e,16817,430 16817,513.77 16817,513.77 16817,440 16817,440"];
		l1_ffn_up_6 -> l1_ffn_down_6	[pos="e,16903,430 16903,513.77 16903,513.77 16903,440 16903,440"];
		l1_ffn_up_6 -> l1_ffn_down_6	[pos="e,16988,430 16988,513.77 16988,513.77 16988,440 16988,440"];
		l1_ffn_up_6 -> l1_ffn_down_6	[pos="e,17074,430 17074,513.77 17074,513.77 17074,440 17074,440"];
		l1_ffn_res_6	[fillcolor=lightgray,
			height=0.5,
			label="<b>FFN Residual Add</b><br/>GPU: base_gpu_6<br/>Input: [batch=1024, seq=?, hidden=512] × 2<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="17171,315",
			shape=diamond,
			width=15.193];
		l1_ffn_down_6 -> l1_ffn_res_6	[pos="e,16864,323.35 16864,393.76 16864,393.76 16864,333.35 16864,333.35"];
		l1_ffn_down_6 -> l1_ffn_res_6	[pos="e,16997,327.32 16997,393.76 16997,393.76 16997,337.32 16997,337.32"];
		l1_ffn_down_6 -> l1_ffn_res_6	[pos="e,17129,331.86 17129,393.76 17129,393.76 17129,341.86 17129,341.86"];
		l1_ffn_down_6 -> l1_ffn_res_6	[pos="e,17262,330.29 17262,393.76 17262,393.76 17262,340.29 17262,340.29"];
		l1_ffn_ln_6	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Layer Norm</b><br/>GPU: base_gpu_6<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=512]",
			pos="17171,243",
			shape=rectangle,
			width=8.7917];
		l1_ffn_res_6 -> l1_ffn_ln_6	[pos="e,16981,261.12 16981,303.11 16981,303.11 16981,271.12 16981,271.12"];
		l1_ffn_res_6 -> l1_ffn_ln_6	[pos="e,17044,261.2 17044,301.12 17044,301.12 17044,271.2 17044,271.2"];
		l1_ffn_res_6 -> l1_ffn_ln_6	[pos="e,17108,261.22 17108,299.02 17108,299.02 17108,271.22 17108,271.22"];
		l1_ffn_res_6 -> l1_ffn_ln_6	[pos="e,17171,261.41 17171,296.83 17171,296.83 17171,271.41 17171,271.41"];
		l1_ffn_ln_6 -> l1_ffn_up_6	[pos="e,16618,513.87 16854,249 16731,249 16618,249 16618,249 16618,249 16618,503.87 16618,503.87"];
		l1_ffn_ln_6 -> l1_ffn_up_6	[pos="e,16611,513.92 16854,243 16728,243 16611,243 16611,243 16611,243 16611,503.92 16611,503.92"];
		l1_ffn_ln_6 -> l1_ffn_up_6	[pos="e,16605,513.99 16854,237 16725,237 16605,237 16605,237 16605,237 16605,503.99 16605,503.99"];
		l1_ffn_ln_6 -> l1_ffn_up_6	[pos="e,16599,513.62 16854,231 16722,231 16599,231 16599,231 16599,231 16599,503.62 16599,503.62"];
		l1_ffn_ln_6 -> l1_ffn_res_6	[pos="e,17234,299.04 17234,261.17 17234,261.17 17234,289.04 17234,289.04"];
		l1_ffn_ln_6 -> l1_ffn_res_6	[pos="e,17298,300.93 17298,261.17 17298,261.17 17298,290.93 17298,290.93"];
		l1_ffn_ln_6 -> l1_ffn_res_6	[pos="e,17361,303.16 17361,261.17 17361,261.17 17361,293.16 17361,293.16"];
		l1_ffn_ln_6 -> l1_ffn_res_6	[pos="e,17424,305.25 17424,261.17 17424,261.17 17424,295.25 17424,295.25"];
		l1_ffn_up_7	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Up Projection</b><br/>GPU: base_gpu_7<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, ffn_dim=\
2048]",
			pos="15864,532",
			shape=rectangle,
			width=9.0278];
		l1_ffn_down_7	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Down Projection</b><br/>GPU: base_gpu_7<br/>Input: [batch=1024, seq=?, ffn_dim=2048]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="15931,412",
			shape=rectangle,
			width=9.1944];
		l1_ffn_up_7 -> l1_ffn_down_7	[pos="e,15718,430 15718,513.77 15718,513.77 15718,440 15718,440"];
		l1_ffn_up_7 -> l1_ffn_down_7	[pos="e,15836,430 15836,513.77 15836,513.77 15836,440 15836,440"];
		l1_ffn_up_7 -> l1_ffn_down_7	[pos="e,15953,430 15953,513.77 15953,513.77 15953,440 15953,440"];
		l1_ffn_up_7 -> l1_ffn_down_7	[pos="e,16071,430 16071,513.77 16071,513.77 16071,440 16071,440"];
		l1_ffn_res_7	[fillcolor=lightgray,
			height=0.5,
			label="<b>FFN Residual Add</b><br/>GPU: base_gpu_7<br/>Input: [batch=1024, seq=?, hidden=512] × 2<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="16039,315",
			shape=diamond,
			width=15.193];
		l1_ffn_down_7 -> l1_ffn_res_7	[pos="e,15732,323.35 15732,393.76 15732,393.76 15732,333.35 15732,333.35"];
		l1_ffn_down_7 -> l1_ffn_res_7	[pos="e,15865,327.32 15865,393.76 15865,393.76 15865,337.32 15865,337.32"];
		l1_ffn_down_7 -> l1_ffn_res_7	[pos="e,15997,331.86 15997,393.76 15997,393.76 15997,341.86 15997,341.86"];
		l1_ffn_down_7 -> l1_ffn_res_7	[pos="e,16130,330.29 16130,393.76 16130,393.76 16130,340.29 16130,340.29"];
		l1_ffn_ln_7	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Layer Norm</b><br/>GPU: base_gpu_7<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=512]",
			pos="16039,243",
			shape=rectangle,
			width=8.7917];
		l1_ffn_res_7 -> l1_ffn_ln_7	[pos="e,15849,261.12 15849,303.11 15849,303.11 15849,271.12 15849,271.12"];
		l1_ffn_res_7 -> l1_ffn_ln_7	[pos="e,15912,261.2 15912,301.12 15912,301.12 15912,271.2 15912,271.2"];
		l1_ffn_res_7 -> l1_ffn_ln_7	[pos="e,15976,261.22 15976,299.02 15976,299.02 15976,271.22 15976,271.22"];
		l1_ffn_res_7 -> l1_ffn_ln_7	[pos="e,16039,261.41 16039,296.83 16039,296.83 16039,271.41 16039,271.41"];
		l1_ffn_ln_7 -> l1_ffn_up_7	[pos="e,15539,534 15722,243 15600,243 15489,243 15489,243 15489,243 15489,534 15489,534 15489,534 15529,534 15529,534"];
		l1_ffn_ln_7 -> l1_ffn_up_7	[pos="e,15539,538 15722,238 15599,238 15486,238 15486,238 15486,238 15486,538 15486,538 15486,538 15529,538 15529,538"];
		l1_ffn_ln_7 -> l1_ffn_up_7	[pos="e,15539,542 15722,234 15597,234 15483,234 15483,234 15483,234 15483,542 15483,542 15483,542 15529,542 15529,542"];
		l1_ffn_ln_7 -> l1_ffn_up_7	[pos="e,15539,546 15722,229 15596,229 15480,229 15480,229 15480,229 15480,546 15480,546 15480,546 15529,546 15529,546"];
		l1_ffn_ln_7 -> l1_ffn_res_7	[pos="e,16102,299.04 16102,261.17 16102,261.17 16102,289.04 16102,289.04"];
		l1_ffn_ln_7 -> l1_ffn_res_7	[pos="e,16166,300.93 16166,261.17 16166,261.17 16166,290.93 16166,290.93"];
		l1_ffn_ln_7 -> l1_ffn_res_7	[pos="e,16229,303.16 16229,261.17 16229,261.17 16229,293.16 16229,293.16"];
		l1_ffn_ln_7 -> l1_ffn_res_7	[pos="e,16292,305.25 16292,261.17 16292,261.17 16292,295.25 16292,295.25"];
	}
	subgraph cluster_layer2_ffn {
		graph [bb="2.9025e+05,217,2.993e+05,579",
			fontsize=12,
			label="Layer 2 FFN (Base GPUs)",
			lheight=0.18,
			lp="2.9478e+05,568.5",
			lwidth=2.18,
			style=rounded
		];
		l2_ffn_up_0	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Up Projection</b><br/>GPU: base_gpu_0<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, ffn_dim=\
2048]",
			pos="2.9823e+05,532",
			shape=rectangle,
			width=9.0278];
		l2_ffn_down_0	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Down Projection</b><br/>GPU: base_gpu_0<br/>Input: [batch=1024, seq=?, ffn_dim=2048]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="2.9864e+05,412",
			shape=rectangle,
			width=9.1944];
		l2_ffn_up_0 -> l2_ffn_down_0	[pos="e,2.9836e+05,430 2.9836e+05,513.77 2.9836e+05,513.77 2.9836e+05,440 2.9836e+05,440"];
		l2_ffn_up_0 -> l2_ffn_down_0	[pos="e,2.9841e+05,430 2.9841e+05,513.77 2.9841e+05,513.77 2.9841e+05,440 2.9841e+05,440"];
		l2_ffn_up_0 -> l2_ffn_down_0	[pos="e,2.9846e+05,430 2.9846e+05,513.77 2.9846e+05,513.77 2.9846e+05,440 2.9846e+05,440"];
		l2_ffn_up_0 -> l2_ffn_down_0	[pos="e,2.9851e+05,430 2.9851e+05,513.77 2.9851e+05,513.77 2.9851e+05,440 2.9851e+05,440"];
		l2_ffn_res_0	[fillcolor=lightgray,
			height=0.5,
			label="<b>FFN Residual Add</b><br/>GPU: base_gpu_0<br/>Input: [batch=1024, seq=?, hidden=512] × 2<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="2.9875e+05,315",
			shape=diamond,
			width=15.193];
		l2_ffn_down_0 -> l2_ffn_res_0	[pos="e,2.9844e+05,323.35 2.9844e+05,393.76 2.9844e+05,393.76 2.9844e+05,333.35 2.9844e+05,333.35"];
		l2_ffn_down_0 -> l2_ffn_res_0	[pos="e,2.9857e+05,327.32 2.9857e+05,393.76 2.9857e+05,393.76 2.9857e+05,337.32 2.9857e+05,337.32"];
		l2_ffn_down_0 -> l2_ffn_res_0	[pos="e,2.9871e+05,331.86 2.9871e+05,393.76 2.9871e+05,393.76 2.9871e+05,341.86 2.9871e+05,341.86"];
		l2_ffn_down_0 -> l2_ffn_res_0	[pos="e,2.9884e+05,330.29 2.9884e+05,393.76 2.9884e+05,393.76 2.9884e+05,340.29 2.9884e+05,340.29"];
		l2_ffn_ln_0	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Layer Norm</b><br/>GPU: base_gpu_0<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=512]",
			pos="2.9833e+05,243",
			shape=rectangle,
			width=8.7917];
		l2_ffn_res_0 -> l2_ffn_ln_0	[pos="e,2.9825e+05,261.27 2.9825e+05,313.22 2.9825e+05,313.22 2.9825e+05,271.27 2.9825e+05,271.27"];
		l2_ffn_res_0 -> l2_ffn_ln_0	[pos="e,2.983e+05,261.21 2.983e+05,311.53 2.983e+05,311.53 2.983e+05,271.21 2.983e+05,271.21"];
		l2_ffn_res_0 -> l2_ffn_ln_0	[pos="e,2.9835e+05,261.02 2.9835e+05,309.82 2.9835e+05,309.82 2.9835e+05,271.02 2.9835e+05,271.02"];
		l2_ffn_res_0 -> l2_ffn_ln_0	[pos="e,2.984e+05,261.05 2.984e+05,308.36 2.984e+05,308.36 2.984e+05,271.05 2.984e+05,271.05"];
		l2_ffn_ln_0 -> l2_ffn_up_0	[pos="e,2.9819e+05,513.93 2.9819e+05,261.08 2.9819e+05,261.08 2.9819e+05,503.93 2.9819e+05,503.93"];
		l2_ffn_ln_0 -> l2_ffn_up_0	[pos="e,2.9819e+05,513.93 2.9819e+05,261.08 2.9819e+05,261.08 2.9819e+05,503.93 2.9819e+05,503.93"];
		l2_ffn_ln_0 -> l2_ffn_up_0	[pos="e,2.9819e+05,513.93 2.9819e+05,261.08 2.9819e+05,261.08 2.9819e+05,503.93 2.9819e+05,503.93"];
		l2_ffn_ln_0 -> l2_ffn_up_0	[pos="e,2.982e+05,513.93 2.982e+05,261.08 2.982e+05,261.08 2.982e+05,503.93 2.982e+05,503.93"];
		l2_ffn_ln_0 -> l2_ffn_res_0	[pos="e,2.9845e+05,306.81 2.9845e+05,261.17 2.9845e+05,261.17 2.9845e+05,296.81 2.9845e+05,296.81"];
		l2_ffn_ln_0 -> l2_ffn_res_0	[pos="e,2.985e+05,305.25 2.985e+05,261.17 2.985e+05,261.17 2.985e+05,295.25 2.985e+05,295.25"];
		l2_ffn_ln_0 -> l2_ffn_res_0	[pos="e,2.9855e+05,303.59 2.9855e+05,261.17 2.9855e+05,261.17 2.9855e+05,293.59 2.9855e+05,293.59"];
		l2_ffn_ln_0 -> l2_ffn_res_0	[pos="e,2.986e+05,301.84 2.986e+05,261.17 2.986e+05,261.17 2.986e+05,291.84 2.986e+05,291.84"];
		l2_ffn_up_1	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Up Projection</b><br/>GPU: base_gpu_1<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, ffn_dim=\
2048]",
			pos="2.9735e+05,532",
			shape=rectangle,
			width=9.0278];
		l2_ffn_down_1	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Down Projection</b><br/>GPU: base_gpu_1<br/>Input: [batch=1024, seq=?, ffn_dim=2048]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="2.9759e+05,412",
			shape=rectangle,
			width=9.1944];
		l2_ffn_up_1 -> l2_ffn_down_1	[pos="e,2.9734e+05,430 2.9734e+05,513.77 2.9734e+05,513.77 2.9734e+05,440 2.9734e+05,440"];
		l2_ffn_up_1 -> l2_ffn_down_1	[pos="e,2.9743e+05,430 2.9743e+05,513.77 2.9743e+05,513.77 2.9743e+05,440 2.9743e+05,440"];
		l2_ffn_up_1 -> l2_ffn_down_1	[pos="e,2.9751e+05,430 2.9751e+05,513.77 2.9751e+05,513.77 2.9751e+05,440 2.9751e+05,440"];
		l2_ffn_up_1 -> l2_ffn_down_1	[pos="e,2.9759e+05,430 2.9759e+05,513.77 2.9759e+05,513.77 2.9759e+05,440 2.9759e+05,440"];
		l2_ffn_res_1	[fillcolor=lightgray,
			height=0.5,
			label="<b>FFN Residual Add</b><br/>GPU: base_gpu_1<br/>Input: [batch=1024, seq=?, hidden=512] × 2<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="2.9762e+05,315",
			shape=diamond,
			width=15.193];
		l2_ffn_down_1 -> l2_ffn_res_1	[pos="e,2.9739e+05,325.66 2.9739e+05,393.76 2.9739e+05,393.76 2.9739e+05,335.66 2.9739e+05,335.66"];
		l2_ffn_down_1 -> l2_ffn_res_1	[pos="e,2.9753e+05,330.29 2.9753e+05,393.76 2.9753e+05,393.76 2.9753e+05,340.29 2.9753e+05,340.29"];
		l2_ffn_down_1 -> l2_ffn_res_1	[pos="e,2.9766e+05,331.86 2.9766e+05,393.76 2.9766e+05,393.76 2.9766e+05,341.86 2.9766e+05,341.86"];
		l2_ffn_down_1 -> l2_ffn_res_1	[pos="e,2.9779e+05,327.32 2.9779e+05,393.76 2.9779e+05,393.76 2.9779e+05,337.32 2.9779e+05,337.32"];
		l2_ffn_ln_1	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Layer Norm</b><br/>GPU: base_gpu_1<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=512]",
			pos="2.9747e+05,243",
			shape=rectangle,
			width=8.7917];
		l2_ffn_res_1 -> l2_ffn_ln_1	[pos="e,2.9728e+05,261.05 2.9728e+05,307.83 2.9728e+05,307.83 2.9728e+05,271.05 2.9728e+05,271.05"];
		l2_ffn_res_1 -> l2_ffn_ln_1	[pos="e,2.9734e+05,261.15 2.9734e+05,305.88 2.9734e+05,305.88 2.9734e+05,271.15 2.9734e+05,271.15"];
		l2_ffn_res_1 -> l2_ffn_ln_1	[pos="e,2.9741e+05,261.17 2.9741e+05,303.75 2.9741e+05,303.75 2.9741e+05,271.17 2.9741e+05,271.17"];
		l2_ffn_res_1 -> l2_ffn_ln_1	[pos="e,2.9747e+05,261 2.9747e+05,301.79 2.9747e+05,301.79 2.9747e+05,271 2.9747e+05,271"];
		l2_ffn_ln_1 -> l2_ffn_up_1	[pos="e,2.9706e+05,513.98 2.9715e+05,244 2.971e+05,244 2.9706e+05,244 2.9706e+05,244 2.9706e+05,244 2.9706e+05,503.98 2.9706e+05,503.98"];
		l2_ffn_ln_1 -> l2_ffn_up_1	[pos="e,2.9706e+05,513.8 2.9715e+05,241 2.971e+05,241 2.9706e+05,241 2.9706e+05,241 2.9706e+05,241 2.9706e+05,503.8 2.9706e+05,503.8"];
		l2_ffn_ln_1 -> l2_ffn_up_1	[pos="e,2.9705e+05,513.61 2.9715e+05,238 2.9709e+05,238 2.9705e+05,238 2.9705e+05,238 2.9705e+05,238 2.9705e+05,503.61 2.9705e+05,503.61"];
		l2_ffn_ln_1 -> l2_ffn_up_1	[pos="e,2.9704e+05,513.81 2.9715e+05,234 2.9709e+05,234 2.9704e+05,234 2.9704e+05,234 2.9704e+05,234 2.9704e+05,503.81 2.9704e+05,503.81"];
		l2_ffn_ln_1 -> l2_ffn_res_1	[pos="e,2.9753e+05,299.52 2.9753e+05,261.17 2.9753e+05,261.17 2.9753e+05,289.52 2.9753e+05,289.52"];
		l2_ffn_ln_1 -> l2_ffn_res_1	[pos="e,2.976e+05,297.58 2.976e+05,261.17 2.976e+05,261.17 2.976e+05,287.58 2.976e+05,287.58"];
		l2_ffn_ln_1 -> l2_ffn_res_1	[pos="e,2.9766e+05,298.07 2.9766e+05,261.17 2.9766e+05,261.17 2.9766e+05,288.07 2.9766e+05,288.07"];
		l2_ffn_ln_1 -> l2_ffn_res_1	[pos="e,2.9772e+05,300.46 2.9772e+05,261.17 2.9772e+05,261.17 2.9772e+05,290.46 2.9772e+05,290.46"];
		l2_ffn_up_2	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Up Projection</b><br/>GPU: base_gpu_2<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, ffn_dim=\
2048]",
			pos="2.9553e+05,532",
			shape=rectangle,
			width=9.0278];
		l2_ffn_down_2	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Down Projection</b><br/>GPU: base_gpu_2<br/>Input: [batch=1024, seq=?, ffn_dim=2048]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="2.9544e+05,412",
			shape=rectangle,
			width=9.1944];
		l2_ffn_up_2 -> l2_ffn_down_2	[pos="e,2.9532e+05,430 2.9532e+05,513.77 2.9532e+05,513.77 2.9532e+05,440 2.9532e+05,440"];
		l2_ffn_up_2 -> l2_ffn_down_2	[pos="e,2.9543e+05,430 2.9543e+05,513.77 2.9543e+05,513.77 2.9543e+05,440 2.9543e+05,440"];
		l2_ffn_up_2 -> l2_ffn_down_2	[pos="e,2.9554e+05,430 2.9554e+05,513.77 2.9554e+05,513.77 2.9554e+05,440 2.9554e+05,440"];
		l2_ffn_up_2 -> l2_ffn_down_2	[pos="e,2.9566e+05,430 2.9566e+05,513.77 2.9566e+05,513.77 2.9566e+05,440 2.9566e+05,440"];
		l2_ffn_res_2	[fillcolor=lightgray,
			height=0.5,
			label="<b>FFN Residual Add</b><br/>GPU: base_gpu_2<br/>Input: [batch=1024, seq=?, hidden=512] × 2<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="2.9533e+05,315",
			shape=diamond,
			width=15.193];
		l2_ffn_down_2 -> l2_ffn_res_2	[pos="e,2.9524e+05,330.29 2.9524e+05,393.76 2.9524e+05,393.76 2.9524e+05,340.29 2.9524e+05,340.29"];
		l2_ffn_down_2 -> l2_ffn_res_2	[pos="e,2.9537e+05,331.86 2.9537e+05,393.76 2.9537e+05,393.76 2.9537e+05,341.86 2.9537e+05,341.86"];
		l2_ffn_down_2 -> l2_ffn_res_2	[pos="e,2.9551e+05,327.32 2.9551e+05,393.76 2.9551e+05,393.76 2.9551e+05,337.32 2.9551e+05,337.32"];
		l2_ffn_down_2 -> l2_ffn_res_2	[pos="e,2.9564e+05,323.35 2.9564e+05,393.76 2.9564e+05,393.76 2.9564e+05,333.35 2.9564e+05,333.35"];
		l2_ffn_ln_2	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Layer Norm</b><br/>GPU: base_gpu_2<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=512]",
			pos="2.9533e+05,243",
			shape=rectangle,
			width=8.7917];
		l2_ffn_res_2 -> l2_ffn_ln_2	[pos="e,2.9514e+05,261.12 2.9514e+05,303.11 2.9514e+05,303.11 2.9514e+05,271.12 2.9514e+05,271.12"];
		l2_ffn_res_2 -> l2_ffn_ln_2	[pos="e,2.9521e+05,261.2 2.9521e+05,301.12 2.9521e+05,301.12 2.9521e+05,271.2 2.9521e+05,271.2"];
		l2_ffn_res_2 -> l2_ffn_ln_2	[pos="e,2.9527e+05,261.22 2.9527e+05,299.02 2.9527e+05,299.02 2.9527e+05,271.22 2.9527e+05,271.22"];
		l2_ffn_res_2 -> l2_ffn_ln_2	[pos="e,2.9533e+05,261.41 2.9533e+05,296.83 2.9533e+05,296.83 2.9533e+05,271.41 2.9533e+05,271.41"];
		l2_ffn_ln_2 -> l2_ffn_up_2	[pos="e,2.9585e+05,521 2.9565e+05,245 2.9578e+05,245 2.959e+05,245 2.959e+05,245 2.959e+05,245 2.959e+05,521 2.959e+05,521 2.959e+05,521 \
2.9586e+05,521 2.9586e+05,521"];
		l2_ffn_ln_2 -> l2_ffn_up_2	[pos="e,2.9585e+05,528 2.9565e+05,240 2.9578e+05,240 2.959e+05,240 2.959e+05,240 2.959e+05,240 2.959e+05,528 2.959e+05,528 2.959e+05,528 \
2.9586e+05,528 2.9586e+05,528"];
		l2_ffn_ln_2 -> l2_ffn_up_2	[pos="e,2.9585e+05,535 2.9565e+05,235 2.9578e+05,235 2.9591e+05,235 2.9591e+05,235 2.9591e+05,235 2.9591e+05,535 2.9591e+05,535 2.9591e+\
05,535 2.9586e+05,535 2.9586e+05,535"];
		l2_ffn_ln_2 -> l2_ffn_up_2	[pos="e,2.9585e+05,542 2.9565e+05,230 2.9578e+05,230 2.9591e+05,230 2.9591e+05,230 2.9591e+05,230 2.9591e+05,542 2.9591e+05,542 2.9591e+\
05,542 2.9586e+05,542 2.9586e+05,542"];
		l2_ffn_ln_2 -> l2_ffn_res_2	[pos="e,2.954e+05,299.04 2.954e+05,261.17 2.954e+05,261.17 2.954e+05,289.04 2.954e+05,289.04"];
		l2_ffn_ln_2 -> l2_ffn_res_2	[pos="e,2.9546e+05,300.93 2.9546e+05,261.17 2.9546e+05,261.17 2.9546e+05,290.93 2.9546e+05,290.93"];
		l2_ffn_ln_2 -> l2_ffn_res_2	[pos="e,2.9552e+05,303.16 2.9552e+05,261.17 2.9552e+05,261.17 2.9552e+05,293.16 2.9552e+05,293.16"];
		l2_ffn_ln_2 -> l2_ffn_res_2	[pos="e,2.9559e+05,305.25 2.9559e+05,261.17 2.9559e+05,261.17 2.9559e+05,295.25 2.9559e+05,295.25"];
		l2_ffn_up_3	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Up Projection</b><br/>GPU: base_gpu_3<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, ffn_dim=\
2048]",
			pos="2.9663e+05,532",
			shape=rectangle,
			width=9.0278];
		l2_ffn_down_3	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Down Projection</b><br/>GPU: base_gpu_3<br/>Input: [batch=1024, seq=?, ffn_dim=2048]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="2.9657e+05,412",
			shape=rectangle,
			width=9.1944];
		l2_ffn_up_3 -> l2_ffn_down_3	[pos="e,2.9642e+05,430 2.9642e+05,513.77 2.9642e+05,513.77 2.9642e+05,440 2.9642e+05,440"];
		l2_ffn_up_3 -> l2_ffn_down_3	[pos="e,2.9654e+05,430 2.9654e+05,513.77 2.9654e+05,513.77 2.9654e+05,440 2.9654e+05,440"];
		l2_ffn_up_3 -> l2_ffn_down_3	[pos="e,2.9666e+05,430 2.9666e+05,513.77 2.9666e+05,513.77 2.9666e+05,440 2.9666e+05,440"];
		l2_ffn_up_3 -> l2_ffn_down_3	[pos="e,2.9678e+05,430 2.9678e+05,513.77 2.9678e+05,513.77 2.9678e+05,440 2.9678e+05,440"];
		l2_ffn_res_3	[fillcolor=lightgray,
			height=0.5,
			label="<b>FFN Residual Add</b><br/>GPU: base_gpu_3<br/>Input: [batch=1024, seq=?, hidden=512] × 2<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="2.9646e+05,315",
			shape=diamond,
			width=15.193];
		l2_ffn_down_3 -> l2_ffn_res_3	[pos="e,2.9637e+05,330.29 2.9637e+05,393.76 2.9637e+05,393.76 2.9637e+05,340.29 2.9637e+05,340.29"];
		l2_ffn_down_3 -> l2_ffn_res_3	[pos="e,2.9651e+05,331.86 2.9651e+05,393.76 2.9651e+05,393.76 2.9651e+05,341.86 2.9651e+05,341.86"];
		l2_ffn_down_3 -> l2_ffn_res_3	[pos="e,2.9664e+05,327.32 2.9664e+05,393.76 2.9664e+05,393.76 2.9664e+05,337.32 2.9664e+05,337.32"];
		l2_ffn_down_3 -> l2_ffn_res_3	[pos="e,2.9677e+05,323.35 2.9677e+05,393.76 2.9677e+05,393.76 2.9677e+05,333.35 2.9677e+05,333.35"];
		l2_ffn_ln_3	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Layer Norm</b><br/>GPU: base_gpu_3<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=512]",
			pos="2.9646e+05,243",
			shape=rectangle,
			width=8.7917];
		l2_ffn_res_3 -> l2_ffn_ln_3	[pos="e,2.9632e+05,261.1 2.9632e+05,301.46 2.9632e+05,301.46 2.9632e+05,271.1 2.9632e+05,271.1"];
		l2_ffn_res_3 -> l2_ffn_ln_3	[pos="e,2.9638e+05,261.05 2.9638e+05,299.73 2.9638e+05,299.73 2.9638e+05,271.05 2.9638e+05,271.05"];
		l2_ffn_res_3 -> l2_ffn_ln_3	[pos="e,2.9644e+05,261.2 2.9644e+05,297.94 2.9644e+05,297.94 2.9644e+05,271.2 2.9644e+05,271.2"];
		l2_ffn_res_3 -> l2_ffn_ln_3	[pos="e,2.9649e+05,261.2 2.9649e+05,297.94 2.9649e+05,297.94 2.9649e+05,271.2 2.9649e+05,271.2"];
		l2_ffn_ln_3 -> l2_ffn_up_3	[pos="e,2.9695e+05,521 2.9678e+05,257 2.969e+05,257 2.9701e+05,257 2.9701e+05,257 2.9701e+05,257 2.9701e+05,521 2.9701e+05,521 2.9701e+\
05,521 2.9696e+05,521 2.9696e+05,521"];
		l2_ffn_ln_3 -> l2_ffn_up_3	[pos="e,2.9695e+05,528 2.9678e+05,254 2.9691e+05,254 2.9702e+05,254 2.9702e+05,254 2.9702e+05,254 2.9702e+05,528 2.9702e+05,528 2.9702e+\
05,528 2.9696e+05,528 2.9696e+05,528"];
		l2_ffn_ln_3 -> l2_ffn_up_3	[pos="e,2.9695e+05,535 2.9678e+05,251 2.9691e+05,251 2.9702e+05,251 2.9702e+05,251 2.9702e+05,251 2.9702e+05,535 2.9702e+05,535 2.9702e+\
05,535 2.9696e+05,535 2.9696e+05,535"];
		l2_ffn_ln_3 -> l2_ffn_up_3	[pos="e,2.9695e+05,542 2.9678e+05,247 2.9691e+05,247 2.9702e+05,247 2.9702e+05,247 2.9702e+05,247 2.9702e+05,542 2.9702e+05,542 2.9702e+\
05,542 2.9696e+05,542 2.9696e+05,542"];
		l2_ffn_ln_3 -> l2_ffn_res_3	[pos="e,2.9655e+05,299.52 2.9655e+05,261.17 2.9655e+05,261.17 2.9655e+05,289.52 2.9655e+05,289.52"];
		l2_ffn_ln_3 -> l2_ffn_res_3	[pos="e,2.9661e+05,301.38 2.9661e+05,261.17 2.9661e+05,261.17 2.9661e+05,291.38 2.9661e+05,291.38"];
		l2_ffn_ln_3 -> l2_ffn_res_3	[pos="e,2.9667e+05,303.59 2.9667e+05,261.17 2.9667e+05,261.17 2.9667e+05,293.59 2.9667e+05,293.59"];
		l2_ffn_ln_3 -> l2_ffn_res_3	[pos="e,2.9672e+05,305.25 2.9672e+05,261.17 2.9672e+05,261.17 2.9672e+05,295.25 2.9672e+05,295.25"];
		l2_ffn_up_4	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Up Projection</b><br/>GPU: base_gpu_4<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, ffn_dim=\
2048]",
			pos="2.9468e+05,532",
			shape=rectangle,
			width=9.0278];
		l2_ffn_down_4	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Down Projection</b><br/>GPU: base_gpu_4<br/>Input: [batch=1024, seq=?, ffn_dim=2048]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="2.9431e+05,412",
			shape=rectangle,
			width=9.1944];
		l2_ffn_up_4 -> l2_ffn_down_4	[pos="e,2.9441e+05,430 2.9441e+05,513.77 2.9441e+05,513.77 2.9441e+05,440 2.9441e+05,440"];
		l2_ffn_up_4 -> l2_ffn_down_4	[pos="e,2.9447e+05,430 2.9447e+05,513.77 2.9447e+05,513.77 2.9447e+05,440 2.9447e+05,440"];
		l2_ffn_up_4 -> l2_ffn_down_4	[pos="e,2.9453e+05,430 2.9453e+05,513.77 2.9453e+05,513.77 2.9453e+05,440 2.9453e+05,440"];
		l2_ffn_up_4 -> l2_ffn_down_4	[pos="e,2.9458e+05,430 2.9458e+05,513.77 2.9458e+05,513.77 2.9458e+05,440 2.9458e+05,440"];
		l2_ffn_res_4	[fillcolor=lightgray,
			height=0.5,
			label="<b>FFN Residual Add</b><br/>GPU: base_gpu_4<br/>Input: [batch=1024, seq=?, hidden=512] × 2<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="2.942e+05,315",
			shape=diamond,
			width=15.193];
		l2_ffn_down_4 -> l2_ffn_res_4	[pos="e,2.9411e+05,330.29 2.9411e+05,393.76 2.9411e+05,393.76 2.9411e+05,340.29 2.9411e+05,340.29"];
		l2_ffn_down_4 -> l2_ffn_res_4	[pos="e,2.9424e+05,331.86 2.9424e+05,393.76 2.9424e+05,393.76 2.9424e+05,341.86 2.9424e+05,341.86"];
		l2_ffn_down_4 -> l2_ffn_res_4	[pos="e,2.9438e+05,327.32 2.9438e+05,393.76 2.9438e+05,393.76 2.9438e+05,337.32 2.9438e+05,337.32"];
		l2_ffn_down_4 -> l2_ffn_res_4	[pos="e,2.9451e+05,323.35 2.9451e+05,393.76 2.9451e+05,393.76 2.9451e+05,333.35 2.9451e+05,333.35"];
		l2_ffn_ln_4	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Layer Norm</b><br/>GPU: base_gpu_4<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=512]",
			pos="2.942e+05,243",
			shape=rectangle,
			width=8.7917];
		l2_ffn_res_4 -> l2_ffn_ln_4	[pos="e,2.9406e+05,261.1 2.9406e+05,301.46 2.9406e+05,301.46 2.9406e+05,271.1 2.9406e+05,271.1"];
		l2_ffn_res_4 -> l2_ffn_ln_4	[pos="e,2.9411e+05,261.05 2.9411e+05,299.73 2.9411e+05,299.73 2.9411e+05,271.05 2.9411e+05,271.05"];
		l2_ffn_res_4 -> l2_ffn_ln_4	[pos="e,2.9417e+05,261.2 2.9417e+05,297.94 2.9417e+05,297.94 2.9417e+05,271.2 2.9417e+05,271.2"];
		l2_ffn_res_4 -> l2_ffn_ln_4	[pos="e,2.9423e+05,261.2 2.9423e+05,297.94 2.9423e+05,297.94 2.9423e+05,271.2 2.9423e+05,271.2"];
		l2_ffn_ln_4 -> l2_ffn_up_4	[pos="e,2.9476e+05,513.61 2.9452e+05,245 2.9465e+05,245 2.9476e+05,245 2.9476e+05,245 2.9476e+05,245 2.9476e+05,503.61 2.9476e+05,503.61"];
		l2_ffn_ln_4 -> l2_ffn_up_4	[pos="e,2.9477e+05,513.73 2.9452e+05,240 2.9465e+05,240 2.9477e+05,240 2.9477e+05,240 2.9477e+05,240 2.9477e+05,503.73 2.9477e+05,503.73"];
		l2_ffn_ln_4 -> l2_ffn_up_4	[pos="e,2.9478e+05,513.87 2.9452e+05,235 2.9465e+05,235 2.9478e+05,235 2.9478e+05,235 2.9478e+05,235 2.9478e+05,503.87 2.9478e+05,503.87"];
		l2_ffn_ln_4 -> l2_ffn_up_4	[pos="e,2.9478e+05,513.56 2.9452e+05,230 2.9465e+05,230 2.9478e+05,230 2.9478e+05,230 2.9478e+05,230 2.9478e+05,503.56 2.9478e+05,503.56"];
		l2_ffn_ln_4 -> l2_ffn_res_4	[pos="e,2.9429e+05,299.52 2.9429e+05,261.17 2.9429e+05,261.17 2.9429e+05,289.52 2.9429e+05,289.52"];
		l2_ffn_ln_4 -> l2_ffn_res_4	[pos="e,2.9434e+05,301.38 2.9434e+05,261.17 2.9434e+05,261.17 2.9434e+05,291.38 2.9434e+05,291.38"];
		l2_ffn_ln_4 -> l2_ffn_res_4	[pos="e,2.944e+05,303.59 2.944e+05,261.17 2.944e+05,261.17 2.944e+05,293.59 2.944e+05,293.59"];
		l2_ffn_ln_4 -> l2_ffn_res_4	[pos="e,2.9446e+05,305.25 2.9446e+05,261.17 2.9446e+05,261.17 2.9446e+05,295.25 2.9446e+05,295.25"];
		l2_ffn_up_5	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Up Projection</b><br/>GPU: base_gpu_5<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, ffn_dim=\
2048]",
			pos="2.9114e+05,532",
			shape=rectangle,
			width=9.0278];
		l2_ffn_down_5	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Down Projection</b><br/>GPU: base_gpu_5<br/>Input: [batch=1024, seq=?, ffn_dim=2048]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="2.9091e+05,412",
			shape=rectangle,
			width=9.1944];
		l2_ffn_up_5 -> l2_ffn_down_5	[pos="e,2.909e+05,430 2.909e+05,513.77 2.909e+05,513.77 2.909e+05,440 2.909e+05,440"];
		l2_ffn_up_5 -> l2_ffn_down_5	[pos="e,2.9099e+05,430 2.9099e+05,513.77 2.9099e+05,513.77 2.9099e+05,440 2.9099e+05,440"];
		l2_ffn_up_5 -> l2_ffn_down_5	[pos="e,2.9107e+05,430 2.9107e+05,513.77 2.9107e+05,513.77 2.9107e+05,440 2.9107e+05,440"];
		l2_ffn_up_5 -> l2_ffn_down_5	[pos="e,2.9116e+05,430 2.9116e+05,513.77 2.9116e+05,513.77 2.9116e+05,440 2.9116e+05,440"];
		l2_ffn_res_5	[fillcolor=lightgray,
			height=0.5,
			label="<b>FFN Residual Add</b><br/>GPU: base_gpu_5<br/>Input: [batch=1024, seq=?, hidden=512] × 2<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="2.908e+05,315",
			shape=diamond,
			width=15.193];
		l2_ffn_down_5 -> l2_ffn_res_5	[pos="e,2.9071e+05,330.29 2.9071e+05,393.76 2.9071e+05,393.76 2.9071e+05,340.29 2.9071e+05,340.29"];
		l2_ffn_down_5 -> l2_ffn_res_5	[pos="e,2.9085e+05,331.86 2.9085e+05,393.76 2.9085e+05,393.76 2.9085e+05,341.86 2.9085e+05,341.86"];
		l2_ffn_down_5 -> l2_ffn_res_5	[pos="e,2.9098e+05,327.32 2.9098e+05,393.76 2.9098e+05,393.76 2.9098e+05,337.32 2.9098e+05,337.32"];
		l2_ffn_down_5 -> l2_ffn_res_5	[pos="e,2.9111e+05,323.35 2.9111e+05,393.76 2.9111e+05,393.76 2.9111e+05,333.35 2.9111e+05,333.35"];
		l2_ffn_ln_5	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Layer Norm</b><br/>GPU: base_gpu_5<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=512]",
			pos="2.908e+05,243",
			shape=rectangle,
			width=8.7917];
		l2_ffn_res_5 -> l2_ffn_ln_5	[pos="e,2.9056e+05,261.25 2.9056e+05,304.99 2.9056e+05,304.99 2.9056e+05,271.25 2.9056e+05,271.25"];
		l2_ffn_res_5 -> l2_ffn_ln_5	[pos="e,2.9063e+05,261.23 2.9063e+05,302.79 2.9063e+05,302.79 2.9063e+05,271.23 2.9063e+05,271.23"];
		l2_ffn_res_5 -> l2_ffn_ln_5	[pos="e,2.907e+05,261.13 2.907e+05,300.43 2.907e+05,300.43 2.907e+05,271.13 2.907e+05,271.13"];
		l2_ffn_res_5 -> l2_ffn_ln_5	[pos="e,2.9077e+05,261.2 2.9077e+05,297.94 2.9077e+05,297.94 2.9077e+05,271.2 2.9077e+05,271.2"];
		l2_ffn_ln_5 -> l2_ffn_up_5	[pos="e,2.9136e+05,513.87 2.9112e+05,249 2.9125e+05,249 2.9136e+05,249 2.9136e+05,249 2.9136e+05,249 2.9136e+05,503.87 2.9136e+05,503.87"];
		l2_ffn_ln_5 -> l2_ffn_up_5	[pos="e,2.9137e+05,513.92 2.9112e+05,243 2.9125e+05,243 2.9137e+05,243 2.9137e+05,243 2.9137e+05,243 2.9137e+05,503.92 2.9137e+05,503.92"];
		l2_ffn_ln_5 -> l2_ffn_up_5	[pos="e,2.9138e+05,513.99 2.9112e+05,237 2.9125e+05,237 2.9138e+05,237 2.9138e+05,237 2.9138e+05,237 2.9138e+05,503.99 2.9138e+05,503.99"];
		l2_ffn_ln_5 -> l2_ffn_up_5	[pos="e,2.9138e+05,513.62 2.9112e+05,231 2.9126e+05,231 2.9138e+05,231 2.9138e+05,231 2.9138e+05,231 2.9138e+05,503.62 2.9138e+05,503.62"];
		l2_ffn_ln_5 -> l2_ffn_res_5	[pos="e,2.9084e+05,298.07 2.9084e+05,261.17 2.9084e+05,261.17 2.9084e+05,288.07 2.9084e+05,288.07"];
		l2_ffn_ln_5 -> l2_ffn_res_5	[pos="e,2.9091e+05,300.46 2.9091e+05,261.17 2.9091e+05,261.17 2.9091e+05,290.46 2.9091e+05,290.46"];
		l2_ffn_ln_5 -> l2_ffn_res_5	[pos="e,2.9098e+05,302.72 2.9098e+05,261.17 2.9098e+05,261.17 2.9098e+05,292.72 2.9098e+05,292.72"];
		l2_ffn_ln_5 -> l2_ffn_res_5	[pos="e,2.9105e+05,304.85 2.9105e+05,261.17 2.9105e+05,261.17 2.9105e+05,294.85 2.9105e+05,294.85"];
		l2_ffn_up_6	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Up Projection</b><br/>GPU: base_gpu_6<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, ffn_dim=\
2048]",
			pos="2.9227e+05,532",
			shape=rectangle,
			width=9.0278];
		l2_ffn_down_6	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Down Projection</b><br/>GPU: base_gpu_6<br/>Input: [batch=1024, seq=?, ffn_dim=2048]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="2.9204e+05,412",
			shape=rectangle,
			width=9.1944];
		l2_ffn_up_6 -> l2_ffn_down_6	[pos="e,2.9203e+05,430 2.9203e+05,513.77 2.9203e+05,513.77 2.9203e+05,440 2.9203e+05,440"];
		l2_ffn_up_6 -> l2_ffn_down_6	[pos="e,2.9212e+05,430 2.9212e+05,513.77 2.9212e+05,513.77 2.9212e+05,440 2.9212e+05,440"];
		l2_ffn_up_6 -> l2_ffn_down_6	[pos="e,2.9221e+05,430 2.9221e+05,513.77 2.9221e+05,513.77 2.9221e+05,440 2.9221e+05,440"];
		l2_ffn_up_6 -> l2_ffn_down_6	[pos="e,2.9229e+05,430 2.9229e+05,513.77 2.9229e+05,513.77 2.9229e+05,440 2.9229e+05,440"];
		l2_ffn_res_6	[fillcolor=lightgray,
			height=0.5,
			label="<b>FFN Residual Add</b><br/>GPU: base_gpu_6<br/>Input: [batch=1024, seq=?, hidden=512] × 2<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="2.9194e+05,315",
			shape=diamond,
			width=15.193];
		l2_ffn_down_6 -> l2_ffn_res_6	[pos="e,2.9185e+05,330.29 2.9185e+05,393.76 2.9185e+05,393.76 2.9185e+05,340.29 2.9185e+05,340.29"];
		l2_ffn_down_6 -> l2_ffn_res_6	[pos="e,2.9198e+05,331.86 2.9198e+05,393.76 2.9198e+05,393.76 2.9198e+05,341.86 2.9198e+05,341.86"];
		l2_ffn_down_6 -> l2_ffn_res_6	[pos="e,2.9211e+05,327.32 2.9211e+05,393.76 2.9211e+05,393.76 2.9211e+05,337.32 2.9211e+05,337.32"];
		l2_ffn_down_6 -> l2_ffn_res_6	[pos="e,2.9224e+05,323.35 2.9224e+05,393.76 2.9224e+05,393.76 2.9224e+05,333.35 2.9224e+05,333.35"];
		l2_ffn_ln_6	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Layer Norm</b><br/>GPU: base_gpu_6<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=512]",
			pos="2.9194e+05,243",
			shape=rectangle,
			width=8.7917];
		l2_ffn_res_6 -> l2_ffn_ln_6	[pos="e,2.9179e+05,261.1 2.9179e+05,301.46 2.9179e+05,301.46 2.9179e+05,271.1 2.9179e+05,271.1"];
		l2_ffn_res_6 -> l2_ffn_ln_6	[pos="e,2.9185e+05,261.05 2.9185e+05,299.73 2.9185e+05,299.73 2.9185e+05,271.05 2.9185e+05,271.05"];
		l2_ffn_res_6 -> l2_ffn_ln_6	[pos="e,2.9191e+05,261.2 2.9191e+05,297.94 2.9191e+05,297.94 2.9191e+05,271.2 2.9191e+05,271.2"];
		l2_ffn_res_6 -> l2_ffn_ln_6	[pos="e,2.9197e+05,261.2 2.9197e+05,297.94 2.9197e+05,297.94 2.9197e+05,271.2 2.9197e+05,271.2"];
		l2_ffn_ln_6 -> l2_ffn_up_6	[pos="e,2.925e+05,513.87 2.9225e+05,249 2.9238e+05,249 2.925e+05,249 2.925e+05,249 2.925e+05,249 2.925e+05,503.87 2.925e+05,503.87"];
		l2_ffn_ln_6 -> l2_ffn_up_6	[pos="e,2.925e+05,513.92 2.9225e+05,243 2.9238e+05,243 2.925e+05,243 2.925e+05,243 2.925e+05,243 2.925e+05,503.92 2.925e+05,503.92"];
		l2_ffn_ln_6 -> l2_ffn_up_6	[pos="e,2.9251e+05,513.99 2.9225e+05,237 2.9239e+05,237 2.9251e+05,237 2.9251e+05,237 2.9251e+05,237 2.9251e+05,503.99 2.9251e+05,503.99"];
		l2_ffn_ln_6 -> l2_ffn_up_6	[pos="e,2.9252e+05,513.62 2.9225e+05,231 2.9239e+05,231 2.9252e+05,231 2.9252e+05,231 2.9252e+05,231 2.9252e+05,503.62 2.9252e+05,503.62"];
		l2_ffn_ln_6 -> l2_ffn_res_6	[pos="e,2.9202e+05,299.52 2.9202e+05,261.17 2.9202e+05,261.17 2.9202e+05,289.52 2.9202e+05,289.52"];
		l2_ffn_ln_6 -> l2_ffn_res_6	[pos="e,2.9208e+05,301.38 2.9208e+05,261.17 2.9208e+05,261.17 2.9208e+05,291.38 2.9208e+05,291.38"];
		l2_ffn_ln_6 -> l2_ffn_res_6	[pos="e,2.9214e+05,303.59 2.9214e+05,261.17 2.9214e+05,261.17 2.9214e+05,293.59 2.9214e+05,293.59"];
		l2_ffn_ln_6 -> l2_ffn_res_6	[pos="e,2.922e+05,305.25 2.922e+05,261.17 2.922e+05,261.17 2.922e+05,295.25 2.922e+05,295.25"];
		l2_ffn_up_7	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Up Projection</b><br/>GPU: base_gpu_7<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, ffn_dim=\
2048]",
			pos="2.9346e+05,532",
			shape=rectangle,
			width=9.0278];
		l2_ffn_down_7	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Down Projection</b><br/>GPU: base_gpu_7<br/>Input: [batch=1024, seq=?, ffn_dim=2048]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="2.9318e+05,412",
			shape=rectangle,
			width=9.1944];
		l2_ffn_up_7 -> l2_ffn_down_7	[pos="e,2.9321e+05,430 2.9321e+05,513.77 2.9321e+05,513.77 2.9321e+05,440 2.9321e+05,440"];
		l2_ffn_up_7 -> l2_ffn_down_7	[pos="e,2.9328e+05,430 2.9328e+05,513.77 2.9328e+05,513.77 2.9328e+05,440 2.9328e+05,440"];
		l2_ffn_up_7 -> l2_ffn_down_7	[pos="e,2.9336e+05,430 2.9336e+05,513.77 2.9336e+05,513.77 2.9336e+05,440 2.9336e+05,440"];
		l2_ffn_up_7 -> l2_ffn_down_7	[pos="e,2.9343e+05,430 2.9343e+05,513.77 2.9343e+05,513.77 2.9343e+05,440 2.9343e+05,440"];
		l2_ffn_res_7	[fillcolor=lightgray,
			height=0.5,
			label="<b>FFN Residual Add</b><br/>GPU: base_gpu_7<br/>Input: [batch=1024, seq=?, hidden=512] × 2<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="2.9307e+05,315",
			shape=diamond,
			width=15.193];
		l2_ffn_down_7 -> l2_ffn_res_7	[pos="e,2.9298e+05,330.29 2.9298e+05,393.76 2.9298e+05,393.76 2.9298e+05,340.29 2.9298e+05,340.29"];
		l2_ffn_down_7 -> l2_ffn_res_7	[pos="e,2.9311e+05,331.86 2.9311e+05,393.76 2.9311e+05,393.76 2.9311e+05,341.86 2.9311e+05,341.86"];
		l2_ffn_down_7 -> l2_ffn_res_7	[pos="e,2.9324e+05,327.32 2.9324e+05,393.76 2.9324e+05,393.76 2.9324e+05,337.32 2.9324e+05,337.32"];
		l2_ffn_down_7 -> l2_ffn_res_7	[pos="e,2.9338e+05,323.35 2.9338e+05,393.76 2.9338e+05,393.76 2.9338e+05,333.35 2.9338e+05,333.35"];
		l2_ffn_ln_7	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Layer Norm</b><br/>GPU: base_gpu_7<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=512]",
			pos="2.9307e+05,243",
			shape=rectangle,
			width=8.7917];
		l2_ffn_res_7 -> l2_ffn_ln_7	[pos="e,2.9293e+05,261.1 2.9293e+05,301.46 2.9293e+05,301.46 2.9293e+05,271.1 2.9293e+05,271.1"];
		l2_ffn_res_7 -> l2_ffn_ln_7	[pos="e,2.9298e+05,261.05 2.9298e+05,299.73 2.9298e+05,299.73 2.9298e+05,271.05 2.9298e+05,271.05"];
		l2_ffn_res_7 -> l2_ffn_ln_7	[pos="e,2.9304e+05,261.2 2.9304e+05,297.94 2.9304e+05,297.94 2.9304e+05,271.2 2.9304e+05,271.2"];
		l2_ffn_res_7 -> l2_ffn_ln_7	[pos="e,2.931e+05,261.2 2.931e+05,297.94 2.931e+05,297.94 2.931e+05,271.2 2.931e+05,271.2"];
		l2_ffn_ln_7 -> l2_ffn_up_7	[pos="e,2.9363e+05,513.87 2.9339e+05,249 2.9351e+05,249 2.9363e+05,249 2.9363e+05,249 2.9363e+05,249 2.9363e+05,503.87 2.9363e+05,503.87"];
		l2_ffn_ln_7 -> l2_ffn_up_7	[pos="e,2.9364e+05,513.92 2.9339e+05,243 2.9352e+05,243 2.9364e+05,243 2.9364e+05,243 2.9364e+05,243 2.9364e+05,503.92 2.9364e+05,503.92"];
		l2_ffn_ln_7 -> l2_ffn_up_7	[pos="e,2.9364e+05,513.99 2.9339e+05,237 2.9352e+05,237 2.9364e+05,237 2.9364e+05,237 2.9364e+05,237 2.9364e+05,503.99 2.9364e+05,503.99"];
		l2_ffn_ln_7 -> l2_ffn_up_7	[pos="e,2.9365e+05,513.62 2.9339e+05,231 2.9352e+05,231 2.9365e+05,231 2.9365e+05,231 2.9365e+05,231 2.9365e+05,503.62 2.9365e+05,503.62"];
		l2_ffn_ln_7 -> l2_ffn_res_7	[pos="e,2.9316e+05,299.52 2.9316e+05,261.17 2.9316e+05,261.17 2.9316e+05,289.52 2.9316e+05,289.52"];
		l2_ffn_ln_7 -> l2_ffn_res_7	[pos="e,2.9321e+05,301.38 2.9321e+05,261.17 2.9321e+05,261.17 2.9321e+05,291.38 2.9321e+05,291.38"];
		l2_ffn_ln_7 -> l2_ffn_res_7	[pos="e,2.9327e+05,303.59 2.9327e+05,261.17 2.9327e+05,261.17 2.9327e+05,293.59 2.9327e+05,293.59"];
		l2_ffn_ln_7 -> l2_ffn_res_7	[pos="e,2.9333e+05,305.25 2.9333e+05,261.17 2.9333e+05,261.17 2.9333e+05,295.25 2.9333e+05,295.25"];
	}
	subgraph cluster_layer3_ffn {
		graph [bb="2.9931e+05,217,3.0837e+05,579",
			fontsize=12,
			label="Layer 3 FFN (Base GPUs)",
			lheight=0.18,
			lp="3.0384e+05,568.5",
			lwidth=2.18,
			style=rounded
		];
		l3_ffn_up_0	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Up Projection</b><br/>GPU: base_gpu_0<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, ffn_dim=\
2048]",
			pos="3.0246e+05,532",
			shape=rectangle,
			width=9.0278];
		l3_ffn_down_0	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Down Projection</b><br/>GPU: base_gpu_0<br/>Input: [batch=1024, seq=?, ffn_dim=2048]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="3.0224e+05,412",
			shape=rectangle,
			width=9.1944];
		l3_ffn_up_0 -> l3_ffn_down_0	[pos="e,3.0223e+05,430 3.0223e+05,513.77 3.0223e+05,513.77 3.0223e+05,440 3.0223e+05,440"];
		l3_ffn_up_0 -> l3_ffn_down_0	[pos="e,3.0231e+05,430 3.0231e+05,513.77 3.0231e+05,513.77 3.0231e+05,440 3.0231e+05,440"];
		l3_ffn_up_0 -> l3_ffn_down_0	[pos="e,3.024e+05,430 3.024e+05,513.77 3.024e+05,513.77 3.024e+05,440 3.024e+05,440"];
		l3_ffn_up_0 -> l3_ffn_down_0	[pos="e,3.0248e+05,430 3.0248e+05,513.77 3.0248e+05,513.77 3.0248e+05,440 3.0248e+05,440"];
		l3_ffn_res_0	[fillcolor=lightgray,
			height=0.5,
			label="<b>FFN Residual Add</b><br/>GPU: base_gpu_0<br/>Input: [batch=1024, seq=?, hidden=512] × 2<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="3.0213e+05,315",
			shape=diamond,
			width=15.193];
		l3_ffn_down_0 -> l3_ffn_res_0	[pos="e,3.0204e+05,330.29 3.0204e+05,393.76 3.0204e+05,393.76 3.0204e+05,340.29 3.0204e+05,340.29"];
		l3_ffn_down_0 -> l3_ffn_res_0	[pos="e,3.0217e+05,331.86 3.0217e+05,393.76 3.0217e+05,393.76 3.0217e+05,341.86 3.0217e+05,341.86"];
		l3_ffn_down_0 -> l3_ffn_res_0	[pos="e,3.0231e+05,327.32 3.0231e+05,393.76 3.0231e+05,393.76 3.0231e+05,337.32 3.0231e+05,337.32"];
		l3_ffn_down_0 -> l3_ffn_res_0	[pos="e,3.0244e+05,323.35 3.0244e+05,393.76 3.0244e+05,393.76 3.0244e+05,333.35 3.0244e+05,333.35"];
		l3_ffn_ln_0	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Layer Norm</b><br/>GPU: base_gpu_0<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=512]",
			pos="3.0213e+05,243",
			shape=rectangle,
			width=8.7917];
		l3_ffn_res_0 -> l3_ffn_ln_0	[pos="e,3.0199e+05,261.1 3.0199e+05,301.46 3.0199e+05,301.46 3.0199e+05,271.1 3.0199e+05,271.1"];
		l3_ffn_res_0 -> l3_ffn_ln_0	[pos="e,3.0204e+05,261.05 3.0204e+05,299.73 3.0204e+05,299.73 3.0204e+05,271.05 3.0204e+05,271.05"];
		l3_ffn_res_0 -> l3_ffn_ln_0	[pos="e,3.021e+05,261.2 3.021e+05,297.94 3.021e+05,297.94 3.021e+05,271.2 3.021e+05,271.2"];
		l3_ffn_res_0 -> l3_ffn_ln_0	[pos="e,3.0216e+05,261.2 3.0216e+05,297.94 3.0216e+05,297.94 3.0216e+05,271.2 3.0216e+05,271.2"];
		l3_ffn_ln_0 -> l3_ffn_up_0	[pos="e,3.0268e+05,513.96 3.0245e+05,257 3.0257e+05,257 3.0268e+05,257 3.0268e+05,257 3.0268e+05,257 3.0268e+05,503.96 3.0268e+05,503.96"];
		l3_ffn_ln_0 -> l3_ffn_up_0	[pos="e,3.0269e+05,513.69 3.0245e+05,253 3.0257e+05,253 3.0269e+05,253 3.0269e+05,253 3.0269e+05,253 3.0269e+05,503.69 3.0269e+05,503.69"];
		l3_ffn_ln_0 -> l3_ffn_up_0	[pos="e,3.0269e+05,513.87 3.0245e+05,249 3.0257e+05,249 3.0269e+05,249 3.0269e+05,249 3.0269e+05,249 3.0269e+05,503.87 3.0269e+05,503.87"];
		l3_ffn_ln_0 -> l3_ffn_up_0	[pos="e,3.0269e+05,513.61 3.0245e+05,245 3.0258e+05,245 3.0269e+05,245 3.0269e+05,245 3.0269e+05,245 3.0269e+05,503.61 3.0269e+05,503.61"];
		l3_ffn_ln_0 -> l3_ffn_res_0	[pos="e,3.0222e+05,299.52 3.0222e+05,261.17 3.0222e+05,261.17 3.0222e+05,289.52 3.0222e+05,289.52"];
		l3_ffn_ln_0 -> l3_ffn_res_0	[pos="e,3.0227e+05,301.38 3.0227e+05,261.17 3.0227e+05,261.17 3.0227e+05,291.38 3.0227e+05,291.38"];
		l3_ffn_ln_0 -> l3_ffn_res_0	[pos="e,3.0233e+05,303.59 3.0233e+05,261.17 3.0233e+05,261.17 3.0233e+05,293.59 3.0233e+05,293.59"];
		l3_ffn_ln_0 -> l3_ffn_res_0	[pos="e,3.0239e+05,305.25 3.0239e+05,261.17 3.0239e+05,261.17 3.0239e+05,295.25 3.0239e+05,295.25"];
		l3_ffn_up_1	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Up Projection</b><br/>GPU: base_gpu_1<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, ffn_dim=\
2048]",
			pos="3.0737e+05,532",
			shape=rectangle,
			width=9.0278];
		l3_ffn_down_1	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Down Projection</b><br/>GPU: base_gpu_1<br/>Input: [batch=1024, seq=?, ffn_dim=2048]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="3.077e+05,412",
			shape=rectangle,
			width=9.1944];
		l3_ffn_up_1 -> l3_ffn_down_1	[pos="e,3.0744e+05,430 3.0744e+05,513.77 3.0744e+05,513.77 3.0744e+05,440 3.0744e+05,440"];
		l3_ffn_up_1 -> l3_ffn_down_1	[pos="e,3.075e+05,430 3.075e+05,513.77 3.075e+05,513.77 3.075e+05,440 3.075e+05,440"];
		l3_ffn_up_1 -> l3_ffn_down_1	[pos="e,3.0756e+05,430 3.0756e+05,513.77 3.0756e+05,513.77 3.0756e+05,440 3.0756e+05,440"];
		l3_ffn_up_1 -> l3_ffn_down_1	[pos="e,3.0763e+05,430 3.0763e+05,513.77 3.0763e+05,513.77 3.0763e+05,440 3.0763e+05,440"];
		l3_ffn_res_1	[fillcolor=lightgray,
			height=0.5,
			label="<b>FFN Residual Add</b><br/>GPU: base_gpu_1<br/>Input: [batch=1024, seq=?, hidden=512] × 2<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="3.0781e+05,315",
			shape=diamond,
			width=15.193];
		l3_ffn_down_1 -> l3_ffn_res_1	[pos="e,3.075e+05,323.35 3.075e+05,393.76 3.075e+05,393.76 3.075e+05,333.35 3.075e+05,333.35"];
		l3_ffn_down_1 -> l3_ffn_res_1	[pos="e,3.0764e+05,327.32 3.0764e+05,393.76 3.0764e+05,393.76 3.0764e+05,337.32 3.0764e+05,337.32"];
		l3_ffn_down_1 -> l3_ffn_res_1	[pos="e,3.0777e+05,331.86 3.0777e+05,393.76 3.0777e+05,393.76 3.0777e+05,341.86 3.0777e+05,341.86"];
		l3_ffn_down_1 -> l3_ffn_res_1	[pos="e,3.079e+05,330.29 3.079e+05,393.76 3.079e+05,393.76 3.079e+05,340.29 3.079e+05,340.29"];
		l3_ffn_ln_1	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Layer Norm</b><br/>GPU: base_gpu_1<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=512]",
			pos="3.0724e+05,243",
			shape=rectangle,
			width=8.7917];
		l3_ffn_res_1 -> l3_ffn_ln_1	[pos="e,3.073e+05,261.13 3.073e+05,313.75 3.073e+05,313.75 3.073e+05,271.13 3.073e+05,271.13"];
		l3_ffn_res_1 -> l3_ffn_ln_1	[pos="e,3.0733e+05,261.06 3.0733e+05,312.6 3.0733e+05,312.6 3.0733e+05,271.06 3.0733e+05,271.06"];
		l3_ffn_res_1 -> l3_ffn_ln_1	[pos="e,3.0736e+05,261.21 3.0736e+05,311.53 3.0736e+05,311.53 3.0736e+05,271.21 3.0736e+05,271.21"];
		l3_ffn_res_1 -> l3_ffn_ln_1	[pos="e,3.074e+05,261.31 3.074e+05,310.28 3.074e+05,310.28 3.074e+05,271.31 3.074e+05,271.31"];
		l3_ffn_ln_1 -> l3_ffn_up_1	[pos="e,3.0724e+05,513.93 3.0724e+05,261.08 3.0724e+05,261.08 3.0724e+05,503.93 3.0724e+05,503.93"];
		l3_ffn_ln_1 -> l3_ffn_up_1	[pos="e,3.0725e+05,513.93 3.0725e+05,261.08 3.0725e+05,261.08 3.0725e+05,503.93 3.0725e+05,503.93"];
		l3_ffn_ln_1 -> l3_ffn_up_1	[pos="e,3.0725e+05,513.93 3.0725e+05,261.08 3.0725e+05,261.08 3.0725e+05,503.93 3.0725e+05,503.93"];
		l3_ffn_ln_1 -> l3_ffn_up_1	[pos="e,3.0726e+05,513.93 3.0726e+05,261.08 3.0726e+05,261.08 3.0726e+05,503.93 3.0726e+05,503.93"];
		l3_ffn_ln_1 -> l3_ffn_res_1	[pos="e,3.0743e+05,309.27 3.0743e+05,261.17 3.0743e+05,261.17 3.0743e+05,299.27 3.0743e+05,299.27"];
		l3_ffn_ln_1 -> l3_ffn_res_1	[pos="e,3.0746e+05,308.26 3.0746e+05,261.17 3.0746e+05,261.17 3.0746e+05,298.26 3.0746e+05,298.26"];
		l3_ffn_ln_1 -> l3_ffn_res_1	[pos="e,3.075e+05,307.18 3.075e+05,261.17 3.075e+05,261.17 3.075e+05,297.18 3.075e+05,297.18"];
		l3_ffn_ln_1 -> l3_ffn_res_1	[pos="e,3.0753e+05,306.04 3.0753e+05,261.17 3.0753e+05,261.17 3.0753e+05,296.04 3.0753e+05,296.04"];
		l3_ffn_up_2	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Up Projection</b><br/>GPU: base_gpu_2<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, ffn_dim=\
2048]",
			pos="3.0651e+05,532",
			shape=rectangle,
			width=9.0278];
		l3_ffn_down_2	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Down Projection</b><br/>GPU: base_gpu_2<br/>Input: [batch=1024, seq=?, ffn_dim=2048]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="3.0663e+05,412",
			shape=rectangle,
			width=9.1944];
		l3_ffn_up_2 -> l3_ffn_down_2	[pos="e,3.064e+05,430 3.064e+05,513.77 3.064e+05,513.77 3.064e+05,440 3.064e+05,440"];
		l3_ffn_up_2 -> l3_ffn_down_2	[pos="e,3.0651e+05,430 3.0651e+05,513.77 3.0651e+05,513.77 3.0651e+05,440 3.0651e+05,440"];
		l3_ffn_up_2 -> l3_ffn_down_2	[pos="e,3.0662e+05,430 3.0662e+05,513.77 3.0662e+05,513.77 3.0662e+05,440 3.0662e+05,440"];
		l3_ffn_up_2 -> l3_ffn_down_2	[pos="e,3.0672e+05,430 3.0672e+05,513.77 3.0672e+05,513.77 3.0672e+05,440 3.0672e+05,440"];
		l3_ffn_res_2	[fillcolor=lightgray,
			height=0.5,
			label="<b>FFN Residual Add</b><br/>GPU: base_gpu_2<br/>Input: [batch=1024, seq=?, hidden=512] × 2<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="3.0668e+05,315",
			shape=diamond,
			width=15.193];
		l3_ffn_down_2 -> l3_ffn_res_2	[pos="e,3.0643e+05,324.87 3.0643e+05,393.76 3.0643e+05,393.76 3.0643e+05,334.87 3.0643e+05,334.87"];
		l3_ffn_down_2 -> l3_ffn_res_2	[pos="e,3.0656e+05,329.37 3.0656e+05,393.76 3.0656e+05,393.76 3.0656e+05,339.37 3.0656e+05,339.37"];
		l3_ffn_down_2 -> l3_ffn_res_2	[pos="e,3.0669e+05,332.51 3.0669e+05,393.76 3.0669e+05,393.76 3.0669e+05,342.51 3.0669e+05,342.51"];
		l3_ffn_down_2 -> l3_ffn_res_2	[pos="e,3.0683e+05,328.19 3.0683e+05,393.76 3.0683e+05,393.76 3.0683e+05,338.19 3.0683e+05,338.19"];
		l3_ffn_ln_2	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Layer Norm</b><br/>GPU: base_gpu_2<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=512]",
			pos="3.0618e+05,243",
			shape=rectangle,
			width=8.7917];
		l3_ffn_res_2 -> l3_ffn_ln_2	[pos="e,3.0617e+05,261.2 3.0617e+05,313.5 3.0617e+05,313.5 3.0617e+05,271.2 3.0617e+05,271.2"];
		l3_ffn_res_2 -> l3_ffn_ln_2	[pos="e,3.0621e+05,261.12 3.0621e+05,312.27 3.0621e+05,312.27 3.0621e+05,271.12 3.0621e+05,271.12"];
		l3_ffn_res_2 -> l3_ffn_ln_2	[pos="e,3.0625e+05,261.28 3.0625e+05,310.71 3.0625e+05,310.71 3.0625e+05,271.28 3.0625e+05,271.28"];
		l3_ffn_res_2 -> l3_ffn_ln_2	[pos="e,3.0629e+05,261.04 3.0629e+05,309.35 3.0629e+05,309.35 3.0629e+05,271.04 3.0629e+05,271.04"];
		l3_ffn_ln_2 -> l3_ffn_up_2	[pos="e,3.0618e+05,542 3.061e+05,261.25 3.061e+05,326.17 3.061e+05,542 3.061e+05,542 3.061e+05,542 3.0617e+05,542 3.0617e+05,542"];
		l3_ffn_ln_2 -> l3_ffn_up_2	[pos="e,3.0618e+05,535 3.0611e+05,261.27 3.0611e+05,325.19 3.0611e+05,535 3.0611e+05,535 3.0611e+05,535 3.0617e+05,535 3.0617e+05,535"];
		l3_ffn_ln_2 -> l3_ffn_up_2	[pos="e,3.0618e+05,528 3.0612e+05,261.26 3.0612e+05,324.16 3.0612e+05,528 3.0612e+05,528 3.0612e+05,528 3.0617e+05,528 3.0617e+05,528"];
		l3_ffn_ln_2 -> l3_ffn_up_2	[pos="e,3.0618e+05,521 3.0612e+05,261.24 3.0612e+05,323.09 3.0612e+05,521 3.0612e+05,521 3.0612e+05,521 3.0617e+05,521 3.0617e+05,521"];
		l3_ffn_ln_2 -> l3_ffn_res_2	[pos="e,3.0633e+05,308.26 3.0633e+05,261.17 3.0633e+05,261.17 3.0633e+05,298.26 3.0633e+05,298.26"];
		l3_ffn_ln_2 -> l3_ffn_res_2	[pos="e,3.0637e+05,306.81 3.0637e+05,261.17 3.0637e+05,261.17 3.0637e+05,296.81 3.0637e+05,296.81"];
		l3_ffn_ln_2 -> l3_ffn_res_2	[pos="e,3.0641e+05,305.65 3.0641e+05,261.17 3.0641e+05,261.17 3.0641e+05,295.65 3.0641e+05,295.65"];
		l3_ffn_ln_2 -> l3_ffn_res_2	[pos="e,3.0645e+05,304.02 3.0645e+05,261.17 3.0645e+05,261.17 3.0645e+05,294.02 3.0645e+05,294.02"];
		l3_ffn_up_3	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Up Projection</b><br/>GPU: base_gpu_3<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, ffn_dim=\
2048]",
			pos="3.0072e+05,532",
			shape=rectangle,
			width=9.0278];
		l3_ffn_down_3	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Down Projection</b><br/>GPU: base_gpu_3<br/>Input: [batch=1024, seq=?, ffn_dim=2048]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="3.0091e+05,412",
			shape=rectangle,
			width=9.1944];
		l3_ffn_up_3 -> l3_ffn_down_3	[pos="e,3.0067e+05,430 3.0067e+05,513.77 3.0067e+05,513.77 3.0067e+05,440 3.0067e+05,440"];
		l3_ffn_up_3 -> l3_ffn_down_3	[pos="e,3.0077e+05,430 3.0077e+05,513.77 3.0077e+05,513.77 3.0077e+05,440 3.0077e+05,440"];
		l3_ffn_up_3 -> l3_ffn_down_3	[pos="e,3.0086e+05,430 3.0086e+05,513.77 3.0086e+05,513.77 3.0086e+05,440 3.0086e+05,440"];
		l3_ffn_up_3 -> l3_ffn_down_3	[pos="e,3.0095e+05,430 3.0095e+05,513.77 3.0095e+05,513.77 3.0095e+05,440 3.0095e+05,440"];
		l3_ffn_res_3	[fillcolor=lightgray,
			height=0.5,
			label="<b>FFN Residual Add</b><br/>GPU: base_gpu_3<br/>Input: [batch=1024, seq=?, hidden=512] × 2<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="3.0102e+05,315",
			shape=diamond,
			width=15.193];
		l3_ffn_down_3 -> l3_ffn_res_3	[pos="e,3.0071e+05,323.35 3.0071e+05,393.76 3.0071e+05,393.76 3.0071e+05,333.35 3.0071e+05,333.35"];
		l3_ffn_down_3 -> l3_ffn_res_3	[pos="e,3.0084e+05,327.32 3.0084e+05,393.76 3.0084e+05,393.76 3.0084e+05,337.32 3.0084e+05,337.32"];
		l3_ffn_down_3 -> l3_ffn_res_3	[pos="e,3.0098e+05,331.86 3.0098e+05,393.76 3.0098e+05,393.76 3.0098e+05,341.86 3.0098e+05,341.86"];
		l3_ffn_down_3 -> l3_ffn_res_3	[pos="e,3.0111e+05,330.29 3.0111e+05,393.76 3.0111e+05,393.76 3.0111e+05,340.29 3.0111e+05,340.29"];
		l3_ffn_ln_3	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Layer Norm</b><br/>GPU: base_gpu_3<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=512]",
			pos="3.0102e+05,243",
			shape=rectangle,
			width=8.7917];
		l3_ffn_res_3 -> l3_ffn_ln_3	[pos="e,3.0077e+05,261.25 3.0077e+05,304.99 3.0077e+05,304.99 3.0077e+05,271.25 3.0077e+05,271.25"];
		l3_ffn_res_3 -> l3_ffn_ln_3	[pos="e,3.0084e+05,261.23 3.0084e+05,302.79 3.0084e+05,302.79 3.0084e+05,271.23 3.0084e+05,271.23"];
		l3_ffn_res_3 -> l3_ffn_ln_3	[pos="e,3.0091e+05,261.13 3.0091e+05,300.43 3.0091e+05,300.43 3.0091e+05,271.13 3.0091e+05,271.13"];
		l3_ffn_res_3 -> l3_ffn_ln_3	[pos="e,3.0098e+05,261.2 3.0098e+05,297.94 3.0098e+05,297.94 3.0098e+05,271.2 3.0098e+05,271.2"];
		l3_ffn_ln_3 -> l3_ffn_up_3	[pos="e,3.0046e+05,513.83 3.007e+05,255 3.0058e+05,255 3.0046e+05,255 3.0046e+05,255 3.0046e+05,255 3.0046e+05,503.83 3.0046e+05,503.83"];
		l3_ffn_ln_3 -> l3_ffn_up_3	[pos="e,3.0045e+05,513.87 3.007e+05,249 3.0057e+05,249 3.0045e+05,249 3.0045e+05,249 3.0045e+05,249 3.0045e+05,503.87 3.0045e+05,503.87"];
		l3_ffn_ln_3 -> l3_ffn_up_3	[pos="e,3.0044e+05,513.92 3.007e+05,243 3.0057e+05,243 3.0044e+05,243 3.0044e+05,243 3.0044e+05,243 3.0044e+05,503.92 3.0044e+05,503.92"];
		l3_ffn_ln_3 -> l3_ffn_up_3	[pos="e,3.0043e+05,513.99 3.007e+05,237 3.0056e+05,237 3.0043e+05,237 3.0043e+05,237 3.0043e+05,237 3.0043e+05,503.99 3.0043e+05,503.99"];
		l3_ffn_ln_3 -> l3_ffn_res_3	[pos="e,3.0105e+05,298.07 3.0105e+05,261.17 3.0105e+05,261.17 3.0105e+05,288.07 3.0105e+05,288.07"];
		l3_ffn_ln_3 -> l3_ffn_res_3	[pos="e,3.0112e+05,300.46 3.0112e+05,261.17 3.0112e+05,261.17 3.0112e+05,290.46 3.0112e+05,290.46"];
		l3_ffn_ln_3 -> l3_ffn_res_3	[pos="e,3.0119e+05,302.72 3.0119e+05,261.17 3.0119e+05,261.17 3.0119e+05,292.72 3.0119e+05,292.72"];
		l3_ffn_ln_3 -> l3_ffn_res_3	[pos="e,3.0127e+05,304.85 3.0127e+05,261.17 3.0127e+05,261.17 3.0127e+05,294.85 3.0127e+05,294.85"];
		l3_ffn_up_4	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Up Projection</b><br/>GPU: base_gpu_4<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, ffn_dim=\
2048]",
			pos="3.0412e+05,532",
			shape=rectangle,
			width=9.0278];
		l3_ffn_down_4	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Down Projection</b><br/>GPU: base_gpu_4<br/>Input: [batch=1024, seq=?, ffn_dim=2048]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="3.0431e+05,412",
			shape=rectangle,
			width=9.1944];
		l3_ffn_up_4 -> l3_ffn_down_4	[pos="e,3.0407e+05,430 3.0407e+05,513.77 3.0407e+05,513.77 3.0407e+05,440 3.0407e+05,440"];
		l3_ffn_up_4 -> l3_ffn_down_4	[pos="e,3.0416e+05,430 3.0416e+05,513.77 3.0416e+05,513.77 3.0416e+05,440 3.0416e+05,440"];
		l3_ffn_up_4 -> l3_ffn_down_4	[pos="e,3.0426e+05,430 3.0426e+05,513.77 3.0426e+05,513.77 3.0426e+05,440 3.0426e+05,440"];
		l3_ffn_up_4 -> l3_ffn_down_4	[pos="e,3.0435e+05,430 3.0435e+05,513.77 3.0435e+05,513.77 3.0435e+05,440 3.0435e+05,440"];
		l3_ffn_res_4	[fillcolor=lightgray,
			height=0.5,
			label="<b>FFN Residual Add</b><br/>GPU: base_gpu_4<br/>Input: [batch=1024, seq=?, hidden=512] × 2<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="3.0442e+05,315",
			shape=diamond,
			width=15.193];
		l3_ffn_down_4 -> l3_ffn_res_4	[pos="e,3.0411e+05,323.35 3.0411e+05,393.76 3.0411e+05,393.76 3.0411e+05,333.35 3.0411e+05,333.35"];
		l3_ffn_down_4 -> l3_ffn_res_4	[pos="e,3.0424e+05,327.32 3.0424e+05,393.76 3.0424e+05,393.76 3.0424e+05,337.32 3.0424e+05,337.32"];
		l3_ffn_down_4 -> l3_ffn_res_4	[pos="e,3.0437e+05,331.86 3.0437e+05,393.76 3.0437e+05,393.76 3.0437e+05,341.86 3.0437e+05,341.86"];
		l3_ffn_down_4 -> l3_ffn_res_4	[pos="e,3.0451e+05,330.29 3.0451e+05,393.76 3.0451e+05,393.76 3.0451e+05,340.29 3.0451e+05,340.29"];
		l3_ffn_ln_4	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Layer Norm</b><br/>GPU: base_gpu_4<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=512]",
			pos="3.0391e+05,243",
			shape=rectangle,
			width=8.7917];
		l3_ffn_res_4 -> l3_ffn_ln_4	[pos="e,3.0391e+05,261.2 3.0391e+05,313.5 3.0391e+05,313.5 3.0391e+05,271.2 3.0391e+05,271.2"];
		l3_ffn_res_4 -> l3_ffn_ln_4	[pos="e,3.0395e+05,261.12 3.0395e+05,312.27 3.0395e+05,312.27 3.0395e+05,271.12 3.0395e+05,271.12"];
		l3_ffn_res_4 -> l3_ffn_ln_4	[pos="e,3.0399e+05,261.28 3.0399e+05,310.71 3.0399e+05,310.71 3.0399e+05,271.28 3.0399e+05,271.28"];
		l3_ffn_res_4 -> l3_ffn_ln_4	[pos="e,3.0403e+05,261.04 3.0403e+05,309.35 3.0403e+05,309.35 3.0403e+05,271.04 3.0403e+05,271.04"];
		l3_ffn_ln_4 -> l3_ffn_up_4	[pos="e,3.0383e+05,513.93 3.0383e+05,261.08 3.0383e+05,261.08 3.0383e+05,503.93 3.0383e+05,503.93"];
		l3_ffn_ln_4 -> l3_ffn_up_4	[pos="e,3.0384e+05,513.93 3.0384e+05,261.08 3.0384e+05,261.08 3.0384e+05,503.93 3.0384e+05,503.93"];
		l3_ffn_ln_4 -> l3_ffn_up_4	[pos="e,3.0385e+05,513.93 3.0385e+05,261.08 3.0385e+05,261.08 3.0385e+05,503.93 3.0385e+05,503.93"];
		l3_ffn_ln_4 -> l3_ffn_up_4	[pos="e,3.0386e+05,513.93 3.0386e+05,261.08 3.0386e+05,261.08 3.0386e+05,503.93 3.0386e+05,503.93"];
		l3_ffn_ln_4 -> l3_ffn_res_4	[pos="e,3.0407e+05,308.26 3.0407e+05,261.17 3.0407e+05,261.17 3.0407e+05,298.26 3.0407e+05,298.26"];
		l3_ffn_ln_4 -> l3_ffn_res_4	[pos="e,3.0411e+05,306.81 3.0411e+05,261.17 3.0411e+05,261.17 3.0411e+05,296.81 3.0411e+05,296.81"];
		l3_ffn_ln_4 -> l3_ffn_res_4	[pos="e,3.0415e+05,305.65 3.0415e+05,261.17 3.0415e+05,261.17 3.0415e+05,295.65 3.0415e+05,295.65"];
		l3_ffn_ln_4 -> l3_ffn_res_4	[pos="e,3.0419e+05,304.02 3.0419e+05,261.17 3.0419e+05,261.17 3.0419e+05,294.02 3.0419e+05,294.02"];
		l3_ffn_up_5	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Up Projection</b><br/>GPU: base_gpu_5<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, ffn_dim=\
2048]",
			pos="3.0001e+05,532",
			shape=rectangle,
			width=9.0278];
		l3_ffn_down_5	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Down Projection</b><br/>GPU: base_gpu_5<br/>Input: [batch=1024, seq=?, ffn_dim=2048]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="2.9996e+05,412",
			shape=rectangle,
			width=9.1944];
		l3_ffn_up_5 -> l3_ffn_down_5	[pos="e,2.998e+05,430 2.998e+05,513.77 2.998e+05,513.77 2.998e+05,440 2.998e+05,440"];
		l3_ffn_up_5 -> l3_ffn_down_5	[pos="e,2.9993e+05,430 2.9993e+05,513.77 2.9993e+05,513.77 2.9993e+05,440 2.9993e+05,440"];
		l3_ffn_up_5 -> l3_ffn_down_5	[pos="e,3.0005e+05,430 3.0005e+05,513.77 3.0005e+05,513.77 3.0005e+05,440 3.0005e+05,440"];
		l3_ffn_up_5 -> l3_ffn_down_5	[pos="e,3.0017e+05,430 3.0017e+05,513.77 3.0017e+05,513.77 3.0017e+05,440 3.0017e+05,440"];
		l3_ffn_res_5	[fillcolor=lightgray,
			height=0.5,
			label="<b>FFN Residual Add</b><br/>GPU: base_gpu_5<br/>Input: [batch=1024, seq=?, hidden=512] × 2<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="2.9987e+05,315",
			shape=diamond,
			width=15.193];
		l3_ffn_down_5 -> l3_ffn_res_5	[pos="e,2.9976e+05,329.68 2.9976e+05,393.76 2.9976e+05,393.76 2.9976e+05,339.68 2.9976e+05,339.68"];
		l3_ffn_down_5 -> l3_ffn_res_5	[pos="e,2.9989e+05,332.19 2.9989e+05,393.76 2.9989e+05,393.76 2.9989e+05,342.19 2.9989e+05,342.19"];
		l3_ffn_down_5 -> l3_ffn_res_5	[pos="e,3.0003e+05,327.89 3.0003e+05,393.76 3.0003e+05,393.76 3.0003e+05,337.89 3.0003e+05,337.89"];
		l3_ffn_down_5 -> l3_ffn_res_5	[pos="e,3.0016e+05,323.6 3.0016e+05,393.76 3.0016e+05,393.76 3.0016e+05,333.6 3.0016e+05,333.6"];
		l3_ffn_ln_5	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Layer Norm</b><br/>GPU: base_gpu_5<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=512]",
			pos="2.9987e+05,243",
			shape=rectangle,
			width=8.7917];
		l3_ffn_res_5 -> l3_ffn_ln_5	[pos="e,2.9972e+05,261.1 2.9972e+05,301.46 2.9972e+05,301.46 2.9972e+05,271.1 2.9972e+05,271.1"];
		l3_ffn_res_5 -> l3_ffn_ln_5	[pos="e,2.9978e+05,261.05 2.9978e+05,299.73 2.9978e+05,299.73 2.9978e+05,271.05 2.9978e+05,271.05"];
		l3_ffn_res_5 -> l3_ffn_ln_5	[pos="e,2.9984e+05,261.2 2.9984e+05,297.94 2.9984e+05,297.94 2.9984e+05,271.2 2.9984e+05,271.2"];
		l3_ffn_res_5 -> l3_ffn_ln_5	[pos="e,2.999e+05,261.2 2.999e+05,297.94 2.999e+05,297.94 2.999e+05,271.2 2.999e+05,271.2"];
		l3_ffn_ln_5 -> l3_ffn_up_5	[pos="e,2.9968e+05,521 2.9955e+05,255 2.9943e+05,255 2.9932e+05,255 2.9932e+05,255 2.9932e+05,255 2.9932e+05,521 2.9932e+05,521 2.9932e+\
05,521 2.9967e+05,521 2.9967e+05,521"];
		l3_ffn_ln_5 -> l3_ffn_up_5	[pos="e,2.9968e+05,528 2.9955e+05,249 2.9943e+05,249 2.9931e+05,249 2.9931e+05,249 2.9931e+05,249 2.9931e+05,528 2.9931e+05,528 2.9931e+\
05,528 2.9967e+05,528 2.9967e+05,528"];
		l3_ffn_ln_5 -> l3_ffn_up_5	[pos="e,2.9968e+05,535 2.9955e+05,243 2.9942e+05,243 2.9931e+05,243 2.9931e+05,243 2.9931e+05,243 2.9931e+05,535 2.9931e+05,535 2.9931e+\
05,535 2.9967e+05,535 2.9967e+05,535"];
		l3_ffn_ln_5 -> l3_ffn_up_5	[pos="e,2.9968e+05,542 2.9955e+05,237 2.9942e+05,237 2.993e+05,237 2.993e+05,237 2.993e+05,237 2.993e+05,542 2.993e+05,542 2.993e+05,542 \
2.9967e+05,542 2.9967e+05,542"];
		l3_ffn_ln_5 -> l3_ffn_res_5	[pos="e,2.9995e+05,299.52 2.9995e+05,261.17 2.9995e+05,261.17 2.9995e+05,289.52 2.9995e+05,289.52"];
		l3_ffn_ln_5 -> l3_ffn_res_5	[pos="e,3.0001e+05,301.38 3.0001e+05,261.17 3.0001e+05,261.17 3.0001e+05,291.38 3.0001e+05,291.38"];
		l3_ffn_ln_5 -> l3_ffn_res_5	[pos="e,3.0007e+05,303.59 3.0007e+05,261.17 3.0007e+05,261.17 3.0007e+05,293.59 3.0007e+05,293.59"];
		l3_ffn_ln_5 -> l3_ffn_res_5	[pos="e,3.0013e+05,305.25 3.0013e+05,261.17 3.0013e+05,261.17 3.0013e+05,295.25 3.0013e+05,295.25"];
		l3_ffn_up_6	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Up Projection</b><br/>GPU: base_gpu_6<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, ffn_dim=\
2048]",
			pos="3.034e+05,532",
			shape=rectangle,
			width=9.0278];
		l3_ffn_down_6	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Down Projection</b><br/>GPU: base_gpu_6<br/>Input: [batch=1024, seq=?, ffn_dim=2048]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="3.0336e+05,412",
			shape=rectangle,
			width=9.1944];
		l3_ffn_up_6 -> l3_ffn_down_6	[pos="e,3.0342e+05,430 3.0342e+05,513.77 3.0342e+05,513.77 3.0342e+05,440 3.0342e+05,440"];
		l3_ffn_up_6 -> l3_ffn_down_6	[pos="e,3.0348e+05,430 3.0348e+05,513.77 3.0348e+05,513.77 3.0348e+05,440 3.0348e+05,440"];
		l3_ffn_up_6 -> l3_ffn_down_6	[pos="e,3.0355e+05,430 3.0355e+05,513.77 3.0355e+05,513.77 3.0355e+05,440 3.0355e+05,440"];
		l3_ffn_up_6 -> l3_ffn_down_6	[pos="e,3.0362e+05,430 3.0362e+05,513.77 3.0362e+05,513.77 3.0362e+05,440 3.0362e+05,440"];
		l3_ffn_res_6	[fillcolor=lightgray,
			height=0.5,
			label="<b>FFN Residual Add</b><br/>GPU: base_gpu_6<br/>Input: [batch=1024, seq=?, hidden=512] × 2<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="3.0326e+05,315",
			shape=diamond,
			width=15.193];
		l3_ffn_down_6 -> l3_ffn_res_6	[pos="e,3.0316e+05,329.68 3.0316e+05,393.76 3.0316e+05,393.76 3.0316e+05,339.68 3.0316e+05,339.68"];
		l3_ffn_down_6 -> l3_ffn_res_6	[pos="e,3.0329e+05,332.19 3.0329e+05,393.76 3.0329e+05,393.76 3.0329e+05,342.19 3.0329e+05,342.19"];
		l3_ffn_down_6 -> l3_ffn_res_6	[pos="e,3.0342e+05,327.89 3.0342e+05,393.76 3.0342e+05,393.76 3.0342e+05,337.89 3.0342e+05,337.89"];
		l3_ffn_down_6 -> l3_ffn_res_6	[pos="e,3.0356e+05,323.6 3.0356e+05,393.76 3.0356e+05,393.76 3.0356e+05,333.6 3.0356e+05,333.6"];
		l3_ffn_ln_6	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Layer Norm</b><br/>GPU: base_gpu_6<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=512]",
			pos="3.0326e+05,243",
			shape=rectangle,
			width=8.7917];
		l3_ffn_res_6 -> l3_ffn_ln_6	[pos="e,3.0302e+05,261.25 3.0302e+05,304.99 3.0302e+05,304.99 3.0302e+05,271.25 3.0302e+05,271.25"];
		l3_ffn_res_6 -> l3_ffn_ln_6	[pos="e,3.0309e+05,261.23 3.0309e+05,302.79 3.0309e+05,302.79 3.0309e+05,271.23 3.0309e+05,271.23"];
		l3_ffn_res_6 -> l3_ffn_ln_6	[pos="e,3.0316e+05,261.13 3.0316e+05,300.43 3.0316e+05,300.43 3.0316e+05,271.13 3.0316e+05,271.13"];
		l3_ffn_res_6 -> l3_ffn_ln_6	[pos="e,3.0323e+05,261.2 3.0323e+05,297.94 3.0323e+05,297.94 3.0323e+05,271.2 3.0323e+05,271.2"];
		l3_ffn_ln_6 -> l3_ffn_up_6	[pos="e,3.0335e+05,513.94 3.0295e+05,241 3.0282e+05,241 3.0271e+05,241 3.0271e+05,241 3.0271e+05,241 3.0271e+05,431 3.0271e+05,431 3.0271e+\
05,431 3.0335e+05,431 3.0335e+05,431 3.0335e+05,431 3.0335e+05,503.94 3.0335e+05,503.94"];
		l3_ffn_ln_6 -> l3_ffn_up_6	[pos="e,3.0328e+05,513.84 3.0295e+05,237 3.0282e+05,237 3.0271e+05,237 3.0271e+05,237 3.0271e+05,237 3.0271e+05,433 3.0271e+05,433 3.0271e+\
05,433 3.0328e+05,433 3.0328e+05,433 3.0328e+05,433 3.0328e+05,503.84 3.0328e+05,503.84"];
		l3_ffn_ln_6 -> l3_ffn_up_6	[pos="e,3.0321e+05,513.76 3.0295e+05,233 3.0282e+05,233 3.027e+05,233 3.027e+05,233 3.027e+05,233 3.027e+05,435 3.027e+05,435 3.027e+05,\
435 3.0321e+05,435 3.0321e+05,435 3.0321e+05,435 3.0321e+05,503.76 3.0321e+05,503.76"];
		l3_ffn_ln_6 -> l3_ffn_up_6	[pos="e,3.0315e+05,513.68 3.0295e+05,229 3.0282e+05,229 3.027e+05,229 3.027e+05,229 3.027e+05,229 3.027e+05,437 3.027e+05,437 3.027e+05,\
437 3.0315e+05,437 3.0315e+05,437 3.0315e+05,437 3.0315e+05,503.68 3.0315e+05,503.68"];
		l3_ffn_ln_6 -> l3_ffn_res_6	[pos="e,3.033e+05,298.07 3.033e+05,261.17 3.033e+05,261.17 3.033e+05,288.07 3.033e+05,288.07"];
		l3_ffn_ln_6 -> l3_ffn_res_6	[pos="e,3.0337e+05,300.46 3.0337e+05,261.17 3.0337e+05,261.17 3.0337e+05,290.46 3.0337e+05,290.46"];
		l3_ffn_ln_6 -> l3_ffn_res_6	[pos="e,3.0344e+05,302.72 3.0344e+05,261.17 3.0344e+05,261.17 3.0344e+05,292.72 3.0344e+05,292.72"];
		l3_ffn_ln_6 -> l3_ffn_res_6	[pos="e,3.0351e+05,304.85 3.0351e+05,261.17 3.0351e+05,261.17 3.0351e+05,294.85 3.0351e+05,294.85"];
		l3_ffn_up_7	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Up Projection</b><br/>GPU: base_gpu_7<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, ffn_dim=\
2048]",
			pos="3.0574e+05,532",
			shape=rectangle,
			width=9.0278];
		l3_ffn_down_7	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Down Projection</b><br/>GPU: base_gpu_7<br/>Input: [batch=1024, seq=?, ffn_dim=2048]<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="3.0564e+05,412",
			shape=rectangle,
			width=9.1944];
		l3_ffn_up_7 -> l3_ffn_down_7	[pos="e,3.0552e+05,430 3.0552e+05,513.77 3.0552e+05,513.77 3.0552e+05,440 3.0552e+05,440"];
		l3_ffn_up_7 -> l3_ffn_down_7	[pos="e,3.0563e+05,430 3.0563e+05,513.77 3.0563e+05,513.77 3.0563e+05,440 3.0563e+05,440"];
		l3_ffn_up_7 -> l3_ffn_down_7	[pos="e,3.0574e+05,430 3.0574e+05,513.77 3.0574e+05,513.77 3.0574e+05,440 3.0574e+05,440"];
		l3_ffn_up_7 -> l3_ffn_down_7	[pos="e,3.0586e+05,430 3.0586e+05,513.77 3.0586e+05,513.77 3.0586e+05,440 3.0586e+05,440"];
		l3_ffn_res_7	[fillcolor=lightgray,
			height=0.5,
			label="<b>FFN Residual Add</b><br/>GPU: base_gpu_7<br/>Input: [batch=1024, seq=?, hidden=512] × 2<br/>Output: [batch=1024, seq=?, hidden=\
512]",
			pos="3.0553e+05,315",
			shape=diamond,
			width=15.193];
		l3_ffn_down_7 -> l3_ffn_res_7	[pos="e,3.0544e+05,330.29 3.0544e+05,393.76 3.0544e+05,393.76 3.0544e+05,340.29 3.0544e+05,340.29"];
		l3_ffn_down_7 -> l3_ffn_res_7	[pos="e,3.0557e+05,331.86 3.0557e+05,393.76 3.0557e+05,393.76 3.0557e+05,341.86 3.0557e+05,341.86"];
		l3_ffn_down_7 -> l3_ffn_res_7	[pos="e,3.057e+05,327.32 3.057e+05,393.76 3.057e+05,393.76 3.057e+05,337.32 3.057e+05,337.32"];
		l3_ffn_down_7 -> l3_ffn_res_7	[pos="e,3.0583e+05,323.35 3.0583e+05,393.76 3.0583e+05,393.76 3.0583e+05,333.35 3.0583e+05,333.35"];
		l3_ffn_ln_7	[fillcolor=lightgreen,
			height=0.5,
			label="<b>FFN Layer Norm</b><br/>GPU: base_gpu_7<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, hidden=512]",
			pos="3.0553e+05,243",
			shape=rectangle,
			width=8.7917];
		l3_ffn_res_7 -> l3_ffn_ln_7	[pos="e,3.0528e+05,261.25 3.0528e+05,304.99 3.0528e+05,304.99 3.0528e+05,271.25 3.0528e+05,271.25"];
		l3_ffn_res_7 -> l3_ffn_ln_7	[pos="e,3.0535e+05,261.23 3.0535e+05,302.79 3.0535e+05,302.79 3.0535e+05,271.23 3.0535e+05,271.23"];
		l3_ffn_res_7 -> l3_ffn_ln_7	[pos="e,3.0542e+05,261.13 3.0542e+05,300.43 3.0542e+05,300.43 3.0542e+05,271.13 3.0542e+05,271.13"];
		l3_ffn_res_7 -> l3_ffn_ln_7	[pos="e,3.0549e+05,261.2 3.0549e+05,297.94 3.0549e+05,297.94 3.0549e+05,271.2 3.0549e+05,271.2"];
		l3_ffn_ln_7 -> l3_ffn_up_7	[pos="e,3.0541e+05,521 3.0521e+05,255 3.0509e+05,255 3.0498e+05,255 3.0498e+05,255 3.0498e+05,255 3.0498e+05,521 3.0498e+05,521 3.0498e+\
05,521 3.054e+05,521 3.054e+05,521"];
		l3_ffn_ln_7 -> l3_ffn_up_7	[pos="e,3.0541e+05,528 3.0521e+05,249 3.0509e+05,249 3.0497e+05,249 3.0497e+05,249 3.0497e+05,249 3.0497e+05,528 3.0497e+05,528 3.0497e+\
05,528 3.054e+05,528 3.054e+05,528"];
		l3_ffn_ln_7 -> l3_ffn_up_7	[pos="e,3.0541e+05,535 3.0521e+05,243 3.0508e+05,243 3.0497e+05,243 3.0497e+05,243 3.0497e+05,243 3.0497e+05,535 3.0497e+05,535 3.0497e+\
05,535 3.054e+05,535 3.054e+05,535"];
		l3_ffn_ln_7 -> l3_ffn_up_7	[pos="e,3.0541e+05,542 3.0521e+05,237 3.0508e+05,237 3.0497e+05,237 3.0497e+05,237 3.0497e+05,237 3.0497e+05,542 3.0497e+05,542 3.0497e+\
05,542 3.054e+05,542 3.054e+05,542"];
		l3_ffn_ln_7 -> l3_ffn_res_7	[pos="e,3.0556e+05,298.07 3.0556e+05,261.17 3.0556e+05,261.17 3.0556e+05,288.07 3.0556e+05,288.07"];
		l3_ffn_ln_7 -> l3_ffn_res_7	[pos="e,3.0563e+05,300.46 3.0563e+05,261.17 3.0563e+05,261.17 3.0563e+05,290.46 3.0563e+05,290.46"];
		l3_ffn_ln_7 -> l3_ffn_res_7	[pos="e,3.057e+05,302.72 3.057e+05,261.17 3.057e+05,261.17 3.057e+05,292.72 3.057e+05,292.72"];
		l3_ffn_ln_7 -> l3_ffn_res_7	[pos="e,3.0577e+05,304.85 3.0577e+05,261.17 3.0577e+05,261.17 3.0577e+05,294.85 3.0577e+05,294.85"];
	}
	subgraph cluster_output {
		graph [bb="3.0103e+05,136,3.0614e+05,209",
			fontsize=12,
			label="Output Layer (Base GPUs)",
			lheight=0.18,
			lp="3.0359e+05,198.5",
			lwidth=2.22,
			style=rounded
		];
		final_output_0	[fillcolor=lightgreen,
			height=0.5,
			label="<b>Linear Output</b><br/>GPU: base_gpu_0<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, vocab=4000]",
			pos="3.0263e+05,162",
			shape=rectangle,
			width=8.625];
		final_output_1	[fillcolor=lightgreen,
			height=0.5,
			label="<b>Linear Output</b><br/>GPU: base_gpu_1<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, vocab=4000]",
			pos="3.0582e+05,162",
			shape=rectangle,
			width=8.625];
		final_output_2	[fillcolor=lightgreen,
			height=0.5,
			label="<b>Linear Output</b><br/>GPU: base_gpu_2<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, vocab=4000]",
			pos="3.0519e+05,162",
			shape=rectangle,
			width=8.625];
		final_output_3	[fillcolor=lightgreen,
			height=0.5,
			label="<b>Linear Output</b><br/>GPU: base_gpu_3<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, vocab=4000]",
			pos="3.0199e+05,162",
			shape=rectangle,
			width=8.625];
		final_output_4	[fillcolor=lightgreen,
			height=0.5,
			label="<b>Linear Output</b><br/>GPU: base_gpu_4<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, vocab=4000]",
			pos="3.0391e+05,162",
			shape=rectangle,
			width=8.625];
		final_output_5	[fillcolor=lightgreen,
			height=0.5,
			label="<b>Linear Output</b><br/>GPU: base_gpu_5<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, vocab=4000]",
			pos="3.0135e+05,162",
			shape=rectangle,
			width=8.625];
		final_output_6	[fillcolor=lightgreen,
			height=0.5,
			label="<b>Linear Output</b><br/>GPU: base_gpu_6<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, vocab=4000]",
			pos="3.0327e+05,162",
			shape=rectangle,
			width=8.625];
		final_output_7	[fillcolor=lightgreen,
			height=0.5,
			label="<b>Linear Output</b><br/>GPU: base_gpu_7<br/>Input: [batch=1024, seq=?, hidden=512]<br/>Output: [batch=1024, seq=?, vocab=4000]",
			pos="3.0455e+05,162",
			shape=rectangle,
			width=8.625];
	}
	input	[fillcolor=lightblue,
		height=0.5,
		label="<b>Model Input</b><br/>Input: [batch_size=1024, seq_len=?, vocab_size=32000]",
		pos="12065,731",
		shape=ellipse,
		width=6.1319];
	resource_manager	[height=0.5,
		label="<b>Resource Manager</b><br/>Monitors sequence length<br/>Allocates attention pool GPUs<br/>Threshold: 4096 tokens",
		pos="53190,659",
		width=10.423];
	input -> resource_manager	[pos="e,52814,659 11991,713.94 11991,692.65 11991,659 11991,659 11991,659 52804,659 52804,659"];
	input -> base_embed_0	[pos="e,14057,430.35 12212,717.34 12212,701.93 12212,679 12212,679 12212,679 14057,679 14057,679 14057,679 14057,440.35 14057,440.35"];
	input -> base_embed_1	[pos="e,13378,430.28 12139,713.94 12139,698.45 12139,678 12139,678 12139,678 13378,678 13378,678 13378,678 13378,440.28 13378,440.28"];
	input -> base_embed_2	[pos="e,12696,430.21 12065,712.72 12065,697.05 12065,677 12065,677 12065,677 12696,677 12696,677 12696,677 12696,440.21 12696,440.21"];
	input -> base_embed_3	[pos="e,11401,430.34 11890,720 11693,720 11401,720 11401,720 11401,720 11401,440.34 11401,440.34"];
	input -> base_embed_4	[pos="e,11918,430.24 11918,717.29 11918,717.29 11918,440.24 11918,440.24"];
	input -> base_embed_5	[pos="e,10737,430.3 11849,727 11473,727 10737,727 10737,727 10737,727 10737,440.3 10737,440.3"];
	input -> base_embed_6	[pos="e,10073,430.23 11847,734 11330,734 10073,734 10073,734 10073,734 10073,440.23 10073,440.23"];
	input -> base_embed_7	[pos="e,9409,430.16 11881,741 11280,741 9409,741 9409,741 9409,741 9409,440.16 9409,440.16"];
	resource_manager -> seq_router	[pos="e,92149,543.7 53399,675 56459,675 92149,675 92149,675 92149,675 92149,553.7 92149,553.7"];
	base_pos_0 -> l0_ffn_ln_0	[pos="e,8813.4,261.18 13863,296.76 13863,281.43 13863,262 13863,262 13863,262 8813.4,262 8813.4,262 8813.4,262 8813.4,261.92 8813.4,261.92"];
	base_pos_0 -> l1_ffn_ln_0	[pos="e,23710,261.04 14251,296.87 14251,286.69 14251,276 14251,276 14251,276 23710,276 23710,276 23710,276 23710,271.04 23710,271.04"];
	base_pos_0 -> l2_ffn_ln_0	[pos="e,2.9818e+05,261.06 14165,333.06 14165,344.44 14165,357 14165,357 14165,357 2.9818e+05,357 2.9818e+05,357 2.9818e+05,357 2.9818e+\
05,271.06 2.9818e+05,271.06"];
	base_pos_0 -> l3_ffn_ln_0	[pos="e,3.0206e+05,224.72 14122,296.95 14122,262.11 14122,189 14122,189 14122,189 3.0206e+05,189 3.0206e+05,189 3.0206e+05,189 3.0206e+\
05,214.72 3.0206e+05,214.72"];
	allreduce_embed	[fillcolor=lightyellow,
		height=0.5,
		label="<b>All-Reduce</b><br/>TP across 8 base GPUs<br/>[batch=1024, seq=?, dim=4096]",
		pos="11733,243",
		shape=parallelogram,
		width=9.47];
	base_pos_0 -> allreduce_embed	[pos="e,12020,247 13992,296.78 13992,276.63 13992,247 13992,247 13992,247 12030,247 12030,247"];
	base_pos_1 -> l0_ffn_ln_1	[pos="e,3416.9,261.16 13199,296.96 13199,284.44 13199,270 13199,270 13199,270 3416.9,270 3416.9,270 3416.9,270 3416.9,269.12 3416.9,269.12"];
	base_pos_1 -> l1_ffn_ln_1	[pos="e,22567,261.04 13587,296.87 13587,286.69 13587,276 13587,276 13587,276 22567,276 22567,276 22567,276 22567,271.04 22567,271.04"];
	base_pos_1 -> l2_ffn_ln_1	[pos="e,2.9747e+05,224.75 13458,296.89 13458,263.13 13458,194 13458,194 13458,194 2.9747e+05,194 2.9747e+05,194 2.9747e+05,194 2.9747e+\
05,214.75 2.9747e+05,214.75"];
	base_pos_1 -> l3_ffn_ln_1	[pos="e,3.0724e+05,261.18 13501,333.24 13501,348.57 13501,368 13501,368 13501,368 3.0724e+05,368 3.0724e+05,368 3.0724e+05,368 3.0724e+\
05,271.18 3.0724e+05,271.18"];
	base_pos_1 -> allreduce_embed	[pos="e,12039,252 13328,296.78 13328,278.17 13328,252 13328,252 13328,252 12049,252 12049,252"];
	base_pos_2 -> l0_ffn_ln_2	[pos="e,741.25,261.1 12514,296.97 12514,290.15 12514,284 12514,284 12514,284 741.25,284 741.25,284 741.25,284 741.25,271.1 741.25,271.1"];
	base_pos_2 -> l1_ffn_ln_2	[pos="e,21435,261.24 12944,296.87 12944,286.29 12944,275 12944,275 12944,275 21435,275 21435,275 21435,275 21435,271.24 21435,271.24"];
	base_pos_2 -> l2_ffn_ln_2	[pos="e,2.9533e+05,224.96 12837,296.93 12837,263.64 12837,196 12837,196 12837,196 2.9533e+05,196 2.9533e+05,196 2.9533e+05,196 2.9533e+\
05,214.96 2.9533e+05,214.96"];
	base_pos_2 -> l3_ffn_ln_2	[pos="e,3.0595e+05,225 12729,296.92 12729,260.77 12729,183 12729,183 12729,183 3.0595e+05,183 3.0595e+05,183 3.0595e+05,183 3.0595e+05,\
215 3.0595e+05,215"];
	base_pos_2 -> allreduce_embed	[pos="e,12055,256 12621,296.98 12621,279.63 12621,256 12621,256 12621,256 12065,256 12065,256"];
	base_pos_3 -> l0_ffn_ln_3	[pos="e,5312.4,261.19 11157,296.85 11157,283.26 11157,267 11157,267 11157,267 5312.4,267 5312.4,267 5312.4,267 5312.4,266.42 5312.4,266.42"];
	base_pos_3 -> l1_ffn_ln_3	[pos="e,19156,261.14 11613,296.94 11613,285.56 11613,273 11613,273 11613,273 19156,273 19156,273 19156,273 19156,271.14 19156,271.14"];
	base_pos_3 -> l2_ffn_ln_3	[pos="e,2.9621e+05,261.1 11314,296.97 11314,290.15 11314,284 11314,284 11314,284 2.9621e+05,284 2.9621e+05,284 2.9621e+05,284 2.9621e+\
05,271.1 2.9621e+05,271.1"];
	base_pos_3 -> l3_ffn_ln_3	[pos="e,3.0096e+05,224.81 11235,296.97 11235,262.58 11235,191 11235,191 11235,191 3.0096e+05,191 3.0096e+05,191 3.0096e+05,191 3.0096e+\
05,214.81 3.0096e+05,214.81"];
	base_pos_3 -> allreduce_embed	[pos="e,11503,253.57 11503,296.83 11503,296.83 11503,263.57 11503,263.57"];
	base_pos_4 -> l0_ffn_ln_4	[pos="e,6812.9,261.12 11853,296.75 11853,282.82 11853,266 11853,266 11853,266 6812.9,266 6812.9,266 6812.9,266 6812.9,265.51 6812.9,265.51"];
	base_pos_4 -> l1_ffn_ln_4	[pos="e,20308,261.03 12309,296.9 12309,285.91 12309,274 12309,274 12309,274 20308,274 20308,274 20308,274 20308,271.03 20308,271.03"];
	base_pos_4 -> l2_ffn_ln_4	[pos="e,2.942e+05,224.82 12231,296.82 12231,263.72 12231,197 12231,197 12231,197 2.942e+05,197 2.942e+05,197 2.942e+05,197 2.942e+05,214.82 \
2.942e+05,214.82"];
	base_pos_4 -> l3_ffn_ln_4	[pos="e,3.038e+05,224.96 12152,296.79 12152,261.23 12152,186 12152,186 12152,186 3.038e+05,186 3.038e+05,186 3.038e+05,186 3.038e+05,214.96 \
3.038e+05,214.96"];
	base_pos_4 -> allreduce_embed	[pos="e,11963,261.41 11963,296.83 11963,296.83 11963,271.41 11963,271.41"];
	base_pos_5 -> l0_ffn_ln_5	[pos="e,4521.9,261.17 9857.7,296.96 9857.7,283.71 9857.7,268 9857.7,268 9857.7,268 4521.9,268 4521.9,268 4521.9,268 4521.9,267.32 4521.9,\
267.32"];
	base_pos_5 -> l1_ffn_ln_5	[pos="e,18044,261.14 10181,296.94 10181,285.56 10181,273 10181,273 10181,273 18044,273 18044,273 18044,273 18044,271.14 18044,271.14"];
	base_pos_5 -> l2_ffn_ln_5	[pos="e,2.908e+05,224.51 10073,296.78 10073,264.35 10073,200 10073,200 10073,200 2.908e+05,200 2.908e+05,200 2.908e+05,200 2.908e+05,214.51 \
2.908e+05,214.51"];
	base_pos_5 -> l3_ffn_ln_5	[pos="e,2.9976e+05,224.88 9965.3,296.85 9965.3,262.64 9965.3,192 9965.3,192 9965.3,192 2.9976e+05,192 2.9976e+05,192 2.9976e+05,192 2.9976e+\
05,214.88 2.9976e+05,214.88"];
	base_pos_5 -> allreduce_embed	[pos="e,11500,253 10288,296.73 10288,278.44 10288,253 10288,253 10288,253 11490,253 11490,253"];
	base_pos_6 -> l0_ffn_ln_6	[pos="e,2284.9,261.21 9193.7,296.85 9193.7,284.73 9193.7,271 9193.7,271 9193.7,271 2284.9,271 2284.9,271 2284.9,271 2284.9,270.02 2284.9,\
270.02"];
	base_pos_6 -> l1_ffn_ln_6	[pos="e,16918,261.2 9516.7,296.51 9516.7,284.86 9516.7,272 9516.7,272 9516.7,272 16918,272 16918,272 16918,272 16918,270.92 16918,270.92"];
	base_pos_6 -> l2_ffn_ln_6	[pos="e,2.9194e+05,224.85 9409,296.88 9409,264.25 9409,199 9409,199 9409,199 2.9194e+05,199 2.9194e+05,199 2.9194e+05,199 2.9194e+05,214.85 \
2.9194e+05,214.85"];
	base_pos_6 -> l3_ffn_ln_6	[pos="e,3.0296e+05,224.99 9301.3,296.8 9301.3,261.69 9301.3,188 9301.3,188 9301.3,188 3.0296e+05,188 3.0296e+05,188 3.0296e+05,188 3.0296e+\
05,214.99 3.0296e+05,214.99"];
	base_pos_6 -> allreduce_embed	[pos="e,11489,250 9624.3,296.89 9624.3,277.66 9624.3,250 9624.3,250 9624.3,250 11479,250 11479,250"];
	base_pos_7 -> l0_ffn_ln_7	[pos="e,7972.5,261.15 10522,296.81 10522,281.82 10522,263 10522,263 10522,263 7972.5,263 7972.5,263 7972.5,263 7972.5,262.82 7972.5,262.82"];
	base_pos_7 -> l1_ffn_ln_7	[pos="e,15786,261.08 10845,296.88 10845,282.22 10845,264 10845,264 10845,264 15786,264 15786,264 15786,264 15786,263.71 15786,263.71"];
	base_pos_7 -> l2_ffn_ln_7	[pos="e,2.9307e+05,224.9 10737,296.84 10737,264.9 10737,202 10737,202 10737,202 2.9307e+05,202 2.9307e+05,202 2.9307e+05,202 2.9307e+05,\
214.9 2.9307e+05,214.9"];
	base_pos_7 -> l3_ffn_ln_7	[pos="e,3.054e+05,224.98 10629,296.79 10629,260.79 10629,184 10629,184 10629,184 3.054e+05,184 3.054e+05,184 3.054e+05,184 3.054e+05,214.98 \
3.054e+05,214.98"];
	base_pos_7 -> allreduce_embed	[pos="e,11516,257 10952,296.97 10952,279.94 10952,257 10952,257 10952,257 11506,257 11506,257"];
	kv_sync_0	[fillcolor=lightyellow,
		height=0.5,
		label="<b>KV Cache Sync</b><br/>Synchronizes K,V tensors<br/>Across attention pool GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
		pos="1.2608e+05,659",
		shape=parallelogram,
		width=14.697];
	seq_router -> kv_sync_0	[pos="e,1.2565e+05,640.7 92468,550.03 92468,569.58 92468,598 92468,598 92468,598 1.2565e+05,598 1.2565e+05,598 1.2565e+05,598 1.2565e+\
05,630.7 1.2565e+05,630.7"];
	kv_sync_1	[fillcolor=lightyellow,
		height=0.5,
		label="<b>KV Cache Sync</b><br/>Synchronizes K,V tensors<br/>Across attention pool GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
		pos="1.2716e+05,659",
		shape=parallelogram,
		width=14.697];
	seq_router -> kv_sync_1	[pos="e,1.2727e+05,640.78 92627,550.17 92627,569.09 92627,596 92627,596 92627,596 1.2727e+05,596 1.2727e+05,596 1.2727e+05,596 1.2727e+\
05,630.78 1.2727e+05,630.78"];
	kv_sync_2	[fillcolor=lightyellow,
		height=0.5,
		label="<b>KV Cache Sync</b><br/>Synchronizes K,V tensors<br/>Across attention pool GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
		pos="1.1765e+05,659",
		shape=parallelogram,
		width=14.697];
	seq_router -> kv_sync_2	[pos="e,1.1731e+05,673 92787,550.14 92787,588.23 92787,673 92787,673 92787,673 1.173e+05,673 1.173e+05,673"];
	kv_sync_3	[fillcolor=lightyellow,
		height=0.5,
		label="<b>KV Cache Sync</b><br/>Synchronizes K,V tensors<br/>Across attention pool GPUs<br/>[batch=1024, seq=?, heads=32, d_k=128]",
		pos="1.25e+05,659",
		shape=parallelogram,
		width=14.697];
	seq_router -> kv_sync_3	[pos="e,1.245e+05,646 92309,550.31 92309,570.15 92309,599 92309,599 92309,599 1.195e+05,599 1.195e+05,599 1.195e+05,599 1.195e+05,646 \
1.195e+05,646 1.195e+05,646 1.2449e+05,646 1.2449e+05,646"];
	hier_reduce_0_8	[fillcolor=lightgray,
		height=0.5,
		label="<b>Hierarchical Reduction</b><br/>Aggregates attention results<br/>From 8 GPUs to 8 base GPUs<br/>[batch=1024, seq=?, hidden=4096]",
		pos="14929,315",
		shape=diamond,
		width=14.592];
	attn_block_0_0_8 -> hier_reduce_0_8	[pos="e,15046,301 93999,430.15 93999,443.74 93999,460 93999,460 93999,460 15475,460 15475,460 15475,460 15475,301 15475,301 15475,301 \
15056,301 15056,301"];
	attn_block_0_1_8 -> hier_reduce_0_8	[pos="e,15162,305 93437,393.83 93437,391.55 93437,390 93437,390 93437,390 15478,390 15478,390 15478,390 15478,305 15478,305 15478,305 \
15172,305 15172,305"];
	attn_block_0_2_8 -> hier_reduce_0_8	[pos="e,15046,329 1.0026e+05,430 1.0026e+05,447.68 1.0026e+05,472 1.0026e+05,472 1.0026e+05,472 15457,472 15457,472 15457,472 15457,329 \
15457,329 15457,329 15056,329 15056,329"];
	attn_block_0_3_8 -> hier_reduce_0_8	[pos="e,15163,325 99214,430.03 99214,447.06 99214,470 99214,470 99214,470 15460,470 15460,470 15460,470 15460,325 15460,325 15460,325 \
15173,325 15173,325"];
	attn_block_0_4_8 -> hier_reduce_0_8	[pos="e,15279,321 98165,430.03 98165,446.4 98165,468 98165,468 98165,468 15463,468 15463,468 15463,468 15463,321 15463,321 15463,321 15289,\
321 15289,321"];
	attn_block_0_5_8 -> hier_reduce_0_8	[pos="e,15396,317 97117,430.28 97117,445.95 97117,466 97117,466 97117,466 15466,466 15466,466 15466,466 15466,317 15466,317 15466,317 \
15406,317 15406,317"];
	attn_block_0_6_8 -> hier_reduce_0_8	[pos="e,15396,313 96072,430.19 96072,445.18 96072,464 96072,464 96072,464 15469,464 15469,464 15469,464 15469,313 15469,313 15469,313 \
15406,313 15406,313"];
	attn_block_0_7_8 -> hier_reduce_0_8	[pos="e,15279,309 95031,430.05 95031,444.37 95031,462 95031,462 95031,462 15472,462 15472,462 15472,462 15472,309 15472,309 15472,309 \
15289,309 15289,309"];
	hier_reduce_1_8	[fillcolor=lightgray,
		height=0.5,
		label="<b>Hierarchical Reduction</b><br/>Aggregates attention results<br/>From 8 GPUs to 8 base GPUs<br/>[batch=1024, seq=?, hidden=4096]",
		pos="90880,315",
		shape=diamond,
		width=14.592];
	attn_block_1_0_8 -> hier_reduce_1_8	[pos="e,91026,328 1.0282e+05,393.77 1.0282e+05,369.07 1.0282e+05,328 1.0282e+05,328 1.0282e+05,328 91036,328 91036,328"];
	attn_block_1_1_8 -> hier_reduce_1_8	[pos="e,90968,330 1.0184e+05,393.8 1.0184e+05,369.64 1.0184e+05,330 1.0184e+05,330 1.0184e+05,330 90978,330 90978,330"];
	attn_block_1_2_8 -> hier_reduce_1_8	[pos="e,91376,316 1.0905e+05,393.94 1.0905e+05,366.13 1.0905e+05,316 1.0905e+05,316 1.0905e+05,316 91386,316 91386,316"];
	attn_block_1_3_8 -> hier_reduce_1_8	[pos="e,91318,318 1.08e+05,393.88 1.08e+05,366.56 1.08e+05,318 1.08e+05,318 1.08e+05,318 91328,318 91328,318"];
	attn_block_1_4_8 -> hier_reduce_1_8	[pos="e,91259,320 1.0695e+05,393.82 1.0695e+05,367.01 1.0695e+05,320 1.0695e+05,320 1.0695e+05,320 91269,320 91269,320"];
	attn_block_1_5_8 -> hier_reduce_1_8	[pos="e,91201,322 1.0591e+05,393.79 1.0591e+05,367.49 1.0591e+05,322 1.0591e+05,322 1.0591e+05,322 91211,322 91211,322"];
	attn_block_1_6_8 -> hier_reduce_1_8	[pos="e,91143,324 1.0487e+05,393.77 1.0487e+05,367.99 1.0487e+05,324 1.0487e+05,324 1.0487e+05,324 91153,324 91153,324"];
	attn_block_1_7_8 -> hier_reduce_1_8	[pos="e,91084,326 1.0383e+05,393.76 1.0383e+05,368.52 1.0383e+05,326 1.0383e+05,326 1.0383e+05,326 91094,326 91094,326"];
	hier_reduce_2_8	[fillcolor=lightgray,
		height=0.5,
		label="<b>Hierarchical Reduction</b><br/>Aggregates attention results<br/>From 8 GPUs to 8 base GPUs<br/>[batch=1024, seq=?, hidden=4096]",
		pos="1.2561e+05,315",
		shape=diamond,
		width=14.592];
	attn_block_2_0_8 -> hier_reduce_2_8	[pos="e,1.2549e+05,301 1.1144e+05,393.67 1.1144e+05,362.14 1.1144e+05,301 1.1144e+05,301 1.1144e+05,301 1.2548e+05,301 1.2548e+05,301"];
	attn_block_2_1_8 -> hier_reduce_2_8	[pos="e,1.2555e+05,299 1.1044e+05,393.84 1.1044e+05,361.9 1.1044e+05,299 1.1044e+05,299 1.1044e+05,299 1.2554e+05,299 1.2554e+05,299"];
	attn_block_2_2_8 -> hier_reduce_2_8	[pos="e,1.2514e+05,313 1.177e+05,393.84 1.177e+05,365.26 1.177e+05,313 1.177e+05,313 1.177e+05,313 1.2513e+05,313 1.2513e+05,313"];
	attn_block_2_3_8 -> hier_reduce_2_8	[pos="e,1.252e+05,311 1.1672e+05,393.94 1.1672e+05,364.89 1.1672e+05,311 1.1672e+05,311 1.1672e+05,311 1.2519e+05,311 1.2519e+05,311"];
	attn_block_2_4_8 -> hier_reduce_2_8	[pos="e,1.2526e+05,309 1.1577e+05,393.59 1.1577e+05,363.96 1.1577e+05,309 1.1577e+05,309 1.1577e+05,309 1.2525e+05,309 1.2525e+05,309"];
	attn_block_2_5_8 -> hier_reduce_2_8	[pos="e,1.2531e+05,307 1.1472e+05,393.71 1.1472e+05,363.63 1.1472e+05,307 1.1472e+05,307 1.1472e+05,307 1.253e+05,307 1.253e+05,307"];
	attn_block_2_6_8 -> hier_reduce_2_8	[pos="e,1.2537e+05,305 1.1365e+05,393.85 1.1365e+05,363.32 1.1365e+05,305 1.1365e+05,305 1.1365e+05,305 1.2536e+05,305 1.2536e+05,305"];
	attn_block_2_7_8 -> hier_reduce_2_8	[pos="e,1.2543e+05,303 1.126e+05,393.51 1.126e+05,362.41 1.126e+05,303 1.126e+05,303 1.126e+05,303 1.2542e+05,303 1.2542e+05,303"];
	hier_reduce_3_8	[fillcolor=lightgray,
		height=0.5,
		label="<b>Hierarchical Reduction</b><br/>Aggregates attention results<br/>From 8 GPUs to 8 base GPUs<br/>[batch=1024, seq=?, hidden=4096]",
		pos="1.3454e+05,315",
		shape=diamond,
		width=14.592];
	attn_block_3_0_8 -> hier_reduce_3_8	[pos="e,1.3403e+05,315.86 1.1985e+05,393.75 1.1985e+05,370.98 1.1985e+05,335 1.1985e+05,335 1.1985e+05,335 1.3403e+05,335 1.3403e+05,335 \
1.3403e+05,335 1.3403e+05,325.86 1.3403e+05,325.86"];
	attn_block_3_1_8 -> hier_reduce_3_8	[pos="e,1.3426e+05,323.82 1.1925e+05,430.15 1.1925e+05,442.27 1.1925e+05,456 1.1925e+05,456 1.1925e+05,456 1.3426e+05,456 1.3426e+05,456 \
1.3426e+05,456 1.3426e+05,333.82 1.3426e+05,333.82"];
	attn_block_3_2_8 -> hier_reduce_3_8	[pos="e,1.3436e+05,327 1.2646e+05,393.97 1.2646e+05,369.02 1.2646e+05,327 1.2646e+05,327 1.2646e+05,327 1.3435e+05,327 1.3435e+05,327"];
	attn_block_3_3_8 -> hier_reduce_3_8	[pos="e,1.3405e+05,316.65 1.2531e+05,393.99 1.2531e+05,371.51 1.2531e+05,336 1.2531e+05,336 1.2531e+05,336 1.3405e+05,336 1.3405e+05,336 \
1.3405e+05,336 1.3405e+05,326.65 1.3405e+05,326.65"];
	attn_block_3_4_8 -> hier_reduce_3_8	[pos="e,1.3413e+05,319.13 1.2455e+05,430.16 1.2455e+05,435.04 1.2455e+05,439 1.2455e+05,439 1.2455e+05,439 1.3413e+05,439 1.3413e+05,439 \
1.3413e+05,439 1.3413e+05,329.13 1.3413e+05,329.13"];
	attn_block_3_5_8 -> hier_reduce_3_8	[pos="e,1.3416e+05,320.41 1.2353e+05,430.2 1.2353e+05,436.03 1.2353e+05,441 1.2353e+05,441 1.2353e+05,441 1.3416e+05,441 1.3416e+05,441 \
1.3416e+05,441 1.3416e+05,330.41 1.3416e+05,330.41"];
	attn_block_3_6_8 -> hier_reduce_3_8	[pos="e,1.342e+05,321.63 1.2243e+05,430.04 1.2243e+05,437.75 1.2243e+05,445 1.2243e+05,445 1.2243e+05,445 1.342e+05,445 1.342e+05,445 \
1.342e+05,445 1.342e+05,331.63 1.342e+05,331.63"];
	attn_block_3_7_8 -> hier_reduce_3_8	[pos="e,1.3423e+05,322.48 1.2138e+05,430.32 1.2138e+05,438.79 1.2138e+05,447 1.2138e+05,447 1.2138e+05,447 1.3423e+05,447 1.3423e+05,447 \
1.3423e+05,447 1.3423e+05,332.48 1.3423e+05,332.48"];
	hier_reduce_0_16	[fillcolor=lightgray,
		height=0.5,
		label="<b>Hierarchical Reduction</b><br/>Aggregates attention results<br/>From 16 GPUs to 8 base GPUs<br/>[batch=1024, seq=?, hidden=4096]",
		pos="62460,315",
		shape=diamond,
		width=14.707];
	attn_block_0_0_16 -> hier_reduce_0_16	[pos="e,62901,312 68104,393.66 68104,364.79 68104,312 68104,312 68104,312 62911,312 62911,312"];
	attn_block_0_1_16 -> hier_reduce_0_16	[pos="e,62960,314 67057,393.57 67057,365.18 67057,314 67057,314 67057,314 62970,314 62970,314"];
	attn_block_0_2_16 -> hier_reduce_0_16	[pos="e,62990,315 66013,393.76 66013,365.66 66013,315 66013,315 66013,315 63000,315 63000,315"];
	attn_block_0_3_16 -> hier_reduce_0_16	[pos="e,62931,317 64974,393.68 64974,366.08 64974,317 64974,317 64974,317 62941,317 62941,317"];
	attn_block_0_4_16 -> hier_reduce_0_16	[pos="e,62901,318 63946,393.88 63946,366.56 63946,318 63946,318 63946,318 62911,318 62911,318"];
	attn_block_0_5_16 -> hier_reduce_0_16	[pos="e,62752,323.35 62752,393.76 62752,393.76 62752,333.35 62752,333.35"];
	attn_block_0_6_16 -> hier_reduce_0_16	[pos="e,62354,329.68 62354,393.76 62354,393.76 62354,339.68 62354,339.68"];
	attn_block_0_7_16 -> hier_reduce_0_16	[pos="e,62225,305 60997,393.85 60997,363.32 60997,305 60997,305 60997,305 62215,305 62215,305"];
	attn_block_0_8_16 -> hier_reduce_0_16	[pos="e,62313,302 60037,393.84 60037,362.59 60037,302 60037,302 60037,302 62303,302 62303,302"];
	attn_block_0_9_16 -> hier_reduce_0_16	[pos="e,62401,299 58986,393.84 58986,361.9 58986,299 58986,299 58986,299 62391,299 62391,299"];
	attn_block_0_10_16 -> hier_reduce_0_16	[pos="e,62636,303 74453,393.51 74453,362.41 74453,303 74453,303 74453,303 62646,303 62646,303"];
	attn_block_0_11_16 -> hier_reduce_0_16	[pos="e,62666,304 73394,393.68 73394,362.87 73394,304 73394,304 73394,304 62676,304 62676,304"];
	attn_block_0_12_16 -> hier_reduce_0_16	[pos="e,62725,306 72335,393.54 72335,363.17 72335,306 72335,306 72335,306 62735,306 62735,306"];
	attn_block_0_13_16 -> hier_reduce_0_16	[pos="e,62754,307 71276,393.71 71276,363.63 71276,307 71276,307 71276,307 62764,307 62764,307"];
	attn_block_0_14_16 -> hier_reduce_0_16	[pos="e,62813,309 70217,393.59 70217,363.96 70217,309 70217,309 70217,309 62823,309 62823,309"];
	attn_block_0_15_16 -> hier_reduce_0_16	[pos="e,62872,311 69158,393.94 69158,364.89 69158,311 69158,311 69158,311 62882,311 62882,311"];
	hier_reduce_1_16	[fillcolor=lightgray,
		height=0.5,
		label="<b>Hierarchical Reduction</b><br/>Aggregates attention results<br/>From 16 GPUs to 8 base GPUs<br/>[batch=1024, seq=?, hidden=4096]",
		pos="79320,315",
		shape=diamond,
		width=14.707];
	attn_block_1_0_16 -> hier_reduce_1_16	[pos="e,79615,323 84964,393.99 84964,367.98 84964,323 84964,323 84964,323 79625,323 79625,323"];
	attn_block_1_1_16 -> hier_reduce_1_16	[pos="e,79555,325 83917,393.97 83917,368.49 83917,325 83917,325 83917,325 79565,325 79565,325"];
	attn_block_1_2_16 -> hier_reduce_1_16	[pos="e,79496,327 82873,393.97 82873,369.02 82873,327 82873,327 82873,327 79506,327 79506,327"];
	attn_block_1_3_16 -> hier_reduce_1_16	[pos="e,79438,329 81834,393.99 81834,369.58 81834,329 81834,329 81834,329 79448,329 79448,329"];
	attn_block_1_4_16 -> hier_reduce_1_16	[pos="e,79379,331 80806,393.62 80806,369.72 80806,331 80806,331 80806,331 79389,331 79389,331"];
	attn_block_1_5_16 -> hier_reduce_1_16	[pos="e,79532,325.93 79532,393.76 79532,393.76 79532,335.93 79532,335.93"];
	attn_block_1_6_16 -> hier_reduce_1_16	[pos="e,79029,323.35 79029,393.76 79029,393.76 79029,333.35 79029,333.35"];
	attn_block_1_7_16 -> hier_reduce_1_16	[pos="e,79202,301 77857,393.67 77857,362.14 77857,301 77857,301 77857,301 79192,301 79192,301"];
	attn_block_1_8_16 -> hier_reduce_1_16	[pos="e,79232,300 76896,393.51 76896,361.69 76896,300 76896,300 76896,300 79222,300 79222,300"];
	attn_block_1_9_16 -> hier_reduce_1_16	[pos="e,79290,298 75833,393.94 75833,361.79 75833,298 75833,298 75833,298 79280,298 79280,298"];
	attn_block_1_10_16 -> hier_reduce_1_16	[pos="e,79691,320.57 91143,393.96 91143,372.34 91143,339 91143,339 91143,339 79691,339 79691,339 79691,339 79691,330.57 79691,330.57"];
	attn_block_1_11_16 -> hier_reduce_1_16	[pos="e,79791,313 89955,393.84 89955,365.26 89955,313 89955,313 89955,313 79801,313 79801,313"];
	attn_block_1_12_16 -> hier_reduce_1_16	[pos="e,79850,315 89195,393.76 89195,365.66 89195,315 89195,315 89195,315 79860,315 79860,315"];
	attn_block_1_13_16 -> hier_reduce_1_16	[pos="e,79791,317 88136,393.68 88136,366.08 88136,317 88136,317 88136,317 79801,317 79801,317"];
	attn_block_1_14_16 -> hier_reduce_1_16	[pos="e,79732,319 87077,393.63 87077,366.52 87077,319 87077,319 87077,319 79742,319 79742,319"];
	attn_block_1_15_16 -> hier_reduce_1_16	[pos="e,79673,321 86018,393.58 86018,366.99 86018,321 86018,321 86018,321 79683,321 79683,321"];
	hier_reduce_2_16	[fillcolor=lightgray,
		height=0.5,
		label="<b>Hierarchical Reduction</b><br/>Aggregates attention results<br/>From 16 GPUs to 8 base GPUs<br/>[batch=1024, seq=?, hidden=4096]",
		pos="37159,315",
		shape=diamond,
		width=14.707];
	attn_block_2_0_16 -> hier_reduce_2_16	[pos="e,36982,327 34737,393.97 34737,369.02 34737,327 34737,327 34737,327 36972,327 36972,327"];
	attn_block_2_1_16 -> hier_reduce_2_16	[pos="e,36894,324 33732,393.77 33732,367.99 33732,324 33732,324 33732,324 36884,324 36884,324"];
	attn_block_2_2_16 -> hier_reduce_2_16	[pos="e,36806,321 32593,393.58 32593,366.99 32593,321 32593,321 32593,321 36796,321 36796,321"];
	attn_block_2_3_16 -> hier_reduce_2_16	[pos="e,36718,318 31488,393.88 31488,366.56 31488,318 31488,318 31488,318 36708,318 36708,318"];
	attn_block_2_4_16 -> hier_reduce_2_16	[pos="e,36629,315 30466,393.76 30466,365.66 30466,315 30466,315 30466,315 36619,315 36619,315"];
	attn_block_2_5_16 -> hier_reduce_2_16	[pos="e,36718,312 29430,393.66 29430,364.79 29430,312 29430,312 29430,312 36708,312 36708,312"];
	attn_block_2_6_16 -> hier_reduce_2_16	[pos="e,36806,309 28469,393.59 28469,363.96 28469,309 28469,309 28469,309 36796,309 36796,309"];
	attn_block_2_7_16 -> hier_reduce_2_16	[pos="e,36894,306 27381,393.54 27381,363.17 27381,306 27381,306 27381,306 36884,306 36884,306"];
	attn_block_2_8_16 -> hier_reduce_2_16	[pos="e,36982,303 26312,393.51 26312,362.41 26312,303 26312,303 26312,303 36972,303 36972,303"];
	attn_block_2_9_16 -> hier_reduce_2_16	[pos="e,37070,300 25251,393.51 25251,361.69 25251,300 25251,300 25251,300 37060,300 37060,300"];
	attn_block_2_10_16 -> hier_reduce_2_16	[pos="e,37659,316 40744,393.94 40744,366.13 40744,316 40744,316 40744,316 37669,316 37669,316"];
	attn_block_2_11_16 -> hier_reduce_2_16	[pos="e,37601,318 39696,393.88 39696,366.56 39696,318 39696,318 39696,318 37611,318 37611,318"];
	attn_block_2_12_16 -> hier_reduce_2_16	[pos="e,37571,319 38659,393.63 38659,366.52 38659,319 38659,319 38659,319 37581,319 37581,319"];
	attn_block_2_13_16 -> hier_reduce_2_16	[pos="e,37371,325.93 37371,393.76 37371,393.76 37371,335.93 37371,335.93"];
	attn_block_2_14_16 -> hier_reduce_2_16	[pos="e,36868,323.35 36868,393.76 36868,393.76 36868,333.35 36868,333.35"];
	attn_block_2_15_16 -> hier_reduce_2_16	[pos="e,37071,330 35681,393.8 35681,369.64 35681,330 35681,330 35681,330 37061,330 37061,330"];
	hier_reduce_3_16	[fillcolor=lightgray,
		height=0.5,
		label="<b>Hierarchical Reduction</b><br/>Aggregates attention results<br/>From 16 GPUs to 8 base GPUs<br/>[batch=1024, seq=?, hidden=4096]",
		pos="54019,315",
		shape=diamond,
		width=14.707];
	attn_block_3_0_16 -> hier_reduce_3_16	[pos="e,53548,313 51597,393.84 51597,365.26 51597,313 51597,313 51597,313 53538,313 53538,313"];
	attn_block_3_1_16 -> hier_reduce_3_16	[pos="e,53607,311 50592,393.94 50592,364.89 50592,311 50592,311 50592,311 53597,311 53597,311"];
	attn_block_3_2_16 -> hier_reduce_3_16	[pos="e,53637,310 49453,393.76 49453,364.43 49453,310 49453,310 49453,310 53627,310 53627,310"];
	attn_block_3_3_16 -> hier_reduce_3_16	[pos="e,53695,308 48348,393.88 48348,364.09 48348,308 48348,308 48348,308 53685,308 53685,308"];
	attn_block_3_4_16 -> hier_reduce_3_16	[pos="e,53754,306 47326,393.54 47326,363.17 47326,306 47326,306 47326,306 53744,306 53744,306"];
	attn_block_3_5_16 -> hier_reduce_3_16	[pos="e,53783,305 46290,393.85 46290,363.32 46290,305 46290,305 46290,305 53773,305 53773,305"];
	attn_block_3_6_16 -> hier_reduce_3_16	[pos="e,53842,303 45247,393.51 45247,362.41 45247,303 45247,303 45247,303 53832,303 53832,303"];
	attn_block_3_7_16 -> hier_reduce_3_16	[pos="e,53901,301 44200,393.67 44200,362.14 44200,301 44200,301 44200,301 53891,301 53891,301"];
	attn_block_3_8_16 -> hier_reduce_3_16	[pos="e,53931,300 43152,393.51 43152,361.69 43152,300 43152,300 43152,300 53921,300 53921,300"];
	attn_block_3_9_16 -> hier_reduce_3_16	[pos="e,53989,298 42101,393.94 42101,361.79 42101,298 42101,298 42101,298 53979,298 53979,298"];
	attn_block_3_10_16 -> hier_reduce_3_16	[pos="e,54490,313 57604,393.84 57604,365.26 57604,313 57604,313 57604,313 54500,313 54500,313"];
	attn_block_3_11_16 -> hier_reduce_3_16	[pos="e,54519,316 56556,393.94 56556,366.13 56556,316 56556,316 56556,316 54529,316 54529,316"];
	attn_block_3_12_16 -> hier_reduce_3_16	[pos="e,54431,319 55519,393.63 55519,366.52 55519,319 55519,319 55519,319 54441,319 54441,319"];
	attn_block_3_13_16 -> hier_reduce_3_16	[pos="e,54167,328.19 54167,393.76 54167,393.76 54167,338.19 54167,338.19"];
	attn_block_3_14_16 -> hier_reduce_3_16	[pos="e,53728,323.35 53728,393.76 53728,393.76 53728,333.35 53728,333.35"];
	attn_block_3_15_16 -> hier_reduce_3_16	[pos="e,53489,315 52541,393.76 52541,365.66 52541,315 52541,315 52541,315 53479,315 53479,315"];
	hier_reduce_0_24	[fillcolor=lightgray,
		height=0.5,
		label="<b>Hierarchical Reduction</b><br/>Aggregates attention results<br/>From 24 GPUs to 8 base GPUs<br/>[batch=1024, seq=?, hidden=4096]",
		pos="1.8626e+05,315",
		shape=diamond,
		width=14.707];
	attn_block_0_0_24 -> hier_reduce_0_24	[pos="e,1.8656e+05,307 1.9553e+05,393.71 1.9553e+05,363.63 1.9553e+05,307 1.9553e+05,307 1.9553e+05,307 1.8657e+05,307 1.8657e+05,307"];
	attn_block_0_1_24 -> hier_reduce_0_24	[pos="e,1.8661e+05,309 1.9448e+05,393.59 1.9448e+05,363.96 1.9448e+05,309 1.9448e+05,309 1.9448e+05,309 1.8662e+05,309 1.8662e+05,309"];
	attn_block_0_2_24 -> hier_reduce_0_24	[pos="e,1.8664e+05,310 1.9344e+05,393.76 1.9344e+05,364.43 1.9344e+05,310 1.9344e+05,310 1.9344e+05,310 1.8665e+05,310 1.8665e+05,310"];
	attn_block_0_3_24 -> hier_reduce_0_24	[pos="e,1.867e+05,312 1.9239e+05,393.66 1.9239e+05,364.79 1.9239e+05,312 1.9239e+05,312 1.9239e+05,312 1.8671e+05,312 1.8671e+05,312"];
	attn_block_0_4_24 -> hier_reduce_0_24	[pos="e,1.8673e+05,313 1.9134e+05,393.84 1.9134e+05,365.26 1.9134e+05,313 1.9134e+05,313 1.9134e+05,313 1.8674e+05,313 1.8674e+05,313"];
	attn_block_0_5_24 -> hier_reduce_0_24	[pos="e,1.8679e+05,315 1.903e+05,393.76 1.903e+05,365.66 1.903e+05,315 1.903e+05,315 1.903e+05,315 1.868e+05,315 1.868e+05,315"];
	attn_block_0_6_24 -> hier_reduce_0_24	[pos="e,1.8676e+05,316 1.8926e+05,393.94 1.8926e+05,366.13 1.8926e+05,316 1.8926e+05,316 1.8926e+05,316 1.8677e+05,316 1.8677e+05,316"];
	attn_block_0_7_24 -> hier_reduce_0_24	[pos="e,1.867e+05,318 1.8823e+05,393.88 1.8823e+05,366.56 1.8823e+05,318 1.8823e+05,318 1.8823e+05,318 1.8671e+05,318 1.8671e+05,318"];
	attn_block_0_8_24 -> hier_reduce_0_24	[pos="e,1.8678e+05,315.28 1.868e+05,412 1.8679e+05,412 1.8678e+05,412 1.8678e+05,412 1.8678e+05,412 1.8678e+05,325.28 1.8678e+05,325.28"];
	attn_block_0_9_24 -> hier_reduce_0_24	[pos="e,1.8626e+05,333.16 1.8626e+05,393.76 1.8626e+05,393.76 1.8626e+05,343.16 1.8626e+05,343.16"];
	attn_block_0_10_24 -> hier_reduce_0_24	[pos="e,1.8573e+05,315.28 1.8573e+05,412 1.8573e+05,412 1.8573e+05,412 1.8573e+05,412 1.8573e+05,412 1.8573e+05,325.28 1.8573e+05,325.28"];
	attn_block_0_11_24 -> hier_reduce_0_24	[pos="e,1.8617e+05,330 1.8428e+05,393.8 1.8428e+05,369.64 1.8428e+05,330 1.8428e+05,330 1.8428e+05,330 1.8616e+05,330 1.8616e+05,330"];
	attn_block_0_12_24 -> hier_reduce_0_24	[pos="e,1.8611e+05,328 1.8324e+05,393.77 1.8324e+05,369.07 1.8324e+05,328 1.8324e+05,328 1.8324e+05,328 1.861e+05,328 1.861e+05,328"];
	attn_block_0_13_24 -> hier_reduce_0_24	[pos="e,1.8606e+05,326 1.822e+05,393.76 1.822e+05,368.52 1.822e+05,326 1.822e+05,326 1.822e+05,326 1.8605e+05,326 1.8605e+05,326"];
	attn_block_0_14_24 -> hier_reduce_0_24	[pos="e,1.86e+05,324 1.8114e+05,393.77 1.8114e+05,367.99 1.8114e+05,324 1.8114e+05,324 1.8114e+05,324 1.8599e+05,324 1.8599e+05,324"];
	attn_block_0_15_24 -> hier_reduce_0_24	[pos="e,1.8591e+05,321 1.8009e+05,393.58 1.8009e+05,366.99 1.8009e+05,321 1.8009e+05,321 1.8009e+05,321 1.859e+05,321 1.859e+05,321"];
	attn_block_0_16_24 -> hier_reduce_0_24	[pos="e,1.8585e+05,319 1.7903e+05,393.63 1.7903e+05,366.52 1.7903e+05,319 1.7903e+05,319 1.7903e+05,319 1.8584e+05,319 1.8584e+05,319"];
	attn_block_0_17_24 -> hier_reduce_0_24	[pos="e,1.8579e+05,317 1.7797e+05,393.68 1.7797e+05,366.08 1.7797e+05,317 1.7797e+05,317 1.7797e+05,317 1.8578e+05,317 1.8578e+05,317"];
	attn_block_0_18_24 -> hier_reduce_0_24	[pos="e,1.8629e+05,298 2.0188e+05,393.94 2.0188e+05,361.79 2.0188e+05,298 2.0188e+05,298 2.0188e+05,298 1.863e+05,298 1.863e+05,298"];
	attn_block_0_19_24 -> hier_reduce_0_24	[pos="e,1.8635e+05,300 2.0082e+05,393.51 2.0082e+05,361.69 2.0082e+05,300 2.0082e+05,300 2.0082e+05,300 1.8636e+05,300 1.8636e+05,300"];
	attn_block_0_20_24 -> hier_reduce_0_24	[pos="e,1.8638e+05,301 1.9977e+05,393.67 1.9977e+05,362.14 1.9977e+05,301 1.9977e+05,301 1.9977e+05,301 1.8639e+05,301 1.8639e+05,301"];
	attn_block_0_21_24 -> hier_reduce_0_24	[pos="e,1.8644e+05,303 1.9871e+05,393.51 1.9871e+05,362.41 1.9871e+05,303 1.9871e+05,303 1.9871e+05,303 1.8645e+05,303 1.8645e+05,303"];
	attn_block_0_22_24 -> hier_reduce_0_24	[pos="e,1.8647e+05,304 1.9765e+05,393.68 1.9765e+05,362.87 1.9765e+05,304 1.9765e+05,304 1.9765e+05,304 1.8648e+05,304 1.8648e+05,304"];
	attn_block_0_23_24 -> hier_reduce_0_24	[pos="e,1.8653e+05,306 1.9659e+05,393.54 1.9659e+05,363.17 1.9659e+05,306 1.9659e+05,306 1.9659e+05,306 1.8654e+05,306 1.8654e+05,306"];
	hier_reduce_1_24	[fillcolor=lightgray,
		height=0.5,
		label="<b>Hierarchical Reduction</b><br/>Aggregates attention results<br/>From 24 GPUs to 8 base GPUs<br/>[batch=1024, seq=?, hidden=4096]",
		pos="2.1159e+05,315",
		shape=diamond,
		width=14.707];
	attn_block_1_0_24 -> hier_reduce_1_24	[pos="e,2.1212e+05,315 2.2087e+05,393.76 2.2087e+05,365.66 2.2087e+05,315 2.2087e+05,315 2.2087e+05,315 2.1213e+05,315 2.1213e+05,315"];
	attn_block_1_1_24 -> hier_reduce_1_24	[pos="e,2.1206e+05,317 2.1982e+05,393.68 2.1982e+05,366.08 2.1982e+05,317 2.1982e+05,317 2.1982e+05,317 2.1207e+05,317 2.1207e+05,317"];
	attn_block_1_2_24 -> hier_reduce_1_24	[pos="e,2.1201e+05,319 2.1877e+05,393.63 2.1877e+05,366.52 2.1877e+05,319 2.1877e+05,319 2.1877e+05,319 2.1202e+05,319 2.1202e+05,319"];
	attn_block_1_3_24 -> hier_reduce_1_24	[pos="e,2.1195e+05,321 2.1772e+05,393.58 2.1772e+05,366.99 2.1772e+05,321 2.1772e+05,321 2.1772e+05,321 2.1196e+05,321 2.1196e+05,321"];
	attn_block_1_4_24 -> hier_reduce_1_24	[pos="e,2.1186e+05,324 2.1667e+05,393.77 2.1667e+05,367.99 2.1667e+05,324 2.1667e+05,324 2.1667e+05,324 2.1187e+05,324 2.1187e+05,324"];
	attn_block_1_5_24 -> hier_reduce_1_24	[pos="e,2.118e+05,326 2.1563e+05,393.76 2.1563e+05,368.52 2.1563e+05,326 2.1563e+05,326 2.1563e+05,326 2.1181e+05,326 2.1181e+05,326"];
	attn_block_1_6_24 -> hier_reduce_1_24	[pos="e,2.1174e+05,328 2.1459e+05,393.77 2.1459e+05,369.07 2.1459e+05,328 2.1459e+05,328 2.1459e+05,328 2.1175e+05,328 2.1175e+05,328"];
	attn_block_1_7_24 -> hier_reduce_1_24	[pos="e,2.1168e+05,330 2.1356e+05,393.8 2.1356e+05,369.64 2.1356e+05,330 2.1356e+05,330 2.1356e+05,330 2.1169e+05,330 2.1169e+05,330"];
	attn_block_1_8_24 -> hier_reduce_1_24	[pos="e,2.1212e+05,315.28 2.1213e+05,412 2.1212e+05,412 2.1212e+05,412 2.1212e+05,412 2.1212e+05,412 2.1212e+05,325.28 2.1212e+05,325.28"];
	attn_block_1_9_24 -> hier_reduce_1_24	[pos="e,2.1159e+05,333.16 2.1159e+05,393.76 2.1159e+05,393.76 2.1159e+05,343.16 2.1159e+05,343.16"];
	attn_block_1_10_24 -> hier_reduce_1_24	[pos="e,2.1107e+05,315.07 2.1106e+05,412 2.1106e+05,412 2.1107e+05,412 2.1107e+05,412 2.1107e+05,412 2.1107e+05,325.07 2.1107e+05,325.07"];
	attn_block_1_11_24 -> hier_reduce_1_24	[pos="e,2.1153e+05,331 2.0961e+05,393.62 2.0961e+05,369.72 2.0961e+05,331 2.0961e+05,331 2.0961e+05,331 2.1152e+05,331 2.1152e+05,331"];
	attn_block_1_12_24 -> hier_reduce_1_24	[pos="e,2.1151e+05,330 2.0864e+05,393.8 2.0864e+05,369.64 2.0864e+05,330 2.0864e+05,330 2.0864e+05,330 2.115e+05,330 2.115e+05,330"];
	attn_block_1_13_24 -> hier_reduce_1_24	[pos="e,2.1145e+05,328 2.0756e+05,393.77 2.0756e+05,369.07 2.0756e+05,328 2.0756e+05,328 2.0756e+05,328 2.1144e+05,328 2.1144e+05,328"];
	attn_block_1_14_24 -> hier_reduce_1_24	[pos="e,2.1142e+05,327 2.0649e+05,393.97 2.0649e+05,369.02 2.0649e+05,327 2.0649e+05,327 2.0649e+05,327 2.1141e+05,327 2.1141e+05,327"];
	attn_block_1_15_24 -> hier_reduce_1_24	[pos="e,2.1136e+05,325 2.0543e+05,393.97 2.0543e+05,368.49 2.0543e+05,325 2.0543e+05,325 2.0543e+05,325 2.1135e+05,325 2.1135e+05,325"];
	attn_block_1_16_24 -> hier_reduce_1_24	[pos="e,2.1133e+05,324 2.0436e+05,393.77 2.0436e+05,367.99 2.0436e+05,324 2.0436e+05,324 2.0436e+05,324 2.1132e+05,324 2.1132e+05,324"];
	attn_block_1_17_24 -> hier_reduce_1_24	[pos="e,2.1127e+05,322 2.033e+05,393.79 2.033e+05,367.49 2.033e+05,322 2.033e+05,322 2.033e+05,322 2.1126e+05,322 2.1126e+05,322"];
	attn_block_1_18_24 -> hier_reduce_1_24	[pos="e,2.1171e+05,301 2.2722e+05,393.67 2.2722e+05,362.14 2.2722e+05,301 2.2722e+05,301 2.2722e+05,301 2.1172e+05,301 2.1172e+05,301"];
	attn_block_1_19_24 -> hier_reduce_1_24	[pos="e,2.1177e+05,303 2.2616e+05,393.51 2.2616e+05,362.41 2.2616e+05,303 2.2616e+05,303 2.2616e+05,303 2.1178e+05,303 2.1178e+05,303"];
	attn_block_1_20_24 -> hier_reduce_1_24	[pos="e,2.1186e+05,306 2.251e+05,393.54 2.251e+05,363.17 2.251e+05,306 2.251e+05,306 2.251e+05,306 2.1187e+05,306 2.1187e+05,306"];
	attn_block_1_21_24 -> hier_reduce_1_24	[pos="e,2.1192e+05,308 2.2404e+05,393.88 2.2404e+05,364.09 2.2404e+05,308 2.2404e+05,308 2.2404e+05,308 2.1193e+05,308 2.1193e+05,308"];
	attn_block_1_22_24 -> hier_reduce_1_24	[pos="e,2.1198e+05,310 2.2298e+05,393.76 2.2298e+05,364.43 2.2298e+05,310 2.2298e+05,310 2.2298e+05,310 2.1199e+05,310 2.1199e+05,310"];
	attn_block_1_23_24 -> hier_reduce_1_24	[pos="e,2.1204e+05,312 2.2192e+05,393.66 2.2192e+05,364.79 2.2192e+05,312 2.2192e+05,312 2.2192e+05,312 2.1205e+05,312 2.1205e+05,312"];
	hier_reduce_2_24	[fillcolor=lightgray,
		height=0.5,
		label="<b>Hierarchical Reduction</b><br/>Aggregates attention results<br/>From 24 GPUs to 8 base GPUs<br/>[batch=1024, seq=?, hidden=4096]",
		pos="1.44e+05,315",
		shape=diamond,
		width=14.707];
	attn_block_2_0_24 -> hier_reduce_2_24	[pos="e,1.4452e+05,315.28 1.4453e+05,412 1.4452e+05,412 1.4452e+05,412 1.4452e+05,412 1.4452e+05,412 1.4452e+05,325.28 1.4452e+05,325.28"];
	attn_block_2_1_24 -> hier_reduce_2_24	[pos="e,1.44e+05,333.16 1.44e+05,393.76 1.44e+05,393.76 1.44e+05,343.16 1.44e+05,343.16"];
	attn_block_2_2_24 -> hier_reduce_2_24	[pos="e,1.4347e+05,315.28 1.4346e+05,412 1.4347e+05,412 1.4347e+05,412 1.4347e+05,412 1.4347e+05,412 1.4347e+05,325.28 1.4347e+05,325.28"];
	attn_block_2_3_24 -> hier_reduce_2_24	[pos="e,1.4391e+05,330 1.421e+05,393.8 1.421e+05,369.64 1.421e+05,330 1.421e+05,330 1.421e+05,330 1.439e+05,330 1.439e+05,330"];
	attn_block_2_4_24 -> hier_reduce_2_24	[pos="e,1.4385e+05,328 1.4109e+05,393.77 1.4109e+05,369.07 1.4109e+05,328 1.4109e+05,328 1.4109e+05,328 1.4384e+05,328 1.4384e+05,328"];
	attn_block_2_5_24 -> hier_reduce_2_24	[pos="e,1.4379e+05,326 1.3995e+05,393.76 1.3995e+05,368.52 1.3995e+05,326 1.3995e+05,326 1.3995e+05,326 1.4378e+05,326 1.4378e+05,326"];
	attn_block_2_6_24 -> hier_reduce_2_24	[pos="e,1.4373e+05,324 1.3892e+05,393.77 1.3892e+05,367.99 1.3892e+05,324 1.3892e+05,324 1.3892e+05,324 1.4372e+05,324 1.4372e+05,324"];
	attn_block_2_7_24 -> hier_reduce_2_24	[pos="e,1.4367e+05,322 1.3795e+05,393.79 1.3795e+05,367.49 1.3795e+05,322 1.3795e+05,322 1.3795e+05,322 1.4366e+05,322 1.4366e+05,322"];
	attn_block_2_8_24 -> hier_reduce_2_24	[pos="e,1.4362e+05,320 1.3686e+05,393.82 1.3686e+05,367.01 1.3686e+05,320 1.3686e+05,320 1.3686e+05,320 1.4361e+05,320 1.4361e+05,320"];
	attn_block_2_9_24 -> hier_reduce_2_24	[pos="e,1.4356e+05,318 1.3579e+05,393.88 1.3579e+05,366.56 1.3579e+05,318 1.3579e+05,318 1.3579e+05,318 1.4355e+05,318 1.4355e+05,318"];
	attn_block_2_10_24 -> hier_reduce_2_24	[pos="e,1.435e+05,316 1.3515e+05,393.94 1.3515e+05,366.13 1.3515e+05,316 1.3515e+05,316 1.3515e+05,316 1.4349e+05,316 1.4349e+05,316"];
	attn_block_2_11_24 -> hier_reduce_2_24	[pos="e,1.4347e+05,315.06 1.3408e+05,393.84 1.3408e+05,371.65 1.3408e+05,337 1.3408e+05,337 1.3408e+05,337 1.4347e+05,337 1.4347e+05,337 \
1.4347e+05,337 1.4347e+05,325.06 1.4347e+05,325.06"];
	attn_block_2_12_24 -> hier_reduce_2_24	[pos="e,1.4347e+05,315.37 1.3301e+05,430.03 1.3301e+05,436.85 1.3301e+05,443 1.3301e+05,443 1.3301e+05,443 1.4347e+05,443 1.4347e+05,443 \
1.4347e+05,443 1.4347e+05,325.37 1.4347e+05,325.37"];
	attn_block_2_13_24 -> hier_reduce_2_24	[pos="e,1.4347e+05,315.38 1.3195e+05,430.07 1.3195e+05,439.46 1.3195e+05,449 1.3195e+05,449 1.3195e+05,449 1.4347e+05,449 1.4347e+05,449 \
1.4347e+05,449 1.4347e+05,325.38 1.4347e+05,325.38"];
	attn_block_2_14_24 -> hier_reduce_2_24	[pos="e,1.4348e+05,315.39 1.3089e+05,430.13 1.3089e+05,440.31 1.3089e+05,451 1.3089e+05,451 1.3089e+05,451 1.4348e+05,451 1.4348e+05,451 \
1.4348e+05,451 1.4348e+05,325.39 1.4348e+05,325.39"];
	attn_block_2_15_24 -> hier_reduce_2_24	[pos="e,1.4348e+05,315.39 1.2983e+05,430.13 1.2983e+05,440.71 1.2983e+05,452 1.2983e+05,452 1.2983e+05,452 1.4348e+05,452 1.4348e+05,452 \
1.4348e+05,452 1.4348e+05,325.39 1.4348e+05,325.39"];
	attn_block_2_16_24 -> hier_reduce_2_24	[pos="e,1.4348e+05,315.4 1.2877e+05,430.06 1.2877e+05,441.44 1.2877e+05,454 1.2877e+05,454 1.2877e+05,454 1.4348e+05,454 1.4348e+05,454 \
1.4348e+05,454 1.4348e+05,325.4 1.4348e+05,325.4"];
	attn_block_2_17_24 -> hier_reduce_2_24	[pos="e,1.4348e+05,315.41 1.277e+05,430.18 1.277e+05,443.04 1.277e+05,458 1.277e+05,458 1.277e+05,458 1.4348e+05,458 1.4348e+05,458 1.4348e+\
05,458 1.4348e+05,325.41 1.4348e+05,325.41"];
	attn_block_2_18_24 -> hier_reduce_2_24	[pos="e,1.4429e+05,323 1.5122e+05,393.99 1.5122e+05,367.98 1.5122e+05,323 1.5122e+05,323 1.5122e+05,323 1.443e+05,323 1.443e+05,323"];
	attn_block_2_19_24 -> hier_reduce_2_24	[pos="e,1.4423e+05,325 1.5016e+05,393.97 1.5016e+05,368.49 1.5016e+05,325 1.5016e+05,325 1.5016e+05,325 1.4424e+05,325 1.4424e+05,325"];
	attn_block_2_20_24 -> hier_reduce_2_24	[pos="e,1.442e+05,326 1.4911e+05,393.76 1.4911e+05,368.52 1.4911e+05,326 1.4911e+05,326 1.4911e+05,326 1.4421e+05,326 1.4421e+05,326"];
	attn_block_2_21_24 -> hier_reduce_2_24	[pos="e,1.4415e+05,328 1.4805e+05,393.77 1.4805e+05,369.07 1.4805e+05,328 1.4805e+05,328 1.4805e+05,328 1.4416e+05,328 1.4416e+05,328"];
	attn_block_2_22_24 -> hier_reduce_2_24	[pos="e,1.4412e+05,329 1.4701e+05,393.99 1.4701e+05,369.58 1.4701e+05,329 1.4701e+05,329 1.4701e+05,329 1.4413e+05,329 1.4413e+05,329"];
	attn_block_2_23_24 -> hier_reduce_2_24	[pos="e,1.4406e+05,331 1.4597e+05,393.62 1.4597e+05,369.72 1.4597e+05,331 1.4597e+05,331 1.4597e+05,331 1.4407e+05,331 1.4407e+05,331"];
	hier_reduce_3_24	[fillcolor=lightgray,
		height=0.5,
		label="<b>Hierarchical Reduction</b><br/>Aggregates attention results<br/>From 24 GPUs to 8 base GPUs<br/>[batch=1024, seq=?, hidden=4096]",
		pos="1.6933e+05,315",
		shape=diamond,
		width=14.707];
	attn_block_3_0_24 -> hier_reduce_3_24	[pos="e,1.6985e+05,315.28 1.6986e+05,412 1.6986e+05,412 1.6985e+05,412 1.6985e+05,412 1.6985e+05,412 1.6985e+05,325.28 1.6985e+05,325.28"];
	attn_block_3_1_24 -> hier_reduce_3_24	[pos="e,1.6933e+05,333.16 1.6933e+05,393.76 1.6933e+05,393.76 1.6933e+05,343.16 1.6933e+05,343.16"];
	attn_block_3_2_24 -> hier_reduce_3_24	[pos="e,1.6881e+05,315.28 1.688e+05,412 1.688e+05,412 1.6881e+05,412 1.6881e+05,412 1.6881e+05,412 1.6881e+05,325.28 1.6881e+05,325.28"];
	attn_block_3_3_24 -> hier_reduce_3_24	[pos="e,1.6895e+05,320 1.6741e+05,393.82 1.6741e+05,367.01 1.6741e+05,320 1.6741e+05,320 1.6741e+05,320 1.6894e+05,320 1.6894e+05,320"];
	attn_block_3_4_24 -> hier_reduce_3_24	[pos="e,1.6889e+05,318 1.6636e+05,393.88 1.6636e+05,366.56 1.6636e+05,318 1.6636e+05,318 1.6636e+05,318 1.6888e+05,318 1.6888e+05,318"];
	attn_block_3_5_24 -> hier_reduce_3_24	[pos="e,1.6886e+05,317 1.6531e+05,393.68 1.6531e+05,366.08 1.6531e+05,317 1.6531e+05,317 1.6531e+05,317 1.6885e+05,317 1.6885e+05,317"];
	attn_block_3_6_24 -> hier_reduce_3_24	[pos="e,1.688e+05,315 1.6435e+05,393.76 1.6435e+05,365.66 1.6435e+05,315 1.6435e+05,315 1.6435e+05,315 1.6879e+05,315 1.6879e+05,315"];
	attn_block_3_7_24 -> hier_reduce_3_24	[pos="e,1.6883e+05,314 1.6325e+05,393.57 1.6325e+05,365.18 1.6325e+05,314 1.6325e+05,314 1.6325e+05,314 1.6882e+05,314 1.6882e+05,314"];
	attn_block_3_8_24 -> hier_reduce_3_24	[pos="e,1.6889e+05,312 1.6218e+05,393.66 1.6218e+05,364.79 1.6218e+05,312 1.6218e+05,312 1.6218e+05,312 1.6888e+05,312 1.6888e+05,312"];
	attn_block_3_9_24 -> hier_reduce_3_24	[pos="e,1.6892e+05,311 1.6112e+05,393.94 1.6112e+05,364.89 1.6112e+05,311 1.6112e+05,311 1.6112e+05,311 1.6891e+05,311 1.6891e+05,311"];
	attn_block_3_10_24 -> hier_reduce_3_24	[pos="e,1.6898e+05,309 1.6006e+05,393.59 1.6006e+05,363.96 1.6006e+05,309 1.6006e+05,309 1.6006e+05,309 1.6897e+05,309 1.6897e+05,309"];
	attn_block_3_11_24 -> hier_reduce_3_24	[pos="e,1.6904e+05,307 1.59e+05,393.71 1.59e+05,363.63 1.59e+05,307 1.59e+05,307 1.59e+05,307 1.6903e+05,307 1.6903e+05,307"];
	attn_block_3_12_24 -> hier_reduce_3_24	[pos="e,1.6907e+05,306 1.5794e+05,393.54 1.5794e+05,363.17 1.5794e+05,306 1.5794e+05,306 1.5794e+05,306 1.6906e+05,306 1.6906e+05,306"];
	attn_block_3_13_24 -> hier_reduce_3_24	[pos="e,1.6912e+05,304 1.5688e+05,393.68 1.5688e+05,362.87 1.5688e+05,304 1.5688e+05,304 1.5688e+05,304 1.6911e+05,304 1.6911e+05,304"];
	attn_block_3_14_24 -> hier_reduce_3_24	[pos="e,1.6915e+05,303 1.5582e+05,393.51 1.5582e+05,362.41 1.5582e+05,303 1.5582e+05,303 1.5582e+05,303 1.6914e+05,303 1.6914e+05,303"];
	attn_block_3_15_24 -> hier_reduce_3_24	[pos="e,1.6921e+05,301 1.5476e+05,393.67 1.5476e+05,362.14 1.5476e+05,301 1.5476e+05,301 1.5476e+05,301 1.692e+05,301 1.692e+05,301"];
	attn_block_3_16_24 -> hier_reduce_3_24	[pos="e,1.6924e+05,300 1.537e+05,393.51 1.537e+05,361.69 1.537e+05,300 1.537e+05,300 1.537e+05,300 1.6923e+05,300 1.6923e+05,300"];
	attn_block_3_17_24 -> hier_reduce_3_24	[pos="e,1.693e+05,298 1.5264e+05,393.94 1.5264e+05,361.79 1.5264e+05,298 1.5264e+05,298 1.5264e+05,298 1.6929e+05,298 1.6929e+05,298"];
	attn_block_3_18_24 -> hier_reduce_3_24	[pos="e,1.6951e+05,303 1.7655e+05,393.51 1.7655e+05,362.41 1.7655e+05,303 1.7655e+05,303 1.7655e+05,303 1.6952e+05,303 1.6952e+05,303"];
	attn_block_3_19_24 -> hier_reduce_3_24	[pos="e,1.6959e+05,306 1.755e+05,393.54 1.755e+05,363.17 1.755e+05,306 1.755e+05,306 1.755e+05,306 1.696e+05,306 1.696e+05,306"];
	attn_block_3_20_24 -> hier_reduce_3_24	[pos="e,1.6965e+05,308 1.7444e+05,393.88 1.7444e+05,364.09 1.7444e+05,308 1.7444e+05,308 1.7444e+05,308 1.6966e+05,308 1.6966e+05,308"];
	attn_block_3_21_24 -> hier_reduce_3_24	[pos="e,1.6971e+05,310 1.7339e+05,393.76 1.7339e+05,364.43 1.7339e+05,310 1.7339e+05,310 1.7339e+05,310 1.6972e+05,310 1.6972e+05,310"];
	attn_block_3_22_24 -> hier_reduce_3_24	[pos="e,1.6977e+05,312 1.7234e+05,393.66 1.7234e+05,364.79 1.7234e+05,312 1.7234e+05,312 1.7234e+05,312 1.6978e+05,312 1.6978e+05,312"];
	attn_block_3_23_24 -> hier_reduce_3_24	[pos="e,1.6986e+05,315 1.713e+05,393.76 1.713e+05,365.66 1.713e+05,315 1.713e+05,315 1.713e+05,315 1.6987e+05,315 1.6987e+05,315"];
	l3_ffn_ln_0 -> final_output_0	[pos="e,3.0238e+05,180.03 3.0238e+05,224.62 3.0238e+05,224.62 3.0238e+05,190.03 3.0238e+05,190.03"];
	l3_ffn_ln_1 -> final_output_1	[pos="e,3.0614e+05,162 3.0724e+05,224.62 3.0724e+05,200.72 3.0724e+05,162 3.0724e+05,162 3.0724e+05,162 3.0615e+05,162 3.0615e+05,162"];
	l3_ffn_ln_2 -> final_output_2	[pos="e,3.0545e+05,180.18 3.0604e+05,224.73 3.0604e+05,206.44 3.0604e+05,181 3.0604e+05,181 3.0604e+05,181 3.0545e+05,181 3.0545e+05,181 \
3.0545e+05,181 3.0545e+05,180.92 3.0545e+05,180.92"];
	l3_ffn_ln_3 -> final_output_3	[pos="e,3.0175e+05,180.16 3.0134e+05,237 3.0153e+05,237 3.0175e+05,237 3.0175e+05,237 3.0175e+05,237 3.0175e+05,190.16 3.0175e+05,190.16"];
	l3_ffn_ln_4 -> final_output_4	[pos="e,3.0401e+05,180.03 3.0401e+05,224.62 3.0401e+05,224.62 3.0401e+05,190.03 3.0401e+05,190.03"];
	l3_ffn_ln_5 -> final_output_5	[pos="e,3.0104e+05,162 2.9997e+05,224.62 2.9997e+05,200.72 2.9997e+05,162 2.9997e+05,162 2.9997e+05,162 3.0103e+05,162 3.0103e+05,162"];
	l3_ffn_ln_6 -> final_output_6	[pos="e,3.0327e+05,180.03 3.0327e+05,224.62 3.0327e+05,224.62 3.0327e+05,190.03 3.0327e+05,190.03"];
	l3_ffn_ln_7 -> final_output_7	[pos="e,3.0455e+05,180.13 3.0521e+05,231 3.0492e+05,231 3.0455e+05,231 3.0455e+05,231 3.0455e+05,231 3.0455e+05,190.13 3.0455e+05,190.13"];
	hier_reduce_0_8 -> l0_ffn_ln_0	[pos="e,8928.8,261 14666,306 14533,306 14399,306 14399,306 14399,306 14399,261 14399,261 14399,261 8938.8,261 8938.8,261"];
	hier_reduce_0_8 -> l0_ffn_ln_1	[pos="e,3421.7,261.06 14929,296.82 14929,283.96 14929,269 14929,269 14929,269 3421.7,269 3421.7,269 3421.7,269 3421.7,268.21 3421.7,268.21"];
	hier_reduce_0_8 -> l0_ffn_ln_2	[pos="e,794,261.13 14579,308.83 14579,299.53 14579,283 14579,283 14579,283 794,283 794,283 794,283 794,271.13 794,271.13"];
	hier_reduce_0_8 -> l0_ffn_ln_3	[pos="e,5370,261.12 15279,308.99 15279,295.91 15279,266 15279,266 15279,266 5370,266 5370,266 5370,266 5370,265.51 5370,265.51"];
	hier_reduce_0_8 -> l0_ffn_ln_4	[pos="e,6817.7,261.17 14666,324 14530,324 14390,324 14390,324 14390,324 14390,265 14390,265 14390,265 6817.7,265 6817.7,265 6817.7,265 \
6817.7,264.62 6817.7,264.62"];
	hier_reduce_0_8 -> l0_ffn_ln_5	[pos="e,4524.2,261.17 15104,302.65 15104,288.73 15104,268 15104,268 15104,268 4524.2,268 4524.2,268 4524.2,268 4524.2,267.32 4524.2,267.32"];
	hier_reduce_0_8 -> l0_ffn_ln_6	[pos="e,2289.7,261.21 14754,302.98 14754,289.95 14754,271 14754,271 14754,271 2289.7,271 2289.7,271 2289.7,271 2289.7,270.02 2289.7,270.02"];
	hier_reduce_0_8 -> l0_ffn_ln_7	[pos="e,8005,261.15 14404,315 14398,315 14395,315 14395,315 14395,315 14395,263 14395,263 14395,263 8005,263 8005,263 8005,263 8005,262.82 \
8005,262.82"];
	hier_reduce_0_16 -> l0_ffn_ln_0	[pos="e,8928.6,228 61983,317.32 61983,327.66 61983,369 61983,369 61983,369 11072,369 11072,369 11072,369 11072,228 11072,228 11072,228 \
8938.6,228 8938.6,228"];
	hier_reduce_0_16 -> l0_ffn_ln_1	[pos="e,3406.6,261.21 62248,325.91 62248,343.45 62248,376 62248,376 62248,376 3406.6,376 3406.6,376 3406.6,376 3406.6,271.21 3406.6,271.21"];
	hier_reduce_0_16 -> l0_ffn_ln_2	[pos="e,846.75,261.13 62107,321 61925,321 61742,321 61742,321 61742,321 61742,282 61742,282 61742,282 846.75,282 846.75,282 846.75,282 \
846.75,271.13 846.75,271.13"];
	hier_reduce_0_16 -> l0_ffn_ln_3	[pos="e,5427.7,237 62142,322.23 62142,337.99 62142,374 62142,374 62142,374 5670,374 5670,374 5670,374 5670,237 5670,237 5670,237 5437.7,\
237 5437.7,237"];
	hier_reduce_0_16 -> l0_ffn_ln_4	[pos="e,6802.6,261.08 62089,320.77 62089,335.44 62089,373 62089,373 62089,373 6802.6,373 6802.6,373 6802.6,373 6802.6,271.08 6802.6,271.08"];
	hier_reduce_0_16 -> l0_ffn_ln_5	[pos="e,4519.6,261.08 62195,324.11 62195,340.9 62195,375 62195,375 62195,375 4519.6,375 4519.6,375 4519.6,375 4519.6,271.08 4519.6,271.08"];
	hier_reduce_0_16 -> l0_ffn_ln_6	[pos="e,2274.6,261.06 62301,327.64 62301,346.3 62301,379 62301,379 62301,379 2274.6,379 2274.6,379 2274.6,379 2274.6,271.06 2274.6,271.06"];
	hier_reduce_0_16 -> l0_ffn_ln_7	[pos="e,7934.6,261.21 62036,318.74 62036,331.42 62036,372 62036,372 62036,372 7934.6,372 7934.6,372 7934.6,372 7934.6,271.21 7934.6,271.21"];
	hier_reduce_0_24 -> l0_ffn_ln_0	[pos="e,8928.7,232 1.8574e+05,315.16 1.8574e+05,318.38 1.8574e+05,370 1.8574e+05,370 1.8574e+05,370 11066,370 11066,370 11066,370 11066,\
232 11066,232 11066,232 8938.7,232 8938.7,232"];
	hier_reduce_0_24 -> l0_ffn_ln_1	[pos="e,3401.2,261.21 1.8574e+05,315.4 1.8574e+05,320.77 1.8574e+05,378 1.8574e+05,378 1.8574e+05,378 3401.2,378 3401.2,378 3401.2,378 \
3401.2,271.21 3401.2,271.21"];
	hier_reduce_0_24 -> l0_ffn_ln_2	[pos="e,899.58,243 1.8574e+05,315.42 1.8574e+05,320.95 1.8574e+05,380 1.8574e+05,380 1.8574e+05,380 1139,380 1139,380 1139,380 1139,243 \
1139,243 1139,243 909.58,243 909.58,243"];
	hier_reduce_0_24 -> l0_ffn_ln_3	[pos="e,5427.9,249 1.858e+05,317.3 1.858e+05,329.27 1.858e+05,384 1.858e+05,384 1.858e+05,384 5664,384 5664,384 5664,384 5664,249 5664,\
249 5664,249 5437.9,249 5437.9,249"];
	hier_reduce_0_24 -> l0_ffn_ln_4	[pos="e,6797.2,261.02 1.8578e+05,316.68 1.8578e+05,327.15 1.8578e+05,383 1.8578e+05,383 1.8578e+05,383 6797.2,383 6797.2,383 6797.2,383 \
6797.2,271.02 6797.2,271.02"];
	hier_reduce_0_24 -> l0_ffn_ln_5	[pos="e,4517.4,261.05 1.8574e+05,315.45 1.8574e+05,324.72 1.8574e+05,473 1.8574e+05,473 1.8574e+05,473 4517.4,473 4517.4,473 4517.4,473 \
4517.4,271.05 4517.4,271.05"];
	hier_reduce_0_24 -> l0_ffn_ln_6	[pos="e,2269.2,261.27 1.8582e+05,318.01 1.8582e+05,331.41 1.8582e+05,385 1.8582e+05,385 1.8582e+05,385 2269.2,385 2269.2,385 2269.2,385 \
2269.2,271.27 2269.2,271.27"];
	hier_reduce_0_24 -> l0_ffn_ln_7	[pos="e,7929.2,261.04 1.8576e+05,316.15 1.8576e+05,324.91 1.8576e+05,381 1.8576e+05,381 1.8576e+05,381 7929.2,381 7929.2,381 7929.2,381 \
7929.2,271.04 7929.2,271.04"];
	hier_reduce_1_8 -> l1_ffn_ln_0	[pos="e,24280,229 90821,299 90595,299 89790,299 89790,299 89790,299 89790,229 89790,229 89790,229 24290,229 24290,229"];
	hier_reduce_1_8 -> l1_ffn_ln_1	[pos="e,23095,261.19 90763,301 90476,301 89757,301 89757,301 89757,301 89757,277 89757,277 89757,277 23095,277 23095,277 23095,277 23095,\
271.19 23095,271.19"];
	hier_reduce_1_8 -> l1_ffn_ln_2	[pos="e,21963,261.32 90705,303 90382,303 89724,303 89724,303 89724,303 89724,278 89724,278 89724,278 21963,278 21963,278 21963,278 21963,\
271.32 21963,271.32"];
	hier_reduce_1_8 -> l1_ffn_ln_3	[pos="e,19732,250 90520,320.8 90520,328.18 90520,340 90520,340 90520,340 20012,340 20012,340 20012,340 20012,250 20012,250 20012,250 19742,\
250 19742,250"];
	hier_reduce_1_8 -> l1_ffn_ln_4	[pos="e,20826,261.42 90646,305 90300,305 89692,305 89692,305 89692,305 89692,279 89692,279 89692,279 20826,279 20826,279 20826,279 20826,\
271.42 20826,271.42"];
	hier_reduce_1_8 -> l1_ffn_ln_5	[pos="e,18562,261.42 90588,307 90227,307 89660,307 89660,307 89660,307 89660,279 89660,279 89660,279 18562,279 18562,279 18562,279 18562,\
271.42 18562,271.42"];
	hier_reduce_1_8 -> l1_ffn_ln_6	[pos="e,17066,224.89 90471,311 90278,311 90088,311 90088,311 90088,311 90088,205 90088,205 90088,205 17066,205 17066,205 17066,205 17066,\
214.89 17066,214.89"];
	hier_reduce_1_8 -> l1_ffn_ln_7	[pos="e,15934,224.87 90530,309 90372,309 90222,309 90222,309 90222,309 90222,204 90222,204 90222,204 15934,204 15934,204 15934,204 15934,\
214.87 15934,214.87"];
	hier_reduce_1_16 -> l1_ffn_ln_0	[pos="e,24280,232 78937,320 78757,320 78581,320 78581,320 78581,320 78581,232 78581,232 78581,232 24290,232 24290,232"];
	hier_reduce_1_16 -> l1_ffn_ln_1	[pos="e,23042,261.07 78996,322 78782,322 78539,322 78539,322 78539,322 78539,280 78539,280 78539,280 23042,280 23042,280 23042,280 23042,\
271.07 23042,271.07"];
	hier_reduce_1_16 -> l1_ffn_ln_2	[pos="e,21910,261.11 79026,323 78789,323 78497,323 78497,323 78497,323 78497,281 78497,281 78497,281 21910,281 21910,281 21910,281 21910,\
271.11 21910,271.11"];
	hier_reduce_1_16 -> l1_ffn_ln_3	[pos="e,19674,261.11 79084,325 78828,325 78455,325 78455,325 78455,325 78455,281 78455,281 78455,281 19674,281 19674,281 19674,281 19674,\
271.11 19674,271.11"];
	hier_reduce_1_16 -> l1_ffn_ln_4	[pos="e,20567,224.86 79261,331 79093,331 78623,331 78623,331 78623,331 78623,213 78623,213 78623,213 20567,213 20567,213 20567,213 20567,\
214.86 20567,214.86"];
	hier_reduce_1_16 -> l1_ffn_ln_5	[pos="e,18408,224.97 79202,329 79013,329 78665,329 78665,329 78665,329 78665,212 78665,212 78665,212 18408,212 18408,212 18408,212 18408,\
214.97 18408,214.97"];
	hier_reduce_1_16 -> l1_ffn_ln_6	[pos="e,17276,224.68 79173,328 78991,328 78707,328 78707,328 78707,328 78707,208 78707,208 78707,208 17276,208 17276,208 17276,208 17276,\
214.68 17276,214.68"];
	hier_reduce_1_16 -> l1_ffn_ln_7	[pos="e,16144,224.58 79114,326 78950,326 78749,326 78749,326 78749,326 78749,207 78749,207 78749,207 16144,207 16144,207 16144,207 16144,\
214.58 16144,214.58"];
	hier_reduce_1_24 -> l1_ffn_ln_0	[pos="e,24280,227 2.1124e+05,321 2.1035e+05,321 2.081e+05,321 2.081e+05,321 2.081e+05,321 2.081e+05,227 2.081e+05,227 2.081e+05,227 24290,\
227 24290,227"];
	hier_reduce_1_24 -> l1_ffn_ln_1	[pos="e,23148,255 2.1107e+05,315.46 2.1107e+05,324.84 2.1107e+05,475 2.1107e+05,475 2.1107e+05,475 23384,475 23384,475 23384,475 23384,\
255 23384,255 23384,255 23158,255 23158,255"];
	hier_reduce_1_24 -> l1_ffn_ln_2	[pos="e,22016,255 2.1107e+05,315.46 2.1107e+05,324.97 2.1107e+05,477 2.1107e+05,477 2.1107e+05,477 22278,477 22278,477 22278,477 22278,\
255 22278,255 22278,255 22026,255 22026,255"];
	hier_reduce_1_24 -> l1_ffn_ln_3	[pos="e,19732,255 2.1107e+05,315.29 2.1107e+05,318.15 2.1107e+05,341 2.1107e+05,341 2.1107e+05,341 20003,341 20003,341 20003,341 20003,\
255 20003,255 20003,255 19742,255 19742,255"];
	hier_reduce_1_24 -> l1_ffn_ln_4	[pos="e,20884,255 2.1107e+05,315.47 2.1107e+05,325.09 2.1107e+05,479 2.1107e+05,479 2.1107e+05,479 21120,479 21120,479 21120,479 21120,\
255 21120,255 21120,255 20894,255 20894,255"];
	hier_reduce_1_24 -> l1_ffn_ln_5	[pos="e,18198,224.96 2.1118e+05,319 2.1092e+05,319 2.1063e+05,319 2.1063e+05,319 2.1063e+05,319 2.1063e+05,210 2.1063e+05,210 2.1063e+\
05,210 18198,210 18198,210 18198,210 18198,214.96 18198,214.96"];
	hier_reduce_1_24 -> l1_ffn_ln_6	[pos="e,17488,255 2.1108e+05,315.48 2.1108e+05,325.21 2.1108e+05,481 2.1108e+05,481 2.1108e+05,481 17724,481 17724,481 17724,481 17724,\
255 17724,255 17724,255 17498,255 17498,255"];
	hier_reduce_1_24 -> l1_ffn_ln_7	[pos="e,16356,255 2.1112e+05,317.12 2.1112e+05,336.57 2.1112e+05,483 2.1112e+05,483 2.1112e+05,483 16592,483 16592,483 16592,483 16592,\
255 16592,255 16592,255 16366,255 16366,255"];
	hier_reduce_2_8 -> l2_ffn_ln_0	[pos="e,2.9817e+05,261.33 1.2577e+05,327.34 1.2577e+05,338.77 1.2577e+05,354 1.2577e+05,354 1.2577e+05,354 2.9817e+05,354 2.9817e+05,354 \
2.9817e+05,354 2.9817e+05,271.33 2.9817e+05,271.33"];
	hier_reduce_2_8 -> l2_ffn_ln_1	[pos="e,2.9715e+05,231 1.2586e+05,324.34 1.2586e+05,335.3 1.2586e+05,352 1.2586e+05,352 1.2586e+05,352 2.9704e+05,352 2.9704e+05,352 2.9704e+\
05,352 2.9704e+05,231 2.9704e+05,231 2.9704e+05,231 2.9714e+05,231 2.9714e+05,231"];
	hier_reduce_2_8 -> l2_ffn_ln_2	[pos="e,2.9502e+05,255 1.2604e+05,318.42 1.2604e+05,326.68 1.2604e+05,347 1.2604e+05,347 1.2604e+05,347 2.9476e+05,347 2.9476e+05,347 \
2.9476e+05,347 2.9476e+05,255 2.9476e+05,255 2.9476e+05,255 2.9501e+05,255 2.9501e+05,255"];
	hier_reduce_2_8 -> l2_ffn_ln_3	[pos="e,2.9615e+05,255 1.2595e+05,321.42 1.2595e+05,331.52 1.2595e+05,350 1.2595e+05,350 1.2595e+05,350 2.9589e+05,350 2.9589e+05,350 \
2.9589e+05,350 2.9589e+05,255 2.9589e+05,255 2.9589e+05,255 2.9614e+05,255 2.9614e+05,255"];
	hier_reduce_2_8 -> l2_ffn_ln_4	[pos="e,2.94e+05,261.18 1.2613e+05,315 1.2627e+05,315 1.2639e+05,315 1.2639e+05,315 1.2639e+05,315 1.2639e+05,289 1.2639e+05,289 1.2639e+\
05,289 2.94e+05,289 2.94e+05,289 2.94e+05,289 2.94e+05,271.18 2.94e+05,271.18"];
	hier_reduce_2_8 -> l2_ffn_ln_5	[pos="e,2.9049e+05,237 1.2596e+05,321 1.2608e+05,321 1.262e+05,321 1.262e+05,321 1.262e+05,321 1.262e+05,237 1.262e+05,237 1.262e+05,237 \
2.9048e+05,237 2.9048e+05,237"];
	hier_reduce_2_8 -> l2_ffn_ln_6	[pos="e,2.9174e+05,261.49 1.2578e+05,303 1.2598e+05,303 1.2626e+05,303 1.2626e+05,303 1.2626e+05,303 1.2626e+05,286 1.2626e+05,286 1.2626e+\
05,286 2.9174e+05,286 2.9174e+05,286 2.9174e+05,286 2.9174e+05,271.49 2.9174e+05,271.49"];
	hier_reduce_2_8 -> l2_ffn_ln_7	[pos="e,2.9287e+05,261.15 1.2596e+05,309 1.2614e+05,309 1.2633e+05,309 1.2633e+05,309 1.2633e+05,309 1.2633e+05,287 1.2633e+05,287 1.2633e+\
05,287 2.9287e+05,287 2.9287e+05,287 2.9287e+05,287 2.9287e+05,271.15 2.9287e+05,271.15"];
	hier_reduce_2_16 -> l2_ffn_ln_0	[pos="e,2.9818e+05,261.16 37530,320.7 37530,331.97 37530,356 37530,356 37530,356 2.9818e+05,356 2.9818e+05,356 2.9818e+05,356 2.9818e+\
05,271.16 2.9818e+05,271.16"];
	hier_reduce_2_16 -> l2_ffn_ln_1	[pos="e,2.9722e+05,261.15 37277,329 37515,329 38028,329 38028,329 38028,329 38028,291 38028,291 38028,291 2.9722e+05,291 2.9722e+05,291 \
2.9722e+05,291 2.9722e+05,271.15 2.9722e+05,271.15"];
	hier_reduce_2_16 -> l2_ffn_ln_2	[pos="e,2.9508e+05,261.18 37365,326 37594,326 37931,326 37931,326 37931,326 37931,289 37931,289 37931,289 2.9508e+05,289 2.9508e+05,289 \
2.9508e+05,289 2.9508e+05,271.18 2.9508e+05,271.18"];
	hier_reduce_2_16 -> l2_ffn_ln_3	[pos="e,2.9626e+05,261.04 37306,328 37542,328 37979,328 37979,328 37979,328 37979,290 37979,290 37979,290 2.9626e+05,290 2.9626e+05,290 \
2.9626e+05,290 2.9626e+05,271.04 2.9626e+05,271.04"];
	hier_reduce_2_16 -> l2_ffn_ln_4	[pos="e,2.9394e+05,261.04 37424,324 37630,324 37882,324 37882,324 37882,324 37882,288 37882,288 37882,288 2.9394e+05,288 2.9394e+05,288 \
2.9394e+05,288 2.9394e+05,271.04 2.9394e+05,271.04"];
	hier_reduce_2_16 -> l2_ffn_ln_5	[pos="e,2.9049e+05,234 37218,331 37365,331 37737,331 37737,331 37737,331 37737,234 37737,234 37737,234 2.9048e+05,234 2.9048e+05,234"];
	hier_reduce_2_16 -> l2_ffn_ln_6	[pos="e,2.9168e+05,261.06 37512,321 37654,321 37785,321 37785,321 37785,321 37785,285 37785,285 37785,285 2.9168e+05,285 2.9168e+05,285 \
2.9168e+05,285 2.9168e+05,271.06 2.9168e+05,271.06"];
	hier_reduce_2_16 -> l2_ffn_ln_7	[pos="e,2.9281e+05,261.49 37454,323 37635,323 37834,323 37834,323 37834,323 37834,286 37834,286 37834,286 2.9281e+05,286 2.9281e+05,286 \
2.9281e+05,286 2.9281e+05,271.49 2.9281e+05,271.49"];
	hier_reduce_2_24 -> l2_ffn_ln_0	[pos="e,2.9817e+05,261.16 1.4444e+05,317.98 1.4444e+05,326.94 1.4444e+05,353 1.4444e+05,353 1.4444e+05,353 2.9817e+05,353 2.9817e+05,353 \
2.9817e+05,353 2.9817e+05,271.16 2.9817e+05,271.16"];
	hier_reduce_2_24 -> l2_ffn_ln_1	[pos="e,2.9715e+05,228 1.4445e+05,317.82 1.4445e+05,326.31 1.4445e+05,351 1.4445e+05,351 1.4445e+05,351 2.9703e+05,351 2.9703e+05,351 \
2.9703e+05,351 2.9703e+05,228 2.9703e+05,228 2.9703e+05,228 2.9714e+05,228 2.9714e+05,228"];
	hier_reduce_2_24 -> l2_ffn_ln_2	[pos="e,2.9502e+05,250 1.4447e+05,317.03 1.4447e+05,323.93 1.4447e+05,346 1.4447e+05,346 1.4447e+05,346 2.9475e+05,346 2.9475e+05,346 \
2.9475e+05,346 2.9475e+05,250 2.9475e+05,250 2.9475e+05,250 2.9501e+05,250 2.9501e+05,250"];
	hier_reduce_2_24 -> l2_ffn_ln_3	[pos="e,2.9615e+05,250 1.4446e+05,317.17 1.4446e+05,324.51 1.4446e+05,348 1.4446e+05,348 1.4446e+05,348 2.9589e+05,348 2.9589e+05,348 \
2.9589e+05,348 2.9589e+05,250 2.9589e+05,250 2.9589e+05,250 2.9614e+05,250 2.9614e+05,250"];
	hier_reduce_2_24 -> l2_ffn_ln_4	[pos="e,2.9388e+05,255 1.4448e+05,316.61 1.4448e+05,322.84 1.4448e+05,345 1.4448e+05,345 1.4448e+05,345 2.9362e+05,345 2.9362e+05,345 \
2.9362e+05,345 2.9362e+05,255 2.9362e+05,255 2.9362e+05,255 2.9387e+05,255 2.9387e+05,255"];
	hier_reduce_2_24 -> l2_ffn_ln_5	[pos="e,2.9049e+05,239 1.4432e+05,322 1.4475e+05,322 1.4546e+05,322 1.4546e+05,322 1.4546e+05,322 1.4546e+05,239 1.4546e+05,239 1.4546e+\
05,239 2.9048e+05,239 2.9048e+05,239"];
	hier_reduce_2_24 -> l2_ffn_ln_6	[pos="e,2.9162e+05,255 1.445e+05,316.16 1.445e+05,321.33 1.445e+05,342 1.445e+05,342 1.445e+05,342 2.9136e+05,342 2.9136e+05,342 2.9136e+\
05,342 2.9136e+05,255 2.9136e+05,255 2.9136e+05,255 2.9161e+05,255 2.9161e+05,255"];
	hier_reduce_2_24 -> l2_ffn_ln_7	[pos="e,2.9275e+05,255 1.4449e+05,316.2 1.4449e+05,321.56 1.4449e+05,343 1.4449e+05,343 1.4449e+05,343 2.9249e+05,343 2.9249e+05,343 2.9249e+\
05,343 2.9249e+05,255 2.9249e+05,255 2.9249e+05,255 2.9274e+05,255 2.9274e+05,255"];
	hier_reduce_3_8 -> l3_ffn_ln_0	[pos="e,3.0193e+05,261.12 1.3465e+05,301 1.3482e+05,301 1.3511e+05,301 1.3511e+05,301 1.3511e+05,301 1.3511e+05,294 1.3511e+05,294 1.3511e+\
05,294 3.0193e+05,294 3.0193e+05,294 3.0193e+05,294 3.0193e+05,271.12 3.0193e+05,271.12"];
	hier_reduce_3_8 -> l3_ffn_ln_1	[pos="e,3.0708e+05,261.24 1.3483e+05,307 1.3498e+05,307 1.3514e+05,307 1.3514e+05,307 1.3514e+05,307 1.3514e+05,296 1.3514e+05,296 1.3514e+\
05,296 3.0708e+05,296 3.0708e+05,296 3.0708e+05,296 3.0708e+05,271.24 3.0708e+05,271.24"];
	hier_reduce_3_8 -> l3_ffn_ln_2	[pos="e,3.0597e+05,261.19 1.3477e+05,305 1.3494e+05,305 1.3513e+05,305 1.3513e+05,305 1.3513e+05,305 1.3513e+05,295 1.3513e+05,295 1.3513e+\
05,295 3.0597e+05,295 3.0597e+05,295 3.0597e+05,295 3.0597e+05,271.19 3.0597e+05,271.19"];
	hier_reduce_3_8 -> l3_ffn_ln_3	[pos="e,3.0079e+05,224.83 1.35e+05,313 1.3506e+05,313 1.3509e+05,313 1.3509e+05,313 1.3509e+05,313 1.3509e+05,221 1.3509e+05,221 1.3509e+\
05,221 3.0079e+05,221 3.0079e+05,221 3.0079e+05,221 3.0079e+05,221.38 3.0079e+05,221.38"];
	hier_reduce_3_8 -> l3_ffn_ln_4	[pos="e,3.037e+05,261.12 1.3471e+05,303 1.3488e+05,303 1.3512e+05,303 1.3512e+05,303 1.3512e+05,303 1.3512e+05,294 1.3512e+05,294 1.3512e+\
05,294 3.037e+05,294 3.037e+05,294 3.037e+05,294 3.037e+05,271.12 3.037e+05,271.12"];
	hier_reduce_3_8 -> l3_ffn_ln_5	[pos="e,2.9967e+05,261.25 1.346e+05,299 1.3474e+05,299 1.351e+05,299 1.351e+05,299 1.351e+05,299 1.351e+05,292 1.351e+05,292 1.351e+05,\
292 2.9967e+05,292 2.9967e+05,292 2.9967e+05,292 2.9967e+05,271.25 2.9967e+05,271.25"];
	hier_reduce_3_8 -> l3_ffn_ln_6	[pos="e,3.0295e+05,224.83 1.3495e+05,311 1.3502e+05,311 1.3508e+05,311 1.3508e+05,311 1.3508e+05,311 1.3508e+05,218 1.3508e+05,218 1.3508e+\
05,218 3.0295e+05,218 3.0295e+05,218 3.0295e+05,218 3.0295e+05,218.68 3.0295e+05,218.68"];
	hier_reduce_3_8 -> l3_ffn_ln_7	[pos="e,3.0531e+05,224.84 1.3489e+05,309 1.3499e+05,309 1.3507e+05,309 1.3507e+05,309 1.3507e+05,309 1.3507e+05,216 1.3507e+05,216 1.3507e+\
05,216 3.0531e+05,216 3.0531e+05,216 3.0531e+05,216 3.0531e+05,216.88 3.0531e+05,216.88"];
	hier_reduce_3_16 -> l3_ffn_ln_0	[pos="e,3.0187e+05,261.05 54284,324 54523,324 54839,324 54839,324 54839,324 54839,293 54839,293 54839,293 3.0187e+05,293 3.0187e+05,293 \
3.0187e+05,293 3.0187e+05,271.05 3.0187e+05,271.05"];
	hier_reduce_3_16 -> l3_ffn_ln_1	[pos="e,3.0724e+05,261.03 54263,325.03 54263,340.14 54263,367 54263,367 54263,367 3.0724e+05,367 3.0724e+05,367 3.0724e+05,367 3.0724e+\
05,271.03 3.0724e+05,271.03"];
	hier_reduce_3_16 -> l3_ffn_ln_2	[pos="e,3.0609e+05,261.11 54358,321.81 54358,335.28 54358,364 54358,364 54358,364 3.0609e+05,364 3.0609e+05,364 3.0609e+05,364 3.0609e+\
05,271.11 3.0609e+05,271.11"];
	hier_reduce_3_16 -> l3_ffn_ln_3	[pos="e,3.0087e+05,224.88 54196,327 54410,327 54742,327 54742,327 54742,327 54742,220 54742,220 54742,220 3.0087e+05,220 3.0087e+05,220 \
3.0087e+05,220 3.0087e+05,220.49 3.0087e+05,220.49"];
	hier_reduce_3_16 -> l3_ffn_ln_4	[pos="e,3.0383e+05,261.07 54453,318.38 54453,329.16 54453,362 54453,362 54453,362 3.0383e+05,362 3.0383e+05,362 3.0383e+05,362 3.0383e+\
05,271.07 3.0383e+05,271.07"];
	hier_reduce_3_16 -> l3_ffn_ln_5	[pos="e,2.9961e+05,261.15 54343,308 54637,308 55025,308 55025,308 55025,308 55025,291 55025,291 55025,291 2.9961e+05,291 2.9961e+05,291 \
2.9961e+05,291 2.9961e+05,271.15 2.9961e+05,271.15"];
	hier_reduce_3_16 -> l3_ffn_ln_6	[pos="e,3.0295e+05,224.85 54107,330 54280,330 54645,330 54645,330 54645,330 54645,120 54645,120 54645,120 3.0295e+05,120 3.0295e+05,120 \
3.0295e+05,120 3.0295e+05,214.85 3.0295e+05,214.85"];
	hier_reduce_3_16 -> l3_ffn_ln_7	[pos="e,3.0535e+05,224.79 54401,310 54670,310 54980,310 54980,310 54980,310 54980,215 54980,215 54980,215 3.0535e+05,215 3.0535e+05,215 \
3.0535e+05,215 3.0535e+05,215.98 3.0535e+05,215.98"];
	hier_reduce_3_24 -> l3_ffn_ln_0	[pos="e,3.0181e+05,249 1.6982e+05,316.46 1.6982e+05,324.1 1.6982e+05,359 1.6982e+05,359 1.6982e+05,359 3.0158e+05,359 3.0158e+05,359 3.0158e+\
05,359 3.0158e+05,249 3.0158e+05,249 3.0158e+05,249 3.018e+05,249 3.018e+05,249"];
	hier_reduce_3_24 -> l3_ffn_ln_1	[pos="e,3.0723e+05,261 1.6979e+05,317.41 1.6979e+05,327.4 1.6979e+05,365 1.6979e+05,365 1.6979e+05,365 3.0723e+05,365 3.0723e+05,365 3.0723e+\
05,365 3.0723e+05,271 3.0723e+05,271"];
	hier_reduce_3_24 -> l3_ffn_ln_2	[pos="e,3.0608e+05,261.23 1.698e+05,317.06 1.698e+05,326.25 1.698e+05,363 1.698e+05,363 1.698e+05,363 3.0608e+05,363 3.0608e+05,363 3.0608e+\
05,363 3.0608e+05,271.23 3.0608e+05,271.23"];
	hier_reduce_3_24 -> l3_ffn_ln_3	[pos="e,3.007e+05,231 1.6983e+05,316.06 1.6983e+05,322.68 1.6983e+05,358 1.6983e+05,358 1.6983e+05,358 3.0042e+05,358 3.0042e+05,358 3.0042e+\
05,358 3.0042e+05,231 3.0042e+05,231 3.0042e+05,231 3.0069e+05,231 3.0069e+05,231"];
	hier_reduce_3_24 -> l3_ffn_ln_4	[pos="e,3.0382e+05,261.18 1.6981e+05,316.98 1.6981e+05,325.78 1.6981e+05,361 1.6981e+05,361 1.6981e+05,361 3.0382e+05,361 3.0382e+05,361 \
3.0382e+05,361 3.0382e+05,271.18 3.0382e+05,271.18"];
	hier_reduce_3_24 -> l3_ffn_ln_5	[pos="e,2.9955e+05,231 1.6977e+05,318.25 1.6977e+05,343.08 1.6977e+05,502 1.6977e+05,502 1.6977e+05,502 2.993e+05,502 2.993e+05,502 2.993e+\
05,502 2.993e+05,231 2.993e+05,231 2.993e+05,231 2.9954e+05,231 2.9954e+05,231"];
	hier_reduce_3_24 -> l3_ffn_ln_6	[pos="e,3.0295e+05,224.67 1.6945e+05,301 1.698e+05,301 1.7079e+05,301 1.7079e+05,301 1.7079e+05,301 1.7079e+05,132 1.7079e+05,132 1.7079e+\
05,132 3.0295e+05,132 3.0295e+05,132 3.0295e+05,132 3.0295e+05,214.67 3.0295e+05,214.67"];
	hier_reduce_3_24 -> l3_ffn_ln_7	[pos="e,3.0526e+05,224.85 1.6939e+05,299 1.696e+05,299 1.7029e+05,299 1.7029e+05,299 1.7029e+05,299 1.7029e+05,223 1.7029e+05,223 1.7029e+\
05,223 3.0526e+05,223 3.0526e+05,223 3.0526e+05,223 3.0526e+05,223.18 3.0526e+05,223.18"];
	kv_sync_0 -> kv_cache_0_0_8	[pos="e,94536,550 1.2586e+05,640.69 1.2586e+05,620.85 1.2586e+05,592 1.2586e+05,592 1.2586e+05,592 94536,592 94536,592 94536,592 94536,\
560 94536,560"];
	kv_sync_0 -> kv_cache_0_1_8	[pos="e,93486,550.22 1.2575e+05,640.83 1.2575e+05,621.91 1.2575e+05,595 1.2575e+05,595 1.2575e+05,595 93486,595 93486,595 93486,595 93486,\
560.22 93486,560.22"];
	kv_sync_0 -> kv_cache_0_2_8	[pos="e,1.0084e+05,550.11 1.2647e+05,653.43 1.2647e+05,633.95 1.2647e+05,570 1.2647e+05,570 1.2647e+05,570 1.0084e+05,570 1.0084e+05,570 \
1.0084e+05,570 1.0084e+05,560.11 1.0084e+05,560.11"];
	kv_sync_0 -> kv_cache_0_3_8	[pos="e,99786,550.13 1.2637e+05,640.77 1.2637e+05,614.99 1.2637e+05,571 1.2637e+05,571 1.2637e+05,571 99786,571 99786,571 99786,571 99786,\
560.13 99786,560.13"];
	kv_sync_0 -> kv_cache_0_4_8	[pos="e,98736,550.13 1.2626e+05,640.97 1.2626e+05,615.49 1.2626e+05,572 1.2626e+05,572 1.2626e+05,572 98736,572 98736,572 98736,572 98736,\
560.13 98736,560.13"];
	kv_sync_0 -> kv_cache_0_5_8	[pos="e,97686,550.19 1.2616e+05,640.84 1.2616e+05,618.65 1.2616e+05,584 1.2616e+05,584 1.2616e+05,584 97686,584 97686,584 97686,584 97686,\
560.19 97686,560.19"];
	kv_sync_0 -> kv_cache_0_6_8	[pos="e,96636,550.01 1.2606e+05,640.83 1.2606e+05,619.5 1.2606e+05,587 1.2606e+05,587 1.2606e+05,587 96636,587 96636,587 96636,587 96636,\
560.01 96636,560.01"];
	kv_sync_0 -> kv_cache_0_7_8	[pos="e,95586,550.03 1.2596e+05,640.87 1.2596e+05,620.43 1.2596e+05,590 1.2596e+05,590 1.2596e+05,590 95586,590 95586,590 95586,590 95586,\
560.03 95586,560.03"];
	kv_sync_0 -> kv_cache_0_0_16	[pos="e,68236,550.08 1.2559e+05,659.08 1.2559e+05,660.72 1.2559e+05,687 1.2559e+05,687 1.2559e+05,687 68236,687 68236,687 68236,687 68236,\
560.08 68236,560.08"];
	kv_sync_0 -> kv_cache_0_1_16	[pos="e,67186,550.2 1.2564e+05,659.08 1.2564e+05,660.78 1.2564e+05,688 1.2564e+05,688 1.2564e+05,688 67186,688 67186,688 67186,688 67186,\
560.2 67186,560.2"];
	kv_sync_0 -> kv_cache_0_2_16	[pos="e,66136,550.01 1.2568e+05,662.21 1.2568e+05,669.95 1.2568e+05,689 1.2568e+05,689 1.2568e+05,689 66136,689 66136,689 66136,689 66136,\
560.01 66136,560.01"];
	kv_sync_0 -> kv_cache_0_3_16	[pos="e,65086,550.12 1.2572e+05,669.5 1.2572e+05,678.49 1.2572e+05,690 1.2572e+05,690 1.2572e+05,690 65086,690 65086,690 65086,690 65086,\
560.12 65086,560.12"];
	kv_sync_0 -> kv_cache_0_4_16	[pos="e,64036,550.24 1.2576e+05,676.5 1.2576e+05,683.97 1.2576e+05,691 1.2576e+05,691 1.2576e+05,691 64036,691 64036,691 64036,691 64036,\
560.24 64036,560.24"];
	kv_sync_0 -> kv_cache_0_5_16	[pos="e,62986,550.04 1.258e+05,677.04 1.258e+05,684.75 1.258e+05,692 1.258e+05,692 1.258e+05,692 62986,692 62986,692 62986,692 62986,560.04 \
62986,560.04"];
	kv_sync_0 -> kv_cache_0_6_16	[pos="e,61936,550.16 1.2585e+05,677.19 1.2585e+05,685.28 1.2585e+05,693 1.2585e+05,693 1.2585e+05,693 61936,693 61936,693 61936,693 61936,\
560.16 61936,560.16"];
	kv_sync_0 -> kv_cache_0_7_16	[pos="e,60886,550.27 1.2589e+05,677.32 1.2589e+05,685.79 1.2589e+05,694 1.2589e+05,694 1.2589e+05,694 60886,694 60886,694 60886,694 60886,\
560.27 60886,560.27"];
	kv_sync_0 -> kv_cache_0_8_16	[pos="e,59836,550.07 1.2593e+05,677 1.2593e+05,686 1.2593e+05,695 1.2593e+05,695 1.2593e+05,695 59836,695 59836,695 59836,695 59836,560.07 \
59836,560.07"];
	kv_sync_0 -> kv_cache_0_9_16	[pos="e,58786,550.12 1.2623e+05,677.27 1.2623e+05,695.56 1.2623e+05,721 1.2623e+05,721 1.2623e+05,721 58786,721 58786,721 58786,721 58786,\
560.12 58786,560.12"];
	kv_sync_0 -> kv_cache_0_10_16	[pos="e,75000,532 1.2597e+05,677.01 1.2597e+05,693.05 1.2597e+05,714 1.2597e+05,714 1.2597e+05,714 75118,714 75118,714 75118,714 75118,\
532 75118,532 75118,532 75010,532 75010,532"];
	kv_sync_0 -> kv_cache_0_11_16	[pos="e,73941,532 1.2602e+05,677.03 1.2602e+05,693.4 1.2602e+05,715 1.2602e+05,715 1.2602e+05,715 74056,715 74056,715 74056,715 74056,\
532 74056,532 74056,532 73951,532 73951,532"];
	kv_sync_0 -> kv_cache_0_12_16	[pos="e,72882,532 1.2606e+05,677.04 1.2606e+05,693.73 1.2606e+05,716 1.2606e+05,716 1.2606e+05,716 72998,716 72998,716 72998,716 72998,\
532 72998,532 72998,532 72892,532 72892,532"];
	kv_sync_0 -> kv_cache_0_13_16	[pos="e,71823,532 1.261e+05,677.03 1.261e+05,694.06 1.261e+05,717 1.261e+05,717 1.261e+05,717 71938,717 71938,717 71938,717 71938,532 \
71938,532 71938,532 71833,532 71833,532"];
	kv_sync_0 -> kv_cache_0_14_16	[pos="e,70764,532 1.2614e+05,677.02 1.2614e+05,694.37 1.2614e+05,718 1.2614e+05,718 1.2614e+05,718 70880,718 70880,718 70880,718 70880,\
532 70880,532 70880,532 70774,532 70774,532"];
	kv_sync_0 -> kv_cache_0_15_16	[pos="e,69705,532 1.2619e+05,677 1.2619e+05,694.68 1.2619e+05,719 1.2619e+05,719 1.2619e+05,719 69820,719 69820,719 69820,719 69820,532 \
69820,532 69820,532 69715,532 69715,532"];
	kv_sync_0 -> kv_cache_0_0_24	[pos="e,1.9571e+05,550.27 1.2659e+05,673 1.266e+05,673 1.2661e+05,673 1.2661e+05,673 1.2661e+05,673 1.2661e+05,730 1.2661e+05,730 1.2661e+\
05,730 1.9571e+05,730 1.9571e+05,730 1.9571e+05,730 1.9571e+05,560.27 1.9571e+05,560.27"];
	kv_sync_0 -> kv_cache_0_1_24	[pos="e,1.9466e+05,550.18 1.2656e+05,669 1.2659e+05,669 1.2661e+05,669 1.2661e+05,669 1.2661e+05,669 1.2661e+05,729 1.2661e+05,729 1.2661e+\
05,729 1.9466e+05,729 1.9466e+05,729 1.9466e+05,729 1.9466e+05,560.18 1.9466e+05,560.18"];
	kv_sync_0 -> kv_cache_0_2_24	[pos="e,1.9361e+05,550.09 1.2654e+05,665 1.2658e+05,665 1.2661e+05,665 1.2661e+05,665 1.2661e+05,665 1.2661e+05,728 1.2661e+05,728 1.2661e+\
05,728 1.9361e+05,728 1.9361e+05,728 1.9361e+05,728 1.9361e+05,560.09 1.9361e+05,560.09"];
	kv_sync_0 -> kv_cache_0_3_24	[pos="e,1.9256e+05,550.25 1.2651e+05,661 1.2657e+05,661 1.2662e+05,661 1.2662e+05,661 1.2662e+05,661 1.2662e+05,726 1.2662e+05,726 1.2662e+\
05,726 1.9256e+05,726 1.9256e+05,726 1.9256e+05,726 1.9256e+05,560.25 1.9256e+05,560.25"];
	kv_sync_0 -> kv_cache_0_4_24	[pos="e,1.9151e+05,550.16 1.2649e+05,657 1.2656e+05,657 1.2662e+05,657 1.2662e+05,657 1.2662e+05,657 1.2662e+05,725 1.2662e+05,725 1.2662e+\
05,725 1.9151e+05,725 1.9151e+05,725 1.9151e+05,725 1.9151e+05,560.16 1.9151e+05,560.16"];
	kv_sync_0 -> kv_cache_0_5_24	[pos="e,1.9046e+05,550.06 1.2646e+05,653 1.2655e+05,653 1.2662e+05,653 1.2662e+05,653 1.2662e+05,653 1.2662e+05,724 1.2662e+05,724 1.2662e+\
05,724 1.9046e+05,724 1.9046e+05,724 1.9046e+05,724 1.9046e+05,560.06 1.9046e+05,560.06"];
	kv_sync_0 -> kv_cache_0_6_24	[pos="e,1.8941e+05,550.31 1.2644e+05,649 1.2654e+05,649 1.2662e+05,649 1.2662e+05,649 1.2662e+05,649 1.2662e+05,723 1.2662e+05,723 1.2662e+\
05,723 1.8941e+05,723 1.8941e+05,723 1.8941e+05,723 1.8941e+05,560.31 1.8941e+05,560.31"];
	kv_sync_0 -> kv_cache_0_7_24	[pos="e,1.8836e+05,550.22 1.2642e+05,645 1.2653e+05,645 1.2662e+05,645 1.2662e+05,645 1.2662e+05,645 1.2662e+05,722 1.2662e+05,722 1.2662e+\
05,722 1.8836e+05,722 1.8836e+05,722 1.8836e+05,722 1.8836e+05,560.22 1.8836e+05,560.22"];
	kv_sync_0 -> kv_cache_0_8_24	[pos="e,1.8731e+05,550.1 1.2652e+05,677.04 1.2652e+05,698.66 1.2652e+05,732 1.2652e+05,732 1.2652e+05,732 1.8731e+05,732 1.8731e+05,732 \
1.8731e+05,732 1.8731e+05,560.1 1.8731e+05,560.1"];
	kv_sync_0 -> kv_cache_0_9_24	[pos="e,1.8626e+05,550.01 1.2657e+05,677.17 1.2657e+05,698.5 1.2657e+05,731 1.2657e+05,731 1.2657e+05,731 1.8626e+05,731 1.8626e+05,731 \
1.8626e+05,731 1.8626e+05,560.01 1.8626e+05,560.01"];
	kv_sync_0 -> kv_cache_0_10_24	[pos="e,1.8479e+05,513.8 1.2657e+05,658.92 1.2657e+05,652.49 1.2657e+05,241 1.2657e+05,241 1.2657e+05,241 1.8479e+05,241 1.8479e+05,241 \
1.8479e+05,241 1.8479e+05,503.8 1.8479e+05,503.8"];
	kv_sync_0 -> kv_cache_0_11_24	[pos="e,1.8376e+05,513.98 1.2658e+05,658.92 1.2658e+05,652.54 1.2658e+05,244 1.2658e+05,244 1.2658e+05,244 1.8376e+05,244 1.8376e+05,244 \
1.8376e+05,244 1.8376e+05,503.98 1.8376e+05,503.98"];
	kv_sync_0 -> kv_cache_0_12_24	[pos="e,1.8272e+05,513.67 1.2658e+05,658.92 1.2658e+05,652.57 1.2658e+05,246 1.2658e+05,246 1.2658e+05,246 1.8272e+05,246 1.8272e+05,246 \
1.8272e+05,246 1.8272e+05,503.67 1.8272e+05,503.67"];
	kv_sync_0 -> kv_cache_0_13_24	[pos="e,1.8167e+05,513.87 1.2659e+05,658.93 1.2659e+05,652.62 1.2659e+05,249 1.2659e+05,249 1.2659e+05,249 1.8167e+05,249 1.8167e+05,249 \
1.8167e+05,249 1.8167e+05,503.87 1.8167e+05,503.87"];
	kv_sync_0 -> kv_cache_0_14_24	[pos="e,1.8061e+05,513.99 1.2659e+05,658.93 1.2659e+05,652.65 1.2659e+05,251 1.2659e+05,251 1.2659e+05,251 1.8061e+05,251 1.8061e+05,251 \
1.8061e+05,251 1.8061e+05,503.99 1.8061e+05,503.99"];
	kv_sync_0 -> kv_cache_0_15_24	[pos="e,1.7956e+05,513.69 1.266e+05,658.93 1.266e+05,652.68 1.266e+05,253 1.266e+05,253 1.266e+05,253 1.7956e+05,253 1.7956e+05,253 1.7956e+\
05,253 1.7956e+05,503.69 1.7956e+05,503.69"];
	kv_sync_0 -> kv_cache_0_16_24	[pos="e,1.785e+05,513.89 1.266e+05,658.93 1.266e+05,652.73 1.266e+05,256 1.266e+05,256 1.266e+05,256 1.785e+05,256 1.785e+05,256 1.785e+\
05,256 1.785e+05,503.89 1.785e+05,503.89"];
	kv_sync_0 -> kv_cache_0_17_24	[pos="e,1.7741e+05,513.6 1.266e+05,658.93 1.266e+05,652.76 1.266e+05,258 1.266e+05,258 1.266e+05,258 1.7741e+05,258 1.7741e+05,258 1.7741e+\
05,258 1.7741e+05,503.6 1.7741e+05,503.6"];
	kv_sync_0 -> kv_cache_0_18_24	[pos="e,2.0165e+05,532 1.2627e+05,677.15 1.2627e+05,700.76 1.2627e+05,739 1.2627e+05,739 1.2627e+05,739 2.0153e+05,739 2.0153e+05,739 \
2.0153e+05,739 2.0153e+05,532 2.0153e+05,532 2.0153e+05,532 2.0164e+05,532 2.0164e+05,532"];
	kv_sync_0 -> kv_cache_0_19_24	[pos="e,2.0059e+05,532 1.2631e+05,677.32 1.2631e+05,700.66 1.2631e+05,738 1.2631e+05,738 1.2631e+05,738 2.0047e+05,738 2.0047e+05,738 \
2.0047e+05,738 2.0047e+05,532 2.0047e+05,532 2.0047e+05,532 2.0058e+05,532 2.0058e+05,532"];
	kv_sync_0 -> kv_cache_0_20_24	[pos="e,1.9953e+05,532 1.2636e+05,677.09 1.2636e+05,700.13 1.2636e+05,737 1.2636e+05,737 1.2636e+05,737 1.9941e+05,737 1.9941e+05,737 \
1.9941e+05,737 1.9941e+05,532 1.9941e+05,532 1.9941e+05,532 1.9952e+05,532 1.9952e+05,532"];
	kv_sync_0 -> kv_cache_0_21_24	[pos="e,1.9847e+05,532 1.264e+05,677.25 1.264e+05,700.02 1.264e+05,736 1.264e+05,736 1.264e+05,736 1.9836e+05,736 1.9836e+05,736 1.9836e+\
05,736 1.9836e+05,532 1.9836e+05,532 1.9836e+05,532 1.9846e+05,532 1.9846e+05,532"];
	kv_sync_0 -> kv_cache_0_22_24	[pos="e,1.9741e+05,532 1.2644e+05,677.01 1.2644e+05,699.49 1.2644e+05,735 1.2644e+05,735 1.2644e+05,735 1.973e+05,735 1.973e+05,735 1.973e+\
05,735 1.973e+05,532 1.973e+05,532 1.973e+05,532 1.974e+05,532 1.974e+05,532"];
	kv_sync_0 -> kv_cache_0_23_24	[pos="e,1.9635e+05,532 1.2648e+05,677.29 1.2648e+05,699.21 1.2648e+05,733 1.2648e+05,733 1.2648e+05,733 1.9624e+05,733 1.9624e+05,733 \
1.9624e+05,733 1.9624e+05,532 1.9624e+05,532 1.9624e+05,532 1.9634e+05,532 1.9634e+05,532"];
	kv_sync_1 -> kv_cache_1_0_8	[pos="e,1.0294e+05,550.19 1.2735e+05,640.63 1.2735e+05,613.52 1.2735e+05,566 1.2735e+05,566 1.2735e+05,566 1.0294e+05,566 1.0294e+05,566 \
1.0294e+05,566 1.0294e+05,560.19 1.0294e+05,560.19"];
	kv_sync_1 -> kv_cache_1_1_8	[pos="e,1.0189e+05,550 1.2731e+05,640.58 1.2731e+05,613.99 1.2731e+05,568 1.2731e+05,568 1.2731e+05,568 1.0189e+05,568 1.0189e+05,568 \
1.0189e+05,568 1.0189e+05,560 1.0189e+05,560"];
	kv_sync_1 -> kv_cache_1_2_8	[pos="e,1.0924e+05,550.17 1.2761e+05,658.92 1.2761e+05,655.74 1.2761e+05,554 1.2761e+05,554 1.2761e+05,554 1.0924e+05,554 1.0924e+05,554 \
1.0924e+05,554 1.0924e+05,553.62 1.0924e+05,553.62"];
	kv_sync_1 -> kv_cache_1_3_8	[pos="e,1.0819e+05,550.12 1.2757e+05,656.83 1.2757e+05,641.89 1.2757e+05,555 1.2757e+05,555 1.2757e+05,555 1.0819e+05,555 1.0819e+05,555 \
1.0819e+05,555 1.0819e+05,554.51 1.0819e+05,554.51"];
	kv_sync_1 -> kv_cache_1_4_8	[pos="e,1.0714e+05,550.19 1.2752e+05,649.86 1.2752e+05,624.65 1.2752e+05,556 1.2752e+05,556 1.2752e+05,556 1.0714e+05,556 1.0714e+05,556 \
1.0714e+05,556 1.0714e+05,555.42 1.0714e+05,555.42"];
	kv_sync_1 -> kv_cache_1_5_8	[pos="e,1.0609e+05,550.16 1.2748e+05,642.49 1.2748e+05,614.08 1.2748e+05,559 1.2748e+05,559 1.2748e+05,559 1.0609e+05,559 1.0609e+05,559 \
1.0609e+05,559 1.0609e+05,558.12 1.0609e+05,558.12"];
	kv_sync_1 -> kv_cache_1_6_8	[pos="e,1.0504e+05,550.14 1.2744e+05,640.76 1.2744e+05,612.66 1.2744e+05,562 1.2744e+05,562 1.2744e+05,562 1.0504e+05,562 1.0504e+05,562 \
1.0504e+05,562 1.0504e+05,560.14 1.0504e+05,560.14"];
	kv_sync_1 -> kv_cache_1_7_8	[pos="e,1.0399e+05,550.03 1.2739e+05,640.94 1.2739e+05,613.13 1.2739e+05,563 1.2739e+05,563 1.2739e+05,563 1.0399e+05,563 1.0399e+05,563 \
1.0399e+05,563 1.0399e+05,560.03 1.0399e+05,560.03"];
	kv_sync_1 -> kv_cache_1_0_16	[pos="e,85096,550.01 1.2697e+05,640.85 1.2697e+05,628.73 1.2697e+05,615 1.2697e+05,615 1.2697e+05,615 85096,615 85096,615 85096,615 85096,\
560.01 85096,560.01"];
	kv_sync_1 -> kv_cache_1_1_16	[pos="e,84046,550.23 1.2693e+05,640.51 1.2693e+05,628.86 1.2693e+05,616 1.2693e+05,616 1.2693e+05,616 84046,616 84046,616 84046,616 84046,\
560.23 84046,560.23"];
	kv_sync_1 -> kv_cache_1_2_16	[pos="e,82996,550.24 1.2688e+05,640.9 1.2688e+05,629.91 1.2688e+05,618 1.2688e+05,618 1.2688e+05,618 82996,618 82996,618 82996,618 82996,\
560.24 82996,560.24"];
	kv_sync_1 -> kv_cache_1_3_16	[pos="e,81946,550.03 1.2684e+05,640.87 1.2684e+05,630.29 1.2684e+05,619 1.2684e+05,619 1.2684e+05,619 81946,619 81946,619 81946,619 81946,\
560.03 81946,560.03"];
	kv_sync_1 -> kv_cache_1_4_16	[pos="e,80896,550.23 1.268e+05,640.87 1.268e+05,630.69 1.268e+05,620 1.268e+05,620 1.268e+05,620 80896,620 80896,620 80896,620 80896,560.23 \
80896,560.23"];
	kv_sync_1 -> kv_cache_1_5_16	[pos="e,79846,550.21 1.2675e+05,640.93 1.2675e+05,631.54 1.2675e+05,622 1.2675e+05,622 1.2675e+05,622 79846,622 79846,622 79846,622 79846,\
560.21 79846,560.21"];
	kv_sync_1 -> kv_cache_1_6_16	[pos="e,78796,550.42 1.2671e+05,641 1.2671e+05,632 1.2671e+05,623 1.2671e+05,623 1.2671e+05,623 78796,623 78796,623 78796,623 78796,560.42 \
78796,560.42"];
	kv_sync_1 -> kv_cache_1_7_16	[pos="e,77746,550.18 1.2667e+05,640.68 1.2667e+05,632.21 1.2667e+05,624 1.2667e+05,624 1.2667e+05,624 77746,624 77746,624 77746,624 77746,\
560.18 77746,560.18"];
	kv_sync_1 -> kv_cache_1_8_16	[pos="e,76696,550.07 1.2673e+05,659.1 1.2673e+05,661.21 1.2673e+05,695 1.2673e+05,695 1.2673e+05,695 76696,695 76696,695 76696,695 76696,\
560.07 76696,560.07"];
	kv_sync_1 -> kv_cache_1_9_16	[pos="e,75646,550.18 1.2684e+05,676.2 1.2684e+05,685.86 1.2684e+05,696 1.2684e+05,696 1.2684e+05,696 75646,696 75646,696 75646,696 75646,\
560.18 75646,560.18"];
	kv_sync_1 -> kv_cache_1_10_16	[pos="e,91860,532 1.2722e+05,640.99 1.2722e+05,624.95 1.2722e+05,604 1.2722e+05,604 1.2722e+05,604 91978,604 91978,604 91978,604 91978,\
532 91978,532 91978,532 91870,532 91870,532"];
	kv_sync_1 -> kv_cache_1_11_16	[pos="e,90801,532 1.2718e+05,640.81 1.2718e+05,625.82 1.2718e+05,607 1.2718e+05,607 1.2718e+05,607 90916,607 90916,607 90916,607 90916,\
532 90916,532 90916,532 90811,532 90811,532"];
	kv_sync_1 -> kv_cache_1_12_16	[pos="e,89742,532 1.2714e+05,640.75 1.2714e+05,626.82 1.2714e+05,610 1.2714e+05,610 1.2714e+05,610 89858,610 89858,610 89858,610 89858,\
532 89858,532 89858,532 89752,532 89752,532"];
	kv_sync_1 -> kv_cache_1_13_16	[pos="e,88683,532 1.271e+05,640.85 1.271e+05,627.26 1.271e+05,611 1.271e+05,611 1.271e+05,611 88798,611 88798,611 88798,611 88798,532 \
88798,532 88798,532 88693,532 88693,532"];
	kv_sync_1 -> kv_cache_1_14_16	[pos="e,87624,532 1.2705e+05,640.96 1.2705e+05,627.71 1.2705e+05,612 1.2705e+05,612 1.2705e+05,612 87740,612 87740,612 87740,612 87740,\
532 87740,532 87740,532 87634,532 87634,532"];
	kv_sync_1 -> kv_cache_1_15_16	[pos="e,86565,532 1.2701e+05,640.96 1.2701e+05,628.44 1.2701e+05,614 1.2701e+05,614 1.2701e+05,614 86680,614 86680,614 86680,614 86680,\
532 86680,532 86680,532 86575,532 86575,532"];
	kv_sync_1 -> kv_cache_1_0_24	[pos="e,2.2104e+05,550.11 1.2767e+05,675 1.3514e+05,675 2.2104e+05,675 2.2104e+05,675 2.2104e+05,675 2.2104e+05,560.11 2.2104e+05,560.11"];
	kv_sync_1 -> kv_cache_1_1_24	[pos="e,2.1999e+05,550.14 1.2766e+05,673 1.3501e+05,673 2.1999e+05,673 2.1999e+05,673 2.1999e+05,673 2.1999e+05,560.14 2.1999e+05,560.14"];
	kv_sync_1 -> kv_cache_1_2_24	[pos="e,2.1894e+05,550.17 1.2765e+05,671 1.3487e+05,671 2.1894e+05,671 2.1894e+05,671 2.1894e+05,671 2.1894e+05,560.17 2.1894e+05,560.17"];
	kv_sync_1 -> kv_cache_1_3_24	[pos="e,2.1789e+05,550.19 1.2764e+05,669 1.3473e+05,669 2.1789e+05,669 2.1789e+05,669 2.1789e+05,669 2.1789e+05,560.19 2.1789e+05,560.19"];
	kv_sync_1 -> kv_cache_1_4_24	[pos="e,2.1684e+05,550.21 1.2763e+05,667 1.3459e+05,667 2.1684e+05,667 2.1684e+05,667 2.1684e+05,667 2.1684e+05,560.21 2.1684e+05,560.21"];
	kv_sync_1 -> kv_cache_1_5_24	[pos="e,2.1579e+05,550.21 1.2761e+05,665 1.3445e+05,665 2.1579e+05,665 2.1579e+05,665 2.1579e+05,665 2.1579e+05,560.21 2.1579e+05,560.21"];
	kv_sync_1 -> kv_cache_1_6_24	[pos="e,2.1474e+05,550.21 1.276e+05,663 1.3432e+05,663 2.1474e+05,663 2.1474e+05,663 2.1474e+05,663 2.1474e+05,560.21 2.1474e+05,560.21"];
	kv_sync_1 -> kv_cache_1_7_24	[pos="e,2.1369e+05,550.21 1.2759e+05,661 1.3418e+05,661 2.1369e+05,661 2.1369e+05,661 2.1369e+05,661 2.1369e+05,560.21 2.1369e+05,560.21"];
	kv_sync_1 -> kv_cache_1_8_24	[pos="e,2.1264e+05,550.2 1.2758e+05,659 1.3404e+05,659 2.1264e+05,659 2.1264e+05,659 2.1264e+05,659 2.1264e+05,560.2 2.1264e+05,560.2"];
	kv_sync_1 -> kv_cache_1_9_24	[pos="e,2.1159e+05,550.18 1.2757e+05,657 1.339e+05,657 2.1159e+05,657 2.1159e+05,657 2.1159e+05,657 2.1159e+05,560.18 2.1159e+05,560.18"];
	kv_sync_1 -> kv_cache_1_10_24	[pos="e,2.1054e+05,550.15 1.2755e+05,655 1.3376e+05,655 2.1054e+05,655 2.1054e+05,655 2.1054e+05,655 2.1054e+05,560.15 2.1054e+05,560.15"];
	kv_sync_1 -> kv_cache_1_11_24	[pos="e,2.0948e+05,550.11 1.2754e+05,653 1.3361e+05,653 2.0948e+05,653 2.0948e+05,653 2.0948e+05,653 2.0948e+05,560.11 2.0948e+05,560.11"];
	kv_sync_1 -> kv_cache_1_12_24	[pos="e,2.0842e+05,550.07 1.2753e+05,651 1.3347e+05,651 2.0842e+05,651 2.0842e+05,651 2.0842e+05,651 2.0842e+05,560.07 2.0842e+05,560.07"];
	kv_sync_1 -> kv_cache_1_13_24	[pos="e,2.0736e+05,550.02 1.2752e+05,649 1.3333e+05,649 2.0736e+05,649 2.0736e+05,649 2.0736e+05,649 2.0736e+05,560.02 2.0736e+05,560.02"];
	kv_sync_1 -> kv_cache_1_14_24	[pos="e,2.063e+05,550.22 1.275e+05,647 1.3318e+05,647 2.063e+05,647 2.063e+05,647 2.063e+05,647 2.063e+05,560.22 2.063e+05,560.22"];
	kv_sync_1 -> kv_cache_1_15_24	[pos="e,2.0524e+05,550.16 1.2749e+05,645 1.3304e+05,645 2.0524e+05,645 2.0524e+05,645 2.0524e+05,645 2.0524e+05,560.16 2.0524e+05,560.16"];
	kv_sync_1 -> kv_cache_1_16_24	[pos="e,2.0418e+05,550.33 1.2748e+05,643 1.329e+05,643 2.0418e+05,643 2.0418e+05,643 2.0418e+05,643 2.0418e+05,560.33 2.0418e+05,560.33"];
	kv_sync_1 -> kv_cache_1_17_24	[pos="e,2.0271e+05,532 1.2758e+05,677.11 1.2758e+05,686.9 1.2758e+05,697 1.2758e+05,697 1.2758e+05,697 2.0259e+05,697 2.0259e+05,697 2.0259e+\
05,697 2.0259e+05,532 2.0259e+05,532 2.0259e+05,532 2.027e+05,532 2.027e+05,532"];
	kv_sync_1 -> kv_cache_1_18_24	[pos="e,2.2698e+05,532 1.2694e+05,677.15 1.2694e+05,689.27 1.2694e+05,703 1.2694e+05,703 1.2694e+05,703 2.2686e+05,703 2.2686e+05,703 \
2.2686e+05,703 2.2686e+05,532 2.2686e+05,532 2.2686e+05,532 2.2697e+05,532 2.2697e+05,532"];
	kv_sync_1 -> kv_cache_1_19_24	[pos="e,2.2592e+05,532 1.2705e+05,677.49 1.2705e+05,689.14 1.2705e+05,702 1.2705e+05,702 1.2705e+05,702 2.2581e+05,702 2.2581e+05,702 \
2.2581e+05,702 2.2581e+05,532 2.2581e+05,532 2.2581e+05,532 2.2591e+05,532 2.2591e+05,532"];
	kv_sync_1 -> kv_cache_1_20_24	[pos="e,2.2486e+05,532 1.2716e+05,677.06 1.2716e+05,688.44 1.2716e+05,701 1.2716e+05,701 1.2716e+05,701 2.2475e+05,701 2.2475e+05,701 \
2.2475e+05,701 2.2475e+05,532 2.2475e+05,532 2.2475e+05,532 2.2485e+05,532 2.2485e+05,532"];
	kv_sync_1 -> kv_cache_1_21_24	[pos="e,2.238e+05,532 1.2726e+05,677.1 1.2726e+05,688.09 1.2726e+05,700 1.2726e+05,700 1.2726e+05,700 2.2369e+05,700 2.2369e+05,700 2.2369e+\
05,700 2.2369e+05,532 2.2369e+05,532 2.2369e+05,532 2.2379e+05,532 2.2379e+05,532"];
	kv_sync_1 -> kv_cache_1_22_24	[pos="e,2.2274e+05,532 1.2737e+05,677.13 1.2737e+05,687.71 1.2737e+05,699 1.2737e+05,699 1.2737e+05,699 2.2263e+05,699 2.2263e+05,699 \
2.2263e+05,699 2.2263e+05,532 2.2263e+05,532 2.2263e+05,532 2.2273e+05,532 2.2273e+05,532"];
	kv_sync_1 -> kv_cache_1_23_24	[pos="e,2.2168e+05,532 1.2747e+05,677.13 1.2747e+05,687.31 1.2747e+05,698 1.2747e+05,698 1.2747e+05,698 2.2157e+05,698 2.2157e+05,698 \
2.2157e+05,698 2.2157e+05,532 2.2157e+05,532 2.2157e+05,532 2.2167e+05,532 2.2167e+05,532"];
	kv_sync_2 -> kv_cache_2_0_8	[pos="e,1.1135e+05,550.08 1.1726e+05,664 1.1588e+05,664 1.1135e+05,664 1.1135e+05,664 1.1135e+05,664 1.1135e+05,560.08 1.1135e+05,560.08"];
	kv_sync_2 -> kv_cache_2_1_8	[pos="e,1.103e+05,550.07 1.1727e+05,666 1.1576e+05,666 1.103e+05,666 1.103e+05,666 1.103e+05,666 1.103e+05,560.07 1.103e+05,560.07"];
	kv_sync_2 -> kv_cache_2_2_8	[pos="e,1.1782e+05,550.16 1.1782e+05,640.8 1.1782e+05,640.8 1.1782e+05,560.16 1.1782e+05,560.16"];
	kv_sync_2 -> kv_cache_2_3_8	[pos="e,1.1701e+05,532 1.1713e+05,658.91 1.1713e+05,655.06 1.1713e+05,532 1.1713e+05,532 1.1713e+05,532 1.1702e+05,532 1.1702e+05,532"];
	kv_sync_2 -> kv_cache_2_4_8	[pos="e,1.1572e+05,550.11 1.1719e+05,653 1.1662e+05,653 1.1572e+05,653 1.1572e+05,653 1.1572e+05,653 1.1572e+05,560.11 1.1572e+05,560.11"];
	kv_sync_2 -> kv_cache_2_5_8	[pos="e,1.145e+05,550.2 1.1723e+05,659 1.1637e+05,659 1.145e+05,659 1.145e+05,659 1.145e+05,659 1.145e+05,560.2 1.145e+05,560.2"];
	kv_sync_2 -> kv_cache_2_6_8	[pos="e,1.1345e+05,550.07 1.1723e+05,660 1.1617e+05,660 1.1345e+05,660 1.1345e+05,660 1.1345e+05,660 1.1345e+05,560.07 1.1345e+05,560.07"];
	kv_sync_2 -> kv_cache_2_7_8	[pos="e,1.124e+05,550.08 1.1725e+05,662 1.1602e+05,662 1.124e+05,662 1.124e+05,662 1.124e+05,662 1.124e+05,560.08 1.124e+05,560.08"];
	kv_sync_2 -> kv_cache_2_0_16	[pos="e,34791,513.79 1.1718e+05,651 1.1671e+05,651 1.1607e+05,651 1.1607e+05,651 1.1607e+05,651 1.1607e+05,504 1.1607e+05,504 1.1607e+\
05,504 34791,504 34791,504 34791,504 34791,504.98 34791,504.98"];
	kv_sync_2 -> kv_cache_2_1_16	[pos="e,33756,513.94 1.1721e+05,657 1.1647e+05,657 1.1502e+05,657 1.1502e+05,657 1.1502e+05,657 1.1502e+05,506 1.1502e+05,506 1.1502e+\
05,506 33756,506 33756,506 33756,506 33756,506.79 33756,506.79"];
	kv_sync_2 -> kv_cache_2_2_16	[pos="e,32677,513.85 1.173e+05,671 1.1577e+05,671 1.0976e+05,671 1.0976e+05,671 1.0976e+05,671 1.0976e+05,512 1.0976e+05,512 1.0976e+05,\
512 32677,512 32677,512 32677,512 32677,512.18 32677,512.18"];
	kv_sync_2 -> kv_cache_2_3_16	[pos="e,31366,550.34 1.1712e+05,642 1.1702e+05,642 1.1694e+05,642 1.1694e+05,642 1.1694e+05,642 1.1694e+05,632 1.1694e+05,632 1.1694e+\
05,632 31366,632 31366,632 31366,632 31366,560.34 31366,560.34"];
	kv_sync_2 -> kv_cache_2_4_16	[pos="e,30568,513.83 1.1729e+05,669 1.1574e+05,669 1.0977e+05,669 1.0977e+05,669 1.0977e+05,669 1.0977e+05,510 1.0977e+05,510 1.0977e+\
05,510 30568,510 30568,510 30568,510 30568,510.38 30568,510.38"];
	kv_sync_2 -> kv_cache_2_5_16	[pos="e,29522,513.81 1.1728e+05,668 1.1573e+05,668 1.0978e+05,668 1.0978e+05,668 1.0978e+05,668 1.0978e+05,508 1.0978e+05,508 1.0978e+\
05,508 29522,508 29522,508 29522,508 29522,508.58 29522,508.58"];
	kv_sync_2 -> kv_cache_2_6_16	[pos="e,28216,550.24 1.1714e+05,644 1.1694e+05,644 1.1677e+05,644 1.1677e+05,644 1.1677e+05,644 1.1677e+05,634 1.1677e+05,634 1.1677e+\
05,634 28216,634 28216,634 28216,634 28216,560.24 28216,560.24"];
	kv_sync_2 -> kv_cache_2_7_16	[pos="e,27166,550.41 1.1715e+05,646 1.1688e+05,646 1.166e+05,646 1.166e+05,646 1.166e+05,646 1.166e+05,635 1.166e+05,635 1.166e+05,635 \
27166,635 27166,635 27166,635 27166,560.41 27166,560.41"];
	kv_sync_2 -> kv_cache_2_8_16	[pos="e,26116,550.12 1.1716e+05,648 1.1682e+05,648 1.1643e+05,648 1.1643e+05,648 1.1643e+05,648 1.1643e+05,636 1.1643e+05,636 1.1643e+\
05,636 26116,636 26116,636 26116,636 26116,560.12 26116,560.12"];
	kv_sync_2 -> kv_cache_2_9_16	[pos="e,25066,550.46 1.1717e+05,650 1.1677e+05,650 1.1625e+05,650 1.1625e+05,650 1.1625e+05,650 1.1625e+05,638 1.1625e+05,638 1.1625e+\
05,638 25066,638 25066,638 25066,638 25066,560.46 25066,560.46"];
	kv_sync_2 -> kv_cache_2_10_16	[pos="e,41280,532 1.172e+05,655 1.1654e+05,655 1.1538e+05,655 1.1538e+05,655 1.1538e+05,655 1.1538e+05,639 1.1538e+05,639 1.1538e+05,639 \
41398,639 41398,639 41398,639 41398,532 41398,532 41398,532 41290,532 41290,532"];
	kv_sync_2 -> kv_cache_2_11_16	[pos="e,40221,532 1.1771e+05,640.96 1.1771e+05,633.25 1.1771e+05,626 1.1771e+05,626 1.1771e+05,626 40336,626 40336,626 40336,626 40336,\
532 40336,532 40336,532 40231,532 40231,532"];
	kv_sync_2 -> kv_cache_2_12_16	[pos="e,39162,532 1.1759e+05,640.76 1.1759e+05,633.57 1.1759e+05,627 1.1759e+05,627 1.1759e+05,627 39278,627 39278,627 39278,627 39278,\
532 39278,532 39278,532 39172,532 39172,532"];
	kv_sync_2 -> kv_cache_2_13_16	[pos="e,38103,532 1.1748e+05,640.97 1.1748e+05,634.15 1.1748e+05,628 1.1748e+05,628 1.1748e+05,628 38218,628 38218,628 38218,628 38218,\
532 38218,532 38218,532 38113,532 38113,532"];
	kv_sync_2 -> kv_cache_2_14_16	[pos="e,37044,532 1.1736e+05,640.8 1.1736e+05,634.97 1.1736e+05,630 1.1736e+05,630 1.1736e+05,630 37160,630 37160,630 37160,630 37160,\
532 37160,532 37160,532 37054,532 37054,532"];
	kv_sync_2 -> kv_cache_2_15_16	[pos="e,35985,532 1.1725e+05,640.79 1.1725e+05,635.45 1.1725e+05,631 1.1725e+05,631 1.1725e+05,631 36100,631 36100,631 36100,631 36100,\
532 36100,532 36100,532 35995,532 35995,532"];
	kv_sync_2 -> kv_cache_2_0_24	[pos="e,1.4505e+05,550.06 1.1803e+05,652 1.1833e+05,652 1.187e+05,652 1.187e+05,652 1.187e+05,652 1.187e+05,574 1.187e+05,574 1.187e+05,\
574 1.4505e+05,574 1.4505e+05,574 1.4505e+05,574 1.4505e+05,560.06 1.4505e+05,560.06"];
	kv_sync_2 -> kv_cache_2_1_24	[pos="e,1.4353e+05,531.89 1.1809e+05,662 1.1883e+05,662 1.2027e+05,662 1.2027e+05,662 1.2027e+05,662 1.2027e+05,386 1.2027e+05,386 1.2027e+\
05,386 1.4353e+05,386 1.4353e+05,386 1.4353e+05,386 1.4353e+05,521.89 1.4353e+05,521.89"];
	kv_sync_2 -> kv_cache_2_2_24	[pos="e,1.4257e+05,513.93 1.1809e+05,663 1.1884e+05,663 1.2028e+05,663 1.2028e+05,663 1.2028e+05,663 1.2028e+05,387 1.2028e+05,387 1.2028e+\
05,387 1.4257e+05,387 1.4257e+05,387 1.4257e+05,387 1.4257e+05,503.93 1.4257e+05,503.93"];
	kv_sync_2 -> kv_cache_2_3_24	[pos="e,1.419e+05,550.32 1.1802e+05,651 1.1829e+05,651 1.186e+05,651 1.186e+05,651 1.186e+05,651 1.186e+05,567 1.186e+05,567 1.186e+05,\
567 1.419e+05,567 1.419e+05,567 1.419e+05,567 1.419e+05,560.32 1.419e+05,560.32"];
	kv_sync_2 -> kv_cache_2_4_24	[pos="e,1.4085e+05,550.24 1.1801e+05,650 1.1824e+05,650 1.185e+05,650 1.185e+05,650 1.185e+05,650 1.185e+05,564 1.185e+05,564 1.185e+05,\
564 1.4085e+05,564 1.4085e+05,564 1.4085e+05,564 1.4085e+05,560.24 1.4085e+05,560.24"];
	kv_sync_2 -> kv_cache_2_5_24	[pos="e,1.3943e+05,513.89 1.181e+05,664 1.1885e+05,664 1.2028e+05,664 1.2028e+05,664 1.2028e+05,664 1.2028e+05,389 1.2028e+05,389 1.2028e+\
05,389 1.3943e+05,389 1.3943e+05,389 1.3943e+05,389 1.3943e+05,503.89 1.3943e+05,503.89"];
	kv_sync_2 -> kv_cache_2_6_24	[pos="e,1.3875e+05,550.21 1.1801e+05,649 1.182e+05,649 1.1839e+05,649 1.1839e+05,649 1.1839e+05,649 1.1839e+05,560 1.1839e+05,560 1.1839e+\
05,560 1.3875e+05,560 1.3875e+05,560 1.3875e+05,560 1.3875e+05,559.02 1.3875e+05,559.02"];
	kv_sync_2 -> kv_cache_2_7_24	[pos="e,1.377e+05,550.06 1.18e+05,648 1.1815e+05,648 1.1829e+05,648 1.1829e+05,648 1.1829e+05,648 1.1829e+05,558 1.1829e+05,558 1.1829e+\
05,558 1.377e+05,558 1.377e+05,558 1.377e+05,558 1.377e+05,557.21 1.377e+05,557.21"];
	kv_sync_2 -> kv_cache_2_8_24	[pos="e,1.3618e+05,531.88 1.1805e+05,656 1.1852e+05,656 1.1922e+05,656 1.1922e+05,656 1.1922e+05,656 1.1922e+05,491 1.1922e+05,491 1.1922e+\
05,491 1.3618e+05,491 1.3618e+05,491 1.3618e+05,491 1.3618e+05,521.88 1.3618e+05,521.88"];
	kv_sync_2 -> kv_cache_2_9_24	[pos="e,1.3512e+05,531.89 1.1806e+05,657 1.1852e+05,657 1.1923e+05,657 1.1923e+05,657 1.1923e+05,657 1.1923e+05,493 1.1923e+05,493 1.1923e+\
05,493 1.3512e+05,493 1.3512e+05,493 1.3512e+05,493 1.3512e+05,521.89 1.3512e+05,521.89"];
	kv_sync_2 -> kv_cache_2_10_24	[pos="e,1.3406e+05,531.89 1.1806e+05,658 1.1853e+05,658 1.1923e+05,658 1.1923e+05,658 1.1923e+05,658 1.1923e+05,494 1.1923e+05,494 1.1923e+\
05,494 1.3406e+05,494 1.3406e+05,494 1.3406e+05,494 1.3406e+05,521.89 1.3406e+05,521.89"];
	kv_sync_2 -> kv_cache_2_11_24	[pos="e,1.3299e+05,531.9 1.1807e+05,659 1.1854e+05,659 1.1923e+05,659 1.1923e+05,659 1.1923e+05,659 1.1923e+05,496 1.1923e+05,496 1.1923e+\
05,496 1.3299e+05,496 1.3299e+05,496 1.3299e+05,496 1.3299e+05,521.9 1.3299e+05,521.9"];
	kv_sync_2 -> kv_cache_2_12_24	[pos="e,1.3193e+05,513.81 1.1808e+05,660 1.1855e+05,660 1.1923e+05,660 1.1923e+05,660 1.1923e+05,660 1.1923e+05,498 1.1923e+05,498 1.1923e+\
05,498 1.3193e+05,498 1.3193e+05,498 1.3193e+05,498 1.3193e+05,503.81 1.3193e+05,503.81"];
	kv_sync_2 -> kv_cache_2_13_24	[pos="e,1.3087e+05,531.87 1.1817e+05,658.87 1.1817e+05,653.6 1.1817e+05,485 1.1817e+05,485 1.1817e+05,485 1.3087e+05,485 1.3087e+05,485 \
1.3087e+05,485 1.3087e+05,521.87 1.3087e+05,521.87"];
	kv_sync_2 -> kv_cache_2_14_24	[pos="e,1.2981e+05,531.87 1.1817e+05,658.88 1.1817e+05,653.67 1.1817e+05,487 1.1817e+05,487 1.1817e+05,487 1.2981e+05,487 1.2981e+05,487 \
1.2981e+05,487 1.2981e+05,521.87 1.2981e+05,521.87"];
	kv_sync_2 -> kv_cache_2_15_24	[pos="e,1.2875e+05,531.88 1.1817e+05,658.88 1.1817e+05,653.73 1.1817e+05,489 1.1817e+05,489 1.1817e+05,489 1.2875e+05,489 1.2875e+05,489 \
1.2875e+05,489 1.2875e+05,521.88 1.2875e+05,521.88"];
	kv_sync_2 -> kv_cache_2_16_24	[pos="e,1.2768e+05,532.06 1.1817e+05,658.92 1.1817e+05,655.68 1.1817e+05,552 1.1817e+05,552 1.1817e+05,552 1.2768e+05,552 1.2768e+05,552 \
1.2768e+05,552 1.2768e+05,542.06 1.2768e+05,542.06"];
	kv_sync_2 -> kv_cache_2_17_24	[pos="e,1.2663e+05,532.05 1.1817e+05,658.92 1.1817e+05,655.65 1.1817e+05,551 1.1817e+05,551 1.1817e+05,551 1.2663e+05,551 1.2663e+05,551 \
1.2663e+05,551 1.2663e+05,542.05 1.2663e+05,542.05"];
	kv_sync_2 -> kv_cache_2_18_24	[pos="e,1.5098e+05,532 1.1805e+05,655.69 1.1805e+05,640.95 1.1805e+05,582 1.1805e+05,582 1.1805e+05,582 1.5087e+05,582 1.5087e+05,582 \
1.5087e+05,582 1.5087e+05,532 1.5087e+05,532 1.5087e+05,532 1.5097e+05,532 1.5097e+05,532"];
	kv_sync_2 -> kv_cache_2_19_24	[pos="e,1.4993e+05,532 1.1793e+05,640.68 1.1793e+05,617.34 1.1793e+05,580 1.1793e+05,580 1.1793e+05,580 1.4981e+05,580 1.4981e+05,580 \
1.4981e+05,580 1.4981e+05,532 1.4981e+05,532 1.4981e+05,532 1.4992e+05,532 1.4992e+05,532"];
	kv_sync_2 -> kv_cache_2_20_24	[pos="e,1.4887e+05,532 1.1808e+05,661 1.187e+05,661 1.1975e+05,661 1.1975e+05,661 1.1975e+05,661 1.1975e+05,579 1.1975e+05,579 1.1975e+\
05,579 1.4875e+05,579 1.4875e+05,579 1.4875e+05,579 1.4875e+05,532 1.4875e+05,532 1.4875e+05,532 1.4886e+05,532 1.4886e+05,532"];
	kv_sync_2 -> kv_cache_2_21_24	[pos="e,1.4781e+05,532 1.1804e+05,655 1.1845e+05,655 1.1901e+05,655 1.1901e+05,655 1.1901e+05,655 1.1901e+05,578 1.1901e+05,578 1.1901e+\
05,578 1.4769e+05,578 1.4769e+05,578 1.4769e+05,578 1.4769e+05,532 1.4769e+05,532 1.4769e+05,532 1.478e+05,532 1.478e+05,532"];
	kv_sync_2 -> kv_cache_2_22_24	[pos="e,1.4675e+05,532 1.1804e+05,654 1.1841e+05,654 1.1891e+05,654 1.1891e+05,654 1.1891e+05,654 1.1891e+05,576 1.1891e+05,576 1.1891e+\
05,576 1.4663e+05,576 1.4663e+05,576 1.4663e+05,576 1.4663e+05,532 1.4663e+05,532 1.4663e+05,532 1.4674e+05,532 1.4674e+05,532"];
	kv_sync_2 -> kv_cache_2_23_24	[pos="e,1.4569e+05,532 1.1803e+05,653 1.1837e+05,653 1.1881e+05,653 1.1881e+05,653 1.1881e+05,653 1.1881e+05,575 1.1881e+05,575 1.1881e+\
05,575 1.4557e+05,575 1.4557e+05,575 1.4557e+05,575 1.4557e+05,532 1.4557e+05,532 1.4557e+05,532 1.4568e+05,532 1.4568e+05,532"];
	kv_sync_3 -> kv_cache_3_0_8	[pos="e,1.2001e+05,550.16 1.245e+05,645 1.2323e+05,645 1.2001e+05,645 1.2001e+05,645 1.2001e+05,645 1.2001e+05,560.16 1.2001e+05,560.16"];
	kv_sync_3 -> kv_cache_3_1_8	[pos="e,1.1912e+05,550.22 1.2451e+05,647 1.2309e+05,647 1.1912e+05,647 1.1912e+05,647 1.1912e+05,647 1.1912e+05,560.22 1.1912e+05,560.22"];
	kv_sync_3 -> kv_cache_3_2_8	[pos="e,1.2564e+05,532 1.2553e+05,658.91 1.2553e+05,655.06 1.2553e+05,532 1.2553e+05,532 1.2553e+05,532 1.2563e+05,532 1.2563e+05,532"];
	kv_sync_3 -> kv_cache_3_3_8	[pos="e,1.2457e+05,532.05 1.2457e+05,640.8 1.2457e+05,640.8 1.2457e+05,542.05 1.2457e+05,542.05"];
	kv_sync_3 -> kv_cache_3_4_8	[pos="e,1.2436e+05,532 1.2448e+05,658.91 1.2448e+05,655.06 1.2448e+05,532 1.2448e+05,532 1.2448e+05,532 1.2437e+05,532 1.2437e+05,532"];
	kv_sync_3 -> kv_cache_3_5_8	[pos="e,1.2308e+05,550.16 1.2448e+05,642 1.2391e+05,642 1.2308e+05,642 1.2308e+05,642 1.2308e+05,642 1.2308e+05,560.16 1.2308e+05,560.16"];
	kv_sync_3 -> kv_cache_3_6_8	[pos="e,1.2185e+05,550.33 1.2449e+05,643 1.2359e+05,643 1.2185e+05,643 1.2185e+05,643 1.2185e+05,643 1.2185e+05,560.33 1.2185e+05,560.33"];
	kv_sync_3 -> kv_cache_3_7_8	[pos="e,1.208e+05,550.49 1.2449e+05,644 1.2337e+05,644 1.208e+05,644 1.208e+05,644 1.208e+05,644 1.208e+05,560.49 1.208e+05,560.49"];
	kv_sync_3 -> kv_cache_3_0_16	[pos="e,51376,550.08 1.2463e+05,667 1.2419e+05,667 1.2353e+05,667 1.2353e+05,667 1.2353e+05,667 1.2353e+05,704 1.2353e+05,704 1.2353e+\
05,704 51376,704 51376,704 51376,704 51376,560.08 51376,560.08"];
	kv_sync_3 -> kv_cache_3_1_16	[pos="e,50326,550.08 1.2464e+05,668 1.2423e+05,668 1.2363e+05,668 1.2363e+05,668 1.2363e+05,668 1.2363e+05,704 1.2363e+05,704 1.2363e+\
05,704 50326,704 50326,704 50326,704 50326,560.08 50326,560.08"];
	kv_sync_3 -> kv_cache_3_2_16	[pos="e,49276,550.19 1.2464e+05,669 1.2426e+05,669 1.2372e+05,669 1.2372e+05,669 1.2372e+05,669 1.2372e+05,705 1.2372e+05,705 1.2372e+\
05,705 49276,705 49276,705 49276,705 49276,560.19 49276,560.19"];
	kv_sync_3 -> kv_cache_3_3_16	[pos="e,48226,550.29 1.2465e+05,670 1.243e+05,670 1.2381e+05,670 1.2381e+05,670 1.2381e+05,670 1.2381e+05,706 1.2381e+05,706 1.2381e+05,\
706 48226,706 48226,706 48226,706 48226,560.29 48226,560.29"];
	kv_sync_3 -> kv_cache_3_4_16	[pos="e,47176,550.07 1.2466e+05,671 1.2433e+05,671 1.2391e+05,671 1.2391e+05,671 1.2391e+05,671 1.2391e+05,707 1.2391e+05,707 1.2391e+\
05,707 47176,707 47176,707 47176,707 47176,560.07 47176,560.07"];
	kv_sync_3 -> kv_cache_3_5_16	[pos="e,46126,550.17 1.2466e+05,672 1.2437e+05,672 1.24e+05,672 1.24e+05,672 1.24e+05,672 1.24e+05,708 1.24e+05,708 1.24e+05,708 46126,\
708 46126,708 46126,708 46126,560.17 46126,560.17"];
	kv_sync_3 -> kv_cache_3_6_16	[pos="e,45076,550.28 1.2456e+05,659.14 1.2456e+05,662.08 1.2456e+05,709 1.2456e+05,709 1.2456e+05,709 45076,709 45076,709 45076,709 45076,\
560.28 45076,560.28"];
	kv_sync_3 -> kv_cache_3_7_16	[pos="e,44026,550.05 1.2464e+05,668.35 1.2464e+05,683.08 1.2464e+05,710 1.2464e+05,710 1.2464e+05,710 44026,710 44026,710 44026,710 44026,\
560.05 44026,560.05"];
	kv_sync_3 -> kv_cache_3_8_16	[pos="e,42976,550.15 1.2472e+05,677.19 1.2472e+05,692.18 1.2472e+05,711 1.2472e+05,711 1.2472e+05,711 42976,711 42976,711 42976,711 42976,\
560.15 42976,560.15"];
	kv_sync_3 -> kv_cache_3_9_16	[pos="e,41926,550.25 1.248e+05,677.24 1.248e+05,692.57 1.248e+05,712 1.248e+05,712 1.248e+05,712 41926,712 41926,712 41926,712 41926,560.25 \
41926,560.25"];
	kv_sync_3 -> kv_cache_3_10_16	[pos="e,58140,532 1.2462e+05,666 1.2416e+05,666 1.2343e+05,666 1.2343e+05,666 1.2343e+05,666 1.2343e+05,740 1.2343e+05,740 1.2343e+05,\
740 58258,740 58258,740 58258,740 58258,532 58258,532 58258,532 58150,532 58150,532"];
	kv_sync_3 -> kv_cache_3_11_16	[pos="e,57081,532 1.2467e+05,673 1.2441e+05,673 1.2409e+05,673 1.2409e+05,673 1.2409e+05,673 1.2409e+05,742 1.2409e+05,742 1.2409e+05,\
742 57196,742 57196,742 57196,742 57196,532 57196,532 57196,532 57091,532 57091,532"];
	kv_sync_3 -> kv_cache_3_12_16	[pos="e,56022,532 1.2467e+05,674 1.2445e+05,674 1.2419e+05,674 1.2419e+05,674 1.2419e+05,674 1.2419e+05,743 1.2419e+05,743 1.2419e+05,\
743 56138,743 56138,743 56138,743 56138,532 56138,532 56138,532 56032,532 56032,532"];
	kv_sync_3 -> kv_cache_3_13_16	[pos="e,54963,532 1.2468e+05,675 1.2449e+05,675 1.2428e+05,675 1.2428e+05,675 1.2428e+05,675 1.2428e+05,744 1.2428e+05,744 1.2428e+05,\
744 55078,744 55078,744 55078,744 55078,532 55078,532 55078,532 54973,532 54973,532"];
	kv_sync_3 -> kv_cache_3_14_16	[pos="e,53788,550.16 1.2469e+05,676 1.2453e+05,676 1.2438e+05,676 1.2438e+05,676 1.2438e+05,676 1.2438e+05,745 1.2438e+05,745 1.2438e+\
05,745 53788,745 53788,745 53788,745 53788,560.16 53788,560.16"];
	kv_sync_3 -> kv_cache_3_15_16	[pos="e,52363,550.25 1.2462e+05,665 1.2397e+05,665 1.2273e+05,665 1.2273e+05,665 1.2273e+05,665 1.2273e+05,746 1.2273e+05,746 1.2273e+\
05,746 52363,746 52363,746 52363,746 52363,560.25 52363,560.25"];
	kv_sync_3 -> kv_cache_3_0_24	[pos="e,1.7038e+05,550.27 1.2537e+05,677.16 1.2537e+05,682.04 1.2537e+05,686 1.2537e+05,686 1.2537e+05,686 1.7038e+05,686 1.7038e+05,686 \
1.7038e+05,686 1.7038e+05,560.27 1.7038e+05,560.27"];
	kv_sync_3 -> kv_cache_3_1_24	[pos="e,1.6933e+05,550.27 1.2545e+05,677.16 1.2545e+05,682.04 1.2545e+05,686 1.2545e+05,686 1.2545e+05,686 1.6933e+05,686 1.6933e+05,686 \
1.6933e+05,686 1.6933e+05,560.27 1.6933e+05,560.27"];
	kv_sync_3 -> kv_cache_3_2_24	[pos="e,1.6828e+05,550.15 1.255e+05,671 1.2552e+05,671 1.2554e+05,671 1.2554e+05,671 1.2554e+05,671 1.2554e+05,685 1.2554e+05,685 1.2554e+\
05,685 1.6828e+05,685 1.6828e+05,685 1.6828e+05,685 1.6828e+05,560.15 1.6828e+05,560.15"];
	kv_sync_3 -> kv_cache_3_3_24	[pos="e,1.6723e+05,550.03 1.2547e+05,666 1.2551e+05,666 1.2554e+05,666 1.2554e+05,666 1.2554e+05,666 1.2554e+05,684 1.2554e+05,684 1.2554e+\
05,684 1.6723e+05,684 1.6723e+05,684 1.6723e+05,684 1.6723e+05,560.03 1.6723e+05,560.03"];
	kv_sync_3 -> kv_cache_3_4_24	[pos="e,1.6618e+05,550.21 1.2544e+05,661 1.255e+05,661 1.2554e+05,661 1.2554e+05,661 1.2554e+05,661 1.2554e+05,683 1.2554e+05,683 1.2554e+\
05,683 1.6618e+05,683 1.6618e+05,683 1.6618e+05,683 1.6618e+05,560.21 1.6618e+05,560.21"];
	kv_sync_3 -> kv_cache_3_5_24	[pos="e,1.6513e+05,550.09 1.2541e+05,656 1.2549e+05,656 1.2555e+05,656 1.2555e+05,656 1.2555e+05,656 1.2555e+05,682 1.2555e+05,682 1.2555e+\
05,682 1.6513e+05,682 1.6513e+05,682 1.6513e+05,682 1.6513e+05,560.09 1.6513e+05,560.09"];
	kv_sync_3 -> kv_cache_3_6_24	[pos="e,1.6408e+05,550.27 1.2538e+05,651 1.2547e+05,651 1.2555e+05,651 1.2555e+05,651 1.2555e+05,651 1.2555e+05,681 1.2555e+05,681 1.2555e+\
05,681 1.6408e+05,681 1.6408e+05,681 1.6408e+05,681 1.6408e+05,560.27 1.6408e+05,560.27"];
	kv_sync_3 -> kv_cache_3_7_24	[pos="e,1.6303e+05,550.15 1.2535e+05,646 1.2546e+05,646 1.2555e+05,646 1.2555e+05,646 1.2555e+05,646 1.2555e+05,680 1.2555e+05,680 1.2555e+\
05,680 1.6303e+05,680 1.6303e+05,680 1.6303e+05,680 1.6303e+05,560.15 1.6303e+05,560.15"];
	kv_sync_3 -> kv_cache_3_8_24	[pos="e,1.6198e+05,550.01 1.2543e+05,658.85 1.2543e+05,655.86 1.2543e+05,608 1.2543e+05,608 1.2543e+05,608 1.6198e+05,608 1.6198e+05,608 \
1.6198e+05,608 1.6198e+05,560.01 1.6198e+05,560.01"];
	kv_sync_3 -> kv_cache_3_9_24	[pos="e,1.6093e+05,550.29 1.2535e+05,646.17 1.2535e+05,630.48 1.2535e+05,606 1.2535e+05,606 1.2535e+05,606 1.6093e+05,606 1.6093e+05,606 \
1.6093e+05,606 1.6093e+05,560.29 1.6093e+05,560.29"];
	kv_sync_3 -> kv_cache_3_10_24	[pos="e,1.5946e+05,532 1.2526e+05,640.97 1.2526e+05,624.6 1.2526e+05,603 1.2526e+05,603 1.2526e+05,603 1.5935e+05,603 1.5935e+05,603 1.5935e+\
05,603 1.5935e+05,532 1.5935e+05,532 1.5935e+05,532 1.5945e+05,532 1.5945e+05,532"];
	kv_sync_3 -> kv_cache_3_11_24	[pos="e,1.584e+05,532 1.2518e+05,640.96 1.2518e+05,624.27 1.2518e+05,602 1.2518e+05,602 1.2518e+05,602 1.5829e+05,602 1.5829e+05,602 1.5829e+\
05,602 1.5829e+05,532 1.5829e+05,532 1.5829e+05,532 1.5839e+05,532 1.5839e+05,532"];
	kv_sync_3 -> kv_cache_3_12_24	[pos="e,1.5734e+05,532 1.2509e+05,640.98 1.2509e+05,623.63 1.2509e+05,600 1.2509e+05,600 1.2509e+05,600 1.5723e+05,600 1.5723e+05,600 \
1.5723e+05,600 1.5723e+05,532 1.5723e+05,532 1.5723e+05,532 1.5733e+05,532 1.5733e+05,532"];
	kv_sync_3 -> kv_cache_3_13_24	[pos="e,1.5628e+05,532 1.25e+05,640.89 1.25e+05,621.66 1.25e+05,594 1.25e+05,594 1.25e+05,594 1.5617e+05,594 1.5617e+05,594 1.5617e+05,\
594 1.5617e+05,532 1.5617e+05,532 1.5617e+05,532 1.5627e+05,532 1.5627e+05,532"];
	kv_sync_3 -> kv_cache_3_14_24	[pos="e,1.5523e+05,532 1.2492e+05,640.78 1.2492e+05,620.63 1.2492e+05,591 1.2492e+05,591 1.2492e+05,591 1.5511e+05,591 1.5511e+05,591 \
1.5511e+05,591 1.5511e+05,532 1.5511e+05,532 1.5511e+05,532 1.5522e+05,532 1.5522e+05,532"];
	kv_sync_3 -> kv_cache_3_15_24	[pos="e,1.5417e+05,532 1.2483e+05,640.72 1.2483e+05,619.68 1.2483e+05,588 1.2483e+05,588 1.2483e+05,588 1.5405e+05,588 1.5405e+05,588 \
1.5405e+05,588 1.5405e+05,532 1.5405e+05,532 1.5405e+05,532 1.5416e+05,532 1.5416e+05,532"];
	kv_sync_3 -> kv_cache_3_16_24	[pos="e,1.5311e+05,532 1.2475e+05,640.96 1.2475e+05,619.34 1.2475e+05,586 1.2475e+05,586 1.2475e+05,586 1.5299e+05,586 1.5299e+05,586 \
1.5299e+05,586 1.5299e+05,532 1.5299e+05,532 1.5299e+05,532 1.531e+05,532 1.531e+05,532"];
	kv_sync_3 -> kv_cache_3_17_24	[pos="e,1.5205e+05,532 1.2466e+05,640.99 1.2466e+05,618.51 1.2466e+05,583 1.2466e+05,583 1.2466e+05,583 1.5193e+05,583 1.5193e+05,583 \
1.5193e+05,583 1.5193e+05,532 1.5193e+05,532 1.5193e+05,532 1.5204e+05,532 1.5204e+05,532"];
	kv_sync_3 -> kv_cache_3_18_24	[pos="e,1.7673e+05,550.33 1.2529e+05,677.23 1.2529e+05,703.01 1.2529e+05,747 1.2529e+05,747 1.2529e+05,747 1.7673e+05,747 1.7673e+05,747 \
1.7673e+05,747 1.7673e+05,560.33 1.7673e+05,560.33"];
	kv_sync_3 -> kv_cache_3_19_24	[pos="e,1.7526e+05,532 1.2488e+05,677.23 1.2488e+05,710.8 1.2488e+05,779 1.2488e+05,779 1.2488e+05,779 1.7514e+05,779 1.7514e+05,779 1.7514e+\
05,779 1.7514e+05,532 1.7514e+05,532 1.7514e+05,532 1.7525e+05,532 1.7525e+05,532"];
	kv_sync_3 -> kv_cache_3_20_24	[pos="e,1.742e+05,532 1.2496e+05,677.06 1.2496e+05,709.21 1.2496e+05,773 1.2496e+05,773 1.2496e+05,773 1.7408e+05,773 1.7408e+05,773 1.7408e+\
05,773 1.7408e+05,532 1.7408e+05,532 1.7408e+05,532 1.7419e+05,532 1.7419e+05,532"];
	kv_sync_3 -> kv_cache_3_21_24	[pos="e,1.7314e+05,532 1.2504e+05,677.32 1.2504e+05,708.13 1.2504e+05,767 1.2504e+05,767 1.2504e+05,767 1.7302e+05,767 1.7302e+05,767 \
1.7302e+05,767 1.7302e+05,532 1.7302e+05,532 1.7302e+05,532 1.7313e+05,532 1.7313e+05,532"];
	kv_sync_3 -> kv_cache_3_22_24	[pos="e,1.7208e+05,532 1.2513e+05,677.24 1.2513e+05,706.57 1.2513e+05,761 1.2513e+05,761 1.2513e+05,761 1.7196e+05,761 1.7196e+05,761 \
1.7196e+05,761 1.7196e+05,532 1.7196e+05,532 1.7196e+05,532 1.7207e+05,532 1.7207e+05,532"];
	kv_sync_3 -> kv_cache_3_23_24	[pos="e,1.7102e+05,532 1.2521e+05,677.06 1.2521e+05,704.87 1.2521e+05,755 1.2521e+05,755 1.2521e+05,755 1.7091e+05,755 1.7091e+05,755 \
1.7091e+05,755 1.7091e+05,532 1.7091e+05,532 1.7091e+05,532 1.7101e+05,532 1.7101e+05,532"];
	async_comm	[fillcolor=lightyellow,
		height=0.5,
		label="<b>Asynchronous Communication</b><br/>Overlaps attention computation<br/>With FFN operations<br/>85% overlap efficiency",
		pos="2.8974e+05,412",
		shape=parallelogram,
		width=13.953];
	async_comm -> hier_reduce_0_24	[pos="e,1.8673e+05,317.19 2.8974e+05,393.92 2.8974e+05,392.15 2.8974e+05,391 2.8974e+05,391 2.8974e+05,391 1.8673e+05,391 1.8673e+05,391 \
1.8673e+05,391 1.8673e+05,327.19 1.8673e+05,327.19"];
	async_comm -> hier_reduce_1_24	[pos="e,2.1165e+05,299 2.8999e+05,393.84 2.8999e+05,361.9 2.8999e+05,299 2.8999e+05,299 2.8999e+05,299 2.1166e+05,299 2.1166e+05,299"];
	async_comm -> hier_reduce_2_24	[pos="e,1.4443e+05,318.31 2.8949e+05,393.85 2.8949e+05,392.7 2.8949e+05,392 2.8949e+05,392 2.8949e+05,392 1.4443e+05,392 1.4443e+05,392 \
1.4443e+05,392 1.4443e+05,328.31 1.4443e+05,328.31"];
	async_comm -> hier_reduce_3_24	[pos="e,1.6978e+05,317.91 2.8974e+05,430.23 2.8974e+05,456.01 2.8974e+05,500 2.8974e+05,500 2.8974e+05,500 1.6978e+05,500 1.6978e+05,500 \
1.6978e+05,500 1.6978e+05,327.91 1.6978e+05,327.91"];
	allreduce_final_output	[fillcolor=lightyellow,
		height=0.5,
		label="<b>All-Reduce</b><br/>TP across 8 base GPUs<br/>[batch=1024, seq=?, dim=4096]",
		pos="3.0359e+05,90",
		shape=parallelogram,
		width=9.47];
	final_output_0 -> allreduce_final_output	[pos="e,3.0335e+05,99 3.0263e+05,143.78 3.0263e+05,125.17 3.0263e+05,99 3.0263e+05,99 3.0263e+05,99 3.0334e+05,99 3.0334e+05,99"];
	final_output_1 -> allreduce_final_output	[pos="e,3.0382e+05,81 3.0582e+05,143.62 3.0582e+05,119.72 3.0582e+05,81 3.0582e+05,81 3.0582e+05,81 3.0383e+05,81 3.0383e+05,81"];
	final_output_2 -> allreduce_final_output	[pos="e,3.0386e+05,90 3.0519e+05,143.83 3.0519e+05,122.5 3.0519e+05,90 3.0519e+05,90 3.0519e+05,90 3.0387e+05,90 3.0387e+05,90"];
	final_output_3 -> allreduce_final_output	[pos="e,3.0332e+05,90 3.0199e+05,143.83 3.0199e+05,122.5 3.0199e+05,90 3.0199e+05,90 3.0199e+05,90 3.0331e+05,90 3.0331e+05,90"];
	final_output_4 -> allreduce_final_output	[pos="e,3.0376e+05,108.41 3.0376e+05,143.83 3.0376e+05,143.83 3.0376e+05,118.41 3.0376e+05,118.41"];
	final_output_5 -> allreduce_final_output	[pos="e,3.0328e+05,81 3.0135e+05,143.62 3.0135e+05,119.72 3.0135e+05,81 3.0135e+05,81 3.0135e+05,81 3.0327e+05,81 3.0327e+05,81"];
	final_output_6 -> allreduce_final_output	[pos="e,3.0341e+05,108.41 3.0341e+05,143.83 3.0341e+05,143.83 3.0341e+05,118.41 3.0341e+05,118.41"];
	final_output_7 -> allreduce_final_output	[pos="e,3.0389e+05,99 3.0455e+05,143.78 3.0455e+05,125.17 3.0455e+05,99 3.0455e+05,99 3.0455e+05,99 3.039e+05,99 3.039e+05,99"];
	final_output	[fillcolor=lightblue,
		height=0.5,
		label="<b>Final Output</b><br/>Aggregated across 8 base GPUs<br/>Input: [batch=1024, seq=?, vocab=32000]<br/>Output: [batch=1024, seq=?, \
vocab=32000]",
		pos="3.0359e+05,18",
		shape=ellipse,
		width=11.332];
	allreduce_pos	[fillcolor=lightyellow,
		height=0.5,
		label="<b>All-Reduce</b><br/>TP across 8 base GPUs<br/>[batch=1024, seq=?, dim=4096]",
		pos="12645,731",
		shape=parallelogram,
		width=9.47];
	allreduce_ffn_up	[fillcolor=lightyellow,
		height=0.5,
		label="<b>All-Reduce</b><br/>TP across 8 base GPUs<br/>[batch=1024, seq=?, dim=4096]",
		pos="13345,731",
		shape=parallelogram,
		width=9.47];
	allreduce_ffn_down	[fillcolor=lightyellow,
		height=0.5,
		label="<b>All-Reduce</b><br/>TP across 8 base GPUs<br/>[batch=1024, seq=?, dim=4096]",
		pos="14045,731",
		shape=parallelogram,
		width=9.47];
	allreduce_final_output -> final_output	[pos="e,3.0332e+05,32.075 3.0332e+05,71.831 3.0332e+05,71.831 3.0332e+05,42.075 3.0332e+05,42.075"];
	allreduce_final_output -> final_output	[pos="e,3.034e+05,33.957 3.034e+05,71.831 3.034e+05,71.831 3.034e+05,43.957 3.034e+05,43.957"];
	allreduce_final_output -> final_output	[pos="e,3.0347e+05,35.418 3.0347e+05,71.831 3.0347e+05,71.831 3.0347e+05,45.418 3.0347e+05,45.418"];
	allreduce_final_output -> final_output	[pos="e,3.0355e+05,36.413 3.0355e+05,71.831 3.0355e+05,71.831 3.0355e+05,46.413 3.0355e+05,46.413"];
	allreduce_final_output -> final_output	[pos="e,3.0363e+05,36.413 3.0363e+05,71.831 3.0363e+05,71.831 3.0363e+05,46.413 3.0363e+05,46.413"];
	allreduce_final_output -> final_output	[pos="e,3.037e+05,35.418 3.037e+05,71.831 3.037e+05,71.831 3.037e+05,45.418 3.037e+05,45.418"];
	allreduce_final_output -> final_output	[pos="e,3.0378e+05,33.957 3.0378e+05,71.831 3.0378e+05,71.831 3.0378e+05,43.957 3.0378e+05,43.957"];
	allreduce_final_output -> final_output	[pos="e,3.0385e+05,31.744 3.0385e+05,88.22 3.0385e+05,88.22 3.0385e+05,41.744 3.0385e+05,41.744"];
}
