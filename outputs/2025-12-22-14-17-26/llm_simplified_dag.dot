digraph {
	graph [bb="0,0,1107.7,390.08",
		bgcolor=white,
		fontname=Arial,
		rankdir=TB,
		size="20,30"
	];
	node [fontname=Arial,
		fontsize=12,
		label="\N",
		shape=rectangle,
		style=filled
	];
	input	[fillcolor=white,
		height=0.5,
		label="Input Layer\n[128, seq_len, 1024]",
		pos="104.65,356.08",
		width=1.7361];
	stage1	[fillcolor=lightblue,
		height=0.65278,
		label="Pipeline Stage 1\nLayers 1-8\nTP8-EP64",
		pos="104.65,262.58",
		width=1.4583];
	input -> stage1	[pos="e,104.65,286.25 104.65,337.87 104.65,326.24 104.65,310.51 104.65,296.51"];
	pp_comm	[fillcolor=lightyellow,
		height=0.66782,
		label="Pipeline Communication\nPP Transfer",
		pos="104.65,179.04",
		shape=ellipse,
		width=2.907];
	stage1 -> pp_comm	[pos="e,104.65,203.2 104.65,238.87 104.65,230.96 104.65,221.92 104.65,213.34"];
	routing	[fillcolor=lightcoral,
		height=0.94444,
		label="MoE Routing\nGate Selection",
		pos="480.65,356.08",
		shape=parallelogram,
		width=2.7359];
	stage1 -> routing	[constraint=false,
		pos="e,383.65,324.77 157.29,273.65 211.75,284.39 299.11,302.52 373.65,322.08 373.75,322.11 373.86,322.14 373.96,322.16",
		style=dashed];
	stage2	[fillcolor=lightgreen,
		height=0.65278,
		label="Pipeline Stage 2\nLayers 9-16\nTP8-EP64",
		pos="104.65,95.5",
		width=1.4583];
	output	[fillcolor=white,
		height=0.5,
		label="Output Layer\n[128, seq_len, vocab_size]",
		pos="104.65,18",
		width=2.1944];
	stage2 -> output	[pos="e,104.65,36.114 104.65,71.848 104.65,63.785 104.65,54.622 104.65,46.216"];
	pp_comm -> stage2	[pos="e,104.65,119.14 104.65,154.89 104.65,146.93 104.65,137.85 104.65,129.26"];
	ep_dispatch	[fillcolor=lightyellow,
		height=0.66782,
		label="Expert Dispatch\nAll-to-All (128 ops)",
		pos="679.65,356.08",
		shape=ellipse,
		width=2.2785];
	experts	[fillcolor=lightblue,
		height=0.5,
		label="64 Expert Computations\nTP8 Parallel",
		pos="852.65,356.08",
		width=2.0139];
	ep_dispatch -> experts	[constraint=false,
		pos="e,779.87,356.08 761.76,356.08 764.4,356.08 767.04,356.08 769.68,356.08"];
	ep_combine	[fillcolor=lightyellow,
		height=0.66782,
		label="Expert Combine\nAll-to-All (128 ops)",
		pos="1025.7,356.08",
		shape=ellipse,
		width=2.2785];
	ep_combine -> stage1	[constraint=false,
		pos="e,157.34,265.39 980.55,335.93 966.13,330.57 949.94,325.33 934.65,322.08 788.2,291 334.74,271.9 167.47,265.76",
		style=dashed];
	tp_sync	[fillcolor=lightyellow,
		height=0.66782,
		label="Tensor Parallel Sync\nAll-Reduce (16 ops)",
		pos="274.65,356.08",
		shape=ellipse,
		width=2.4945];
	tp_sync -> stage1	[constraint=false,
		pos="e,146.65,286.19 236.08,334.32 212.24,321.49 181.38,304.88 155.55,290.98",
		style=dotted];
	tp_sync -> stage2	[constraint=false,
		pos="e,157.32,112.89 274.01,331.99 271.75,291.7 261.77,207.81 218.65,155 205.11,138.42 185.63,126.03 166.6,117.04",
		style=dotted];
	routing -> ep_dispatch	[constraint=false,
		pos="e,597.29,356.08 559.16,356.08 568.5,356.08 577.83,356.08 587.16,356.08"];
	experts -> ep_combine	[constraint=false,
		pos="e,943.33,356.08 925.3,356.08 927.93,356.08 930.56,356.08 933.19,356.08"];
}
