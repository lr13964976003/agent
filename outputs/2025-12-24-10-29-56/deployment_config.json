{
  "parallel_strategy": {
    "type": "TPxPP",
    "tensor_parallel_size": 4,
    "pipeline_parallel_size": 2,
    "data_parallel_size": 1,
    "total_gpus": 8,
    "gpu_mapping": {
      "stage_0": [0, 1, 2, 3],
      "stage_1": [4, 5, 6, 7]
    }
  },
  "model_config": {
    "model_name": "Llama3_70B_Instruct",
    "num_layers": 80,
    "layers_per_stage": 40,
    "hidden_size": 8192,
    "num_attention_heads": 64,
    "num_key_value_heads": 8,
    "vocabulary_size": 128256,
    "max_position_embeddings": 8192,
    "quantization": "fp16"
  },
  "performance_config": {
    "max_batch_size": 32,
    "max_num_seqs": 64,
    "max_num_batched_tokens": 4096,
    "gpu_memory_utilization": 0.85,
    "target_requests_per_second": 8,
    "prefill_chunk_size": 2048
  },
  "latency_targets": {
    "prefill_p50_ms": 500,
    "prefill_p99_ms": 1000,
    "decode_per_token_p50_ms": 50,
    "decode_per_token_p99_ms": 100,
    "first_token_p99_ms": 1500
  },
  "memory_analysis": {
    "model_weights_per_gpu_gb": 17.5,
    "available_memory_per_gpu_gb": 68.0,
    "kv_cache_budget_per_gpu_gb": 50.5,
    "max_tokens_per_gpu": 51000
  },
  "communication_config": {
    "nccl_ib_disable": 0,
    "nccl_socket_ifname": "eth0",
    "nccl_debug": "INFO",
    "nvlink_bandwidth_gbps": 900,
    "pcie_bandwidth_gbps": 64
  },
  "optimization_settings": {
    "enable_cuda_graph": true,
    "enable_prefix_caching": true,
    "enable_chunked_prefill": true,
    "max_num_batched_tokens": 4096,
    "max_num_seqs": 64,
    "max_paddings": 256
  },
  "load_balancing": {
    "gpu_utilization_target": 0.70,
    "memory_balance_epsilon": 0.05,
    "request_distribution": "round_robin",
    "dynamic_batching": true
  },
  "monitoring": {
    "metrics_port": 8080,
    "log_level": "INFO",
    "track_gpu_utilization": true,
    "track_latency_percentiles": true,
    "track_throughput": true
  }
}