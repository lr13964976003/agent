// MA Separation: 12 Attention GPUs + 4 MoE GPUs
digraph MA_Separation_MoE_Attention {
	rankdir=TB size="30,20"
	node [fillcolor=lightblue shape=ellipse style=filled]
	node [fillcolor=lightgreen shape=rectangle style=filled]
	node [fillcolor=yellow shape=parallelogram style=filled]
	node [fillcolor=lightcoral shape=diamond style=filled]
	label="MA Separation: 4-Layer MoE Transformer
12 Attention GPUs + 4 MoE GPUs
Sequence: 2048 tokens, Batch: 1024, Hidden: 4096"
	fontsize=20
	input [label="INPUT
Input: [batch_size=1024, seq_len=2048, hidden=4096]
GPU: all" fillcolor=lightblue shape=ellipse]
	layer1_qkv_gpu0 [label="L1_QKV_Projection_GPU0
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 0-2
GPU: 0" fillcolor=lightgreen shape=rectangle]
	layer1_attn_gpu0 [label="L1_Multi-Head_Attention_GPU0
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 0" fillcolor=lightgreen shape=rectangle]
	layer1_attn_norm_gpu0 [label="L1_Residual+LayerNorm_GPU0
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 0" fillcolor=lightgreen shape=rectangle]
	layer1_qkv_gpu1 [label="L1_QKV_Projection_GPU1
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 3-5
GPU: 1" fillcolor=lightgreen shape=rectangle]
	layer1_attn_gpu1 [label="L1_Multi-Head_Attention_GPU1
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 1" fillcolor=lightgreen shape=rectangle]
	layer1_attn_norm_gpu1 [label="L1_Residual+LayerNorm_GPU1
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 1" fillcolor=lightgreen shape=rectangle]
	layer1_qkv_gpu2 [label="L1_QKV_Projection_GPU2
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 6-8
GPU: 2" fillcolor=lightgreen shape=rectangle]
	layer1_attn_gpu2 [label="L1_Multi-Head_Attention_GPU2
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 2" fillcolor=lightgreen shape=rectangle]
	layer1_attn_norm_gpu2 [label="L1_Residual+LayerNorm_GPU2
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 2" fillcolor=lightgreen shape=rectangle]
	layer1_qkv_gpu3 [label="L1_QKV_Projection_GPU3
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 9-11
GPU: 3" fillcolor=lightgreen shape=rectangle]
	layer1_attn_gpu3 [label="L1_Multi-Head_Attention_GPU3
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 3" fillcolor=lightgreen shape=rectangle]
	layer1_attn_norm_gpu3 [label="L1_Residual+LayerNorm_GPU3
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 3" fillcolor=lightgreen shape=rectangle]
	layer1_qkv_gpu4 [label="L1_QKV_Projection_GPU4
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 12-14
GPU: 4" fillcolor=lightgreen shape=rectangle]
	layer1_attn_gpu4 [label="L1_Multi-Head_Attention_GPU4
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 4" fillcolor=lightgreen shape=rectangle]
	layer1_attn_norm_gpu4 [label="L1_Residual+LayerNorm_GPU4
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 4" fillcolor=lightgreen shape=rectangle]
	layer1_qkv_gpu5 [label="L1_QKV_Projection_GPU5
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 15-17
GPU: 5" fillcolor=lightgreen shape=rectangle]
	layer1_attn_gpu5 [label="L1_Multi-Head_Attention_GPU5
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 5" fillcolor=lightgreen shape=rectangle]
	layer1_attn_norm_gpu5 [label="L1_Residual+LayerNorm_GPU5
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 5" fillcolor=lightgreen shape=rectangle]
	layer1_qkv_gpu6 [label="L1_QKV_Projection_GPU6
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 18-20
GPU: 6" fillcolor=lightgreen shape=rectangle]
	layer1_attn_gpu6 [label="L1_Multi-Head_Attention_GPU6
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 6" fillcolor=lightgreen shape=rectangle]
	layer1_attn_norm_gpu6 [label="L1_Residual+LayerNorm_GPU6
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 6" fillcolor=lightgreen shape=rectangle]
	layer1_qkv_gpu7 [label="L1_QKV_Projection_GPU7
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 21-23
GPU: 7" fillcolor=lightgreen shape=rectangle]
	layer1_attn_gpu7 [label="L1_Multi-Head_Attention_GPU7
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 7" fillcolor=lightgreen shape=rectangle]
	layer1_attn_norm_gpu7 [label="L1_Residual+LayerNorm_GPU7
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 7" fillcolor=lightgreen shape=rectangle]
	layer1_qkv_gpu8 [label="L1_QKV_Projection_GPU8
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 24-26
GPU: 8" fillcolor=lightgreen shape=rectangle]
	layer1_attn_gpu8 [label="L1_Multi-Head_Attention_GPU8
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 8" fillcolor=lightgreen shape=rectangle]
	layer1_attn_norm_gpu8 [label="L1_Residual+LayerNorm_GPU8
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 8" fillcolor=lightgreen shape=rectangle]
	layer1_qkv_gpu9 [label="L1_QKV_Projection_GPU9
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 27-29
GPU: 9" fillcolor=lightgreen shape=rectangle]
	layer1_attn_gpu9 [label="L1_Multi-Head_Attention_GPU9
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 9" fillcolor=lightgreen shape=rectangle]
	layer1_attn_norm_gpu9 [label="L1_Residual+LayerNorm_GPU9
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 9" fillcolor=lightgreen shape=rectangle]
	layer1_qkv_gpu10 [label="L1_QKV_Projection_GPU10
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 30-32
GPU: 10" fillcolor=lightgreen shape=rectangle]
	layer1_attn_gpu10 [label="L1_Multi-Head_Attention_GPU10
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 10" fillcolor=lightgreen shape=rectangle]
	layer1_attn_norm_gpu10 [label="L1_Residual+LayerNorm_GPU10
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 10" fillcolor=lightgreen shape=rectangle]
	layer1_qkv_gpu11 [label="L1_QKV_Projection_GPU11
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 33-35
GPU: 11" fillcolor=lightgreen shape=rectangle]
	layer1_attn_gpu11 [label="L1_Multi-Head_Attention_GPU11
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 11" fillcolor=lightgreen shape=rectangle]
	layer1_attn_norm_gpu11 [label="L1_Residual+LayerNorm_GPU11
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 11" fillcolor=lightgreen shape=rectangle]
	layer1_attn_aggregate [label="L1_Attention_Aggregate
Input: 12×[1024,2048,4096]
Output: [1024,2048,4096]
All-Reduce across GPUs 0-11" fillcolor=lightcoral shape=diamond]
	layer1_moe_broadcast [label="L1_Broadcast_to_MoE
Input: [1024,2048,4096]
Output: 4×[1024,2048,4096]
Broadcast to GPUs 12-15" fillcolor=yellow shape=parallelogram]
	layer1_gate_gpu12 [label="L1_Gate_GPU12
Input: [1024,2048,4096]
Output: [1024,2048,16 experts]
Top-2 routing
GPU: 12" fillcolor=lightgreen shape=rectangle]
	layer1_expert12_0 [label="L1_Expert0_GPU12
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 12" fillcolor=lightgreen shape=rectangle]
	layer1_expert12_1 [label="L1_Expert1_GPU12
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 12" fillcolor=lightgreen shape=rectangle]
	layer1_expert12_2 [label="L1_Expert2_GPU12
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 12" fillcolor=lightgreen shape=rectangle]
	layer1_expert12_3 [label="L1_Expert3_GPU12
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 12" fillcolor=lightgreen shape=rectangle]
	layer1_moe_aggregate_gpu12 [label="L1_MoE_Aggregate_GPU12
Input: 4×[tokens,4096]
Output: [1024,2048,4096]
GPU: 12" fillcolor=lightgreen shape=rectangle]
	layer1_moe_norm_gpu12 [label="L1_Residual+LayerNorm_GPU12
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 12" fillcolor=lightgreen shape=rectangle]
	layer1_gate_gpu13 [label="L1_Gate_GPU13
Input: [1024,2048,4096]
Output: [1024,2048,16 experts]
Top-2 routing
GPU: 13" fillcolor=lightgreen shape=rectangle]
	layer1_expert13_4 [label="L1_Expert4_GPU13
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 13" fillcolor=lightgreen shape=rectangle]
	layer1_expert13_5 [label="L1_Expert5_GPU13
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 13" fillcolor=lightgreen shape=rectangle]
	layer1_expert13_6 [label="L1_Expert6_GPU13
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 13" fillcolor=lightgreen shape=rectangle]
	layer1_expert13_7 [label="L1_Expert7_GPU13
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 13" fillcolor=lightgreen shape=rectangle]
	layer1_moe_aggregate_gpu13 [label="L1_MoE_Aggregate_GPU13
Input: 4×[tokens,4096]
Output: [1024,2048,4096]
GPU: 13" fillcolor=lightgreen shape=rectangle]
	layer1_moe_norm_gpu13 [label="L1_Residual+LayerNorm_GPU13
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 13" fillcolor=lightgreen shape=rectangle]
	layer1_gate_gpu14 [label="L1_Gate_GPU14
Input: [1024,2048,4096]
Output: [1024,2048,16 experts]
Top-2 routing
GPU: 14" fillcolor=lightgreen shape=rectangle]
	layer1_expert14_8 [label="L1_Expert8_GPU14
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 14" fillcolor=lightgreen shape=rectangle]
	layer1_expert14_9 [label="L1_Expert9_GPU14
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 14" fillcolor=lightgreen shape=rectangle]
	layer1_expert14_10 [label="L1_Expert10_GPU14
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 14" fillcolor=lightgreen shape=rectangle]
	layer1_expert14_11 [label="L1_Expert11_GPU14
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 14" fillcolor=lightgreen shape=rectangle]
	layer1_moe_aggregate_gpu14 [label="L1_MoE_Aggregate_GPU14
Input: 4×[tokens,4096]
Output: [1024,2048,4096]
GPU: 14" fillcolor=lightgreen shape=rectangle]
	layer1_moe_norm_gpu14 [label="L1_Residual+LayerNorm_GPU14
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 14" fillcolor=lightgreen shape=rectangle]
	layer1_gate_gpu15 [label="L1_Gate_GPU15
Input: [1024,2048,4096]
Output: [1024,2048,16 experts]
Top-2 routing
GPU: 15" fillcolor=lightgreen shape=rectangle]
	layer1_expert15_12 [label="L1_Expert12_GPU15
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 15" fillcolor=lightgreen shape=rectangle]
	layer1_expert15_13 [label="L1_Expert13_GPU15
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 15" fillcolor=lightgreen shape=rectangle]
	layer1_expert15_14 [label="L1_Expert14_GPU15
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 15" fillcolor=lightgreen shape=rectangle]
	layer1_expert15_15 [label="L1_Expert15_GPU15
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 15" fillcolor=lightgreen shape=rectangle]
	layer1_moe_aggregate_gpu15 [label="L1_MoE_Aggregate_GPU15
Input: 4×[tokens,4096]
Output: [1024,2048,4096]
GPU: 15" fillcolor=lightgreen shape=rectangle]
	layer1_moe_norm_gpu15 [label="L1_Residual+LayerNorm_GPU15
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 15" fillcolor=lightgreen shape=rectangle]
	layer2_qkv_gpu0 [label="L2_QKV_Projection_GPU0
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 0-2
GPU: 0" fillcolor=lightgreen shape=rectangle]
	layer2_attn_gpu0 [label="L2_Multi-Head_Attention_GPU0
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 0" fillcolor=lightgreen shape=rectangle]
	layer2_attn_norm_gpu0 [label="L2_Residual+LayerNorm_GPU0
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 0" fillcolor=lightgreen shape=rectangle]
	layer2_qkv_gpu1 [label="L2_QKV_Projection_GPU1
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 3-5
GPU: 1" fillcolor=lightgreen shape=rectangle]
	layer2_attn_gpu1 [label="L2_Multi-Head_Attention_GPU1
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 1" fillcolor=lightgreen shape=rectangle]
	layer2_attn_norm_gpu1 [label="L2_Residual+LayerNorm_GPU1
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 1" fillcolor=lightgreen shape=rectangle]
	layer2_qkv_gpu2 [label="L2_QKV_Projection_GPU2
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 6-8
GPU: 2" fillcolor=lightgreen shape=rectangle]
	layer2_attn_gpu2 [label="L2_Multi-Head_Attention_GPU2
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 2" fillcolor=lightgreen shape=rectangle]
	layer2_attn_norm_gpu2 [label="L2_Residual+LayerNorm_GPU2
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 2" fillcolor=lightgreen shape=rectangle]
	layer2_qkv_gpu3 [label="L2_QKV_Projection_GPU3
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 9-11
GPU: 3" fillcolor=lightgreen shape=rectangle]
	layer2_attn_gpu3 [label="L2_Multi-Head_Attention_GPU3
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 3" fillcolor=lightgreen shape=rectangle]
	layer2_attn_norm_gpu3 [label="L2_Residual+LayerNorm_GPU3
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 3" fillcolor=lightgreen shape=rectangle]
	layer2_qkv_gpu4 [label="L2_QKV_Projection_GPU4
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 12-14
GPU: 4" fillcolor=lightgreen shape=rectangle]
	layer2_attn_gpu4 [label="L2_Multi-Head_Attention_GPU4
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 4" fillcolor=lightgreen shape=rectangle]
	layer2_attn_norm_gpu4 [label="L2_Residual+LayerNorm_GPU4
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 4" fillcolor=lightgreen shape=rectangle]
	layer2_qkv_gpu5 [label="L2_QKV_Projection_GPU5
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 15-17
GPU: 5" fillcolor=lightgreen shape=rectangle]
	layer2_attn_gpu5 [label="L2_Multi-Head_Attention_GPU5
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 5" fillcolor=lightgreen shape=rectangle]
	layer2_attn_norm_gpu5 [label="L2_Residual+LayerNorm_GPU5
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 5" fillcolor=lightgreen shape=rectangle]
	layer2_qkv_gpu6 [label="L2_QKV_Projection_GPU6
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 18-20
GPU: 6" fillcolor=lightgreen shape=rectangle]
	layer2_attn_gpu6 [label="L2_Multi-Head_Attention_GPU6
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 6" fillcolor=lightgreen shape=rectangle]
	layer2_attn_norm_gpu6 [label="L2_Residual+LayerNorm_GPU6
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 6" fillcolor=lightgreen shape=rectangle]
	layer2_qkv_gpu7 [label="L2_QKV_Projection_GPU7
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 21-23
GPU: 7" fillcolor=lightgreen shape=rectangle]
	layer2_attn_gpu7 [label="L2_Multi-Head_Attention_GPU7
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 7" fillcolor=lightgreen shape=rectangle]
	layer2_attn_norm_gpu7 [label="L2_Residual+LayerNorm_GPU7
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 7" fillcolor=lightgreen shape=rectangle]
	layer2_qkv_gpu8 [label="L2_QKV_Projection_GPU8
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 24-26
GPU: 8" fillcolor=lightgreen shape=rectangle]
	layer2_attn_gpu8 [label="L2_Multi-Head_Attention_GPU8
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 8" fillcolor=lightgreen shape=rectangle]
	layer2_attn_norm_gpu8 [label="L2_Residual+LayerNorm_GPU8
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 8" fillcolor=lightgreen shape=rectangle]
	layer2_qkv_gpu9 [label="L2_QKV_Projection_GPU9
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 27-29
GPU: 9" fillcolor=lightgreen shape=rectangle]
	layer2_attn_gpu9 [label="L2_Multi-Head_Attention_GPU9
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 9" fillcolor=lightgreen shape=rectangle]
	layer2_attn_norm_gpu9 [label="L2_Residual+LayerNorm_GPU9
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 9" fillcolor=lightgreen shape=rectangle]
	layer2_qkv_gpu10 [label="L2_QKV_Projection_GPU10
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 30-32
GPU: 10" fillcolor=lightgreen shape=rectangle]
	layer2_attn_gpu10 [label="L2_Multi-Head_Attention_GPU10
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 10" fillcolor=lightgreen shape=rectangle]
	layer2_attn_norm_gpu10 [label="L2_Residual+LayerNorm_GPU10
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 10" fillcolor=lightgreen shape=rectangle]
	layer2_qkv_gpu11 [label="L2_QKV_Projection_GPU11
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 33-35
GPU: 11" fillcolor=lightgreen shape=rectangle]
	layer2_attn_gpu11 [label="L2_Multi-Head_Attention_GPU11
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 11" fillcolor=lightgreen shape=rectangle]
	layer2_attn_norm_gpu11 [label="L2_Residual+LayerNorm_GPU11
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 11" fillcolor=lightgreen shape=rectangle]
	layer2_attn_aggregate [label="L2_Attention_Aggregate
Input: 12×[1024,2048,4096]
Output: [1024,2048,4096]
All-Reduce across GPUs 0-11" fillcolor=lightcoral shape=diamond]
	layer2_moe_broadcast [label="L2_Broadcast_to_MoE
Input: [1024,2048,4096]
Output: 4×[1024,2048,4096]
Broadcast to GPUs 12-15" fillcolor=yellow shape=parallelogram]
	layer2_gate_gpu12 [label="L2_Gate_GPU12
Input: [1024,2048,4096]
Output: [1024,2048,16 experts]
Top-2 routing
GPU: 12" fillcolor=lightgreen shape=rectangle]
	layer2_expert12_0 [label="L2_Expert0_GPU12
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 12" fillcolor=lightgreen shape=rectangle]
	layer2_expert12_1 [label="L2_Expert1_GPU12
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 12" fillcolor=lightgreen shape=rectangle]
	layer2_expert12_2 [label="L2_Expert2_GPU12
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 12" fillcolor=lightgreen shape=rectangle]
	layer2_expert12_3 [label="L2_Expert3_GPU12
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 12" fillcolor=lightgreen shape=rectangle]
	layer2_moe_aggregate_gpu12 [label="L2_MoE_Aggregate_GPU12
Input: 4×[tokens,4096]
Output: [1024,2048,4096]
GPU: 12" fillcolor=lightgreen shape=rectangle]
	layer2_moe_norm_gpu12 [label="L2_Residual+LayerNorm_GPU12
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 12" fillcolor=lightgreen shape=rectangle]
	layer2_gate_gpu13 [label="L2_Gate_GPU13
Input: [1024,2048,4096]
Output: [1024,2048,16 experts]
Top-2 routing
GPU: 13" fillcolor=lightgreen shape=rectangle]
	layer2_expert13_4 [label="L2_Expert4_GPU13
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 13" fillcolor=lightgreen shape=rectangle]
	layer2_expert13_5 [label="L2_Expert5_GPU13
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 13" fillcolor=lightgreen shape=rectangle]
	layer2_expert13_6 [label="L2_Expert6_GPU13
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 13" fillcolor=lightgreen shape=rectangle]
	layer2_expert13_7 [label="L2_Expert7_GPU13
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 13" fillcolor=lightgreen shape=rectangle]
	layer2_moe_aggregate_gpu13 [label="L2_MoE_Aggregate_GPU13
Input: 4×[tokens,4096]
Output: [1024,2048,4096]
GPU: 13" fillcolor=lightgreen shape=rectangle]
	layer2_moe_norm_gpu13 [label="L2_Residual+LayerNorm_GPU13
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 13" fillcolor=lightgreen shape=rectangle]
	layer2_gate_gpu14 [label="L2_Gate_GPU14
Input: [1024,2048,4096]
Output: [1024,2048,16 experts]
Top-2 routing
GPU: 14" fillcolor=lightgreen shape=rectangle]
	layer2_expert14_8 [label="L2_Expert8_GPU14
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 14" fillcolor=lightgreen shape=rectangle]
	layer2_expert14_9 [label="L2_Expert9_GPU14
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 14" fillcolor=lightgreen shape=rectangle]
	layer2_expert14_10 [label="L2_Expert10_GPU14
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 14" fillcolor=lightgreen shape=rectangle]
	layer2_expert14_11 [label="L2_Expert11_GPU14
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 14" fillcolor=lightgreen shape=rectangle]
	layer2_moe_aggregate_gpu14 [label="L2_MoE_Aggregate_GPU14
Input: 4×[tokens,4096]
Output: [1024,2048,4096]
GPU: 14" fillcolor=lightgreen shape=rectangle]
	layer2_moe_norm_gpu14 [label="L2_Residual+LayerNorm_GPU14
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 14" fillcolor=lightgreen shape=rectangle]
	layer2_gate_gpu15 [label="L2_Gate_GPU15
Input: [1024,2048,4096]
Output: [1024,2048,16 experts]
Top-2 routing
GPU: 15" fillcolor=lightgreen shape=rectangle]
	layer2_expert15_12 [label="L2_Expert12_GPU15
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 15" fillcolor=lightgreen shape=rectangle]
	layer2_expert15_13 [label="L2_Expert13_GPU15
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 15" fillcolor=lightgreen shape=rectangle]
	layer2_expert15_14 [label="L2_Expert14_GPU15
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 15" fillcolor=lightgreen shape=rectangle]
	layer2_expert15_15 [label="L2_Expert15_GPU15
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 15" fillcolor=lightgreen shape=rectangle]
	layer2_moe_aggregate_gpu15 [label="L2_MoE_Aggregate_GPU15
Input: 4×[tokens,4096]
Output: [1024,2048,4096]
GPU: 15" fillcolor=lightgreen shape=rectangle]
	layer2_moe_norm_gpu15 [label="L2_Residual+LayerNorm_GPU15
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 15" fillcolor=lightgreen shape=rectangle]
	layer3_qkv_gpu0 [label="L3_QKV_Projection_GPU0
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 0-2
GPU: 0" fillcolor=lightgreen shape=rectangle]
	layer3_attn_gpu0 [label="L3_Multi-Head_Attention_GPU0
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 0" fillcolor=lightgreen shape=rectangle]
	layer3_attn_norm_gpu0 [label="L3_Residual+LayerNorm_GPU0
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 0" fillcolor=lightgreen shape=rectangle]
	layer3_qkv_gpu1 [label="L3_QKV_Projection_GPU1
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 3-5
GPU: 1" fillcolor=lightgreen shape=rectangle]
	layer3_attn_gpu1 [label="L3_Multi-Head_Attention_GPU1
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 1" fillcolor=lightgreen shape=rectangle]
	layer3_attn_norm_gpu1 [label="L3_Residual+LayerNorm_GPU1
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 1" fillcolor=lightgreen shape=rectangle]
	layer3_qkv_gpu2 [label="L3_QKV_Projection_GPU2
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 6-8
GPU: 2" fillcolor=lightgreen shape=rectangle]
	layer3_attn_gpu2 [label="L3_Multi-Head_Attention_GPU2
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 2" fillcolor=lightgreen shape=rectangle]
	layer3_attn_norm_gpu2 [label="L3_Residual+LayerNorm_GPU2
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 2" fillcolor=lightgreen shape=rectangle]
	layer3_qkv_gpu3 [label="L3_QKV_Projection_GPU3
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 9-11
GPU: 3" fillcolor=lightgreen shape=rectangle]
	layer3_attn_gpu3 [label="L3_Multi-Head_Attention_GPU3
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 3" fillcolor=lightgreen shape=rectangle]
	layer3_attn_norm_gpu3 [label="L3_Residual+LayerNorm_GPU3
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 3" fillcolor=lightgreen shape=rectangle]
	layer3_qkv_gpu4 [label="L3_QKV_Projection_GPU4
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 12-14
GPU: 4" fillcolor=lightgreen shape=rectangle]
	layer3_attn_gpu4 [label="L3_Multi-Head_Attention_GPU4
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 4" fillcolor=lightgreen shape=rectangle]
	layer3_attn_norm_gpu4 [label="L3_Residual+LayerNorm_GPU4
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 4" fillcolor=lightgreen shape=rectangle]
	layer3_qkv_gpu5 [label="L3_QKV_Projection_GPU5
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 15-17
GPU: 5" fillcolor=lightgreen shape=rectangle]
	layer3_attn_gpu5 [label="L3_Multi-Head_Attention_GPU5
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 5" fillcolor=lightgreen shape=rectangle]
	layer3_attn_norm_gpu5 [label="L3_Residual+LayerNorm_GPU5
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 5" fillcolor=lightgreen shape=rectangle]
	layer3_qkv_gpu6 [label="L3_QKV_Projection_GPU6
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 18-20
GPU: 6" fillcolor=lightgreen shape=rectangle]
	layer3_attn_gpu6 [label="L3_Multi-Head_Attention_GPU6
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 6" fillcolor=lightgreen shape=rectangle]
	layer3_attn_norm_gpu6 [label="L3_Residual+LayerNorm_GPU6
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 6" fillcolor=lightgreen shape=rectangle]
	layer3_qkv_gpu7 [label="L3_QKV_Projection_GPU7
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 21-23
GPU: 7" fillcolor=lightgreen shape=rectangle]
	layer3_attn_gpu7 [label="L3_Multi-Head_Attention_GPU7
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 7" fillcolor=lightgreen shape=rectangle]
	layer3_attn_norm_gpu7 [label="L3_Residual+LayerNorm_GPU7
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 7" fillcolor=lightgreen shape=rectangle]
	layer3_qkv_gpu8 [label="L3_QKV_Projection_GPU8
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 24-26
GPU: 8" fillcolor=lightgreen shape=rectangle]
	layer3_attn_gpu8 [label="L3_Multi-Head_Attention_GPU8
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 8" fillcolor=lightgreen shape=rectangle]
	layer3_attn_norm_gpu8 [label="L3_Residual+LayerNorm_GPU8
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 8" fillcolor=lightgreen shape=rectangle]
	layer3_qkv_gpu9 [label="L3_QKV_Projection_GPU9
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 27-29
GPU: 9" fillcolor=lightgreen shape=rectangle]
	layer3_attn_gpu9 [label="L3_Multi-Head_Attention_GPU9
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 9" fillcolor=lightgreen shape=rectangle]
	layer3_attn_norm_gpu9 [label="L3_Residual+LayerNorm_GPU9
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 9" fillcolor=lightgreen shape=rectangle]
	layer3_qkv_gpu10 [label="L3_QKV_Projection_GPU10
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 30-32
GPU: 10" fillcolor=lightgreen shape=rectangle]
	layer3_attn_gpu10 [label="L3_Multi-Head_Attention_GPU10
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 10" fillcolor=lightgreen shape=rectangle]
	layer3_attn_norm_gpu10 [label="L3_Residual+LayerNorm_GPU10
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 10" fillcolor=lightgreen shape=rectangle]
	layer3_qkv_gpu11 [label="L3_QKV_Projection_GPU11
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 33-35
GPU: 11" fillcolor=lightgreen shape=rectangle]
	layer3_attn_gpu11 [label="L3_Multi-Head_Attention_GPU11
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 11" fillcolor=lightgreen shape=rectangle]
	layer3_attn_norm_gpu11 [label="L3_Residual+LayerNorm_GPU11
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 11" fillcolor=lightgreen shape=rectangle]
	layer3_attn_aggregate [label="L3_Attention_Aggregate
Input: 12×[1024,2048,4096]
Output: [1024,2048,4096]
All-Reduce across GPUs 0-11" fillcolor=lightcoral shape=diamond]
	layer3_moe_broadcast [label="L3_Broadcast_to_MoE
Input: [1024,2048,4096]
Output: 4×[1024,2048,4096]
Broadcast to GPUs 12-15" fillcolor=yellow shape=parallelogram]
	layer3_gate_gpu12 [label="L3_Gate_GPU12
Input: [1024,2048,4096]
Output: [1024,2048,16 experts]
Top-2 routing
GPU: 12" fillcolor=lightgreen shape=rectangle]
	layer3_expert12_0 [label="L3_Expert0_GPU12
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 12" fillcolor=lightgreen shape=rectangle]
	layer3_expert12_1 [label="L3_Expert1_GPU12
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 12" fillcolor=lightgreen shape=rectangle]
	layer3_expert12_2 [label="L3_Expert2_GPU12
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 12" fillcolor=lightgreen shape=rectangle]
	layer3_expert12_3 [label="L3_Expert3_GPU12
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 12" fillcolor=lightgreen shape=rectangle]
	layer3_moe_aggregate_gpu12 [label="L3_MoE_Aggregate_GPU12
Input: 4×[tokens,4096]
Output: [1024,2048,4096]
GPU: 12" fillcolor=lightgreen shape=rectangle]
	layer3_moe_norm_gpu12 [label="L3_Residual+LayerNorm_GPU12
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 12" fillcolor=lightgreen shape=rectangle]
	layer3_gate_gpu13 [label="L3_Gate_GPU13
Input: [1024,2048,4096]
Output: [1024,2048,16 experts]
Top-2 routing
GPU: 13" fillcolor=lightgreen shape=rectangle]
	layer3_expert13_4 [label="L3_Expert4_GPU13
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 13" fillcolor=lightgreen shape=rectangle]
	layer3_expert13_5 [label="L3_Expert5_GPU13
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 13" fillcolor=lightgreen shape=rectangle]
	layer3_expert13_6 [label="L3_Expert6_GPU13
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 13" fillcolor=lightgreen shape=rectangle]
	layer3_expert13_7 [label="L3_Expert7_GPU13
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 13" fillcolor=lightgreen shape=rectangle]
	layer3_moe_aggregate_gpu13 [label="L3_MoE_Aggregate_GPU13
Input: 4×[tokens,4096]
Output: [1024,2048,4096]
GPU: 13" fillcolor=lightgreen shape=rectangle]
	layer3_moe_norm_gpu13 [label="L3_Residual+LayerNorm_GPU13
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 13" fillcolor=lightgreen shape=rectangle]
	layer3_gate_gpu14 [label="L3_Gate_GPU14
Input: [1024,2048,4096]
Output: [1024,2048,16 experts]
Top-2 routing
GPU: 14" fillcolor=lightgreen shape=rectangle]
	layer3_expert14_8 [label="L3_Expert8_GPU14
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 14" fillcolor=lightgreen shape=rectangle]
	layer3_expert14_9 [label="L3_Expert9_GPU14
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 14" fillcolor=lightgreen shape=rectangle]
	layer3_expert14_10 [label="L3_Expert10_GPU14
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 14" fillcolor=lightgreen shape=rectangle]
	layer3_expert14_11 [label="L3_Expert11_GPU14
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 14" fillcolor=lightgreen shape=rectangle]
	layer3_moe_aggregate_gpu14 [label="L3_MoE_Aggregate_GPU14
Input: 4×[tokens,4096]
Output: [1024,2048,4096]
GPU: 14" fillcolor=lightgreen shape=rectangle]
	layer3_moe_norm_gpu14 [label="L3_Residual+LayerNorm_GPU14
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 14" fillcolor=lightgreen shape=rectangle]
	layer3_gate_gpu15 [label="L3_Gate_GPU15
Input: [1024,2048,4096]
Output: [1024,2048,16 experts]
Top-2 routing
GPU: 15" fillcolor=lightgreen shape=rectangle]
	layer3_expert15_12 [label="L3_Expert12_GPU15
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 15" fillcolor=lightgreen shape=rectangle]
	layer3_expert15_13 [label="L3_Expert13_GPU15
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 15" fillcolor=lightgreen shape=rectangle]
	layer3_expert15_14 [label="L3_Expert14_GPU15
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 15" fillcolor=lightgreen shape=rectangle]
	layer3_expert15_15 [label="L3_Expert15_GPU15
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 15" fillcolor=lightgreen shape=rectangle]
	layer3_moe_aggregate_gpu15 [label="L3_MoE_Aggregate_GPU15
Input: 4×[tokens,4096]
Output: [1024,2048,4096]
GPU: 15" fillcolor=lightgreen shape=rectangle]
	layer3_moe_norm_gpu15 [label="L3_Residual+LayerNorm_GPU15
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 15" fillcolor=lightgreen shape=rectangle]
	layer4_qkv_gpu0 [label="L4_QKV_Projection_GPU0
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 0-2
GPU: 0" fillcolor=lightgreen shape=rectangle]
	layer4_attn_gpu0 [label="L4_Multi-Head_Attention_GPU0
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 0" fillcolor=lightgreen shape=rectangle]
	layer4_attn_norm_gpu0 [label="L4_Residual+LayerNorm_GPU0
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 0" fillcolor=lightgreen shape=rectangle]
	layer4_qkv_gpu1 [label="L4_QKV_Projection_GPU1
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 3-5
GPU: 1" fillcolor=lightgreen shape=rectangle]
	layer4_attn_gpu1 [label="L4_Multi-Head_Attention_GPU1
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 1" fillcolor=lightgreen shape=rectangle]
	layer4_attn_norm_gpu1 [label="L4_Residual+LayerNorm_GPU1
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 1" fillcolor=lightgreen shape=rectangle]
	layer4_qkv_gpu2 [label="L4_QKV_Projection_GPU2
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 6-8
GPU: 2" fillcolor=lightgreen shape=rectangle]
	layer4_attn_gpu2 [label="L4_Multi-Head_Attention_GPU2
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 2" fillcolor=lightgreen shape=rectangle]
	layer4_attn_norm_gpu2 [label="L4_Residual+LayerNorm_GPU2
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 2" fillcolor=lightgreen shape=rectangle]
	layer4_qkv_gpu3 [label="L4_QKV_Projection_GPU3
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 9-11
GPU: 3" fillcolor=lightgreen shape=rectangle]
	layer4_attn_gpu3 [label="L4_Multi-Head_Attention_GPU3
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 3" fillcolor=lightgreen shape=rectangle]
	layer4_attn_norm_gpu3 [label="L4_Residual+LayerNorm_GPU3
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 3" fillcolor=lightgreen shape=rectangle]
	layer4_qkv_gpu4 [label="L4_QKV_Projection_GPU4
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 12-14
GPU: 4" fillcolor=lightgreen shape=rectangle]
	layer4_attn_gpu4 [label="L4_Multi-Head_Attention_GPU4
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 4" fillcolor=lightgreen shape=rectangle]
	layer4_attn_norm_gpu4 [label="L4_Residual+LayerNorm_GPU4
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 4" fillcolor=lightgreen shape=rectangle]
	layer4_qkv_gpu5 [label="L4_QKV_Projection_GPU5
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 15-17
GPU: 5" fillcolor=lightgreen shape=rectangle]
	layer4_attn_gpu5 [label="L4_Multi-Head_Attention_GPU5
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 5" fillcolor=lightgreen shape=rectangle]
	layer4_attn_norm_gpu5 [label="L4_Residual+LayerNorm_GPU5
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 5" fillcolor=lightgreen shape=rectangle]
	layer4_qkv_gpu6 [label="L4_QKV_Projection_GPU6
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 18-20
GPU: 6" fillcolor=lightgreen shape=rectangle]
	layer4_attn_gpu6 [label="L4_Multi-Head_Attention_GPU6
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 6" fillcolor=lightgreen shape=rectangle]
	layer4_attn_norm_gpu6 [label="L4_Residual+LayerNorm_GPU6
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 6" fillcolor=lightgreen shape=rectangle]
	layer4_qkv_gpu7 [label="L4_QKV_Projection_GPU7
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 21-23
GPU: 7" fillcolor=lightgreen shape=rectangle]
	layer4_attn_gpu7 [label="L4_Multi-Head_Attention_GPU7
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 7" fillcolor=lightgreen shape=rectangle]
	layer4_attn_norm_gpu7 [label="L4_Residual+LayerNorm_GPU7
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 7" fillcolor=lightgreen shape=rectangle]
	layer4_qkv_gpu8 [label="L4_QKV_Projection_GPU8
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 24-26
GPU: 8" fillcolor=lightgreen shape=rectangle]
	layer4_attn_gpu8 [label="L4_Multi-Head_Attention_GPU8
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 8" fillcolor=lightgreen shape=rectangle]
	layer4_attn_norm_gpu8 [label="L4_Residual+LayerNorm_GPU8
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 8" fillcolor=lightgreen shape=rectangle]
	layer4_qkv_gpu9 [label="L4_QKV_Projection_GPU9
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 27-29
GPU: 9" fillcolor=lightgreen shape=rectangle]
	layer4_attn_gpu9 [label="L4_Multi-Head_Attention_GPU9
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 9" fillcolor=lightgreen shape=rectangle]
	layer4_attn_norm_gpu9 [label="L4_Residual+LayerNorm_GPU9
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 9" fillcolor=lightgreen shape=rectangle]
	layer4_qkv_gpu10 [label="L4_QKV_Projection_GPU10
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 30-32
GPU: 10" fillcolor=lightgreen shape=rectangle]
	layer4_attn_gpu10 [label="L4_Multi-Head_Attention_GPU10
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 10" fillcolor=lightgreen shape=rectangle]
	layer4_attn_norm_gpu10 [label="L4_Residual+LayerNorm_GPU10
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 10" fillcolor=lightgreen shape=rectangle]
	layer4_qkv_gpu11 [label="L4_QKV_Projection_GPU11
Input: [1024, 2048, 4096]
Output: [1024, 2048, 3*4096]
Heads: 33-35
GPU: 11" fillcolor=lightgreen shape=rectangle]
	layer4_attn_gpu11 [label="L4_Multi-Head_Attention_GPU11
Input: [1024, 2048, 3*4096]
Output: [1024, 2048, 4096]
GPU: 11" fillcolor=lightgreen shape=rectangle]
	layer4_attn_norm_gpu11 [label="L4_Residual+LayerNorm_GPU11
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 11" fillcolor=lightgreen shape=rectangle]
	layer4_attn_aggregate [label="L4_Attention_Aggregate
Input: 12×[1024,2048,4096]
Output: [1024,2048,4096]
All-Reduce across GPUs 0-11" fillcolor=lightcoral shape=diamond]
	layer4_moe_broadcast [label="L4_Broadcast_to_MoE
Input: [1024,2048,4096]
Output: 4×[1024,2048,4096]
Broadcast to GPUs 12-15" fillcolor=yellow shape=parallelogram]
	layer4_gate_gpu12 [label="L4_Gate_GPU12
Input: [1024,2048,4096]
Output: [1024,2048,16 experts]
Top-2 routing
GPU: 12" fillcolor=lightgreen shape=rectangle]
	layer4_expert12_0 [label="L4_Expert0_GPU12
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 12" fillcolor=lightgreen shape=rectangle]
	layer4_expert12_1 [label="L4_Expert1_GPU12
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 12" fillcolor=lightgreen shape=rectangle]
	layer4_expert12_2 [label="L4_Expert2_GPU12
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 12" fillcolor=lightgreen shape=rectangle]
	layer4_expert12_3 [label="L4_Expert3_GPU12
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 12" fillcolor=lightgreen shape=rectangle]
	layer4_moe_aggregate_gpu12 [label="L4_MoE_Aggregate_GPU12
Input: 4×[tokens,4096]
Output: [1024,2048,4096]
GPU: 12" fillcolor=lightgreen shape=rectangle]
	layer4_moe_norm_gpu12 [label="L4_Residual+LayerNorm_GPU12
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 12" fillcolor=lightgreen shape=rectangle]
	layer4_gate_gpu13 [label="L4_Gate_GPU13
Input: [1024,2048,4096]
Output: [1024,2048,16 experts]
Top-2 routing
GPU: 13" fillcolor=lightgreen shape=rectangle]
	layer4_expert13_4 [label="L4_Expert4_GPU13
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 13" fillcolor=lightgreen shape=rectangle]
	layer4_expert13_5 [label="L4_Expert5_GPU13
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 13" fillcolor=lightgreen shape=rectangle]
	layer4_expert13_6 [label="L4_Expert6_GPU13
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 13" fillcolor=lightgreen shape=rectangle]
	layer4_expert13_7 [label="L4_Expert7_GPU13
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 13" fillcolor=lightgreen shape=rectangle]
	layer4_moe_aggregate_gpu13 [label="L4_MoE_Aggregate_GPU13
Input: 4×[tokens,4096]
Output: [1024,2048,4096]
GPU: 13" fillcolor=lightgreen shape=rectangle]
	layer4_moe_norm_gpu13 [label="L4_Residual+LayerNorm_GPU13
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 13" fillcolor=lightgreen shape=rectangle]
	layer4_gate_gpu14 [label="L4_Gate_GPU14
Input: [1024,2048,4096]
Output: [1024,2048,16 experts]
Top-2 routing
GPU: 14" fillcolor=lightgreen shape=rectangle]
	layer4_expert14_8 [label="L4_Expert8_GPU14
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 14" fillcolor=lightgreen shape=rectangle]
	layer4_expert14_9 [label="L4_Expert9_GPU14
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 14" fillcolor=lightgreen shape=rectangle]
	layer4_expert14_10 [label="L4_Expert10_GPU14
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 14" fillcolor=lightgreen shape=rectangle]
	layer4_expert14_11 [label="L4_Expert11_GPU14
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 14" fillcolor=lightgreen shape=rectangle]
	layer4_moe_aggregate_gpu14 [label="L4_MoE_Aggregate_GPU14
Input: 4×[tokens,4096]
Output: [1024,2048,4096]
GPU: 14" fillcolor=lightgreen shape=rectangle]
	layer4_moe_norm_gpu14 [label="L4_Residual+LayerNorm_GPU14
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 14" fillcolor=lightgreen shape=rectangle]
	layer4_gate_gpu15 [label="L4_Gate_GPU15
Input: [1024,2048,4096]
Output: [1024,2048,16 experts]
Top-2 routing
GPU: 15" fillcolor=lightgreen shape=rectangle]
	layer4_expert15_12 [label="L4_Expert12_GPU15
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 15" fillcolor=lightgreen shape=rectangle]
	layer4_expert15_13 [label="L4_Expert13_GPU15
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 15" fillcolor=lightgreen shape=rectangle]
	layer4_expert15_14 [label="L4_Expert14_GPU15
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 15" fillcolor=lightgreen shape=rectangle]
	layer4_expert15_15 [label="L4_Expert15_GPU15
Input: [tokens,4096]
Output: [tokens,4096]
Expert hidden: 16384
GPU: 15" fillcolor=lightgreen shape=rectangle]
	layer4_moe_aggregate_gpu15 [label="L4_MoE_Aggregate_GPU15
Input: 4×[tokens,4096]
Output: [1024,2048,4096]
GPU: 15" fillcolor=lightgreen shape=rectangle]
	layer4_moe_norm_gpu15 [label="L4_Residual+LayerNorm_GPU15
Input: [1024,2048,4096]x2
Output: [1024,2048,4096]
GPU: 15" fillcolor=lightgreen shape=rectangle]
	output [label="OUTPUT
Input: [batch_size=1024, seq_len=2048, hidden=4096]
GPU: 12-15" fillcolor=lightblue shape=ellipse]
	input -> layer1_qkv_gpu0
	input -> layer1_qkv_gpu1
	input -> layer1_qkv_gpu2
	input -> layer1_qkv_gpu3
	input -> layer1_qkv_gpu4
	input -> layer1_qkv_gpu5
	input -> layer1_qkv_gpu6
	input -> layer1_qkv_gpu7
	input -> layer1_qkv_gpu8
	input -> layer1_qkv_gpu9
	input -> layer1_qkv_gpu10
	input -> layer1_qkv_gpu11
	layer1_qkv_gpu0 -> layer1_attn_gpu0
	layer1_attn_gpu0 -> layer1_attn_norm_gpu0
	layer1_attn_norm_gpu0 -> layer1_attn_aggregate
	layer1_qkv_gpu1 -> layer1_attn_gpu1
	layer1_attn_gpu1 -> layer1_attn_norm_gpu1
	layer1_attn_norm_gpu1 -> layer1_attn_aggregate
	layer1_qkv_gpu2 -> layer1_attn_gpu2
	layer1_attn_gpu2 -> layer1_attn_norm_gpu2
	layer1_attn_norm_gpu2 -> layer1_attn_aggregate
	layer1_qkv_gpu3 -> layer1_attn_gpu3
	layer1_attn_gpu3 -> layer1_attn_norm_gpu3
	layer1_attn_norm_gpu3 -> layer1_attn_aggregate
	layer1_qkv_gpu4 -> layer1_attn_gpu4
	layer1_attn_gpu4 -> layer1_attn_norm_gpu4
	layer1_attn_norm_gpu4 -> layer1_attn_aggregate
	layer1_qkv_gpu5 -> layer1_attn_gpu5
	layer1_attn_gpu5 -> layer1_attn_norm_gpu5
	layer1_attn_norm_gpu5 -> layer1_attn_aggregate
	layer1_qkv_gpu6 -> layer1_attn_gpu6
	layer1_attn_gpu6 -> layer1_attn_norm_gpu6
	layer1_attn_norm_gpu6 -> layer1_attn_aggregate
	layer1_qkv_gpu7 -> layer1_attn_gpu7
	layer1_attn_gpu7 -> layer1_attn_norm_gpu7
	layer1_attn_norm_gpu7 -> layer1_attn_aggregate
	layer1_qkv_gpu8 -> layer1_attn_gpu8
	layer1_attn_gpu8 -> layer1_attn_norm_gpu8
	layer1_attn_norm_gpu8 -> layer1_attn_aggregate
	layer1_qkv_gpu9 -> layer1_attn_gpu9
	layer1_attn_gpu9 -> layer1_attn_norm_gpu9
	layer1_attn_norm_gpu9 -> layer1_attn_aggregate
	layer1_qkv_gpu10 -> layer1_attn_gpu10
	layer1_attn_gpu10 -> layer1_attn_norm_gpu10
	layer1_attn_norm_gpu10 -> layer1_attn_aggregate
	layer1_qkv_gpu11 -> layer1_attn_gpu11
	layer1_attn_gpu11 -> layer1_attn_norm_gpu11
	layer1_attn_norm_gpu11 -> layer1_attn_aggregate
	layer1_attn_aggregate -> layer1_moe_broadcast
	layer1_moe_broadcast -> layer1_gate_gpu12
	layer1_gate_gpu12 -> layer1_expert12_0 [style=dashed]
	layer1_gate_gpu12 -> layer1_expert12_1 [style=dashed]
	layer1_gate_gpu12 -> layer1_expert12_2 [style=dashed]
	layer1_gate_gpu12 -> layer1_expert12_3 [style=dashed]
	layer1_expert12_0 -> layer1_moe_aggregate_gpu12
	layer1_expert12_1 -> layer1_moe_aggregate_gpu12
	layer1_expert12_2 -> layer1_moe_aggregate_gpu12
	layer1_expert12_3 -> layer1_moe_aggregate_gpu12
	layer1_moe_aggregate_gpu12 -> layer1_moe_norm_gpu12
	layer1_moe_broadcast -> layer1_gate_gpu13
	layer1_gate_gpu13 -> layer1_expert13_4 [style=dashed]
	layer1_gate_gpu13 -> layer1_expert13_5 [style=dashed]
	layer1_gate_gpu13 -> layer1_expert13_6 [style=dashed]
	layer1_gate_gpu13 -> layer1_expert13_7 [style=dashed]
	layer1_expert13_4 -> layer1_moe_aggregate_gpu13
	layer1_expert13_5 -> layer1_moe_aggregate_gpu13
	layer1_expert13_6 -> layer1_moe_aggregate_gpu13
	layer1_expert13_7 -> layer1_moe_aggregate_gpu13
	layer1_moe_aggregate_gpu13 -> layer1_moe_norm_gpu13
	layer1_moe_broadcast -> layer1_gate_gpu14
	layer1_gate_gpu14 -> layer1_expert14_8 [style=dashed]
	layer1_gate_gpu14 -> layer1_expert14_9 [style=dashed]
	layer1_gate_gpu14 -> layer1_expert14_10 [style=dashed]
	layer1_gate_gpu14 -> layer1_expert14_11 [style=dashed]
	layer1_expert14_8 -> layer1_moe_aggregate_gpu14
	layer1_expert14_9 -> layer1_moe_aggregate_gpu14
	layer1_expert14_10 -> layer1_moe_aggregate_gpu14
	layer1_expert14_11 -> layer1_moe_aggregate_gpu14
	layer1_moe_aggregate_gpu14 -> layer1_moe_norm_gpu14
	layer1_moe_broadcast -> layer1_gate_gpu15
	layer1_gate_gpu15 -> layer1_expert15_12 [style=dashed]
	layer1_gate_gpu15 -> layer1_expert15_13 [style=dashed]
	layer1_gate_gpu15 -> layer1_expert15_14 [style=dashed]
	layer1_gate_gpu15 -> layer1_expert15_15 [style=dashed]
	layer1_expert15_12 -> layer1_moe_aggregate_gpu15
	layer1_expert15_13 -> layer1_moe_aggregate_gpu15
	layer1_expert15_14 -> layer1_moe_aggregate_gpu15
	layer1_expert15_15 -> layer1_moe_aggregate_gpu15
	layer1_moe_aggregate_gpu15 -> layer1_moe_norm_gpu15
	layer1_moe_norm_gpu12 -> layer2_qkv_gpu0
	layer1_moe_norm_gpu12 -> layer2_qkv_gpu1
	layer1_moe_norm_gpu12 -> layer2_qkv_gpu2
	layer1_moe_norm_gpu12 -> layer2_qkv_gpu3
	layer1_moe_norm_gpu12 -> layer2_qkv_gpu4
	layer1_moe_norm_gpu12 -> layer2_qkv_gpu5
	layer1_moe_norm_gpu12 -> layer2_qkv_gpu6
	layer1_moe_norm_gpu12 -> layer2_qkv_gpu7
	layer1_moe_norm_gpu12 -> layer2_qkv_gpu8
	layer1_moe_norm_gpu12 -> layer2_qkv_gpu9
	layer1_moe_norm_gpu12 -> layer2_qkv_gpu10
	layer1_moe_norm_gpu12 -> layer2_qkv_gpu11
	layer1_moe_norm_gpu13 -> layer2_qkv_gpu0
	layer1_moe_norm_gpu13 -> layer2_qkv_gpu1
	layer1_moe_norm_gpu13 -> layer2_qkv_gpu2
	layer1_moe_norm_gpu13 -> layer2_qkv_gpu3
	layer1_moe_norm_gpu13 -> layer2_qkv_gpu4
	layer1_moe_norm_gpu13 -> layer2_qkv_gpu5
	layer1_moe_norm_gpu13 -> layer2_qkv_gpu6
	layer1_moe_norm_gpu13 -> layer2_qkv_gpu7
	layer1_moe_norm_gpu13 -> layer2_qkv_gpu8
	layer1_moe_norm_gpu13 -> layer2_qkv_gpu9
	layer1_moe_norm_gpu13 -> layer2_qkv_gpu10
	layer1_moe_norm_gpu13 -> layer2_qkv_gpu11
	layer1_moe_norm_gpu14 -> layer2_qkv_gpu0
	layer1_moe_norm_gpu14 -> layer2_qkv_gpu1
	layer1_moe_norm_gpu14 -> layer2_qkv_gpu2
	layer1_moe_norm_gpu14 -> layer2_qkv_gpu3
	layer1_moe_norm_gpu14 -> layer2_qkv_gpu4
	layer1_moe_norm_gpu14 -> layer2_qkv_gpu5
	layer1_moe_norm_gpu14 -> layer2_qkv_gpu6
	layer1_moe_norm_gpu14 -> layer2_qkv_gpu7
	layer1_moe_norm_gpu14 -> layer2_qkv_gpu8
	layer1_moe_norm_gpu14 -> layer2_qkv_gpu9
	layer1_moe_norm_gpu14 -> layer2_qkv_gpu10
	layer1_moe_norm_gpu14 -> layer2_qkv_gpu11
	layer1_moe_norm_gpu15 -> layer2_qkv_gpu0
	layer1_moe_norm_gpu15 -> layer2_qkv_gpu1
	layer1_moe_norm_gpu15 -> layer2_qkv_gpu2
	layer1_moe_norm_gpu15 -> layer2_qkv_gpu3
	layer1_moe_norm_gpu15 -> layer2_qkv_gpu4
	layer1_moe_norm_gpu15 -> layer2_qkv_gpu5
	layer1_moe_norm_gpu15 -> layer2_qkv_gpu6
	layer1_moe_norm_gpu15 -> layer2_qkv_gpu7
	layer1_moe_norm_gpu15 -> layer2_qkv_gpu8
	layer1_moe_norm_gpu15 -> layer2_qkv_gpu9
	layer1_moe_norm_gpu15 -> layer2_qkv_gpu10
	layer1_moe_norm_gpu15 -> layer2_qkv_gpu11
	layer2_qkv_gpu0 -> layer2_attn_gpu0
	layer2_attn_gpu0 -> layer2_attn_norm_gpu0
	layer2_attn_norm_gpu0 -> layer2_attn_aggregate
	layer2_qkv_gpu1 -> layer2_attn_gpu1
	layer2_attn_gpu1 -> layer2_attn_norm_gpu1
	layer2_attn_norm_gpu1 -> layer2_attn_aggregate
	layer2_qkv_gpu2 -> layer2_attn_gpu2
	layer2_attn_gpu2 -> layer2_attn_norm_gpu2
	layer2_attn_norm_gpu2 -> layer2_attn_aggregate
	layer2_qkv_gpu3 -> layer2_attn_gpu3
	layer2_attn_gpu3 -> layer2_attn_norm_gpu3
	layer2_attn_norm_gpu3 -> layer2_attn_aggregate
	layer2_qkv_gpu4 -> layer2_attn_gpu4
	layer2_attn_gpu4 -> layer2_attn_norm_gpu4
	layer2_attn_norm_gpu4 -> layer2_attn_aggregate
	layer2_qkv_gpu5 -> layer2_attn_gpu5
	layer2_attn_gpu5 -> layer2_attn_norm_gpu5
	layer2_attn_norm_gpu5 -> layer2_attn_aggregate
	layer2_qkv_gpu6 -> layer2_attn_gpu6
	layer2_attn_gpu6 -> layer2_attn_norm_gpu6
	layer2_attn_norm_gpu6 -> layer2_attn_aggregate
	layer2_qkv_gpu7 -> layer2_attn_gpu7
	layer2_attn_gpu7 -> layer2_attn_norm_gpu7
	layer2_attn_norm_gpu7 -> layer2_attn_aggregate
	layer2_qkv_gpu8 -> layer2_attn_gpu8
	layer2_attn_gpu8 -> layer2_attn_norm_gpu8
	layer2_attn_norm_gpu8 -> layer2_attn_aggregate
	layer2_qkv_gpu9 -> layer2_attn_gpu9
	layer2_attn_gpu9 -> layer2_attn_norm_gpu9
	layer2_attn_norm_gpu9 -> layer2_attn_aggregate
	layer2_qkv_gpu10 -> layer2_attn_gpu10
	layer2_attn_gpu10 -> layer2_attn_norm_gpu10
	layer2_attn_norm_gpu10 -> layer2_attn_aggregate
	layer2_qkv_gpu11 -> layer2_attn_gpu11
	layer2_attn_gpu11 -> layer2_attn_norm_gpu11
	layer2_attn_norm_gpu11 -> layer2_attn_aggregate
	layer2_attn_aggregate -> layer2_moe_broadcast
	layer2_moe_broadcast -> layer2_gate_gpu12
	layer2_gate_gpu12 -> layer2_expert12_0 [style=dashed]
	layer2_gate_gpu12 -> layer2_expert12_1 [style=dashed]
	layer2_gate_gpu12 -> layer2_expert12_2 [style=dashed]
	layer2_gate_gpu12 -> layer2_expert12_3 [style=dashed]
	layer2_expert12_0 -> layer2_moe_aggregate_gpu12
	layer2_expert12_1 -> layer2_moe_aggregate_gpu12
	layer2_expert12_2 -> layer2_moe_aggregate_gpu12
	layer2_expert12_3 -> layer2_moe_aggregate_gpu12
	layer2_moe_aggregate_gpu12 -> layer2_moe_norm_gpu12
	layer2_moe_broadcast -> layer2_gate_gpu13
	layer2_gate_gpu13 -> layer2_expert13_4 [style=dashed]
	layer2_gate_gpu13 -> layer2_expert13_5 [style=dashed]
	layer2_gate_gpu13 -> layer2_expert13_6 [style=dashed]
	layer2_gate_gpu13 -> layer2_expert13_7 [style=dashed]
	layer2_expert13_4 -> layer2_moe_aggregate_gpu13
	layer2_expert13_5 -> layer2_moe_aggregate_gpu13
	layer2_expert13_6 -> layer2_moe_aggregate_gpu13
	layer2_expert13_7 -> layer2_moe_aggregate_gpu13
	layer2_moe_aggregate_gpu13 -> layer2_moe_norm_gpu13
	layer2_moe_broadcast -> layer2_gate_gpu14
	layer2_gate_gpu14 -> layer2_expert14_8 [style=dashed]
	layer2_gate_gpu14 -> layer2_expert14_9 [style=dashed]
	layer2_gate_gpu14 -> layer2_expert14_10 [style=dashed]
	layer2_gate_gpu14 -> layer2_expert14_11 [style=dashed]
	layer2_expert14_8 -> layer2_moe_aggregate_gpu14
	layer2_expert14_9 -> layer2_moe_aggregate_gpu14
	layer2_expert14_10 -> layer2_moe_aggregate_gpu14
	layer2_expert14_11 -> layer2_moe_aggregate_gpu14
	layer2_moe_aggregate_gpu14 -> layer2_moe_norm_gpu14
	layer2_moe_broadcast -> layer2_gate_gpu15
	layer2_gate_gpu15 -> layer2_expert15_12 [style=dashed]
	layer2_gate_gpu15 -> layer2_expert15_13 [style=dashed]
	layer2_gate_gpu15 -> layer2_expert15_14 [style=dashed]
	layer2_gate_gpu15 -> layer2_expert15_15 [style=dashed]
	layer2_expert15_12 -> layer2_moe_aggregate_gpu15
	layer2_expert15_13 -> layer2_moe_aggregate_gpu15
	layer2_expert15_14 -> layer2_moe_aggregate_gpu15
	layer2_expert15_15 -> layer2_moe_aggregate_gpu15
	layer2_moe_aggregate_gpu15 -> layer2_moe_norm_gpu15
	layer2_moe_norm_gpu12 -> layer3_qkv_gpu0
	layer2_moe_norm_gpu12 -> layer3_qkv_gpu1
	layer2_moe_norm_gpu12 -> layer3_qkv_gpu2
	layer2_moe_norm_gpu12 -> layer3_qkv_gpu3
	layer2_moe_norm_gpu12 -> layer3_qkv_gpu4
	layer2_moe_norm_gpu12 -> layer3_qkv_gpu5
	layer2_moe_norm_gpu12 -> layer3_qkv_gpu6
	layer2_moe_norm_gpu12 -> layer3_qkv_gpu7
	layer2_moe_norm_gpu12 -> layer3_qkv_gpu8
	layer2_moe_norm_gpu12 -> layer3_qkv_gpu9
	layer2_moe_norm_gpu12 -> layer3_qkv_gpu10
	layer2_moe_norm_gpu12 -> layer3_qkv_gpu11
	layer2_moe_norm_gpu13 -> layer3_qkv_gpu0
	layer2_moe_norm_gpu13 -> layer3_qkv_gpu1
	layer2_moe_norm_gpu13 -> layer3_qkv_gpu2
	layer2_moe_norm_gpu13 -> layer3_qkv_gpu3
	layer2_moe_norm_gpu13 -> layer3_qkv_gpu4
	layer2_moe_norm_gpu13 -> layer3_qkv_gpu5
	layer2_moe_norm_gpu13 -> layer3_qkv_gpu6
	layer2_moe_norm_gpu13 -> layer3_qkv_gpu7
	layer2_moe_norm_gpu13 -> layer3_qkv_gpu8
	layer2_moe_norm_gpu13 -> layer3_qkv_gpu9
	layer2_moe_norm_gpu13 -> layer3_qkv_gpu10
	layer2_moe_norm_gpu13 -> layer3_qkv_gpu11
	layer2_moe_norm_gpu14 -> layer3_qkv_gpu0
	layer2_moe_norm_gpu14 -> layer3_qkv_gpu1
	layer2_moe_norm_gpu14 -> layer3_qkv_gpu2
	layer2_moe_norm_gpu14 -> layer3_qkv_gpu3
	layer2_moe_norm_gpu14 -> layer3_qkv_gpu4
	layer2_moe_norm_gpu14 -> layer3_qkv_gpu5
	layer2_moe_norm_gpu14 -> layer3_qkv_gpu6
	layer2_moe_norm_gpu14 -> layer3_qkv_gpu7
	layer2_moe_norm_gpu14 -> layer3_qkv_gpu8
	layer2_moe_norm_gpu14 -> layer3_qkv_gpu9
	layer2_moe_norm_gpu14 -> layer3_qkv_gpu10
	layer2_moe_norm_gpu14 -> layer3_qkv_gpu11
	layer2_moe_norm_gpu15 -> layer3_qkv_gpu0
	layer2_moe_norm_gpu15 -> layer3_qkv_gpu1
	layer2_moe_norm_gpu15 -> layer3_qkv_gpu2
	layer2_moe_norm_gpu15 -> layer3_qkv_gpu3
	layer2_moe_norm_gpu15 -> layer3_qkv_gpu4
	layer2_moe_norm_gpu15 -> layer3_qkv_gpu5
	layer2_moe_norm_gpu15 -> layer3_qkv_gpu6
	layer2_moe_norm_gpu15 -> layer3_qkv_gpu7
	layer2_moe_norm_gpu15 -> layer3_qkv_gpu8
	layer2_moe_norm_gpu15 -> layer3_qkv_gpu9
	layer2_moe_norm_gpu15 -> layer3_qkv_gpu10
	layer2_moe_norm_gpu15 -> layer3_qkv_gpu11
	layer3_qkv_gpu0 -> layer3_attn_gpu0
	layer3_attn_gpu0 -> layer3_attn_norm_gpu0
	layer3_attn_norm_gpu0 -> layer3_attn_aggregate
	layer3_qkv_gpu1 -> layer3_attn_gpu1
	layer3_attn_gpu1 -> layer3_attn_norm_gpu1
	layer3_attn_norm_gpu1 -> layer3_attn_aggregate
	layer3_qkv_gpu2 -> layer3_attn_gpu2
	layer3_attn_gpu2 -> layer3_attn_norm_gpu2
	layer3_attn_norm_gpu2 -> layer3_attn_aggregate
	layer3_qkv_gpu3 -> layer3_attn_gpu3
	layer3_attn_gpu3 -> layer3_attn_norm_gpu3
	layer3_attn_norm_gpu3 -> layer3_attn_aggregate
	layer3_qkv_gpu4 -> layer3_attn_gpu4
	layer3_attn_gpu4 -> layer3_attn_norm_gpu4
	layer3_attn_norm_gpu4 -> layer3_attn_aggregate
	layer3_qkv_gpu5 -> layer3_attn_gpu5
	layer3_attn_gpu5 -> layer3_attn_norm_gpu5
	layer3_attn_norm_gpu5 -> layer3_attn_aggregate
	layer3_qkv_gpu6 -> layer3_attn_gpu6
	layer3_attn_gpu6 -> layer3_attn_norm_gpu6
	layer3_attn_norm_gpu6 -> layer3_attn_aggregate
	layer3_qkv_gpu7 -> layer3_attn_gpu7
	layer3_attn_gpu7 -> layer3_attn_norm_gpu7
	layer3_attn_norm_gpu7 -> layer3_attn_aggregate
	layer3_qkv_gpu8 -> layer3_attn_gpu8
	layer3_attn_gpu8 -> layer3_attn_norm_gpu8
	layer3_attn_norm_gpu8 -> layer3_attn_aggregate
	layer3_qkv_gpu9 -> layer3_attn_gpu9
	layer3_attn_gpu9 -> layer3_attn_norm_gpu9
	layer3_attn_norm_gpu9 -> layer3_attn_aggregate
	layer3_qkv_gpu10 -> layer3_attn_gpu10
	layer3_attn_gpu10 -> layer3_attn_norm_gpu10
	layer3_attn_norm_gpu10 -> layer3_attn_aggregate
	layer3_qkv_gpu11 -> layer3_attn_gpu11
	layer3_attn_gpu11 -> layer3_attn_norm_gpu11
	layer3_attn_norm_gpu11 -> layer3_attn_aggregate
	layer3_attn_aggregate -> layer3_moe_broadcast
	layer3_moe_broadcast -> layer3_gate_gpu12
	layer3_gate_gpu12 -> layer3_expert12_0 [style=dashed]
	layer3_gate_gpu12 -> layer3_expert12_1 [style=dashed]
	layer3_gate_gpu12 -> layer3_expert12_2 [style=dashed]
	layer3_gate_gpu12 -> layer3_expert12_3 [style=dashed]
	layer3_expert12_0 -> layer3_moe_aggregate_gpu12
	layer3_expert12_1 -> layer3_moe_aggregate_gpu12
	layer3_expert12_2 -> layer3_moe_aggregate_gpu12
	layer3_expert12_3 -> layer3_moe_aggregate_gpu12
	layer3_moe_aggregate_gpu12 -> layer3_moe_norm_gpu12
	layer3_moe_broadcast -> layer3_gate_gpu13
	layer3_gate_gpu13 -> layer3_expert13_4 [style=dashed]
	layer3_gate_gpu13 -> layer3_expert13_5 [style=dashed]
	layer3_gate_gpu13 -> layer3_expert13_6 [style=dashed]
	layer3_gate_gpu13 -> layer3_expert13_7 [style=dashed]
	layer3_expert13_4 -> layer3_moe_aggregate_gpu13
	layer3_expert13_5 -> layer3_moe_aggregate_gpu13
	layer3_expert13_6 -> layer3_moe_aggregate_gpu13
	layer3_expert13_7 -> layer3_moe_aggregate_gpu13
	layer3_moe_aggregate_gpu13 -> layer3_moe_norm_gpu13
	layer3_moe_broadcast -> layer3_gate_gpu14
	layer3_gate_gpu14 -> layer3_expert14_8 [style=dashed]
	layer3_gate_gpu14 -> layer3_expert14_9 [style=dashed]
	layer3_gate_gpu14 -> layer3_expert14_10 [style=dashed]
	layer3_gate_gpu14 -> layer3_expert14_11 [style=dashed]
	layer3_expert14_8 -> layer3_moe_aggregate_gpu14
	layer3_expert14_9 -> layer3_moe_aggregate_gpu14
	layer3_expert14_10 -> layer3_moe_aggregate_gpu14
	layer3_expert14_11 -> layer3_moe_aggregate_gpu14
	layer3_moe_aggregate_gpu14 -> layer3_moe_norm_gpu14
	layer3_moe_broadcast -> layer3_gate_gpu15
	layer3_gate_gpu15 -> layer3_expert15_12 [style=dashed]
	layer3_gate_gpu15 -> layer3_expert15_13 [style=dashed]
	layer3_gate_gpu15 -> layer3_expert15_14 [style=dashed]
	layer3_gate_gpu15 -> layer3_expert15_15 [style=dashed]
	layer3_expert15_12 -> layer3_moe_aggregate_gpu15
	layer3_expert15_13 -> layer3_moe_aggregate_gpu15
	layer3_expert15_14 -> layer3_moe_aggregate_gpu15
	layer3_expert15_15 -> layer3_moe_aggregate_gpu15
	layer3_moe_aggregate_gpu15 -> layer3_moe_norm_gpu15
	layer3_moe_norm_gpu12 -> layer4_qkv_gpu0
	layer3_moe_norm_gpu12 -> layer4_qkv_gpu1
	layer3_moe_norm_gpu12 -> layer4_qkv_gpu2
	layer3_moe_norm_gpu12 -> layer4_qkv_gpu3
	layer3_moe_norm_gpu12 -> layer4_qkv_gpu4
	layer3_moe_norm_gpu12 -> layer4_qkv_gpu5
	layer3_moe_norm_gpu12 -> layer4_qkv_gpu6
	layer3_moe_norm_gpu12 -> layer4_qkv_gpu7
	layer3_moe_norm_gpu12 -> layer4_qkv_gpu8
	layer3_moe_norm_gpu12 -> layer4_qkv_gpu9
	layer3_moe_norm_gpu12 -> layer4_qkv_gpu10
	layer3_moe_norm_gpu12 -> layer4_qkv_gpu11
	layer3_moe_norm_gpu13 -> layer4_qkv_gpu0
	layer3_moe_norm_gpu13 -> layer4_qkv_gpu1
	layer3_moe_norm_gpu13 -> layer4_qkv_gpu2
	layer3_moe_norm_gpu13 -> layer4_qkv_gpu3
	layer3_moe_norm_gpu13 -> layer4_qkv_gpu4
	layer3_moe_norm_gpu13 -> layer4_qkv_gpu5
	layer3_moe_norm_gpu13 -> layer4_qkv_gpu6
	layer3_moe_norm_gpu13 -> layer4_qkv_gpu7
	layer3_moe_norm_gpu13 -> layer4_qkv_gpu8
	layer3_moe_norm_gpu13 -> layer4_qkv_gpu9
	layer3_moe_norm_gpu13 -> layer4_qkv_gpu10
	layer3_moe_norm_gpu13 -> layer4_qkv_gpu11
	layer3_moe_norm_gpu14 -> layer4_qkv_gpu0
	layer3_moe_norm_gpu14 -> layer4_qkv_gpu1
	layer3_moe_norm_gpu14 -> layer4_qkv_gpu2
	layer3_moe_norm_gpu14 -> layer4_qkv_gpu3
	layer3_moe_norm_gpu14 -> layer4_qkv_gpu4
	layer3_moe_norm_gpu14 -> layer4_qkv_gpu5
	layer3_moe_norm_gpu14 -> layer4_qkv_gpu6
	layer3_moe_norm_gpu14 -> layer4_qkv_gpu7
	layer3_moe_norm_gpu14 -> layer4_qkv_gpu8
	layer3_moe_norm_gpu14 -> layer4_qkv_gpu9
	layer3_moe_norm_gpu14 -> layer4_qkv_gpu10
	layer3_moe_norm_gpu14 -> layer4_qkv_gpu11
	layer3_moe_norm_gpu15 -> layer4_qkv_gpu0
	layer3_moe_norm_gpu15 -> layer4_qkv_gpu1
	layer3_moe_norm_gpu15 -> layer4_qkv_gpu2
	layer3_moe_norm_gpu15 -> layer4_qkv_gpu3
	layer3_moe_norm_gpu15 -> layer4_qkv_gpu4
	layer3_moe_norm_gpu15 -> layer4_qkv_gpu5
	layer3_moe_norm_gpu15 -> layer4_qkv_gpu6
	layer3_moe_norm_gpu15 -> layer4_qkv_gpu7
	layer3_moe_norm_gpu15 -> layer4_qkv_gpu8
	layer3_moe_norm_gpu15 -> layer4_qkv_gpu9
	layer3_moe_norm_gpu15 -> layer4_qkv_gpu10
	layer3_moe_norm_gpu15 -> layer4_qkv_gpu11
	layer4_qkv_gpu0 -> layer4_attn_gpu0
	layer4_attn_gpu0 -> layer4_attn_norm_gpu0
	layer4_attn_norm_gpu0 -> layer4_attn_aggregate
	layer4_qkv_gpu1 -> layer4_attn_gpu1
	layer4_attn_gpu1 -> layer4_attn_norm_gpu1
	layer4_attn_norm_gpu1 -> layer4_attn_aggregate
	layer4_qkv_gpu2 -> layer4_attn_gpu2
	layer4_attn_gpu2 -> layer4_attn_norm_gpu2
	layer4_attn_norm_gpu2 -> layer4_attn_aggregate
	layer4_qkv_gpu3 -> layer4_attn_gpu3
	layer4_attn_gpu3 -> layer4_attn_norm_gpu3
	layer4_attn_norm_gpu3 -> layer4_attn_aggregate
	layer4_qkv_gpu4 -> layer4_attn_gpu4
	layer4_attn_gpu4 -> layer4_attn_norm_gpu4
	layer4_attn_norm_gpu4 -> layer4_attn_aggregate
	layer4_qkv_gpu5 -> layer4_attn_gpu5
	layer4_attn_gpu5 -> layer4_attn_norm_gpu5
	layer4_attn_norm_gpu5 -> layer4_attn_aggregate
	layer4_qkv_gpu6 -> layer4_attn_gpu6
	layer4_attn_gpu6 -> layer4_attn_norm_gpu6
	layer4_attn_norm_gpu6 -> layer4_attn_aggregate
	layer4_qkv_gpu7 -> layer4_attn_gpu7
	layer4_attn_gpu7 -> layer4_attn_norm_gpu7
	layer4_attn_norm_gpu7 -> layer4_attn_aggregate
	layer4_qkv_gpu8 -> layer4_attn_gpu8
	layer4_attn_gpu8 -> layer4_attn_norm_gpu8
	layer4_attn_norm_gpu8 -> layer4_attn_aggregate
	layer4_qkv_gpu9 -> layer4_attn_gpu9
	layer4_attn_gpu9 -> layer4_attn_norm_gpu9
	layer4_attn_norm_gpu9 -> layer4_attn_aggregate
	layer4_qkv_gpu10 -> layer4_attn_gpu10
	layer4_attn_gpu10 -> layer4_attn_norm_gpu10
	layer4_attn_norm_gpu10 -> layer4_attn_aggregate
	layer4_qkv_gpu11 -> layer4_attn_gpu11
	layer4_attn_gpu11 -> layer4_attn_norm_gpu11
	layer4_attn_norm_gpu11 -> layer4_attn_aggregate
	layer4_attn_aggregate -> layer4_moe_broadcast
	layer4_moe_broadcast -> layer4_gate_gpu12
	layer4_gate_gpu12 -> layer4_expert12_0 [style=dashed]
	layer4_gate_gpu12 -> layer4_expert12_1 [style=dashed]
	layer4_gate_gpu12 -> layer4_expert12_2 [style=dashed]
	layer4_gate_gpu12 -> layer4_expert12_3 [style=dashed]
	layer4_expert12_0 -> layer4_moe_aggregate_gpu12
	layer4_expert12_1 -> layer4_moe_aggregate_gpu12
	layer4_expert12_2 -> layer4_moe_aggregate_gpu12
	layer4_expert12_3 -> layer4_moe_aggregate_gpu12
	layer4_moe_aggregate_gpu12 -> layer4_moe_norm_gpu12
	layer4_moe_broadcast -> layer4_gate_gpu13
	layer4_gate_gpu13 -> layer4_expert13_4 [style=dashed]
	layer4_gate_gpu13 -> layer4_expert13_5 [style=dashed]
	layer4_gate_gpu13 -> layer4_expert13_6 [style=dashed]
	layer4_gate_gpu13 -> layer4_expert13_7 [style=dashed]
	layer4_expert13_4 -> layer4_moe_aggregate_gpu13
	layer4_expert13_5 -> layer4_moe_aggregate_gpu13
	layer4_expert13_6 -> layer4_moe_aggregate_gpu13
	layer4_expert13_7 -> layer4_moe_aggregate_gpu13
	layer4_moe_aggregate_gpu13 -> layer4_moe_norm_gpu13
	layer4_moe_broadcast -> layer4_gate_gpu14
	layer4_gate_gpu14 -> layer4_expert14_8 [style=dashed]
	layer4_gate_gpu14 -> layer4_expert14_9 [style=dashed]
	layer4_gate_gpu14 -> layer4_expert14_10 [style=dashed]
	layer4_gate_gpu14 -> layer4_expert14_11 [style=dashed]
	layer4_expert14_8 -> layer4_moe_aggregate_gpu14
	layer4_expert14_9 -> layer4_moe_aggregate_gpu14
	layer4_expert14_10 -> layer4_moe_aggregate_gpu14
	layer4_expert14_11 -> layer4_moe_aggregate_gpu14
	layer4_moe_aggregate_gpu14 -> layer4_moe_norm_gpu14
	layer4_moe_broadcast -> layer4_gate_gpu15
	layer4_gate_gpu15 -> layer4_expert15_12 [style=dashed]
	layer4_gate_gpu15 -> layer4_expert15_13 [style=dashed]
	layer4_gate_gpu15 -> layer4_expert15_14 [style=dashed]
	layer4_gate_gpu15 -> layer4_expert15_15 [style=dashed]
	layer4_expert15_12 -> layer4_moe_aggregate_gpu15
	layer4_expert15_13 -> layer4_moe_aggregate_gpu15
	layer4_expert15_14 -> layer4_moe_aggregate_gpu15
	layer4_expert15_15 -> layer4_moe_aggregate_gpu15
	layer4_moe_aggregate_gpu15 -> layer4_moe_norm_gpu15
	layer4_moe_norm_gpu12 -> output
	layer4_moe_norm_gpu13 -> output
	layer4_moe_norm_gpu14 -> output
	layer4_moe_norm_gpu15 -> output
}
