digraph helix_dag {
	compound=true concentrate=true rankdir=TB
	node [fontname=Arial fontsize=10]
	edge [fontname=Arial fontsize=8]
	input [label="Input\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all GPUs" fillcolor=lightblue shape=ellipse style=filled]
	subgraph cluster_layer_0 {
		bgcolor=lightgray fillcolor=lightgray label="Layer 0\nHelix 4x4 Partitioning" style=rounded
		subgraph cluster_device_0_layer_0 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 0\nHeads 0-7\nDims 0-31" style=rounded
			l0_broadcast_0 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 0" fillcolor=lightyellow shape=parallelogram style=filled]
			l0_q_proj_0 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 0" fillcolor=lightcoral shape=rectangle style=filled]
			l0_k_proj_0 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 0" fillcolor=lightcoral shape=rectangle style=filled]
			l0_v_proj_0 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 0" fillcolor=lightcoral shape=rectangle style=filled]
			l0_attention_0 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 0" fillcolor=lightgreen shape=rectangle style=filled]
			l0_o_proj_0 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 0" fillcolor=lightcoral shape=rectangle style=filled]
			l0_mlp_fc_0 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 0" fillcolor=lightpink shape=rectangle style=filled]
			l0_mlp_proj_0 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 0" fillcolor=lightpink shape=rectangle style=filled]
			l0_residual1_0 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 0" fillcolor=lightsteelblue shape=rectangle style=filled]
			l0_residual2_0 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 0" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_1_layer_0 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 1\nHeads 0-7\nDims 32-63" style=rounded
			l0_broadcast_1 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 1" fillcolor=lightyellow shape=parallelogram style=filled]
			l0_q_proj_1 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 1" fillcolor=lightcoral shape=rectangle style=filled]
			l0_k_proj_1 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 1" fillcolor=lightcoral shape=rectangle style=filled]
			l0_v_proj_1 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 1" fillcolor=lightcoral shape=rectangle style=filled]
			l0_attention_1 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 1" fillcolor=lightgreen shape=rectangle style=filled]
			l0_o_proj_1 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 1" fillcolor=lightcoral shape=rectangle style=filled]
			l0_mlp_fc_1 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 1" fillcolor=lightpink shape=rectangle style=filled]
			l0_mlp_proj_1 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 1" fillcolor=lightpink shape=rectangle style=filled]
			l0_residual1_1 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 1" fillcolor=lightsteelblue shape=rectangle style=filled]
			l0_residual2_1 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 1" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_2_layer_0 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 2\nHeads 0-7\nDims 64-95" style=rounded
			l0_broadcast_2 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 2" fillcolor=lightyellow shape=parallelogram style=filled]
			l0_q_proj_2 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 2" fillcolor=lightcoral shape=rectangle style=filled]
			l0_k_proj_2 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 2" fillcolor=lightcoral shape=rectangle style=filled]
			l0_v_proj_2 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 2" fillcolor=lightcoral shape=rectangle style=filled]
			l0_attention_2 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 2" fillcolor=lightgreen shape=rectangle style=filled]
			l0_o_proj_2 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 2" fillcolor=lightcoral shape=rectangle style=filled]
			l0_mlp_fc_2 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 2" fillcolor=lightpink shape=rectangle style=filled]
			l0_mlp_proj_2 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 2" fillcolor=lightpink shape=rectangle style=filled]
			l0_residual1_2 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 2" fillcolor=lightsteelblue shape=rectangle style=filled]
			l0_residual2_2 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 2" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_3_layer_0 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 3\nHeads 0-7\nDims 96-127" style=rounded
			l0_broadcast_3 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 3" fillcolor=lightyellow shape=parallelogram style=filled]
			l0_q_proj_3 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 3" fillcolor=lightcoral shape=rectangle style=filled]
			l0_k_proj_3 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 3" fillcolor=lightcoral shape=rectangle style=filled]
			l0_v_proj_3 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 3" fillcolor=lightcoral shape=rectangle style=filled]
			l0_attention_3 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 3" fillcolor=lightgreen shape=rectangle style=filled]
			l0_o_proj_3 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 3" fillcolor=lightcoral shape=rectangle style=filled]
			l0_mlp_fc_3 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 3" fillcolor=lightpink shape=rectangle style=filled]
			l0_mlp_proj_3 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 3" fillcolor=lightpink shape=rectangle style=filled]
			l0_residual1_3 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 3" fillcolor=lightsteelblue shape=rectangle style=filled]
			l0_residual2_3 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 3" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_4_layer_0 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 4\nHeads 8-15\nDims 0-31" style=rounded
			l0_broadcast_4 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 4" fillcolor=lightyellow shape=parallelogram style=filled]
			l0_q_proj_4 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 4" fillcolor=lightcoral shape=rectangle style=filled]
			l0_k_proj_4 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 4" fillcolor=lightcoral shape=rectangle style=filled]
			l0_v_proj_4 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 4" fillcolor=lightcoral shape=rectangle style=filled]
			l0_attention_4 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 4" fillcolor=lightgreen shape=rectangle style=filled]
			l0_o_proj_4 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 4" fillcolor=lightcoral shape=rectangle style=filled]
			l0_mlp_fc_4 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 4" fillcolor=lightpink shape=rectangle style=filled]
			l0_mlp_proj_4 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 4" fillcolor=lightpink shape=rectangle style=filled]
			l0_residual1_4 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 4" fillcolor=lightsteelblue shape=rectangle style=filled]
			l0_residual2_4 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 4" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_5_layer_0 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 5\nHeads 8-15\nDims 32-63" style=rounded
			l0_broadcast_5 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 5" fillcolor=lightyellow shape=parallelogram style=filled]
			l0_q_proj_5 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 5" fillcolor=lightcoral shape=rectangle style=filled]
			l0_k_proj_5 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 5" fillcolor=lightcoral shape=rectangle style=filled]
			l0_v_proj_5 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 5" fillcolor=lightcoral shape=rectangle style=filled]
			l0_attention_5 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 5" fillcolor=lightgreen shape=rectangle style=filled]
			l0_o_proj_5 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 5" fillcolor=lightcoral shape=rectangle style=filled]
			l0_mlp_fc_5 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 5" fillcolor=lightpink shape=rectangle style=filled]
			l0_mlp_proj_5 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 5" fillcolor=lightpink shape=rectangle style=filled]
			l0_residual1_5 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 5" fillcolor=lightsteelblue shape=rectangle style=filled]
			l0_residual2_5 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 5" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_6_layer_0 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 6\nHeads 8-15\nDims 64-95" style=rounded
			l0_broadcast_6 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 6" fillcolor=lightyellow shape=parallelogram style=filled]
			l0_q_proj_6 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 6" fillcolor=lightcoral shape=rectangle style=filled]
			l0_k_proj_6 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 6" fillcolor=lightcoral shape=rectangle style=filled]
			l0_v_proj_6 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 6" fillcolor=lightcoral shape=rectangle style=filled]
			l0_attention_6 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 6" fillcolor=lightgreen shape=rectangle style=filled]
			l0_o_proj_6 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 6" fillcolor=lightcoral shape=rectangle style=filled]
			l0_mlp_fc_6 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 6" fillcolor=lightpink shape=rectangle style=filled]
			l0_mlp_proj_6 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 6" fillcolor=lightpink shape=rectangle style=filled]
			l0_residual1_6 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 6" fillcolor=lightsteelblue shape=rectangle style=filled]
			l0_residual2_6 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 6" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_7_layer_0 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 7\nHeads 8-15\nDims 96-127" style=rounded
			l0_broadcast_7 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 7" fillcolor=lightyellow shape=parallelogram style=filled]
			l0_q_proj_7 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 7" fillcolor=lightcoral shape=rectangle style=filled]
			l0_k_proj_7 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 7" fillcolor=lightcoral shape=rectangle style=filled]
			l0_v_proj_7 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 7" fillcolor=lightcoral shape=rectangle style=filled]
			l0_attention_7 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 7" fillcolor=lightgreen shape=rectangle style=filled]
			l0_o_proj_7 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 7" fillcolor=lightcoral shape=rectangle style=filled]
			l0_mlp_fc_7 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 7" fillcolor=lightpink shape=rectangle style=filled]
			l0_mlp_proj_7 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 7" fillcolor=lightpink shape=rectangle style=filled]
			l0_residual1_7 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 7" fillcolor=lightsteelblue shape=rectangle style=filled]
			l0_residual2_7 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 7" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_8_layer_0 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 8\nHeads 16-23\nDims 0-31" style=rounded
			l0_broadcast_8 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 8" fillcolor=lightyellow shape=parallelogram style=filled]
			l0_q_proj_8 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 8" fillcolor=lightcoral shape=rectangle style=filled]
			l0_k_proj_8 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 8" fillcolor=lightcoral shape=rectangle style=filled]
			l0_v_proj_8 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 8" fillcolor=lightcoral shape=rectangle style=filled]
			l0_attention_8 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 8" fillcolor=lightgreen shape=rectangle style=filled]
			l0_o_proj_8 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 8" fillcolor=lightcoral shape=rectangle style=filled]
			l0_mlp_fc_8 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 8" fillcolor=lightpink shape=rectangle style=filled]
			l0_mlp_proj_8 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 8" fillcolor=lightpink shape=rectangle style=filled]
			l0_residual1_8 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 8" fillcolor=lightsteelblue shape=rectangle style=filled]
			l0_residual2_8 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 8" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_9_layer_0 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 9\nHeads 16-23\nDims 32-63" style=rounded
			l0_broadcast_9 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 9" fillcolor=lightyellow shape=parallelogram style=filled]
			l0_q_proj_9 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 9" fillcolor=lightcoral shape=rectangle style=filled]
			l0_k_proj_9 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 9" fillcolor=lightcoral shape=rectangle style=filled]
			l0_v_proj_9 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 9" fillcolor=lightcoral shape=rectangle style=filled]
			l0_attention_9 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 9" fillcolor=lightgreen shape=rectangle style=filled]
			l0_o_proj_9 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 9" fillcolor=lightcoral shape=rectangle style=filled]
			l0_mlp_fc_9 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 9" fillcolor=lightpink shape=rectangle style=filled]
			l0_mlp_proj_9 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 9" fillcolor=lightpink shape=rectangle style=filled]
			l0_residual1_9 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 9" fillcolor=lightsteelblue shape=rectangle style=filled]
			l0_residual2_9 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 9" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_10_layer_0 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 10\nHeads 16-23\nDims 64-95" style=rounded
			l0_broadcast_10 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 10" fillcolor=lightyellow shape=parallelogram style=filled]
			l0_q_proj_10 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 10" fillcolor=lightcoral shape=rectangle style=filled]
			l0_k_proj_10 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 10" fillcolor=lightcoral shape=rectangle style=filled]
			l0_v_proj_10 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 10" fillcolor=lightcoral shape=rectangle style=filled]
			l0_attention_10 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 10" fillcolor=lightgreen shape=rectangle style=filled]
			l0_o_proj_10 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 10" fillcolor=lightcoral shape=rectangle style=filled]
			l0_mlp_fc_10 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 10" fillcolor=lightpink shape=rectangle style=filled]
			l0_mlp_proj_10 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 10" fillcolor=lightpink shape=rectangle style=filled]
			l0_residual1_10 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 10" fillcolor=lightsteelblue shape=rectangle style=filled]
			l0_residual2_10 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 10" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_11_layer_0 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 11\nHeads 16-23\nDims 96-127" style=rounded
			l0_broadcast_11 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 11" fillcolor=lightyellow shape=parallelogram style=filled]
			l0_q_proj_11 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 11" fillcolor=lightcoral shape=rectangle style=filled]
			l0_k_proj_11 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 11" fillcolor=lightcoral shape=rectangle style=filled]
			l0_v_proj_11 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 11" fillcolor=lightcoral shape=rectangle style=filled]
			l0_attention_11 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 11" fillcolor=lightgreen shape=rectangle style=filled]
			l0_o_proj_11 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 11" fillcolor=lightcoral shape=rectangle style=filled]
			l0_mlp_fc_11 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 11" fillcolor=lightpink shape=rectangle style=filled]
			l0_mlp_proj_11 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 11" fillcolor=lightpink shape=rectangle style=filled]
			l0_residual1_11 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 11" fillcolor=lightsteelblue shape=rectangle style=filled]
			l0_residual2_11 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 11" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_12_layer_0 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 12\nHeads 24-31\nDims 0-31" style=rounded
			l0_broadcast_12 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 12" fillcolor=lightyellow shape=parallelogram style=filled]
			l0_q_proj_12 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 12" fillcolor=lightcoral shape=rectangle style=filled]
			l0_k_proj_12 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 12" fillcolor=lightcoral shape=rectangle style=filled]
			l0_v_proj_12 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 12" fillcolor=lightcoral shape=rectangle style=filled]
			l0_attention_12 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 12" fillcolor=lightgreen shape=rectangle style=filled]
			l0_o_proj_12 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 12" fillcolor=lightcoral shape=rectangle style=filled]
			l0_mlp_fc_12 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 12" fillcolor=lightpink shape=rectangle style=filled]
			l0_mlp_proj_12 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 12" fillcolor=lightpink shape=rectangle style=filled]
			l0_residual1_12 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 12" fillcolor=lightsteelblue shape=rectangle style=filled]
			l0_residual2_12 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 12" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_13_layer_0 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 13\nHeads 24-31\nDims 32-63" style=rounded
			l0_broadcast_13 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 13" fillcolor=lightyellow shape=parallelogram style=filled]
			l0_q_proj_13 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 13" fillcolor=lightcoral shape=rectangle style=filled]
			l0_k_proj_13 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 13" fillcolor=lightcoral shape=rectangle style=filled]
			l0_v_proj_13 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 13" fillcolor=lightcoral shape=rectangle style=filled]
			l0_attention_13 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 13" fillcolor=lightgreen shape=rectangle style=filled]
			l0_o_proj_13 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 13" fillcolor=lightcoral shape=rectangle style=filled]
			l0_mlp_fc_13 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 13" fillcolor=lightpink shape=rectangle style=filled]
			l0_mlp_proj_13 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 13" fillcolor=lightpink shape=rectangle style=filled]
			l0_residual1_13 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 13" fillcolor=lightsteelblue shape=rectangle style=filled]
			l0_residual2_13 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 13" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_14_layer_0 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 14\nHeads 24-31\nDims 64-95" style=rounded
			l0_broadcast_14 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 14" fillcolor=lightyellow shape=parallelogram style=filled]
			l0_q_proj_14 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 14" fillcolor=lightcoral shape=rectangle style=filled]
			l0_k_proj_14 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 14" fillcolor=lightcoral shape=rectangle style=filled]
			l0_v_proj_14 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 14" fillcolor=lightcoral shape=rectangle style=filled]
			l0_attention_14 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 14" fillcolor=lightgreen shape=rectangle style=filled]
			l0_o_proj_14 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 14" fillcolor=lightcoral shape=rectangle style=filled]
			l0_mlp_fc_14 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 14" fillcolor=lightpink shape=rectangle style=filled]
			l0_mlp_proj_14 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 14" fillcolor=lightpink shape=rectangle style=filled]
			l0_residual1_14 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 14" fillcolor=lightsteelblue shape=rectangle style=filled]
			l0_residual2_14 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 14" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_15_layer_0 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 15\nHeads 24-31\nDims 96-127" style=rounded
			l0_broadcast_15 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 15" fillcolor=lightyellow shape=parallelogram style=filled]
			l0_q_proj_15 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 15" fillcolor=lightcoral shape=rectangle style=filled]
			l0_k_proj_15 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 15" fillcolor=lightcoral shape=rectangle style=filled]
			l0_v_proj_15 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 15" fillcolor=lightcoral shape=rectangle style=filled]
			l0_attention_15 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 15" fillcolor=lightgreen shape=rectangle style=filled]
			l0_o_proj_15 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 15" fillcolor=lightcoral shape=rectangle style=filled]
			l0_mlp_fc_15 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 15" fillcolor=lightpink shape=rectangle style=filled]
			l0_mlp_proj_15 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 15" fillcolor=lightpink shape=rectangle style=filled]
			l0_residual1_15 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 15" fillcolor=lightsteelblue shape=rectangle style=filled]
			l0_residual2_15 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 15" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
	}
	subgraph cluster_layer_1 {
		bgcolor=lightgray fillcolor=lightgray label="Layer 1\nHelix 4x4 Partitioning" style=rounded
		subgraph cluster_device_0_layer_1 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 0\nHeads 0-7\nDims 0-31" style=rounded
			l1_broadcast_0 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 0" fillcolor=lightyellow shape=parallelogram style=filled]
			l1_q_proj_0 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 0" fillcolor=lightcoral shape=rectangle style=filled]
			l1_k_proj_0 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 0" fillcolor=lightcoral shape=rectangle style=filled]
			l1_v_proj_0 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 0" fillcolor=lightcoral shape=rectangle style=filled]
			l1_attention_0 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 0" fillcolor=lightgreen shape=rectangle style=filled]
			l1_o_proj_0 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 0" fillcolor=lightcoral shape=rectangle style=filled]
			l1_mlp_fc_0 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 0" fillcolor=lightpink shape=rectangle style=filled]
			l1_mlp_proj_0 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 0" fillcolor=lightpink shape=rectangle style=filled]
			l1_residual1_0 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 0" fillcolor=lightsteelblue shape=rectangle style=filled]
			l1_residual2_0 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 0" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_1_layer_1 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 1\nHeads 0-7\nDims 32-63" style=rounded
			l1_broadcast_1 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 1" fillcolor=lightyellow shape=parallelogram style=filled]
			l1_q_proj_1 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 1" fillcolor=lightcoral shape=rectangle style=filled]
			l1_k_proj_1 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 1" fillcolor=lightcoral shape=rectangle style=filled]
			l1_v_proj_1 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 1" fillcolor=lightcoral shape=rectangle style=filled]
			l1_attention_1 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 1" fillcolor=lightgreen shape=rectangle style=filled]
			l1_o_proj_1 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 1" fillcolor=lightcoral shape=rectangle style=filled]
			l1_mlp_fc_1 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 1" fillcolor=lightpink shape=rectangle style=filled]
			l1_mlp_proj_1 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 1" fillcolor=lightpink shape=rectangle style=filled]
			l1_residual1_1 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 1" fillcolor=lightsteelblue shape=rectangle style=filled]
			l1_residual2_1 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 1" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_2_layer_1 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 2\nHeads 0-7\nDims 64-95" style=rounded
			l1_broadcast_2 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 2" fillcolor=lightyellow shape=parallelogram style=filled]
			l1_q_proj_2 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 2" fillcolor=lightcoral shape=rectangle style=filled]
			l1_k_proj_2 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 2" fillcolor=lightcoral shape=rectangle style=filled]
			l1_v_proj_2 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 2" fillcolor=lightcoral shape=rectangle style=filled]
			l1_attention_2 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 2" fillcolor=lightgreen shape=rectangle style=filled]
			l1_o_proj_2 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 2" fillcolor=lightcoral shape=rectangle style=filled]
			l1_mlp_fc_2 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 2" fillcolor=lightpink shape=rectangle style=filled]
			l1_mlp_proj_2 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 2" fillcolor=lightpink shape=rectangle style=filled]
			l1_residual1_2 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 2" fillcolor=lightsteelblue shape=rectangle style=filled]
			l1_residual2_2 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 2" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_3_layer_1 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 3\nHeads 0-7\nDims 96-127" style=rounded
			l1_broadcast_3 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 3" fillcolor=lightyellow shape=parallelogram style=filled]
			l1_q_proj_3 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 3" fillcolor=lightcoral shape=rectangle style=filled]
			l1_k_proj_3 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 3" fillcolor=lightcoral shape=rectangle style=filled]
			l1_v_proj_3 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 3" fillcolor=lightcoral shape=rectangle style=filled]
			l1_attention_3 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 3" fillcolor=lightgreen shape=rectangle style=filled]
			l1_o_proj_3 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 3" fillcolor=lightcoral shape=rectangle style=filled]
			l1_mlp_fc_3 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 3" fillcolor=lightpink shape=rectangle style=filled]
			l1_mlp_proj_3 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 3" fillcolor=lightpink shape=rectangle style=filled]
			l1_residual1_3 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 3" fillcolor=lightsteelblue shape=rectangle style=filled]
			l1_residual2_3 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 3" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_4_layer_1 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 4\nHeads 8-15\nDims 0-31" style=rounded
			l1_broadcast_4 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 4" fillcolor=lightyellow shape=parallelogram style=filled]
			l1_q_proj_4 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 4" fillcolor=lightcoral shape=rectangle style=filled]
			l1_k_proj_4 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 4" fillcolor=lightcoral shape=rectangle style=filled]
			l1_v_proj_4 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 4" fillcolor=lightcoral shape=rectangle style=filled]
			l1_attention_4 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 4" fillcolor=lightgreen shape=rectangle style=filled]
			l1_o_proj_4 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 4" fillcolor=lightcoral shape=rectangle style=filled]
			l1_mlp_fc_4 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 4" fillcolor=lightpink shape=rectangle style=filled]
			l1_mlp_proj_4 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 4" fillcolor=lightpink shape=rectangle style=filled]
			l1_residual1_4 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 4" fillcolor=lightsteelblue shape=rectangle style=filled]
			l1_residual2_4 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 4" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_5_layer_1 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 5\nHeads 8-15\nDims 32-63" style=rounded
			l1_broadcast_5 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 5" fillcolor=lightyellow shape=parallelogram style=filled]
			l1_q_proj_5 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 5" fillcolor=lightcoral shape=rectangle style=filled]
			l1_k_proj_5 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 5" fillcolor=lightcoral shape=rectangle style=filled]
			l1_v_proj_5 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 5" fillcolor=lightcoral shape=rectangle style=filled]
			l1_attention_5 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 5" fillcolor=lightgreen shape=rectangle style=filled]
			l1_o_proj_5 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 5" fillcolor=lightcoral shape=rectangle style=filled]
			l1_mlp_fc_5 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 5" fillcolor=lightpink shape=rectangle style=filled]
			l1_mlp_proj_5 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 5" fillcolor=lightpink shape=rectangle style=filled]
			l1_residual1_5 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 5" fillcolor=lightsteelblue shape=rectangle style=filled]
			l1_residual2_5 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 5" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_6_layer_1 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 6\nHeads 8-15\nDims 64-95" style=rounded
			l1_broadcast_6 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 6" fillcolor=lightyellow shape=parallelogram style=filled]
			l1_q_proj_6 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 6" fillcolor=lightcoral shape=rectangle style=filled]
			l1_k_proj_6 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 6" fillcolor=lightcoral shape=rectangle style=filled]
			l1_v_proj_6 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 6" fillcolor=lightcoral shape=rectangle style=filled]
			l1_attention_6 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 6" fillcolor=lightgreen shape=rectangle style=filled]
			l1_o_proj_6 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 6" fillcolor=lightcoral shape=rectangle style=filled]
			l1_mlp_fc_6 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 6" fillcolor=lightpink shape=rectangle style=filled]
			l1_mlp_proj_6 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 6" fillcolor=lightpink shape=rectangle style=filled]
			l1_residual1_6 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 6" fillcolor=lightsteelblue shape=rectangle style=filled]
			l1_residual2_6 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 6" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_7_layer_1 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 7\nHeads 8-15\nDims 96-127" style=rounded
			l1_broadcast_7 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 7" fillcolor=lightyellow shape=parallelogram style=filled]
			l1_q_proj_7 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 7" fillcolor=lightcoral shape=rectangle style=filled]
			l1_k_proj_7 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 7" fillcolor=lightcoral shape=rectangle style=filled]
			l1_v_proj_7 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 7" fillcolor=lightcoral shape=rectangle style=filled]
			l1_attention_7 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 7" fillcolor=lightgreen shape=rectangle style=filled]
			l1_o_proj_7 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 7" fillcolor=lightcoral shape=rectangle style=filled]
			l1_mlp_fc_7 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 7" fillcolor=lightpink shape=rectangle style=filled]
			l1_mlp_proj_7 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 7" fillcolor=lightpink shape=rectangle style=filled]
			l1_residual1_7 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 7" fillcolor=lightsteelblue shape=rectangle style=filled]
			l1_residual2_7 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 7" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_8_layer_1 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 8\nHeads 16-23\nDims 0-31" style=rounded
			l1_broadcast_8 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 8" fillcolor=lightyellow shape=parallelogram style=filled]
			l1_q_proj_8 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 8" fillcolor=lightcoral shape=rectangle style=filled]
			l1_k_proj_8 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 8" fillcolor=lightcoral shape=rectangle style=filled]
			l1_v_proj_8 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 8" fillcolor=lightcoral shape=rectangle style=filled]
			l1_attention_8 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 8" fillcolor=lightgreen shape=rectangle style=filled]
			l1_o_proj_8 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 8" fillcolor=lightcoral shape=rectangle style=filled]
			l1_mlp_fc_8 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 8" fillcolor=lightpink shape=rectangle style=filled]
			l1_mlp_proj_8 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 8" fillcolor=lightpink shape=rectangle style=filled]
			l1_residual1_8 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 8" fillcolor=lightsteelblue shape=rectangle style=filled]
			l1_residual2_8 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 8" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_9_layer_1 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 9\nHeads 16-23\nDims 32-63" style=rounded
			l1_broadcast_9 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 9" fillcolor=lightyellow shape=parallelogram style=filled]
			l1_q_proj_9 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 9" fillcolor=lightcoral shape=rectangle style=filled]
			l1_k_proj_9 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 9" fillcolor=lightcoral shape=rectangle style=filled]
			l1_v_proj_9 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 9" fillcolor=lightcoral shape=rectangle style=filled]
			l1_attention_9 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 9" fillcolor=lightgreen shape=rectangle style=filled]
			l1_o_proj_9 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 9" fillcolor=lightcoral shape=rectangle style=filled]
			l1_mlp_fc_9 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 9" fillcolor=lightpink shape=rectangle style=filled]
			l1_mlp_proj_9 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 9" fillcolor=lightpink shape=rectangle style=filled]
			l1_residual1_9 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 9" fillcolor=lightsteelblue shape=rectangle style=filled]
			l1_residual2_9 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 9" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_10_layer_1 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 10\nHeads 16-23\nDims 64-95" style=rounded
			l1_broadcast_10 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 10" fillcolor=lightyellow shape=parallelogram style=filled]
			l1_q_proj_10 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 10" fillcolor=lightcoral shape=rectangle style=filled]
			l1_k_proj_10 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 10" fillcolor=lightcoral shape=rectangle style=filled]
			l1_v_proj_10 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 10" fillcolor=lightcoral shape=rectangle style=filled]
			l1_attention_10 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 10" fillcolor=lightgreen shape=rectangle style=filled]
			l1_o_proj_10 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 10" fillcolor=lightcoral shape=rectangle style=filled]
			l1_mlp_fc_10 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 10" fillcolor=lightpink shape=rectangle style=filled]
			l1_mlp_proj_10 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 10" fillcolor=lightpink shape=rectangle style=filled]
			l1_residual1_10 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 10" fillcolor=lightsteelblue shape=rectangle style=filled]
			l1_residual2_10 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 10" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_11_layer_1 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 11\nHeads 16-23\nDims 96-127" style=rounded
			l1_broadcast_11 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 11" fillcolor=lightyellow shape=parallelogram style=filled]
			l1_q_proj_11 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 11" fillcolor=lightcoral shape=rectangle style=filled]
			l1_k_proj_11 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 11" fillcolor=lightcoral shape=rectangle style=filled]
			l1_v_proj_11 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 11" fillcolor=lightcoral shape=rectangle style=filled]
			l1_attention_11 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 11" fillcolor=lightgreen shape=rectangle style=filled]
			l1_o_proj_11 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 11" fillcolor=lightcoral shape=rectangle style=filled]
			l1_mlp_fc_11 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 11" fillcolor=lightpink shape=rectangle style=filled]
			l1_mlp_proj_11 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 11" fillcolor=lightpink shape=rectangle style=filled]
			l1_residual1_11 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 11" fillcolor=lightsteelblue shape=rectangle style=filled]
			l1_residual2_11 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 11" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_12_layer_1 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 12\nHeads 24-31\nDims 0-31" style=rounded
			l1_broadcast_12 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 12" fillcolor=lightyellow shape=parallelogram style=filled]
			l1_q_proj_12 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 12" fillcolor=lightcoral shape=rectangle style=filled]
			l1_k_proj_12 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 12" fillcolor=lightcoral shape=rectangle style=filled]
			l1_v_proj_12 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 12" fillcolor=lightcoral shape=rectangle style=filled]
			l1_attention_12 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 12" fillcolor=lightgreen shape=rectangle style=filled]
			l1_o_proj_12 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 12" fillcolor=lightcoral shape=rectangle style=filled]
			l1_mlp_fc_12 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 12" fillcolor=lightpink shape=rectangle style=filled]
			l1_mlp_proj_12 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 12" fillcolor=lightpink shape=rectangle style=filled]
			l1_residual1_12 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 12" fillcolor=lightsteelblue shape=rectangle style=filled]
			l1_residual2_12 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 12" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_13_layer_1 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 13\nHeads 24-31\nDims 32-63" style=rounded
			l1_broadcast_13 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 13" fillcolor=lightyellow shape=parallelogram style=filled]
			l1_q_proj_13 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 13" fillcolor=lightcoral shape=rectangle style=filled]
			l1_k_proj_13 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 13" fillcolor=lightcoral shape=rectangle style=filled]
			l1_v_proj_13 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 13" fillcolor=lightcoral shape=rectangle style=filled]
			l1_attention_13 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 13" fillcolor=lightgreen shape=rectangle style=filled]
			l1_o_proj_13 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 13" fillcolor=lightcoral shape=rectangle style=filled]
			l1_mlp_fc_13 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 13" fillcolor=lightpink shape=rectangle style=filled]
			l1_mlp_proj_13 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 13" fillcolor=lightpink shape=rectangle style=filled]
			l1_residual1_13 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 13" fillcolor=lightsteelblue shape=rectangle style=filled]
			l1_residual2_13 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 13" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_14_layer_1 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 14\nHeads 24-31\nDims 64-95" style=rounded
			l1_broadcast_14 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 14" fillcolor=lightyellow shape=parallelogram style=filled]
			l1_q_proj_14 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 14" fillcolor=lightcoral shape=rectangle style=filled]
			l1_k_proj_14 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 14" fillcolor=lightcoral shape=rectangle style=filled]
			l1_v_proj_14 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 14" fillcolor=lightcoral shape=rectangle style=filled]
			l1_attention_14 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 14" fillcolor=lightgreen shape=rectangle style=filled]
			l1_o_proj_14 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 14" fillcolor=lightcoral shape=rectangle style=filled]
			l1_mlp_fc_14 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 14" fillcolor=lightpink shape=rectangle style=filled]
			l1_mlp_proj_14 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 14" fillcolor=lightpink shape=rectangle style=filled]
			l1_residual1_14 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 14" fillcolor=lightsteelblue shape=rectangle style=filled]
			l1_residual2_14 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 14" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_15_layer_1 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 15\nHeads 24-31\nDims 96-127" style=rounded
			l1_broadcast_15 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 15" fillcolor=lightyellow shape=parallelogram style=filled]
			l1_q_proj_15 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 15" fillcolor=lightcoral shape=rectangle style=filled]
			l1_k_proj_15 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 15" fillcolor=lightcoral shape=rectangle style=filled]
			l1_v_proj_15 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 15" fillcolor=lightcoral shape=rectangle style=filled]
			l1_attention_15 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 15" fillcolor=lightgreen shape=rectangle style=filled]
			l1_o_proj_15 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 15" fillcolor=lightcoral shape=rectangle style=filled]
			l1_mlp_fc_15 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 15" fillcolor=lightpink shape=rectangle style=filled]
			l1_mlp_proj_15 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 15" fillcolor=lightpink shape=rectangle style=filled]
			l1_residual1_15 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 15" fillcolor=lightsteelblue shape=rectangle style=filled]
			l1_residual2_15 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 15" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
	}
	subgraph cluster_layer_2 {
		bgcolor=lightgray fillcolor=lightgray label="Layer 2\nHelix 4x4 Partitioning" style=rounded
		subgraph cluster_device_0_layer_2 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 0\nHeads 0-7\nDims 0-31" style=rounded
			l2_broadcast_0 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 0" fillcolor=lightyellow shape=parallelogram style=filled]
			l2_q_proj_0 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 0" fillcolor=lightcoral shape=rectangle style=filled]
			l2_k_proj_0 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 0" fillcolor=lightcoral shape=rectangle style=filled]
			l2_v_proj_0 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 0" fillcolor=lightcoral shape=rectangle style=filled]
			l2_attention_0 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 0" fillcolor=lightgreen shape=rectangle style=filled]
			l2_o_proj_0 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 0" fillcolor=lightcoral shape=rectangle style=filled]
			l2_mlp_fc_0 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 0" fillcolor=lightpink shape=rectangle style=filled]
			l2_mlp_proj_0 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 0" fillcolor=lightpink shape=rectangle style=filled]
			l2_residual1_0 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 0" fillcolor=lightsteelblue shape=rectangle style=filled]
			l2_residual2_0 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 0" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_1_layer_2 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 1\nHeads 0-7\nDims 32-63" style=rounded
			l2_broadcast_1 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 1" fillcolor=lightyellow shape=parallelogram style=filled]
			l2_q_proj_1 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 1" fillcolor=lightcoral shape=rectangle style=filled]
			l2_k_proj_1 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 1" fillcolor=lightcoral shape=rectangle style=filled]
			l2_v_proj_1 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 1" fillcolor=lightcoral shape=rectangle style=filled]
			l2_attention_1 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 1" fillcolor=lightgreen shape=rectangle style=filled]
			l2_o_proj_1 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 1" fillcolor=lightcoral shape=rectangle style=filled]
			l2_mlp_fc_1 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 1" fillcolor=lightpink shape=rectangle style=filled]
			l2_mlp_proj_1 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 1" fillcolor=lightpink shape=rectangle style=filled]
			l2_residual1_1 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 1" fillcolor=lightsteelblue shape=rectangle style=filled]
			l2_residual2_1 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 1" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_2_layer_2 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 2\nHeads 0-7\nDims 64-95" style=rounded
			l2_broadcast_2 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 2" fillcolor=lightyellow shape=parallelogram style=filled]
			l2_q_proj_2 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 2" fillcolor=lightcoral shape=rectangle style=filled]
			l2_k_proj_2 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 2" fillcolor=lightcoral shape=rectangle style=filled]
			l2_v_proj_2 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 2" fillcolor=lightcoral shape=rectangle style=filled]
			l2_attention_2 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 2" fillcolor=lightgreen shape=rectangle style=filled]
			l2_o_proj_2 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 2" fillcolor=lightcoral shape=rectangle style=filled]
			l2_mlp_fc_2 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 2" fillcolor=lightpink shape=rectangle style=filled]
			l2_mlp_proj_2 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 2" fillcolor=lightpink shape=rectangle style=filled]
			l2_residual1_2 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 2" fillcolor=lightsteelblue shape=rectangle style=filled]
			l2_residual2_2 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 2" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_3_layer_2 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 3\nHeads 0-7\nDims 96-127" style=rounded
			l2_broadcast_3 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 3" fillcolor=lightyellow shape=parallelogram style=filled]
			l2_q_proj_3 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 3" fillcolor=lightcoral shape=rectangle style=filled]
			l2_k_proj_3 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 3" fillcolor=lightcoral shape=rectangle style=filled]
			l2_v_proj_3 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 3" fillcolor=lightcoral shape=rectangle style=filled]
			l2_attention_3 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 3" fillcolor=lightgreen shape=rectangle style=filled]
			l2_o_proj_3 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 3" fillcolor=lightcoral shape=rectangle style=filled]
			l2_mlp_fc_3 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 3" fillcolor=lightpink shape=rectangle style=filled]
			l2_mlp_proj_3 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 3" fillcolor=lightpink shape=rectangle style=filled]
			l2_residual1_3 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 3" fillcolor=lightsteelblue shape=rectangle style=filled]
			l2_residual2_3 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 3" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_4_layer_2 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 4\nHeads 8-15\nDims 0-31" style=rounded
			l2_broadcast_4 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 4" fillcolor=lightyellow shape=parallelogram style=filled]
			l2_q_proj_4 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 4" fillcolor=lightcoral shape=rectangle style=filled]
			l2_k_proj_4 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 4" fillcolor=lightcoral shape=rectangle style=filled]
			l2_v_proj_4 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 4" fillcolor=lightcoral shape=rectangle style=filled]
			l2_attention_4 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 4" fillcolor=lightgreen shape=rectangle style=filled]
			l2_o_proj_4 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 4" fillcolor=lightcoral shape=rectangle style=filled]
			l2_mlp_fc_4 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 4" fillcolor=lightpink shape=rectangle style=filled]
			l2_mlp_proj_4 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 4" fillcolor=lightpink shape=rectangle style=filled]
			l2_residual1_4 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 4" fillcolor=lightsteelblue shape=rectangle style=filled]
			l2_residual2_4 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 4" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_5_layer_2 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 5\nHeads 8-15\nDims 32-63" style=rounded
			l2_broadcast_5 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 5" fillcolor=lightyellow shape=parallelogram style=filled]
			l2_q_proj_5 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 5" fillcolor=lightcoral shape=rectangle style=filled]
			l2_k_proj_5 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 5" fillcolor=lightcoral shape=rectangle style=filled]
			l2_v_proj_5 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 5" fillcolor=lightcoral shape=rectangle style=filled]
			l2_attention_5 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 5" fillcolor=lightgreen shape=rectangle style=filled]
			l2_o_proj_5 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 5" fillcolor=lightcoral shape=rectangle style=filled]
			l2_mlp_fc_5 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 5" fillcolor=lightpink shape=rectangle style=filled]
			l2_mlp_proj_5 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 5" fillcolor=lightpink shape=rectangle style=filled]
			l2_residual1_5 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 5" fillcolor=lightsteelblue shape=rectangle style=filled]
			l2_residual2_5 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 5" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_6_layer_2 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 6\nHeads 8-15\nDims 64-95" style=rounded
			l2_broadcast_6 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 6" fillcolor=lightyellow shape=parallelogram style=filled]
			l2_q_proj_6 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 6" fillcolor=lightcoral shape=rectangle style=filled]
			l2_k_proj_6 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 6" fillcolor=lightcoral shape=rectangle style=filled]
			l2_v_proj_6 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 6" fillcolor=lightcoral shape=rectangle style=filled]
			l2_attention_6 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 6" fillcolor=lightgreen shape=rectangle style=filled]
			l2_o_proj_6 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 6" fillcolor=lightcoral shape=rectangle style=filled]
			l2_mlp_fc_6 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 6" fillcolor=lightpink shape=rectangle style=filled]
			l2_mlp_proj_6 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 6" fillcolor=lightpink shape=rectangle style=filled]
			l2_residual1_6 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 6" fillcolor=lightsteelblue shape=rectangle style=filled]
			l2_residual2_6 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 6" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_7_layer_2 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 7\nHeads 8-15\nDims 96-127" style=rounded
			l2_broadcast_7 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 7" fillcolor=lightyellow shape=parallelogram style=filled]
			l2_q_proj_7 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 7" fillcolor=lightcoral shape=rectangle style=filled]
			l2_k_proj_7 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 7" fillcolor=lightcoral shape=rectangle style=filled]
			l2_v_proj_7 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 7" fillcolor=lightcoral shape=rectangle style=filled]
			l2_attention_7 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 7" fillcolor=lightgreen shape=rectangle style=filled]
			l2_o_proj_7 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 7" fillcolor=lightcoral shape=rectangle style=filled]
			l2_mlp_fc_7 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 7" fillcolor=lightpink shape=rectangle style=filled]
			l2_mlp_proj_7 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 7" fillcolor=lightpink shape=rectangle style=filled]
			l2_residual1_7 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 7" fillcolor=lightsteelblue shape=rectangle style=filled]
			l2_residual2_7 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 7" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_8_layer_2 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 8\nHeads 16-23\nDims 0-31" style=rounded
			l2_broadcast_8 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 8" fillcolor=lightyellow shape=parallelogram style=filled]
			l2_q_proj_8 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 8" fillcolor=lightcoral shape=rectangle style=filled]
			l2_k_proj_8 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 8" fillcolor=lightcoral shape=rectangle style=filled]
			l2_v_proj_8 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 8" fillcolor=lightcoral shape=rectangle style=filled]
			l2_attention_8 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 8" fillcolor=lightgreen shape=rectangle style=filled]
			l2_o_proj_8 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 8" fillcolor=lightcoral shape=rectangle style=filled]
			l2_mlp_fc_8 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 8" fillcolor=lightpink shape=rectangle style=filled]
			l2_mlp_proj_8 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 8" fillcolor=lightpink shape=rectangle style=filled]
			l2_residual1_8 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 8" fillcolor=lightsteelblue shape=rectangle style=filled]
			l2_residual2_8 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 8" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_9_layer_2 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 9\nHeads 16-23\nDims 32-63" style=rounded
			l2_broadcast_9 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 9" fillcolor=lightyellow shape=parallelogram style=filled]
			l2_q_proj_9 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 9" fillcolor=lightcoral shape=rectangle style=filled]
			l2_k_proj_9 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 9" fillcolor=lightcoral shape=rectangle style=filled]
			l2_v_proj_9 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 9" fillcolor=lightcoral shape=rectangle style=filled]
			l2_attention_9 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 9" fillcolor=lightgreen shape=rectangle style=filled]
			l2_o_proj_9 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 9" fillcolor=lightcoral shape=rectangle style=filled]
			l2_mlp_fc_9 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 9" fillcolor=lightpink shape=rectangle style=filled]
			l2_mlp_proj_9 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 9" fillcolor=lightpink shape=rectangle style=filled]
			l2_residual1_9 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 9" fillcolor=lightsteelblue shape=rectangle style=filled]
			l2_residual2_9 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 9" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_10_layer_2 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 10\nHeads 16-23\nDims 64-95" style=rounded
			l2_broadcast_10 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 10" fillcolor=lightyellow shape=parallelogram style=filled]
			l2_q_proj_10 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 10" fillcolor=lightcoral shape=rectangle style=filled]
			l2_k_proj_10 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 10" fillcolor=lightcoral shape=rectangle style=filled]
			l2_v_proj_10 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 10" fillcolor=lightcoral shape=rectangle style=filled]
			l2_attention_10 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 10" fillcolor=lightgreen shape=rectangle style=filled]
			l2_o_proj_10 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 10" fillcolor=lightcoral shape=rectangle style=filled]
			l2_mlp_fc_10 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 10" fillcolor=lightpink shape=rectangle style=filled]
			l2_mlp_proj_10 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 10" fillcolor=lightpink shape=rectangle style=filled]
			l2_residual1_10 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 10" fillcolor=lightsteelblue shape=rectangle style=filled]
			l2_residual2_10 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 10" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_11_layer_2 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 11\nHeads 16-23\nDims 96-127" style=rounded
			l2_broadcast_11 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 11" fillcolor=lightyellow shape=parallelogram style=filled]
			l2_q_proj_11 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 11" fillcolor=lightcoral shape=rectangle style=filled]
			l2_k_proj_11 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 11" fillcolor=lightcoral shape=rectangle style=filled]
			l2_v_proj_11 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 11" fillcolor=lightcoral shape=rectangle style=filled]
			l2_attention_11 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 11" fillcolor=lightgreen shape=rectangle style=filled]
			l2_o_proj_11 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 11" fillcolor=lightcoral shape=rectangle style=filled]
			l2_mlp_fc_11 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 11" fillcolor=lightpink shape=rectangle style=filled]
			l2_mlp_proj_11 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 11" fillcolor=lightpink shape=rectangle style=filled]
			l2_residual1_11 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 11" fillcolor=lightsteelblue shape=rectangle style=filled]
			l2_residual2_11 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 11" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_12_layer_2 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 12\nHeads 24-31\nDims 0-31" style=rounded
			l2_broadcast_12 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 12" fillcolor=lightyellow shape=parallelogram style=filled]
			l2_q_proj_12 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 12" fillcolor=lightcoral shape=rectangle style=filled]
			l2_k_proj_12 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 12" fillcolor=lightcoral shape=rectangle style=filled]
			l2_v_proj_12 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 12" fillcolor=lightcoral shape=rectangle style=filled]
			l2_attention_12 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 12" fillcolor=lightgreen shape=rectangle style=filled]
			l2_o_proj_12 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 12" fillcolor=lightcoral shape=rectangle style=filled]
			l2_mlp_fc_12 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 12" fillcolor=lightpink shape=rectangle style=filled]
			l2_mlp_proj_12 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 12" fillcolor=lightpink shape=rectangle style=filled]
			l2_residual1_12 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 12" fillcolor=lightsteelblue shape=rectangle style=filled]
			l2_residual2_12 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 12" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_13_layer_2 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 13\nHeads 24-31\nDims 32-63" style=rounded
			l2_broadcast_13 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 13" fillcolor=lightyellow shape=parallelogram style=filled]
			l2_q_proj_13 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 13" fillcolor=lightcoral shape=rectangle style=filled]
			l2_k_proj_13 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 13" fillcolor=lightcoral shape=rectangle style=filled]
			l2_v_proj_13 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 13" fillcolor=lightcoral shape=rectangle style=filled]
			l2_attention_13 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 13" fillcolor=lightgreen shape=rectangle style=filled]
			l2_o_proj_13 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 13" fillcolor=lightcoral shape=rectangle style=filled]
			l2_mlp_fc_13 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 13" fillcolor=lightpink shape=rectangle style=filled]
			l2_mlp_proj_13 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 13" fillcolor=lightpink shape=rectangle style=filled]
			l2_residual1_13 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 13" fillcolor=lightsteelblue shape=rectangle style=filled]
			l2_residual2_13 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 13" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_14_layer_2 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 14\nHeads 24-31\nDims 64-95" style=rounded
			l2_broadcast_14 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 14" fillcolor=lightyellow shape=parallelogram style=filled]
			l2_q_proj_14 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 14" fillcolor=lightcoral shape=rectangle style=filled]
			l2_k_proj_14 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 14" fillcolor=lightcoral shape=rectangle style=filled]
			l2_v_proj_14 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 14" fillcolor=lightcoral shape=rectangle style=filled]
			l2_attention_14 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 14" fillcolor=lightgreen shape=rectangle style=filled]
			l2_o_proj_14 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 14" fillcolor=lightcoral shape=rectangle style=filled]
			l2_mlp_fc_14 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 14" fillcolor=lightpink shape=rectangle style=filled]
			l2_mlp_proj_14 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 14" fillcolor=lightpink shape=rectangle style=filled]
			l2_residual1_14 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 14" fillcolor=lightsteelblue shape=rectangle style=filled]
			l2_residual2_14 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 14" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_15_layer_2 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 15\nHeads 24-31\nDims 96-127" style=rounded
			l2_broadcast_15 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 15" fillcolor=lightyellow shape=parallelogram style=filled]
			l2_q_proj_15 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 15" fillcolor=lightcoral shape=rectangle style=filled]
			l2_k_proj_15 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 15" fillcolor=lightcoral shape=rectangle style=filled]
			l2_v_proj_15 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 15" fillcolor=lightcoral shape=rectangle style=filled]
			l2_attention_15 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 15" fillcolor=lightgreen shape=rectangle style=filled]
			l2_o_proj_15 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 15" fillcolor=lightcoral shape=rectangle style=filled]
			l2_mlp_fc_15 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 15" fillcolor=lightpink shape=rectangle style=filled]
			l2_mlp_proj_15 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 15" fillcolor=lightpink shape=rectangle style=filled]
			l2_residual1_15 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 15" fillcolor=lightsteelblue shape=rectangle style=filled]
			l2_residual2_15 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 15" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
	}
	subgraph cluster_layer_3 {
		bgcolor=lightgray fillcolor=lightgray label="Layer 3\nHelix 4x4 Partitioning" style=rounded
		subgraph cluster_device_0_layer_3 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 0\nHeads 0-7\nDims 0-31" style=rounded
			l3_broadcast_0 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 0" fillcolor=lightyellow shape=parallelogram style=filled]
			l3_q_proj_0 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 0" fillcolor=lightcoral shape=rectangle style=filled]
			l3_k_proj_0 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 0" fillcolor=lightcoral shape=rectangle style=filled]
			l3_v_proj_0 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 0" fillcolor=lightcoral shape=rectangle style=filled]
			l3_attention_0 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 0" fillcolor=lightgreen shape=rectangle style=filled]
			l3_o_proj_0 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 0" fillcolor=lightcoral shape=rectangle style=filled]
			l3_mlp_fc_0 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 0" fillcolor=lightpink shape=rectangle style=filled]
			l3_mlp_proj_0 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 0" fillcolor=lightpink shape=rectangle style=filled]
			l3_residual1_0 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 0" fillcolor=lightsteelblue shape=rectangle style=filled]
			l3_residual2_0 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 0" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_1_layer_3 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 1\nHeads 0-7\nDims 32-63" style=rounded
			l3_broadcast_1 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 1" fillcolor=lightyellow shape=parallelogram style=filled]
			l3_q_proj_1 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 1" fillcolor=lightcoral shape=rectangle style=filled]
			l3_k_proj_1 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 1" fillcolor=lightcoral shape=rectangle style=filled]
			l3_v_proj_1 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 1" fillcolor=lightcoral shape=rectangle style=filled]
			l3_attention_1 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 1" fillcolor=lightgreen shape=rectangle style=filled]
			l3_o_proj_1 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 1" fillcolor=lightcoral shape=rectangle style=filled]
			l3_mlp_fc_1 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 1" fillcolor=lightpink shape=rectangle style=filled]
			l3_mlp_proj_1 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 1" fillcolor=lightpink shape=rectangle style=filled]
			l3_residual1_1 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 1" fillcolor=lightsteelblue shape=rectangle style=filled]
			l3_residual2_1 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 1" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_2_layer_3 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 2\nHeads 0-7\nDims 64-95" style=rounded
			l3_broadcast_2 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 2" fillcolor=lightyellow shape=parallelogram style=filled]
			l3_q_proj_2 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 2" fillcolor=lightcoral shape=rectangle style=filled]
			l3_k_proj_2 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 2" fillcolor=lightcoral shape=rectangle style=filled]
			l3_v_proj_2 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 2" fillcolor=lightcoral shape=rectangle style=filled]
			l3_attention_2 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 2" fillcolor=lightgreen shape=rectangle style=filled]
			l3_o_proj_2 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 2" fillcolor=lightcoral shape=rectangle style=filled]
			l3_mlp_fc_2 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 2" fillcolor=lightpink shape=rectangle style=filled]
			l3_mlp_proj_2 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 2" fillcolor=lightpink shape=rectangle style=filled]
			l3_residual1_2 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 2" fillcolor=lightsteelblue shape=rectangle style=filled]
			l3_residual2_2 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 2" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_3_layer_3 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 3\nHeads 0-7\nDims 96-127" style=rounded
			l3_broadcast_3 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 3" fillcolor=lightyellow shape=parallelogram style=filled]
			l3_q_proj_3 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 3" fillcolor=lightcoral shape=rectangle style=filled]
			l3_k_proj_3 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 3" fillcolor=lightcoral shape=rectangle style=filled]
			l3_v_proj_3 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 3" fillcolor=lightcoral shape=rectangle style=filled]
			l3_attention_3 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 3" fillcolor=lightgreen shape=rectangle style=filled]
			l3_o_proj_3 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 3" fillcolor=lightcoral shape=rectangle style=filled]
			l3_mlp_fc_3 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 3" fillcolor=lightpink shape=rectangle style=filled]
			l3_mlp_proj_3 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 3" fillcolor=lightpink shape=rectangle style=filled]
			l3_residual1_3 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 3" fillcolor=lightsteelblue shape=rectangle style=filled]
			l3_residual2_3 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 3" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_4_layer_3 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 4\nHeads 8-15\nDims 0-31" style=rounded
			l3_broadcast_4 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 4" fillcolor=lightyellow shape=parallelogram style=filled]
			l3_q_proj_4 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 4" fillcolor=lightcoral shape=rectangle style=filled]
			l3_k_proj_4 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 4" fillcolor=lightcoral shape=rectangle style=filled]
			l3_v_proj_4 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 4" fillcolor=lightcoral shape=rectangle style=filled]
			l3_attention_4 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 4" fillcolor=lightgreen shape=rectangle style=filled]
			l3_o_proj_4 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 4" fillcolor=lightcoral shape=rectangle style=filled]
			l3_mlp_fc_4 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 4" fillcolor=lightpink shape=rectangle style=filled]
			l3_mlp_proj_4 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 4" fillcolor=lightpink shape=rectangle style=filled]
			l3_residual1_4 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 4" fillcolor=lightsteelblue shape=rectangle style=filled]
			l3_residual2_4 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 4" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_5_layer_3 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 5\nHeads 8-15\nDims 32-63" style=rounded
			l3_broadcast_5 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 5" fillcolor=lightyellow shape=parallelogram style=filled]
			l3_q_proj_5 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 5" fillcolor=lightcoral shape=rectangle style=filled]
			l3_k_proj_5 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 5" fillcolor=lightcoral shape=rectangle style=filled]
			l3_v_proj_5 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 5" fillcolor=lightcoral shape=rectangle style=filled]
			l3_attention_5 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 5" fillcolor=lightgreen shape=rectangle style=filled]
			l3_o_proj_5 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 5" fillcolor=lightcoral shape=rectangle style=filled]
			l3_mlp_fc_5 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 5" fillcolor=lightpink shape=rectangle style=filled]
			l3_mlp_proj_5 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 5" fillcolor=lightpink shape=rectangle style=filled]
			l3_residual1_5 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 5" fillcolor=lightsteelblue shape=rectangle style=filled]
			l3_residual2_5 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 5" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_6_layer_3 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 6\nHeads 8-15\nDims 64-95" style=rounded
			l3_broadcast_6 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 6" fillcolor=lightyellow shape=parallelogram style=filled]
			l3_q_proj_6 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 6" fillcolor=lightcoral shape=rectangle style=filled]
			l3_k_proj_6 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 6" fillcolor=lightcoral shape=rectangle style=filled]
			l3_v_proj_6 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 6" fillcolor=lightcoral shape=rectangle style=filled]
			l3_attention_6 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 6" fillcolor=lightgreen shape=rectangle style=filled]
			l3_o_proj_6 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 6" fillcolor=lightcoral shape=rectangle style=filled]
			l3_mlp_fc_6 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 6" fillcolor=lightpink shape=rectangle style=filled]
			l3_mlp_proj_6 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 6" fillcolor=lightpink shape=rectangle style=filled]
			l3_residual1_6 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 6" fillcolor=lightsteelblue shape=rectangle style=filled]
			l3_residual2_6 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 6" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_7_layer_3 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 7\nHeads 8-15\nDims 96-127" style=rounded
			l3_broadcast_7 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 7" fillcolor=lightyellow shape=parallelogram style=filled]
			l3_q_proj_7 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 7" fillcolor=lightcoral shape=rectangle style=filled]
			l3_k_proj_7 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 7" fillcolor=lightcoral shape=rectangle style=filled]
			l3_v_proj_7 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 7" fillcolor=lightcoral shape=rectangle style=filled]
			l3_attention_7 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 7" fillcolor=lightgreen shape=rectangle style=filled]
			l3_o_proj_7 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 7" fillcolor=lightcoral shape=rectangle style=filled]
			l3_mlp_fc_7 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 7" fillcolor=lightpink shape=rectangle style=filled]
			l3_mlp_proj_7 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 7" fillcolor=lightpink shape=rectangle style=filled]
			l3_residual1_7 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 7" fillcolor=lightsteelblue shape=rectangle style=filled]
			l3_residual2_7 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 7" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_8_layer_3 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 8\nHeads 16-23\nDims 0-31" style=rounded
			l3_broadcast_8 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 8" fillcolor=lightyellow shape=parallelogram style=filled]
			l3_q_proj_8 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 8" fillcolor=lightcoral shape=rectangle style=filled]
			l3_k_proj_8 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 8" fillcolor=lightcoral shape=rectangle style=filled]
			l3_v_proj_8 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 8" fillcolor=lightcoral shape=rectangle style=filled]
			l3_attention_8 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 8" fillcolor=lightgreen shape=rectangle style=filled]
			l3_o_proj_8 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 8" fillcolor=lightcoral shape=rectangle style=filled]
			l3_mlp_fc_8 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 8" fillcolor=lightpink shape=rectangle style=filled]
			l3_mlp_proj_8 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 8" fillcolor=lightpink shape=rectangle style=filled]
			l3_residual1_8 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 8" fillcolor=lightsteelblue shape=rectangle style=filled]
			l3_residual2_8 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 8" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_9_layer_3 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 9\nHeads 16-23\nDims 32-63" style=rounded
			l3_broadcast_9 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 9" fillcolor=lightyellow shape=parallelogram style=filled]
			l3_q_proj_9 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 9" fillcolor=lightcoral shape=rectangle style=filled]
			l3_k_proj_9 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 9" fillcolor=lightcoral shape=rectangle style=filled]
			l3_v_proj_9 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 9" fillcolor=lightcoral shape=rectangle style=filled]
			l3_attention_9 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 9" fillcolor=lightgreen shape=rectangle style=filled]
			l3_o_proj_9 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 9" fillcolor=lightcoral shape=rectangle style=filled]
			l3_mlp_fc_9 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 9" fillcolor=lightpink shape=rectangle style=filled]
			l3_mlp_proj_9 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 9" fillcolor=lightpink shape=rectangle style=filled]
			l3_residual1_9 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 9" fillcolor=lightsteelblue shape=rectangle style=filled]
			l3_residual2_9 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 9" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_10_layer_3 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 10\nHeads 16-23\nDims 64-95" style=rounded
			l3_broadcast_10 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 10" fillcolor=lightyellow shape=parallelogram style=filled]
			l3_q_proj_10 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 10" fillcolor=lightcoral shape=rectangle style=filled]
			l3_k_proj_10 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 10" fillcolor=lightcoral shape=rectangle style=filled]
			l3_v_proj_10 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 10" fillcolor=lightcoral shape=rectangle style=filled]
			l3_attention_10 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 10" fillcolor=lightgreen shape=rectangle style=filled]
			l3_o_proj_10 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 10" fillcolor=lightcoral shape=rectangle style=filled]
			l3_mlp_fc_10 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 10" fillcolor=lightpink shape=rectangle style=filled]
			l3_mlp_proj_10 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 10" fillcolor=lightpink shape=rectangle style=filled]
			l3_residual1_10 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 10" fillcolor=lightsteelblue shape=rectangle style=filled]
			l3_residual2_10 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 10" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_11_layer_3 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 11\nHeads 16-23\nDims 96-127" style=rounded
			l3_broadcast_11 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 11" fillcolor=lightyellow shape=parallelogram style=filled]
			l3_q_proj_11 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 11" fillcolor=lightcoral shape=rectangle style=filled]
			l3_k_proj_11 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 11" fillcolor=lightcoral shape=rectangle style=filled]
			l3_v_proj_11 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 11" fillcolor=lightcoral shape=rectangle style=filled]
			l3_attention_11 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 11" fillcolor=lightgreen shape=rectangle style=filled]
			l3_o_proj_11 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 11" fillcolor=lightcoral shape=rectangle style=filled]
			l3_mlp_fc_11 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 11" fillcolor=lightpink shape=rectangle style=filled]
			l3_mlp_proj_11 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 11" fillcolor=lightpink shape=rectangle style=filled]
			l3_residual1_11 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 11" fillcolor=lightsteelblue shape=rectangle style=filled]
			l3_residual2_11 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 11" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_12_layer_3 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 12\nHeads 24-31\nDims 0-31" style=rounded
			l3_broadcast_12 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 12" fillcolor=lightyellow shape=parallelogram style=filled]
			l3_q_proj_12 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 12" fillcolor=lightcoral shape=rectangle style=filled]
			l3_k_proj_12 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 12" fillcolor=lightcoral shape=rectangle style=filled]
			l3_v_proj_12 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 12" fillcolor=lightcoral shape=rectangle style=filled]
			l3_attention_12 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 12" fillcolor=lightgreen shape=rectangle style=filled]
			l3_o_proj_12 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 12" fillcolor=lightcoral shape=rectangle style=filled]
			l3_mlp_fc_12 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 12" fillcolor=lightpink shape=rectangle style=filled]
			l3_mlp_proj_12 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 12" fillcolor=lightpink shape=rectangle style=filled]
			l3_residual1_12 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 12" fillcolor=lightsteelblue shape=rectangle style=filled]
			l3_residual2_12 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 12" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_13_layer_3 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 13\nHeads 24-31\nDims 32-63" style=rounded
			l3_broadcast_13 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 13" fillcolor=lightyellow shape=parallelogram style=filled]
			l3_q_proj_13 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 13" fillcolor=lightcoral shape=rectangle style=filled]
			l3_k_proj_13 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 13" fillcolor=lightcoral shape=rectangle style=filled]
			l3_v_proj_13 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 13" fillcolor=lightcoral shape=rectangle style=filled]
			l3_attention_13 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 13" fillcolor=lightgreen shape=rectangle style=filled]
			l3_o_proj_13 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 13" fillcolor=lightcoral shape=rectangle style=filled]
			l3_mlp_fc_13 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 13" fillcolor=lightpink shape=rectangle style=filled]
			l3_mlp_proj_13 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 13" fillcolor=lightpink shape=rectangle style=filled]
			l3_residual1_13 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 13" fillcolor=lightsteelblue shape=rectangle style=filled]
			l3_residual2_13 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 13" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_14_layer_3 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 14\nHeads 24-31\nDims 64-95" style=rounded
			l3_broadcast_14 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 14" fillcolor=lightyellow shape=parallelogram style=filled]
			l3_q_proj_14 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 14" fillcolor=lightcoral shape=rectangle style=filled]
			l3_k_proj_14 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 14" fillcolor=lightcoral shape=rectangle style=filled]
			l3_v_proj_14 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 14" fillcolor=lightcoral shape=rectangle style=filled]
			l3_attention_14 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 14" fillcolor=lightgreen shape=rectangle style=filled]
			l3_o_proj_14 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 14" fillcolor=lightcoral shape=rectangle style=filled]
			l3_mlp_fc_14 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 14" fillcolor=lightpink shape=rectangle style=filled]
			l3_mlp_proj_14 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 14" fillcolor=lightpink shape=rectangle style=filled]
			l3_residual1_14 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 14" fillcolor=lightsteelblue shape=rectangle style=filled]
			l3_residual2_14 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 14" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
		subgraph cluster_device_15_layer_3 {
			bgcolor=lightcyan fillcolor=lightcyan label="Device 15\nHeads 24-31\nDims 96-127" style=rounded
			l3_broadcast_15 [label="Input Broadcast\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: 15" fillcolor=lightyellow shape=parallelogram style=filled]
			l3_q_proj_15 [label="Q Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 15" fillcolor=lightcoral shape=rectangle style=filled]
			l3_k_proj_15 [label="K Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 15" fillcolor=lightcoral shape=rectangle style=filled]
			l3_v_proj_15 [label="V Projection\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 15" fillcolor=lightcoral shape=rectangle style=filled]
			l3_attention_15 [label="Local Attention\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 256]\nGPU: 15" fillcolor=lightgreen shape=rectangle style=filled]
			l3_o_proj_15 [label="O Projection\nInput: [batch_size=128, seq_len=10000, 256]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 15" fillcolor=lightcoral shape=rectangle style=filled]
			l3_mlp_fc_15 [label="MLP FC\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: 15" fillcolor=lightpink shape=rectangle style=filled]
			l3_mlp_proj_15 [label="MLP Projection\nInput: [batch_size=128, seq_len=10000, 4096]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 15" fillcolor=lightpink shape=rectangle style=filled]
			l3_residual1_15 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 15" fillcolor=lightsteelblue shape=rectangle style=filled]
			l3_residual2_15 [label="Residual Add\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 1024]\nGPU: 15" fillcolor=lightsteelblue shape=rectangle style=filled]
		}
	}
	l0_dim_concat_0 [label="Dimension Concat\nHead Group 0\nInput: [batch_size=128, seq_len=10000, 32]\nOutput: [batch_size=128, seq_len=10000, 128]\nGPU: 0-3" fillcolor=orange shape=parallelogram style=filled]
	l0_dim_concat_1 [label="Dimension Concat\nHead Group 1\nInput: [batch_size=128, seq_len=10000, 32]\nOutput: [batch_size=128, seq_len=10000, 128]\nGPU: 4-7" fillcolor=orange shape=parallelogram style=filled]
	l0_dim_concat_2 [label="Dimension Concat\nHead Group 2\nInput: [batch_size=128, seq_len=10000, 32]\nOutput: [batch_size=128, seq_len=10000, 128]\nGPU: 8-11" fillcolor=orange shape=parallelogram style=filled]
	l0_dim_concat_3 [label="Dimension Concat\nHead Group 3\nInput: [batch_size=128, seq_len=10000, 32]\nOutput: [batch_size=128, seq_len=10000, 128]\nGPU: 12-15" fillcolor=orange shape=parallelogram style=filled]
	l0_head_concat [label="Head Concat\nAll Groups\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: all GPUs" fillcolor=gold shape=parallelogram style=filled]
	l1_dim_concat_0 [label="Dimension Concat\nHead Group 0\nInput: [batch_size=128, seq_len=10000, 32]\nOutput: [batch_size=128, seq_len=10000, 128]\nGPU: 0-3" fillcolor=orange shape=parallelogram style=filled]
	l1_dim_concat_1 [label="Dimension Concat\nHead Group 1\nInput: [batch_size=128, seq_len=10000, 32]\nOutput: [batch_size=128, seq_len=10000, 128]\nGPU: 4-7" fillcolor=orange shape=parallelogram style=filled]
	l1_dim_concat_2 [label="Dimension Concat\nHead Group 2\nInput: [batch_size=128, seq_len=10000, 32]\nOutput: [batch_size=128, seq_len=10000, 128]\nGPU: 8-11" fillcolor=orange shape=parallelogram style=filled]
	l1_dim_concat_3 [label="Dimension Concat\nHead Group 3\nInput: [batch_size=128, seq_len=10000, 32]\nOutput: [batch_size=128, seq_len=10000, 128]\nGPU: 12-15" fillcolor=orange shape=parallelogram style=filled]
	l1_head_concat [label="Head Concat\nAll Groups\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: all GPUs" fillcolor=gold shape=parallelogram style=filled]
	l2_dim_concat_0 [label="Dimension Concat\nHead Group 0\nInput: [batch_size=128, seq_len=10000, 32]\nOutput: [batch_size=128, seq_len=10000, 128]\nGPU: 0-3" fillcolor=orange shape=parallelogram style=filled]
	l2_dim_concat_1 [label="Dimension Concat\nHead Group 1\nInput: [batch_size=128, seq_len=10000, 32]\nOutput: [batch_size=128, seq_len=10000, 128]\nGPU: 4-7" fillcolor=orange shape=parallelogram style=filled]
	l2_dim_concat_2 [label="Dimension Concat\nHead Group 2\nInput: [batch_size=128, seq_len=10000, 32]\nOutput: [batch_size=128, seq_len=10000, 128]\nGPU: 8-11" fillcolor=orange shape=parallelogram style=filled]
	l2_dim_concat_3 [label="Dimension Concat\nHead Group 3\nInput: [batch_size=128, seq_len=10000, 32]\nOutput: [batch_size=128, seq_len=10000, 128]\nGPU: 12-15" fillcolor=orange shape=parallelogram style=filled]
	l2_head_concat [label="Head Concat\nAll Groups\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: all GPUs" fillcolor=gold shape=parallelogram style=filled]
	l3_dim_concat_0 [label="Dimension Concat\nHead Group 0\nInput: [batch_size=128, seq_len=10000, 32]\nOutput: [batch_size=128, seq_len=10000, 128]\nGPU: 0-3" fillcolor=orange shape=parallelogram style=filled]
	l3_dim_concat_1 [label="Dimension Concat\nHead Group 1\nInput: [batch_size=128, seq_len=10000, 32]\nOutput: [batch_size=128, seq_len=10000, 128]\nGPU: 4-7" fillcolor=orange shape=parallelogram style=filled]
	l3_dim_concat_2 [label="Dimension Concat\nHead Group 2\nInput: [batch_size=128, seq_len=10000, 32]\nOutput: [batch_size=128, seq_len=10000, 128]\nGPU: 8-11" fillcolor=orange shape=parallelogram style=filled]
	l3_dim_concat_3 [label="Dimension Concat\nHead Group 3\nInput: [batch_size=128, seq_len=10000, 32]\nOutput: [batch_size=128, seq_len=10000, 128]\nGPU: 12-15" fillcolor=orange shape=parallelogram style=filled]
	l3_head_concat [label="Head Concat\nAll Groups\nInput: [batch_size=128, seq_len=10000, 1024]\nOutput: [batch_size=128, seq_len=10000, 4096]\nGPU: all GPUs" fillcolor=gold shape=parallelogram style=filled]
	output [label="Output\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]\nGPU: all GPUs" fillcolor=lightgreen shape=ellipse style=filled]
	input -> l0_broadcast_0
	l0_broadcast_0 -> l0_q_proj_0
	l0_broadcast_0 -> l0_k_proj_0
	l0_broadcast_0 -> l0_v_proj_0
	l0_q_proj_0 -> l0_attention_0
	l0_k_proj_0 -> l0_attention_0
	l0_v_proj_0 -> l0_attention_0
	l0_attention_0 -> l0_o_proj_0
	l0_o_proj_0 -> l0_residual1_0
	l0_residual1_0 -> l0_mlp_fc_0
	l0_mlp_fc_0 -> l0_mlp_proj_0
	l0_mlp_proj_0 -> l0_residual2_0
	l0_residual2_0 -> l0_dim_concat_0
	input -> l0_broadcast_1
	l0_broadcast_1 -> l0_q_proj_1
	l0_broadcast_1 -> l0_k_proj_1
	l0_broadcast_1 -> l0_v_proj_1
	l0_q_proj_1 -> l0_attention_1
	l0_k_proj_1 -> l0_attention_1
	l0_v_proj_1 -> l0_attention_1
	l0_attention_1 -> l0_o_proj_1
	l0_o_proj_1 -> l0_residual1_1
	l0_residual1_1 -> l0_mlp_fc_1
	l0_mlp_fc_1 -> l0_mlp_proj_1
	l0_mlp_proj_1 -> l0_residual2_1
	l0_residual2_1 -> l0_dim_concat_0
	input -> l0_broadcast_2
	l0_broadcast_2 -> l0_q_proj_2
	l0_broadcast_2 -> l0_k_proj_2
	l0_broadcast_2 -> l0_v_proj_2
	l0_q_proj_2 -> l0_attention_2
	l0_k_proj_2 -> l0_attention_2
	l0_v_proj_2 -> l0_attention_2
	l0_attention_2 -> l0_o_proj_2
	l0_o_proj_2 -> l0_residual1_2
	l0_residual1_2 -> l0_mlp_fc_2
	l0_mlp_fc_2 -> l0_mlp_proj_2
	l0_mlp_proj_2 -> l0_residual2_2
	l0_residual2_2 -> l0_dim_concat_0
	input -> l0_broadcast_3
	l0_broadcast_3 -> l0_q_proj_3
	l0_broadcast_3 -> l0_k_proj_3
	l0_broadcast_3 -> l0_v_proj_3
	l0_q_proj_3 -> l0_attention_3
	l0_k_proj_3 -> l0_attention_3
	l0_v_proj_3 -> l0_attention_3
	l0_attention_3 -> l0_o_proj_3
	l0_o_proj_3 -> l0_residual1_3
	l0_residual1_3 -> l0_mlp_fc_3
	l0_mlp_fc_3 -> l0_mlp_proj_3
	l0_mlp_proj_3 -> l0_residual2_3
	l0_residual2_3 -> l0_dim_concat_0
	input -> l0_broadcast_4
	l0_broadcast_4 -> l0_q_proj_4
	l0_broadcast_4 -> l0_k_proj_4
	l0_broadcast_4 -> l0_v_proj_4
	l0_q_proj_4 -> l0_attention_4
	l0_k_proj_4 -> l0_attention_4
	l0_v_proj_4 -> l0_attention_4
	l0_attention_4 -> l0_o_proj_4
	l0_o_proj_4 -> l0_residual1_4
	l0_residual1_4 -> l0_mlp_fc_4
	l0_mlp_fc_4 -> l0_mlp_proj_4
	l0_mlp_proj_4 -> l0_residual2_4
	l0_residual2_4 -> l0_dim_concat_1
	input -> l0_broadcast_5
	l0_broadcast_5 -> l0_q_proj_5
	l0_broadcast_5 -> l0_k_proj_5
	l0_broadcast_5 -> l0_v_proj_5
	l0_q_proj_5 -> l0_attention_5
	l0_k_proj_5 -> l0_attention_5
	l0_v_proj_5 -> l0_attention_5
	l0_attention_5 -> l0_o_proj_5
	l0_o_proj_5 -> l0_residual1_5
	l0_residual1_5 -> l0_mlp_fc_5
	l0_mlp_fc_5 -> l0_mlp_proj_5
	l0_mlp_proj_5 -> l0_residual2_5
	l0_residual2_5 -> l0_dim_concat_1
	input -> l0_broadcast_6
	l0_broadcast_6 -> l0_q_proj_6
	l0_broadcast_6 -> l0_k_proj_6
	l0_broadcast_6 -> l0_v_proj_6
	l0_q_proj_6 -> l0_attention_6
	l0_k_proj_6 -> l0_attention_6
	l0_v_proj_6 -> l0_attention_6
	l0_attention_6 -> l0_o_proj_6
	l0_o_proj_6 -> l0_residual1_6
	l0_residual1_6 -> l0_mlp_fc_6
	l0_mlp_fc_6 -> l0_mlp_proj_6
	l0_mlp_proj_6 -> l0_residual2_6
	l0_residual2_6 -> l0_dim_concat_1
	input -> l0_broadcast_7
	l0_broadcast_7 -> l0_q_proj_7
	l0_broadcast_7 -> l0_k_proj_7
	l0_broadcast_7 -> l0_v_proj_7
	l0_q_proj_7 -> l0_attention_7
	l0_k_proj_7 -> l0_attention_7
	l0_v_proj_7 -> l0_attention_7
	l0_attention_7 -> l0_o_proj_7
	l0_o_proj_7 -> l0_residual1_7
	l0_residual1_7 -> l0_mlp_fc_7
	l0_mlp_fc_7 -> l0_mlp_proj_7
	l0_mlp_proj_7 -> l0_residual2_7
	l0_residual2_7 -> l0_dim_concat_1
	input -> l0_broadcast_8
	l0_broadcast_8 -> l0_q_proj_8
	l0_broadcast_8 -> l0_k_proj_8
	l0_broadcast_8 -> l0_v_proj_8
	l0_q_proj_8 -> l0_attention_8
	l0_k_proj_8 -> l0_attention_8
	l0_v_proj_8 -> l0_attention_8
	l0_attention_8 -> l0_o_proj_8
	l0_o_proj_8 -> l0_residual1_8
	l0_residual1_8 -> l0_mlp_fc_8
	l0_mlp_fc_8 -> l0_mlp_proj_8
	l0_mlp_proj_8 -> l0_residual2_8
	l0_residual2_8 -> l0_dim_concat_2
	input -> l0_broadcast_9
	l0_broadcast_9 -> l0_q_proj_9
	l0_broadcast_9 -> l0_k_proj_9
	l0_broadcast_9 -> l0_v_proj_9
	l0_q_proj_9 -> l0_attention_9
	l0_k_proj_9 -> l0_attention_9
	l0_v_proj_9 -> l0_attention_9
	l0_attention_9 -> l0_o_proj_9
	l0_o_proj_9 -> l0_residual1_9
	l0_residual1_9 -> l0_mlp_fc_9
	l0_mlp_fc_9 -> l0_mlp_proj_9
	l0_mlp_proj_9 -> l0_residual2_9
	l0_residual2_9 -> l0_dim_concat_2
	input -> l0_broadcast_10
	l0_broadcast_10 -> l0_q_proj_10
	l0_broadcast_10 -> l0_k_proj_10
	l0_broadcast_10 -> l0_v_proj_10
	l0_q_proj_10 -> l0_attention_10
	l0_k_proj_10 -> l0_attention_10
	l0_v_proj_10 -> l0_attention_10
	l0_attention_10 -> l0_o_proj_10
	l0_o_proj_10 -> l0_residual1_10
	l0_residual1_10 -> l0_mlp_fc_10
	l0_mlp_fc_10 -> l0_mlp_proj_10
	l0_mlp_proj_10 -> l0_residual2_10
	l0_residual2_10 -> l0_dim_concat_2
	input -> l0_broadcast_11
	l0_broadcast_11 -> l0_q_proj_11
	l0_broadcast_11 -> l0_k_proj_11
	l0_broadcast_11 -> l0_v_proj_11
	l0_q_proj_11 -> l0_attention_11
	l0_k_proj_11 -> l0_attention_11
	l0_v_proj_11 -> l0_attention_11
	l0_attention_11 -> l0_o_proj_11
	l0_o_proj_11 -> l0_residual1_11
	l0_residual1_11 -> l0_mlp_fc_11
	l0_mlp_fc_11 -> l0_mlp_proj_11
	l0_mlp_proj_11 -> l0_residual2_11
	l0_residual2_11 -> l0_dim_concat_2
	input -> l0_broadcast_12
	l0_broadcast_12 -> l0_q_proj_12
	l0_broadcast_12 -> l0_k_proj_12
	l0_broadcast_12 -> l0_v_proj_12
	l0_q_proj_12 -> l0_attention_12
	l0_k_proj_12 -> l0_attention_12
	l0_v_proj_12 -> l0_attention_12
	l0_attention_12 -> l0_o_proj_12
	l0_o_proj_12 -> l0_residual1_12
	l0_residual1_12 -> l0_mlp_fc_12
	l0_mlp_fc_12 -> l0_mlp_proj_12
	l0_mlp_proj_12 -> l0_residual2_12
	l0_residual2_12 -> l0_dim_concat_3
	input -> l0_broadcast_13
	l0_broadcast_13 -> l0_q_proj_13
	l0_broadcast_13 -> l0_k_proj_13
	l0_broadcast_13 -> l0_v_proj_13
	l0_q_proj_13 -> l0_attention_13
	l0_k_proj_13 -> l0_attention_13
	l0_v_proj_13 -> l0_attention_13
	l0_attention_13 -> l0_o_proj_13
	l0_o_proj_13 -> l0_residual1_13
	l0_residual1_13 -> l0_mlp_fc_13
	l0_mlp_fc_13 -> l0_mlp_proj_13
	l0_mlp_proj_13 -> l0_residual2_13
	l0_residual2_13 -> l0_dim_concat_3
	input -> l0_broadcast_14
	l0_broadcast_14 -> l0_q_proj_14
	l0_broadcast_14 -> l0_k_proj_14
	l0_broadcast_14 -> l0_v_proj_14
	l0_q_proj_14 -> l0_attention_14
	l0_k_proj_14 -> l0_attention_14
	l0_v_proj_14 -> l0_attention_14
	l0_attention_14 -> l0_o_proj_14
	l0_o_proj_14 -> l0_residual1_14
	l0_residual1_14 -> l0_mlp_fc_14
	l0_mlp_fc_14 -> l0_mlp_proj_14
	l0_mlp_proj_14 -> l0_residual2_14
	l0_residual2_14 -> l0_dim_concat_3
	input -> l0_broadcast_15
	l0_broadcast_15 -> l0_q_proj_15
	l0_broadcast_15 -> l0_k_proj_15
	l0_broadcast_15 -> l0_v_proj_15
	l0_q_proj_15 -> l0_attention_15
	l0_k_proj_15 -> l0_attention_15
	l0_v_proj_15 -> l0_attention_15
	l0_attention_15 -> l0_o_proj_15
	l0_o_proj_15 -> l0_residual1_15
	l0_residual1_15 -> l0_mlp_fc_15
	l0_mlp_fc_15 -> l0_mlp_proj_15
	l0_mlp_proj_15 -> l0_residual2_15
	l0_residual2_15 -> l0_dim_concat_3
	l0_dim_concat_0 -> l0_head_concat
	l0_dim_concat_1 -> l0_head_concat
	l0_dim_concat_2 -> l0_head_concat
	l0_dim_concat_3 -> l0_head_concat
	l0_head_concat -> l1_broadcast_15
	l1_dim_concat_0 -> l1_head_concat
	l1_dim_concat_1 -> l1_head_concat
	l1_dim_concat_2 -> l1_head_concat
	l1_dim_concat_3 -> l1_head_concat
	l1_head_concat -> l2_broadcast_15
	l2_dim_concat_0 -> l2_head_concat
	l2_dim_concat_1 -> l2_head_concat
	l2_dim_concat_2 -> l2_head_concat
	l2_dim_concat_3 -> l2_head_concat
	l2_head_concat -> l3_broadcast_15
	l3_dim_concat_0 -> l3_head_concat
	l3_dim_concat_1 -> l3_head_concat
	l3_dim_concat_2 -> l3_head_concat
	l3_dim_concat_3 -> l3_head_concat
	l3_head_concat -> output
}
