{
  "generated_dags": {
    "comprehensive_deployment": {
      "svg_path": "../outputs/2025-11-26-17-03-32/complete_moe_deployment_dag.svg",
      "dot_path": "../outputs/2025-11-26-17-03-32/complete_deployment_dag.dot",
      "description": "Complete deployment DAG showing integration of EP=64, DP=2, and one expert per GPU strategy across 128 GPUs"
    },
    "moe_deployment": {
      "svg_path": "../outputs/2025-11-26-17-03-32/moe_deployment_dag.svg", 
      "dot_path": "../outputs/2025-11-26-17-03-32/moe_deployment_dag.dot",
      "description": "Large-scale cross-node MoE deployment DAG showing 61 layers with operator-level breakdown"
    }
  },
  "deployment_plan": "../outputs/2025-11-26-17-03-32/deployment_plan.md",
  "generation_scripts": {
    "main_generator": "../outputs/2025-11-26-17-03-32/generate_moe_dag.py",
    "complete_deployment_generator": "../outputs/2025-11-26-17-03-32/complete_deployment_dag.py"
  },
  "configuration_files": {
    "deployment_config": "../outputs/2025-11-26-17-03-32/deployment_configuration.json",
    "concise_paper": "../outputs/2025-11-26-17-03-32/concise_paper.md",
    "phase1_keypoints": "../outputs/2025-11-26-17-03-32/phase1_keypoints.md",
    "phase2_methodology": "../outputs/2025-11-26-17-03-32/phase2_methodology.md", 
    "phase3_experiments": "../outputs/2025-11-26-17-03-32/phase3_experiments.md"
  },
  "deployment_specifications": {
    "model_architecture": {
      "total_layers": 61,
      "dense_layers": 3,
      "moe_layers": 58,
      "token_dimension": 7168,
      "mha_heads": 128,
      "head_dimension": 128,
      "mlp_hidden_size": 2048,
      "precision": "BF16"
    },
    "parallel_strategies": {
      "expert_parallelism": {
        "degree": 64,
        "strategy": "one_expert_per_gpu",
        "threshold": ">=16"
      },
      "data_parallelism": {
        "degree": 2,
        "strategy": "replica_based"
      },
      "tensor_parallelism": {
        "applicability": "within_expert_when_needed",
        "partitioning": "row_and_column_parallel"
      }
    },
    "hardware_configuration": {
      "gpu_type": "H100",
      "total_gpus": 128,
      "gpus_per_node": 8,
      "total_nodes": 16,
      "memory_per_gpu": "64GB",
      "computing_power_per_gpu": "400TFlops",
      "memory_bandwidth": "1.8TBps",
      "target_mfu": "60%",
      "network_technologies": ["NVLink", "InfiniBand", "NVSwitch"]
    }
  },
  "dag_features": {
    "operator_level_breakdown": true,
    "gpu_specific_assignment": true,
    "tensor_dimensions_specified": true,
    "communication_patterns_shown": true,
    "mha_communication_dashed": true,
    "gating_routing_dashed": true,
    "aggregation_nodes_included": true,
    "parallel_strategies_integrated": true,
    "acyclic_structure_verified": true
  },
  "optimization_targets": {
    "throughput": "maximize_tokens_per_second",
    "latency": "minimize_per_token",
    "scalability": "linear_with_experts",
    "utilization": {
      "compute": "60%_MFU",
      "memory_bandwidth": "80%",
      "network": "topology_dependent"
    }
  }
}