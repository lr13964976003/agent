digraph proposed_ep16 {
rankdir=TB; splines=true;
"INPUT" [shape=box, label="INPUT\nGPU: all\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, d_model=1024"];
"gpu0_mha_qkv" [shape=box, label="gpu0_mha_qkv\nGPU: 0\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, heads=16, d_k=64"];
"INPUT" -> "gpu0_mha_qkv";
"gpu1_mha_qkv" [shape=box, label="gpu1_mha_qkv\nGPU: 1\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, heads=16, d_k=64"];
"INPUT" -> "gpu1_mha_qkv";
"gpu2_mha_qkv" [shape=box, label="gpu2_mha_qkv\nGPU: 2\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, heads=16, d_k=64"];
"INPUT" -> "gpu2_mha_qkv";
"gpu3_mha_qkv" [shape=box, label="gpu3_mha_qkv\nGPU: 3\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, heads=16, d_k=64"];
"INPUT" -> "gpu3_mha_qkv";
"gpu4_mha_qkv" [shape=box, label="gpu4_mha_qkv\nGPU: 4\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, heads=16, d_k=64"];
"INPUT" -> "gpu4_mha_qkv";
"gpu5_mha_qkv" [shape=box, label="gpu5_mha_qkv\nGPU: 5\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, heads=16, d_k=64"];
"INPUT" -> "gpu5_mha_qkv";
"gpu6_mha_qkv" [shape=box, label="gpu6_mha_qkv\nGPU: 6\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, heads=16, d_k=64"];
"INPUT" -> "gpu6_mha_qkv";
"gpu7_mha_qkv" [shape=box, label="gpu7_mha_qkv\nGPU: 7\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, heads=16, d_k=64"];
"INPUT" -> "gpu7_mha_qkv";
"gpu8_mha_qkv" [shape=box, label="gpu8_mha_qkv\nGPU: 8\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, heads=16, d_k=64"];
"INPUT" -> "gpu8_mha_qkv";
"gpu9_mha_qkv" [shape=box, label="gpu9_mha_qkv\nGPU: 9\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, heads=16, d_k=64"];
"INPUT" -> "gpu9_mha_qkv";
"gpu10_mha_qkv" [shape=box, label="gpu10_mha_qkv\nGPU: 10\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, heads=16, d_k=64"];
"INPUT" -> "gpu10_mha_qkv";
"gpu11_mha_qkv" [shape=box, label="gpu11_mha_qkv\nGPU: 11\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, heads=16, d_k=64"];
"INPUT" -> "gpu11_mha_qkv";
"gpu12_mha_qkv" [shape=box, label="gpu12_mha_qkv\nGPU: 12\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, heads=16, d_k=64"];
"INPUT" -> "gpu12_mha_qkv";
"gpu13_mha_qkv" [shape=box, label="gpu13_mha_qkv\nGPU: 13\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, heads=16, d_k=64"];
"INPUT" -> "gpu13_mha_qkv";
"gpu14_mha_qkv" [shape=box, label="gpu14_mha_qkv\nGPU: 14\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, heads=16, d_k=64"];
"INPUT" -> "gpu14_mha_qkv";
"gpu15_mha_qkv" [shape=box, label="gpu15_mha_qkv\nGPU: 15\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, heads=16, d_k=64"];
"INPUT" -> "gpu15_mha_qkv";
"ag_qkv" [shape=ellipse, style=dashed, label="ag_qkv\nIn: shard\nOut: full"];
"gpu0_mha_qkv" -> "ag_qkv";
"gpu1_mha_qkv" -> "ag_qkv";
"gpu2_mha_qkv" -> "ag_qkv";
"gpu3_mha_qkv" -> "ag_qkv";
"gpu4_mha_qkv" -> "ag_qkv";
"gpu5_mha_qkv" -> "ag_qkv";
"gpu6_mha_qkv" -> "ag_qkv";
"gpu7_mha_qkv" -> "ag_qkv";
"gpu8_mha_qkv" -> "ag_qkv";
"gpu9_mha_qkv" -> "ag_qkv";
"gpu10_mha_qkv" -> "ag_qkv";
"gpu11_mha_qkv" -> "ag_qkv";
"gpu12_mha_qkv" -> "ag_qkv";
"gpu13_mha_qkv" -> "ag_qkv";
"gpu14_mha_qkv" -> "ag_qkv";
"gpu15_mha_qkv" -> "ag_qkv";
"mha_score" [shape=box, label="mha_score\nGPU: all\nIn: full\nOut: batch_size, heads=16, seq_len=128, seq_len=128"];
"ag_qkv" -> "mha_score";
"mha_softmax" [shape=box, label="mha_softmax\nGPU: all\nIn: batch_size, heads=16, seq_len=128, seq_len=128\nOut: batch_size, heads=16, seq_len=128, seq_len=128"];
"mha_score" -> "mha_softmax";
"gpu0_mha_out" [shape=box, label="gpu0_mha_out\nGPU: 0\nIn: full\nOut: batch_size, seq_len=128, d_model=1024//16"];
"mha_softmax" -> "gpu0_mha_out";
"gpu1_mha_out" [shape=box, label="gpu1_mha_out\nGPU: 1\nIn: full\nOut: batch_size, seq_len=128, d_model=1024//16"];
"mha_softmax" -> "gpu1_mha_out";
"gpu2_mha_out" [shape=box, label="gpu2_mha_out\nGPU: 2\nIn: full\nOut: batch_size, seq_len=128, d_model=1024//16"];
"mha_softmax" -> "gpu2_mha_out";
"gpu3_mha_out" [shape=box, label="gpu3_mha_out\nGPU: 3\nIn: full\nOut: batch_size, seq_len=128, d_model=1024//16"];
"mha_softmax" -> "gpu3_mha_out";
"gpu4_mha_out" [shape=box, label="gpu4_mha_out\nGPU: 4\nIn: full\nOut: batch_size, seq_len=128, d_model=1024//16"];
"mha_softmax" -> "gpu4_mha_out";
"gpu5_mha_out" [shape=box, label="gpu5_mha_out\nGPU: 5\nIn: full\nOut: batch_size, seq_len=128, d_model=1024//16"];
"mha_softmax" -> "gpu5_mha_out";
"gpu6_mha_out" [shape=box, label="gpu6_mha_out\nGPU: 6\nIn: full\nOut: batch_size, seq_len=128, d_model=1024//16"];
"mha_softmax" -> "gpu6_mha_out";
"gpu7_mha_out" [shape=box, label="gpu7_mha_out\nGPU: 7\nIn: full\nOut: batch_size, seq_len=128, d_model=1024//16"];
"mha_softmax" -> "gpu7_mha_out";
"gpu8_mha_out" [shape=box, label="gpu8_mha_out\nGPU: 8\nIn: full\nOut: batch_size, seq_len=128, d_model=1024//16"];
"mha_softmax" -> "gpu8_mha_out";
"gpu9_mha_out" [shape=box, label="gpu9_mha_out\nGPU: 9\nIn: full\nOut: batch_size, seq_len=128, d_model=1024//16"];
"mha_softmax" -> "gpu9_mha_out";
"gpu10_mha_out" [shape=box, label="gpu10_mha_out\nGPU: 10\nIn: full\nOut: batch_size, seq_len=128, d_model=1024//16"];
"mha_softmax" -> "gpu10_mha_out";
"gpu11_mha_out" [shape=box, label="gpu11_mha_out\nGPU: 11\nIn: full\nOut: batch_size, seq_len=128, d_model=1024//16"];
"mha_softmax" -> "gpu11_mha_out";
"gpu12_mha_out" [shape=box, label="gpu12_mha_out\nGPU: 12\nIn: full\nOut: batch_size, seq_len=128, d_model=1024//16"];
"mha_softmax" -> "gpu12_mha_out";
"gpu13_mha_out" [shape=box, label="gpu13_mha_out\nGPU: 13\nIn: full\nOut: batch_size, seq_len=128, d_model=1024//16"];
"mha_softmax" -> "gpu13_mha_out";
"gpu14_mha_out" [shape=box, label="gpu14_mha_out\nGPU: 14\nIn: full\nOut: batch_size, seq_len=128, d_model=1024//16"];
"mha_softmax" -> "gpu14_mha_out";
"gpu15_mha_out" [shape=box, label="gpu15_mha_out\nGPU: 15\nIn: full\nOut: batch_size, seq_len=128, d_model=1024//16"];
"mha_softmax" -> "gpu15_mha_out";
"ar_mha" [shape=ellipse, style=dashed, label="ar_mha\nIn: shard\nOut: full"];
"gpu0_mha_out" -> "ar_mha";
"gpu1_mha_out" -> "ar_mha";
"gpu2_mha_out" -> "ar_mha";
"gpu3_mha_out" -> "ar_mha";
"gpu4_mha_out" -> "ar_mha";
"gpu5_mha_out" -> "ar_mha";
"gpu6_mha_out" -> "ar_mha";
"gpu7_mha_out" -> "ar_mha";
"gpu8_mha_out" -> "ar_mha";
"gpu9_mha_out" -> "ar_mha";
"gpu10_mha_out" -> "ar_mha";
"gpu11_mha_out" -> "ar_mha";
"gpu12_mha_out" -> "ar_mha";
"gpu13_mha_out" -> "ar_mha";
"gpu14_mha_out" -> "ar_mha";
"gpu15_mha_out" -> "ar_mha";
"resid1" [shape=box, label="resid1\nGPU: all\nIn: x2\nOut: batch_size, seq_len=128, d_model=1024"];
"INPUT" -> "resid1";
"ar_mha" -> "resid1";
"moe_gate" [shape=box, label="moe_gate\nGPU: all\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, 64"];
"resid1" -> "moe_gate";
"dispatch" [shape=ellipse, style=dashed, label="dispatch\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, d_model=1024"];
"moe_gate" -> "dispatch";
"gpu0_expert" [shape=box, label="gpu0_expert\nGPU: 0\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, d_model=1024"];
"dispatch" -> "gpu0_expert";
"gpu1_expert" [shape=box, label="gpu1_expert\nGPU: 1\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, d_model=1024"];
"dispatch" -> "gpu1_expert";
"gpu2_expert" [shape=box, label="gpu2_expert\nGPU: 2\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, d_model=1024"];
"dispatch" -> "gpu2_expert";
"gpu3_expert" [shape=box, label="gpu3_expert\nGPU: 3\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, d_model=1024"];
"dispatch" -> "gpu3_expert";
"gpu4_expert" [shape=box, label="gpu4_expert\nGPU: 4\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, d_model=1024"];
"dispatch" -> "gpu4_expert";
"gpu5_expert" [shape=box, label="gpu5_expert\nGPU: 5\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, d_model=1024"];
"dispatch" -> "gpu5_expert";
"gpu6_expert" [shape=box, label="gpu6_expert\nGPU: 6\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, d_model=1024"];
"dispatch" -> "gpu6_expert";
"gpu7_expert" [shape=box, label="gpu7_expert\nGPU: 7\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, d_model=1024"];
"dispatch" -> "gpu7_expert";
"gpu8_expert" [shape=box, label="gpu8_expert\nGPU: 8\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, d_model=1024"];
"dispatch" -> "gpu8_expert";
"gpu9_expert" [shape=box, label="gpu9_expert\nGPU: 9\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, d_model=1024"];
"dispatch" -> "gpu9_expert";
"gpu10_expert" [shape=box, label="gpu10_expert\nGPU: 10\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, d_model=1024"];
"dispatch" -> "gpu10_expert";
"gpu11_expert" [shape=box, label="gpu11_expert\nGPU: 11\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, d_model=1024"];
"dispatch" -> "gpu11_expert";
"gpu12_expert" [shape=box, label="gpu12_expert\nGPU: 12\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, d_model=1024"];
"dispatch" -> "gpu12_expert";
"gpu13_expert" [shape=box, label="gpu13_expert\nGPU: 13\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, d_model=1024"];
"dispatch" -> "gpu13_expert";
"gpu14_expert" [shape=box, label="gpu14_expert\nGPU: 14\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, d_model=1024"];
"dispatch" -> "gpu14_expert";
"gpu15_expert" [shape=box, label="gpu15_expert\nGPU: 15\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, d_model=1024"];
"dispatch" -> "gpu15_expert";
"combine" [shape=ellipse, style=dashed, label="combine\nIn: batch_size, seq_len=128, d_model=1024 (x16)\nOut: batch_size, seq_len=128, d_model=1024"];
"gpu0_expert" -> "combine";
"gpu1_expert" -> "combine";
"gpu2_expert" -> "combine";
"gpu3_expert" -> "combine";
"gpu4_expert" -> "combine";
"gpu5_expert" -> "combine";
"gpu6_expert" -> "combine";
"gpu7_expert" -> "combine";
"gpu8_expert" -> "combine";
"gpu9_expert" -> "combine";
"gpu10_expert" -> "combine";
"gpu11_expert" -> "combine";
"gpu12_expert" -> "combine";
"gpu13_expert" -> "combine";
"gpu14_expert" -> "combine";
"gpu15_expert" -> "combine";
"resid2" [shape=box, label="resid2\nGPU: all\nIn: x2\nOut: batch_size, seq_len=128, d_model=1024"];
"resid1" -> "resid2";
"combine" -> "resid2";
"OUTPUT" [shape=box, label="OUTPUT\nGPU: all\nIn: batch_size, seq_len=128, d_model=1024\nOut: batch_size, seq_len=128, d_model=1024"];
"resid2" -> "OUTPUT";
}