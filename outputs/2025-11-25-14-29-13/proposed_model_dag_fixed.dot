// MoE Proposed Model DAG (EP=16)
digraph {
	rankdir=TB size="20,40"
	node [fillcolor=lightblue shape=rectangle style=filled]
	input [label="Input\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightgreen shape=ellipse]
	router [label="Token Router\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, k=2, d_model=4096]\nGPU: All GPUs" fillcolor=lightgray shape=parallelogram]
	ln1_l0 [label="LayerNorm L0\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightyellow]
	attn_l0 [label="Multi-Head Attention L0\nInput: [batch_size=128, seq_len=10000, heads=32, d_k=128]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightcoral]
	residual1_l0 [label="ResidualAdd L0\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightpink]
	ln2_l0 [label="LayerNorm L0\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightyellow]
	route_l0 [label="Expert Routing L0\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: All GPUs" fillcolor=lightgray shape=parallelogram]
	recv_l0_e0_gpu0 [label="Token Receive L0E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightgreen shape=ellipse]
	expert_l0_e0_gpu0 [label="Expert L0E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightsalmon]
	send_l0_e0_gpu0 [label="Token Send L0E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightgreen shape=ellipse]
	recv_l0_e1_gpu1 [label="Token Receive L0E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightgreen shape=ellipse]
	expert_l0_e1_gpu1 [label="Expert L0E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightsalmon]
	send_l0_e1_gpu1 [label="Token Send L0E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightgreen shape=ellipse]
	recv_l0_e2_gpu2 [label="Token Receive L0E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightgreen shape=ellipse]
	expert_l0_e2_gpu2 [label="Expert L0E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightsalmon]
	send_l0_e2_gpu2 [label="Token Send L0E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightgreen shape=ellipse]
	recv_l0_e3_gpu3 [label="Token Receive L0E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightgreen shape=ellipse]
	expert_l0_e3_gpu3 [label="Expert L0E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightsalmon]
	send_l0_e3_gpu3 [label="Token Send L0E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightgreen shape=ellipse]
	recv_l0_e4_gpu4 [label="Token Receive L0E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightgreen shape=ellipse]
	expert_l0_e4_gpu4 [label="Expert L0E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightsalmon]
	send_l0_e4_gpu4 [label="Token Send L0E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightgreen shape=ellipse]
	recv_l0_e5_gpu5 [label="Token Receive L0E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightgreen shape=ellipse]
	expert_l0_e5_gpu5 [label="Expert L0E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightsalmon]
	send_l0_e5_gpu5 [label="Token Send L0E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightgreen shape=ellipse]
	recv_l0_e6_gpu6 [label="Token Receive L0E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightgreen shape=ellipse]
	expert_l0_e6_gpu6 [label="Expert L0E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightsalmon]
	send_l0_e6_gpu6 [label="Token Send L0E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightgreen shape=ellipse]
	recv_l0_e7_gpu7 [label="Token Receive L0E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightgreen shape=ellipse]
	expert_l0_e7_gpu7 [label="Expert L0E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightsalmon]
	send_l0_e7_gpu7 [label="Token Send L0E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightgreen shape=ellipse]
	recv_l0_e8_gpu8 [label="Token Receive L0E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightgreen shape=ellipse]
	expert_l0_e8_gpu8 [label="Expert L0E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightsalmon]
	send_l0_e8_gpu8 [label="Token Send L0E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightgreen shape=ellipse]
	recv_l0_e9_gpu9 [label="Token Receive L0E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightgreen shape=ellipse]
	expert_l0_e9_gpu9 [label="Expert L0E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightsalmon]
	send_l0_e9_gpu9 [label="Token Send L0E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightgreen shape=ellipse]
	recv_l0_e10_gpu10 [label="Token Receive L0E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightgreen shape=ellipse]
	expert_l0_e10_gpu10 [label="Expert L0E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightsalmon]
	send_l0_e10_gpu10 [label="Token Send L0E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightgreen shape=ellipse]
	recv_l0_e11_gpu11 [label="Token Receive L0E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightgreen shape=ellipse]
	expert_l0_e11_gpu11 [label="Expert L0E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightsalmon]
	send_l0_e11_gpu11 [label="Token Send L0E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightgreen shape=ellipse]
	recv_l0_e12_gpu12 [label="Token Receive L0E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightgreen shape=ellipse]
	expert_l0_e12_gpu12 [label="Expert L0E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightsalmon]
	send_l0_e12_gpu12 [label="Token Send L0E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightgreen shape=ellipse]
	recv_l0_e13_gpu13 [label="Token Receive L0E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightgreen shape=ellipse]
	expert_l0_e13_gpu13 [label="Expert L0E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightsalmon]
	send_l0_e13_gpu13 [label="Token Send L0E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightgreen shape=ellipse]
	recv_l0_e14_gpu14 [label="Token Receive L0E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightgreen shape=ellipse]
	expert_l0_e14_gpu14 [label="Expert L0E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightsalmon]
	send_l0_e14_gpu14 [label="Token Send L0E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightgreen shape=ellipse]
	recv_l0_e15_gpu15 [label="Token Receive L0E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightgreen shape=ellipse]
	expert_l0_e15_gpu15 [label="Expert L0E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightsalmon]
	send_l0_e15_gpu15 [label="Token Send L0E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightgreen shape=ellipse]
	agg_l0 [label="Expert Aggregation L0\nInput: [batch_size=128, seq_len=10000, k=2, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightgray shape=parallelogram]
	residual2_l0 [label="ResidualAdd L0\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightpink]
	ln1_l1 [label="LayerNorm L1\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightyellow]
	attn_l1 [label="Multi-Head Attention L1\nInput: [batch_size=128, seq_len=10000, heads=32, d_k=128]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightcoral]
	residual1_l1 [label="ResidualAdd L1\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightpink]
	ln2_l1 [label="LayerNorm L1\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightyellow]
	route_l1 [label="Expert Routing L1\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: All GPUs" fillcolor=lightgray shape=parallelogram]
	recv_l1_e0_gpu0 [label="Token Receive L1E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightgreen shape=ellipse]
	expert_l1_e0_gpu0 [label="Expert L1E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightsalmon]
	send_l1_e0_gpu0 [label="Token Send L1E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightgreen shape=ellipse]
	recv_l1_e1_gpu1 [label="Token Receive L1E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightgreen shape=ellipse]
	expert_l1_e1_gpu1 [label="Expert L1E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightsalmon]
	send_l1_e1_gpu1 [label="Token Send L1E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightgreen shape=ellipse]
	recv_l1_e2_gpu2 [label="Token Receive L1E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightgreen shape=ellipse]
	expert_l1_e2_gpu2 [label="Expert L1E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightsalmon]
	send_l1_e2_gpu2 [label="Token Send L1E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightgreen shape=ellipse]
	recv_l1_e3_gpu3 [label="Token Receive L1E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightgreen shape=ellipse]
	expert_l1_e3_gpu3 [label="Expert L1E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightsalmon]
	send_l1_e3_gpu3 [label="Token Send L1E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightgreen shape=ellipse]
	recv_l1_e4_gpu4 [label="Token Receive L1E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightgreen shape=ellipse]
	expert_l1_e4_gpu4 [label="Expert L1E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightsalmon]
	send_l1_e4_gpu4 [label="Token Send L1E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightgreen shape=ellipse]
	recv_l1_e5_gpu5 [label="Token Receive L1E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightgreen shape=ellipse]
	expert_l1_e5_gpu5 [label="Expert L1E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightsalmon]
	send_l1_e5_gpu5 [label="Token Send L1E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightgreen shape=ellipse]
	recv_l1_e6_gpu6 [label="Token Receive L1E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightgreen shape=ellipse]
	expert_l1_e6_gpu6 [label="Expert L1E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightsalmon]
	send_l1_e6_gpu6 [label="Token Send L1E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightgreen shape=ellipse]
	recv_l1_e7_gpu7 [label="Token Receive L1E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightgreen shape=ellipse]
	expert_l1_e7_gpu7 [label="Expert L1E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightsalmon]
	send_l1_e7_gpu7 [label="Token Send L1E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightgreen shape=ellipse]
	recv_l1_e8_gpu8 [label="Token Receive L1E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightgreen shape=ellipse]
	expert_l1_e8_gpu8 [label="Expert L1E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightsalmon]
	send_l1_e8_gpu8 [label="Token Send L1E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightgreen shape=ellipse]
	recv_l1_e9_gpu9 [label="Token Receive L1E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightgreen shape=ellipse]
	expert_l1_e9_gpu9 [label="Expert L1E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightsalmon]
	send_l1_e9_gpu9 [label="Token Send L1E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightgreen shape=ellipse]
	recv_l1_e10_gpu10 [label="Token Receive L1E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightgreen shape=ellipse]
	expert_l1_e10_gpu10 [label="Expert L1E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightsalmon]
	send_l1_e10_gpu10 [label="Token Send L1E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightgreen shape=ellipse]
	recv_l1_e11_gpu11 [label="Token Receive L1E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightgreen shape=ellipse]
	expert_l1_e11_gpu11 [label="Expert L1E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightsalmon]
	send_l1_e11_gpu11 [label="Token Send L1E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightgreen shape=ellipse]
	recv_l1_e12_gpu12 [label="Token Receive L1E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightgreen shape=ellipse]
	expert_l1_e12_gpu12 [label="Expert L1E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightsalmon]
	send_l1_e12_gpu12 [label="Token Send L1E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightgreen shape=ellipse]
	recv_l1_e13_gpu13 [label="Token Receive L1E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightgreen shape=ellipse]
	expert_l1_e13_gpu13 [label="Expert L1E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightsalmon]
	send_l1_e13_gpu13 [label="Token Send L1E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightgreen shape=ellipse]
	recv_l1_e14_gpu14 [label="Token Receive L1E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightgreen shape=ellipse]
	expert_l1_e14_gpu14 [label="Expert L1E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightsalmon]
	send_l1_e14_gpu14 [label="Token Send L1E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightgreen shape=ellipse]
	recv_l1_e15_gpu15 [label="Token Receive L1E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightgreen shape=ellipse]
	expert_l1_e15_gpu15 [label="Expert L1E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightsalmon]
	send_l1_e15_gpu15 [label="Token Send L1E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightgreen shape=ellipse]
	agg_l1 [label="Expert Aggregation L1\nInput: [batch_size=128, seq_len=10000, k=2, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightgray shape=parallelogram]
	residual2_l1 [label="ResidualAdd L1\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightpink]
	ln1_l2 [label="LayerNorm L2\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightyellow]
	attn_l2 [label="Multi-Head Attention L2\nInput: [batch_size=128, seq_len=10000, heads=32, d_k=128]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightcoral]
	residual1_l2 [label="ResidualAdd L2\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightpink]
	ln2_l2 [label="LayerNorm L2\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightyellow]
	route_l2 [label="Expert Routing L2\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: All GPUs" fillcolor=lightgray shape=parallelogram]
	recv_l2_e0_gpu0 [label="Token Receive L2E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightgreen shape=ellipse]
	expert_l2_e0_gpu0 [label="Expert L2E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightsalmon]
	send_l2_e0_gpu0 [label="Token Send L2E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightgreen shape=ellipse]
	recv_l2_e1_gpu1 [label="Token Receive L2E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightgreen shape=ellipse]
	expert_l2_e1_gpu1 [label="Expert L2E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightsalmon]
	send_l2_e1_gpu1 [label="Token Send L2E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightgreen shape=ellipse]
	recv_l2_e2_gpu2 [label="Token Receive L2E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightgreen shape=ellipse]
	expert_l2_e2_gpu2 [label="Expert L2E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightsalmon]
	send_l2_e2_gpu2 [label="Token Send L2E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightgreen shape=ellipse]
	recv_l2_e3_gpu3 [label="Token Receive L2E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightgreen shape=ellipse]
	expert_l2_e3_gpu3 [label="Expert L2E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightsalmon]
	send_l2_e3_gpu3 [label="Token Send L2E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightgreen shape=ellipse]
	recv_l2_e4_gpu4 [label="Token Receive L2E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightgreen shape=ellipse]
	expert_l2_e4_gpu4 [label="Expert L2E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightsalmon]
	send_l2_e4_gpu4 [label="Token Send L2E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightgreen shape=ellipse]
	recv_l2_e5_gpu5 [label="Token Receive L2E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightgreen shape=ellipse]
	expert_l2_e5_gpu5 [label="Expert L2E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightsalmon]
	send_l2_e5_gpu5 [label="Token Send L2E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightgreen shape=ellipse]
	recv_l2_e6_gpu6 [label="Token Receive L2E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightgreen shape=ellipse]
	expert_l2_e6_gpu6 [label="Expert L2E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightsalmon]
	send_l2_e6_gpu6 [label="Token Send L2E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightgreen shape=ellipse]
	recv_l2_e7_gpu7 [label="Token Receive L2E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightgreen shape=ellipse]
	expert_l2_e7_gpu7 [label="Expert L2E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightsalmon]
	send_l2_e7_gpu7 [label="Token Send L2E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightgreen shape=ellipse]
	recv_l2_e8_gpu8 [label="Token Receive L2E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightgreen shape=ellipse]
	expert_l2_e8_gpu8 [label="Expert L2E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightsalmon]
	send_l2_e8_gpu8 [label="Token Send L2E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightgreen shape=ellipse]
	recv_l2_e9_gpu9 [label="Token Receive L2E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightgreen shape=ellipse]
	expert_l2_e9_gpu9 [label="Expert L2E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightsalmon]
	send_l2_e9_gpu9 [label="Token Send L2E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightgreen shape=ellipse]
	recv_l2_e10_gpu10 [label="Token Receive L2E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightgreen shape=ellipse]
	expert_l2_e10_gpu10 [label="Expert L2E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightsalmon]
	send_l2_e10_gpu10 [label="Token Send L2E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightgreen shape=ellipse]
	recv_l2_e11_gpu11 [label="Token Receive L2E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightgreen shape=ellipse]
	expert_l2_e11_gpu11 [label="Expert L2E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightsalmon]
	send_l2_e11_gpu11 [label="Token Send L2E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightgreen shape=ellipse]
	recv_l2_e12_gpu12 [label="Token Receive L2E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightgreen shape=ellipse]
	expert_l2_e12_gpu12 [label="Expert L2E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightsalmon]
	send_l2_e12_gpu12 [label="Token Send L2E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightgreen shape=ellipse]
	recv_l2_e13_gpu13 [label="Token Receive L2E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightgreen shape=ellipse]
	expert_l2_e13_gpu13 [label="Expert L2E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightsalmon]
	send_l2_e13_gpu13 [label="Token Send L2E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightgreen shape=ellipse]
	recv_l2_e14_gpu14 [label="Token Receive L2E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightgreen shape=ellipse]
	expert_l2_e14_gpu14 [label="Expert L2E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightsalmon]
	send_l2_e14_gpu14 [label="Token Send L2E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightgreen shape=ellipse]
	recv_l2_e15_gpu15 [label="Token Receive L2E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightgreen shape=ellipse]
	expert_l2_e15_gpu15 [label="Expert L2E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightsalmon]
	send_l2_e15_gpu15 [label="Token Send L2E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightgreen shape=ellipse]
	agg_l2 [label="Expert Aggregation L2\nInput: [batch_size=128, seq_len=10000, k=2, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightgray shape=parallelogram]
	residual2_l2 [label="ResidualAdd L2\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightpink]
	ln1_l3 [label="LayerNorm L3\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightyellow]
	attn_l3 [label="Multi-Head Attention L3\nInput: [batch_size=128, seq_len=10000, heads=32, d_k=128]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightcoral]
	residual1_l3 [label="ResidualAdd L3\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightpink]
	ln2_l3 [label="LayerNorm L3\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightyellow]
	route_l3 [label="Expert Routing L3\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: All GPUs" fillcolor=lightgray shape=parallelogram]
	recv_l3_e0_gpu0 [label="Token Receive L3E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightgreen shape=ellipse]
	expert_l3_e0_gpu0 [label="Expert L3E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightsalmon]
	send_l3_e0_gpu0 [label="Token Send L3E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightgreen shape=ellipse]
	recv_l3_e1_gpu1 [label="Token Receive L3E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightgreen shape=ellipse]
	expert_l3_e1_gpu1 [label="Expert L3E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightsalmon]
	send_l3_e1_gpu1 [label="Token Send L3E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightgreen shape=ellipse]
	recv_l3_e2_gpu2 [label="Token Receive L3E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightgreen shape=ellipse]
	expert_l3_e2_gpu2 [label="Expert L3E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightsalmon]
	send_l3_e2_gpu2 [label="Token Send L3E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightgreen shape=ellipse]
	recv_l3_e3_gpu3 [label="Token Receive L3E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightgreen shape=ellipse]
	expert_l3_e3_gpu3 [label="Expert L3E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightsalmon]
	send_l3_e3_gpu3 [label="Token Send L3E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightgreen shape=ellipse]
	recv_l3_e4_gpu4 [label="Token Receive L3E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightgreen shape=ellipse]
	expert_l3_e4_gpu4 [label="Expert L3E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightsalmon]
	send_l3_e4_gpu4 [label="Token Send L3E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightgreen shape=ellipse]
	recv_l3_e5_gpu5 [label="Token Receive L3E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightgreen shape=ellipse]
	expert_l3_e5_gpu5 [label="Expert L3E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightsalmon]
	send_l3_e5_gpu5 [label="Token Send L3E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightgreen shape=ellipse]
	recv_l3_e6_gpu6 [label="Token Receive L3E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightgreen shape=ellipse]
	expert_l3_e6_gpu6 [label="Expert L3E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightsalmon]
	send_l3_e6_gpu6 [label="Token Send L3E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightgreen shape=ellipse]
	recv_l3_e7_gpu7 [label="Token Receive L3E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightgreen shape=ellipse]
	expert_l3_e7_gpu7 [label="Expert L3E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightsalmon]
	send_l3_e7_gpu7 [label="Token Send L3E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightgreen shape=ellipse]
	recv_l3_e8_gpu8 [label="Token Receive L3E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightgreen shape=ellipse]
	expert_l3_e8_gpu8 [label="Expert L3E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightsalmon]
	send_l3_e8_gpu8 [label="Token Send L3E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightgreen shape=ellipse]
	recv_l3_e9_gpu9 [label="Token Receive L3E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightgreen shape=ellipse]
	expert_l3_e9_gpu9 [label="Expert L3E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightsalmon]
	send_l3_e9_gpu9 [label="Token Send L3E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightgreen shape=ellipse]
	recv_l3_e10_gpu10 [label="Token Receive L3E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightgreen shape=ellipse]
	expert_l3_e10_gpu10 [label="Expert L3E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightsalmon]
	send_l3_e10_gpu10 [label="Token Send L3E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightgreen shape=ellipse]
	recv_l3_e11_gpu11 [label="Token Receive L3E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightgreen shape=ellipse]
	expert_l3_e11_gpu11 [label="Expert L3E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightsalmon]
	send_l3_e11_gpu11 [label="Token Send L3E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightgreen shape=ellipse]
	recv_l3_e12_gpu12 [label="Token Receive L3E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightgreen shape=ellipse]
	expert_l3_e12_gpu12 [label="Expert L3E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightsalmon]
	send_l3_e12_gpu12 [label="Token Send L3E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightgreen shape=ellipse]
	recv_l3_e13_gpu13 [label="Token Receive L3E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightgreen shape=ellipse]
	expert_l3_e13_gpu13 [label="Expert L3E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightsalmon]
	send_l3_e13_gpu13 [label="Token Send L3E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightgreen shape=ellipse]
	recv_l3_e14_gpu14 [label="Token Receive L3E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightgreen shape=ellipse]
	expert_l3_e14_gpu14 [label="Expert L3E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightsalmon]
	send_l3_e14_gpu14 [label="Token Send L3E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightgreen shape=ellipse]
	recv_l3_e15_gpu15 [label="Token Receive L3E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightgreen shape=ellipse]
	expert_l3_e15_gpu15 [label="Expert L3E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightsalmon]
	send_l3_e15_gpu15 [label="Token Send L3E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightgreen shape=ellipse]
	agg_l3 [label="Expert Aggregation L3\nInput: [batch_size=128, seq_len=10000, k=2, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightgray shape=parallelogram]
	residual2_l3 [label="ResidualAdd L3\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightpink]
	ln1_l4 [label="LayerNorm L4\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightyellow]
	attn_l4 [label="Multi-Head Attention L4\nInput: [batch_size=128, seq_len=10000, heads=32, d_k=128]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightcoral]
	residual1_l4 [label="ResidualAdd L4\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightpink]
	ln2_l4 [label="LayerNorm L4\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightyellow]
	route_l4 [label="Expert Routing L4\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: All GPUs" fillcolor=lightgray shape=parallelogram]
	recv_l4_e0_gpu0 [label="Token Receive L4E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightgreen shape=ellipse]
	expert_l4_e0_gpu0 [label="Expert L4E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightsalmon]
	send_l4_e0_gpu0 [label="Token Send L4E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightgreen shape=ellipse]
	recv_l4_e1_gpu1 [label="Token Receive L4E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightgreen shape=ellipse]
	expert_l4_e1_gpu1 [label="Expert L4E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightsalmon]
	send_l4_e1_gpu1 [label="Token Send L4E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightgreen shape=ellipse]
	recv_l4_e2_gpu2 [label="Token Receive L4E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightgreen shape=ellipse]
	expert_l4_e2_gpu2 [label="Expert L4E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightsalmon]
	send_l4_e2_gpu2 [label="Token Send L4E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightgreen shape=ellipse]
	recv_l4_e3_gpu3 [label="Token Receive L4E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightgreen shape=ellipse]
	expert_l4_e3_gpu3 [label="Expert L4E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightsalmon]
	send_l4_e3_gpu3 [label="Token Send L4E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightgreen shape=ellipse]
	recv_l4_e4_gpu4 [label="Token Receive L4E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightgreen shape=ellipse]
	expert_l4_e4_gpu4 [label="Expert L4E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightsalmon]
	send_l4_e4_gpu4 [label="Token Send L4E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightgreen shape=ellipse]
	recv_l4_e5_gpu5 [label="Token Receive L4E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightgreen shape=ellipse]
	expert_l4_e5_gpu5 [label="Expert L4E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightsalmon]
	send_l4_e5_gpu5 [label="Token Send L4E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightgreen shape=ellipse]
	recv_l4_e6_gpu6 [label="Token Receive L4E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightgreen shape=ellipse]
	expert_l4_e6_gpu6 [label="Expert L4E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightsalmon]
	send_l4_e6_gpu6 [label="Token Send L4E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightgreen shape=ellipse]
	recv_l4_e7_gpu7 [label="Token Receive L4E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightgreen shape=ellipse]
	expert_l4_e7_gpu7 [label="Expert L4E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightsalmon]
	send_l4_e7_gpu7 [label="Token Send L4E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightgreen shape=ellipse]
	recv_l4_e8_gpu8 [label="Token Receive L4E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightgreen shape=ellipse]
	expert_l4_e8_gpu8 [label="Expert L4E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightsalmon]
	send_l4_e8_gpu8 [label="Token Send L4E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightgreen shape=ellipse]
	recv_l4_e9_gpu9 [label="Token Receive L4E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightgreen shape=ellipse]
	expert_l4_e9_gpu9 [label="Expert L4E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightsalmon]
	send_l4_e9_gpu9 [label="Token Send L4E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightgreen shape=ellipse]
	recv_l4_e10_gpu10 [label="Token Receive L4E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightgreen shape=ellipse]
	expert_l4_e10_gpu10 [label="Expert L4E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightsalmon]
	send_l4_e10_gpu10 [label="Token Send L4E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightgreen shape=ellipse]
	recv_l4_e11_gpu11 [label="Token Receive L4E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightgreen shape=ellipse]
	expert_l4_e11_gpu11 [label="Expert L4E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightsalmon]
	send_l4_e11_gpu11 [label="Token Send L4E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightgreen shape=ellipse]
	recv_l4_e12_gpu12 [label="Token Receive L4E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightgreen shape=ellipse]
	expert_l4_e12_gpu12 [label="Expert L4E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightsalmon]
	send_l4_e12_gpu12 [label="Token Send L4E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightgreen shape=ellipse]
	recv_l4_e13_gpu13 [label="Token Receive L4E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightgreen shape=ellipse]
	expert_l4_e13_gpu13 [label="Expert L4E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightsalmon]
	send_l4_e13_gpu13 [label="Token Send L4E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightgreen shape=ellipse]
	recv_l4_e14_gpu14 [label="Token Receive L4E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightgreen shape=ellipse]
	expert_l4_e14_gpu14 [label="Expert L4E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightsalmon]
	send_l4_e14_gpu14 [label="Token Send L4E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightgreen shape=ellipse]
	recv_l4_e15_gpu15 [label="Token Receive L4E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightgreen shape=ellipse]
	expert_l4_e15_gpu15 [label="Expert L4E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightsalmon]
	send_l4_e15_gpu15 [label="Token Send L4E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightgreen shape=ellipse]
	agg_l4 [label="Expert Aggregation L4\nInput: [batch_size=128, seq_len=10000, k=2, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightgray shape=parallelogram]
	residual2_l4 [label="ResidualAdd L4\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightpink]
	ln1_l5 [label="LayerNorm L5\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightyellow]
	attn_l5 [label="Multi-Head Attention L5\nInput: [batch_size=128, seq_len=10000, heads=32, d_k=128]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightcoral]
	residual1_l5 [label="ResidualAdd L5\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightpink]
	ln2_l5 [label="LayerNorm L5\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightyellow]
	route_l5 [label="Expert Routing L5\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: All GPUs" fillcolor=lightgray shape=parallelogram]
	recv_l5_e0_gpu0 [label="Token Receive L5E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightgreen shape=ellipse]
	expert_l5_e0_gpu0 [label="Expert L5E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightsalmon]
	send_l5_e0_gpu0 [label="Token Send L5E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightgreen shape=ellipse]
	recv_l5_e1_gpu1 [label="Token Receive L5E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightgreen shape=ellipse]
	expert_l5_e1_gpu1 [label="Expert L5E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightsalmon]
	send_l5_e1_gpu1 [label="Token Send L5E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightgreen shape=ellipse]
	recv_l5_e2_gpu2 [label="Token Receive L5E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightgreen shape=ellipse]
	expert_l5_e2_gpu2 [label="Expert L5E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightsalmon]
	send_l5_e2_gpu2 [label="Token Send L5E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightgreen shape=ellipse]
	recv_l5_e3_gpu3 [label="Token Receive L5E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightgreen shape=ellipse]
	expert_l5_e3_gpu3 [label="Expert L5E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightsalmon]
	send_l5_e3_gpu3 [label="Token Send L5E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightgreen shape=ellipse]
	recv_l5_e4_gpu4 [label="Token Receive L5E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightgreen shape=ellipse]
	expert_l5_e4_gpu4 [label="Expert L5E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightsalmon]
	send_l5_e4_gpu4 [label="Token Send L5E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightgreen shape=ellipse]
	recv_l5_e5_gpu5 [label="Token Receive L5E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightgreen shape=ellipse]
	expert_l5_e5_gpu5 [label="Expert L5E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightsalmon]
	send_l5_e5_gpu5 [label="Token Send L5E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightgreen shape=ellipse]
	recv_l5_e6_gpu6 [label="Token Receive L5E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightgreen shape=ellipse]
	expert_l5_e6_gpu6 [label="Expert L5E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightsalmon]
	send_l5_e6_gpu6 [label="Token Send L5E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightgreen shape=ellipse]
	recv_l5_e7_gpu7 [label="Token Receive L5E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightgreen shape=ellipse]
	expert_l5_e7_gpu7 [label="Expert L5E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightsalmon]
	send_l5_e7_gpu7 [label="Token Send L5E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightgreen shape=ellipse]
	recv_l5_e8_gpu8 [label="Token Receive L5E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightgreen shape=ellipse]
	expert_l5_e8_gpu8 [label="Expert L5E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightsalmon]
	send_l5_e8_gpu8 [label="Token Send L5E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightgreen shape=ellipse]
	recv_l5_e9_gpu9 [label="Token Receive L5E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightgreen shape=ellipse]
	expert_l5_e9_gpu9 [label="Expert L5E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightsalmon]
	send_l5_e9_gpu9 [label="Token Send L5E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightgreen shape=ellipse]
	recv_l5_e10_gpu10 [label="Token Receive L5E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightgreen shape=ellipse]
	expert_l5_e10_gpu10 [label="Expert L5E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightsalmon]
	send_l5_e10_gpu10 [label="Token Send L5E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightgreen shape=ellipse]
	recv_l5_e11_gpu11 [label="Token Receive L5E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightgreen shape=ellipse]
	expert_l5_e11_gpu11 [label="Expert L5E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightsalmon]
	send_l5_e11_gpu11 [label="Token Send L5E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightgreen shape=ellipse]
	recv_l5_e12_gpu12 [label="Token Receive L5E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightgreen shape=ellipse]
	expert_l5_e12_gpu12 [label="Expert L5E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightsalmon]
	send_l5_e12_gpu12 [label="Token Send L5E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightgreen shape=ellipse]
	recv_l5_e13_gpu13 [label="Token Receive L5E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightgreen shape=ellipse]
	expert_l5_e13_gpu13 [label="Expert L5E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightsalmon]
	send_l5_e13_gpu13 [label="Token Send L5E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightgreen shape=ellipse]
	recv_l5_e14_gpu14 [label="Token Receive L5E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightgreen shape=ellipse]
	expert_l5_e14_gpu14 [label="Expert L5E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightsalmon]
	send_l5_e14_gpu14 [label="Token Send L5E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightgreen shape=ellipse]
	recv_l5_e15_gpu15 [label="Token Receive L5E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightgreen shape=ellipse]
	expert_l5_e15_gpu15 [label="Expert L5E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightsalmon]
	send_l5_e15_gpu15 [label="Token Send L5E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightgreen shape=ellipse]
	agg_l5 [label="Expert Aggregation L5\nInput: [batch_size=128, seq_len=10000, k=2, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightgray shape=parallelogram]
	residual2_l5 [label="ResidualAdd L5\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightpink]
	ln1_l6 [label="LayerNorm L6\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightyellow]
	attn_l6 [label="Multi-Head Attention L6\nInput: [batch_size=128, seq_len=10000, heads=32, d_k=128]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightcoral]
	residual1_l6 [label="ResidualAdd L6\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightpink]
	ln2_l6 [label="LayerNorm L6\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightyellow]
	route_l6 [label="Expert Routing L6\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: All GPUs" fillcolor=lightgray shape=parallelogram]
	recv_l6_e0_gpu0 [label="Token Receive L6E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightgreen shape=ellipse]
	expert_l6_e0_gpu0 [label="Expert L6E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightsalmon]
	send_l6_e0_gpu0 [label="Token Send L6E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightgreen shape=ellipse]
	recv_l6_e1_gpu1 [label="Token Receive L6E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightgreen shape=ellipse]
	expert_l6_e1_gpu1 [label="Expert L6E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightsalmon]
	send_l6_e1_gpu1 [label="Token Send L6E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightgreen shape=ellipse]
	recv_l6_e2_gpu2 [label="Token Receive L6E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightgreen shape=ellipse]
	expert_l6_e2_gpu2 [label="Expert L6E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightsalmon]
	send_l6_e2_gpu2 [label="Token Send L6E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightgreen shape=ellipse]
	recv_l6_e3_gpu3 [label="Token Receive L6E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightgreen shape=ellipse]
	expert_l6_e3_gpu3 [label="Expert L6E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightsalmon]
	send_l6_e3_gpu3 [label="Token Send L6E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightgreen shape=ellipse]
	recv_l6_e4_gpu4 [label="Token Receive L6E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightgreen shape=ellipse]
	expert_l6_e4_gpu4 [label="Expert L6E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightsalmon]
	send_l6_e4_gpu4 [label="Token Send L6E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightgreen shape=ellipse]
	recv_l6_e5_gpu5 [label="Token Receive L6E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightgreen shape=ellipse]
	expert_l6_e5_gpu5 [label="Expert L6E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightsalmon]
	send_l6_e5_gpu5 [label="Token Send L6E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightgreen shape=ellipse]
	recv_l6_e6_gpu6 [label="Token Receive L6E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightgreen shape=ellipse]
	expert_l6_e6_gpu6 [label="Expert L6E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightsalmon]
	send_l6_e6_gpu6 [label="Token Send L6E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightgreen shape=ellipse]
	recv_l6_e7_gpu7 [label="Token Receive L6E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightgreen shape=ellipse]
	expert_l6_e7_gpu7 [label="Expert L6E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightsalmon]
	send_l6_e7_gpu7 [label="Token Send L6E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightgreen shape=ellipse]
	recv_l6_e8_gpu8 [label="Token Receive L6E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightgreen shape=ellipse]
	expert_l6_e8_gpu8 [label="Expert L6E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightsalmon]
	send_l6_e8_gpu8 [label="Token Send L6E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightgreen shape=ellipse]
	recv_l6_e9_gpu9 [label="Token Receive L6E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightgreen shape=ellipse]
	expert_l6_e9_gpu9 [label="Expert L6E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightsalmon]
	send_l6_e9_gpu9 [label="Token Send L6E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightgreen shape=ellipse]
	recv_l6_e10_gpu10 [label="Token Receive L6E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightgreen shape=ellipse]
	expert_l6_e10_gpu10 [label="Expert L6E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightsalmon]
	send_l6_e10_gpu10 [label="Token Send L6E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightgreen shape=ellipse]
	recv_l6_e11_gpu11 [label="Token Receive L6E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightgreen shape=ellipse]
	expert_l6_e11_gpu11 [label="Expert L6E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightsalmon]
	send_l6_e11_gpu11 [label="Token Send L6E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightgreen shape=ellipse]
	recv_l6_e12_gpu12 [label="Token Receive L6E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightgreen shape=ellipse]
	expert_l6_e12_gpu12 [label="Expert L6E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightsalmon]
	send_l6_e12_gpu12 [label="Token Send L6E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightgreen shape=ellipse]
	recv_l6_e13_gpu13 [label="Token Receive L6E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightgreen shape=ellipse]
	expert_l6_e13_gpu13 [label="Expert L6E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightsalmon]
	send_l6_e13_gpu13 [label="Token Send L6E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightgreen shape=ellipse]
	recv_l6_e14_gpu14 [label="Token Receive L6E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightgreen shape=ellipse]
	expert_l6_e14_gpu14 [label="Expert L6E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightsalmon]
	send_l6_e14_gpu14 [label="Token Send L6E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightgreen shape=ellipse]
	recv_l6_e15_gpu15 [label="Token Receive L6E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightgreen shape=ellipse]
	expert_l6_e15_gpu15 [label="Expert L6E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightsalmon]
	send_l6_e15_gpu15 [label="Token Send L6E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightgreen shape=ellipse]
	agg_l6 [label="Expert Aggregation L6\nInput: [batch_size=128, seq_len=10000, k=2, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightgray shape=parallelogram]
	residual2_l6 [label="ResidualAdd L6\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightpink]
	ln1_l7 [label="LayerNorm L7\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightyellow]
	attn_l7 [label="Multi-Head Attention L7\nInput: [batch_size=128, seq_len=10000, heads=32, d_k=128]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightcoral]
	residual1_l7 [label="ResidualAdd L7\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightpink]
	ln2_l7 [label="LayerNorm L7\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightyellow]
	route_l7 [label="Expert Routing L7\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: All GPUs" fillcolor=lightgray shape=parallelogram]
	recv_l7_e0_gpu0 [label="Token Receive L7E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightgreen shape=ellipse]
	expert_l7_e0_gpu0 [label="Expert L7E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightsalmon]
	send_l7_e0_gpu0 [label="Token Send L7E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightgreen shape=ellipse]
	recv_l7_e1_gpu1 [label="Token Receive L7E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightgreen shape=ellipse]
	expert_l7_e1_gpu1 [label="Expert L7E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightsalmon]
	send_l7_e1_gpu1 [label="Token Send L7E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightgreen shape=ellipse]
	recv_l7_e2_gpu2 [label="Token Receive L7E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightgreen shape=ellipse]
	expert_l7_e2_gpu2 [label="Expert L7E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightsalmon]
	send_l7_e2_gpu2 [label="Token Send L7E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightgreen shape=ellipse]
	recv_l7_e3_gpu3 [label="Token Receive L7E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightgreen shape=ellipse]
	expert_l7_e3_gpu3 [label="Expert L7E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightsalmon]
	send_l7_e3_gpu3 [label="Token Send L7E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightgreen shape=ellipse]
	recv_l7_e4_gpu4 [label="Token Receive L7E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightgreen shape=ellipse]
	expert_l7_e4_gpu4 [label="Expert L7E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightsalmon]
	send_l7_e4_gpu4 [label="Token Send L7E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightgreen shape=ellipse]
	recv_l7_e5_gpu5 [label="Token Receive L7E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightgreen shape=ellipse]
	expert_l7_e5_gpu5 [label="Expert L7E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightsalmon]
	send_l7_e5_gpu5 [label="Token Send L7E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightgreen shape=ellipse]
	recv_l7_e6_gpu6 [label="Token Receive L7E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightgreen shape=ellipse]
	expert_l7_e6_gpu6 [label="Expert L7E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightsalmon]
	send_l7_e6_gpu6 [label="Token Send L7E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightgreen shape=ellipse]
	recv_l7_e7_gpu7 [label="Token Receive L7E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightgreen shape=ellipse]
	expert_l7_e7_gpu7 [label="Expert L7E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightsalmon]
	send_l7_e7_gpu7 [label="Token Send L7E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightgreen shape=ellipse]
	recv_l7_e8_gpu8 [label="Token Receive L7E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightgreen shape=ellipse]
	expert_l7_e8_gpu8 [label="Expert L7E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightsalmon]
	send_l7_e8_gpu8 [label="Token Send L7E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightgreen shape=ellipse]
	recv_l7_e9_gpu9 [label="Token Receive L7E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightgreen shape=ellipse]
	expert_l7_e9_gpu9 [label="Expert L7E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightsalmon]
	send_l7_e9_gpu9 [label="Token Send L7E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightgreen shape=ellipse]
	recv_l7_e10_gpu10 [label="Token Receive L7E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightgreen shape=ellipse]
	expert_l7_e10_gpu10 [label="Expert L7E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightsalmon]
	send_l7_e10_gpu10 [label="Token Send L7E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightgreen shape=ellipse]
	recv_l7_e11_gpu11 [label="Token Receive L7E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightgreen shape=ellipse]
	expert_l7_e11_gpu11 [label="Expert L7E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightsalmon]
	send_l7_e11_gpu11 [label="Token Send L7E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightgreen shape=ellipse]
	recv_l7_e12_gpu12 [label="Token Receive L7E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightgreen shape=ellipse]
	expert_l7_e12_gpu12 [label="Expert L7E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightsalmon]
	send_l7_e12_gpu12 [label="Token Send L7E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightgreen shape=ellipse]
	recv_l7_e13_gpu13 [label="Token Receive L7E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightgreen shape=ellipse]
	expert_l7_e13_gpu13 [label="Expert L7E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightsalmon]
	send_l7_e13_gpu13 [label="Token Send L7E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightgreen shape=ellipse]
	recv_l7_e14_gpu14 [label="Token Receive L7E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightgreen shape=ellipse]
	expert_l7_e14_gpu14 [label="Expert L7E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightsalmon]
	send_l7_e14_gpu14 [label="Token Send L7E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightgreen shape=ellipse]
	recv_l7_e15_gpu15 [label="Token Receive L7E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightgreen shape=ellipse]
	expert_l7_e15_gpu15 [label="Expert L7E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightsalmon]
	send_l7_e15_gpu15 [label="Token Send L7E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightgreen shape=ellipse]
	agg_l7 [label="Expert Aggregation L7\nInput: [batch_size=128, seq_len=10000, k=2, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightgray shape=parallelogram]
	residual2_l7 [label="ResidualAdd L7\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightpink]
	ln1_l8 [label="LayerNorm L8\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightyellow]
	attn_l8 [label="Multi-Head Attention L8\nInput: [batch_size=128, seq_len=10000, heads=32, d_k=128]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightcoral]
	residual1_l8 [label="ResidualAdd L8\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightpink]
	ln2_l8 [label="LayerNorm L8\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightyellow]
	route_l8 [label="Expert Routing L8\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: All GPUs" fillcolor=lightgray shape=parallelogram]
	recv_l8_e0_gpu0 [label="Token Receive L8E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightgreen shape=ellipse]
	expert_l8_e0_gpu0 [label="Expert L8E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightsalmon]
	send_l8_e0_gpu0 [label="Token Send L8E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightgreen shape=ellipse]
	recv_l8_e1_gpu1 [label="Token Receive L8E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightgreen shape=ellipse]
	expert_l8_e1_gpu1 [label="Expert L8E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightsalmon]
	send_l8_e1_gpu1 [label="Token Send L8E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightgreen shape=ellipse]
	recv_l8_e2_gpu2 [label="Token Receive L8E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightgreen shape=ellipse]
	expert_l8_e2_gpu2 [label="Expert L8E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightsalmon]
	send_l8_e2_gpu2 [label="Token Send L8E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightgreen shape=ellipse]
	recv_l8_e3_gpu3 [label="Token Receive L8E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightgreen shape=ellipse]
	expert_l8_e3_gpu3 [label="Expert L8E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightsalmon]
	send_l8_e3_gpu3 [label="Token Send L8E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightgreen shape=ellipse]
	recv_l8_e4_gpu4 [label="Token Receive L8E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightgreen shape=ellipse]
	expert_l8_e4_gpu4 [label="Expert L8E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightsalmon]
	send_l8_e4_gpu4 [label="Token Send L8E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightgreen shape=ellipse]
	recv_l8_e5_gpu5 [label="Token Receive L8E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightgreen shape=ellipse]
	expert_l8_e5_gpu5 [label="Expert L8E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightsalmon]
	send_l8_e5_gpu5 [label="Token Send L8E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightgreen shape=ellipse]
	recv_l8_e6_gpu6 [label="Token Receive L8E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightgreen shape=ellipse]
	expert_l8_e6_gpu6 [label="Expert L8E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightsalmon]
	send_l8_e6_gpu6 [label="Token Send L8E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightgreen shape=ellipse]
	recv_l8_e7_gpu7 [label="Token Receive L8E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightgreen shape=ellipse]
	expert_l8_e7_gpu7 [label="Expert L8E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightsalmon]
	send_l8_e7_gpu7 [label="Token Send L8E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightgreen shape=ellipse]
	recv_l8_e8_gpu8 [label="Token Receive L8E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightgreen shape=ellipse]
	expert_l8_e8_gpu8 [label="Expert L8E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightsalmon]
	send_l8_e8_gpu8 [label="Token Send L8E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightgreen shape=ellipse]
	recv_l8_e9_gpu9 [label="Token Receive L8E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightgreen shape=ellipse]
	expert_l8_e9_gpu9 [label="Expert L8E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightsalmon]
	send_l8_e9_gpu9 [label="Token Send L8E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightgreen shape=ellipse]
	recv_l8_e10_gpu10 [label="Token Receive L8E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightgreen shape=ellipse]
	expert_l8_e10_gpu10 [label="Expert L8E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightsalmon]
	send_l8_e10_gpu10 [label="Token Send L8E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightgreen shape=ellipse]
	recv_l8_e11_gpu11 [label="Token Receive L8E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightgreen shape=ellipse]
	expert_l8_e11_gpu11 [label="Expert L8E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightsalmon]
	send_l8_e11_gpu11 [label="Token Send L8E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightgreen shape=ellipse]
	recv_l8_e12_gpu12 [label="Token Receive L8E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightgreen shape=ellipse]
	expert_l8_e12_gpu12 [label="Expert L8E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightsalmon]
	send_l8_e12_gpu12 [label="Token Send L8E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightgreen shape=ellipse]
	recv_l8_e13_gpu13 [label="Token Receive L8E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightgreen shape=ellipse]
	expert_l8_e13_gpu13 [label="Expert L8E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightsalmon]
	send_l8_e13_gpu13 [label="Token Send L8E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightgreen shape=ellipse]
	recv_l8_e14_gpu14 [label="Token Receive L8E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightgreen shape=ellipse]
	expert_l8_e14_gpu14 [label="Expert L8E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightsalmon]
	send_l8_e14_gpu14 [label="Token Send L8E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightgreen shape=ellipse]
	recv_l8_e15_gpu15 [label="Token Receive L8E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightgreen shape=ellipse]
	expert_l8_e15_gpu15 [label="Expert L8E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightsalmon]
	send_l8_e15_gpu15 [label="Token Send L8E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightgreen shape=ellipse]
	agg_l8 [label="Expert Aggregation L8\nInput: [batch_size=128, seq_len=10000, k=2, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightgray shape=parallelogram]
	residual2_l8 [label="ResidualAdd L8\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightpink]
	ln1_l9 [label="LayerNorm L9\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightyellow]
	attn_l9 [label="Multi-Head Attention L9\nInput: [batch_size=128, seq_len=10000, heads=32, d_k=128]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightcoral]
	residual1_l9 [label="ResidualAdd L9\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightpink]
	ln2_l9 [label="LayerNorm L9\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightyellow]
	route_l9 [label="Expert Routing L9\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: All GPUs" fillcolor=lightgray shape=parallelogram]
	recv_l9_e0_gpu0 [label="Token Receive L9E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightgreen shape=ellipse]
	expert_l9_e0_gpu0 [label="Expert L9E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightsalmon]
	send_l9_e0_gpu0 [label="Token Send L9E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightgreen shape=ellipse]
	recv_l9_e1_gpu1 [label="Token Receive L9E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightgreen shape=ellipse]
	expert_l9_e1_gpu1 [label="Expert L9E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightsalmon]
	send_l9_e1_gpu1 [label="Token Send L9E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightgreen shape=ellipse]
	recv_l9_e2_gpu2 [label="Token Receive L9E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightgreen shape=ellipse]
	expert_l9_e2_gpu2 [label="Expert L9E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightsalmon]
	send_l9_e2_gpu2 [label="Token Send L9E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightgreen shape=ellipse]
	recv_l9_e3_gpu3 [label="Token Receive L9E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightgreen shape=ellipse]
	expert_l9_e3_gpu3 [label="Expert L9E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightsalmon]
	send_l9_e3_gpu3 [label="Token Send L9E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightgreen shape=ellipse]
	recv_l9_e4_gpu4 [label="Token Receive L9E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightgreen shape=ellipse]
	expert_l9_e4_gpu4 [label="Expert L9E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightsalmon]
	send_l9_e4_gpu4 [label="Token Send L9E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightgreen shape=ellipse]
	recv_l9_e5_gpu5 [label="Token Receive L9E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightgreen shape=ellipse]
	expert_l9_e5_gpu5 [label="Expert L9E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightsalmon]
	send_l9_e5_gpu5 [label="Token Send L9E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightgreen shape=ellipse]
	recv_l9_e6_gpu6 [label="Token Receive L9E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightgreen shape=ellipse]
	expert_l9_e6_gpu6 [label="Expert L9E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightsalmon]
	send_l9_e6_gpu6 [label="Token Send L9E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightgreen shape=ellipse]
	recv_l9_e7_gpu7 [label="Token Receive L9E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightgreen shape=ellipse]
	expert_l9_e7_gpu7 [label="Expert L9E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightsalmon]
	send_l9_e7_gpu7 [label="Token Send L9E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightgreen shape=ellipse]
	recv_l9_e8_gpu8 [label="Token Receive L9E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightgreen shape=ellipse]
	expert_l9_e8_gpu8 [label="Expert L9E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightsalmon]
	send_l9_e8_gpu8 [label="Token Send L9E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightgreen shape=ellipse]
	recv_l9_e9_gpu9 [label="Token Receive L9E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightgreen shape=ellipse]
	expert_l9_e9_gpu9 [label="Expert L9E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightsalmon]
	send_l9_e9_gpu9 [label="Token Send L9E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightgreen shape=ellipse]
	recv_l9_e10_gpu10 [label="Token Receive L9E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightgreen shape=ellipse]
	expert_l9_e10_gpu10 [label="Expert L9E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightsalmon]
	send_l9_e10_gpu10 [label="Token Send L9E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightgreen shape=ellipse]
	recv_l9_e11_gpu11 [label="Token Receive L9E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightgreen shape=ellipse]
	expert_l9_e11_gpu11 [label="Expert L9E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightsalmon]
	send_l9_e11_gpu11 [label="Token Send L9E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightgreen shape=ellipse]
	recv_l9_e12_gpu12 [label="Token Receive L9E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightgreen shape=ellipse]
	expert_l9_e12_gpu12 [label="Expert L9E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightsalmon]
	send_l9_e12_gpu12 [label="Token Send L9E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightgreen shape=ellipse]
	recv_l9_e13_gpu13 [label="Token Receive L9E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightgreen shape=ellipse]
	expert_l9_e13_gpu13 [label="Expert L9E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightsalmon]
	send_l9_e13_gpu13 [label="Token Send L9E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightgreen shape=ellipse]
	recv_l9_e14_gpu14 [label="Token Receive L9E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightgreen shape=ellipse]
	expert_l9_e14_gpu14 [label="Expert L9E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightsalmon]
	send_l9_e14_gpu14 [label="Token Send L9E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightgreen shape=ellipse]
	recv_l9_e15_gpu15 [label="Token Receive L9E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightgreen shape=ellipse]
	expert_l9_e15_gpu15 [label="Expert L9E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightsalmon]
	send_l9_e15_gpu15 [label="Token Send L9E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightgreen shape=ellipse]
	agg_l9 [label="Expert Aggregation L9\nInput: [batch_size=128, seq_len=10000, k=2, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightgray shape=parallelogram]
	residual2_l9 [label="ResidualAdd L9\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightpink]
	ln1_l10 [label="LayerNorm L10\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightyellow]
	attn_l10 [label="Multi-Head Attention L10\nInput: [batch_size=128, seq_len=10000, heads=32, d_k=128]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightcoral]
	residual1_l10 [label="ResidualAdd L10\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightpink]
	ln2_l10 [label="LayerNorm L10\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightyellow]
	route_l10 [label="Expert Routing L10\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: All GPUs" fillcolor=lightgray shape=parallelogram]
	recv_l10_e0_gpu0 [label="Token Receive L10E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightgreen shape=ellipse]
	expert_l10_e0_gpu0 [label="Expert L10E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightsalmon]
	send_l10_e0_gpu0 [label="Token Send L10E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightgreen shape=ellipse]
	recv_l10_e1_gpu1 [label="Token Receive L10E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightgreen shape=ellipse]
	expert_l10_e1_gpu1 [label="Expert L10E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightsalmon]
	send_l10_e1_gpu1 [label="Token Send L10E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightgreen shape=ellipse]
	recv_l10_e2_gpu2 [label="Token Receive L10E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightgreen shape=ellipse]
	expert_l10_e2_gpu2 [label="Expert L10E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightsalmon]
	send_l10_e2_gpu2 [label="Token Send L10E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightgreen shape=ellipse]
	recv_l10_e3_gpu3 [label="Token Receive L10E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightgreen shape=ellipse]
	expert_l10_e3_gpu3 [label="Expert L10E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightsalmon]
	send_l10_e3_gpu3 [label="Token Send L10E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightgreen shape=ellipse]
	recv_l10_e4_gpu4 [label="Token Receive L10E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightgreen shape=ellipse]
	expert_l10_e4_gpu4 [label="Expert L10E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightsalmon]
	send_l10_e4_gpu4 [label="Token Send L10E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightgreen shape=ellipse]
	recv_l10_e5_gpu5 [label="Token Receive L10E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightgreen shape=ellipse]
	expert_l10_e5_gpu5 [label="Expert L10E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightsalmon]
	send_l10_e5_gpu5 [label="Token Send L10E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightgreen shape=ellipse]
	recv_l10_e6_gpu6 [label="Token Receive L10E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightgreen shape=ellipse]
	expert_l10_e6_gpu6 [label="Expert L10E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightsalmon]
	send_l10_e6_gpu6 [label="Token Send L10E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightgreen shape=ellipse]
	recv_l10_e7_gpu7 [label="Token Receive L10E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightgreen shape=ellipse]
	expert_l10_e7_gpu7 [label="Expert L10E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightsalmon]
	send_l10_e7_gpu7 [label="Token Send L10E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightgreen shape=ellipse]
	recv_l10_e8_gpu8 [label="Token Receive L10E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightgreen shape=ellipse]
	expert_l10_e8_gpu8 [label="Expert L10E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightsalmon]
	send_l10_e8_gpu8 [label="Token Send L10E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightgreen shape=ellipse]
	recv_l10_e9_gpu9 [label="Token Receive L10E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightgreen shape=ellipse]
	expert_l10_e9_gpu9 [label="Expert L10E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightsalmon]
	send_l10_e9_gpu9 [label="Token Send L10E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightgreen shape=ellipse]
	recv_l10_e10_gpu10 [label="Token Receive L10E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightgreen shape=ellipse]
	expert_l10_e10_gpu10 [label="Expert L10E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightsalmon]
	send_l10_e10_gpu10 [label="Token Send L10E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightgreen shape=ellipse]
	recv_l10_e11_gpu11 [label="Token Receive L10E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightgreen shape=ellipse]
	expert_l10_e11_gpu11 [label="Expert L10E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightsalmon]
	send_l10_e11_gpu11 [label="Token Send L10E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightgreen shape=ellipse]
	recv_l10_e12_gpu12 [label="Token Receive L10E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightgreen shape=ellipse]
	expert_l10_e12_gpu12 [label="Expert L10E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightsalmon]
	send_l10_e12_gpu12 [label="Token Send L10E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightgreen shape=ellipse]
	recv_l10_e13_gpu13 [label="Token Receive L10E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightgreen shape=ellipse]
	expert_l10_e13_gpu13 [label="Expert L10E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightsalmon]
	send_l10_e13_gpu13 [label="Token Send L10E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightgreen shape=ellipse]
	recv_l10_e14_gpu14 [label="Token Receive L10E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightgreen shape=ellipse]
	expert_l10_e14_gpu14 [label="Expert L10E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightsalmon]
	send_l10_e14_gpu14 [label="Token Send L10E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightgreen shape=ellipse]
	recv_l10_e15_gpu15 [label="Token Receive L10E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightgreen shape=ellipse]
	expert_l10_e15_gpu15 [label="Expert L10E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightsalmon]
	send_l10_e15_gpu15 [label="Token Send L10E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightgreen shape=ellipse]
	agg_l10 [label="Expert Aggregation L10\nInput: [batch_size=128, seq_len=10000, k=2, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightgray shape=parallelogram]
	residual2_l10 [label="ResidualAdd L10\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightpink]
	ln1_l11 [label="LayerNorm L11\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightyellow]
	attn_l11 [label="Multi-Head Attention L11\nInput: [batch_size=128, seq_len=10000, heads=32, d_k=128]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightcoral]
	residual1_l11 [label="ResidualAdd L11\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightpink]
	ln2_l11 [label="LayerNorm L11\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightyellow]
	route_l11 [label="Expert Routing L11\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: All GPUs" fillcolor=lightgray shape=parallelogram]
	recv_l11_e0_gpu0 [label="Token Receive L11E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightgreen shape=ellipse]
	expert_l11_e0_gpu0 [label="Expert L11E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightsalmon]
	send_l11_e0_gpu0 [label="Token Send L11E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightgreen shape=ellipse]
	recv_l11_e1_gpu1 [label="Token Receive L11E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightgreen shape=ellipse]
	expert_l11_e1_gpu1 [label="Expert L11E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightsalmon]
	send_l11_e1_gpu1 [label="Token Send L11E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightgreen shape=ellipse]
	recv_l11_e2_gpu2 [label="Token Receive L11E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightgreen shape=ellipse]
	expert_l11_e2_gpu2 [label="Expert L11E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightsalmon]
	send_l11_e2_gpu2 [label="Token Send L11E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightgreen shape=ellipse]
	recv_l11_e3_gpu3 [label="Token Receive L11E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightgreen shape=ellipse]
	expert_l11_e3_gpu3 [label="Expert L11E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightsalmon]
	send_l11_e3_gpu3 [label="Token Send L11E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightgreen shape=ellipse]
	recv_l11_e4_gpu4 [label="Token Receive L11E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightgreen shape=ellipse]
	expert_l11_e4_gpu4 [label="Expert L11E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightsalmon]
	send_l11_e4_gpu4 [label="Token Send L11E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightgreen shape=ellipse]
	recv_l11_e5_gpu5 [label="Token Receive L11E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightgreen shape=ellipse]
	expert_l11_e5_gpu5 [label="Expert L11E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightsalmon]
	send_l11_e5_gpu5 [label="Token Send L11E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightgreen shape=ellipse]
	recv_l11_e6_gpu6 [label="Token Receive L11E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightgreen shape=ellipse]
	expert_l11_e6_gpu6 [label="Expert L11E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightsalmon]
	send_l11_e6_gpu6 [label="Token Send L11E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightgreen shape=ellipse]
	recv_l11_e7_gpu7 [label="Token Receive L11E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightgreen shape=ellipse]
	expert_l11_e7_gpu7 [label="Expert L11E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightsalmon]
	send_l11_e7_gpu7 [label="Token Send L11E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightgreen shape=ellipse]
	recv_l11_e8_gpu8 [label="Token Receive L11E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightgreen shape=ellipse]
	expert_l11_e8_gpu8 [label="Expert L11E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightsalmon]
	send_l11_e8_gpu8 [label="Token Send L11E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightgreen shape=ellipse]
	recv_l11_e9_gpu9 [label="Token Receive L11E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightgreen shape=ellipse]
	expert_l11_e9_gpu9 [label="Expert L11E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightsalmon]
	send_l11_e9_gpu9 [label="Token Send L11E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightgreen shape=ellipse]
	recv_l11_e10_gpu10 [label="Token Receive L11E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightgreen shape=ellipse]
	expert_l11_e10_gpu10 [label="Expert L11E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightsalmon]
	send_l11_e10_gpu10 [label="Token Send L11E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightgreen shape=ellipse]
	recv_l11_e11_gpu11 [label="Token Receive L11E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightgreen shape=ellipse]
	expert_l11_e11_gpu11 [label="Expert L11E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightsalmon]
	send_l11_e11_gpu11 [label="Token Send L11E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightgreen shape=ellipse]
	recv_l11_e12_gpu12 [label="Token Receive L11E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightgreen shape=ellipse]
	expert_l11_e12_gpu12 [label="Expert L11E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightsalmon]
	send_l11_e12_gpu12 [label="Token Send L11E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightgreen shape=ellipse]
	recv_l11_e13_gpu13 [label="Token Receive L11E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightgreen shape=ellipse]
	expert_l11_e13_gpu13 [label="Expert L11E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightsalmon]
	send_l11_e13_gpu13 [label="Token Send L11E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightgreen shape=ellipse]
	recv_l11_e14_gpu14 [label="Token Receive L11E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightgreen shape=ellipse]
	expert_l11_e14_gpu14 [label="Expert L11E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightsalmon]
	send_l11_e14_gpu14 [label="Token Send L11E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightgreen shape=ellipse]
	recv_l11_e15_gpu15 [label="Token Receive L11E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightgreen shape=ellipse]
	expert_l11_e15_gpu15 [label="Expert L11E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightsalmon]
	send_l11_e15_gpu15 [label="Token Send L11E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightgreen shape=ellipse]
	agg_l11 [label="Expert Aggregation L11\nInput: [batch_size=128, seq_len=10000, k=2, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightgray shape=parallelogram]
	residual2_l11 [label="ResidualAdd L11\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightpink]
	ln1_l12 [label="LayerNorm L12\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightyellow]
	attn_l12 [label="Multi-Head Attention L12\nInput: [batch_size=128, seq_len=10000, heads=32, d_k=128]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightcoral]
	residual1_l12 [label="ResidualAdd L12\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightpink]
	ln2_l12 [label="LayerNorm L12\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightyellow]
	route_l12 [label="Expert Routing L12\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: All GPUs" fillcolor=lightgray shape=parallelogram]
	recv_l12_e0_gpu0 [label="Token Receive L12E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightgreen shape=ellipse]
	expert_l12_e0_gpu0 [label="Expert L12E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightsalmon]
	send_l12_e0_gpu0 [label="Token Send L12E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightgreen shape=ellipse]
	recv_l12_e1_gpu1 [label="Token Receive L12E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightgreen shape=ellipse]
	expert_l12_e1_gpu1 [label="Expert L12E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightsalmon]
	send_l12_e1_gpu1 [label="Token Send L12E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightgreen shape=ellipse]
	recv_l12_e2_gpu2 [label="Token Receive L12E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightgreen shape=ellipse]
	expert_l12_e2_gpu2 [label="Expert L12E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightsalmon]
	send_l12_e2_gpu2 [label="Token Send L12E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightgreen shape=ellipse]
	recv_l12_e3_gpu3 [label="Token Receive L12E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightgreen shape=ellipse]
	expert_l12_e3_gpu3 [label="Expert L12E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightsalmon]
	send_l12_e3_gpu3 [label="Token Send L12E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightgreen shape=ellipse]
	recv_l12_e4_gpu4 [label="Token Receive L12E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightgreen shape=ellipse]
	expert_l12_e4_gpu4 [label="Expert L12E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightsalmon]
	send_l12_e4_gpu4 [label="Token Send L12E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightgreen shape=ellipse]
	recv_l12_e5_gpu5 [label="Token Receive L12E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightgreen shape=ellipse]
	expert_l12_e5_gpu5 [label="Expert L12E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightsalmon]
	send_l12_e5_gpu5 [label="Token Send L12E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightgreen shape=ellipse]
	recv_l12_e6_gpu6 [label="Token Receive L12E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightgreen shape=ellipse]
	expert_l12_e6_gpu6 [label="Expert L12E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightsalmon]
	send_l12_e6_gpu6 [label="Token Send L12E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightgreen shape=ellipse]
	recv_l12_e7_gpu7 [label="Token Receive L12E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightgreen shape=ellipse]
	expert_l12_e7_gpu7 [label="Expert L12E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightsalmon]
	send_l12_e7_gpu7 [label="Token Send L12E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightgreen shape=ellipse]
	recv_l12_e8_gpu8 [label="Token Receive L12E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightgreen shape=ellipse]
	expert_l12_e8_gpu8 [label="Expert L12E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightsalmon]
	send_l12_e8_gpu8 [label="Token Send L12E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightgreen shape=ellipse]
	recv_l12_e9_gpu9 [label="Token Receive L12E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightgreen shape=ellipse]
	expert_l12_e9_gpu9 [label="Expert L12E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightsalmon]
	send_l12_e9_gpu9 [label="Token Send L12E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightgreen shape=ellipse]
	recv_l12_e10_gpu10 [label="Token Receive L12E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightgreen shape=ellipse]
	expert_l12_e10_gpu10 [label="Expert L12E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightsalmon]
	send_l12_e10_gpu10 [label="Token Send L12E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightgreen shape=ellipse]
	recv_l12_e11_gpu11 [label="Token Receive L12E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightgreen shape=ellipse]
	expert_l12_e11_gpu11 [label="Expert L12E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightsalmon]
	send_l12_e11_gpu11 [label="Token Send L12E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightgreen shape=ellipse]
	recv_l12_e12_gpu12 [label="Token Receive L12E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightgreen shape=ellipse]
	expert_l12_e12_gpu12 [label="Expert L12E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightsalmon]
	send_l12_e12_gpu12 [label="Token Send L12E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightgreen shape=ellipse]
	recv_l12_e13_gpu13 [label="Token Receive L12E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightgreen shape=ellipse]
	expert_l12_e13_gpu13 [label="Expert L12E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightsalmon]
	send_l12_e13_gpu13 [label="Token Send L12E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightgreen shape=ellipse]
	recv_l12_e14_gpu14 [label="Token Receive L12E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightgreen shape=ellipse]
	expert_l12_e14_gpu14 [label="Expert L12E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightsalmon]
	send_l12_e14_gpu14 [label="Token Send L12E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightgreen shape=ellipse]
	recv_l12_e15_gpu15 [label="Token Receive L12E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightgreen shape=ellipse]
	expert_l12_e15_gpu15 [label="Expert L12E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightsalmon]
	send_l12_e15_gpu15 [label="Token Send L12E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightgreen shape=ellipse]
	agg_l12 [label="Expert Aggregation L12\nInput: [batch_size=128, seq_len=10000, k=2, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightgray shape=parallelogram]
	residual2_l12 [label="ResidualAdd L12\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightpink]
	ln1_l13 [label="LayerNorm L13\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightyellow]
	attn_l13 [label="Multi-Head Attention L13\nInput: [batch_size=128, seq_len=10000, heads=32, d_k=128]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightcoral]
	residual1_l13 [label="ResidualAdd L13\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightpink]
	ln2_l13 [label="LayerNorm L13\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightyellow]
	route_l13 [label="Expert Routing L13\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: All GPUs" fillcolor=lightgray shape=parallelogram]
	recv_l13_e0_gpu0 [label="Token Receive L13E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightgreen shape=ellipse]
	expert_l13_e0_gpu0 [label="Expert L13E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightsalmon]
	send_l13_e0_gpu0 [label="Token Send L13E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightgreen shape=ellipse]
	recv_l13_e1_gpu1 [label="Token Receive L13E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightgreen shape=ellipse]
	expert_l13_e1_gpu1 [label="Expert L13E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightsalmon]
	send_l13_e1_gpu1 [label="Token Send L13E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightgreen shape=ellipse]
	recv_l13_e2_gpu2 [label="Token Receive L13E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightgreen shape=ellipse]
	expert_l13_e2_gpu2 [label="Expert L13E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightsalmon]
	send_l13_e2_gpu2 [label="Token Send L13E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightgreen shape=ellipse]
	recv_l13_e3_gpu3 [label="Token Receive L13E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightgreen shape=ellipse]
	expert_l13_e3_gpu3 [label="Expert L13E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightsalmon]
	send_l13_e3_gpu3 [label="Token Send L13E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightgreen shape=ellipse]
	recv_l13_e4_gpu4 [label="Token Receive L13E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightgreen shape=ellipse]
	expert_l13_e4_gpu4 [label="Expert L13E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightsalmon]
	send_l13_e4_gpu4 [label="Token Send L13E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightgreen shape=ellipse]
	recv_l13_e5_gpu5 [label="Token Receive L13E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightgreen shape=ellipse]
	expert_l13_e5_gpu5 [label="Expert L13E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightsalmon]
	send_l13_e5_gpu5 [label="Token Send L13E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightgreen shape=ellipse]
	recv_l13_e6_gpu6 [label="Token Receive L13E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightgreen shape=ellipse]
	expert_l13_e6_gpu6 [label="Expert L13E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightsalmon]
	send_l13_e6_gpu6 [label="Token Send L13E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightgreen shape=ellipse]
	recv_l13_e7_gpu7 [label="Token Receive L13E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightgreen shape=ellipse]
	expert_l13_e7_gpu7 [label="Expert L13E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightsalmon]
	send_l13_e7_gpu7 [label="Token Send L13E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightgreen shape=ellipse]
	recv_l13_e8_gpu8 [label="Token Receive L13E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightgreen shape=ellipse]
	expert_l13_e8_gpu8 [label="Expert L13E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightsalmon]
	send_l13_e8_gpu8 [label="Token Send L13E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightgreen shape=ellipse]
	recv_l13_e9_gpu9 [label="Token Receive L13E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightgreen shape=ellipse]
	expert_l13_e9_gpu9 [label="Expert L13E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightsalmon]
	send_l13_e9_gpu9 [label="Token Send L13E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightgreen shape=ellipse]
	recv_l13_e10_gpu10 [label="Token Receive L13E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightgreen shape=ellipse]
	expert_l13_e10_gpu10 [label="Expert L13E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightsalmon]
	send_l13_e10_gpu10 [label="Token Send L13E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightgreen shape=ellipse]
	recv_l13_e11_gpu11 [label="Token Receive L13E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightgreen shape=ellipse]
	expert_l13_e11_gpu11 [label="Expert L13E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightsalmon]
	send_l13_e11_gpu11 [label="Token Send L13E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightgreen shape=ellipse]
	recv_l13_e12_gpu12 [label="Token Receive L13E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightgreen shape=ellipse]
	expert_l13_e12_gpu12 [label="Expert L13E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightsalmon]
	send_l13_e12_gpu12 [label="Token Send L13E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightgreen shape=ellipse]
	recv_l13_e13_gpu13 [label="Token Receive L13E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightgreen shape=ellipse]
	expert_l13_e13_gpu13 [label="Expert L13E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightsalmon]
	send_l13_e13_gpu13 [label="Token Send L13E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightgreen shape=ellipse]
	recv_l13_e14_gpu14 [label="Token Receive L13E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightgreen shape=ellipse]
	expert_l13_e14_gpu14 [label="Expert L13E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightsalmon]
	send_l13_e14_gpu14 [label="Token Send L13E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightgreen shape=ellipse]
	recv_l13_e15_gpu15 [label="Token Receive L13E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightgreen shape=ellipse]
	expert_l13_e15_gpu15 [label="Expert L13E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightsalmon]
	send_l13_e15_gpu15 [label="Token Send L13E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightgreen shape=ellipse]
	agg_l13 [label="Expert Aggregation L13\nInput: [batch_size=128, seq_len=10000, k=2, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightgray shape=parallelogram]
	residual2_l13 [label="ResidualAdd L13\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightpink]
	ln1_l14 [label="LayerNorm L14\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightyellow]
	attn_l14 [label="Multi-Head Attention L14\nInput: [batch_size=128, seq_len=10000, heads=32, d_k=128]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightcoral]
	residual1_l14 [label="ResidualAdd L14\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightpink]
	ln2_l14 [label="LayerNorm L14\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightyellow]
	route_l14 [label="Expert Routing L14\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: All GPUs" fillcolor=lightgray shape=parallelogram]
	recv_l14_e0_gpu0 [label="Token Receive L14E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightgreen shape=ellipse]
	expert_l14_e0_gpu0 [label="Expert L14E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightsalmon]
	send_l14_e0_gpu0 [label="Token Send L14E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightgreen shape=ellipse]
	recv_l14_e1_gpu1 [label="Token Receive L14E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightgreen shape=ellipse]
	expert_l14_e1_gpu1 [label="Expert L14E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightsalmon]
	send_l14_e1_gpu1 [label="Token Send L14E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightgreen shape=ellipse]
	recv_l14_e2_gpu2 [label="Token Receive L14E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightgreen shape=ellipse]
	expert_l14_e2_gpu2 [label="Expert L14E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightsalmon]
	send_l14_e2_gpu2 [label="Token Send L14E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightgreen shape=ellipse]
	recv_l14_e3_gpu3 [label="Token Receive L14E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightgreen shape=ellipse]
	expert_l14_e3_gpu3 [label="Expert L14E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightsalmon]
	send_l14_e3_gpu3 [label="Token Send L14E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightgreen shape=ellipse]
	recv_l14_e4_gpu4 [label="Token Receive L14E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightgreen shape=ellipse]
	expert_l14_e4_gpu4 [label="Expert L14E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightsalmon]
	send_l14_e4_gpu4 [label="Token Send L14E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightgreen shape=ellipse]
	recv_l14_e5_gpu5 [label="Token Receive L14E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightgreen shape=ellipse]
	expert_l14_e5_gpu5 [label="Expert L14E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightsalmon]
	send_l14_e5_gpu5 [label="Token Send L14E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightgreen shape=ellipse]
	recv_l14_e6_gpu6 [label="Token Receive L14E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightgreen shape=ellipse]
	expert_l14_e6_gpu6 [label="Expert L14E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightsalmon]
	send_l14_e6_gpu6 [label="Token Send L14E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightgreen shape=ellipse]
	recv_l14_e7_gpu7 [label="Token Receive L14E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightgreen shape=ellipse]
	expert_l14_e7_gpu7 [label="Expert L14E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightsalmon]
	send_l14_e7_gpu7 [label="Token Send L14E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightgreen shape=ellipse]
	recv_l14_e8_gpu8 [label="Token Receive L14E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightgreen shape=ellipse]
	expert_l14_e8_gpu8 [label="Expert L14E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightsalmon]
	send_l14_e8_gpu8 [label="Token Send L14E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightgreen shape=ellipse]
	recv_l14_e9_gpu9 [label="Token Receive L14E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightgreen shape=ellipse]
	expert_l14_e9_gpu9 [label="Expert L14E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightsalmon]
	send_l14_e9_gpu9 [label="Token Send L14E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightgreen shape=ellipse]
	recv_l14_e10_gpu10 [label="Token Receive L14E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightgreen shape=ellipse]
	expert_l14_e10_gpu10 [label="Expert L14E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightsalmon]
	send_l14_e10_gpu10 [label="Token Send L14E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightgreen shape=ellipse]
	recv_l14_e11_gpu11 [label="Token Receive L14E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightgreen shape=ellipse]
	expert_l14_e11_gpu11 [label="Expert L14E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightsalmon]
	send_l14_e11_gpu11 [label="Token Send L14E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightgreen shape=ellipse]
	recv_l14_e12_gpu12 [label="Token Receive L14E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightgreen shape=ellipse]
	expert_l14_e12_gpu12 [label="Expert L14E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightsalmon]
	send_l14_e12_gpu12 [label="Token Send L14E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightgreen shape=ellipse]
	recv_l14_e13_gpu13 [label="Token Receive L14E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightgreen shape=ellipse]
	expert_l14_e13_gpu13 [label="Expert L14E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightsalmon]
	send_l14_e13_gpu13 [label="Token Send L14E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightgreen shape=ellipse]
	recv_l14_e14_gpu14 [label="Token Receive L14E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightgreen shape=ellipse]
	expert_l14_e14_gpu14 [label="Expert L14E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightsalmon]
	send_l14_e14_gpu14 [label="Token Send L14E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightgreen shape=ellipse]
	recv_l14_e15_gpu15 [label="Token Receive L14E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightgreen shape=ellipse]
	expert_l14_e15_gpu15 [label="Expert L14E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightsalmon]
	send_l14_e15_gpu15 [label="Token Send L14E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightgreen shape=ellipse]
	agg_l14 [label="Expert Aggregation L14\nInput: [batch_size=128, seq_len=10000, k=2, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightgray shape=parallelogram]
	residual2_l14 [label="ResidualAdd L14\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightpink]
	ln1_l15 [label="LayerNorm L15\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightyellow]
	attn_l15 [label="Multi-Head Attention L15\nInput: [batch_size=128, seq_len=10000, heads=32, d_k=128]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightcoral]
	residual1_l15 [label="ResidualAdd L15\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightpink]
	ln2_l15 [label="LayerNorm L15\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightyellow]
	route_l15 [label="Expert Routing L15\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: All GPUs" fillcolor=lightgray shape=parallelogram]
	recv_l15_e0_gpu0 [label="Token Receive L15E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightgreen shape=ellipse]
	expert_l15_e0_gpu0 [label="Expert L15E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightsalmon]
	send_l15_e0_gpu0 [label="Token Send L15E0\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 0" fillcolor=lightgreen shape=ellipse]
	recv_l15_e1_gpu1 [label="Token Receive L15E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightgreen shape=ellipse]
	expert_l15_e1_gpu1 [label="Expert L15E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightsalmon]
	send_l15_e1_gpu1 [label="Token Send L15E1\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 1" fillcolor=lightgreen shape=ellipse]
	recv_l15_e2_gpu2 [label="Token Receive L15E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightgreen shape=ellipse]
	expert_l15_e2_gpu2 [label="Expert L15E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightsalmon]
	send_l15_e2_gpu2 [label="Token Send L15E2\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 2" fillcolor=lightgreen shape=ellipse]
	recv_l15_e3_gpu3 [label="Token Receive L15E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightgreen shape=ellipse]
	expert_l15_e3_gpu3 [label="Expert L15E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightsalmon]
	send_l15_e3_gpu3 [label="Token Send L15E3\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 3" fillcolor=lightgreen shape=ellipse]
	recv_l15_e4_gpu4 [label="Token Receive L15E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightgreen shape=ellipse]
	expert_l15_e4_gpu4 [label="Expert L15E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightsalmon]
	send_l15_e4_gpu4 [label="Token Send L15E4\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 4" fillcolor=lightgreen shape=ellipse]
	recv_l15_e5_gpu5 [label="Token Receive L15E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightgreen shape=ellipse]
	expert_l15_e5_gpu5 [label="Expert L15E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightsalmon]
	send_l15_e5_gpu5 [label="Token Send L15E5\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 5" fillcolor=lightgreen shape=ellipse]
	recv_l15_e6_gpu6 [label="Token Receive L15E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightgreen shape=ellipse]
	expert_l15_e6_gpu6 [label="Expert L15E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightsalmon]
	send_l15_e6_gpu6 [label="Token Send L15E6\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 6" fillcolor=lightgreen shape=ellipse]
	recv_l15_e7_gpu7 [label="Token Receive L15E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightgreen shape=ellipse]
	expert_l15_e7_gpu7 [label="Expert L15E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightsalmon]
	send_l15_e7_gpu7 [label="Token Send L15E7\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 7" fillcolor=lightgreen shape=ellipse]
	recv_l15_e8_gpu8 [label="Token Receive L15E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightgreen shape=ellipse]
	expert_l15_e8_gpu8 [label="Expert L15E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightsalmon]
	send_l15_e8_gpu8 [label="Token Send L15E8\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 8" fillcolor=lightgreen shape=ellipse]
	recv_l15_e9_gpu9 [label="Token Receive L15E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightgreen shape=ellipse]
	expert_l15_e9_gpu9 [label="Expert L15E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightsalmon]
	send_l15_e9_gpu9 [label="Token Send L15E9\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 9" fillcolor=lightgreen shape=ellipse]
	recv_l15_e10_gpu10 [label="Token Receive L15E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightgreen shape=ellipse]
	expert_l15_e10_gpu10 [label="Expert L15E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightsalmon]
	send_l15_e10_gpu10 [label="Token Send L15E10\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 10" fillcolor=lightgreen shape=ellipse]
	recv_l15_e11_gpu11 [label="Token Receive L15E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightgreen shape=ellipse]
	expert_l15_e11_gpu11 [label="Expert L15E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightsalmon]
	send_l15_e11_gpu11 [label="Token Send L15E11\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 11" fillcolor=lightgreen shape=ellipse]
	recv_l15_e12_gpu12 [label="Token Receive L15E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightgreen shape=ellipse]
	expert_l15_e12_gpu12 [label="Expert L15E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightsalmon]
	send_l15_e12_gpu12 [label="Token Send L15E12\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 12" fillcolor=lightgreen shape=ellipse]
	recv_l15_e13_gpu13 [label="Token Receive L15E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightgreen shape=ellipse]
	expert_l15_e13_gpu13 [label="Expert L15E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightsalmon]
	send_l15_e13_gpu13 [label="Token Send L15E13\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 13" fillcolor=lightgreen shape=ellipse]
	recv_l15_e14_gpu14 [label="Token Receive L15E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightgreen shape=ellipse]
	expert_l15_e14_gpu14 [label="Expert L15E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightsalmon]
	send_l15_e14_gpu14 [label="Token Send L15E14\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 14" fillcolor=lightgreen shape=ellipse]
	recv_l15_e15_gpu15 [label="Token Receive L15E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightgreen shape=ellipse]
	expert_l15_e15_gpu15 [label="Expert L15E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightsalmon]
	send_l15_e15_gpu15 [label="Token Send L15E15\nInput: [batch_size=128, tokens_per_expert, d_model=4096]\nOutput: [batch_size=128, tokens_per_expert, d_model=4096]\nGPU: 15" fillcolor=lightgreen shape=ellipse]
	agg_l15 [label="Expert Aggregation L15\nInput: [batch_size=128, seq_len=10000, k=2, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightgray shape=parallelogram]
	residual2_l15 [label="ResidualAdd L15\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightpink]
	output [label="Output\nInput: [batch_size=128, seq_len=10000, d_model=4096]\nOutput: [batch_size=128, seq_len=10000, d_model=4096]\nGPU: All GPUs" fillcolor=lightgreen shape=ellipse]
	input -> router
	router -> route_l0 [style=dashed]
	router -> ln1_l0
	ln1_l0 -> attn_l0
	attn_l0 -> residual1_l0
	residual1_l0 -> ln2_l0
	ln2_l0 -> route_l0
	route_l0 -> recv_l0_e0_gpu0 [label=tokens_for_expert_0]
	recv_l0_e0_gpu0 -> expert_l0_e0_gpu0
	expert_l0_e0_gpu0 -> send_l0_e0_gpu0
	send_l0_e0_gpu0 -> agg_l0
	route_l0 -> recv_l0_e1_gpu1 [label=tokens_for_expert_1]
	recv_l0_e1_gpu1 -> expert_l0_e1_gpu1
	expert_l0_e1_gpu1 -> send_l0_e1_gpu1
	send_l0_e1_gpu1 -> agg_l0
	route_l0 -> recv_l0_e2_gpu2 [label=tokens_for_expert_2]
	recv_l0_e2_gpu2 -> expert_l0_e2_gpu2
	expert_l0_e2_gpu2 -> send_l0_e2_gpu2
	send_l0_e2_gpu2 -> agg_l0
	route_l0 -> recv_l0_e3_gpu3 [label=tokens_for_expert_3]
	recv_l0_e3_gpu3 -> expert_l0_e3_gpu3
	expert_l0_e3_gpu3 -> send_l0_e3_gpu3
	send_l0_e3_gpu3 -> agg_l0
	route_l0 -> recv_l0_e4_gpu4 [label=tokens_for_expert_4]
	recv_l0_e4_gpu4 -> expert_l0_e4_gpu4
	expert_l0_e4_gpu4 -> send_l0_e4_gpu4
	send_l0_e4_gpu4 -> agg_l0
	route_l0 -> recv_l0_e5_gpu5 [label=tokens_for_expert_5]
	recv_l0_e5_gpu5 -> expert_l0_e5_gpu5
	expert_l0_e5_gpu5 -> send_l0_e5_gpu5
	send_l0_e5_gpu5 -> agg_l0
	route_l0 -> recv_l0_e6_gpu6 [label=tokens_for_expert_6]
	recv_l0_e6_gpu6 -> expert_l0_e6_gpu6
	expert_l0_e6_gpu6 -> send_l0_e6_gpu6
	send_l0_e6_gpu6 -> agg_l0
	route_l0 -> recv_l0_e7_gpu7 [label=tokens_for_expert_7]
	recv_l0_e7_gpu7 -> expert_l0_e7_gpu7
	expert_l0_e7_gpu7 -> send_l0_e7_gpu7
	send_l0_e7_gpu7 -> agg_l0
	route_l0 -> recv_l0_e8_gpu8 [label=tokens_for_expert_8]
	recv_l0_e8_gpu8 -> expert_l0_e8_gpu8
	expert_l0_e8_gpu8 -> send_l0_e8_gpu8
	send_l0_e8_gpu8 -> agg_l0
	route_l0 -> recv_l0_e9_gpu9 [label=tokens_for_expert_9]
	recv_l0_e9_gpu9 -> expert_l0_e9_gpu9
	expert_l0_e9_gpu9 -> send_l0_e9_gpu9
	send_l0_e9_gpu9 -> agg_l0
	route_l0 -> recv_l0_e10_gpu10 [label=tokens_for_expert_10]
	recv_l0_e10_gpu10 -> expert_l0_e10_gpu10
	expert_l0_e10_gpu10 -> send_l0_e10_gpu10
	send_l0_e10_gpu10 -> agg_l0
	route_l0 -> recv_l0_e11_gpu11 [label=tokens_for_expert_11]
	recv_l0_e11_gpu11 -> expert_l0_e11_gpu11
	expert_l0_e11_gpu11 -> send_l0_e11_gpu11
	send_l0_e11_gpu11 -> agg_l0
	route_l0 -> recv_l0_e12_gpu12 [label=tokens_for_expert_12]
	recv_l0_e12_gpu12 -> expert_l0_e12_gpu12
	expert_l0_e12_gpu12 -> send_l0_e12_gpu12
	send_l0_e12_gpu12 -> agg_l0
	route_l0 -> recv_l0_e13_gpu13 [label=tokens_for_expert_13]
	recv_l0_e13_gpu13 -> expert_l0_e13_gpu13
	expert_l0_e13_gpu13 -> send_l0_e13_gpu13
	send_l0_e13_gpu13 -> agg_l0
	route_l0 -> recv_l0_e14_gpu14 [label=tokens_for_expert_14]
	recv_l0_e14_gpu14 -> expert_l0_e14_gpu14
	expert_l0_e14_gpu14 -> send_l0_e14_gpu14
	send_l0_e14_gpu14 -> agg_l0
	route_l0 -> recv_l0_e15_gpu15 [label=tokens_for_expert_15]
	recv_l0_e15_gpu15 -> expert_l0_e15_gpu15
	expert_l0_e15_gpu15 -> send_l0_e15_gpu15
	send_l0_e15_gpu15 -> agg_l0
	agg_l0 -> residual2_l0
	residual2_l0 -> ln1_l1
	router -> route_l1 [style=dashed]
	router -> ln1_l1
	ln1_l1 -> attn_l1
	attn_l1 -> residual1_l1
	residual1_l1 -> ln2_l1
	ln2_l1 -> route_l1
	route_l1 -> recv_l1_e0_gpu0 [label=tokens_for_expert_0]
	recv_l1_e0_gpu0 -> expert_l1_e0_gpu0
	expert_l1_e0_gpu0 -> send_l1_e0_gpu0
	send_l1_e0_gpu0 -> agg_l1
	route_l1 -> recv_l1_e1_gpu1 [label=tokens_for_expert_1]
	recv_l1_e1_gpu1 -> expert_l1_e1_gpu1
	expert_l1_e1_gpu1 -> send_l1_e1_gpu1
	send_l1_e1_gpu1 -> agg_l1
	route_l1 -> recv_l1_e2_gpu2 [label=tokens_for_expert_2]
	recv_l1_e2_gpu2 -> expert_l1_e2_gpu2
	expert_l1_e2_gpu2 -> send_l1_e2_gpu2
	send_l1_e2_gpu2 -> agg_l1
	route_l1 -> recv_l1_e3_gpu3 [label=tokens_for_expert_3]
	recv_l1_e3_gpu3 -> expert_l1_e3_gpu3
	expert_l1_e3_gpu3 -> send_l1_e3_gpu3
	send_l1_e3_gpu3 -> agg_l1
	route_l1 -> recv_l1_e4_gpu4 [label=tokens_for_expert_4]
	recv_l1_e4_gpu4 -> expert_l1_e4_gpu4
	expert_l1_e4_gpu4 -> send_l1_e4_gpu4
	send_l1_e4_gpu4 -> agg_l1
	route_l1 -> recv_l1_e5_gpu5 [label=tokens_for_expert_5]
	recv_l1_e5_gpu5 -> expert_l1_e5_gpu5
	expert_l1_e5_gpu5 -> send_l1_e5_gpu5
	send_l1_e5_gpu5 -> agg_l1
	route_l1 -> recv_l1_e6_gpu6 [label=tokens_for_expert_6]
	recv_l1_e6_gpu6 -> expert_l1_e6_gpu6
	expert_l1_e6_gpu6 -> send_l1_e6_gpu6
	send_l1_e6_gpu6 -> agg_l1
	route_l1 -> recv_l1_e7_gpu7 [label=tokens_for_expert_7]
	recv_l1_e7_gpu7 -> expert_l1_e7_gpu7
	expert_l1_e7_gpu7 -> send_l1_e7_gpu7
	send_l1_e7_gpu7 -> agg_l1
	route_l1 -> recv_l1_e8_gpu8 [label=tokens_for_expert_8]
	recv_l1_e8_gpu8 -> expert_l1_e8_gpu8
	expert_l1_e8_gpu8 -> send_l1_e8_gpu8
	send_l1_e8_gpu8 -> agg_l1
	route_l1 -> recv_l1_e9_gpu9 [label=tokens_for_expert_9]
	recv_l1_e9_gpu9 -> expert_l1_e9_gpu9
	expert_l1_e9_gpu9 -> send_l1_e9_gpu9
	send_l1_e9_gpu9 -> agg_l1
	route_l1 -> recv_l1_e10_gpu10 [label=tokens_for_expert_10]
	recv_l1_e10_gpu10 -> expert_l1_e10_gpu10
	expert_l1_e10_gpu10 -> send_l1_e10_gpu10
	send_l1_e10_gpu10 -> agg_l1
	route_l1 -> recv_l1_e11_gpu11 [label=tokens_for_expert_11]
	recv_l1_e11_gpu11 -> expert_l1_e11_gpu11
	expert_l1_e11_gpu11 -> send_l1_e11_gpu11
	send_l1_e11_gpu11 -> agg_l1
	route_l1 -> recv_l1_e12_gpu12 [label=tokens_for_expert_12]
	recv_l1_e12_gpu12 -> expert_l1_e12_gpu12
	expert_l1_e12_gpu12 -> send_l1_e12_gpu12
	send_l1_e12_gpu12 -> agg_l1
	route_l1 -> recv_l1_e13_gpu13 [label=tokens_for_expert_13]
	recv_l1_e13_gpu13 -> expert_l1_e13_gpu13
	expert_l1_e13_gpu13 -> send_l1_e13_gpu13
	send_l1_e13_gpu13 -> agg_l1
	route_l1 -> recv_l1_e14_gpu14 [label=tokens_for_expert_14]
	recv_l1_e14_gpu14 -> expert_l1_e14_gpu14
	expert_l1_e14_gpu14 -> send_l1_e14_gpu14
	send_l1_e14_gpu14 -> agg_l1
	route_l1 -> recv_l1_e15_gpu15 [label=tokens_for_expert_15]
	recv_l1_e15_gpu15 -> expert_l1_e15_gpu15
	expert_l1_e15_gpu15 -> send_l1_e15_gpu15
	send_l1_e15_gpu15 -> agg_l1
	agg_l1 -> residual2_l1
	residual2_l1 -> ln1_l2
	router -> route_l2 [style=dashed]
	router -> ln1_l2
	ln1_l2 -> attn_l2
	attn_l2 -> residual1_l2
	residual1_l2 -> ln2_l2
	ln2_l2 -> route_l2
	route_l2 -> recv_l2_e0_gpu0 [label=tokens_for_expert_0]
	recv_l2_e0_gpu0 -> expert_l2_e0_gpu0
	expert_l2_e0_gpu0 -> send_l2_e0_gpu0
	send_l2_e0_gpu0 -> agg_l2
	route_l2 -> recv_l2_e1_gpu1 [label=tokens_for_expert_1]
	recv_l2_e1_gpu1 -> expert_l2_e1_gpu1
	expert_l2_e1_gpu1 -> send_l2_e1_gpu1
	send_l2_e1_gpu1 -> agg_l2
	route_l2 -> recv_l2_e2_gpu2 [label=tokens_for_expert_2]
	recv_l2_e2_gpu2 -> expert_l2_e2_gpu2
	expert_l2_e2_gpu2 -> send_l2_e2_gpu2
	send_l2_e2_gpu2 -> agg_l2
	route_l2 -> recv_l2_e3_gpu3 [label=tokens_for_expert_3]
	recv_l2_e3_gpu3 -> expert_l2_e3_gpu3
	expert_l2_e3_gpu3 -> send_l2_e3_gpu3
	send_l2_e3_gpu3 -> agg_l2
	route_l2 -> recv_l2_e4_gpu4 [label=tokens_for_expert_4]
	recv_l2_e4_gpu4 -> expert_l2_e4_gpu4
	expert_l2_e4_gpu4 -> send_l2_e4_gpu4
	send_l2_e4_gpu4 -> agg_l2
	route_l2 -> recv_l2_e5_gpu5 [label=tokens_for_expert_5]
	recv_l2_e5_gpu5 -> expert_l2_e5_gpu5
	expert_l2_e5_gpu5 -> send_l2_e5_gpu5
	send_l2_e5_gpu5 -> agg_l2
	route_l2 -> recv_l2_e6_gpu6 [label=tokens_for_expert_6]
	recv_l2_e6_gpu6 -> expert_l2_e6_gpu6
	expert_l2_e6_gpu6 -> send_l2_e6_gpu6
	send_l2_e6_gpu6 -> agg_l2
	route_l2 -> recv_l2_e7_gpu7 [label=tokens_for_expert_7]
	recv_l2_e7_gpu7 -> expert_l2_e7_gpu7
	expert_l2_e7_gpu7 -> send_l2_e7_gpu7
	send_l2_e7_gpu7 -> agg_l2
	route_l2 -> recv_l2_e8_gpu8 [label=tokens_for_expert_8]
	recv_l2_e8_gpu8 -> expert_l2_e8_gpu8
	expert_l2_e8_gpu8 -> send_l2_e8_gpu8
	send_l2_e8_gpu8 -> agg_l2
	route_l2 -> recv_l2_e9_gpu9 [label=tokens_for_expert_9]
	recv_l2_e9_gpu9 -> expert_l2_e9_gpu9
	expert_l2_e9_gpu9 -> send_l2_e9_gpu9
	send_l2_e9_gpu9 -> agg_l2
	route_l2 -> recv_l2_e10_gpu10 [label=tokens_for_expert_10]
	recv_l2_e10_gpu10 -> expert_l2_e10_gpu10
	expert_l2_e10_gpu10 -> send_l2_e10_gpu10
	send_l2_e10_gpu10 -> agg_l2
	route_l2 -> recv_l2_e11_gpu11 [label=tokens_for_expert_11]
	recv_l2_e11_gpu11 -> expert_l2_e11_gpu11
	expert_l2_e11_gpu11 -> send_l2_e11_gpu11
	send_l2_e11_gpu11 -> agg_l2
	route_l2 -> recv_l2_e12_gpu12 [label=tokens_for_expert_12]
	recv_l2_e12_gpu12 -> expert_l2_e12_gpu12
	expert_l2_e12_gpu12 -> send_l2_e12_gpu12
	send_l2_e12_gpu12 -> agg_l2
	route_l2 -> recv_l2_e13_gpu13 [label=tokens_for_expert_13]
	recv_l2_e13_gpu13 -> expert_l2_e13_gpu13
	expert_l2_e13_gpu13 -> send_l2_e13_gpu13
	send_l2_e13_gpu13 -> agg_l2
	route_l2 -> recv_l2_e14_gpu14 [label=tokens_for_expert_14]
	recv_l2_e14_gpu14 -> expert_l2_e14_gpu14
	expert_l2_e14_gpu14 -> send_l2_e14_gpu14
	send_l2_e14_gpu14 -> agg_l2
	route_l2 -> recv_l2_e15_gpu15 [label=tokens_for_expert_15]
	recv_l2_e15_gpu15 -> expert_l2_e15_gpu15
	expert_l2_e15_gpu15 -> send_l2_e15_gpu15
	send_l2_e15_gpu15 -> agg_l2
	agg_l2 -> residual2_l2
	residual2_l2 -> ln1_l3
	router -> route_l3 [style=dashed]
	router -> ln1_l3
	ln1_l3 -> attn_l3
	attn_l3 -> residual1_l3
	residual1_l3 -> ln2_l3
	ln2_l3 -> route_l3
	route_l3 -> recv_l3_e0_gpu0 [label=tokens_for_expert_0]
	recv_l3_e0_gpu0 -> expert_l3_e0_gpu0
	expert_l3_e0_gpu0 -> send_l3_e0_gpu0
	send_l3_e0_gpu0 -> agg_l3
	route_l3 -> recv_l3_e1_gpu1 [label=tokens_for_expert_1]
	recv_l3_e1_gpu1 -> expert_l3_e1_gpu1
	expert_l3_e1_gpu1 -> send_l3_e1_gpu1
	send_l3_e1_gpu1 -> agg_l3
	route_l3 -> recv_l3_e2_gpu2 [label=tokens_for_expert_2]
	recv_l3_e2_gpu2 -> expert_l3_e2_gpu2
	expert_l3_e2_gpu2 -> send_l3_e2_gpu2
	send_l3_e2_gpu2 -> agg_l3
	route_l3 -> recv_l3_e3_gpu3 [label=tokens_for_expert_3]
	recv_l3_e3_gpu3 -> expert_l3_e3_gpu3
	expert_l3_e3_gpu3 -> send_l3_e3_gpu3
	send_l3_e3_gpu3 -> agg_l3
	route_l3 -> recv_l3_e4_gpu4 [label=tokens_for_expert_4]
	recv_l3_e4_gpu4 -> expert_l3_e4_gpu4
	expert_l3_e4_gpu4 -> send_l3_e4_gpu4
	send_l3_e4_gpu4 -> agg_l3
	route_l3 -> recv_l3_e5_gpu5 [label=tokens_for_expert_5]
	recv_l3_e5_gpu5 -> expert_l3_e5_gpu5
	expert_l3_e5_gpu5 -> send_l3_e5_gpu5
	send_l3_e5_gpu5 -> agg_l3
	route_l3 -> recv_l3_e6_gpu6 [label=tokens_for_expert_6]
	recv_l3_e6_gpu6 -> expert_l3_e6_gpu6
	expert_l3_e6_gpu6 -> send_l3_e6_gpu6
	send_l3_e6_gpu6 -> agg_l3
	route_l3 -> recv_l3_e7_gpu7 [label=tokens_for_expert_7]
	recv_l3_e7_gpu7 -> expert_l3_e7_gpu7
	expert_l3_e7_gpu7 -> send_l3_e7_gpu7
	send_l3_e7_gpu7 -> agg_l3
	route_l3 -> recv_l3_e8_gpu8 [label=tokens_for_expert_8]
	recv_l3_e8_gpu8 -> expert_l3_e8_gpu8
	expert_l3_e8_gpu8 -> send_l3_e8_gpu8
	send_l3_e8_gpu8 -> agg_l3
	route_l3 -> recv_l3_e9_gpu9 [label=tokens_for_expert_9]
	recv_l3_e9_gpu9 -> expert_l3_e9_gpu9
	expert_l3_e9_gpu9 -> send_l3_e9_gpu9
	send_l3_e9_gpu9 -> agg_l3
	route_l3 -> recv_l3_e10_gpu10 [label=tokens_for_expert_10]
	recv_l3_e10_gpu10 -> expert_l3_e10_gpu10
	expert_l3_e10_gpu10 -> send_l3_e10_gpu10
	send_l3_e10_gpu10 -> agg_l3
	route_l3 -> recv_l3_e11_gpu11 [label=tokens_for_expert_11]
	recv_l3_e11_gpu11 -> expert_l3_e11_gpu11
	expert_l3_e11_gpu11 -> send_l3_e11_gpu11
	send_l3_e11_gpu11 -> agg_l3
	route_l3 -> recv_l3_e12_gpu12 [label=tokens_for_expert_12]
	recv_l3_e12_gpu12 -> expert_l3_e12_gpu12
	expert_l3_e12_gpu12 -> send_l3_e12_gpu12
	send_l3_e12_gpu12 -> agg_l3
	route_l3 -> recv_l3_e13_gpu13 [label=tokens_for_expert_13]
	recv_l3_e13_gpu13 -> expert_l3_e13_gpu13
	expert_l3_e13_gpu13 -> send_l3_e13_gpu13
	send_l3_e13_gpu13 -> agg_l3
	route_l3 -> recv_l3_e14_gpu14 [label=tokens_for_expert_14]
	recv_l3_e14_gpu14 -> expert_l3_e14_gpu14
	expert_l3_e14_gpu14 -> send_l3_e14_gpu14
	send_l3_e14_gpu14 -> agg_l3
	route_l3 -> recv_l3_e15_gpu15 [label=tokens_for_expert_15]
	recv_l3_e15_gpu15 -> expert_l3_e15_gpu15
	expert_l3_e15_gpu15 -> send_l3_e15_gpu15
	send_l3_e15_gpu15 -> agg_l3
	agg_l3 -> residual2_l3
	residual2_l3 -> ln1_l4
	router -> route_l4 [style=dashed]
	router -> ln1_l4
	ln1_l4 -> attn_l4
	attn_l4 -> residual1_l4
	residual1_l4 -> ln2_l4
	ln2_l4 -> route_l4
	route_l4 -> recv_l4_e0_gpu0 [label=tokens_for_expert_0]
	recv_l4_e0_gpu0 -> expert_l4_e0_gpu0
	expert_l4_e0_gpu0 -> send_l4_e0_gpu0
	send_l4_e0_gpu0 -> agg_l4
	route_l4 -> recv_l4_e1_gpu1 [label=tokens_for_expert_1]
	recv_l4_e1_gpu1 -> expert_l4_e1_gpu1
	expert_l4_e1_gpu1 -> send_l4_e1_gpu1
	send_l4_e1_gpu1 -> agg_l4
	route_l4 -> recv_l4_e2_gpu2 [label=tokens_for_expert_2]
	recv_l4_e2_gpu2 -> expert_l4_e2_gpu2
	expert_l4_e2_gpu2 -> send_l4_e2_gpu2
	send_l4_e2_gpu2 -> agg_l4
	route_l4 -> recv_l4_e3_gpu3 [label=tokens_for_expert_3]
	recv_l4_e3_gpu3 -> expert_l4_e3_gpu3
	expert_l4_e3_gpu3 -> send_l4_e3_gpu3
	send_l4_e3_gpu3 -> agg_l4
	route_l4 -> recv_l4_e4_gpu4 [label=tokens_for_expert_4]
	recv_l4_e4_gpu4 -> expert_l4_e4_gpu4
	expert_l4_e4_gpu4 -> send_l4_e4_gpu4
	send_l4_e4_gpu4 -> agg_l4
	route_l4 -> recv_l4_e5_gpu5 [label=tokens_for_expert_5]
	recv_l4_e5_gpu5 -> expert_l4_e5_gpu5
	expert_l4_e5_gpu5 -> send_l4_e5_gpu5
	send_l4_e5_gpu5 -> agg_l4
	route_l4 -> recv_l4_e6_gpu6 [label=tokens_for_expert_6]
	recv_l4_e6_gpu6 -> expert_l4_e6_gpu6
	expert_l4_e6_gpu6 -> send_l4_e6_gpu6
	send_l4_e6_gpu6 -> agg_l4
	route_l4 -> recv_l4_e7_gpu7 [label=tokens_for_expert_7]
	recv_l4_e7_gpu7 -> expert_l4_e7_gpu7
	expert_l4_e7_gpu7 -> send_l4_e7_gpu7
	send_l4_e7_gpu7 -> agg_l4
	route_l4 -> recv_l4_e8_gpu8 [label=tokens_for_expert_8]
	recv_l4_e8_gpu8 -> expert_l4_e8_gpu8
	expert_l4_e8_gpu8 -> send_l4_e8_gpu8
	send_l4_e8_gpu8 -> agg_l4
	route_l4 -> recv_l4_e9_gpu9 [label=tokens_for_expert_9]
	recv_l4_e9_gpu9 -> expert_l4_e9_gpu9
	expert_l4_e9_gpu9 -> send_l4_e9_gpu9
	send_l4_e9_gpu9 -> agg_l4
	route_l4 -> recv_l4_e10_gpu10 [label=tokens_for_expert_10]
	recv_l4_e10_gpu10 -> expert_l4_e10_gpu10
	expert_l4_e10_gpu10 -> send_l4_e10_gpu10
	send_l4_e10_gpu10 -> agg_l4
	route_l4 -> recv_l4_e11_gpu11 [label=tokens_for_expert_11]
	recv_l4_e11_gpu11 -> expert_l4_e11_gpu11
	expert_l4_e11_gpu11 -> send_l4_e11_gpu11
	send_l4_e11_gpu11 -> agg_l4
	route_l4 -> recv_l4_e12_gpu12 [label=tokens_for_expert_12]
	recv_l4_e12_gpu12 -> expert_l4_e12_gpu12
	expert_l4_e12_gpu12 -> send_l4_e12_gpu12
	send_l4_e12_gpu12 -> agg_l4
	route_l4 -> recv_l4_e13_gpu13 [label=tokens_for_expert_13]
	recv_l4_e13_gpu13 -> expert_l4_e13_gpu13
	expert_l4_e13_gpu13 -> send_l4_e13_gpu13
	send_l4_e13_gpu13 -> agg_l4
	route_l4 -> recv_l4_e14_gpu14 [label=tokens_for_expert_14]
	recv_l4_e14_gpu14 -> expert_l4_e14_gpu14
	expert_l4_e14_gpu14 -> send_l4_e14_gpu14
	send_l4_e14_gpu14 -> agg_l4
	route_l4 -> recv_l4_e15_gpu15 [label=tokens_for_expert_15]
	recv_l4_e15_gpu15 -> expert_l4_e15_gpu15
	expert_l4_e15_gpu15 -> send_l4_e15_gpu15
	send_l4_e15_gpu15 -> agg_l4
	agg_l4 -> residual2_l4
	residual2_l4 -> ln1_l5
	router -> route_l5 [style=dashed]
	router -> ln1_l5
	ln1_l5 -> attn_l5
	attn_l5 -> residual1_l5
	residual1_l5 -> ln2_l5
	ln2_l5 -> route_l5
	route_l5 -> recv_l5_e0_gpu0 [label=tokens_for_expert_0]
	recv_l5_e0_gpu0 -> expert_l5_e0_gpu0
	expert_l5_e0_gpu0 -> send_l5_e0_gpu0
	send_l5_e0_gpu0 -> agg_l5
	route_l5 -> recv_l5_e1_gpu1 [label=tokens_for_expert_1]
	recv_l5_e1_gpu1 -> expert_l5_e1_gpu1
	expert_l5_e1_gpu1 -> send_l5_e1_gpu1
	send_l5_e1_gpu1 -> agg_l5
	route_l5 -> recv_l5_e2_gpu2 [label=tokens_for_expert_2]
	recv_l5_e2_gpu2 -> expert_l5_e2_gpu2
	expert_l5_e2_gpu2 -> send_l5_e2_gpu2
	send_l5_e2_gpu2 -> agg_l5
	route_l5 -> recv_l5_e3_gpu3 [label=tokens_for_expert_3]
	recv_l5_e3_gpu3 -> expert_l5_e3_gpu3
	expert_l5_e3_gpu3 -> send_l5_e3_gpu3
	send_l5_e3_gpu3 -> agg_l5
	route_l5 -> recv_l5_e4_gpu4 [label=tokens_for_expert_4]
	recv_l5_e4_gpu4 -> expert_l5_e4_gpu4
	expert_l5_e4_gpu4 -> send_l5_e4_gpu4
	send_l5_e4_gpu4 -> agg_l5
	route_l5 -> recv_l5_e5_gpu5 [label=tokens_for_expert_5]
	recv_l5_e5_gpu5 -> expert_l5_e5_gpu5
	expert_l5_e5_gpu5 -> send_l5_e5_gpu5
	send_l5_e5_gpu5 -> agg_l5
	route_l5 -> recv_l5_e6_gpu6 [label=tokens_for_expert_6]
	recv_l5_e6_gpu6 -> expert_l5_e6_gpu6
	expert_l5_e6_gpu6 -> send_l5_e6_gpu6
	send_l5_e6_gpu6 -> agg_l5
	route_l5 -> recv_l5_e7_gpu7 [label=tokens_for_expert_7]
	recv_l5_e7_gpu7 -> expert_l5_e7_gpu7
	expert_l5_e7_gpu7 -> send_l5_e7_gpu7
	send_l5_e7_gpu7 -> agg_l5
	route_l5 -> recv_l5_e8_gpu8 [label=tokens_for_expert_8]
	recv_l5_e8_gpu8 -> expert_l5_e8_gpu8
	expert_l5_e8_gpu8 -> send_l5_e8_gpu8
	send_l5_e8_gpu8 -> agg_l5
	route_l5 -> recv_l5_e9_gpu9 [label=tokens_for_expert_9]
	recv_l5_e9_gpu9 -> expert_l5_e9_gpu9
	expert_l5_e9_gpu9 -> send_l5_e9_gpu9
	send_l5_e9_gpu9 -> agg_l5
	route_l5 -> recv_l5_e10_gpu10 [label=tokens_for_expert_10]
	recv_l5_e10_gpu10 -> expert_l5_e10_gpu10
	expert_l5_e10_gpu10 -> send_l5_e10_gpu10
	send_l5_e10_gpu10 -> agg_l5
	route_l5 -> recv_l5_e11_gpu11 [label=tokens_for_expert_11]
	recv_l5_e11_gpu11 -> expert_l5_e11_gpu11
	expert_l5_e11_gpu11 -> send_l5_e11_gpu11
	send_l5_e11_gpu11 -> agg_l5
	route_l5 -> recv_l5_e12_gpu12 [label=tokens_for_expert_12]
	recv_l5_e12_gpu12 -> expert_l5_e12_gpu12
	expert_l5_e12_gpu12 -> send_l5_e12_gpu12
	send_l5_e12_gpu12 -> agg_l5
	route_l5 -> recv_l5_e13_gpu13 [label=tokens_for_expert_13]
	recv_l5_e13_gpu13 -> expert_l5_e13_gpu13
	expert_l5_e13_gpu13 -> send_l5_e13_gpu13
	send_l5_e13_gpu13 -> agg_l5
	route_l5 -> recv_l5_e14_gpu14 [label=tokens_for_expert_14]
	recv_l5_e14_gpu14 -> expert_l5_e14_gpu14
	expert_l5_e14_gpu14 -> send_l5_e14_gpu14
	send_l5_e14_gpu14 -> agg_l5
	route_l5 -> recv_l5_e15_gpu15 [label=tokens_for_expert_15]
	recv_l5_e15_gpu15 -> expert_l5_e15_gpu15
	expert_l5_e15_gpu15 -> send_l5_e15_gpu15
	send_l5_e15_gpu15 -> agg_l5
	agg_l5 -> residual2_l5
	residual2_l5 -> ln1_l6
	router -> route_l6 [style=dashed]
	router -> ln1_l6
	ln1_l6 -> attn_l6
	attn_l6 -> residual1_l6
	residual1_l6 -> ln2_l6
	ln2_l6 -> route_l6
	route_l6 -> recv_l6_e0_gpu0 [label=tokens_for_expert_0]
	recv_l6_e0_gpu0 -> expert_l6_e0_gpu0
	expert_l6_e0_gpu0 -> send_l6_e0_gpu0
	send_l6_e0_gpu0 -> agg_l6
	route_l6 -> recv_l6_e1_gpu1 [label=tokens_for_expert_1]
	recv_l6_e1_gpu1 -> expert_l6_e1_gpu1
	expert_l6_e1_gpu1 -> send_l6_e1_gpu1
	send_l6_e1_gpu1 -> agg_l6
	route_l6 -> recv_l6_e2_gpu2 [label=tokens_for_expert_2]
	recv_l6_e2_gpu2 -> expert_l6_e2_gpu2
	expert_l6_e2_gpu2 -> send_l6_e2_gpu2
	send_l6_e2_gpu2 -> agg_l6
	route_l6 -> recv_l6_e3_gpu3 [label=tokens_for_expert_3]
	recv_l6_e3_gpu3 -> expert_l6_e3_gpu3
	expert_l6_e3_gpu3 -> send_l6_e3_gpu3
	send_l6_e3_gpu3 -> agg_l6
	route_l6 -> recv_l6_e4_gpu4 [label=tokens_for_expert_4]
	recv_l6_e4_gpu4 -> expert_l6_e4_gpu4
	expert_l6_e4_gpu4 -> send_l6_e4_gpu4
	send_l6_e4_gpu4 -> agg_l6
	route_l6 -> recv_l6_e5_gpu5 [label=tokens_for_expert_5]
	recv_l6_e5_gpu5 -> expert_l6_e5_gpu5
	expert_l6_e5_gpu5 -> send_l6_e5_gpu5
	send_l6_e5_gpu5 -> agg_l6
	route_l6 -> recv_l6_e6_gpu6 [label=tokens_for_expert_6]
	recv_l6_e6_gpu6 -> expert_l6_e6_gpu6
	expert_l6_e6_gpu6 -> send_l6_e6_gpu6
	send_l6_e6_gpu6 -> agg_l6
	route_l6 -> recv_l6_e7_gpu7 [label=tokens_for_expert_7]
	recv_l6_e7_gpu7 -> expert_l6_e7_gpu7
	expert_l6_e7_gpu7 -> send_l6_e7_gpu7
	send_l6_e7_gpu7 -> agg_l6
	route_l6 -> recv_l6_e8_gpu8 [label=tokens_for_expert_8]
	recv_l6_e8_gpu8 -> expert_l6_e8_gpu8
	expert_l6_e8_gpu8 -> send_l6_e8_gpu8
	send_l6_e8_gpu8 -> agg_l6
	route_l6 -> recv_l6_e9_gpu9 [label=tokens_for_expert_9]
	recv_l6_e9_gpu9 -> expert_l6_e9_gpu9
	expert_l6_e9_gpu9 -> send_l6_e9_gpu9
	send_l6_e9_gpu9 -> agg_l6
	route_l6 -> recv_l6_e10_gpu10 [label=tokens_for_expert_10]
	recv_l6_e10_gpu10 -> expert_l6_e10_gpu10
	expert_l6_e10_gpu10 -> send_l6_e10_gpu10
	send_l6_e10_gpu10 -> agg_l6
	route_l6 -> recv_l6_e11_gpu11 [label=tokens_for_expert_11]
	recv_l6_e11_gpu11 -> expert_l6_e11_gpu11
	expert_l6_e11_gpu11 -> send_l6_e11_gpu11
	send_l6_e11_gpu11 -> agg_l6
	route_l6 -> recv_l6_e12_gpu12 [label=tokens_for_expert_12]
	recv_l6_e12_gpu12 -> expert_l6_e12_gpu12
	expert_l6_e12_gpu12 -> send_l6_e12_gpu12
	send_l6_e12_gpu12 -> agg_l6
	route_l6 -> recv_l6_e13_gpu13 [label=tokens_for_expert_13]
	recv_l6_e13_gpu13 -> expert_l6_e13_gpu13
	expert_l6_e13_gpu13 -> send_l6_e13_gpu13
	send_l6_e13_gpu13 -> agg_l6
	route_l6 -> recv_l6_e14_gpu14 [label=tokens_for_expert_14]
	recv_l6_e14_gpu14 -> expert_l6_e14_gpu14
	expert_l6_e14_gpu14 -> send_l6_e14_gpu14
	send_l6_e14_gpu14 -> agg_l6
	route_l6 -> recv_l6_e15_gpu15 [label=tokens_for_expert_15]
	recv_l6_e15_gpu15 -> expert_l6_e15_gpu15
	expert_l6_e15_gpu15 -> send_l6_e15_gpu15
	send_l6_e15_gpu15 -> agg_l6
	agg_l6 -> residual2_l6
	residual2_l6 -> ln1_l7
	router -> route_l7 [style=dashed]
	router -> ln1_l7
	ln1_l7 -> attn_l7
	attn_l7 -> residual1_l7
	residual1_l7 -> ln2_l7
	ln2_l7 -> route_l7
	route_l7 -> recv_l7_e0_gpu0 [label=tokens_for_expert_0]
	recv_l7_e0_gpu0 -> expert_l7_e0_gpu0
	expert_l7_e0_gpu0 -> send_l7_e0_gpu0
	send_l7_e0_gpu0 -> agg_l7
	route_l7 -> recv_l7_e1_gpu1 [label=tokens_for_expert_1]
	recv_l7_e1_gpu1 -> expert_l7_e1_gpu1
	expert_l7_e1_gpu1 -> send_l7_e1_gpu1
	send_l7_e1_gpu1 -> agg_l7
	route_l7 -> recv_l7_e2_gpu2 [label=tokens_for_expert_2]
	recv_l7_e2_gpu2 -> expert_l7_e2_gpu2
	expert_l7_e2_gpu2 -> send_l7_e2_gpu2
	send_l7_e2_gpu2 -> agg_l7
	route_l7 -> recv_l7_e3_gpu3 [label=tokens_for_expert_3]
	recv_l7_e3_gpu3 -> expert_l7_e3_gpu3
	expert_l7_e3_gpu3 -> send_l7_e3_gpu3
	send_l7_e3_gpu3 -> agg_l7
	route_l7 -> recv_l7_e4_gpu4 [label=tokens_for_expert_4]
	recv_l7_e4_gpu4 -> expert_l7_e4_gpu4
	expert_l7_e4_gpu4 -> send_l7_e4_gpu4
	send_l7_e4_gpu4 -> agg_l7
	route_l7 -> recv_l7_e5_gpu5 [label=tokens_for_expert_5]
	recv_l7_e5_gpu5 -> expert_l7_e5_gpu5
	expert_l7_e5_gpu5 -> send_l7_e5_gpu5
	send_l7_e5_gpu5 -> agg_l7
	route_l7 -> recv_l7_e6_gpu6 [label=tokens_for_expert_6]
	recv_l7_e6_gpu6 -> expert_l7_e6_gpu6
	expert_l7_e6_gpu6 -> send_l7_e6_gpu6
	send_l7_e6_gpu6 -> agg_l7
	route_l7 -> recv_l7_e7_gpu7 [label=tokens_for_expert_7]
	recv_l7_e7_gpu7 -> expert_l7_e7_gpu7
	expert_l7_e7_gpu7 -> send_l7_e7_gpu7
	send_l7_e7_gpu7 -> agg_l7
	route_l7 -> recv_l7_e8_gpu8 [label=tokens_for_expert_8]
	recv_l7_e8_gpu8 -> expert_l7_e8_gpu8
	expert_l7_e8_gpu8 -> send_l7_e8_gpu8
	send_l7_e8_gpu8 -> agg_l7
	route_l7 -> recv_l7_e9_gpu9 [label=tokens_for_expert_9]
	recv_l7_e9_gpu9 -> expert_l7_e9_gpu9
	expert_l7_e9_gpu9 -> send_l7_e9_gpu9
	send_l7_e9_gpu9 -> agg_l7
	route_l7 -> recv_l7_e10_gpu10 [label=tokens_for_expert_10]
	recv_l7_e10_gpu10 -> expert_l7_e10_gpu10
	expert_l7_e10_gpu10 -> send_l7_e10_gpu10
	send_l7_e10_gpu10 -> agg_l7
	route_l7 -> recv_l7_e11_gpu11 [label=tokens_for_expert_11]
	recv_l7_e11_gpu11 -> expert_l7_e11_gpu11
	expert_l7_e11_gpu11 -> send_l7_e11_gpu11
	send_l7_e11_gpu11 -> agg_l7
	route_l7 -> recv_l7_e12_gpu12 [label=tokens_for_expert_12]
	recv_l7_e12_gpu12 -> expert_l7_e12_gpu12
	expert_l7_e12_gpu12 -> send_l7_e12_gpu12
	send_l7_e12_gpu12 -> agg_l7
	route_l7 -> recv_l7_e13_gpu13 [label=tokens_for_expert_13]
	recv_l7_e13_gpu13 -> expert_l7_e13_gpu13
	expert_l7_e13_gpu13 -> send_l7_e13_gpu13
	send_l7_e13_gpu13 -> agg_l7
	route_l7 -> recv_l7_e14_gpu14 [label=tokens_for_expert_14]
	recv_l7_e14_gpu14 -> expert_l7_e14_gpu14
	expert_l7_e14_gpu14 -> send_l7_e14_gpu14
	send_l7_e14_gpu14 -> agg_l7
	route_l7 -> recv_l7_e15_gpu15 [label=tokens_for_expert_15]
	recv_l7_e15_gpu15 -> expert_l7_e15_gpu15
	expert_l7_e15_gpu15 -> send_l7_e15_gpu15
	send_l7_e15_gpu15 -> agg_l7
	agg_l7 -> residual2_l7
	residual2_l7 -> ln1_l8
	router -> route_l8 [style=dashed]
	router -> ln1_l8
	ln1_l8 -> attn_l8
	attn_l8 -> residual1_l8
	residual1_l8 -> ln2_l8
	ln2_l8 -> route_l8
	route_l8 -> recv_l8_e0_gpu0 [label=tokens_for_expert_0]
	recv_l8_e0_gpu0 -> expert_l8_e0_gpu0
	expert_l8_e0_gpu0 -> send_l8_e0_gpu0
	send_l8_e0_gpu0 -> agg_l8
	route_l8 -> recv_l8_e1_gpu1 [label=tokens_for_expert_1]
	recv_l8_e1_gpu1 -> expert_l8_e1_gpu1
	expert_l8_e1_gpu1 -> send_l8_e1_gpu1
	send_l8_e1_gpu1 -> agg_l8
	route_l8 -> recv_l8_e2_gpu2 [label=tokens_for_expert_2]
	recv_l8_e2_gpu2 -> expert_l8_e2_gpu2
	expert_l8_e2_gpu2 -> send_l8_e2_gpu2
	send_l8_e2_gpu2 -> agg_l8
	route_l8 -> recv_l8_e3_gpu3 [label=tokens_for_expert_3]
	recv_l8_e3_gpu3 -> expert_l8_e3_gpu3
	expert_l8_e3_gpu3 -> send_l8_e3_gpu3
	send_l8_e3_gpu3 -> agg_l8
	route_l8 -> recv_l8_e4_gpu4 [label=tokens_for_expert_4]
	recv_l8_e4_gpu4 -> expert_l8_e4_gpu4
	expert_l8_e4_gpu4 -> send_l8_e4_gpu4
	send_l8_e4_gpu4 -> agg_l8
	route_l8 -> recv_l8_e5_gpu5 [label=tokens_for_expert_5]
	recv_l8_e5_gpu5 -> expert_l8_e5_gpu5
	expert_l8_e5_gpu5 -> send_l8_e5_gpu5
	send_l8_e5_gpu5 -> agg_l8
	route_l8 -> recv_l8_e6_gpu6 [label=tokens_for_expert_6]
	recv_l8_e6_gpu6 -> expert_l8_e6_gpu6
	expert_l8_e6_gpu6 -> send_l8_e6_gpu6
	send_l8_e6_gpu6 -> agg_l8
	route_l8 -> recv_l8_e7_gpu7 [label=tokens_for_expert_7]
	recv_l8_e7_gpu7 -> expert_l8_e7_gpu7
	expert_l8_e7_gpu7 -> send_l8_e7_gpu7
	send_l8_e7_gpu7 -> agg_l8
	route_l8 -> recv_l8_e8_gpu8 [label=tokens_for_expert_8]
	recv_l8_e8_gpu8 -> expert_l8_e8_gpu8
	expert_l8_e8_gpu8 -> send_l8_e8_gpu8
	send_l8_e8_gpu8 -> agg_l8
	route_l8 -> recv_l8_e9_gpu9 [label=tokens_for_expert_9]
	recv_l8_e9_gpu9 -> expert_l8_e9_gpu9
	expert_l8_e9_gpu9 -> send_l8_e9_gpu9
	send_l8_e9_gpu9 -> agg_l8
	route_l8 -> recv_l8_e10_gpu10 [label=tokens_for_expert_10]
	recv_l8_e10_gpu10 -> expert_l8_e10_gpu10
	expert_l8_e10_gpu10 -> send_l8_e10_gpu10
	send_l8_e10_gpu10 -> agg_l8
	route_l8 -> recv_l8_e11_gpu11 [label=tokens_for_expert_11]
	recv_l8_e11_gpu11 -> expert_l8_e11_gpu11
	expert_l8_e11_gpu11 -> send_l8_e11_gpu11
	send_l8_e11_gpu11 -> agg_l8
	route_l8 -> recv_l8_e12_gpu12 [label=tokens_for_expert_12]
	recv_l8_e12_gpu12 -> expert_l8_e12_gpu12
	expert_l8_e12_gpu12 -> send_l8_e12_gpu12
	send_l8_e12_gpu12 -> agg_l8
	route_l8 -> recv_l8_e13_gpu13 [label=tokens_for_expert_13]
	recv_l8_e13_gpu13 -> expert_l8_e13_gpu13
	expert_l8_e13_gpu13 -> send_l8_e13_gpu13
	send_l8_e13_gpu13 -> agg_l8
	route_l8 -> recv_l8_e14_gpu14 [label=tokens_for_expert_14]
	recv_l8_e14_gpu14 -> expert_l8_e14_gpu14
	expert_l8_e14_gpu14 -> send_l8_e14_gpu14
	send_l8_e14_gpu14 -> agg_l8
	route_l8 -> recv_l8_e15_gpu15 [label=tokens_for_expert_15]
	recv_l8_e15_gpu15 -> expert_l8_e15_gpu15
	expert_l8_e15_gpu15 -> send_l8_e15_gpu15
	send_l8_e15_gpu15 -> agg_l8
	agg_l8 -> residual2_l8
	residual2_l8 -> ln1_l9
	router -> route_l9 [style=dashed]
	router -> ln1_l9
	ln1_l9 -> attn_l9
	attn_l9 -> residual1_l9
	residual1_l9 -> ln2_l9
	ln2_l9 -> route_l9
	route_l9 -> recv_l9_e0_gpu0 [label=tokens_for_expert_0]
	recv_l9_e0_gpu0 -> expert_l9_e0_gpu0
	expert_l9_e0_gpu0 -> send_l9_e0_gpu0
	send_l9_e0_gpu0 -> agg_l9
	route_l9 -> recv_l9_e1_gpu1 [label=tokens_for_expert_1]
	recv_l9_e1_gpu1 -> expert_l9_e1_gpu1
	expert_l9_e1_gpu1 -> send_l9_e1_gpu1
	send_l9_e1_gpu1 -> agg_l9
	route_l9 -> recv_l9_e2_gpu2 [label=tokens_for_expert_2]
	recv_l9_e2_gpu2 -> expert_l9_e2_gpu2
	expert_l9_e2_gpu2 -> send_l9_e2_gpu2
	send_l9_e2_gpu2 -> agg_l9
	route_l9 -> recv_l9_e3_gpu3 [label=tokens_for_expert_3]
	recv_l9_e3_gpu3 -> expert_l9_e3_gpu3
	expert_l9_e3_gpu3 -> send_l9_e3_gpu3
	send_l9_e3_gpu3 -> agg_l9
	route_l9 -> recv_l9_e4_gpu4 [label=tokens_for_expert_4]
	recv_l9_e4_gpu4 -> expert_l9_e4_gpu4
	expert_l9_e4_gpu4 -> send_l9_e4_gpu4
	send_l9_e4_gpu4 -> agg_l9
	route_l9 -> recv_l9_e5_gpu5 [label=tokens_for_expert_5]
	recv_l9_e5_gpu5 -> expert_l9_e5_gpu5
	expert_l9_e5_gpu5 -> send_l9_e5_gpu5
	send_l9_e5_gpu5 -> agg_l9
	route_l9 -> recv_l9_e6_gpu6 [label=tokens_for_expert_6]
	recv_l9_e6_gpu6 -> expert_l9_e6_gpu6
	expert_l9_e6_gpu6 -> send_l9_e6_gpu6
	send_l9_e6_gpu6 -> agg_l9
	route_l9 -> recv_l9_e7_gpu7 [label=tokens_for_expert_7]
	recv_l9_e7_gpu7 -> expert_l9_e7_gpu7
	expert_l9_e7_gpu7 -> send_l9_e7_gpu7
	send_l9_e7_gpu7 -> agg_l9
	route_l9 -> recv_l9_e8_gpu8 [label=tokens_for_expert_8]
	recv_l9_e8_gpu8 -> expert_l9_e8_gpu8
	expert_l9_e8_gpu8 -> send_l9_e8_gpu8
	send_l9_e8_gpu8 -> agg_l9
	route_l9 -> recv_l9_e9_gpu9 [label=tokens_for_expert_9]
	recv_l9_e9_gpu9 -> expert_l9_e9_gpu9
	expert_l9_e9_gpu9 -> send_l9_e9_gpu9
	send_l9_e9_gpu9 -> agg_l9
	route_l9 -> recv_l9_e10_gpu10 [label=tokens_for_expert_10]
	recv_l9_e10_gpu10 -> expert_l9_e10_gpu10
	expert_l9_e10_gpu10 -> send_l9_e10_gpu10
	send_l9_e10_gpu10 -> agg_l9
	route_l9 -> recv_l9_e11_gpu11 [label=tokens_for_expert_11]
	recv_l9_e11_gpu11 -> expert_l9_e11_gpu11
	expert_l9_e11_gpu11 -> send_l9_e11_gpu11
	send_l9_e11_gpu11 -> agg_l9
	route_l9 -> recv_l9_e12_gpu12 [label=tokens_for_expert_12]
	recv_l9_e12_gpu12 -> expert_l9_e12_gpu12
	expert_l9_e12_gpu12 -> send_l9_e12_gpu12
	send_l9_e12_gpu12 -> agg_l9
	route_l9 -> recv_l9_e13_gpu13 [label=tokens_for_expert_13]
	recv_l9_e13_gpu13 -> expert_l9_e13_gpu13
	expert_l9_e13_gpu13 -> send_l9_e13_gpu13
	send_l9_e13_gpu13 -> agg_l9
	route_l9 -> recv_l9_e14_gpu14 [label=tokens_for_expert_14]
	recv_l9_e14_gpu14 -> expert_l9_e14_gpu14
	expert_l9_e14_gpu14 -> send_l9_e14_gpu14
	send_l9_e14_gpu14 -> agg_l9
	route_l9 -> recv_l9_e15_gpu15 [label=tokens_for_expert_15]
	recv_l9_e15_gpu15 -> expert_l9_e15_gpu15
	expert_l9_e15_gpu15 -> send_l9_e15_gpu15
	send_l9_e15_gpu15 -> agg_l9
	agg_l9 -> residual2_l9
	residual2_l9 -> ln1_l10
	router -> route_l10 [style=dashed]
	router -> ln1_l10
	ln1_l10 -> attn_l10
	attn_l10 -> residual1_l10
	residual1_l10 -> ln2_l10
	ln2_l10 -> route_l10
	route_l10 -> recv_l10_e0_gpu0 [label=tokens_for_expert_0]
	recv_l10_e0_gpu0 -> expert_l10_e0_gpu0
	expert_l10_e0_gpu0 -> send_l10_e0_gpu0
	send_l10_e0_gpu0 -> agg_l10
	route_l10 -> recv_l10_e1_gpu1 [label=tokens_for_expert_1]
	recv_l10_e1_gpu1 -> expert_l10_e1_gpu1
	expert_l10_e1_gpu1 -> send_l10_e1_gpu1
	send_l10_e1_gpu1 -> agg_l10
	route_l10 -> recv_l10_e2_gpu2 [label=tokens_for_expert_2]
	recv_l10_e2_gpu2 -> expert_l10_e2_gpu2
	expert_l10_e2_gpu2 -> send_l10_e2_gpu2
	send_l10_e2_gpu2 -> agg_l10
	route_l10 -> recv_l10_e3_gpu3 [label=tokens_for_expert_3]
	recv_l10_e3_gpu3 -> expert_l10_e3_gpu3
	expert_l10_e3_gpu3 -> send_l10_e3_gpu3
	send_l10_e3_gpu3 -> agg_l10
	route_l10 -> recv_l10_e4_gpu4 [label=tokens_for_expert_4]
	recv_l10_e4_gpu4 -> expert_l10_e4_gpu4
	expert_l10_e4_gpu4 -> send_l10_e4_gpu4
	send_l10_e4_gpu4 -> agg_l10
	route_l10 -> recv_l10_e5_gpu5 [label=tokens_for_expert_5]
	recv_l10_e5_gpu5 -> expert_l10_e5_gpu5
	expert_l10_e5_gpu5 -> send_l10_e5_gpu5
	send_l10_e5_gpu5 -> agg_l10
	route_l10 -> recv_l10_e6_gpu6 [label=tokens_for_expert_6]
	recv_l10_e6_gpu6 -> expert_l10_e6_gpu6
	expert_l10_e6_gpu6 -> send_l10_e6_gpu6
	send_l10_e6_gpu6 -> agg_l10
	route_l10 -> recv_l10_e7_gpu7 [label=tokens_for_expert_7]
	recv_l10_e7_gpu7 -> expert_l10_e7_gpu7
	expert_l10_e7_gpu7 -> send_l10_e7_gpu7
	send_l10_e7_gpu7 -> agg_l10
	route_l10 -> recv_l10_e8_gpu8 [label=tokens_for_expert_8]
	recv_l10_e8_gpu8 -> expert_l10_e8_gpu8
	expert_l10_e8_gpu8 -> send_l10_e8_gpu8
	send_l10_e8_gpu8 -> agg_l10
	route_l10 -> recv_l10_e9_gpu9 [label=tokens_for_expert_9]
	recv_l10_e9_gpu9 -> expert_l10_e9_gpu9
	expert_l10_e9_gpu9 -> send_l10_e9_gpu9
	send_l10_e9_gpu9 -> agg_l10
	route_l10 -> recv_l10_e10_gpu10 [label=tokens_for_expert_10]
	recv_l10_e10_gpu10 -> expert_l10_e10_gpu10
	expert_l10_e10_gpu10 -> send_l10_e10_gpu10
	send_l10_e10_gpu10 -> agg_l10
	route_l10 -> recv_l10_e11_gpu11 [label=tokens_for_expert_11]
	recv_l10_e11_gpu11 -> expert_l10_e11_gpu11
	expert_l10_e11_gpu11 -> send_l10_e11_gpu11
	send_l10_e11_gpu11 -> agg_l10
	route_l10 -> recv_l10_e12_gpu12 [label=tokens_for_expert_12]
	recv_l10_e12_gpu12 -> expert_l10_e12_gpu12
	expert_l10_e12_gpu12 -> send_l10_e12_gpu12
	send_l10_e12_gpu12 -> agg_l10
	route_l10 -> recv_l10_e13_gpu13 [label=tokens_for_expert_13]
	recv_l10_e13_gpu13 -> expert_l10_e13_gpu13
	expert_l10_e13_gpu13 -> send_l10_e13_gpu13
	send_l10_e13_gpu13 -> agg_l10
	route_l10 -> recv_l10_e14_gpu14 [label=tokens_for_expert_14]
	recv_l10_e14_gpu14 -> expert_l10_e14_gpu14
	expert_l10_e14_gpu14 -> send_l10_e14_gpu14
	send_l10_e14_gpu14 -> agg_l10
	route_l10 -> recv_l10_e15_gpu15 [label=tokens_for_expert_15]
	recv_l10_e15_gpu15 -> expert_l10_e15_gpu15
	expert_l10_e15_gpu15 -> send_l10_e15_gpu15
	send_l10_e15_gpu15 -> agg_l10
	agg_l10 -> residual2_l10
	residual2_l10 -> ln1_l11
	router -> route_l11 [style=dashed]
	router -> ln1_l11
	ln1_l11 -> attn_l11
	attn_l11 -> residual1_l11
	residual1_l11 -> ln2_l11
	ln2_l11 -> route_l11
	route_l11 -> recv_l11_e0_gpu0 [label=tokens_for_expert_0]
	recv_l11_e0_gpu0 -> expert_l11_e0_gpu0
	expert_l11_e0_gpu0 -> send_l11_e0_gpu0
	send_l11_e0_gpu0 -> agg_l11
	route_l11 -> recv_l11_e1_gpu1 [label=tokens_for_expert_1]
	recv_l11_e1_gpu1 -> expert_l11_e1_gpu1
	expert_l11_e1_gpu1 -> send_l11_e1_gpu1
	send_l11_e1_gpu1 -> agg_l11
	route_l11 -> recv_l11_e2_gpu2 [label=tokens_for_expert_2]
	recv_l11_e2_gpu2 -> expert_l11_e2_gpu2
	expert_l11_e2_gpu2 -> send_l11_e2_gpu2
	send_l11_e2_gpu2 -> agg_l11
	route_l11 -> recv_l11_e3_gpu3 [label=tokens_for_expert_3]
	recv_l11_e3_gpu3 -> expert_l11_e3_gpu3
	expert_l11_e3_gpu3 -> send_l11_e3_gpu3
	send_l11_e3_gpu3 -> agg_l11
	route_l11 -> recv_l11_e4_gpu4 [label=tokens_for_expert_4]
	recv_l11_e4_gpu4 -> expert_l11_e4_gpu4
	expert_l11_e4_gpu4 -> send_l11_e4_gpu4
	send_l11_e4_gpu4 -> agg_l11
	route_l11 -> recv_l11_e5_gpu5 [label=tokens_for_expert_5]
	recv_l11_e5_gpu5 -> expert_l11_e5_gpu5
	expert_l11_e5_gpu5 -> send_l11_e5_gpu5
	send_l11_e5_gpu5 -> agg_l11
	route_l11 -> recv_l11_e6_gpu6 [label=tokens_for_expert_6]
	recv_l11_e6_gpu6 -> expert_l11_e6_gpu6
	expert_l11_e6_gpu6 -> send_l11_e6_gpu6
	send_l11_e6_gpu6 -> agg_l11
	route_l11 -> recv_l11_e7_gpu7 [label=tokens_for_expert_7]
	recv_l11_e7_gpu7 -> expert_l11_e7_gpu7
	expert_l11_e7_gpu7 -> send_l11_e7_gpu7
	send_l11_e7_gpu7 -> agg_l11
	route_l11 -> recv_l11_e8_gpu8 [label=tokens_for_expert_8]
	recv_l11_e8_gpu8 -> expert_l11_e8_gpu8
	expert_l11_e8_gpu8 -> send_l11_e8_gpu8
	send_l11_e8_gpu8 -> agg_l11
	route_l11 -> recv_l11_e9_gpu9 [label=tokens_for_expert_9]
	recv_l11_e9_gpu9 -> expert_l11_e9_gpu9
	expert_l11_e9_gpu9 -> send_l11_e9_gpu9
	send_l11_e9_gpu9 -> agg_l11
	route_l11 -> recv_l11_e10_gpu10 [label=tokens_for_expert_10]
	recv_l11_e10_gpu10 -> expert_l11_e10_gpu10
	expert_l11_e10_gpu10 -> send_l11_e10_gpu10
	send_l11_e10_gpu10 -> agg_l11
	route_l11 -> recv_l11_e11_gpu11 [label=tokens_for_expert_11]
	recv_l11_e11_gpu11 -> expert_l11_e11_gpu11
	expert_l11_e11_gpu11 -> send_l11_e11_gpu11
	send_l11_e11_gpu11 -> agg_l11
	route_l11 -> recv_l11_e12_gpu12 [label=tokens_for_expert_12]
	recv_l11_e12_gpu12 -> expert_l11_e12_gpu12
	expert_l11_e12_gpu12 -> send_l11_e12_gpu12
	send_l11_e12_gpu12 -> agg_l11
	route_l11 -> recv_l11_e13_gpu13 [label=tokens_for_expert_13]
	recv_l11_e13_gpu13 -> expert_l11_e13_gpu13
	expert_l11_e13_gpu13 -> send_l11_e13_gpu13
	send_l11_e13_gpu13 -> agg_l11
	route_l11 -> recv_l11_e14_gpu14 [label=tokens_for_expert_14]
	recv_l11_e14_gpu14 -> expert_l11_e14_gpu14
	expert_l11_e14_gpu14 -> send_l11_e14_gpu14
	send_l11_e14_gpu14 -> agg_l11
	route_l11 -> recv_l11_e15_gpu15 [label=tokens_for_expert_15]
	recv_l11_e15_gpu15 -> expert_l11_e15_gpu15
	expert_l11_e15_gpu15 -> send_l11_e15_gpu15
	send_l11_e15_gpu15 -> agg_l11
	agg_l11 -> residual2_l11
	residual2_l11 -> ln1_l12
	router -> route_l12 [style=dashed]
	router -> ln1_l12
	ln1_l12 -> attn_l12
	attn_l12 -> residual1_l12
	residual1_l12 -> ln2_l12
	ln2_l12 -> route_l12
	route_l12 -> recv_l12_e0_gpu0 [label=tokens_for_expert_0]
	recv_l12_e0_gpu0 -> expert_l12_e0_gpu0
	expert_l12_e0_gpu0 -> send_l12_e0_gpu0
	send_l12_e0_gpu0 -> agg_l12
	route_l12 -> recv_l12_e1_gpu1 [label=tokens_for_expert_1]
	recv_l12_e1_gpu1 -> expert_l12_e1_gpu1
	expert_l12_e1_gpu1 -> send_l12_e1_gpu1
	send_l12_e1_gpu1 -> agg_l12
	route_l12 -> recv_l12_e2_gpu2 [label=tokens_for_expert_2]
	recv_l12_e2_gpu2 -> expert_l12_e2_gpu2
	expert_l12_e2_gpu2 -> send_l12_e2_gpu2
	send_l12_e2_gpu2 -> agg_l12
	route_l12 -> recv_l12_e3_gpu3 [label=tokens_for_expert_3]
	recv_l12_e3_gpu3 -> expert_l12_e3_gpu3
	expert_l12_e3_gpu3 -> send_l12_e3_gpu3
	send_l12_e3_gpu3 -> agg_l12
	route_l12 -> recv_l12_e4_gpu4 [label=tokens_for_expert_4]
	recv_l12_e4_gpu4 -> expert_l12_e4_gpu4
	expert_l12_e4_gpu4 -> send_l12_e4_gpu4
	send_l12_e4_gpu4 -> agg_l12
	route_l12 -> recv_l12_e5_gpu5 [label=tokens_for_expert_5]
	recv_l12_e5_gpu5 -> expert_l12_e5_gpu5
	expert_l12_e5_gpu5 -> send_l12_e5_gpu5
	send_l12_e5_gpu5 -> agg_l12
	route_l12 -> recv_l12_e6_gpu6 [label=tokens_for_expert_6]
	recv_l12_e6_gpu6 -> expert_l12_e6_gpu6
	expert_l12_e6_gpu6 -> send_l12_e6_gpu6
	send_l12_e6_gpu6 -> agg_l12
	route_l12 -> recv_l12_e7_gpu7 [label=tokens_for_expert_7]
	recv_l12_e7_gpu7 -> expert_l12_e7_gpu7
	expert_l12_e7_gpu7 -> send_l12_e7_gpu7
	send_l12_e7_gpu7 -> agg_l12
	route_l12 -> recv_l12_e8_gpu8 [label=tokens_for_expert_8]
	recv_l12_e8_gpu8 -> expert_l12_e8_gpu8
	expert_l12_e8_gpu8 -> send_l12_e8_gpu8
	send_l12_e8_gpu8 -> agg_l12
	route_l12 -> recv_l12_e9_gpu9 [label=tokens_for_expert_9]
	recv_l12_e9_gpu9 -> expert_l12_e9_gpu9
	expert_l12_e9_gpu9 -> send_l12_e9_gpu9
	send_l12_e9_gpu9 -> agg_l12
	route_l12 -> recv_l12_e10_gpu10 [label=tokens_for_expert_10]
	recv_l12_e10_gpu10 -> expert_l12_e10_gpu10
	expert_l12_e10_gpu10 -> send_l12_e10_gpu10
	send_l12_e10_gpu10 -> agg_l12
	route_l12 -> recv_l12_e11_gpu11 [label=tokens_for_expert_11]
	recv_l12_e11_gpu11 -> expert_l12_e11_gpu11
	expert_l12_e11_gpu11 -> send_l12_e11_gpu11
	send_l12_e11_gpu11 -> agg_l12
	route_l12 -> recv_l12_e12_gpu12 [label=tokens_for_expert_12]
	recv_l12_e12_gpu12 -> expert_l12_e12_gpu12
	expert_l12_e12_gpu12 -> send_l12_e12_gpu12
	send_l12_e12_gpu12 -> agg_l12
	route_l12 -> recv_l12_e13_gpu13 [label=tokens_for_expert_13]
	recv_l12_e13_gpu13 -> expert_l12_e13_gpu13
	expert_l12_e13_gpu13 -> send_l12_e13_gpu13
	send_l12_e13_gpu13 -> agg_l12
	route_l12 -> recv_l12_e14_gpu14 [label=tokens_for_expert_14]
	recv_l12_e14_gpu14 -> expert_l12_e14_gpu14
	expert_l12_e14_gpu14 -> send_l12_e14_gpu14
	send_l12_e14_gpu14 -> agg_l12
	route_l12 -> recv_l12_e15_gpu15 [label=tokens_for_expert_15]
	recv_l12_e15_gpu15 -> expert_l12_e15_gpu15
	expert_l12_e15_gpu15 -> send_l12_e15_gpu15
	send_l12_e15_gpu15 -> agg_l12
	agg_l12 -> residual2_l12
	residual2_l12 -> ln1_l13
	router -> route_l13 [style=dashed]
	router -> ln1_l13
	ln1_l13 -> attn_l13
	attn_l13 -> residual1_l13
	residual1_l13 -> ln2_l13
	ln2_l13 -> route_l13
	route_l13 -> recv_l13_e0_gpu0 [label=tokens_for_expert_0]
	recv_l13_e0_gpu0 -> expert_l13_e0_gpu0
	expert_l13_e0_gpu0 -> send_l13_e0_gpu0
	send_l13_e0_gpu0 -> agg_l13
	route_l13 -> recv_l13_e1_gpu1 [label=tokens_for_expert_1]
	recv_l13_e1_gpu1 -> expert_l13_e1_gpu1
	expert_l13_e1_gpu1 -> send_l13_e1_gpu1
	send_l13_e1_gpu1 -> agg_l13
	route_l13 -> recv_l13_e2_gpu2 [label=tokens_for_expert_2]
	recv_l13_e2_gpu2 -> expert_l13_e2_gpu2
	expert_l13_e2_gpu2 -> send_l13_e2_gpu2
	send_l13_e2_gpu2 -> agg_l13
	route_l13 -> recv_l13_e3_gpu3 [label=tokens_for_expert_3]
	recv_l13_e3_gpu3 -> expert_l13_e3_gpu3
	expert_l13_e3_gpu3 -> send_l13_e3_gpu3
	send_l13_e3_gpu3 -> agg_l13
	route_l13 -> recv_l13_e4_gpu4 [label=tokens_for_expert_4]
	recv_l13_e4_gpu4 -> expert_l13_e4_gpu4
	expert_l13_e4_gpu4 -> send_l13_e4_gpu4
	send_l13_e4_gpu4 -> agg_l13
	route_l13 -> recv_l13_e5_gpu5 [label=tokens_for_expert_5]
	recv_l13_e5_gpu5 -> expert_l13_e5_gpu5
	expert_l13_e5_gpu5 -> send_l13_e5_gpu5
	send_l13_e5_gpu5 -> agg_l13
	route_l13 -> recv_l13_e6_gpu6 [label=tokens_for_expert_6]
	recv_l13_e6_gpu6 -> expert_l13_e6_gpu6
	expert_l13_e6_gpu6 -> send_l13_e6_gpu6
	send_l13_e6_gpu6 -> agg_l13
	route_l13 -> recv_l13_e7_gpu7 [label=tokens_for_expert_7]
	recv_l13_e7_gpu7 -> expert_l13_e7_gpu7
	expert_l13_e7_gpu7 -> send_l13_e7_gpu7
	send_l13_e7_gpu7 -> agg_l13
	route_l13 -> recv_l13_e8_gpu8 [label=tokens_for_expert_8]
	recv_l13_e8_gpu8 -> expert_l13_e8_gpu8
	expert_l13_e8_gpu8 -> send_l13_e8_gpu8
	send_l13_e8_gpu8 -> agg_l13
	route_l13 -> recv_l13_e9_gpu9 [label=tokens_for_expert_9]
	recv_l13_e9_gpu9 -> expert_l13_e9_gpu9
	expert_l13_e9_gpu9 -> send_l13_e9_gpu9
	send_l13_e9_gpu9 -> agg_l13
	route_l13 -> recv_l13_e10_gpu10 [label=tokens_for_expert_10]
	recv_l13_e10_gpu10 -> expert_l13_e10_gpu10
	expert_l13_e10_gpu10 -> send_l13_e10_gpu10
	send_l13_e10_gpu10 -> agg_l13
	route_l13 -> recv_l13_e11_gpu11 [label=tokens_for_expert_11]
	recv_l13_e11_gpu11 -> expert_l13_e11_gpu11
	expert_l13_e11_gpu11 -> send_l13_e11_gpu11
	send_l13_e11_gpu11 -> agg_l13
	route_l13 -> recv_l13_e12_gpu12 [label=tokens_for_expert_12]
	recv_l13_e12_gpu12 -> expert_l13_e12_gpu12
	expert_l13_e12_gpu12 -> send_l13_e12_gpu12
	send_l13_e12_gpu12 -> agg_l13
	route_l13 -> recv_l13_e13_gpu13 [label=tokens_for_expert_13]
	recv_l13_e13_gpu13 -> expert_l13_e13_gpu13
	expert_l13_e13_gpu13 -> send_l13_e13_gpu13
	send_l13_e13_gpu13 -> agg_l13
	route_l13 -> recv_l13_e14_gpu14 [label=tokens_for_expert_14]
	recv_l13_e14_gpu14 -> expert_l13_e14_gpu14
	expert_l13_e14_gpu14 -> send_l13_e14_gpu14
	send_l13_e14_gpu14 -> agg_l13
	route_l13 -> recv_l13_e15_gpu15 [label=tokens_for_expert_15]
	recv_l13_e15_gpu15 -> expert_l13_e15_gpu15
	expert_l13_e15_gpu15 -> send_l13_e15_gpu15
	send_l13_e15_gpu15 -> agg_l13
	agg_l13 -> residual2_l13
	residual2_l13 -> ln1_l14
	router -> route_l14 [style=dashed]
	router -> ln1_l14
	ln1_l14 -> attn_l14
	attn_l14 -> residual1_l14
	residual1_l14 -> ln2_l14
	ln2_l14 -> route_l14
	route_l14 -> recv_l14_e0_gpu0 [label=tokens_for_expert_0]
	recv_l14_e0_gpu0 -> expert_l14_e0_gpu0
	expert_l14_e0_gpu0 -> send_l14_e0_gpu0
	send_l14_e0_gpu0 -> agg_l14
	route_l14 -> recv_l14_e1_gpu1 [label=tokens_for_expert_1]
	recv_l14_e1_gpu1 -> expert_l14_e1_gpu1
	expert_l14_e1_gpu1 -> send_l14_e1_gpu1
	send_l14_e1_gpu1 -> agg_l14
	route_l14 -> recv_l14_e2_gpu2 [label=tokens_for_expert_2]
	recv_l14_e2_gpu2 -> expert_l14_e2_gpu2
	expert_l14_e2_gpu2 -> send_l14_e2_gpu2
	send_l14_e2_gpu2 -> agg_l14
	route_l14 -> recv_l14_e3_gpu3 [label=tokens_for_expert_3]
	recv_l14_e3_gpu3 -> expert_l14_e3_gpu3
	expert_l14_e3_gpu3 -> send_l14_e3_gpu3
	send_l14_e3_gpu3 -> agg_l14
	route_l14 -> recv_l14_e4_gpu4 [label=tokens_for_expert_4]
	recv_l14_e4_gpu4 -> expert_l14_e4_gpu4
	expert_l14_e4_gpu4 -> send_l14_e4_gpu4
	send_l14_e4_gpu4 -> agg_l14
	route_l14 -> recv_l14_e5_gpu5 [label=tokens_for_expert_5]
	recv_l14_e5_gpu5 -> expert_l14_e5_gpu5
	expert_l14_e5_gpu5 -> send_l14_e5_gpu5
	send_l14_e5_gpu5 -> agg_l14
	route_l14 -> recv_l14_e6_gpu6 [label=tokens_for_expert_6]
	recv_l14_e6_gpu6 -> expert_l14_e6_gpu6
	expert_l14_e6_gpu6 -> send_l14_e6_gpu6
	send_l14_e6_gpu6 -> agg_l14
	route_l14 -> recv_l14_e7_gpu7 [label=tokens_for_expert_7]
	recv_l14_e7_gpu7 -> expert_l14_e7_gpu7
	expert_l14_e7_gpu7 -> send_l14_e7_gpu7
	send_l14_e7_gpu7 -> agg_l14
	route_l14 -> recv_l14_e8_gpu8 [label=tokens_for_expert_8]
	recv_l14_e8_gpu8 -> expert_l14_e8_gpu8
	expert_l14_e8_gpu8 -> send_l14_e8_gpu8
	send_l14_e8_gpu8 -> agg_l14
	route_l14 -> recv_l14_e9_gpu9 [label=tokens_for_expert_9]
	recv_l14_e9_gpu9 -> expert_l14_e9_gpu9
	expert_l14_e9_gpu9 -> send_l14_e9_gpu9
	send_l14_e9_gpu9 -> agg_l14
	route_l14 -> recv_l14_e10_gpu10 [label=tokens_for_expert_10]
	recv_l14_e10_gpu10 -> expert_l14_e10_gpu10
	expert_l14_e10_gpu10 -> send_l14_e10_gpu10
	send_l14_e10_gpu10 -> agg_l14
	route_l14 -> recv_l14_e11_gpu11 [label=tokens_for_expert_11]
	recv_l14_e11_gpu11 -> expert_l14_e11_gpu11
	expert_l14_e11_gpu11 -> send_l14_e11_gpu11
	send_l14_e11_gpu11 -> agg_l14
	route_l14 -> recv_l14_e12_gpu12 [label=tokens_for_expert_12]
	recv_l14_e12_gpu12 -> expert_l14_e12_gpu12
	expert_l14_e12_gpu12 -> send_l14_e12_gpu12
	send_l14_e12_gpu12 -> agg_l14
	route_l14 -> recv_l14_e13_gpu13 [label=tokens_for_expert_13]
	recv_l14_e13_gpu13 -> expert_l14_e13_gpu13
	expert_l14_e13_gpu13 -> send_l14_e13_gpu13
	send_l14_e13_gpu13 -> agg_l14
	route_l14 -> recv_l14_e14_gpu14 [label=tokens_for_expert_14]
	recv_l14_e14_gpu14 -> expert_l14_e14_gpu14
	expert_l14_e14_gpu14 -> send_l14_e14_gpu14
	send_l14_e14_gpu14 -> agg_l14
	route_l14 -> recv_l14_e15_gpu15 [label=tokens_for_expert_15]
	recv_l14_e15_gpu15 -> expert_l14_e15_gpu15
	expert_l14_e15_gpu15 -> send_l14_e15_gpu15
	send_l14_e15_gpu15 -> agg_l14
	agg_l14 -> residual2_l14
	residual2_l14 -> ln1_l15
	router -> route_l15 [style=dashed]
	router -> ln1_l15
	ln1_l15 -> attn_l15
	attn_l15 -> residual1_l15
	residual1_l15 -> ln2_l15
	ln2_l15 -> route_l15
	route_l15 -> recv_l15_e0_gpu0 [label=tokens_for_expert_0]
	recv_l15_e0_gpu0 -> expert_l15_e0_gpu0
	expert_l15_e0_gpu0 -> send_l15_e0_gpu0
	send_l15_e0_gpu0 -> agg_l15
	route_l15 -> recv_l15_e1_gpu1 [label=tokens_for_expert_1]
	recv_l15_e1_gpu1 -> expert_l15_e1_gpu1
	expert_l15_e1_gpu1 -> send_l15_e1_gpu1
	send_l15_e1_gpu1 -> agg_l15
	route_l15 -> recv_l15_e2_gpu2 [label=tokens_for_expert_2]
	recv_l15_e2_gpu2 -> expert_l15_e2_gpu2
	expert_l15_e2_gpu2 -> send_l15_e2_gpu2
	send_l15_e2_gpu2 -> agg_l15
	route_l15 -> recv_l15_e3_gpu3 [label=tokens_for_expert_3]
	recv_l15_e3_gpu3 -> expert_l15_e3_gpu3
	expert_l15_e3_gpu3 -> send_l15_e3_gpu3
	send_l15_e3_gpu3 -> agg_l15
	route_l15 -> recv_l15_e4_gpu4 [label=tokens_for_expert_4]
	recv_l15_e4_gpu4 -> expert_l15_e4_gpu4
	expert_l15_e4_gpu4 -> send_l15_e4_gpu4
	send_l15_e4_gpu4 -> agg_l15
	route_l15 -> recv_l15_e5_gpu5 [label=tokens_for_expert_5]
	recv_l15_e5_gpu5 -> expert_l15_e5_gpu5
	expert_l15_e5_gpu5 -> send_l15_e5_gpu5
	send_l15_e5_gpu5 -> agg_l15
	route_l15 -> recv_l15_e6_gpu6 [label=tokens_for_expert_6]
	recv_l15_e6_gpu6 -> expert_l15_e6_gpu6
	expert_l15_e6_gpu6 -> send_l15_e6_gpu6
	send_l15_e6_gpu6 -> agg_l15
	route_l15 -> recv_l15_e7_gpu7 [label=tokens_for_expert_7]
	recv_l15_e7_gpu7 -> expert_l15_e7_gpu7
	expert_l15_e7_gpu7 -> send_l15_e7_gpu7
	send_l15_e7_gpu7 -> agg_l15
	route_l15 -> recv_l15_e8_gpu8 [label=tokens_for_expert_8]
	recv_l15_e8_gpu8 -> expert_l15_e8_gpu8
	expert_l15_e8_gpu8 -> send_l15_e8_gpu8
	send_l15_e8_gpu8 -> agg_l15
	route_l15 -> recv_l15_e9_gpu9 [label=tokens_for_expert_9]
	recv_l15_e9_gpu9 -> expert_l15_e9_gpu9
	expert_l15_e9_gpu9 -> send_l15_e9_gpu9
	send_l15_e9_gpu9 -> agg_l15
	route_l15 -> recv_l15_e10_gpu10 [label=tokens_for_expert_10]
	recv_l15_e10_gpu10 -> expert_l15_e10_gpu10
	expert_l15_e10_gpu10 -> send_l15_e10_gpu10
	send_l15_e10_gpu10 -> agg_l15
	route_l15 -> recv_l15_e11_gpu11 [label=tokens_for_expert_11]
	recv_l15_e11_gpu11 -> expert_l15_e11_gpu11
	expert_l15_e11_gpu11 -> send_l15_e11_gpu11
	send_l15_e11_gpu11 -> agg_l15
	route_l15 -> recv_l15_e12_gpu12 [label=tokens_for_expert_12]
	recv_l15_e12_gpu12 -> expert_l15_e12_gpu12
	expert_l15_e12_gpu12 -> send_l15_e12_gpu12
	send_l15_e12_gpu12 -> agg_l15
	route_l15 -> recv_l15_e13_gpu13 [label=tokens_for_expert_13]
	recv_l15_e13_gpu13 -> expert_l15_e13_gpu13
	expert_l15_e13_gpu13 -> send_l15_e13_gpu13
	send_l15_e13_gpu13 -> agg_l15
	route_l15 -> recv_l15_e14_gpu14 [label=tokens_for_expert_14]
	recv_l15_e14_gpu14 -> expert_l15_e14_gpu14
	expert_l15_e14_gpu14 -> send_l15_e14_gpu14
	send_l15_e14_gpu14 -> agg_l15
	route_l15 -> recv_l15_e15_gpu15 [label=tokens_for_expert_15]
	recv_l15_e15_gpu15 -> expert_l15_e15_gpu15
	expert_l15_e15_gpu15 -> send_l15_e15_gpu15
	send_l15_e15_gpu15 -> agg_l15
	agg_l15 -> residual2_l15
	residual2_l15 -> output
}
