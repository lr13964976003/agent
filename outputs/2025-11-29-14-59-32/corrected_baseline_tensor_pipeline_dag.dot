// Corrected Baseline Tensor Pipeline Parallelism DAG
digraph baseline_tensor_pipeline_dag {
	bgcolor=white fontname=Arial rankdir=TB
	node [fontname=Arial fontsize=10]
	node [fillcolor=lightblue shape=rectangle style=filled]
	input [label="Input\nBatch: 128\nSeq: 10000\nHidden: 4096" fillcolor=lightgreen shape=parallelogram]
	layer_0_input_dist [label="Layer 0\nInput Distribution" fillcolor=lightyellow shape=parallelogram]
	layer_0_qkv_gpu0 [label="Layer 0 QKV Proj\nGPU 0\nTP Rank 0\n[4096→12288]" fillcolor=lightblue]
	layer_0_qkv_gpu1 [label="Layer 0 QKV Proj\nGPU 1\nTP Rank 1\n[4096→12288]" fillcolor=lightblue]
	layer_0_qkv_gpu2 [label="Layer 0 QKV Proj\nGPU 2\nTP Rank 2\n[4096→12288]" fillcolor=lightblue]
	layer_0_qkv_gpu3 [label="Layer 0 QKV Proj\nGPU 3\nTP Rank 3\n[4096→12288]" fillcolor=lightblue]
	layer_0_qkv_gpu4 [label="Layer 0 QKV Proj\nGPU 4\nTP Rank 4\n[4096→12288]" fillcolor=lightblue]
	layer_0_qkv_gpu5 [label="Layer 0 QKV Proj\nGPU 5\nTP Rank 5\n[4096→12288]" fillcolor=lightblue]
	layer_0_qkv_gpu6 [label="Layer 0 QKV Proj\nGPU 6\nTP Rank 6\n[4096→12288]" fillcolor=lightblue]
	layer_0_qkv_gpu7 [label="Layer 0 QKV Proj\nGPU 7\nTP Rank 7\n[4096→12288]" fillcolor=lightblue]
	layer_0_allgather_qkv [label="Layer 0\nAllGather QKV\nTP=8" fillcolor=orange shape=ellipse]
	layer_0_attention [label="Layer 0\nAttention\n32×128 dim\nSoftmax" fillcolor=lightblue]
	layer_0_attn_out_gpu0 [label="Layer 0 Attn Out\nGPU 0\nTP Rank 0\n[4096→4096]" fillcolor=lightblue]
	layer_0_attn_out_gpu1 [label="Layer 0 Attn Out\nGPU 1\nTP Rank 1\n[4096→4096]" fillcolor=lightblue]
	layer_0_attn_out_gpu2 [label="Layer 0 Attn Out\nGPU 2\nTP Rank 2\n[4096→4096]" fillcolor=lightblue]
	layer_0_attn_out_gpu3 [label="Layer 0 Attn Out\nGPU 3\nTP Rank 3\n[4096→4096]" fillcolor=lightblue]
	layer_0_attn_out_gpu4 [label="Layer 0 Attn Out\nGPU 4\nTP Rank 4\n[4096→4096]" fillcolor=lightblue]
	layer_0_attn_out_gpu5 [label="Layer 0 Attn Out\nGPU 5\nTP Rank 5\n[4096→4096]" fillcolor=lightblue]
	layer_0_attn_out_gpu6 [label="Layer 0 Attn Out\nGPU 6\nTP Rank 6\n[4096→4096]" fillcolor=lightblue]
	layer_0_attn_out_gpu7 [label="Layer 0 Attn Out\nGPU 7\nTP Rank 7\n[4096→4096]" fillcolor=lightblue]
	layer_0_allreduce_attn [label="Layer 0\nAllReduce Attn\nTP=8" fillcolor=orange shape=ellipse]
	layer_0_residual1 [label="Layer 0\nResidual Add" fillcolor=lightyellow shape=parallelogram]
	layer_0_ln1 [label="Layer 0\nLayerNorm 1\nγ,β: 4096" fillcolor=lightblue]
	layer_0_mlp_fc1_gpu0 [label="Layer 0 MLP FC1\nGPU 0\nTP Rank 0\n[4096→16384]" fillcolor=lightblue]
	layer_0_mlp_fc1_gpu1 [label="Layer 0 MLP FC1\nGPU 1\nTP Rank 1\n[4096→16384]" fillcolor=lightblue]
	layer_0_mlp_fc1_gpu2 [label="Layer 0 MLP FC1\nGPU 2\nTP Rank 2\n[4096→16384]" fillcolor=lightblue]
	layer_0_mlp_fc1_gpu3 [label="Layer 0 MLP FC1\nGPU 3\nTP Rank 3\n[4096→16384]" fillcolor=lightblue]
	layer_0_mlp_fc1_gpu4 [label="Layer 0 MLP FC1\nGPU 4\nTP Rank 4\n[4096→16384]" fillcolor=lightblue]
	layer_0_mlp_fc1_gpu5 [label="Layer 0 MLP FC1\nGPU 5\nTP Rank 5\n[4096→16384]" fillcolor=lightblue]
	layer_0_mlp_fc1_gpu6 [label="Layer 0 MLP FC1\nGPU 6\nTP Rank 6\n[4096→16384]" fillcolor=lightblue]
	layer_0_mlp_fc1_gpu7 [label="Layer 0 MLP FC1\nGPU 7\nTP Rank 7\n[4096→16384]" fillcolor=lightblue]
	layer_0_allgather_mlp [label="Layer 0\nAllGather MLP\nTP=8" fillcolor=orange shape=ellipse]
	layer_0_gelu [label="Layer 0\nGELU Activation" fillcolor=lightblue]
	layer_0_mlp_fc2_gpu0 [label="Layer 0 MLP FC2\nGPU 0\nTP Rank 0\n[16384→4096]" fillcolor=lightblue]
	layer_0_mlp_fc2_gpu1 [label="Layer 0 MLP FC2\nGPU 1\nTP Rank 1\n[16384→4096]" fillcolor=lightblue]
	layer_0_mlp_fc2_gpu2 [label="Layer 0 MLP FC2\nGPU 2\nTP Rank 2\n[16384→4096]" fillcolor=lightblue]
	layer_0_mlp_fc2_gpu3 [label="Layer 0 MLP FC2\nGPU 3\nTP Rank 3\n[16384→4096]" fillcolor=lightblue]
	layer_0_mlp_fc2_gpu4 [label="Layer 0 MLP FC2\nGPU 4\nTP Rank 4\n[16384→4096]" fillcolor=lightblue]
	layer_0_mlp_fc2_gpu5 [label="Layer 0 MLP FC2\nGPU 5\nTP Rank 5\n[16384→4096]" fillcolor=lightblue]
	layer_0_mlp_fc2_gpu6 [label="Layer 0 MLP FC2\nGPU 6\nTP Rank 6\n[16384→4096]" fillcolor=lightblue]
	layer_0_mlp_fc2_gpu7 [label="Layer 0 MLP FC2\nGPU 7\nTP Rank 7\n[16384→4096]" fillcolor=lightblue]
	layer_0_allreduce_mlp [label="Layer 0\nAllReduce MLP\nTP=8" fillcolor=orange shape=ellipse]
	layer_0_residual2 [label="Layer 0\nResidual Add" fillcolor=lightyellow shape=parallelogram]
	layer_0_ln2 [label="Layer 0\nLayerNorm 2\nγ,β: 4096" fillcolor=lightblue]
	layer_0_output_dist [label="Layer 0\nOutput Distribution" fillcolor=lightyellow shape=parallelogram]
	layer_1_input_dist [label="Layer 1\nInput Distribution" fillcolor=lightyellow shape=parallelogram]
	layer_1_qkv_gpu0 [label="Layer 1 QKV Proj\nGPU 0\nTP Rank 0\n[4096→12288]" fillcolor=lightblue]
	layer_1_qkv_gpu1 [label="Layer 1 QKV Proj\nGPU 1\nTP Rank 1\n[4096→12288]" fillcolor=lightblue]
	layer_1_qkv_gpu2 [label="Layer 1 QKV Proj\nGPU 2\nTP Rank 2\n[4096→12288]" fillcolor=lightblue]
	layer_1_qkv_gpu3 [label="Layer 1 QKV Proj\nGPU 3\nTP Rank 3\n[4096→12288]" fillcolor=lightblue]
	layer_1_qkv_gpu4 [label="Layer 1 QKV Proj\nGPU 4\nTP Rank 4\n[4096→12288]" fillcolor=lightblue]
	layer_1_qkv_gpu5 [label="Layer 1 QKV Proj\nGPU 5\nTP Rank 5\n[4096→12288]" fillcolor=lightblue]
	layer_1_qkv_gpu6 [label="Layer 1 QKV Proj\nGPU 6\nTP Rank 6\n[4096→12288]" fillcolor=lightblue]
	layer_1_qkv_gpu7 [label="Layer 1 QKV Proj\nGPU 7\nTP Rank 7\n[4096→12288]" fillcolor=lightblue]
	layer_1_allgather_qkv [label="Layer 1\nAllGather QKV\nTP=8" fillcolor=orange shape=ellipse]
	layer_1_attention [label="Layer 1\nAttention\n32×128 dim\nSoftmax" fillcolor=lightblue]
	layer_1_attn_out_gpu0 [label="Layer 1 Attn Out\nGPU 0\nTP Rank 0\n[4096→4096]" fillcolor=lightblue]
	layer_1_attn_out_gpu1 [label="Layer 1 Attn Out\nGPU 1\nTP Rank 1\n[4096→4096]" fillcolor=lightblue]
	layer_1_attn_out_gpu2 [label="Layer 1 Attn Out\nGPU 2\nTP Rank 2\n[4096→4096]" fillcolor=lightblue]
	layer_1_attn_out_gpu3 [label="Layer 1 Attn Out\nGPU 3\nTP Rank 3\n[4096→4096]" fillcolor=lightblue]
	layer_1_attn_out_gpu4 [label="Layer 1 Attn Out\nGPU 4\nTP Rank 4\n[4096→4096]" fillcolor=lightblue]
	layer_1_attn_out_gpu5 [label="Layer 1 Attn Out\nGPU 5\nTP Rank 5\n[4096→4096]" fillcolor=lightblue]
	layer_1_attn_out_gpu6 [label="Layer 1 Attn Out\nGPU 6\nTP Rank 6\n[4096→4096]" fillcolor=lightblue]
	layer_1_attn_out_gpu7 [label="Layer 1 Attn Out\nGPU 7\nTP Rank 7\n[4096→4096]" fillcolor=lightblue]
	layer_1_allreduce_attn [label="Layer 1\nAllReduce Attn\nTP=8" fillcolor=orange shape=ellipse]
	layer_1_residual1 [label="Layer 1\nResidual Add" fillcolor=lightyellow shape=parallelogram]
	layer_1_ln1 [label="Layer 1\nLayerNorm 1\nγ,β: 4096" fillcolor=lightblue]
	layer_1_mlp_fc1_gpu0 [label="Layer 1 MLP FC1\nGPU 0\nTP Rank 0\n[4096→16384]" fillcolor=lightblue]
	layer_1_mlp_fc1_gpu1 [label="Layer 1 MLP FC1\nGPU 1\nTP Rank 1\n[4096→16384]" fillcolor=lightblue]
	layer_1_mlp_fc1_gpu2 [label="Layer 1 MLP FC1\nGPU 2\nTP Rank 2\n[4096→16384]" fillcolor=lightblue]
	layer_1_mlp_fc1_gpu3 [label="Layer 1 MLP FC1\nGPU 3\nTP Rank 3\n[4096→16384]" fillcolor=lightblue]
	layer_1_mlp_fc1_gpu4 [label="Layer 1 MLP FC1\nGPU 4\nTP Rank 4\n[4096→16384]" fillcolor=lightblue]
	layer_1_mlp_fc1_gpu5 [label="Layer 1 MLP FC1\nGPU 5\nTP Rank 5\n[4096→16384]" fillcolor=lightblue]
	layer_1_mlp_fc1_gpu6 [label="Layer 1 MLP FC1\nGPU 6\nTP Rank 6\n[4096→16384]" fillcolor=lightblue]
	layer_1_mlp_fc1_gpu7 [label="Layer 1 MLP FC1\nGPU 7\nTP Rank 7\n[4096→16384]" fillcolor=lightblue]
	layer_1_allgather_mlp [label="Layer 1\nAllGather MLP\nTP=8" fillcolor=orange shape=ellipse]
	layer_1_gelu [label="Layer 1\nGELU Activation" fillcolor=lightblue]
	layer_1_mlp_fc2_gpu0 [label="Layer 1 MLP FC2\nGPU 0\nTP Rank 0\n[16384→4096]" fillcolor=lightblue]
	layer_1_mlp_fc2_gpu1 [label="Layer 1 MLP FC2\nGPU 1\nTP Rank 1\n[16384→4096]" fillcolor=lightblue]
	layer_1_mlp_fc2_gpu2 [label="Layer 1 MLP FC2\nGPU 2\nTP Rank 2\n[16384→4096]" fillcolor=lightblue]
	layer_1_mlp_fc2_gpu3 [label="Layer 1 MLP FC2\nGPU 3\nTP Rank 3\n[16384→4096]" fillcolor=lightblue]
	layer_1_mlp_fc2_gpu4 [label="Layer 1 MLP FC2\nGPU 4\nTP Rank 4\n[16384→4096]" fillcolor=lightblue]
	layer_1_mlp_fc2_gpu5 [label="Layer 1 MLP FC2\nGPU 5\nTP Rank 5\n[16384→4096]" fillcolor=lightblue]
	layer_1_mlp_fc2_gpu6 [label="Layer 1 MLP FC2\nGPU 6\nTP Rank 6\n[16384→4096]" fillcolor=lightblue]
	layer_1_mlp_fc2_gpu7 [label="Layer 1 MLP FC2\nGPU 7\nTP Rank 7\n[16384→4096]" fillcolor=lightblue]
	layer_1_allreduce_mlp [label="Layer 1\nAllReduce MLP\nTP=8" fillcolor=orange shape=ellipse]
	layer_1_residual2 [label="Layer 1\nResidual Add" fillcolor=lightyellow shape=parallelogram]
	layer_1_ln2 [label="Layer 1\nLayerNorm 2\nγ,β: 4096" fillcolor=lightblue]
	layer_1_output_dist [label="Layer 1\nOutput Distribution" fillcolor=lightyellow shape=parallelogram]
	layer_2_input_dist [label="Layer 2\nInput Distribution" fillcolor=lightyellow shape=parallelogram]
	layer_2_qkv_gpu0 [label="Layer 2 QKV Proj\nGPU 0\nTP Rank 0\n[4096→12288]" fillcolor=lightblue]
	layer_2_qkv_gpu1 [label="Layer 2 QKV Proj\nGPU 1\nTP Rank 1\n[4096→12288]" fillcolor=lightblue]
	layer_2_qkv_gpu2 [label="Layer 2 QKV Proj\nGPU 2\nTP Rank 2\n[4096→12288]" fillcolor=lightblue]
	layer_2_qkv_gpu3 [label="Layer 2 QKV Proj\nGPU 3\nTP Rank 3\n[4096→12288]" fillcolor=lightblue]
	layer_2_qkv_gpu4 [label="Layer 2 QKV Proj\nGPU 4\nTP Rank 4\n[4096→12288]" fillcolor=lightblue]
	layer_2_qkv_gpu5 [label="Layer 2 QKV Proj\nGPU 5\nTP Rank 5\n[4096→12288]" fillcolor=lightblue]
	layer_2_qkv_gpu6 [label="Layer 2 QKV Proj\nGPU 6\nTP Rank 6\n[4096→12288]" fillcolor=lightblue]
	layer_2_qkv_gpu7 [label="Layer 2 QKV Proj\nGPU 7\nTP Rank 7\n[4096→12288]" fillcolor=lightblue]
	layer_2_allgather_qkv [label="Layer 2\nAllGather QKV\nTP=8" fillcolor=orange shape=ellipse]
	layer_2_attention [label="Layer 2\nAttention\n32×128 dim\nSoftmax" fillcolor=lightblue]
	layer_2_attn_out_gpu0 [label="Layer 2 Attn Out\nGPU 0\nTP Rank 0\n[4096→4096]" fillcolor=lightblue]
	layer_2_attn_out_gpu1 [label="Layer 2 Attn Out\nGPU 1\nTP Rank 1\n[4096→4096]" fillcolor=lightblue]
	layer_2_attn_out_gpu2 [label="Layer 2 Attn Out\nGPU 2\nTP Rank 2\n[4096→4096]" fillcolor=lightblue]
	layer_2_attn_out_gpu3 [label="Layer 2 Attn Out\nGPU 3\nTP Rank 3\n[4096→4096]" fillcolor=lightblue]
	layer_2_attn_out_gpu4 [label="Layer 2 Attn Out\nGPU 4\nTP Rank 4\n[4096→4096]" fillcolor=lightblue]
	layer_2_attn_out_gpu5 [label="Layer 2 Attn Out\nGPU 5\nTP Rank 5\n[4096→4096]" fillcolor=lightblue]
	layer_2_attn_out_gpu6 [label="Layer 2 Attn Out\nGPU 6\nTP Rank 6\n[4096→4096]" fillcolor=lightblue]
	layer_2_attn_out_gpu7 [label="Layer 2 Attn Out\nGPU 7\nTP Rank 7\n[4096→4096]" fillcolor=lightblue]
	layer_2_allreduce_attn [label="Layer 2\nAllReduce Attn\nTP=8" fillcolor=orange shape=ellipse]
	layer_2_residual1 [label="Layer 2\nResidual Add" fillcolor=lightyellow shape=parallelogram]
	layer_2_ln1 [label="Layer 2\nLayerNorm 1\nγ,β: 4096" fillcolor=lightblue]
	layer_2_mlp_fc1_gpu0 [label="Layer 2 MLP FC1\nGPU 0\nTP Rank 0\n[4096→16384]" fillcolor=lightblue]
	layer_2_mlp_fc1_gpu1 [label="Layer 2 MLP FC1\nGPU 1\nTP Rank 1\n[4096→16384]" fillcolor=lightblue]
	layer_2_mlp_fc1_gpu2 [label="Layer 2 MLP FC1\nGPU 2\nTP Rank 2\n[4096→16384]" fillcolor=lightblue]
	layer_2_mlp_fc1_gpu3 [label="Layer 2 MLP FC1\nGPU 3\nTP Rank 3\n[4096→16384]" fillcolor=lightblue]
	layer_2_mlp_fc1_gpu4 [label="Layer 2 MLP FC1\nGPU 4\nTP Rank 4\n[4096→16384]" fillcolor=lightblue]
	layer_2_mlp_fc1_gpu5 [label="Layer 2 MLP FC1\nGPU 5\nTP Rank 5\n[4096→16384]" fillcolor=lightblue]
	layer_2_mlp_fc1_gpu6 [label="Layer 2 MLP FC1\nGPU 6\nTP Rank 6\n[4096→16384]" fillcolor=lightblue]
	layer_2_mlp_fc1_gpu7 [label="Layer 2 MLP FC1\nGPU 7\nTP Rank 7\n[4096→16384]" fillcolor=lightblue]
	layer_2_allgather_mlp [label="Layer 2\nAllGather MLP\nTP=8" fillcolor=orange shape=ellipse]
	layer_2_gelu [label="Layer 2\nGELU Activation" fillcolor=lightblue]
	layer_2_mlp_fc2_gpu0 [label="Layer 2 MLP FC2\nGPU 0\nTP Rank 0\n[16384→4096]" fillcolor=lightblue]
	layer_2_mlp_fc2_gpu1 [label="Layer 2 MLP FC2\nGPU 1\nTP Rank 1\n[16384→4096]" fillcolor=lightblue]
	layer_2_mlp_fc2_gpu2 [label="Layer 2 MLP FC2\nGPU 2\nTP Rank 2\n[16384→4096]" fillcolor=lightblue]
	layer_2_mlp_fc2_gpu3 [label="Layer 2 MLP FC2\nGPU 3\nTP Rank 3\n[16384→4096]" fillcolor=lightblue]
	layer_2_mlp_fc2_gpu4 [label="Layer 2 MLP FC2\nGPU 4\nTP Rank 4\n[16384→4096]" fillcolor=lightblue]
	layer_2_mlp_fc2_gpu5 [label="Layer 2 MLP FC2\nGPU 5\nTP Rank 5\n[16384→4096]" fillcolor=lightblue]
	layer_2_mlp_fc2_gpu6 [label="Layer 2 MLP FC2\nGPU 6\nTP Rank 6\n[16384→4096]" fillcolor=lightblue]
	layer_2_mlp_fc2_gpu7 [label="Layer 2 MLP FC2\nGPU 7\nTP Rank 7\n[16384→4096]" fillcolor=lightblue]
	layer_2_allreduce_mlp [label="Layer 2\nAllReduce MLP\nTP=8" fillcolor=orange shape=ellipse]
	layer_2_residual2 [label="Layer 2\nResidual Add" fillcolor=lightyellow shape=parallelogram]
	layer_2_ln2 [label="Layer 2\nLayerNorm 2\nγ,β: 4096" fillcolor=lightblue]
	layer_2_output_dist [label="Layer 2\nOutput Distribution" fillcolor=lightyellow shape=parallelogram]
	layer_3_input_dist [label="Layer 3\nInput Distribution" fillcolor=lightyellow shape=parallelogram]
	layer_3_qkv_gpu0 [label="Layer 3 QKV Proj\nGPU 0\nTP Rank 0\n[4096→12288]" fillcolor=lightblue]
	layer_3_qkv_gpu1 [label="Layer 3 QKV Proj\nGPU 1\nTP Rank 1\n[4096→12288]" fillcolor=lightblue]
	layer_3_qkv_gpu2 [label="Layer 3 QKV Proj\nGPU 2\nTP Rank 2\n[4096→12288]" fillcolor=lightblue]
	layer_3_qkv_gpu3 [label="Layer 3 QKV Proj\nGPU 3\nTP Rank 3\n[4096→12288]" fillcolor=lightblue]
	layer_3_qkv_gpu4 [label="Layer 3 QKV Proj\nGPU 4\nTP Rank 4\n[4096→12288]" fillcolor=lightblue]
	layer_3_qkv_gpu5 [label="Layer 3 QKV Proj\nGPU 5\nTP Rank 5\n[4096→12288]" fillcolor=lightblue]
	layer_3_qkv_gpu6 [label="Layer 3 QKV Proj\nGPU 6\nTP Rank 6\n[4096→12288]" fillcolor=lightblue]
	layer_3_qkv_gpu7 [label="Layer 3 QKV Proj\nGPU 7\nTP Rank 7\n[4096→12288]" fillcolor=lightblue]
	layer_3_allgather_qkv [label="Layer 3\nAllGather QKV\nTP=8" fillcolor=orange shape=ellipse]
	layer_3_attention [label="Layer 3\nAttention\n32×128 dim\nSoftmax" fillcolor=lightblue]
	layer_3_attn_out_gpu0 [label="Layer 3 Attn Out\nGPU 0\nTP Rank 0\n[4096→4096]" fillcolor=lightblue]
	layer_3_attn_out_gpu1 [label="Layer 3 Attn Out\nGPU 1\nTP Rank 1\n[4096→4096]" fillcolor=lightblue]
	layer_3_attn_out_gpu2 [label="Layer 3 Attn Out\nGPU 2\nTP Rank 2\n[4096→4096]" fillcolor=lightblue]
	layer_3_attn_out_gpu3 [label="Layer 3 Attn Out\nGPU 3\nTP Rank 3\n[4096→4096]" fillcolor=lightblue]
	layer_3_attn_out_gpu4 [label="Layer 3 Attn Out\nGPU 4\nTP Rank 4\n[4096→4096]" fillcolor=lightblue]
	layer_3_attn_out_gpu5 [label="Layer 3 Attn Out\nGPU 5\nTP Rank 5\n[4096→4096]" fillcolor=lightblue]
	layer_3_attn_out_gpu6 [label="Layer 3 Attn Out\nGPU 6\nTP Rank 6\n[4096→4096]" fillcolor=lightblue]
	layer_3_attn_out_gpu7 [label="Layer 3 Attn Out\nGPU 7\nTP Rank 7\n[4096→4096]" fillcolor=lightblue]
	layer_3_allreduce_attn [label="Layer 3\nAllReduce Attn\nTP=8" fillcolor=orange shape=ellipse]
	layer_3_residual1 [label="Layer 3\nResidual Add" fillcolor=lightyellow shape=parallelogram]
	layer_3_ln1 [label="Layer 3\nLayerNorm 1\nγ,β: 4096" fillcolor=lightblue]
	layer_3_mlp_fc1_gpu0 [label="Layer 3 MLP FC1\nGPU 0\nTP Rank 0\n[4096→16384]" fillcolor=lightblue]
	layer_3_mlp_fc1_gpu1 [label="Layer 3 MLP FC1\nGPU 1\nTP Rank 1\n[4096→16384]" fillcolor=lightblue]
	layer_3_mlp_fc1_gpu2 [label="Layer 3 MLP FC1\nGPU 2\nTP Rank 2\n[4096→16384]" fillcolor=lightblue]
	layer_3_mlp_fc1_gpu3 [label="Layer 3 MLP FC1\nGPU 3\nTP Rank 3\n[4096→16384]" fillcolor=lightblue]
	layer_3_mlp_fc1_gpu4 [label="Layer 3 MLP FC1\nGPU 4\nTP Rank 4\n[4096→16384]" fillcolor=lightblue]
	layer_3_mlp_fc1_gpu5 [label="Layer 3 MLP FC1\nGPU 5\nTP Rank 5\n[4096→16384]" fillcolor=lightblue]
	layer_3_mlp_fc1_gpu6 [label="Layer 3 MLP FC1\nGPU 6\nTP Rank 6\n[4096→16384]" fillcolor=lightblue]
	layer_3_mlp_fc1_gpu7 [label="Layer 3 MLP FC1\nGPU 7\nTP Rank 7\n[4096→16384]" fillcolor=lightblue]
	layer_3_allgather_mlp [label="Layer 3\nAllGather MLP\nTP=8" fillcolor=orange shape=ellipse]
	layer_3_gelu [label="Layer 3\nGELU Activation" fillcolor=lightblue]
	layer_3_mlp_fc2_gpu0 [label="Layer 3 MLP FC2\nGPU 0\nTP Rank 0\n[16384→4096]" fillcolor=lightblue]
	layer_3_mlp_fc2_gpu1 [label="Layer 3 MLP FC2\nGPU 1\nTP Rank 1\n[16384→4096]" fillcolor=lightblue]
	layer_3_mlp_fc2_gpu2 [label="Layer 3 MLP FC2\nGPU 2\nTP Rank 2\n[16384→4096]" fillcolor=lightblue]
	layer_3_mlp_fc2_gpu3 [label="Layer 3 MLP FC2\nGPU 3\nTP Rank 3\n[16384→4096]" fillcolor=lightblue]
	layer_3_mlp_fc2_gpu4 [label="Layer 3 MLP FC2\nGPU 4\nTP Rank 4\n[16384→4096]" fillcolor=lightblue]
	layer_3_mlp_fc2_gpu5 [label="Layer 3 MLP FC2\nGPU 5\nTP Rank 5\n[16384→4096]" fillcolor=lightblue]
	layer_3_mlp_fc2_gpu6 [label="Layer 3 MLP FC2\nGPU 6\nTP Rank 6\n[16384→4096]" fillcolor=lightblue]
	layer_3_mlp_fc2_gpu7 [label="Layer 3 MLP FC2\nGPU 7\nTP Rank 7\n[16384→4096]" fillcolor=lightblue]
	layer_3_allreduce_mlp [label="Layer 3\nAllReduce MLP\nTP=8" fillcolor=orange shape=ellipse]
	layer_3_residual2 [label="Layer 3\nResidual Add" fillcolor=lightyellow shape=parallelogram]
	layer_3_ln2 [label="Layer 3\nLayerNorm 2\nγ,β: 4096" fillcolor=lightblue]
	layer_3_output_dist [label="Layer 3\nOutput Distribution" fillcolor=lightyellow shape=parallelogram]
	layer_4_input_dist [label="Layer 4\nInput Distribution" fillcolor=lightyellow shape=parallelogram]
	layer_4_qkv_gpu0 [label="Layer 4 QKV Proj\nGPU 0\nTP Rank 0\n[4096→12288]" fillcolor=lightblue]
	layer_4_qkv_gpu1 [label="Layer 4 QKV Proj\nGPU 1\nTP Rank 1\n[4096→12288]" fillcolor=lightblue]
	layer_4_qkv_gpu2 [label="Layer 4 QKV Proj\nGPU 2\nTP Rank 2\n[4096→12288]" fillcolor=lightblue]
	layer_4_qkv_gpu3 [label="Layer 4 QKV Proj\nGPU 3\nTP Rank 3\n[4096→12288]" fillcolor=lightblue]
	layer_4_qkv_gpu4 [label="Layer 4 QKV Proj\nGPU 4\nTP Rank 4\n[4096→12288]" fillcolor=lightblue]
	layer_4_qkv_gpu5 [label="Layer 4 QKV Proj\nGPU 5\nTP Rank 5\n[4096→12288]" fillcolor=lightblue]
	layer_4_qkv_gpu6 [label="Layer 4 QKV Proj\nGPU 6\nTP Rank 6\n[4096→12288]" fillcolor=lightblue]
	layer_4_qkv_gpu7 [label="Layer 4 QKV Proj\nGPU 7\nTP Rank 7\n[4096→12288]" fillcolor=lightblue]
	layer_4_allgather_qkv [label="Layer 4\nAllGather QKV\nTP=8" fillcolor=orange shape=ellipse]
	layer_4_attention [label="Layer 4\nAttention\n32×128 dim\nSoftmax" fillcolor=lightblue]
	layer_4_attn_out_gpu0 [label="Layer 4 Attn Out\nGPU 0\nTP Rank 0\n[4096→4096]" fillcolor=lightblue]
	layer_4_attn_out_gpu1 [label="Layer 4 Attn Out\nGPU 1\nTP Rank 1\n[4096→4096]" fillcolor=lightblue]
	layer_4_attn_out_gpu2 [label="Layer 4 Attn Out\nGPU 2\nTP Rank 2\n[4096→4096]" fillcolor=lightblue]
	layer_4_attn_out_gpu3 [label="Layer 4 Attn Out\nGPU 3\nTP Rank 3\n[4096→4096]" fillcolor=lightblue]
	layer_4_attn_out_gpu4 [label="Layer 4 Attn Out\nGPU 4\nTP Rank 4\n[4096→4096]" fillcolor=lightblue]
	layer_4_attn_out_gpu5 [label="Layer 4 Attn Out\nGPU 5\nTP Rank 5\n[4096→4096]" fillcolor=lightblue]
	layer_4_attn_out_gpu6 [label="Layer 4 Attn Out\nGPU 6\nTP Rank 6\n[4096→4096]" fillcolor=lightblue]
	layer_4_attn_out_gpu7 [label="Layer 4 Attn Out\nGPU 7\nTP Rank 7\n[4096→4096]" fillcolor=lightblue]
	layer_4_allreduce_attn [label="Layer 4\nAllReduce Attn\nTP=8" fillcolor=orange shape=ellipse]
	layer_4_residual1 [label="Layer 4\nResidual Add" fillcolor=lightyellow shape=parallelogram]
	layer_4_ln1 [label="Layer 4\nLayerNorm 1\nγ,β: 4096" fillcolor=lightblue]
	layer_4_mlp_fc1_gpu0 [label="Layer 4 MLP FC1\nGPU 0\nTP Rank 0\n[4096→16384]" fillcolor=lightblue]
	layer_4_mlp_fc1_gpu1 [label="Layer 4 MLP FC1\nGPU 1\nTP Rank 1\n[4096→16384]" fillcolor=lightblue]
	layer_4_mlp_fc1_gpu2 [label="Layer 4 MLP FC1\nGPU 2\nTP Rank 2\n[4096→16384]" fillcolor=lightblue]
	layer_4_mlp_fc1_gpu3 [label="Layer 4 MLP FC1\nGPU 3\nTP Rank 3\n[4096→16384]" fillcolor=lightblue]
	layer_4_mlp_fc1_gpu4 [label="Layer 4 MLP FC1\nGPU 4\nTP Rank 4\n[4096→16384]" fillcolor=lightblue]
	layer_4_mlp_fc1_gpu5 [label="Layer 4 MLP FC1\nGPU 5\nTP Rank 5\n[4096→16384]" fillcolor=lightblue]
	layer_4_mlp_fc1_gpu6 [label="Layer 4 MLP FC1\nGPU 6\nTP Rank 6\n[4096→16384]" fillcolor=lightblue]
	layer_4_mlp_fc1_gpu7 [label="Layer 4 MLP FC1\nGPU 7\nTP Rank 7\n[4096→16384]" fillcolor=lightblue]
	layer_4_allgather_mlp [label="Layer 4\nAllGather MLP\nTP=8" fillcolor=orange shape=ellipse]
	layer_4_gelu [label="Layer 4\nGELU Activation" fillcolor=lightblue]
	layer_4_mlp_fc2_gpu0 [label="Layer 4 MLP FC2\nGPU 0\nTP Rank 0\n[16384→4096]" fillcolor=lightblue]
	layer_4_mlp_fc2_gpu1 [label="Layer 4 MLP FC2\nGPU 1\nTP Rank 1\n[16384→4096]" fillcolor=lightblue]
	layer_4_mlp_fc2_gpu2 [label="Layer 4 MLP FC2\nGPU 2\nTP Rank 2\n[16384→4096]" fillcolor=lightblue]
	layer_4_mlp_fc2_gpu3 [label="Layer 4 MLP FC2\nGPU 3\nTP Rank 3\n[16384→4096]" fillcolor=lightblue]
	layer_4_mlp_fc2_gpu4 [label="Layer 4 MLP FC2\nGPU 4\nTP Rank 4\n[16384→4096]" fillcolor=lightblue]
	layer_4_mlp_fc2_gpu5 [label="Layer 4 MLP FC2\nGPU 5\nTP Rank 5\n[16384→4096]" fillcolor=lightblue]
	layer_4_mlp_fc2_gpu6 [label="Layer 4 MLP FC2\nGPU 6\nTP Rank 6\n[16384→4096]" fillcolor=lightblue]
	layer_4_mlp_fc2_gpu7 [label="Layer 4 MLP FC2\nGPU 7\nTP Rank 7\n[16384→4096]" fillcolor=lightblue]
	layer_4_allreduce_mlp [label="Layer 4\nAllReduce MLP\nTP=8" fillcolor=orange shape=ellipse]
	layer_4_residual2 [label="Layer 4\nResidual Add" fillcolor=lightyellow shape=parallelogram]
	layer_4_ln2 [label="Layer 4\nLayerNorm 2\nγ,β: 4096" fillcolor=lightblue]
	layer_4_output_dist [label="Layer 4\nOutput Distribution" fillcolor=lightyellow shape=parallelogram]
	layer_5_input_dist [label="Layer 5\nInput Distribution" fillcolor=lightyellow shape=parallelogram]
	layer_5_qkv_gpu0 [label="Layer 5 QKV Proj\nGPU 0\nTP Rank 0\n[4096→12288]" fillcolor=lightblue]
	layer_5_qkv_gpu1 [label="Layer 5 QKV Proj\nGPU 1\nTP Rank 1\n[4096→12288]" fillcolor=lightblue]
	layer_5_qkv_gpu2 [label="Layer 5 QKV Proj\nGPU 2\nTP Rank 2\n[4096→12288]" fillcolor=lightblue]
	layer_5_qkv_gpu3 [label="Layer 5 QKV Proj\nGPU 3\nTP Rank 3\n[4096→12288]" fillcolor=lightblue]
	layer_5_qkv_gpu4 [label="Layer 5 QKV Proj\nGPU 4\nTP Rank 4\n[4096→12288]" fillcolor=lightblue]
	layer_5_qkv_gpu5 [label="Layer 5 QKV Proj\nGPU 5\nTP Rank 5\n[4096→12288]" fillcolor=lightblue]
	layer_5_qkv_gpu6 [label="Layer 5 QKV Proj\nGPU 6\nTP Rank 6\n[4096→12288]" fillcolor=lightblue]
	layer_5_qkv_gpu7 [label="Layer 5 QKV Proj\nGPU 7\nTP Rank 7\n[4096→12288]" fillcolor=lightblue]
	layer_5_allgather_qkv [label="Layer 5\nAllGather QKV\nTP=8" fillcolor=orange shape=ellipse]
	layer_5_attention [label="Layer 5\nAttention\n32×128 dim\nSoftmax" fillcolor=lightblue]
	layer_5_attn_out_gpu0 [label="Layer 5 Attn Out\nGPU 0\nTP Rank 0\n[4096→4096]" fillcolor=lightblue]
	layer_5_attn_out_gpu1 [label="Layer 5 Attn Out\nGPU 1\nTP Rank 1\n[4096→4096]" fillcolor=lightblue]
	layer_5_attn_out_gpu2 [label="Layer 5 Attn Out\nGPU 2\nTP Rank 2\n[4096→4096]" fillcolor=lightblue]
	layer_5_attn_out_gpu3 [label="Layer 5 Attn Out\nGPU 3\nTP Rank 3\n[4096→4096]" fillcolor=lightblue]
	layer_5_attn_out_gpu4 [label="Layer 5 Attn Out\nGPU 4\nTP Rank 4\n[4096→4096]" fillcolor=lightblue]
	layer_5_attn_out_gpu5 [label="Layer 5 Attn Out\nGPU 5\nTP Rank 5\n[4096→4096]" fillcolor=lightblue]
	layer_5_attn_out_gpu6 [label="Layer 5 Attn Out\nGPU 6\nTP Rank 6\n[4096→4096]" fillcolor=lightblue]
	layer_5_attn_out_gpu7 [label="Layer 5 Attn Out\nGPU 7\nTP Rank 7\n[4096→4096]" fillcolor=lightblue]
	layer_5_allreduce_attn [label="Layer 5\nAllReduce Attn\nTP=8" fillcolor=orange shape=ellipse]
	layer_5_residual1 [label="Layer 5\nResidual Add" fillcolor=lightyellow shape=parallelogram]
	layer_5_ln1 [label="Layer 5\nLayerNorm 1\nγ,β: 4096" fillcolor=lightblue]
	layer_5_mlp_fc1_gpu0 [label="Layer 5 MLP FC1\nGPU 0\nTP Rank 0\n[4096→16384]" fillcolor=lightblue]
	layer_5_mlp_fc1_gpu1 [label="Layer 5 MLP FC1\nGPU 1\nTP Rank 1\n[4096→16384]" fillcolor=lightblue]
	layer_5_mlp_fc1_gpu2 [label="Layer 5 MLP FC1\nGPU 2\nTP Rank 2\n[4096→16384]" fillcolor=lightblue]
	layer_5_mlp_fc1_gpu3 [label="Layer 5 MLP FC1\nGPU 3\nTP Rank 3\n[4096→16384]" fillcolor=lightblue]
	layer_5_mlp_fc1_gpu4 [label="Layer 5 MLP FC1\nGPU 4\nTP Rank 4\n[4096→16384]" fillcolor=lightblue]
	layer_5_mlp_fc1_gpu5 [label="Layer 5 MLP FC1\nGPU 5\nTP Rank 5\n[4096→16384]" fillcolor=lightblue]
	layer_5_mlp_fc1_gpu6 [label="Layer 5 MLP FC1\nGPU 6\nTP Rank 6\n[4096→16384]" fillcolor=lightblue]
	layer_5_mlp_fc1_gpu7 [label="Layer 5 MLP FC1\nGPU 7\nTP Rank 7\n[4096→16384]" fillcolor=lightblue]
	layer_5_allgather_mlp [label="Layer 5\nAllGather MLP\nTP=8" fillcolor=orange shape=ellipse]
	layer_5_gelu [label="Layer 5\nGELU Activation" fillcolor=lightblue]
	layer_5_mlp_fc2_gpu0 [label="Layer 5 MLP FC2\nGPU 0\nTP Rank 0\n[16384→4096]" fillcolor=lightblue]
	layer_5_mlp_fc2_gpu1 [label="Layer 5 MLP FC2\nGPU 1\nTP Rank 1\n[16384→4096]" fillcolor=lightblue]
	layer_5_mlp_fc2_gpu2 [label="Layer 5 MLP FC2\nGPU 2\nTP Rank 2\n[16384→4096]" fillcolor=lightblue]
	layer_5_mlp_fc2_gpu3 [label="Layer 5 MLP FC2\nGPU 3\nTP Rank 3\n[16384→4096]" fillcolor=lightblue]
	layer_5_mlp_fc2_gpu4 [label="Layer 5 MLP FC2\nGPU 4\nTP Rank 4\n[16384→4096]" fillcolor=lightblue]
	layer_5_mlp_fc2_gpu5 [label="Layer 5 MLP FC2\nGPU 5\nTP Rank 5\n[16384→4096]" fillcolor=lightblue]
	layer_5_mlp_fc2_gpu6 [label="Layer 5 MLP FC2\nGPU 6\nTP Rank 6\n[16384→4096]" fillcolor=lightblue]
	layer_5_mlp_fc2_gpu7 [label="Layer 5 MLP FC2\nGPU 7\nTP Rank 7\n[16384→4096]" fillcolor=lightblue]
	layer_5_allreduce_mlp [label="Layer 5\nAllReduce MLP\nTP=8" fillcolor=orange shape=ellipse]
	layer_5_residual2 [label="Layer 5\nResidual Add" fillcolor=lightyellow shape=parallelogram]
	layer_5_ln2 [label="Layer 5\nLayerNorm 2\nγ,β: 4096" fillcolor=lightblue]
	layer_5_output_dist [label="Layer 5\nOutput Distribution" fillcolor=lightyellow shape=parallelogram]
	layer_6_input_dist [label="Layer 6\nInput Distribution" fillcolor=lightyellow shape=parallelogram]
	layer_6_qkv_gpu0 [label="Layer 6 QKV Proj\nGPU 0\nTP Rank 0\n[4096→12288]" fillcolor=lightblue]
	layer_6_qkv_gpu1 [label="Layer 6 QKV Proj\nGPU 1\nTP Rank 1\n[4096→12288]" fillcolor=lightblue]
	layer_6_qkv_gpu2 [label="Layer 6 QKV Proj\nGPU 2\nTP Rank 2\n[4096→12288]" fillcolor=lightblue]
	layer_6_qkv_gpu3 [label="Layer 6 QKV Proj\nGPU 3\nTP Rank 3\n[4096→12288]" fillcolor=lightblue]
	layer_6_qkv_gpu4 [label="Layer 6 QKV Proj\nGPU 4\nTP Rank 4\n[4096→12288]" fillcolor=lightblue]
	layer_6_qkv_gpu5 [label="Layer 6 QKV Proj\nGPU 5\nTP Rank 5\n[4096→12288]" fillcolor=lightblue]
	layer_6_qkv_gpu6 [label="Layer 6 QKV Proj\nGPU 6\nTP Rank 6\n[4096→12288]" fillcolor=lightblue]
	layer_6_qkv_gpu7 [label="Layer 6 QKV Proj\nGPU 7\nTP Rank 7\n[4096→12288]" fillcolor=lightblue]
	layer_6_allgather_qkv [label="Layer 6\nAllGather QKV\nTP=8" fillcolor=orange shape=ellipse]
	layer_6_attention [label="Layer 6\nAttention\n32×128 dim\nSoftmax" fillcolor=lightblue]
	layer_6_attn_out_gpu0 [label="Layer 6 Attn Out\nGPU 0\nTP Rank 0\n[4096→4096]" fillcolor=lightblue]
	layer_6_attn_out_gpu1 [label="Layer 6 Attn Out\nGPU 1\nTP Rank 1\n[4096→4096]" fillcolor=lightblue]
	layer_6_attn_out_gpu2 [label="Layer 6 Attn Out\nGPU 2\nTP Rank 2\n[4096→4096]" fillcolor=lightblue]
	layer_6_attn_out_gpu3 [label="Layer 6 Attn Out\nGPU 3\nTP Rank 3\n[4096→4096]" fillcolor=lightblue]
	layer_6_attn_out_gpu4 [label="Layer 6 Attn Out\nGPU 4\nTP Rank 4\n[4096→4096]" fillcolor=lightblue]
	layer_6_attn_out_gpu5 [label="Layer 6 Attn Out\nGPU 5\nTP Rank 5\n[4096→4096]" fillcolor=lightblue]
	layer_6_attn_out_gpu6 [label="Layer 6 Attn Out\nGPU 6\nTP Rank 6\n[4096→4096]" fillcolor=lightblue]
	layer_6_attn_out_gpu7 [label="Layer 6 Attn Out\nGPU 7\nTP Rank 7\n[4096→4096]" fillcolor=lightblue]
	layer_6_allreduce_attn [label="Layer 6\nAllReduce Attn\nTP=8" fillcolor=orange shape=ellipse]
	layer_6_residual1 [label="Layer 6\nResidual Add" fillcolor=lightyellow shape=parallelogram]
	layer_6_ln1 [label="Layer 6\nLayerNorm 1\nγ,β: 4096" fillcolor=lightblue]
	layer_6_mlp_fc1_gpu0 [label="Layer 6 MLP FC1\nGPU 0\nTP Rank 0\n[4096→16384]" fillcolor=lightblue]
	layer_6_mlp_fc1_gpu1 [label="Layer 6 MLP FC1\nGPU 1\nTP Rank 1\n[4096→16384]" fillcolor=lightblue]
	layer_6_mlp_fc1_gpu2 [label="Layer 6 MLP FC1\nGPU 2\nTP Rank 2\n[4096→16384]" fillcolor=lightblue]
	layer_6_mlp_fc1_gpu3 [label="Layer 6 MLP FC1\nGPU 3\nTP Rank 3\n[4096→16384]" fillcolor=lightblue]
	layer_6_mlp_fc1_gpu4 [label="Layer 6 MLP FC1\nGPU 4\nTP Rank 4\n[4096→16384]" fillcolor=lightblue]
	layer_6_mlp_fc1_gpu5 [label="Layer 6 MLP FC1\nGPU 5\nTP Rank 5\n[4096→16384]" fillcolor=lightblue]
	layer_6_mlp_fc1_gpu6 [label="Layer 6 MLP FC1\nGPU 6\nTP Rank 6\n[4096→16384]" fillcolor=lightblue]
	layer_6_mlp_fc1_gpu7 [label="Layer 6 MLP FC1\nGPU 7\nTP Rank 7\n[4096→16384]" fillcolor=lightblue]
	layer_6_allgather_mlp [label="Layer 6\nAllGather MLP\nTP=8" fillcolor=orange shape=ellipse]
	layer_6_gelu [label="Layer 6\nGELU Activation" fillcolor=lightblue]
	layer_6_mlp_fc2_gpu0 [label="Layer 6 MLP FC2\nGPU 0\nTP Rank 0\n[16384→4096]" fillcolor=lightblue]
	layer_6_mlp_fc2_gpu1 [label="Layer 6 MLP FC2\nGPU 1\nTP Rank 1\n[16384→4096]" fillcolor=lightblue]
	layer_6_mlp_fc2_gpu2 [label="Layer 6 MLP FC2\nGPU 2\nTP Rank 2\n[16384→4096]" fillcolor=lightblue]
	layer_6_mlp_fc2_gpu3 [label="Layer 6 MLP FC2\nGPU 3\nTP Rank 3\n[16384→4096]" fillcolor=lightblue]
	layer_6_mlp_fc2_gpu4 [label="Layer 6 MLP FC2\nGPU 4\nTP Rank 4\n[16384→4096]" fillcolor=lightblue]
	layer_6_mlp_fc2_gpu5 [label="Layer 6 MLP FC2\nGPU 5\nTP Rank 5\n[16384→4096]" fillcolor=lightblue]
	layer_6_mlp_fc2_gpu6 [label="Layer 6 MLP FC2\nGPU 6\nTP Rank 6\n[16384→4096]" fillcolor=lightblue]
	layer_6_mlp_fc2_gpu7 [label="Layer 6 MLP FC2\nGPU 7\nTP Rank 7\n[16384→4096]" fillcolor=lightblue]
	layer_6_allreduce_mlp [label="Layer 6\nAllReduce MLP\nTP=8" fillcolor=orange shape=ellipse]
	layer_6_residual2 [label="Layer 6\nResidual Add" fillcolor=lightyellow shape=parallelogram]
	layer_6_ln2 [label="Layer 6\nLayerNorm 2\nγ,β: 4096" fillcolor=lightblue]
	layer_6_output_dist [label="Layer 6\nOutput Distribution" fillcolor=lightyellow shape=parallelogram]
	layer_7_input_dist [label="Layer 7\nInput Distribution" fillcolor=lightyellow shape=parallelogram]
	layer_7_qkv_gpu0 [label="Layer 7 QKV Proj\nGPU 0\nTP Rank 0\n[4096→12288]" fillcolor=lightblue]
	layer_7_qkv_gpu1 [label="Layer 7 QKV Proj\nGPU 1\nTP Rank 1\n[4096→12288]" fillcolor=lightblue]
	layer_7_qkv_gpu2 [label="Layer 7 QKV Proj\nGPU 2\nTP Rank 2\n[4096→12288]" fillcolor=lightblue]
	layer_7_qkv_gpu3 [label="Layer 7 QKV Proj\nGPU 3\nTP Rank 3\n[4096→12288]" fillcolor=lightblue]
	layer_7_qkv_gpu4 [label="Layer 7 QKV Proj\nGPU 4\nTP Rank 4\n[4096→12288]" fillcolor=lightblue]
	layer_7_qkv_gpu5 [label="Layer 7 QKV Proj\nGPU 5\nTP Rank 5\n[4096→12288]" fillcolor=lightblue]
	layer_7_qkv_gpu6 [label="Layer 7 QKV Proj\nGPU 6\nTP Rank 6\n[4096→12288]" fillcolor=lightblue]
	layer_7_qkv_gpu7 [label="Layer 7 QKV Proj\nGPU 7\nTP Rank 7\n[4096→12288]" fillcolor=lightblue]
	layer_7_allgather_qkv [label="Layer 7\nAllGather QKV\nTP=8" fillcolor=orange shape=ellipse]
	layer_7_attention [label="Layer 7\nAttention\n32×128 dim\nSoftmax" fillcolor=lightblue]
	layer_7_attn_out_gpu0 [label="Layer 7 Attn Out\nGPU 0\nTP Rank 0\n[4096→4096]" fillcolor=lightblue]
	layer_7_attn_out_gpu1 [label="Layer 7 Attn Out\nGPU 1\nTP Rank 1\n[4096→4096]" fillcolor=lightblue]
	layer_7_attn_out_gpu2 [label="Layer 7 Attn Out\nGPU 2\nTP Rank 2\n[4096→4096]" fillcolor=lightblue]
	layer_7_attn_out_gpu3 [label="Layer 7 Attn Out\nGPU 3\nTP Rank 3\n[4096→4096]" fillcolor=lightblue]
	layer_7_attn_out_gpu4 [label="Layer 7 Attn Out\nGPU 4\nTP Rank 4\n[4096→4096]" fillcolor=lightblue]
	layer_7_attn_out_gpu5 [label="Layer 7 Attn Out\nGPU 5\nTP Rank 5\n[4096→4096]" fillcolor=lightblue]
	layer_7_attn_out_gpu6 [label="Layer 7 Attn Out\nGPU 6\nTP Rank 6\n[4096→4096]" fillcolor=lightblue]
	layer_7_attn_out_gpu7 [label="Layer 7 Attn Out\nGPU 7\nTP Rank 7\n[4096→4096]" fillcolor=lightblue]
	layer_7_allreduce_attn [label="Layer 7\nAllReduce Attn\nTP=8" fillcolor=orange shape=ellipse]
	layer_7_residual1 [label="Layer 7\nResidual Add" fillcolor=lightyellow shape=parallelogram]
	layer_7_ln1 [label="Layer 7\nLayerNorm 1\nγ,β: 4096" fillcolor=lightblue]
	layer_7_mlp_fc1_gpu0 [label="Layer 7 MLP FC1\nGPU 0\nTP Rank 0\n[4096→16384]" fillcolor=lightblue]
	layer_7_mlp_fc1_gpu1 [label="Layer 7 MLP FC1\nGPU 1\nTP Rank 1\n[4096→16384]" fillcolor=lightblue]
	layer_7_mlp_fc1_gpu2 [label="Layer 7 MLP FC1\nGPU 2\nTP Rank 2\n[4096→16384]" fillcolor=lightblue]
	layer_7_mlp_fc1_gpu3 [label="Layer 7 MLP FC1\nGPU 3\nTP Rank 3\n[4096→16384]" fillcolor=lightblue]
	layer_7_mlp_fc1_gpu4 [label="Layer 7 MLP FC1\nGPU 4\nTP Rank 4\n[4096→16384]" fillcolor=lightblue]
	layer_7_mlp_fc1_gpu5 [label="Layer 7 MLP FC1\nGPU 5\nTP Rank 5\n[4096→16384]" fillcolor=lightblue]
	layer_7_mlp_fc1_gpu6 [label="Layer 7 MLP FC1\nGPU 6\nTP Rank 6\n[4096→16384]" fillcolor=lightblue]
	layer_7_mlp_fc1_gpu7 [label="Layer 7 MLP FC1\nGPU 7\nTP Rank 7\n[4096→16384]" fillcolor=lightblue]
	layer_7_allgather_mlp [label="Layer 7\nAllGather MLP\nTP=8" fillcolor=orange shape=ellipse]
	layer_7_gelu [label="Layer 7\nGELU Activation" fillcolor=lightblue]
	layer_7_mlp_fc2_gpu0 [label="Layer 7 MLP FC2\nGPU 0\nTP Rank 0\n[16384→4096]" fillcolor=lightblue]
	layer_7_mlp_fc2_gpu1 [label="Layer 7 MLP FC2\nGPU 1\nTP Rank 1\n[16384→4096]" fillcolor=lightblue]
	layer_7_mlp_fc2_gpu2 [label="Layer 7 MLP FC2\nGPU 2\nTP Rank 2\n[16384→4096]" fillcolor=lightblue]
	layer_7_mlp_fc2_gpu3 [label="Layer 7 MLP FC2\nGPU 3\nTP Rank 3\n[16384→4096]" fillcolor=lightblue]
	layer_7_mlp_fc2_gpu4 [label="Layer 7 MLP FC2\nGPU 4\nTP Rank 4\n[16384→4096]" fillcolor=lightblue]
	layer_7_mlp_fc2_gpu5 [label="Layer 7 MLP FC2\nGPU 5\nTP Rank 5\n[16384→4096]" fillcolor=lightblue]
	layer_7_mlp_fc2_gpu6 [label="Layer 7 MLP FC2\nGPU 6\nTP Rank 6\n[16384→4096]" fillcolor=lightblue]
	layer_7_mlp_fc2_gpu7 [label="Layer 7 MLP FC2\nGPU 7\nTP Rank 7\n[16384→4096]" fillcolor=lightblue]
	layer_7_allreduce_mlp [label="Layer 7\nAllReduce MLP\nTP=8" fillcolor=orange shape=ellipse]
	layer_7_residual2 [label="Layer 7\nResidual Add" fillcolor=lightyellow shape=parallelogram]
	layer_7_ln2 [label="Layer 7\nLayerNorm 2\nγ,β: 4096" fillcolor=lightblue]
	layer_7_output_dist [label="Layer 7\nOutput Distribution" fillcolor=lightyellow shape=parallelogram]
	layer_8_input_dist [label="Layer 8\nInput Distribution" fillcolor=lightyellow shape=parallelogram]
	layer_8_qkv_gpu8 [label="Layer 8 QKV Proj\nGPU 8\nTP Rank 0\n[4096→12288]" fillcolor=lightblue]
	layer_8_qkv_gpu9 [label="Layer 8 QKV Proj\nGPU 9\nTP Rank 1\n[4096→12288]" fillcolor=lightblue]
	layer_8_qkv_gpu10 [label="Layer 8 QKV Proj\nGPU 10\nTP Rank 2\n[4096→12288]" fillcolor=lightblue]
	layer_8_qkv_gpu11 [label="Layer 8 QKV Proj\nGPU 11\nTP Rank 3\n[4096→12288]" fillcolor=lightblue]
	layer_8_qkv_gpu12 [label="Layer 8 QKV Proj\nGPU 12\nTP Rank 4\n[4096→12288]" fillcolor=lightblue]
	layer_8_qkv_gpu13 [label="Layer 8 QKV Proj\nGPU 13\nTP Rank 5\n[4096→12288]" fillcolor=lightblue]
	layer_8_qkv_gpu14 [label="Layer 8 QKV Proj\nGPU 14\nTP Rank 6\n[4096→12288]" fillcolor=lightblue]
	layer_8_qkv_gpu15 [label="Layer 8 QKV Proj\nGPU 15\nTP Rank 7\n[4096→12288]" fillcolor=lightblue]
	layer_8_allgather_qkv [label="Layer 8\nAllGather QKV\nTP=8" fillcolor=orange shape=ellipse]
	layer_8_attention [label="Layer 8\nAttention\n32×128 dim\nSoftmax" fillcolor=lightblue]
	layer_8_attn_out_gpu8 [label="Layer 8 Attn Out\nGPU 8\nTP Rank 0\n[4096→4096]" fillcolor=lightblue]
	layer_8_attn_out_gpu9 [label="Layer 8 Attn Out\nGPU 9\nTP Rank 1\n[4096→4096]" fillcolor=lightblue]
	layer_8_attn_out_gpu10 [label="Layer 8 Attn Out\nGPU 10\nTP Rank 2\n[4096→4096]" fillcolor=lightblue]
	layer_8_attn_out_gpu11 [label="Layer 8 Attn Out\nGPU 11\nTP Rank 3\n[4096→4096]" fillcolor=lightblue]
	layer_8_attn_out_gpu12 [label="Layer 8 Attn Out\nGPU 12\nTP Rank 4\n[4096→4096]" fillcolor=lightblue]
	layer_8_attn_out_gpu13 [label="Layer 8 Attn Out\nGPU 13\nTP Rank 5\n[4096→4096]" fillcolor=lightblue]
	layer_8_attn_out_gpu14 [label="Layer 8 Attn Out\nGPU 14\nTP Rank 6\n[4096→4096]" fillcolor=lightblue]
	layer_8_attn_out_gpu15 [label="Layer 8 Attn Out\nGPU 15\nTP Rank 7\n[4096→4096]" fillcolor=lightblue]
	layer_8_allreduce_attn [label="Layer 8\nAllReduce Attn\nTP=8" fillcolor=orange shape=ellipse]
	layer_8_residual1 [label="Layer 8\nResidual Add" fillcolor=lightyellow shape=parallelogram]
	layer_8_ln1 [label="Layer 8\nLayerNorm 1\nγ,β: 4096" fillcolor=lightblue]
	layer_8_mlp_fc1_gpu8 [label="Layer 8 MLP FC1\nGPU 8\nTP Rank 0\n[4096→16384]" fillcolor=lightblue]
	layer_8_mlp_fc1_gpu9 [label="Layer 8 MLP FC1\nGPU 9\nTP Rank 1\n[4096→16384]" fillcolor=lightblue]
	layer_8_mlp_fc1_gpu10 [label="Layer 8 MLP FC1\nGPU 10\nTP Rank 2\n[4096→16384]" fillcolor=lightblue]
	layer_8_mlp_fc1_gpu11 [label="Layer 8 MLP FC1\nGPU 11\nTP Rank 3\n[4096→16384]" fillcolor=lightblue]
	layer_8_mlp_fc1_gpu12 [label="Layer 8 MLP FC1\nGPU 12\nTP Rank 4\n[4096→16384]" fillcolor=lightblue]
	layer_8_mlp_fc1_gpu13 [label="Layer 8 MLP FC1\nGPU 13\nTP Rank 5\n[4096→16384]" fillcolor=lightblue]
	layer_8_mlp_fc1_gpu14 [label="Layer 8 MLP FC1\nGPU 14\nTP Rank 6\n[4096→16384]" fillcolor=lightblue]
	layer_8_mlp_fc1_gpu15 [label="Layer 8 MLP FC1\nGPU 15\nTP Rank 7\n[4096→16384]" fillcolor=lightblue]
	layer_8_allgather_mlp [label="Layer 8\nAllGather MLP\nTP=8" fillcolor=orange shape=ellipse]
	layer_8_gelu [label="Layer 8\nGELU Activation" fillcolor=lightblue]
	layer_8_mlp_fc2_gpu8 [label="Layer 8 MLP FC2\nGPU 8\nTP Rank 0\n[16384→4096]" fillcolor=lightblue]
	layer_8_mlp_fc2_gpu9 [label="Layer 8 MLP FC2\nGPU 9\nTP Rank 1\n[16384→4096]" fillcolor=lightblue]
	layer_8_mlp_fc2_gpu10 [label="Layer 8 MLP FC2\nGPU 10\nTP Rank 2\n[16384→4096]" fillcolor=lightblue]
	layer_8_mlp_fc2_gpu11 [label="Layer 8 MLP FC2\nGPU 11\nTP Rank 3\n[16384→4096]" fillcolor=lightblue]
	layer_8_mlp_fc2_gpu12 [label="Layer 8 MLP FC2\nGPU 12\nTP Rank 4\n[16384→4096]" fillcolor=lightblue]
	layer_8_mlp_fc2_gpu13 [label="Layer 8 MLP FC2\nGPU 13\nTP Rank 5\n[16384→4096]" fillcolor=lightblue]
	layer_8_mlp_fc2_gpu14 [label="Layer 8 MLP FC2\nGPU 14\nTP Rank 6\n[16384→4096]" fillcolor=lightblue]
	layer_8_mlp_fc2_gpu15 [label="Layer 8 MLP FC2\nGPU 15\nTP Rank 7\n[16384→4096]" fillcolor=lightblue]
	layer_8_allreduce_mlp [label="Layer 8\nAllReduce MLP\nTP=8" fillcolor=orange shape=ellipse]
	layer_8_residual2 [label="Layer 8\nResidual Add" fillcolor=lightyellow shape=parallelogram]
	layer_8_ln2 [label="Layer 8\nLayerNorm 2\nγ,β: 4096" fillcolor=lightblue]
	layer_8_output_dist [label="Layer 8\nOutput Distribution" fillcolor=lightyellow shape=parallelogram]
	layer_9_input_dist [label="Layer 9\nInput Distribution" fillcolor=lightyellow shape=parallelogram]
	layer_9_qkv_gpu8 [label="Layer 9 QKV Proj\nGPU 8\nTP Rank 0\n[4096→12288]" fillcolor=lightblue]
	layer_9_qkv_gpu9 [label="Layer 9 QKV Proj\nGPU 9\nTP Rank 1\n[4096→12288]" fillcolor=lightblue]
	layer_9_qkv_gpu10 [label="Layer 9 QKV Proj\nGPU 10\nTP Rank 2\n[4096→12288]" fillcolor=lightblue]
	layer_9_qkv_gpu11 [label="Layer 9 QKV Proj\nGPU 11\nTP Rank 3\n[4096→12288]" fillcolor=lightblue]
	layer_9_qkv_gpu12 [label="Layer 9 QKV Proj\nGPU 12\nTP Rank 4\n[4096→12288]" fillcolor=lightblue]
	layer_9_qkv_gpu13 [label="Layer 9 QKV Proj\nGPU 13\nTP Rank 5\n[4096→12288]" fillcolor=lightblue]
	layer_9_qkv_gpu14 [label="Layer 9 QKV Proj\nGPU 14\nTP Rank 6\n[4096→12288]" fillcolor=lightblue]
	layer_9_qkv_gpu15 [label="Layer 9 QKV Proj\nGPU 15\nTP Rank 7\n[4096→12288]" fillcolor=lightblue]
	layer_9_allgather_qkv [label="Layer 9\nAllGather QKV\nTP=8" fillcolor=orange shape=ellipse]
	layer_9_attention [label="Layer 9\nAttention\n32×128 dim\nSoftmax" fillcolor=lightblue]
	layer_9_attn_out_gpu8 [label="Layer 9 Attn Out\nGPU 8\nTP Rank 0\n[4096→4096]" fillcolor=lightblue]
	layer_9_attn_out_gpu9 [label="Layer 9 Attn Out\nGPU 9\nTP Rank 1\n[4096→4096]" fillcolor=lightblue]
	layer_9_attn_out_gpu10 [label="Layer 9 Attn Out\nGPU 10\nTP Rank 2\n[4096→4096]" fillcolor=lightblue]
	layer_9_attn_out_gpu11 [label="Layer 9 Attn Out\nGPU 11\nTP Rank 3\n[4096→4096]" fillcolor=lightblue]
	layer_9_attn_out_gpu12 [label="Layer 9 Attn Out\nGPU 12\nTP Rank 4\n[4096→4096]" fillcolor=lightblue]
	layer_9_attn_out_gpu13 [label="Layer 9 Attn Out\nGPU 13\nTP Rank 5\n[4096→4096]" fillcolor=lightblue]
	layer_9_attn_out_gpu14 [label="Layer 9 Attn Out\nGPU 14\nTP Rank 6\n[4096→4096]" fillcolor=lightblue]
	layer_9_attn_out_gpu15 [label="Layer 9 Attn Out\nGPU 15\nTP Rank 7\n[4096→4096]" fillcolor=lightblue]
	layer_9_allreduce_attn [label="Layer 9\nAllReduce Attn\nTP=8" fillcolor=orange shape=ellipse]
	layer_9_residual1 [label="Layer 9\nResidual Add" fillcolor=lightyellow shape=parallelogram]
	layer_9_ln1 [label="Layer 9\nLayerNorm 1\nγ,β: 4096" fillcolor=lightblue]
	layer_9_mlp_fc1_gpu8 [label="Layer 9 MLP FC1\nGPU 8\nTP Rank 0\n[4096→16384]" fillcolor=lightblue]
	layer_9_mlp_fc1_gpu9 [label="Layer 9 MLP FC1\nGPU 9\nTP Rank 1\n[4096→16384]" fillcolor=lightblue]
	layer_9_mlp_fc1_gpu10 [label="Layer 9 MLP FC1\nGPU 10\nTP Rank 2\n[4096→16384]" fillcolor=lightblue]
	layer_9_mlp_fc1_gpu11 [label="Layer 9 MLP FC1\nGPU 11\nTP Rank 3\n[4096→16384]" fillcolor=lightblue]
	layer_9_mlp_fc1_gpu12 [label="Layer 9 MLP FC1\nGPU 12\nTP Rank 4\n[4096→16384]" fillcolor=lightblue]
	layer_9_mlp_fc1_gpu13 [label="Layer 9 MLP FC1\nGPU 13\nTP Rank 5\n[4096→16384]" fillcolor=lightblue]
	layer_9_mlp_fc1_gpu14 [label="Layer 9 MLP FC1\nGPU 14\nTP Rank 6\n[4096→16384]" fillcolor=lightblue]
	layer_9_mlp_fc1_gpu15 [label="Layer 9 MLP FC1\nGPU 15\nTP Rank 7\n[4096→16384]" fillcolor=lightblue]
	layer_9_allgather_mlp [label="Layer 9\nAllGather MLP\nTP=8" fillcolor=orange shape=ellipse]
	layer_9_gelu [label="Layer 9\nGELU Activation" fillcolor=lightblue]
	layer_9_mlp_fc2_gpu8 [label="Layer 9 MLP FC2\nGPU 8\nTP Rank 0\n[16384→4096]" fillcolor=lightblue]
	layer_9_mlp_fc2_gpu9 [label="Layer 9 MLP FC2\nGPU 9\nTP Rank 1\n[16384→4096]" fillcolor=lightblue]
	layer_9_mlp_fc2_gpu10 [label="Layer 9 MLP FC2\nGPU 10\nTP Rank 2\n[16384→4096]" fillcolor=lightblue]
	layer_9_mlp_fc2_gpu11 [label="Layer 9 MLP FC2\nGPU 11\nTP Rank 3\n[16384→4096]" fillcolor=lightblue]
	layer_9_mlp_fc2_gpu12 [label="Layer 9 MLP FC2\nGPU 12\nTP Rank 4\n[16384→4096]" fillcolor=lightblue]
	layer_9_mlp_fc2_gpu13 [label="Layer 9 MLP FC2\nGPU 13\nTP Rank 5\n[16384→4096]" fillcolor=lightblue]
	layer_9_mlp_fc2_gpu14 [label="Layer 9 MLP FC2\nGPU 14\nTP Rank 6\n[16384→4096]" fillcolor=lightblue]
	layer_9_mlp_fc2_gpu15 [label="Layer 9 MLP FC2\nGPU 15\nTP Rank 7\n[16384→4096]" fillcolor=lightblue]
	layer_9_allreduce_mlp [label="Layer 9\nAllReduce MLP\nTP=8" fillcolor=orange shape=ellipse]
	layer_9_residual2 [label="Layer 9\nResidual Add" fillcolor=lightyellow shape=parallelogram]
	layer_9_ln2 [label="Layer 9\nLayerNorm 2\nγ,β: 4096" fillcolor=lightblue]
	layer_9_output_dist [label="Layer 9\nOutput Distribution" fillcolor=lightyellow shape=parallelogram]
	layer_10_input_dist [label="Layer 10\nInput Distribution" fillcolor=lightyellow shape=parallelogram]
	layer_10_qkv_gpu8 [label="Layer 10 QKV Proj\nGPU 8\nTP Rank 0\n[4096→12288]" fillcolor=lightblue]
	layer_10_qkv_gpu9 [label="Layer 10 QKV Proj\nGPU 9\nTP Rank 1\n[4096→12288]" fillcolor=lightblue]
	layer_10_qkv_gpu10 [label="Layer 10 QKV Proj\nGPU 10\nTP Rank 2\n[4096→12288]" fillcolor=lightblue]
	layer_10_qkv_gpu11 [label="Layer 10 QKV Proj\nGPU 11\nTP Rank 3\n[4096→12288]" fillcolor=lightblue]
	layer_10_qkv_gpu12 [label="Layer 10 QKV Proj\nGPU 12\nTP Rank 4\n[4096→12288]" fillcolor=lightblue]
	layer_10_qkv_gpu13 [label="Layer 10 QKV Proj\nGPU 13\nTP Rank 5\n[4096→12288]" fillcolor=lightblue]
	layer_10_qkv_gpu14 [label="Layer 10 QKV Proj\nGPU 14\nTP Rank 6\n[4096→12288]" fillcolor=lightblue]
	layer_10_qkv_gpu15 [label="Layer 10 QKV Proj\nGPU 15\nTP Rank 7\n[4096→12288]" fillcolor=lightblue]
	layer_10_allgather_qkv [label="Layer 10\nAllGather QKV\nTP=8" fillcolor=orange shape=ellipse]
	layer_10_attention [label="Layer 10\nAttention\n32×128 dim\nSoftmax" fillcolor=lightblue]
	layer_10_attn_out_gpu8 [label="Layer 10 Attn Out\nGPU 8\nTP Rank 0\n[4096→4096]" fillcolor=lightblue]
	layer_10_attn_out_gpu9 [label="Layer 10 Attn Out\nGPU 9\nTP Rank 1\n[4096→4096]" fillcolor=lightblue]
	layer_10_attn_out_gpu10 [label="Layer 10 Attn Out\nGPU 10\nTP Rank 2\n[4096→4096]" fillcolor=lightblue]
	layer_10_attn_out_gpu11 [label="Layer 10 Attn Out\nGPU 11\nTP Rank 3\n[4096→4096]" fillcolor=lightblue]
	layer_10_attn_out_gpu12 [label="Layer 10 Attn Out\nGPU 12\nTP Rank 4\n[4096→4096]" fillcolor=lightblue]
	layer_10_attn_out_gpu13 [label="Layer 10 Attn Out\nGPU 13\nTP Rank 5\n[4096→4096]" fillcolor=lightblue]
	layer_10_attn_out_gpu14 [label="Layer 10 Attn Out\nGPU 14\nTP Rank 6\n[4096→4096]" fillcolor=lightblue]
	layer_10_attn_out_gpu15 [label="Layer 10 Attn Out\nGPU 15\nTP Rank 7\n[4096→4096]" fillcolor=lightblue]
	layer_10_allreduce_attn [label="Layer 10\nAllReduce Attn\nTP=8" fillcolor=orange shape=ellipse]
	layer_10_residual1 [label="Layer 10\nResidual Add" fillcolor=lightyellow shape=parallelogram]
	layer_10_ln1 [label="Layer 10\nLayerNorm 1\nγ,β: 4096" fillcolor=lightblue]
	layer_10_mlp_fc1_gpu8 [label="Layer 10 MLP FC1\nGPU 8\nTP Rank 0\n[4096→16384]" fillcolor=lightblue]
	layer_10_mlp_fc1_gpu9 [label="Layer 10 MLP FC1\nGPU 9\nTP Rank 1\n[4096→16384]" fillcolor=lightblue]
	layer_10_mlp_fc1_gpu10 [label="Layer 10 MLP FC1\nGPU 10\nTP Rank 2\n[4096→16384]" fillcolor=lightblue]
	layer_10_mlp_fc1_gpu11 [label="Layer 10 MLP FC1\nGPU 11\nTP Rank 3\n[4096→16384]" fillcolor=lightblue]
	layer_10_mlp_fc1_gpu12 [label="Layer 10 MLP FC1\nGPU 12\nTP Rank 4\n[4096→16384]" fillcolor=lightblue]
	layer_10_mlp_fc1_gpu13 [label="Layer 10 MLP FC1\nGPU 13\nTP Rank 5\n[4096→16384]" fillcolor=lightblue]
	layer_10_mlp_fc1_gpu14 [label="Layer 10 MLP FC1\nGPU 14\nTP Rank 6\n[4096→16384]" fillcolor=lightblue]
	layer_10_mlp_fc1_gpu15 [label="Layer 10 MLP FC1\nGPU 15\nTP Rank 7\n[4096→16384]" fillcolor=lightblue]
	layer_10_allgather_mlp [label="Layer 10\nAllGather MLP\nTP=8" fillcolor=orange shape=ellipse]
	layer_10_gelu [label="Layer 10\nGELU Activation" fillcolor=lightblue]
	layer_10_mlp_fc2_gpu8 [label="Layer 10 MLP FC2\nGPU 8\nTP Rank 0\n[16384→4096]" fillcolor=lightblue]
	layer_10_mlp_fc2_gpu9 [label="Layer 10 MLP FC2\nGPU 9\nTP Rank 1\n[16384→4096]" fillcolor=lightblue]
	layer_10_mlp_fc2_gpu10 [label="Layer 10 MLP FC2\nGPU 10\nTP Rank 2\n[16384→4096]" fillcolor=lightblue]
	layer_10_mlp_fc2_gpu11 [label="Layer 10 MLP FC2\nGPU 11\nTP Rank 3\n[16384→4096]" fillcolor=lightblue]
	layer_10_mlp_fc2_gpu12 [label="Layer 10 MLP FC2\nGPU 12\nTP Rank 4\n[16384→4096]" fillcolor=lightblue]
	layer_10_mlp_fc2_gpu13 [label="Layer 10 MLP FC2\nGPU 13\nTP Rank 5\n[16384→4096]" fillcolor=lightblue]
	layer_10_mlp_fc2_gpu14 [label="Layer 10 MLP FC2\nGPU 14\nTP Rank 6\n[16384→4096]" fillcolor=lightblue]
	layer_10_mlp_fc2_gpu15 [label="Layer 10 MLP FC2\nGPU 15\nTP Rank 7\n[16384→4096]" fillcolor=lightblue]
	layer_10_allreduce_mlp [label="Layer 10\nAllReduce MLP\nTP=8" fillcolor=orange shape=ellipse]
	layer_10_residual2 [label="Layer 10\nResidual Add" fillcolor=lightyellow shape=parallelogram]
	layer_10_ln2 [label="Layer 10\nLayerNorm 2\nγ,β: 4096" fillcolor=lightblue]
	layer_10_output_dist [label="Layer 10\nOutput Distribution" fillcolor=lightyellow shape=parallelogram]
	layer_11_input_dist [label="Layer 11\nInput Distribution" fillcolor=lightyellow shape=parallelogram]
	layer_11_qkv_gpu8 [label="Layer 11 QKV Proj\nGPU 8\nTP Rank 0\n[4096→12288]" fillcolor=lightblue]
	layer_11_qkv_gpu9 [label="Layer 11 QKV Proj\nGPU 9\nTP Rank 1\n[4096→12288]" fillcolor=lightblue]
	layer_11_qkv_gpu10 [label="Layer 11 QKV Proj\nGPU 10\nTP Rank 2\n[4096→12288]" fillcolor=lightblue]
	layer_11_qkv_gpu11 [label="Layer 11 QKV Proj\nGPU 11\nTP Rank 3\n[4096→12288]" fillcolor=lightblue]
	layer_11_qkv_gpu12 [label="Layer 11 QKV Proj\nGPU 12\nTP Rank 4\n[4096→12288]" fillcolor=lightblue]
	layer_11_qkv_gpu13 [label="Layer 11 QKV Proj\nGPU 13\nTP Rank 5\n[4096→12288]" fillcolor=lightblue]
	layer_11_qkv_gpu14 [label="Layer 11 QKV Proj\nGPU 14\nTP Rank 6\n[4096→12288]" fillcolor=lightblue]
	layer_11_qkv_gpu15 [label="Layer 11 QKV Proj\nGPU 15\nTP Rank 7\n[4096→12288]" fillcolor=lightblue]
	layer_11_allgather_qkv [label="Layer 11\nAllGather QKV\nTP=8" fillcolor=orange shape=ellipse]
	layer_11_attention [label="Layer 11\nAttention\n32×128 dim\nSoftmax" fillcolor=lightblue]
	layer_11_attn_out_gpu8 [label="Layer 11 Attn Out\nGPU 8\nTP Rank 0\n[4096→4096]" fillcolor=lightblue]
	layer_11_attn_out_gpu9 [label="Layer 11 Attn Out\nGPU 9\nTP Rank 1\n[4096→4096]" fillcolor=lightblue]
	layer_11_attn_out_gpu10 [label="Layer 11 Attn Out\nGPU 10\nTP Rank 2\n[4096→4096]" fillcolor=lightblue]
	layer_11_attn_out_gpu11 [label="Layer 11 Attn Out\nGPU 11\nTP Rank 3\n[4096→4096]" fillcolor=lightblue]
	layer_11_attn_out_gpu12 [label="Layer 11 Attn Out\nGPU 12\nTP Rank 4\n[4096→4096]" fillcolor=lightblue]
	layer_11_attn_out_gpu13 [label="Layer 11 Attn Out\nGPU 13\nTP Rank 5\n[4096→4096]" fillcolor=lightblue]
	layer_11_attn_out_gpu14 [label="Layer 11 Attn Out\nGPU 14\nTP Rank 6\n[4096→4096]" fillcolor=lightblue]
	layer_11_attn_out_gpu15 [label="Layer 11 Attn Out\nGPU 15\nTP Rank 7\n[4096→4096]" fillcolor=lightblue]
	layer_11_allreduce_attn [label="Layer 11\nAllReduce Attn\nTP=8" fillcolor=orange shape=ellipse]
	layer_11_residual1 [label="Layer 11\nResidual Add" fillcolor=lightyellow shape=parallelogram]
	layer_11_ln1 [label="Layer 11\nLayerNorm 1\nγ,β: 4096" fillcolor=lightblue]
	layer_11_mlp_fc1_gpu8 [label="Layer 11 MLP FC1\nGPU 8\nTP Rank 0\n[4096→16384]" fillcolor=lightblue]
	layer_11_mlp_fc1_gpu9 [label="Layer 11 MLP FC1\nGPU 9\nTP Rank 1\n[4096→16384]" fillcolor=lightblue]
	layer_11_mlp_fc1_gpu10 [label="Layer 11 MLP FC1\nGPU 10\nTP Rank 2\n[4096→16384]" fillcolor=lightblue]
	layer_11_mlp_fc1_gpu11 [label="Layer 11 MLP FC1\nGPU 11\nTP Rank 3\n[4096→16384]" fillcolor=lightblue]
	layer_11_mlp_fc1_gpu12 [label="Layer 11 MLP FC1\nGPU 12\nTP Rank 4\n[4096→16384]" fillcolor=lightblue]
	layer_11_mlp_fc1_gpu13 [label="Layer 11 MLP FC1\nGPU 13\nTP Rank 5\n[4096→16384]" fillcolor=lightblue]
	layer_11_mlp_fc1_gpu14 [label="Layer 11 MLP FC1\nGPU 14\nTP Rank 6\n[4096→16384]" fillcolor=lightblue]
	layer_11_mlp_fc1_gpu15 [label="Layer 11 MLP FC1\nGPU 15\nTP Rank 7\n[4096→16384]" fillcolor=lightblue]
	layer_11_allgather_mlp [label="Layer 11\nAllGather MLP\nTP=8" fillcolor=orange shape=ellipse]
	layer_11_gelu [label="Layer 11\nGELU Activation" fillcolor=lightblue]
	layer_11_mlp_fc2_gpu8 [label="Layer 11 MLP FC2\nGPU 8\nTP Rank 0\n[16384→4096]" fillcolor=lightblue]
	layer_11_mlp_fc2_gpu9 [label="Layer 11 MLP FC2\nGPU 9\nTP Rank 1\n[16384→4096]" fillcolor=lightblue]
	layer_11_mlp_fc2_gpu10 [label="Layer 11 MLP FC2\nGPU 10\nTP Rank 2\n[16384→4096]" fillcolor=lightblue]
	layer_11_mlp_fc2_gpu11 [label="Layer 11 MLP FC2\nGPU 11\nTP Rank 3\n[16384→4096]" fillcolor=lightblue]
	layer_11_mlp_fc2_gpu12 [label="Layer 11 MLP FC2\nGPU 12\nTP Rank 4\n[16384→4096]" fillcolor=lightblue]
	layer_11_mlp_fc2_gpu13 [label="Layer 11 MLP FC2\nGPU 13\nTP Rank 5\n[16384→4096]" fillcolor=lightblue]
	layer_11_mlp_fc2_gpu14 [label="Layer 11 MLP FC2\nGPU 14\nTP Rank 6\n[16384→4096]" fillcolor=lightblue]
	layer_11_mlp_fc2_gpu15 [label="Layer 11 MLP FC2\nGPU 15\nTP Rank 7\n[16384→4096]" fillcolor=lightblue]
	layer_11_allreduce_mlp [label="Layer 11\nAllReduce MLP\nTP=8" fillcolor=orange shape=ellipse]
	layer_11_residual2 [label="Layer 11\nResidual Add" fillcolor=lightyellow shape=parallelogram]
	layer_11_ln2 [label="Layer 11\nLayerNorm 2\nγ,β: 4096" fillcolor=lightblue]
	layer_11_output_dist [label="Layer 11\nOutput Distribution" fillcolor=lightyellow shape=parallelogram]
	layer_12_input_dist [label="Layer 12\nInput Distribution" fillcolor=lightyellow shape=parallelogram]
	layer_12_qkv_gpu8 [label="Layer 12 QKV Proj\nGPU 8\nTP Rank 0\n[4096→12288]" fillcolor=lightblue]
	layer_12_qkv_gpu9 [label="Layer 12 QKV Proj\nGPU 9\nTP Rank 1\n[4096→12288]" fillcolor=lightblue]
	layer_12_qkv_gpu10 [label="Layer 12 QKV Proj\nGPU 10\nTP Rank 2\n[4096→12288]" fillcolor=lightblue]
	layer_12_qkv_gpu11 [label="Layer 12 QKV Proj\nGPU 11\nTP Rank 3\n[4096→12288]" fillcolor=lightblue]
	layer_12_qkv_gpu12 [label="Layer 12 QKV Proj\nGPU 12\nTP Rank 4\n[4096→12288]" fillcolor=lightblue]
	layer_12_qkv_gpu13 [label="Layer 12 QKV Proj\nGPU 13\nTP Rank 5\n[4096→12288]" fillcolor=lightblue]
	layer_12_qkv_gpu14 [label="Layer 12 QKV Proj\nGPU 14\nTP Rank 6\n[4096→12288]" fillcolor=lightblue]
	layer_12_qkv_gpu15 [label="Layer 12 QKV Proj\nGPU 15\nTP Rank 7\n[4096→12288]" fillcolor=lightblue]
	layer_12_allgather_qkv [label="Layer 12\nAllGather QKV\nTP=8" fillcolor=orange shape=ellipse]
	layer_12_attention [label="Layer 12\nAttention\n32×128 dim\nSoftmax" fillcolor=lightblue]
	layer_12_attn_out_gpu8 [label="Layer 12 Attn Out\nGPU 8\nTP Rank 0\n[4096→4096]" fillcolor=lightblue]
	layer_12_attn_out_gpu9 [label="Layer 12 Attn Out\nGPU 9\nTP Rank 1\n[4096→4096]" fillcolor=lightblue]
	layer_12_attn_out_gpu10 [label="Layer 12 Attn Out\nGPU 10\nTP Rank 2\n[4096→4096]" fillcolor=lightblue]
	layer_12_attn_out_gpu11 [label="Layer 12 Attn Out\nGPU 11\nTP Rank 3\n[4096→4096]" fillcolor=lightblue]
	layer_12_attn_out_gpu12 [label="Layer 12 Attn Out\nGPU 12\nTP Rank 4\n[4096→4096]" fillcolor=lightblue]
	layer_12_attn_out_gpu13 [label="Layer 12 Attn Out\nGPU 13\nTP Rank 5\n[4096→4096]" fillcolor=lightblue]
	layer_12_attn_out_gpu14 [label="Layer 12 Attn Out\nGPU 14\nTP Rank 6\n[4096→4096]" fillcolor=lightblue]
	layer_12_attn_out_gpu15 [label="Layer 12 Attn Out\nGPU 15\nTP Rank 7\n[4096→4096]" fillcolor=lightblue]
	layer_12_allreduce_attn [label="Layer 12\nAllReduce Attn\nTP=8" fillcolor=orange shape=ellipse]
	layer_12_residual1 [label="Layer 12\nResidual Add" fillcolor=lightyellow shape=parallelogram]
	layer_12_ln1 [label="Layer 12\nLayerNorm 1\nγ,β: 4096" fillcolor=lightblue]
	layer_12_mlp_fc1_gpu8 [label="Layer 12 MLP FC1\nGPU 8\nTP Rank 0\n[4096→16384]" fillcolor=lightblue]
	layer_12_mlp_fc1_gpu9 [label="Layer 12 MLP FC1\nGPU 9\nTP Rank 1\n[4096→16384]" fillcolor=lightblue]
	layer_12_mlp_fc1_gpu10 [label="Layer 12 MLP FC1\nGPU 10\nTP Rank 2\n[4096→16384]" fillcolor=lightblue]
	layer_12_mlp_fc1_gpu11 [label="Layer 12 MLP FC1\nGPU 11\nTP Rank 3\n[4096→16384]" fillcolor=lightblue]
	layer_12_mlp_fc1_gpu12 [label="Layer 12 MLP FC1\nGPU 12\nTP Rank 4\n[4096→16384]" fillcolor=lightblue]
	layer_12_mlp_fc1_gpu13 [label="Layer 12 MLP FC1\nGPU 13\nTP Rank 5\n[4096→16384]" fillcolor=lightblue]
	layer_12_mlp_fc1_gpu14 [label="Layer 12 MLP FC1\nGPU 14\nTP Rank 6\n[4096→16384]" fillcolor=lightblue]
	layer_12_mlp_fc1_gpu15 [label="Layer 12 MLP FC1\nGPU 15\nTP Rank 7\n[4096→16384]" fillcolor=lightblue]
	layer_12_allgather_mlp [label="Layer 12\nAllGather MLP\nTP=8" fillcolor=orange shape=ellipse]
	layer_12_gelu [label="Layer 12\nGELU Activation" fillcolor=lightblue]
	layer_12_mlp_fc2_gpu8 [label="Layer 12 MLP FC2\nGPU 8\nTP Rank 0\n[16384→4096]" fillcolor=lightblue]
	layer_12_mlp_fc2_gpu9 [label="Layer 12 MLP FC2\nGPU 9\nTP Rank 1\n[16384→4096]" fillcolor=lightblue]
	layer_12_mlp_fc2_gpu10 [label="Layer 12 MLP FC2\nGPU 10\nTP Rank 2\n[16384→4096]" fillcolor=lightblue]
	layer_12_mlp_fc2_gpu11 [label="Layer 12 MLP FC2\nGPU 11\nTP Rank 3\n[16384→4096]" fillcolor=lightblue]
	layer_12_mlp_fc2_gpu12 [label="Layer 12 MLP FC2\nGPU 12\nTP Rank 4\n[16384→4096]" fillcolor=lightblue]
	layer_12_mlp_fc2_gpu13 [label="Layer 12 MLP FC2\nGPU 13\nTP Rank 5\n[16384→4096]" fillcolor=lightblue]
	layer_12_mlp_fc2_gpu14 [label="Layer 12 MLP FC2\nGPU 14\nTP Rank 6\n[16384→4096]" fillcolor=lightblue]
	layer_12_mlp_fc2_gpu15 [label="Layer 12 MLP FC2\nGPU 15\nTP Rank 7\n[16384→4096]" fillcolor=lightblue]
	layer_12_allreduce_mlp [label="Layer 12\nAllReduce MLP\nTP=8" fillcolor=orange shape=ellipse]
	layer_12_residual2 [label="Layer 12\nResidual Add" fillcolor=lightyellow shape=parallelogram]
	layer_12_ln2 [label="Layer 12\nLayerNorm 2\nγ,β: 4096" fillcolor=lightblue]
	layer_12_output_dist [label="Layer 12\nOutput Distribution" fillcolor=lightyellow shape=parallelogram]
	layer_13_input_dist [label="Layer 13\nInput Distribution" fillcolor=lightyellow shape=parallelogram]
	layer_13_qkv_gpu8 [label="Layer 13 QKV Proj\nGPU 8\nTP Rank 0\n[4096→12288]" fillcolor=lightblue]
	layer_13_qkv_gpu9 [label="Layer 13 QKV Proj\nGPU 9\nTP Rank 1\n[4096→12288]" fillcolor=lightblue]
	layer_13_qkv_gpu10 [label="Layer 13 QKV Proj\nGPU 10\nTP Rank 2\n[4096→12288]" fillcolor=lightblue]
	layer_13_qkv_gpu11 [label="Layer 13 QKV Proj\nGPU 11\nTP Rank 3\n[4096→12288]" fillcolor=lightblue]
	layer_13_qkv_gpu12 [label="Layer 13 QKV Proj\nGPU 12\nTP Rank 4\n[4096→12288]" fillcolor=lightblue]
	layer_13_qkv_gpu13 [label="Layer 13 QKV Proj\nGPU 13\nTP Rank 5\n[4096→12288]" fillcolor=lightblue]
	layer_13_qkv_gpu14 [label="Layer 13 QKV Proj\nGPU 14\nTP Rank 6\n[4096→12288]" fillcolor=lightblue]
	layer_13_qkv_gpu15 [label="Layer 13 QKV Proj\nGPU 15\nTP Rank 7\n[4096→12288]" fillcolor=lightblue]
	layer_13_allgather_qkv [label="Layer 13\nAllGather QKV\nTP=8" fillcolor=orange shape=ellipse]
	layer_13_attention [label="Layer 13\nAttention\n32×128 dim\nSoftmax" fillcolor=lightblue]
	layer_13_attn_out_gpu8 [label="Layer 13 Attn Out\nGPU 8\nTP Rank 0\n[4096→4096]" fillcolor=lightblue]
	layer_13_attn_out_gpu9 [label="Layer 13 Attn Out\nGPU 9\nTP Rank 1\n[4096→4096]" fillcolor=lightblue]
	layer_13_attn_out_gpu10 [label="Layer 13 Attn Out\nGPU 10\nTP Rank 2\n[4096→4096]" fillcolor=lightblue]
	layer_13_attn_out_gpu11 [label="Layer 13 Attn Out\nGPU 11\nTP Rank 3\n[4096→4096]" fillcolor=lightblue]
	layer_13_attn_out_gpu12 [label="Layer 13 Attn Out\nGPU 12\nTP Rank 4\n[4096→4096]" fillcolor=lightblue]
	layer_13_attn_out_gpu13 [label="Layer 13 Attn Out\nGPU 13\nTP Rank 5\n[4096→4096]" fillcolor=lightblue]
	layer_13_attn_out_gpu14 [label="Layer 13 Attn Out\nGPU 14\nTP Rank 6\n[4096→4096]" fillcolor=lightblue]
	layer_13_attn_out_gpu15 [label="Layer 13 Attn Out\nGPU 15\nTP Rank 7\n[4096→4096]" fillcolor=lightblue]
	layer_13_allreduce_attn [label="Layer 13\nAllReduce Attn\nTP=8" fillcolor=orange shape=ellipse]
	layer_13_residual1 [label="Layer 13\nResidual Add" fillcolor=lightyellow shape=parallelogram]
	layer_13_ln1 [label="Layer 13\nLayerNorm 1\nγ,β: 4096" fillcolor=lightblue]
	layer_13_mlp_fc1_gpu8 [label="Layer 13 MLP FC1\nGPU 8\nTP Rank 0\n[4096→16384]" fillcolor=lightblue]
	layer_13_mlp_fc1_gpu9 [label="Layer 13 MLP FC1\nGPU 9\nTP Rank 1\n[4096→16384]" fillcolor=lightblue]
	layer_13_mlp_fc1_gpu10 [label="Layer 13 MLP FC1\nGPU 10\nTP Rank 2\n[4096→16384]" fillcolor=lightblue]
	layer_13_mlp_fc1_gpu11 [label="Layer 13 MLP FC1\nGPU 11\nTP Rank 3\n[4096→16384]" fillcolor=lightblue]
	layer_13_mlp_fc1_gpu12 [label="Layer 13 MLP FC1\nGPU 12\nTP Rank 4\n[4096→16384]" fillcolor=lightblue]
	layer_13_mlp_fc1_gpu13 [label="Layer 13 MLP FC1\nGPU 13\nTP Rank 5\n[4096→16384]" fillcolor=lightblue]
	layer_13_mlp_fc1_gpu14 [label="Layer 13 MLP FC1\nGPU 14\nTP Rank 6\n[4096→16384]" fillcolor=lightblue]
	layer_13_mlp_fc1_gpu15 [label="Layer 13 MLP FC1\nGPU 15\nTP Rank 7\n[4096→16384]" fillcolor=lightblue]
	layer_13_allgather_mlp [label="Layer 13\nAllGather MLP\nTP=8" fillcolor=orange shape=ellipse]
	layer_13_gelu [label="Layer 13\nGELU Activation" fillcolor=lightblue]
	layer_13_mlp_fc2_gpu8 [label="Layer 13 MLP FC2\nGPU 8\nTP Rank 0\n[16384→4096]" fillcolor=lightblue]
	layer_13_mlp_fc2_gpu9 [label="Layer 13 MLP FC2\nGPU 9\nTP Rank 1\n[16384→4096]" fillcolor=lightblue]
	layer_13_mlp_fc2_gpu10 [label="Layer 13 MLP FC2\nGPU 10\nTP Rank 2\n[16384→4096]" fillcolor=lightblue]
	layer_13_mlp_fc2_gpu11 [label="Layer 13 MLP FC2\nGPU 11\nTP Rank 3\n[16384→4096]" fillcolor=lightblue]
	layer_13_mlp_fc2_gpu12 [label="Layer 13 MLP FC2\nGPU 12\nTP Rank 4\n[16384→4096]" fillcolor=lightblue]
	layer_13_mlp_fc2_gpu13 [label="Layer 13 MLP FC2\nGPU 13\nTP Rank 5\n[16384→4096]" fillcolor=lightblue]
	layer_13_mlp_fc2_gpu14 [label="Layer 13 MLP FC2\nGPU 14\nTP Rank 6\n[16384→4096]" fillcolor=lightblue]
	layer_13_mlp_fc2_gpu15 [label="Layer 13 MLP FC2\nGPU 15\nTP Rank 7\n[16384→4096]" fillcolor=lightblue]
	layer_13_allreduce_mlp [label="Layer 13\nAllReduce MLP\nTP=8" fillcolor=orange shape=ellipse]
	layer_13_residual2 [label="Layer 13\nResidual Add" fillcolor=lightyellow shape=parallelogram]
	layer_13_ln2 [label="Layer 13\nLayerNorm 2\nγ,β: 4096" fillcolor=lightblue]
	layer_13_output_dist [label="Layer 13\nOutput Distribution" fillcolor=lightyellow shape=parallelogram]
	layer_14_input_dist [label="Layer 14\nInput Distribution" fillcolor=lightyellow shape=parallelogram]
	layer_14_qkv_gpu8 [label="Layer 14 QKV Proj\nGPU 8\nTP Rank 0\n[4096→12288]" fillcolor=lightblue]
	layer_14_qkv_gpu9 [label="Layer 14 QKV Proj\nGPU 9\nTP Rank 1\n[4096→12288]" fillcolor=lightblue]
	layer_14_qkv_gpu10 [label="Layer 14 QKV Proj\nGPU 10\nTP Rank 2\n[4096→12288]" fillcolor=lightblue]
	layer_14_qkv_gpu11 [label="Layer 14 QKV Proj\nGPU 11\nTP Rank 3\n[4096→12288]" fillcolor=lightblue]
	layer_14_qkv_gpu12 [label="Layer 14 QKV Proj\nGPU 12\nTP Rank 4\n[4096→12288]" fillcolor=lightblue]
	layer_14_qkv_gpu13 [label="Layer 14 QKV Proj\nGPU 13\nTP Rank 5\n[4096→12288]" fillcolor=lightblue]
	layer_14_qkv_gpu14 [label="Layer 14 QKV Proj\nGPU 14\nTP Rank 6\n[4096→12288]" fillcolor=lightblue]
	layer_14_qkv_gpu15 [label="Layer 14 QKV Proj\nGPU 15\nTP Rank 7\n[4096→12288]" fillcolor=lightblue]
	layer_14_allgather_qkv [label="Layer 14\nAllGather QKV\nTP=8" fillcolor=orange shape=ellipse]
	layer_14_attention [label="Layer 14\nAttention\n32×128 dim\nSoftmax" fillcolor=lightblue]
	layer_14_attn_out_gpu8 [label="Layer 14 Attn Out\nGPU 8\nTP Rank 0\n[4096→4096]" fillcolor=lightblue]
	layer_14_attn_out_gpu9 [label="Layer 14 Attn Out\nGPU 9\nTP Rank 1\n[4096→4096]" fillcolor=lightblue]
	layer_14_attn_out_gpu10 [label="Layer 14 Attn Out\nGPU 10\nTP Rank 2\n[4096→4096]" fillcolor=lightblue]
	layer_14_attn_out_gpu11 [label="Layer 14 Attn Out\nGPU 11\nTP Rank 3\n[4096→4096]" fillcolor=lightblue]
	layer_14_attn_out_gpu12 [label="Layer 14 Attn Out\nGPU 12\nTP Rank 4\n[4096→4096]" fillcolor=lightblue]
	layer_14_attn_out_gpu13 [label="Layer 14 Attn Out\nGPU 13\nTP Rank 5\n[4096→4096]" fillcolor=lightblue]
	layer_14_attn_out_gpu14 [label="Layer 14 Attn Out\nGPU 14\nTP Rank 6\n[4096→4096]" fillcolor=lightblue]
	layer_14_attn_out_gpu15 [label="Layer 14 Attn Out\nGPU 15\nTP Rank 7\n[4096→4096]" fillcolor=lightblue]
	layer_14_allreduce_attn [label="Layer 14\nAllReduce Attn\nTP=8" fillcolor=orange shape=ellipse]
	layer_14_residual1 [label="Layer 14\nResidual Add" fillcolor=lightyellow shape=parallelogram]
	layer_14_ln1 [label="Layer 14\nLayerNorm 1\nγ,β: 4096" fillcolor=lightblue]
	layer_14_mlp_fc1_gpu8 [label="Layer 14 MLP FC1\nGPU 8\nTP Rank 0\n[4096→16384]" fillcolor=lightblue]
	layer_14_mlp_fc1_gpu9 [label="Layer 14 MLP FC1\nGPU 9\nTP Rank 1\n[4096→16384]" fillcolor=lightblue]
	layer_14_mlp_fc1_gpu10 [label="Layer 14 MLP FC1\nGPU 10\nTP Rank 2\n[4096→16384]" fillcolor=lightblue]
	layer_14_mlp_fc1_gpu11 [label="Layer 14 MLP FC1\nGPU 11\nTP Rank 3\n[4096→16384]" fillcolor=lightblue]
	layer_14_mlp_fc1_gpu12 [label="Layer 14 MLP FC1\nGPU 12\nTP Rank 4\n[4096→16384]" fillcolor=lightblue]
	layer_14_mlp_fc1_gpu13 [label="Layer 14 MLP FC1\nGPU 13\nTP Rank 5\n[4096→16384]" fillcolor=lightblue]
	layer_14_mlp_fc1_gpu14 [label="Layer 14 MLP FC1\nGPU 14\nTP Rank 6\n[4096→16384]" fillcolor=lightblue]
	layer_14_mlp_fc1_gpu15 [label="Layer 14 MLP FC1\nGPU 15\nTP Rank 7\n[4096→16384]" fillcolor=lightblue]
	layer_14_allgather_mlp [label="Layer 14\nAllGather MLP\nTP=8" fillcolor=orange shape=ellipse]
	layer_14_gelu [label="Layer 14\nGELU Activation" fillcolor=lightblue]
	layer_14_mlp_fc2_gpu8 [label="Layer 14 MLP FC2\nGPU 8\nTP Rank 0\n[16384→4096]" fillcolor=lightblue]
	layer_14_mlp_fc2_gpu9 [label="Layer 14 MLP FC2\nGPU 9\nTP Rank 1\n[16384→4096]" fillcolor=lightblue]
	layer_14_mlp_fc2_gpu10 [label="Layer 14 MLP FC2\nGPU 10\nTP Rank 2\n[16384→4096]" fillcolor=lightblue]
	layer_14_mlp_fc2_gpu11 [label="Layer 14 MLP FC2\nGPU 11\nTP Rank 3\n[16384→4096]" fillcolor=lightblue]
	layer_14_mlp_fc2_gpu12 [label="Layer 14 MLP FC2\nGPU 12\nTP Rank 4\n[16384→4096]" fillcolor=lightblue]
	layer_14_mlp_fc2_gpu13 [label="Layer 14 MLP FC2\nGPU 13\nTP Rank 5\n[16384→4096]" fillcolor=lightblue]
	layer_14_mlp_fc2_gpu14 [label="Layer 14 MLP FC2\nGPU 14\nTP Rank 6\n[16384→4096]" fillcolor=lightblue]
	layer_14_mlp_fc2_gpu15 [label="Layer 14 MLP FC2\nGPU 15\nTP Rank 7\n[16384→4096]" fillcolor=lightblue]
	layer_14_allreduce_mlp [label="Layer 14\nAllReduce MLP\nTP=8" fillcolor=orange shape=ellipse]
	layer_14_residual2 [label="Layer 14\nResidual Add" fillcolor=lightyellow shape=parallelogram]
	layer_14_ln2 [label="Layer 14\nLayerNorm 2\nγ,β: 4096" fillcolor=lightblue]
	layer_14_output_dist [label="Layer 14\nOutput Distribution" fillcolor=lightyellow shape=parallelogram]
	layer_15_input_dist [label="Layer 15\nInput Distribution" fillcolor=lightyellow shape=parallelogram]
	layer_15_qkv_gpu8 [label="Layer 15 QKV Proj\nGPU 8\nTP Rank 0\n[4096→12288]" fillcolor=lightblue]
	layer_15_qkv_gpu9 [label="Layer 15 QKV Proj\nGPU 9\nTP Rank 1\n[4096→12288]" fillcolor=lightblue]
	layer_15_qkv_gpu10 [label="Layer 15 QKV Proj\nGPU 10\nTP Rank 2\n[4096→12288]" fillcolor=lightblue]
	layer_15_qkv_gpu11 [label="Layer 15 QKV Proj\nGPU 11\nTP Rank 3\n[4096→12288]" fillcolor=lightblue]
	layer_15_qkv_gpu12 [label="Layer 15 QKV Proj\nGPU 12\nTP Rank 4\n[4096→12288]" fillcolor=lightblue]
	layer_15_qkv_gpu13 [label="Layer 15 QKV Proj\nGPU 13\nTP Rank 5\n[4096→12288]" fillcolor=lightblue]
	layer_15_qkv_gpu14 [label="Layer 15 QKV Proj\nGPU 14\nTP Rank 6\n[4096→12288]" fillcolor=lightblue]
	layer_15_qkv_gpu15 [label="Layer 15 QKV Proj\nGPU 15\nTP Rank 7\n[4096→12288]" fillcolor=lightblue]
	layer_15_allgather_qkv [label="Layer 15\nAllGather QKV\nTP=8" fillcolor=orange shape=ellipse]
	layer_15_attention [label="Layer 15\nAttention\n32×128 dim\nSoftmax" fillcolor=lightblue]
	layer_15_attn_out_gpu8 [label="Layer 15 Attn Out\nGPU 8\nTP Rank 0\n[4096→4096]" fillcolor=lightblue]
	layer_15_attn_out_gpu9 [label="Layer 15 Attn Out\nGPU 9\nTP Rank 1\n[4096→4096]" fillcolor=lightblue]
	layer_15_attn_out_gpu10 [label="Layer 15 Attn Out\nGPU 10\nTP Rank 2\n[4096→4096]" fillcolor=lightblue]
	layer_15_attn_out_gpu11 [label="Layer 15 Attn Out\nGPU 11\nTP Rank 3\n[4096→4096]" fillcolor=lightblue]
	layer_15_attn_out_gpu12 [label="Layer 15 Attn Out\nGPU 12\nTP Rank 4\n[4096→4096]" fillcolor=lightblue]
	layer_15_attn_out_gpu13 [label="Layer 15 Attn Out\nGPU 13\nTP Rank 5\n[4096→4096]" fillcolor=lightblue]
	layer_15_attn_out_gpu14 [label="Layer 15 Attn Out\nGPU 14\nTP Rank 6\n[4096→4096]" fillcolor=lightblue]
	layer_15_attn_out_gpu15 [label="Layer 15 Attn Out\nGPU 15\nTP Rank 7\n[4096→4096]" fillcolor=lightblue]
	layer_15_allreduce_attn [label="Layer 15\nAllReduce Attn\nTP=8" fillcolor=orange shape=ellipse]
	layer_15_residual1 [label="Layer 15\nResidual Add" fillcolor=lightyellow shape=parallelogram]
	layer_15_ln1 [label="Layer 15\nLayerNorm 1\nγ,β: 4096" fillcolor=lightblue]
	layer_15_mlp_fc1_gpu8 [label="Layer 15 MLP FC1\nGPU 8\nTP Rank 0\n[4096→16384]" fillcolor=lightblue]
	layer_15_mlp_fc1_gpu9 [label="Layer 15 MLP FC1\nGPU 9\nTP Rank 1\n[4096→16384]" fillcolor=lightblue]
	layer_15_mlp_fc1_gpu10 [label="Layer 15 MLP FC1\nGPU 10\nTP Rank 2\n[4096→16384]" fillcolor=lightblue]
	layer_15_mlp_fc1_gpu11 [label="Layer 15 MLP FC1\nGPU 11\nTP Rank 3\n[4096→16384]" fillcolor=lightblue]
	layer_15_mlp_fc1_gpu12 [label="Layer 15 MLP FC1\nGPU 12\nTP Rank 4\n[4096→16384]" fillcolor=lightblue]
	layer_15_mlp_fc1_gpu13 [label="Layer 15 MLP FC1\nGPU 13\nTP Rank 5\n[4096→16384]" fillcolor=lightblue]
	layer_15_mlp_fc1_gpu14 [label="Layer 15 MLP FC1\nGPU 14\nTP Rank 6\n[4096→16384]" fillcolor=lightblue]
	layer_15_mlp_fc1_gpu15 [label="Layer 15 MLP FC1\nGPU 15\nTP Rank 7\n[4096→16384]" fillcolor=lightblue]
	layer_15_allgather_mlp [label="Layer 15\nAllGather MLP\nTP=8" fillcolor=orange shape=ellipse]
	layer_15_gelu [label="Layer 15\nGELU Activation" fillcolor=lightblue]
	layer_15_mlp_fc2_gpu8 [label="Layer 15 MLP FC2\nGPU 8\nTP Rank 0\n[16384→4096]" fillcolor=lightblue]
	layer_15_mlp_fc2_gpu9 [label="Layer 15 MLP FC2\nGPU 9\nTP Rank 1\n[16384→4096]" fillcolor=lightblue]
	layer_15_mlp_fc2_gpu10 [label="Layer 15 MLP FC2\nGPU 10\nTP Rank 2\n[16384→4096]" fillcolor=lightblue]
	layer_15_mlp_fc2_gpu11 [label="Layer 15 MLP FC2\nGPU 11\nTP Rank 3\n[16384→4096]" fillcolor=lightblue]
	layer_15_mlp_fc2_gpu12 [label="Layer 15 MLP FC2\nGPU 12\nTP Rank 4\n[16384→4096]" fillcolor=lightblue]
	layer_15_mlp_fc2_gpu13 [label="Layer 15 MLP FC2\nGPU 13\nTP Rank 5\n[16384→4096]" fillcolor=lightblue]
	layer_15_mlp_fc2_gpu14 [label="Layer 15 MLP FC2\nGPU 14\nTP Rank 6\n[16384→4096]" fillcolor=lightblue]
	layer_15_mlp_fc2_gpu15 [label="Layer 15 MLP FC2\nGPU 15\nTP Rank 7\n[16384→4096]" fillcolor=lightblue]
	layer_15_allreduce_mlp [label="Layer 15\nAllReduce MLP\nTP=8" fillcolor=orange shape=ellipse]
	layer_15_residual2 [label="Layer 15\nResidual Add" fillcolor=lightyellow shape=parallelogram]
	layer_15_ln2 [label="Layer 15\nLayerNorm 2\nγ,β: 4096" fillcolor=lightblue]
	output [label="Output\nBatch: 128\nSeq: 10000\nHidden: 4096" fillcolor=lightgreen shape=parallelogram]
	input -> layer_0_input_dist
	input -> layer_0_input_dist
	layer_0_input_dist -> layer_0_qkv_gpu0
	layer_0_input_dist -> layer_0_qkv_gpu1
	layer_0_input_dist -> layer_0_qkv_gpu2
	layer_0_input_dist -> layer_0_qkv_gpu3
	layer_0_input_dist -> layer_0_qkv_gpu4
	layer_0_input_dist -> layer_0_qkv_gpu5
	layer_0_input_dist -> layer_0_qkv_gpu6
	layer_0_input_dist -> layer_0_qkv_gpu7
	layer_0_qkv_gpu0 -> layer_0_allgather_qkv
	layer_0_qkv_gpu1 -> layer_0_allgather_qkv
	layer_0_qkv_gpu2 -> layer_0_allgather_qkv
	layer_0_qkv_gpu3 -> layer_0_allgather_qkv
	layer_0_qkv_gpu4 -> layer_0_allgather_qkv
	layer_0_qkv_gpu5 -> layer_0_allgather_qkv
	layer_0_qkv_gpu6 -> layer_0_allgather_qkv
	layer_0_qkv_gpu7 -> layer_0_allgather_qkv
	layer_0_allgather_qkv -> layer_0_attention
	layer_0_attention -> layer_0_attn_out_gpu7
	layer_0_attn_out_gpu0 -> layer_0_allreduce_attn
	layer_0_attn_out_gpu1 -> layer_0_allreduce_attn
	layer_0_attn_out_gpu2 -> layer_0_allreduce_attn
	layer_0_attn_out_gpu3 -> layer_0_allreduce_attn
	layer_0_attn_out_gpu4 -> layer_0_allreduce_attn
	layer_0_attn_out_gpu5 -> layer_0_allreduce_attn
	layer_0_attn_out_gpu6 -> layer_0_allreduce_attn
	layer_0_attn_out_gpu7 -> layer_0_allreduce_attn
	layer_0_allreduce_attn -> layer_0_residual1
	layer_0_input_dist -> layer_0_residual1
	layer_0_residual1 -> layer_0_ln1
	layer_0_ln1 -> layer_0_mlp_fc1_gpu0
	layer_0_ln1 -> layer_0_mlp_fc1_gpu1
	layer_0_ln1 -> layer_0_mlp_fc1_gpu2
	layer_0_ln1 -> layer_0_mlp_fc1_gpu3
	layer_0_ln1 -> layer_0_mlp_fc1_gpu4
	layer_0_ln1 -> layer_0_mlp_fc1_gpu5
	layer_0_ln1 -> layer_0_mlp_fc1_gpu6
	layer_0_ln1 -> layer_0_mlp_fc1_gpu7
	layer_0_mlp_fc1_gpu0 -> layer_0_allgather_mlp
	layer_0_mlp_fc1_gpu1 -> layer_0_allgather_mlp
	layer_0_mlp_fc1_gpu2 -> layer_0_allgather_mlp
	layer_0_mlp_fc1_gpu3 -> layer_0_allgather_mlp
	layer_0_mlp_fc1_gpu4 -> layer_0_allgather_mlp
	layer_0_mlp_fc1_gpu5 -> layer_0_allgather_mlp
	layer_0_mlp_fc1_gpu6 -> layer_0_allgather_mlp
	layer_0_mlp_fc1_gpu7 -> layer_0_allgather_mlp
	layer_0_allgather_mlp -> layer_0_gelu
	layer_0_gelu -> layer_0_mlp_fc2_gpu7
	layer_0_mlp_fc2_gpu0 -> layer_0_allreduce_mlp
	layer_0_mlp_fc2_gpu1 -> layer_0_allreduce_mlp
	layer_0_mlp_fc2_gpu2 -> layer_0_allreduce_mlp
	layer_0_mlp_fc2_gpu3 -> layer_0_allreduce_mlp
	layer_0_mlp_fc2_gpu4 -> layer_0_allreduce_mlp
	layer_0_mlp_fc2_gpu5 -> layer_0_allreduce_mlp
	layer_0_mlp_fc2_gpu6 -> layer_0_allreduce_mlp
	layer_0_mlp_fc2_gpu7 -> layer_0_allreduce_mlp
	layer_0_allreduce_mlp -> layer_0_residual2
	layer_0_residual1 -> layer_0_residual2
	layer_0_residual2 -> layer_0_ln2
	layer_0_ln2 -> layer_0_output_dist
	layer_0_output_dist -> layer_1_input_dist
	layer_1_input_dist -> layer_1_qkv_gpu0
	layer_1_input_dist -> layer_1_qkv_gpu1
	layer_1_input_dist -> layer_1_qkv_gpu2
	layer_1_input_dist -> layer_1_qkv_gpu3
	layer_1_input_dist -> layer_1_qkv_gpu4
	layer_1_input_dist -> layer_1_qkv_gpu5
	layer_1_input_dist -> layer_1_qkv_gpu6
	layer_1_input_dist -> layer_1_qkv_gpu7
	layer_1_qkv_gpu0 -> layer_1_allgather_qkv
	layer_1_qkv_gpu1 -> layer_1_allgather_qkv
	layer_1_qkv_gpu2 -> layer_1_allgather_qkv
	layer_1_qkv_gpu3 -> layer_1_allgather_qkv
	layer_1_qkv_gpu4 -> layer_1_allgather_qkv
	layer_1_qkv_gpu5 -> layer_1_allgather_qkv
	layer_1_qkv_gpu6 -> layer_1_allgather_qkv
	layer_1_qkv_gpu7 -> layer_1_allgather_qkv
	layer_1_allgather_qkv -> layer_1_attention
	layer_1_attention -> layer_1_attn_out_gpu7
	layer_1_attn_out_gpu0 -> layer_1_allreduce_attn
	layer_1_attn_out_gpu1 -> layer_1_allreduce_attn
	layer_1_attn_out_gpu2 -> layer_1_allreduce_attn
	layer_1_attn_out_gpu3 -> layer_1_allreduce_attn
	layer_1_attn_out_gpu4 -> layer_1_allreduce_attn
	layer_1_attn_out_gpu5 -> layer_1_allreduce_attn
	layer_1_attn_out_gpu6 -> layer_1_allreduce_attn
	layer_1_attn_out_gpu7 -> layer_1_allreduce_attn
	layer_1_allreduce_attn -> layer_1_residual1
	layer_1_input_dist -> layer_1_residual1
	layer_1_residual1 -> layer_1_ln1
	layer_1_ln1 -> layer_1_mlp_fc1_gpu0
	layer_1_ln1 -> layer_1_mlp_fc1_gpu1
	layer_1_ln1 -> layer_1_mlp_fc1_gpu2
	layer_1_ln1 -> layer_1_mlp_fc1_gpu3
	layer_1_ln1 -> layer_1_mlp_fc1_gpu4
	layer_1_ln1 -> layer_1_mlp_fc1_gpu5
	layer_1_ln1 -> layer_1_mlp_fc1_gpu6
	layer_1_ln1 -> layer_1_mlp_fc1_gpu7
	layer_1_mlp_fc1_gpu0 -> layer_1_allgather_mlp
	layer_1_mlp_fc1_gpu1 -> layer_1_allgather_mlp
	layer_1_mlp_fc1_gpu2 -> layer_1_allgather_mlp
	layer_1_mlp_fc1_gpu3 -> layer_1_allgather_mlp
	layer_1_mlp_fc1_gpu4 -> layer_1_allgather_mlp
	layer_1_mlp_fc1_gpu5 -> layer_1_allgather_mlp
	layer_1_mlp_fc1_gpu6 -> layer_1_allgather_mlp
	layer_1_mlp_fc1_gpu7 -> layer_1_allgather_mlp
	layer_1_allgather_mlp -> layer_1_gelu
	layer_1_gelu -> layer_1_mlp_fc2_gpu7
	layer_1_mlp_fc2_gpu0 -> layer_1_allreduce_mlp
	layer_1_mlp_fc2_gpu1 -> layer_1_allreduce_mlp
	layer_1_mlp_fc2_gpu2 -> layer_1_allreduce_mlp
	layer_1_mlp_fc2_gpu3 -> layer_1_allreduce_mlp
	layer_1_mlp_fc2_gpu4 -> layer_1_allreduce_mlp
	layer_1_mlp_fc2_gpu5 -> layer_1_allreduce_mlp
	layer_1_mlp_fc2_gpu6 -> layer_1_allreduce_mlp
	layer_1_mlp_fc2_gpu7 -> layer_1_allreduce_mlp
	layer_1_allreduce_mlp -> layer_1_residual2
	layer_1_residual1 -> layer_1_residual2
	layer_1_residual2 -> layer_1_ln2
	layer_1_ln2 -> layer_1_output_dist
	layer_1_output_dist -> layer_2_input_dist
	layer_2_input_dist -> layer_2_qkv_gpu0
	layer_2_input_dist -> layer_2_qkv_gpu1
	layer_2_input_dist -> layer_2_qkv_gpu2
	layer_2_input_dist -> layer_2_qkv_gpu3
	layer_2_input_dist -> layer_2_qkv_gpu4
	layer_2_input_dist -> layer_2_qkv_gpu5
	layer_2_input_dist -> layer_2_qkv_gpu6
	layer_2_input_dist -> layer_2_qkv_gpu7
	layer_2_qkv_gpu0 -> layer_2_allgather_qkv
	layer_2_qkv_gpu1 -> layer_2_allgather_qkv
	layer_2_qkv_gpu2 -> layer_2_allgather_qkv
	layer_2_qkv_gpu3 -> layer_2_allgather_qkv
	layer_2_qkv_gpu4 -> layer_2_allgather_qkv
	layer_2_qkv_gpu5 -> layer_2_allgather_qkv
	layer_2_qkv_gpu6 -> layer_2_allgather_qkv
	layer_2_qkv_gpu7 -> layer_2_allgather_qkv
	layer_2_allgather_qkv -> layer_2_attention
	layer_2_attention -> layer_2_attn_out_gpu7
	layer_2_attn_out_gpu0 -> layer_2_allreduce_attn
	layer_2_attn_out_gpu1 -> layer_2_allreduce_attn
	layer_2_attn_out_gpu2 -> layer_2_allreduce_attn
	layer_2_attn_out_gpu3 -> layer_2_allreduce_attn
	layer_2_attn_out_gpu4 -> layer_2_allreduce_attn
	layer_2_attn_out_gpu5 -> layer_2_allreduce_attn
	layer_2_attn_out_gpu6 -> layer_2_allreduce_attn
	layer_2_attn_out_gpu7 -> layer_2_allreduce_attn
	layer_2_allreduce_attn -> layer_2_residual1
	layer_2_input_dist -> layer_2_residual1
	layer_2_residual1 -> layer_2_ln1
	layer_2_ln1 -> layer_2_mlp_fc1_gpu0
	layer_2_ln1 -> layer_2_mlp_fc1_gpu1
	layer_2_ln1 -> layer_2_mlp_fc1_gpu2
	layer_2_ln1 -> layer_2_mlp_fc1_gpu3
	layer_2_ln1 -> layer_2_mlp_fc1_gpu4
	layer_2_ln1 -> layer_2_mlp_fc1_gpu5
	layer_2_ln1 -> layer_2_mlp_fc1_gpu6
	layer_2_ln1 -> layer_2_mlp_fc1_gpu7
	layer_2_mlp_fc1_gpu0 -> layer_2_allgather_mlp
	layer_2_mlp_fc1_gpu1 -> layer_2_allgather_mlp
	layer_2_mlp_fc1_gpu2 -> layer_2_allgather_mlp
	layer_2_mlp_fc1_gpu3 -> layer_2_allgather_mlp
	layer_2_mlp_fc1_gpu4 -> layer_2_allgather_mlp
	layer_2_mlp_fc1_gpu5 -> layer_2_allgather_mlp
	layer_2_mlp_fc1_gpu6 -> layer_2_allgather_mlp
	layer_2_mlp_fc1_gpu7 -> layer_2_allgather_mlp
	layer_2_allgather_mlp -> layer_2_gelu
	layer_2_gelu -> layer_2_mlp_fc2_gpu7
	layer_2_mlp_fc2_gpu0 -> layer_2_allreduce_mlp
	layer_2_mlp_fc2_gpu1 -> layer_2_allreduce_mlp
	layer_2_mlp_fc2_gpu2 -> layer_2_allreduce_mlp
	layer_2_mlp_fc2_gpu3 -> layer_2_allreduce_mlp
	layer_2_mlp_fc2_gpu4 -> layer_2_allreduce_mlp
	layer_2_mlp_fc2_gpu5 -> layer_2_allreduce_mlp
	layer_2_mlp_fc2_gpu6 -> layer_2_allreduce_mlp
	layer_2_mlp_fc2_gpu7 -> layer_2_allreduce_mlp
	layer_2_allreduce_mlp -> layer_2_residual2
	layer_2_residual1 -> layer_2_residual2
	layer_2_residual2 -> layer_2_ln2
	layer_2_ln2 -> layer_2_output_dist
	layer_2_output_dist -> layer_3_input_dist
	layer_3_input_dist -> layer_3_qkv_gpu0
	layer_3_input_dist -> layer_3_qkv_gpu1
	layer_3_input_dist -> layer_3_qkv_gpu2
	layer_3_input_dist -> layer_3_qkv_gpu3
	layer_3_input_dist -> layer_3_qkv_gpu4
	layer_3_input_dist -> layer_3_qkv_gpu5
	layer_3_input_dist -> layer_3_qkv_gpu6
	layer_3_input_dist -> layer_3_qkv_gpu7
	layer_3_qkv_gpu0 -> layer_3_allgather_qkv
	layer_3_qkv_gpu1 -> layer_3_allgather_qkv
	layer_3_qkv_gpu2 -> layer_3_allgather_qkv
	layer_3_qkv_gpu3 -> layer_3_allgather_qkv
	layer_3_qkv_gpu4 -> layer_3_allgather_qkv
	layer_3_qkv_gpu5 -> layer_3_allgather_qkv
	layer_3_qkv_gpu6 -> layer_3_allgather_qkv
	layer_3_qkv_gpu7 -> layer_3_allgather_qkv
	layer_3_allgather_qkv -> layer_3_attention
	layer_3_attention -> layer_3_attn_out_gpu7
	layer_3_attn_out_gpu0 -> layer_3_allreduce_attn
	layer_3_attn_out_gpu1 -> layer_3_allreduce_attn
	layer_3_attn_out_gpu2 -> layer_3_allreduce_attn
	layer_3_attn_out_gpu3 -> layer_3_allreduce_attn
	layer_3_attn_out_gpu4 -> layer_3_allreduce_attn
	layer_3_attn_out_gpu5 -> layer_3_allreduce_attn
	layer_3_attn_out_gpu6 -> layer_3_allreduce_attn
	layer_3_attn_out_gpu7 -> layer_3_allreduce_attn
	layer_3_allreduce_attn -> layer_3_residual1
	layer_3_input_dist -> layer_3_residual1
	layer_3_residual1 -> layer_3_ln1
	layer_3_ln1 -> layer_3_mlp_fc1_gpu0
	layer_3_ln1 -> layer_3_mlp_fc1_gpu1
	layer_3_ln1 -> layer_3_mlp_fc1_gpu2
	layer_3_ln1 -> layer_3_mlp_fc1_gpu3
	layer_3_ln1 -> layer_3_mlp_fc1_gpu4
	layer_3_ln1 -> layer_3_mlp_fc1_gpu5
	layer_3_ln1 -> layer_3_mlp_fc1_gpu6
	layer_3_ln1 -> layer_3_mlp_fc1_gpu7
	layer_3_mlp_fc1_gpu0 -> layer_3_allgather_mlp
	layer_3_mlp_fc1_gpu1 -> layer_3_allgather_mlp
	layer_3_mlp_fc1_gpu2 -> layer_3_allgather_mlp
	layer_3_mlp_fc1_gpu3 -> layer_3_allgather_mlp
	layer_3_mlp_fc1_gpu4 -> layer_3_allgather_mlp
	layer_3_mlp_fc1_gpu5 -> layer_3_allgather_mlp
	layer_3_mlp_fc1_gpu6 -> layer_3_allgather_mlp
	layer_3_mlp_fc1_gpu7 -> layer_3_allgather_mlp
	layer_3_allgather_mlp -> layer_3_gelu
	layer_3_gelu -> layer_3_mlp_fc2_gpu7
	layer_3_mlp_fc2_gpu0 -> layer_3_allreduce_mlp
	layer_3_mlp_fc2_gpu1 -> layer_3_allreduce_mlp
	layer_3_mlp_fc2_gpu2 -> layer_3_allreduce_mlp
	layer_3_mlp_fc2_gpu3 -> layer_3_allreduce_mlp
	layer_3_mlp_fc2_gpu4 -> layer_3_allreduce_mlp
	layer_3_mlp_fc2_gpu5 -> layer_3_allreduce_mlp
	layer_3_mlp_fc2_gpu6 -> layer_3_allreduce_mlp
	layer_3_mlp_fc2_gpu7 -> layer_3_allreduce_mlp
	layer_3_allreduce_mlp -> layer_3_residual2
	layer_3_residual1 -> layer_3_residual2
	layer_3_residual2 -> layer_3_ln2
	layer_3_ln2 -> layer_3_output_dist
	layer_3_output_dist -> layer_4_input_dist
	layer_4_input_dist -> layer_4_qkv_gpu0
	layer_4_input_dist -> layer_4_qkv_gpu1
	layer_4_input_dist -> layer_4_qkv_gpu2
	layer_4_input_dist -> layer_4_qkv_gpu3
	layer_4_input_dist -> layer_4_qkv_gpu4
	layer_4_input_dist -> layer_4_qkv_gpu5
	layer_4_input_dist -> layer_4_qkv_gpu6
	layer_4_input_dist -> layer_4_qkv_gpu7
	layer_4_qkv_gpu0 -> layer_4_allgather_qkv
	layer_4_qkv_gpu1 -> layer_4_allgather_qkv
	layer_4_qkv_gpu2 -> layer_4_allgather_qkv
	layer_4_qkv_gpu3 -> layer_4_allgather_qkv
	layer_4_qkv_gpu4 -> layer_4_allgather_qkv
	layer_4_qkv_gpu5 -> layer_4_allgather_qkv
	layer_4_qkv_gpu6 -> layer_4_allgather_qkv
	layer_4_qkv_gpu7 -> layer_4_allgather_qkv
	layer_4_allgather_qkv -> layer_4_attention
	layer_4_attention -> layer_4_attn_out_gpu7
	layer_4_attn_out_gpu0 -> layer_4_allreduce_attn
	layer_4_attn_out_gpu1 -> layer_4_allreduce_attn
	layer_4_attn_out_gpu2 -> layer_4_allreduce_attn
	layer_4_attn_out_gpu3 -> layer_4_allreduce_attn
	layer_4_attn_out_gpu4 -> layer_4_allreduce_attn
	layer_4_attn_out_gpu5 -> layer_4_allreduce_attn
	layer_4_attn_out_gpu6 -> layer_4_allreduce_attn
	layer_4_attn_out_gpu7 -> layer_4_allreduce_attn
	layer_4_allreduce_attn -> layer_4_residual1
	layer_4_input_dist -> layer_4_residual1
	layer_4_residual1 -> layer_4_ln1
	layer_4_ln1 -> layer_4_mlp_fc1_gpu0
	layer_4_ln1 -> layer_4_mlp_fc1_gpu1
	layer_4_ln1 -> layer_4_mlp_fc1_gpu2
	layer_4_ln1 -> layer_4_mlp_fc1_gpu3
	layer_4_ln1 -> layer_4_mlp_fc1_gpu4
	layer_4_ln1 -> layer_4_mlp_fc1_gpu5
	layer_4_ln1 -> layer_4_mlp_fc1_gpu6
	layer_4_ln1 -> layer_4_mlp_fc1_gpu7
	layer_4_mlp_fc1_gpu0 -> layer_4_allgather_mlp
	layer_4_mlp_fc1_gpu1 -> layer_4_allgather_mlp
	layer_4_mlp_fc1_gpu2 -> layer_4_allgather_mlp
	layer_4_mlp_fc1_gpu3 -> layer_4_allgather_mlp
	layer_4_mlp_fc1_gpu4 -> layer_4_allgather_mlp
	layer_4_mlp_fc1_gpu5 -> layer_4_allgather_mlp
	layer_4_mlp_fc1_gpu6 -> layer_4_allgather_mlp
	layer_4_mlp_fc1_gpu7 -> layer_4_allgather_mlp
	layer_4_allgather_mlp -> layer_4_gelu
	layer_4_gelu -> layer_4_mlp_fc2_gpu7
	layer_4_mlp_fc2_gpu0 -> layer_4_allreduce_mlp
	layer_4_mlp_fc2_gpu1 -> layer_4_allreduce_mlp
	layer_4_mlp_fc2_gpu2 -> layer_4_allreduce_mlp
	layer_4_mlp_fc2_gpu3 -> layer_4_allreduce_mlp
	layer_4_mlp_fc2_gpu4 -> layer_4_allreduce_mlp
	layer_4_mlp_fc2_gpu5 -> layer_4_allreduce_mlp
	layer_4_mlp_fc2_gpu6 -> layer_4_allreduce_mlp
	layer_4_mlp_fc2_gpu7 -> layer_4_allreduce_mlp
	layer_4_allreduce_mlp -> layer_4_residual2
	layer_4_residual1 -> layer_4_residual2
	layer_4_residual2 -> layer_4_ln2
	layer_4_ln2 -> layer_4_output_dist
	layer_4_output_dist -> layer_5_input_dist
	layer_5_input_dist -> layer_5_qkv_gpu0
	layer_5_input_dist -> layer_5_qkv_gpu1
	layer_5_input_dist -> layer_5_qkv_gpu2
	layer_5_input_dist -> layer_5_qkv_gpu3
	layer_5_input_dist -> layer_5_qkv_gpu4
	layer_5_input_dist -> layer_5_qkv_gpu5
	layer_5_input_dist -> layer_5_qkv_gpu6
	layer_5_input_dist -> layer_5_qkv_gpu7
	layer_5_qkv_gpu0 -> layer_5_allgather_qkv
	layer_5_qkv_gpu1 -> layer_5_allgather_qkv
	layer_5_qkv_gpu2 -> layer_5_allgather_qkv
	layer_5_qkv_gpu3 -> layer_5_allgather_qkv
	layer_5_qkv_gpu4 -> layer_5_allgather_qkv
	layer_5_qkv_gpu5 -> layer_5_allgather_qkv
	layer_5_qkv_gpu6 -> layer_5_allgather_qkv
	layer_5_qkv_gpu7 -> layer_5_allgather_qkv
	layer_5_allgather_qkv -> layer_5_attention
	layer_5_attention -> layer_5_attn_out_gpu7
	layer_5_attn_out_gpu0 -> layer_5_allreduce_attn
	layer_5_attn_out_gpu1 -> layer_5_allreduce_attn
	layer_5_attn_out_gpu2 -> layer_5_allreduce_attn
	layer_5_attn_out_gpu3 -> layer_5_allreduce_attn
	layer_5_attn_out_gpu4 -> layer_5_allreduce_attn
	layer_5_attn_out_gpu5 -> layer_5_allreduce_attn
	layer_5_attn_out_gpu6 -> layer_5_allreduce_attn
	layer_5_attn_out_gpu7 -> layer_5_allreduce_attn
	layer_5_allreduce_attn -> layer_5_residual1
	layer_5_input_dist -> layer_5_residual1
	layer_5_residual1 -> layer_5_ln1
	layer_5_ln1 -> layer_5_mlp_fc1_gpu0
	layer_5_ln1 -> layer_5_mlp_fc1_gpu1
	layer_5_ln1 -> layer_5_mlp_fc1_gpu2
	layer_5_ln1 -> layer_5_mlp_fc1_gpu3
	layer_5_ln1 -> layer_5_mlp_fc1_gpu4
	layer_5_ln1 -> layer_5_mlp_fc1_gpu5
	layer_5_ln1 -> layer_5_mlp_fc1_gpu6
	layer_5_ln1 -> layer_5_mlp_fc1_gpu7
	layer_5_mlp_fc1_gpu0 -> layer_5_allgather_mlp
	layer_5_mlp_fc1_gpu1 -> layer_5_allgather_mlp
	layer_5_mlp_fc1_gpu2 -> layer_5_allgather_mlp
	layer_5_mlp_fc1_gpu3 -> layer_5_allgather_mlp
	layer_5_mlp_fc1_gpu4 -> layer_5_allgather_mlp
	layer_5_mlp_fc1_gpu5 -> layer_5_allgather_mlp
	layer_5_mlp_fc1_gpu6 -> layer_5_allgather_mlp
	layer_5_mlp_fc1_gpu7 -> layer_5_allgather_mlp
	layer_5_allgather_mlp -> layer_5_gelu
	layer_5_gelu -> layer_5_mlp_fc2_gpu7
	layer_5_mlp_fc2_gpu0 -> layer_5_allreduce_mlp
	layer_5_mlp_fc2_gpu1 -> layer_5_allreduce_mlp
	layer_5_mlp_fc2_gpu2 -> layer_5_allreduce_mlp
	layer_5_mlp_fc2_gpu3 -> layer_5_allreduce_mlp
	layer_5_mlp_fc2_gpu4 -> layer_5_allreduce_mlp
	layer_5_mlp_fc2_gpu5 -> layer_5_allreduce_mlp
	layer_5_mlp_fc2_gpu6 -> layer_5_allreduce_mlp
	layer_5_mlp_fc2_gpu7 -> layer_5_allreduce_mlp
	layer_5_allreduce_mlp -> layer_5_residual2
	layer_5_residual1 -> layer_5_residual2
	layer_5_residual2 -> layer_5_ln2
	layer_5_ln2 -> layer_5_output_dist
	layer_5_output_dist -> layer_6_input_dist
	layer_6_input_dist -> layer_6_qkv_gpu0
	layer_6_input_dist -> layer_6_qkv_gpu1
	layer_6_input_dist -> layer_6_qkv_gpu2
	layer_6_input_dist -> layer_6_qkv_gpu3
	layer_6_input_dist -> layer_6_qkv_gpu4
	layer_6_input_dist -> layer_6_qkv_gpu5
	layer_6_input_dist -> layer_6_qkv_gpu6
	layer_6_input_dist -> layer_6_qkv_gpu7
	layer_6_qkv_gpu0 -> layer_6_allgather_qkv
	layer_6_qkv_gpu1 -> layer_6_allgather_qkv
	layer_6_qkv_gpu2 -> layer_6_allgather_qkv
	layer_6_qkv_gpu3 -> layer_6_allgather_qkv
	layer_6_qkv_gpu4 -> layer_6_allgather_qkv
	layer_6_qkv_gpu5 -> layer_6_allgather_qkv
	layer_6_qkv_gpu6 -> layer_6_allgather_qkv
	layer_6_qkv_gpu7 -> layer_6_allgather_qkv
	layer_6_allgather_qkv -> layer_6_attention
	layer_6_attention -> layer_6_attn_out_gpu7
	layer_6_attn_out_gpu0 -> layer_6_allreduce_attn
	layer_6_attn_out_gpu1 -> layer_6_allreduce_attn
	layer_6_attn_out_gpu2 -> layer_6_allreduce_attn
	layer_6_attn_out_gpu3 -> layer_6_allreduce_attn
	layer_6_attn_out_gpu4 -> layer_6_allreduce_attn
	layer_6_attn_out_gpu5 -> layer_6_allreduce_attn
	layer_6_attn_out_gpu6 -> layer_6_allreduce_attn
	layer_6_attn_out_gpu7 -> layer_6_allreduce_attn
	layer_6_allreduce_attn -> layer_6_residual1
	layer_6_input_dist -> layer_6_residual1
	layer_6_residual1 -> layer_6_ln1
	layer_6_ln1 -> layer_6_mlp_fc1_gpu0
	layer_6_ln1 -> layer_6_mlp_fc1_gpu1
	layer_6_ln1 -> layer_6_mlp_fc1_gpu2
	layer_6_ln1 -> layer_6_mlp_fc1_gpu3
	layer_6_ln1 -> layer_6_mlp_fc1_gpu4
	layer_6_ln1 -> layer_6_mlp_fc1_gpu5
	layer_6_ln1 -> layer_6_mlp_fc1_gpu6
	layer_6_ln1 -> layer_6_mlp_fc1_gpu7
	layer_6_mlp_fc1_gpu0 -> layer_6_allgather_mlp
	layer_6_mlp_fc1_gpu1 -> layer_6_allgather_mlp
	layer_6_mlp_fc1_gpu2 -> layer_6_allgather_mlp
	layer_6_mlp_fc1_gpu3 -> layer_6_allgather_mlp
	layer_6_mlp_fc1_gpu4 -> layer_6_allgather_mlp
	layer_6_mlp_fc1_gpu5 -> layer_6_allgather_mlp
	layer_6_mlp_fc1_gpu6 -> layer_6_allgather_mlp
	layer_6_mlp_fc1_gpu7 -> layer_6_allgather_mlp
	layer_6_allgather_mlp -> layer_6_gelu
	layer_6_gelu -> layer_6_mlp_fc2_gpu7
	layer_6_mlp_fc2_gpu0 -> layer_6_allreduce_mlp
	layer_6_mlp_fc2_gpu1 -> layer_6_allreduce_mlp
	layer_6_mlp_fc2_gpu2 -> layer_6_allreduce_mlp
	layer_6_mlp_fc2_gpu3 -> layer_6_allreduce_mlp
	layer_6_mlp_fc2_gpu4 -> layer_6_allreduce_mlp
	layer_6_mlp_fc2_gpu5 -> layer_6_allreduce_mlp
	layer_6_mlp_fc2_gpu6 -> layer_6_allreduce_mlp
	layer_6_mlp_fc2_gpu7 -> layer_6_allreduce_mlp
	layer_6_allreduce_mlp -> layer_6_residual2
	layer_6_residual1 -> layer_6_residual2
	layer_6_residual2 -> layer_6_ln2
	layer_6_ln2 -> layer_6_output_dist
	layer_6_output_dist -> layer_7_input_dist
	layer_7_input_dist -> layer_7_qkv_gpu0
	layer_7_input_dist -> layer_7_qkv_gpu1
	layer_7_input_dist -> layer_7_qkv_gpu2
	layer_7_input_dist -> layer_7_qkv_gpu3
	layer_7_input_dist -> layer_7_qkv_gpu4
	layer_7_input_dist -> layer_7_qkv_gpu5
	layer_7_input_dist -> layer_7_qkv_gpu6
	layer_7_input_dist -> layer_7_qkv_gpu7
	layer_7_qkv_gpu0 -> layer_7_allgather_qkv
	layer_7_qkv_gpu1 -> layer_7_allgather_qkv
	layer_7_qkv_gpu2 -> layer_7_allgather_qkv
	layer_7_qkv_gpu3 -> layer_7_allgather_qkv
	layer_7_qkv_gpu4 -> layer_7_allgather_qkv
	layer_7_qkv_gpu5 -> layer_7_allgather_qkv
	layer_7_qkv_gpu6 -> layer_7_allgather_qkv
	layer_7_qkv_gpu7 -> layer_7_allgather_qkv
	layer_7_allgather_qkv -> layer_7_attention
	layer_7_attention -> layer_7_attn_out_gpu7
	layer_7_attn_out_gpu0 -> layer_7_allreduce_attn
	layer_7_attn_out_gpu1 -> layer_7_allreduce_attn
	layer_7_attn_out_gpu2 -> layer_7_allreduce_attn
	layer_7_attn_out_gpu3 -> layer_7_allreduce_attn
	layer_7_attn_out_gpu4 -> layer_7_allreduce_attn
	layer_7_attn_out_gpu5 -> layer_7_allreduce_attn
	layer_7_attn_out_gpu6 -> layer_7_allreduce_attn
	layer_7_attn_out_gpu7 -> layer_7_allreduce_attn
	layer_7_allreduce_attn -> layer_7_residual1
	layer_7_input_dist -> layer_7_residual1
	layer_7_residual1 -> layer_7_ln1
	layer_7_ln1 -> layer_7_mlp_fc1_gpu0
	layer_7_ln1 -> layer_7_mlp_fc1_gpu1
	layer_7_ln1 -> layer_7_mlp_fc1_gpu2
	layer_7_ln1 -> layer_7_mlp_fc1_gpu3
	layer_7_ln1 -> layer_7_mlp_fc1_gpu4
	layer_7_ln1 -> layer_7_mlp_fc1_gpu5
	layer_7_ln1 -> layer_7_mlp_fc1_gpu6
	layer_7_ln1 -> layer_7_mlp_fc1_gpu7
	layer_7_mlp_fc1_gpu0 -> layer_7_allgather_mlp
	layer_7_mlp_fc1_gpu1 -> layer_7_allgather_mlp
	layer_7_mlp_fc1_gpu2 -> layer_7_allgather_mlp
	layer_7_mlp_fc1_gpu3 -> layer_7_allgather_mlp
	layer_7_mlp_fc1_gpu4 -> layer_7_allgather_mlp
	layer_7_mlp_fc1_gpu5 -> layer_7_allgather_mlp
	layer_7_mlp_fc1_gpu6 -> layer_7_allgather_mlp
	layer_7_mlp_fc1_gpu7 -> layer_7_allgather_mlp
	layer_7_allgather_mlp -> layer_7_gelu
	layer_7_gelu -> layer_7_mlp_fc2_gpu7
	layer_7_mlp_fc2_gpu0 -> layer_7_allreduce_mlp
	layer_7_mlp_fc2_gpu1 -> layer_7_allreduce_mlp
	layer_7_mlp_fc2_gpu2 -> layer_7_allreduce_mlp
	layer_7_mlp_fc2_gpu3 -> layer_7_allreduce_mlp
	layer_7_mlp_fc2_gpu4 -> layer_7_allreduce_mlp
	layer_7_mlp_fc2_gpu5 -> layer_7_allreduce_mlp
	layer_7_mlp_fc2_gpu6 -> layer_7_allreduce_mlp
	layer_7_mlp_fc2_gpu7 -> layer_7_allreduce_mlp
	layer_7_allreduce_mlp -> layer_7_residual2
	layer_7_residual1 -> layer_7_residual2
	layer_7_residual2 -> layer_7_ln2
	layer_7_ln2 -> layer_7_output_dist
	layer_7_output_dist -> layer_8_input_dist
	layer_8_input_dist -> layer_8_qkv_gpu8
	layer_8_input_dist -> layer_8_qkv_gpu9
	layer_8_input_dist -> layer_8_qkv_gpu10
	layer_8_input_dist -> layer_8_qkv_gpu11
	layer_8_input_dist -> layer_8_qkv_gpu12
	layer_8_input_dist -> layer_8_qkv_gpu13
	layer_8_input_dist -> layer_8_qkv_gpu14
	layer_8_input_dist -> layer_8_qkv_gpu15
	layer_8_qkv_gpu8 -> layer_8_allgather_qkv
	layer_8_qkv_gpu9 -> layer_8_allgather_qkv
	layer_8_qkv_gpu10 -> layer_8_allgather_qkv
	layer_8_qkv_gpu11 -> layer_8_allgather_qkv
	layer_8_qkv_gpu12 -> layer_8_allgather_qkv
	layer_8_qkv_gpu13 -> layer_8_allgather_qkv
	layer_8_qkv_gpu14 -> layer_8_allgather_qkv
	layer_8_qkv_gpu15 -> layer_8_allgather_qkv
	layer_8_allgather_qkv -> layer_8_attention
	layer_8_attention -> layer_8_attn_out_gpu15
	layer_8_attn_out_gpu8 -> layer_8_allreduce_attn
	layer_8_attn_out_gpu9 -> layer_8_allreduce_attn
	layer_8_attn_out_gpu10 -> layer_8_allreduce_attn
	layer_8_attn_out_gpu11 -> layer_8_allreduce_attn
	layer_8_attn_out_gpu12 -> layer_8_allreduce_attn
	layer_8_attn_out_gpu13 -> layer_8_allreduce_attn
	layer_8_attn_out_gpu14 -> layer_8_allreduce_attn
	layer_8_attn_out_gpu15 -> layer_8_allreduce_attn
	layer_8_allreduce_attn -> layer_8_residual1
	layer_8_input_dist -> layer_8_residual1
	layer_8_residual1 -> layer_8_ln1
	layer_8_ln1 -> layer_8_mlp_fc1_gpu8
	layer_8_ln1 -> layer_8_mlp_fc1_gpu9
	layer_8_ln1 -> layer_8_mlp_fc1_gpu10
	layer_8_ln1 -> layer_8_mlp_fc1_gpu11
	layer_8_ln1 -> layer_8_mlp_fc1_gpu12
	layer_8_ln1 -> layer_8_mlp_fc1_gpu13
	layer_8_ln1 -> layer_8_mlp_fc1_gpu14
	layer_8_ln1 -> layer_8_mlp_fc1_gpu15
	layer_8_mlp_fc1_gpu8 -> layer_8_allgather_mlp
	layer_8_mlp_fc1_gpu9 -> layer_8_allgather_mlp
	layer_8_mlp_fc1_gpu10 -> layer_8_allgather_mlp
	layer_8_mlp_fc1_gpu11 -> layer_8_allgather_mlp
	layer_8_mlp_fc1_gpu12 -> layer_8_allgather_mlp
	layer_8_mlp_fc1_gpu13 -> layer_8_allgather_mlp
	layer_8_mlp_fc1_gpu14 -> layer_8_allgather_mlp
	layer_8_mlp_fc1_gpu15 -> layer_8_allgather_mlp
	layer_8_allgather_mlp -> layer_8_gelu
	layer_8_gelu -> layer_8_mlp_fc2_gpu15
	layer_8_mlp_fc2_gpu8 -> layer_8_allreduce_mlp
	layer_8_mlp_fc2_gpu9 -> layer_8_allreduce_mlp
	layer_8_mlp_fc2_gpu10 -> layer_8_allreduce_mlp
	layer_8_mlp_fc2_gpu11 -> layer_8_allreduce_mlp
	layer_8_mlp_fc2_gpu12 -> layer_8_allreduce_mlp
	layer_8_mlp_fc2_gpu13 -> layer_8_allreduce_mlp
	layer_8_mlp_fc2_gpu14 -> layer_8_allreduce_mlp
	layer_8_mlp_fc2_gpu15 -> layer_8_allreduce_mlp
	layer_8_allreduce_mlp -> layer_8_residual2
	layer_8_residual1 -> layer_8_residual2
	layer_8_residual2 -> layer_8_ln2
	layer_8_ln2 -> layer_8_output_dist
	layer_8_output_dist -> layer_9_input_dist
	layer_9_input_dist -> layer_9_qkv_gpu8
	layer_9_input_dist -> layer_9_qkv_gpu9
	layer_9_input_dist -> layer_9_qkv_gpu10
	layer_9_input_dist -> layer_9_qkv_gpu11
	layer_9_input_dist -> layer_9_qkv_gpu12
	layer_9_input_dist -> layer_9_qkv_gpu13
	layer_9_input_dist -> layer_9_qkv_gpu14
	layer_9_input_dist -> layer_9_qkv_gpu15
	layer_9_qkv_gpu8 -> layer_9_allgather_qkv
	layer_9_qkv_gpu9 -> layer_9_allgather_qkv
	layer_9_qkv_gpu10 -> layer_9_allgather_qkv
	layer_9_qkv_gpu11 -> layer_9_allgather_qkv
	layer_9_qkv_gpu12 -> layer_9_allgather_qkv
	layer_9_qkv_gpu13 -> layer_9_allgather_qkv
	layer_9_qkv_gpu14 -> layer_9_allgather_qkv
	layer_9_qkv_gpu15 -> layer_9_allgather_qkv
	layer_9_allgather_qkv -> layer_9_attention
	layer_9_attention -> layer_9_attn_out_gpu15
	layer_9_attn_out_gpu8 -> layer_9_allreduce_attn
	layer_9_attn_out_gpu9 -> layer_9_allreduce_attn
	layer_9_attn_out_gpu10 -> layer_9_allreduce_attn
	layer_9_attn_out_gpu11 -> layer_9_allreduce_attn
	layer_9_attn_out_gpu12 -> layer_9_allreduce_attn
	layer_9_attn_out_gpu13 -> layer_9_allreduce_attn
	layer_9_attn_out_gpu14 -> layer_9_allreduce_attn
	layer_9_attn_out_gpu15 -> layer_9_allreduce_attn
	layer_9_allreduce_attn -> layer_9_residual1
	layer_9_input_dist -> layer_9_residual1
	layer_9_residual1 -> layer_9_ln1
	layer_9_ln1 -> layer_9_mlp_fc1_gpu8
	layer_9_ln1 -> layer_9_mlp_fc1_gpu9
	layer_9_ln1 -> layer_9_mlp_fc1_gpu10
	layer_9_ln1 -> layer_9_mlp_fc1_gpu11
	layer_9_ln1 -> layer_9_mlp_fc1_gpu12
	layer_9_ln1 -> layer_9_mlp_fc1_gpu13
	layer_9_ln1 -> layer_9_mlp_fc1_gpu14
	layer_9_ln1 -> layer_9_mlp_fc1_gpu15
	layer_9_mlp_fc1_gpu8 -> layer_9_allgather_mlp
	layer_9_mlp_fc1_gpu9 -> layer_9_allgather_mlp
	layer_9_mlp_fc1_gpu10 -> layer_9_allgather_mlp
	layer_9_mlp_fc1_gpu11 -> layer_9_allgather_mlp
	layer_9_mlp_fc1_gpu12 -> layer_9_allgather_mlp
	layer_9_mlp_fc1_gpu13 -> layer_9_allgather_mlp
	layer_9_mlp_fc1_gpu14 -> layer_9_allgather_mlp
	layer_9_mlp_fc1_gpu15 -> layer_9_allgather_mlp
	layer_9_allgather_mlp -> layer_9_gelu
	layer_9_gelu -> layer_9_mlp_fc2_gpu15
	layer_9_mlp_fc2_gpu8 -> layer_9_allreduce_mlp
	layer_9_mlp_fc2_gpu9 -> layer_9_allreduce_mlp
	layer_9_mlp_fc2_gpu10 -> layer_9_allreduce_mlp
	layer_9_mlp_fc2_gpu11 -> layer_9_allreduce_mlp
	layer_9_mlp_fc2_gpu12 -> layer_9_allreduce_mlp
	layer_9_mlp_fc2_gpu13 -> layer_9_allreduce_mlp
	layer_9_mlp_fc2_gpu14 -> layer_9_allreduce_mlp
	layer_9_mlp_fc2_gpu15 -> layer_9_allreduce_mlp
	layer_9_allreduce_mlp -> layer_9_residual2
	layer_9_residual1 -> layer_9_residual2
	layer_9_residual2 -> layer_9_ln2
	layer_9_ln2 -> layer_9_output_dist
	layer_9_output_dist -> layer_10_input_dist
	layer_10_input_dist -> layer_10_qkv_gpu8
	layer_10_input_dist -> layer_10_qkv_gpu9
	layer_10_input_dist -> layer_10_qkv_gpu10
	layer_10_input_dist -> layer_10_qkv_gpu11
	layer_10_input_dist -> layer_10_qkv_gpu12
	layer_10_input_dist -> layer_10_qkv_gpu13
	layer_10_input_dist -> layer_10_qkv_gpu14
	layer_10_input_dist -> layer_10_qkv_gpu15
	layer_10_qkv_gpu8 -> layer_10_allgather_qkv
	layer_10_qkv_gpu9 -> layer_10_allgather_qkv
	layer_10_qkv_gpu10 -> layer_10_allgather_qkv
	layer_10_qkv_gpu11 -> layer_10_allgather_qkv
	layer_10_qkv_gpu12 -> layer_10_allgather_qkv
	layer_10_qkv_gpu13 -> layer_10_allgather_qkv
	layer_10_qkv_gpu14 -> layer_10_allgather_qkv
	layer_10_qkv_gpu15 -> layer_10_allgather_qkv
	layer_10_allgather_qkv -> layer_10_attention
	layer_10_attention -> layer_10_attn_out_gpu15
	layer_10_attn_out_gpu8 -> layer_10_allreduce_attn
	layer_10_attn_out_gpu9 -> layer_10_allreduce_attn
	layer_10_attn_out_gpu10 -> layer_10_allreduce_attn
	layer_10_attn_out_gpu11 -> layer_10_allreduce_attn
	layer_10_attn_out_gpu12 -> layer_10_allreduce_attn
	layer_10_attn_out_gpu13 -> layer_10_allreduce_attn
	layer_10_attn_out_gpu14 -> layer_10_allreduce_attn
	layer_10_attn_out_gpu15 -> layer_10_allreduce_attn
	layer_10_allreduce_attn -> layer_10_residual1
	layer_10_input_dist -> layer_10_residual1
	layer_10_residual1 -> layer_10_ln1
	layer_10_ln1 -> layer_10_mlp_fc1_gpu8
	layer_10_ln1 -> layer_10_mlp_fc1_gpu9
	layer_10_ln1 -> layer_10_mlp_fc1_gpu10
	layer_10_ln1 -> layer_10_mlp_fc1_gpu11
	layer_10_ln1 -> layer_10_mlp_fc1_gpu12
	layer_10_ln1 -> layer_10_mlp_fc1_gpu13
	layer_10_ln1 -> layer_10_mlp_fc1_gpu14
	layer_10_ln1 -> layer_10_mlp_fc1_gpu15
	layer_10_mlp_fc1_gpu8 -> layer_10_allgather_mlp
	layer_10_mlp_fc1_gpu9 -> layer_10_allgather_mlp
	layer_10_mlp_fc1_gpu10 -> layer_10_allgather_mlp
	layer_10_mlp_fc1_gpu11 -> layer_10_allgather_mlp
	layer_10_mlp_fc1_gpu12 -> layer_10_allgather_mlp
	layer_10_mlp_fc1_gpu13 -> layer_10_allgather_mlp
	layer_10_mlp_fc1_gpu14 -> layer_10_allgather_mlp
	layer_10_mlp_fc1_gpu15 -> layer_10_allgather_mlp
	layer_10_allgather_mlp -> layer_10_gelu
	layer_10_gelu -> layer_10_mlp_fc2_gpu15
	layer_10_mlp_fc2_gpu8 -> layer_10_allreduce_mlp
	layer_10_mlp_fc2_gpu9 -> layer_10_allreduce_mlp
	layer_10_mlp_fc2_gpu10 -> layer_10_allreduce_mlp
	layer_10_mlp_fc2_gpu11 -> layer_10_allreduce_mlp
	layer_10_mlp_fc2_gpu12 -> layer_10_allreduce_mlp
	layer_10_mlp_fc2_gpu13 -> layer_10_allreduce_mlp
	layer_10_mlp_fc2_gpu14 -> layer_10_allreduce_mlp
	layer_10_mlp_fc2_gpu15 -> layer_10_allreduce_mlp
	layer_10_allreduce_mlp -> layer_10_residual2
	layer_10_residual1 -> layer_10_residual2
	layer_10_residual2 -> layer_10_ln2
	layer_10_ln2 -> layer_10_output_dist
	layer_10_output_dist -> layer_11_input_dist
	layer_11_input_dist -> layer_11_qkv_gpu8
	layer_11_input_dist -> layer_11_qkv_gpu9
	layer_11_input_dist -> layer_11_qkv_gpu10
	layer_11_input_dist -> layer_11_qkv_gpu11
	layer_11_input_dist -> layer_11_qkv_gpu12
	layer_11_input_dist -> layer_11_qkv_gpu13
	layer_11_input_dist -> layer_11_qkv_gpu14
	layer_11_input_dist -> layer_11_qkv_gpu15
	layer_11_qkv_gpu8 -> layer_11_allgather_qkv
	layer_11_qkv_gpu9 -> layer_11_allgather_qkv
	layer_11_qkv_gpu10 -> layer_11_allgather_qkv
	layer_11_qkv_gpu11 -> layer_11_allgather_qkv
	layer_11_qkv_gpu12 -> layer_11_allgather_qkv
	layer_11_qkv_gpu13 -> layer_11_allgather_qkv
	layer_11_qkv_gpu14 -> layer_11_allgather_qkv
	layer_11_qkv_gpu15 -> layer_11_allgather_qkv
	layer_11_allgather_qkv -> layer_11_attention
	layer_11_attention -> layer_11_attn_out_gpu15
	layer_11_attn_out_gpu8 -> layer_11_allreduce_attn
	layer_11_attn_out_gpu9 -> layer_11_allreduce_attn
	layer_11_attn_out_gpu10 -> layer_11_allreduce_attn
	layer_11_attn_out_gpu11 -> layer_11_allreduce_attn
	layer_11_attn_out_gpu12 -> layer_11_allreduce_attn
	layer_11_attn_out_gpu13 -> layer_11_allreduce_attn
	layer_11_attn_out_gpu14 -> layer_11_allreduce_attn
	layer_11_attn_out_gpu15 -> layer_11_allreduce_attn
	layer_11_allreduce_attn -> layer_11_residual1
	layer_11_input_dist -> layer_11_residual1
	layer_11_residual1 -> layer_11_ln1
	layer_11_ln1 -> layer_11_mlp_fc1_gpu8
	layer_11_ln1 -> layer_11_mlp_fc1_gpu9
	layer_11_ln1 -> layer_11_mlp_fc1_gpu10
	layer_11_ln1 -> layer_11_mlp_fc1_gpu11
	layer_11_ln1 -> layer_11_mlp_fc1_gpu12
	layer_11_ln1 -> layer_11_mlp_fc1_gpu13
	layer_11_ln1 -> layer_11_mlp_fc1_gpu14
	layer_11_ln1 -> layer_11_mlp_fc1_gpu15
	layer_11_mlp_fc1_gpu8 -> layer_11_allgather_mlp
	layer_11_mlp_fc1_gpu9 -> layer_11_allgather_mlp
	layer_11_mlp_fc1_gpu10 -> layer_11_allgather_mlp
	layer_11_mlp_fc1_gpu11 -> layer_11_allgather_mlp
	layer_11_mlp_fc1_gpu12 -> layer_11_allgather_mlp
	layer_11_mlp_fc1_gpu13 -> layer_11_allgather_mlp
	layer_11_mlp_fc1_gpu14 -> layer_11_allgather_mlp
	layer_11_mlp_fc1_gpu15 -> layer_11_allgather_mlp
	layer_11_allgather_mlp -> layer_11_gelu
	layer_11_gelu -> layer_11_mlp_fc2_gpu15
	layer_11_mlp_fc2_gpu8 -> layer_11_allreduce_mlp
	layer_11_mlp_fc2_gpu9 -> layer_11_allreduce_mlp
	layer_11_mlp_fc2_gpu10 -> layer_11_allreduce_mlp
	layer_11_mlp_fc2_gpu11 -> layer_11_allreduce_mlp
	layer_11_mlp_fc2_gpu12 -> layer_11_allreduce_mlp
	layer_11_mlp_fc2_gpu13 -> layer_11_allreduce_mlp
	layer_11_mlp_fc2_gpu14 -> layer_11_allreduce_mlp
	layer_11_mlp_fc2_gpu15 -> layer_11_allreduce_mlp
	layer_11_allreduce_mlp -> layer_11_residual2
	layer_11_residual1 -> layer_11_residual2
	layer_11_residual2 -> layer_11_ln2
	layer_11_ln2 -> layer_11_output_dist
	layer_11_output_dist -> layer_12_input_dist
	layer_12_input_dist -> layer_12_qkv_gpu8
	layer_12_input_dist -> layer_12_qkv_gpu9
	layer_12_input_dist -> layer_12_qkv_gpu10
	layer_12_input_dist -> layer_12_qkv_gpu11
	layer_12_input_dist -> layer_12_qkv_gpu12
	layer_12_input_dist -> layer_12_qkv_gpu13
	layer_12_input_dist -> layer_12_qkv_gpu14
	layer_12_input_dist -> layer_12_qkv_gpu15
	layer_12_qkv_gpu8 -> layer_12_allgather_qkv
	layer_12_qkv_gpu9 -> layer_12_allgather_qkv
	layer_12_qkv_gpu10 -> layer_12_allgather_qkv
	layer_12_qkv_gpu11 -> layer_12_allgather_qkv
	layer_12_qkv_gpu12 -> layer_12_allgather_qkv
	layer_12_qkv_gpu13 -> layer_12_allgather_qkv
	layer_12_qkv_gpu14 -> layer_12_allgather_qkv
	layer_12_qkv_gpu15 -> layer_12_allgather_qkv
	layer_12_allgather_qkv -> layer_12_attention
	layer_12_attention -> layer_12_attn_out_gpu15
	layer_12_attn_out_gpu8 -> layer_12_allreduce_attn
	layer_12_attn_out_gpu9 -> layer_12_allreduce_attn
	layer_12_attn_out_gpu10 -> layer_12_allreduce_attn
	layer_12_attn_out_gpu11 -> layer_12_allreduce_attn
	layer_12_attn_out_gpu12 -> layer_12_allreduce_attn
	layer_12_attn_out_gpu13 -> layer_12_allreduce_attn
	layer_12_attn_out_gpu14 -> layer_12_allreduce_attn
	layer_12_attn_out_gpu15 -> layer_12_allreduce_attn
	layer_12_allreduce_attn -> layer_12_residual1
	layer_12_input_dist -> layer_12_residual1
	layer_12_residual1 -> layer_12_ln1
	layer_12_ln1 -> layer_12_mlp_fc1_gpu8
	layer_12_ln1 -> layer_12_mlp_fc1_gpu9
	layer_12_ln1 -> layer_12_mlp_fc1_gpu10
	layer_12_ln1 -> layer_12_mlp_fc1_gpu11
	layer_12_ln1 -> layer_12_mlp_fc1_gpu12
	layer_12_ln1 -> layer_12_mlp_fc1_gpu13
	layer_12_ln1 -> layer_12_mlp_fc1_gpu14
	layer_12_ln1 -> layer_12_mlp_fc1_gpu15
	layer_12_mlp_fc1_gpu8 -> layer_12_allgather_mlp
	layer_12_mlp_fc1_gpu9 -> layer_12_allgather_mlp
	layer_12_mlp_fc1_gpu10 -> layer_12_allgather_mlp
	layer_12_mlp_fc1_gpu11 -> layer_12_allgather_mlp
	layer_12_mlp_fc1_gpu12 -> layer_12_allgather_mlp
	layer_12_mlp_fc1_gpu13 -> layer_12_allgather_mlp
	layer_12_mlp_fc1_gpu14 -> layer_12_allgather_mlp
	layer_12_mlp_fc1_gpu15 -> layer_12_allgather_mlp
	layer_12_allgather_mlp -> layer_12_gelu
	layer_12_gelu -> layer_12_mlp_fc2_gpu15
	layer_12_mlp_fc2_gpu8 -> layer_12_allreduce_mlp
	layer_12_mlp_fc2_gpu9 -> layer_12_allreduce_mlp
	layer_12_mlp_fc2_gpu10 -> layer_12_allreduce_mlp
	layer_12_mlp_fc2_gpu11 -> layer_12_allreduce_mlp
	layer_12_mlp_fc2_gpu12 -> layer_12_allreduce_mlp
	layer_12_mlp_fc2_gpu13 -> layer_12_allreduce_mlp
	layer_12_mlp_fc2_gpu14 -> layer_12_allreduce_mlp
	layer_12_mlp_fc2_gpu15 -> layer_12_allreduce_mlp
	layer_12_allreduce_mlp -> layer_12_residual2
	layer_12_residual1 -> layer_12_residual2
	layer_12_residual2 -> layer_12_ln2
	layer_12_ln2 -> layer_12_output_dist
	layer_12_output_dist -> layer_13_input_dist
	layer_13_input_dist -> layer_13_qkv_gpu8
	layer_13_input_dist -> layer_13_qkv_gpu9
	layer_13_input_dist -> layer_13_qkv_gpu10
	layer_13_input_dist -> layer_13_qkv_gpu11
	layer_13_input_dist -> layer_13_qkv_gpu12
	layer_13_input_dist -> layer_13_qkv_gpu13
	layer_13_input_dist -> layer_13_qkv_gpu14
	layer_13_input_dist -> layer_13_qkv_gpu15
	layer_13_qkv_gpu8 -> layer_13_allgather_qkv
	layer_13_qkv_gpu9 -> layer_13_allgather_qkv
	layer_13_qkv_gpu10 -> layer_13_allgather_qkv
	layer_13_qkv_gpu11 -> layer_13_allgather_qkv
	layer_13_qkv_gpu12 -> layer_13_allgather_qkv
	layer_13_qkv_gpu13 -> layer_13_allgather_qkv
	layer_13_qkv_gpu14 -> layer_13_allgather_qkv
	layer_13_qkv_gpu15 -> layer_13_allgather_qkv
	layer_13_allgather_qkv -> layer_13_attention
	layer_13_attention -> layer_13_attn_out_gpu15
	layer_13_attn_out_gpu8 -> layer_13_allreduce_attn
	layer_13_attn_out_gpu9 -> layer_13_allreduce_attn
	layer_13_attn_out_gpu10 -> layer_13_allreduce_attn
	layer_13_attn_out_gpu11 -> layer_13_allreduce_attn
	layer_13_attn_out_gpu12 -> layer_13_allreduce_attn
	layer_13_attn_out_gpu13 -> layer_13_allreduce_attn
	layer_13_attn_out_gpu14 -> layer_13_allreduce_attn
	layer_13_attn_out_gpu15 -> layer_13_allreduce_attn
	layer_13_allreduce_attn -> layer_13_residual1
	layer_13_input_dist -> layer_13_residual1
	layer_13_residual1 -> layer_13_ln1
	layer_13_ln1 -> layer_13_mlp_fc1_gpu8
	layer_13_ln1 -> layer_13_mlp_fc1_gpu9
	layer_13_ln1 -> layer_13_mlp_fc1_gpu10
	layer_13_ln1 -> layer_13_mlp_fc1_gpu11
	layer_13_ln1 -> layer_13_mlp_fc1_gpu12
	layer_13_ln1 -> layer_13_mlp_fc1_gpu13
	layer_13_ln1 -> layer_13_mlp_fc1_gpu14
	layer_13_ln1 -> layer_13_mlp_fc1_gpu15
	layer_13_mlp_fc1_gpu8 -> layer_13_allgather_mlp
	layer_13_mlp_fc1_gpu9 -> layer_13_allgather_mlp
	layer_13_mlp_fc1_gpu10 -> layer_13_allgather_mlp
	layer_13_mlp_fc1_gpu11 -> layer_13_allgather_mlp
	layer_13_mlp_fc1_gpu12 -> layer_13_allgather_mlp
	layer_13_mlp_fc1_gpu13 -> layer_13_allgather_mlp
	layer_13_mlp_fc1_gpu14 -> layer_13_allgather_mlp
	layer_13_mlp_fc1_gpu15 -> layer_13_allgather_mlp
	layer_13_allgather_mlp -> layer_13_gelu
	layer_13_gelu -> layer_13_mlp_fc2_gpu15
	layer_13_mlp_fc2_gpu8 -> layer_13_allreduce_mlp
	layer_13_mlp_fc2_gpu9 -> layer_13_allreduce_mlp
	layer_13_mlp_fc2_gpu10 -> layer_13_allreduce_mlp
	layer_13_mlp_fc2_gpu11 -> layer_13_allreduce_mlp
	layer_13_mlp_fc2_gpu12 -> layer_13_allreduce_mlp
	layer_13_mlp_fc2_gpu13 -> layer_13_allreduce_mlp
	layer_13_mlp_fc2_gpu14 -> layer_13_allreduce_mlp
	layer_13_mlp_fc2_gpu15 -> layer_13_allreduce_mlp
	layer_13_allreduce_mlp -> layer_13_residual2
	layer_13_residual1 -> layer_13_residual2
	layer_13_residual2 -> layer_13_ln2
	layer_13_ln2 -> layer_13_output_dist
	layer_13_output_dist -> layer_14_input_dist
	layer_14_input_dist -> layer_14_qkv_gpu8
	layer_14_input_dist -> layer_14_qkv_gpu9
	layer_14_input_dist -> layer_14_qkv_gpu10
	layer_14_input_dist -> layer_14_qkv_gpu11
	layer_14_input_dist -> layer_14_qkv_gpu12
	layer_14_input_dist -> layer_14_qkv_gpu13
	layer_14_input_dist -> layer_14_qkv_gpu14
	layer_14_input_dist -> layer_14_qkv_gpu15
	layer_14_qkv_gpu8 -> layer_14_allgather_qkv
	layer_14_qkv_gpu9 -> layer_14_allgather_qkv
	layer_14_qkv_gpu10 -> layer_14_allgather_qkv
	layer_14_qkv_gpu11 -> layer_14_allgather_qkv
	layer_14_qkv_gpu12 -> layer_14_allgather_qkv
	layer_14_qkv_gpu13 -> layer_14_allgather_qkv
	layer_14_qkv_gpu14 -> layer_14_allgather_qkv
	layer_14_qkv_gpu15 -> layer_14_allgather_qkv
	layer_14_allgather_qkv -> layer_14_attention
	layer_14_attention -> layer_14_attn_out_gpu15
	layer_14_attn_out_gpu8 -> layer_14_allreduce_attn
	layer_14_attn_out_gpu9 -> layer_14_allreduce_attn
	layer_14_attn_out_gpu10 -> layer_14_allreduce_attn
	layer_14_attn_out_gpu11 -> layer_14_allreduce_attn
	layer_14_attn_out_gpu12 -> layer_14_allreduce_attn
	layer_14_attn_out_gpu13 -> layer_14_allreduce_attn
	layer_14_attn_out_gpu14 -> layer_14_allreduce_attn
	layer_14_attn_out_gpu15 -> layer_14_allreduce_attn
	layer_14_allreduce_attn -> layer_14_residual1
	layer_14_input_dist -> layer_14_residual1
	layer_14_residual1 -> layer_14_ln1
	layer_14_ln1 -> layer_14_mlp_fc1_gpu8
	layer_14_ln1 -> layer_14_mlp_fc1_gpu9
	layer_14_ln1 -> layer_14_mlp_fc1_gpu10
	layer_14_ln1 -> layer_14_mlp_fc1_gpu11
	layer_14_ln1 -> layer_14_mlp_fc1_gpu12
	layer_14_ln1 -> layer_14_mlp_fc1_gpu13
	layer_14_ln1 -> layer_14_mlp_fc1_gpu14
	layer_14_ln1 -> layer_14_mlp_fc1_gpu15
	layer_14_mlp_fc1_gpu8 -> layer_14_allgather_mlp
	layer_14_mlp_fc1_gpu9 -> layer_14_allgather_mlp
	layer_14_mlp_fc1_gpu10 -> layer_14_allgather_mlp
	layer_14_mlp_fc1_gpu11 -> layer_14_allgather_mlp
	layer_14_mlp_fc1_gpu12 -> layer_14_allgather_mlp
	layer_14_mlp_fc1_gpu13 -> layer_14_allgather_mlp
	layer_14_mlp_fc1_gpu14 -> layer_14_allgather_mlp
	layer_14_mlp_fc1_gpu15 -> layer_14_allgather_mlp
	layer_14_allgather_mlp -> layer_14_gelu
	layer_14_gelu -> layer_14_mlp_fc2_gpu15
	layer_14_mlp_fc2_gpu8 -> layer_14_allreduce_mlp
	layer_14_mlp_fc2_gpu9 -> layer_14_allreduce_mlp
	layer_14_mlp_fc2_gpu10 -> layer_14_allreduce_mlp
	layer_14_mlp_fc2_gpu11 -> layer_14_allreduce_mlp
	layer_14_mlp_fc2_gpu12 -> layer_14_allreduce_mlp
	layer_14_mlp_fc2_gpu13 -> layer_14_allreduce_mlp
	layer_14_mlp_fc2_gpu14 -> layer_14_allreduce_mlp
	layer_14_mlp_fc2_gpu15 -> layer_14_allreduce_mlp
	layer_14_allreduce_mlp -> layer_14_residual2
	layer_14_residual1 -> layer_14_residual2
	layer_14_residual2 -> layer_14_ln2
	layer_14_ln2 -> layer_14_output_dist
	layer_14_output_dist -> layer_15_input_dist
	layer_15_input_dist -> layer_15_qkv_gpu8
	layer_15_input_dist -> layer_15_qkv_gpu9
	layer_15_input_dist -> layer_15_qkv_gpu10
	layer_15_input_dist -> layer_15_qkv_gpu11
	layer_15_input_dist -> layer_15_qkv_gpu12
	layer_15_input_dist -> layer_15_qkv_gpu13
	layer_15_input_dist -> layer_15_qkv_gpu14
	layer_15_input_dist -> layer_15_qkv_gpu15
	layer_15_qkv_gpu8 -> layer_15_allgather_qkv
	layer_15_qkv_gpu9 -> layer_15_allgather_qkv
	layer_15_qkv_gpu10 -> layer_15_allgather_qkv
	layer_15_qkv_gpu11 -> layer_15_allgather_qkv
	layer_15_qkv_gpu12 -> layer_15_allgather_qkv
	layer_15_qkv_gpu13 -> layer_15_allgather_qkv
	layer_15_qkv_gpu14 -> layer_15_allgather_qkv
	layer_15_qkv_gpu15 -> layer_15_allgather_qkv
	layer_15_allgather_qkv -> layer_15_attention
	layer_15_attention -> layer_15_attn_out_gpu15
	layer_15_attn_out_gpu8 -> layer_15_allreduce_attn
	layer_15_attn_out_gpu9 -> layer_15_allreduce_attn
	layer_15_attn_out_gpu10 -> layer_15_allreduce_attn
	layer_15_attn_out_gpu11 -> layer_15_allreduce_attn
	layer_15_attn_out_gpu12 -> layer_15_allreduce_attn
	layer_15_attn_out_gpu13 -> layer_15_allreduce_attn
	layer_15_attn_out_gpu14 -> layer_15_allreduce_attn
	layer_15_attn_out_gpu15 -> layer_15_allreduce_attn
	layer_15_allreduce_attn -> layer_15_residual1
	layer_15_input_dist -> layer_15_residual1
	layer_15_residual1 -> layer_15_ln1
	layer_15_ln1 -> layer_15_mlp_fc1_gpu8
	layer_15_ln1 -> layer_15_mlp_fc1_gpu9
	layer_15_ln1 -> layer_15_mlp_fc1_gpu10
	layer_15_ln1 -> layer_15_mlp_fc1_gpu11
	layer_15_ln1 -> layer_15_mlp_fc1_gpu12
	layer_15_ln1 -> layer_15_mlp_fc1_gpu13
	layer_15_ln1 -> layer_15_mlp_fc1_gpu14
	layer_15_ln1 -> layer_15_mlp_fc1_gpu15
	layer_15_mlp_fc1_gpu8 -> layer_15_allgather_mlp
	layer_15_mlp_fc1_gpu9 -> layer_15_allgather_mlp
	layer_15_mlp_fc1_gpu10 -> layer_15_allgather_mlp
	layer_15_mlp_fc1_gpu11 -> layer_15_allgather_mlp
	layer_15_mlp_fc1_gpu12 -> layer_15_allgather_mlp
	layer_15_mlp_fc1_gpu13 -> layer_15_allgather_mlp
	layer_15_mlp_fc1_gpu14 -> layer_15_allgather_mlp
	layer_15_mlp_fc1_gpu15 -> layer_15_allgather_mlp
	layer_15_allgather_mlp -> layer_15_gelu
	layer_15_gelu -> layer_15_mlp_fc2_gpu15
	layer_15_mlp_fc2_gpu8 -> layer_15_allreduce_mlp
	layer_15_mlp_fc2_gpu9 -> layer_15_allreduce_mlp
	layer_15_mlp_fc2_gpu10 -> layer_15_allreduce_mlp
	layer_15_mlp_fc2_gpu11 -> layer_15_allreduce_mlp
	layer_15_mlp_fc2_gpu12 -> layer_15_allreduce_mlp
	layer_15_mlp_fc2_gpu13 -> layer_15_allreduce_mlp
	layer_15_mlp_fc2_gpu14 -> layer_15_allreduce_mlp
	layer_15_mlp_fc2_gpu15 -> layer_15_allreduce_mlp
	layer_15_allreduce_mlp -> layer_15_residual2
	layer_15_residual1 -> layer_15_residual2
	layer_15_residual2 -> layer_15_ln2
	layer_15_ln2 -> output
}
