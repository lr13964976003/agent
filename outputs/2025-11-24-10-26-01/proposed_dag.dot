digraph proposed_layer_wise {
	graph [bb="0,0,951.74,34721",
		nodesep=0.5,
		rankdir=TB,
		ranksep=1.0,
		splines=ortho
	];
	node [fillcolor=lightblue,
		label="\N",
		shape=ellipse,
		style=filled
	];
	subgraph cluster_layer0_gpu0 {
		graph [bb="156.87,32455,670.87,34589",
			color=green,
			fillcolor=lightyellow,
			label="Layer 0 on GPU 0\nCache-capacity: 11.8GB",
			lheight=0.42,
			lp="413.87,34570",
			lwidth=2.36,
			style="rounded,dashed"
		];
		layer0_input	[fillcolor=lightyellow,
			height=1.8889,
			label="Input Transfer\nFrom: Input\nSize: 524MB\nGPU: 0",
			pos="475.87,34475",
			shape=parallelogram,
			width=3.4558];
		lay0_qkv_proj	[fillcolor=lightcoral,
			height=0.94444,
			label="QKV Projection\nInput: [128,10000,4096]\nOutput: [128,10000,32,128]\nGPU: 0",
			pos="421.87,34301",
			shape=rectangle,
			width=3.0139];
		layer0_input -> lay0_qkv_proj	[pos="e,440.91,34335 440.91,34407 440.91,34407 440.91,34345 440.91,34345"];
		lay0_res1	[fillcolor=lightgray,
			height=1.3356,
			label="Residual Add 1\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 0",
			pos="430.87,33727",
			width=6.4425];
		layer0_input -> lay0_res1	[pos="e,582.32,33764 582.32,34475 582.32,34475 582.32,33774 582.32,33774"];
		lay0_attn_score	[fillcolor=lightpink,
			height=0.94444,
			label="Scaled Dot-Product Attention\nInput: [128,10000,32,128], [128,10000,32,128]\nOutput: [128,10000,32,128]\nGPU: 0",
			pos="386.87,34161",
			shape=rectangle,
			width=4.9306];
		lay0_qkv_proj -> lay0_attn_score	[pos="e,421.87,34196 421.87,34267 421.87,34267 421.87,34206 421.87,34206"];
		lay0_attn_concat	[fillcolor=lightpink,
			height=0.94444,
			label="Concat Heads\nInput: [128,10000,32,128]\nOutput: [128,10000,4096]\nGPU: 0",
			pos="403.87,34021",
			shape=rectangle,
			width=2.8472];
		lay0_attn_score -> lay0_attn_concat	[pos="e,403.87,34056 403.87,34127 403.87,34127 403.87,34066 403.87,34066"];
		lay0_attn_out	[fillcolor=lightcoral,
			height=0.94444,
			label="Attention Output Projection\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 0",
			pos="421.87,33881",
			shape=rectangle,
			width=2.9861];
		lay0_attn_concat -> lay0_attn_out	[pos="e,410.37,33916 410.37,33987 410.37,33987 410.37,33926 410.37,33926"];
		lay0_attn_out -> lay0_res1	[pos="e,421.87,33775 421.87,33847 421.87,33847 421.87,33785 421.87,33785"];
		lay0_ln1	[fillcolor=lightsteelblue,
			height=0.94444,
			label="LayerNorm 1\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 0",
			pos="461.87,33573",
			shape=rectangle,
			width=2.8194];
		lay0_res1 -> lay0_ln1	[pos="e,461.87,33607 461.87,33679 461.87,33679 461.87,33617 461.87,33617"];
		lay0_mlp_gate	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Gate Projection\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nGPU: 0",
			pos="297.87,33433",
			shape=rectangle,
			width=2.9444];
		lay0_ln1 -> lay0_mlp_gate	[pos="e,382.12,33468 382.12,33539 382.12,33539 382.12,33478 382.12,33478"];
		lay0_mlp_up	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Up Projection\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nGPU: 0",
			pos="518.87,33293",
			shape=rectangle,
			width=2.9444];
		lay0_ln1 -> lay0_mlp_up	[pos="e,488.12,33327 488.12,33539 488.12,33539 488.12,33337 488.12,33337"];
		lay0_res2	[fillcolor=lightgray,
			height=1.3356,
			label="Residual Add 2\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 0",
			pos="430.87,32859",
			width=6.4425];
		lay0_ln1 -> lay0_res2	[pos="e,643.84,32878 563.49,33573 605.17,33573 643.84,33573 643.84,33573 643.84,33573 643.84,32888 643.84,32888"];
		lay0_mlp_act	[height=0.94444,
			label="GELU Activation\nInput: [128,10000,16384]\nOutput: [128,10000,16384]\nGPU: 0",
			pos="270.87,33293",
			shape=rectangle,
			width=2.9444];
		lay0_mlp_gate -> lay0_mlp_act	[pos="e,284.37,33328 284.37,33399 284.37,33399 284.37,33338 284.37,33338"];
		lay0_mlp_mul	[height=0.94444,
			label="Element-wise Mul\nInput: [128,10000,16384], [128,10000,16384]\nOutput: [128,10000,16384]\nGPU: 0",
			pos="430.87,33153",
			shape=rectangle,
			width=4.8056];
		lay0_mlp_up -> lay0_mlp_mul	[pos="e,508.37,33188 508.37,33259 508.37,33259 508.37,33198 508.37,33198"];
		lay0_mlp_act -> lay0_mlp_mul	[pos="e,317.37,33188 317.37,33259 317.37,33259 317.37,33198 317.37,33198"];
		lay0_mlp_down	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Down Projection\nInput: [128,10000,16384]\nOutput: [128,10000,4096]\nGPU: 0",
			pos="430.87,33013",
			shape=rectangle,
			width=2.8194];
		lay0_mlp_mul -> lay0_mlp_down	[pos="e,430.87,33048 430.87,33119 430.87,33119 430.87,33058 430.87,33058"];
		lay0_mlp_down -> lay0_res2	[pos="e,430.87,32907 430.87,32979 430.87,32979 430.87,32917 430.87,32917"];
		lay0_ln2	[fillcolor=lightsteelblue,
			height=0.94444,
			label="LayerNorm 2\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 0",
			pos="430.87,32705",
			shape=rectangle,
			width=2.8194];
		lay0_res2 -> lay0_ln2	[pos="e,430.87,32739 430.87,32811 430.87,32811 430.87,32749 430.87,32749"];
		layer0_output	[fillcolor=lightyellow,
			height=1.8889,
			label="Output Transfer\nTo: GPU 1\nSize: 524MB\nGPU: 0",
			pos="430.87,32531",
			shape=parallelogram,
			width=3.8014];
		lay0_ln2 -> layer0_output	[pos="e,430.87,32599 430.87,32671 430.87,32671 430.87,32609 430.87,32609"];
	}
	subgraph cluster_layer1_gpu1 {
		graph [bb="147.87,30303,661.87,32437",
			color=green,
			fillcolor=lightyellow,
			label="Layer 1 on GPU 1\nCache-capacity: 11.8GB",
			lheight=0.42,
			lp="404.87,32418",
			lwidth=2.36,
			style="rounded,dashed"
		];
		layer1_input	[fillcolor=lightyellow,
			height=1.8889,
			label="Input Transfer\nFrom: GPU 0\nSize: 524MB\nGPU: 1",
			pos="430.87,32323",
			shape=parallelogram,
			width=3.4558];
		lay1_qkv_proj	[fillcolor=lightcoral,
			height=0.94444,
			label="QKV Projection\nInput: [128,10000,4096]\nOutput: [128,10000,32,128]\nGPU: 1",
			pos="399.87,32149",
			shape=rectangle,
			width=3.0139];
		layer1_input -> lay1_qkv_proj	[pos="e,407.41,32183 407.41,32255 407.41,32255 407.41,32193 407.41,32193"];
		lay1_res1	[fillcolor=lightgray,
			height=1.3356,
			label="Residual Add 1\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 1",
			pos="421.87,31575",
			width=6.4425];
		layer1_input -> lay1_res1	[pos="e,548.82,31615 548.82,32323 548.82,32323 548.82,31625 548.82,31625"];
		lay1_attn_score	[fillcolor=lightpink,
			height=0.94444,
			label="Scaled Dot-Product Attention\nInput: [128,10000,32,128], [128,10000,32,128]\nOutput: [128,10000,32,128]\nGPU: 1",
			pos="364.87,32009",
			shape=rectangle,
			width=4.9306];
		lay1_qkv_proj -> lay1_attn_score	[pos="e,399.87,32043 399.87,32115 399.87,32115 399.87,32053 399.87,32053"];
		lay1_attn_concat	[fillcolor=lightpink,
			height=0.94444,
			label="Concat Heads\nInput: [128,10000,32,128]\nOutput: [128,10000,4096]\nGPU: 1",
			pos="388.87,31869",
			shape=rectangle,
			width=2.8472];
		lay1_attn_score -> lay1_attn_concat	[pos="e,388.87,31903 388.87,31975 388.87,31975 388.87,31913 388.87,31913"];
		lay1_attn_out	[fillcolor=lightcoral,
			height=0.94444,
			label="Attention Output Projection\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 1",
			pos="412.87,31729",
			shape=rectangle,
			width=2.9861];
		lay1_attn_concat -> lay1_attn_out	[pos="e,398.37,31763 398.37,31835 398.37,31835 398.37,31773 398.37,31773"];
		lay1_attn_out -> lay1_res1	[pos="e,412.87,31623 412.87,31695 412.87,31695 412.87,31633 412.87,31633"];
		lay1_ln1	[fillcolor=lightsteelblue,
			height=0.94444,
			label="LayerNorm 1\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 1",
			pos="452.87,31421",
			shape=rectangle,
			width=2.8194];
		lay1_res1 -> lay1_ln1	[pos="e,452.87,31455 452.87,31527 452.87,31527 452.87,31465 452.87,31465"];
		lay1_mlp_gate	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Gate Projection\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nGPU: 1",
			pos="288.87,31281",
			shape=rectangle,
			width=2.9444];
		lay1_ln1 -> lay1_mlp_gate	[pos="e,373.12,31315 373.12,31387 373.12,31387 373.12,31325 373.12,31325"];
		lay1_mlp_up	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Up Projection\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nGPU: 1",
			pos="509.87,31141",
			shape=rectangle,
			width=2.9444];
		lay1_ln1 -> lay1_mlp_up	[pos="e,479.12,31175 479.12,31387 479.12,31387 479.12,31185 479.12,31185"];
		lay1_res2	[fillcolor=lightgray,
			height=1.3356,
			label="Residual Add 2\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 1",
			pos="421.87,30707",
			width=6.4425];
		lay1_ln1 -> lay1_res2	[pos="e,634.84,30726 554.49,31420 596.17,31420 634.84,31420 634.84,31420 634.84,31420 634.84,30736 634.84,30736"];
		lay1_mlp_act	[height=0.94444,
			label="GELU Activation\nInput: [128,10000,16384]\nOutput: [128,10000,16384]\nGPU: 1",
			pos="261.87,31141",
			shape=rectangle,
			width=2.9444];
		lay1_mlp_gate -> lay1_mlp_act	[pos="e,275.37,31175 275.37,31247 275.37,31247 275.37,31185 275.37,31185"];
		lay1_mlp_mul	[height=0.94444,
			label="Element-wise Mul\nInput: [128,10000,16384], [128,10000,16384]\nOutput: [128,10000,16384]\nGPU: 1",
			pos="421.87,31001",
			shape=rectangle,
			width=4.8056];
		lay1_mlp_up -> lay1_mlp_mul	[pos="e,499.37,31035 499.37,31107 499.37,31107 499.37,31045 499.37,31045"];
		lay1_mlp_act -> lay1_mlp_mul	[pos="e,308.37,31035 308.37,31107 308.37,31107 308.37,31045 308.37,31045"];
		lay1_mlp_down	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Down Projection\nInput: [128,10000,16384]\nOutput: [128,10000,4096]\nGPU: 1",
			pos="421.87,30861",
			shape=rectangle,
			width=2.8194];
		lay1_mlp_mul -> lay1_mlp_down	[pos="e,421.87,30895 421.87,30967 421.87,30967 421.87,30905 421.87,30905"];
		lay1_mlp_down -> lay1_res2	[pos="e,421.87,30755 421.87,30827 421.87,30827 421.87,30765 421.87,30765"];
		lay1_ln2	[fillcolor=lightsteelblue,
			height=0.94444,
			label="LayerNorm 2\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 1",
			pos="421.87,30553",
			shape=rectangle,
			width=2.8194];
		lay1_res2 -> lay1_ln2	[pos="e,421.87,30587 421.87,30658 421.87,30658 421.87,30597 421.87,30597"];
		layer1_output	[fillcolor=lightyellow,
			height=1.8889,
			label="Output Transfer\nTo: GPU 2\nSize: 524MB\nGPU: 1",
			pos="421.87,30379",
			shape=parallelogram,
			width=3.8014];
		lay1_ln2 -> layer1_output	[pos="e,421.87,30447 421.87,30518 421.87,30518 421.87,30457 421.87,30457"];
	}
	subgraph cluster_layer2_gpu2 {
		graph [bb="147.87,28150,661.87,30285",
			color=green,
			fillcolor=lightyellow,
			label="Layer 2 on GPU 2\nCache-capacity: 11.8GB",
			lheight=0.42,
			lp="404.87,30266",
			lwidth=2.36,
			style="rounded,dashed"
		];
		layer2_input	[fillcolor=lightyellow,
			height=1.8889,
			label="Input Transfer\nFrom: GPU 1\nSize: 524MB\nGPU: 2",
			pos="421.87,30171",
			shape=parallelogram,
			width=3.4558];
		lay2_qkv_proj	[fillcolor=lightcoral,
			height=0.94444,
			label="QKV Projection\nInput: [128,10000,4096]\nOutput: [128,10000,32,128]\nGPU: 2",
			pos="386.87,29997",
			shape=rectangle,
			width=3.0139];
		layer2_input -> lay2_qkv_proj	[pos="e,396.41,30031 396.41,30102 396.41,30102 396.41,30041 396.41,30041"];
		lay2_res1	[fillcolor=lightgray,
			height=1.3356,
			label="Residual Add 1\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 2",
			pos="421.87,29423",
			width=6.4425];
		layer2_input -> lay2_res1	[pos="e,537.82,29464 537.82,30171 537.82,30171 537.82,29474 537.82,29474"];
		lay2_attn_score	[fillcolor=lightpink,
			height=0.94444,
			label="Scaled Dot-Product Attention\nInput: [128,10000,32,128], [128,10000,32,128]\nOutput: [128,10000,32,128]\nGPU: 2",
			pos="351.87,29857",
			shape=rectangle,
			width=4.9306];
		lay2_qkv_proj -> lay2_attn_score	[pos="e,386.87,29891 386.87,29962 386.87,29962 386.87,29901 386.87,29901"];
		lay2_attn_concat	[fillcolor=lightpink,
			height=0.94444,
			label="Concat Heads\nInput: [128,10000,32,128]\nOutput: [128,10000,4096]\nGPU: 2",
			pos="369.87,29717",
			shape=rectangle,
			width=2.8472];
		lay2_attn_score -> lay2_attn_concat	[pos="e,369.87,29751 369.87,29822 369.87,29822 369.87,29761 369.87,29761"];
		lay2_attn_out	[fillcolor=lightcoral,
			height=0.94444,
			label="Attention Output Projection\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 2",
			pos="404.87,29577",
			shape=rectangle,
			width=2.9861];
		lay2_attn_concat -> lay2_attn_out	[pos="e,384.87,29611 384.87,29682 384.87,29682 384.87,29621 384.87,29621"];
		lay2_attn_out -> lay2_res1	[pos="e,404.87,29471 404.87,29542 404.87,29542 404.87,29481 404.87,29481"];
		lay2_ln1	[fillcolor=lightsteelblue,
			height=0.94444,
			label="LayerNorm 1\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 2",
			pos="452.87,29268",
			shape=rectangle,
			width=2.8194];
		lay2_res1 -> lay2_ln1	[pos="e,452.87,29303 452.87,29375 452.87,29375 452.87,29313 452.87,29313"];
		lay2_mlp_gate	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Gate Projection\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nGPU: 2",
			pos="288.87,29128",
			shape=rectangle,
			width=2.9444];
		lay2_ln1 -> lay2_mlp_gate	[pos="e,373.12,29163 373.12,29234 373.12,29234 373.12,29173 373.12,29173"];
		lay2_mlp_up	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Up Projection\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nGPU: 2",
			pos="509.87,28988",
			shape=rectangle,
			width=2.9444];
		lay2_ln1 -> lay2_mlp_up	[pos="e,479.12,29023 479.12,29234 479.12,29234 479.12,29033 479.12,29033"];
		lay2_res2	[fillcolor=lightgray,
			height=1.3356,
			label="Residual Add 2\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 2",
			pos="421.87,28554",
			width=6.4425];
		lay2_ln1 -> lay2_res2	[pos="e,634.84,28573 554.49,29268 596.17,29268 634.84,29268 634.84,29268 634.84,29268 634.84,28583 634.84,28583"];
		lay2_mlp_act	[height=0.94444,
			label="GELU Activation\nInput: [128,10000,16384]\nOutput: [128,10000,16384]\nGPU: 2",
			pos="261.87,28988",
			shape=rectangle,
			width=2.9444];
		lay2_mlp_gate -> lay2_mlp_act	[pos="e,275.37,29023 275.37,29094 275.37,29094 275.37,29033 275.37,29033"];
		lay2_mlp_mul	[height=0.94444,
			label="Element-wise Mul\nInput: [128,10000,16384], [128,10000,16384]\nOutput: [128,10000,16384]\nGPU: 2",
			pos="421.87,28848",
			shape=rectangle,
			width=4.8056];
		lay2_mlp_up -> lay2_mlp_mul	[pos="e,499.37,28883 499.37,28954 499.37,28954 499.37,28893 499.37,28893"];
		lay2_mlp_act -> lay2_mlp_mul	[pos="e,308.37,28883 308.37,28954 308.37,28954 308.37,28893 308.37,28893"];
		lay2_mlp_down	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Down Projection\nInput: [128,10000,16384]\nOutput: [128,10000,4096]\nGPU: 2",
			pos="421.87,28708",
			shape=rectangle,
			width=2.8194];
		lay2_mlp_mul -> lay2_mlp_down	[pos="e,421.87,28743 421.87,28814 421.87,28814 421.87,28753 421.87,28753"];
		lay2_mlp_down -> lay2_res2	[pos="e,421.87,28603 421.87,28674 421.87,28674 421.87,28613 421.87,28613"];
		lay2_ln2	[fillcolor=lightsteelblue,
			height=0.94444,
			label="LayerNorm 2\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 2",
			pos="421.87,28400",
			shape=rectangle,
			width=2.8194];
		lay2_res2 -> lay2_ln2	[pos="e,421.87,28435 421.87,28506 421.87,28506 421.87,28445 421.87,28445"];
		layer2_output	[fillcolor=lightyellow,
			height=1.8889,
			label="Output Transfer\nTo: GPU 3\nSize: 524MB\nGPU: 2",
			pos="421.87,28226",
			shape=parallelogram,
			width=3.8014];
		lay2_ln2 -> layer2_output	[pos="e,421.87,28294 421.87,28366 421.87,28366 421.87,28304 421.87,28304"];
	}
	subgraph cluster_layer3_gpu3 {
		graph [bb="147.87,25998,661.87,28132",
			color=green,
			fillcolor=lightyellow,
			label="Layer 3 on GPU 3\nCache-capacity: 11.8GB",
			lheight=0.42,
			lp="404.87,28113",
			lwidth=2.36,
			style="rounded,dashed"
		];
		layer3_input	[fillcolor=lightyellow,
			height=1.8889,
			label="Input Transfer\nFrom: GPU 2\nSize: 524MB\nGPU: 3",
			pos="421.87,28018",
			shape=parallelogram,
			width=3.4558];
		lay3_qkv_proj	[fillcolor=lightcoral,
			height=0.94444,
			label="QKV Projection\nInput: [128,10000,4096]\nOutput: [128,10000,32,128]\nGPU: 3",
			pos="399.87,27844",
			shape=rectangle,
			width=3.0139];
		layer3_input -> lay3_qkv_proj	[pos="e,402.91,27878 402.91,27950 402.91,27950 402.91,27888 402.91,27888"];
		lay3_res1	[fillcolor=lightgray,
			height=1.3356,
			label="Residual Add 1\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 3",
			pos="421.87,27270",
			width=6.4425];
		layer3_input -> lay3_res1	[pos="e,552.5,27310 520.88,28018 539.1,28018 552.5,28018 552.5,28018 552.5,28018 552.5,27320 552.5,27320"];
		lay3_attn_score	[fillcolor=lightpink,
			height=0.94444,
			label="Scaled Dot-Product Attention\nInput: [128,10000,32,128], [128,10000,32,128]\nOutput: [128,10000,32,128]\nGPU: 3",
			pos="364.87,27704",
			shape=rectangle,
			width=4.9306];
		lay3_qkv_proj -> lay3_attn_score	[pos="e,399.87,27739 399.87,27810 399.87,27810 399.87,27749 399.87,27749"];
		lay3_attn_concat	[fillcolor=lightpink,
			height=0.94444,
			label="Concat Heads\nInput: [128,10000,32,128]\nOutput: [128,10000,4096]\nGPU: 3",
			pos="388.87,27564",
			shape=rectangle,
			width=2.8472];
		lay3_attn_score -> lay3_attn_concat	[pos="e,388.87,27599 388.87,27670 388.87,27670 388.87,27609 388.87,27609"];
		lay3_attn_out	[fillcolor=lightcoral,
			height=0.94444,
			label="Attention Output Projection\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 3",
			pos="412.87,27424",
			shape=rectangle,
			width=2.9861];
		lay3_attn_concat -> lay3_attn_out	[pos="e,398.37,27459 398.37,27530 398.37,27530 398.37,27469 398.37,27469"];
		lay3_attn_out -> lay3_res1	[pos="e,412.87,27318 412.87,27390 412.87,27390 412.87,27328 412.87,27328"];
		lay3_ln1	[fillcolor=lightsteelblue,
			height=0.94444,
			label="LayerNorm 1\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 3",
			pos="452.87,27116",
			shape=rectangle,
			width=2.8194];
		lay3_res1 -> lay3_ln1	[pos="e,452.87,27150 452.87,27222 452.87,27222 452.87,27160 452.87,27160"];
		lay3_mlp_gate	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Gate Projection\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nGPU: 3",
			pos="288.87,26976",
			shape=rectangle,
			width=2.9444];
		lay3_ln1 -> lay3_mlp_gate	[pos="e,373.12,27011 373.12,27082 373.12,27082 373.12,27021 373.12,27021"];
		lay3_mlp_up	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Up Projection\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nGPU: 3",
			pos="509.87,26836",
			shape=rectangle,
			width=2.9444];
		lay3_ln1 -> lay3_mlp_up	[pos="e,479.12,26870 479.12,27082 479.12,27082 479.12,26880 479.12,26880"];
		lay3_res2	[fillcolor=lightgray,
			height=1.3356,
			label="Residual Add 2\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 3",
			pos="421.87,26402",
			width=6.4425];
		lay3_ln1 -> lay3_res2	[pos="e,634.84,26421 554.49,27116 596.17,27116 634.84,27116 634.84,27116 634.84,27116 634.84,26431 634.84,26431"];
		lay3_mlp_act	[height=0.94444,
			label="GELU Activation\nInput: [128,10000,16384]\nOutput: [128,10000,16384]\nGPU: 3",
			pos="261.87,26836",
			shape=rectangle,
			width=2.9444];
		lay3_mlp_gate -> lay3_mlp_act	[pos="e,275.37,26871 275.37,26942 275.37,26942 275.37,26881 275.37,26881"];
		lay3_mlp_mul	[height=0.94444,
			label="Element-wise Mul\nInput: [128,10000,16384], [128,10000,16384]\nOutput: [128,10000,16384]\nGPU: 3",
			pos="421.87,26696",
			shape=rectangle,
			width=4.8056];
		lay3_mlp_up -> lay3_mlp_mul	[pos="e,499.37,26731 499.37,26802 499.37,26802 499.37,26741 499.37,26741"];
		lay3_mlp_act -> lay3_mlp_mul	[pos="e,308.37,26731 308.37,26802 308.37,26802 308.37,26741 308.37,26741"];
		lay3_mlp_down	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Down Projection\nInput: [128,10000,16384]\nOutput: [128,10000,4096]\nGPU: 3",
			pos="421.87,26556",
			shape=rectangle,
			width=2.8194];
		lay3_mlp_mul -> lay3_mlp_down	[pos="e,421.87,26591 421.87,26662 421.87,26662 421.87,26601 421.87,26601"];
		lay3_mlp_down -> lay3_res2	[pos="e,421.87,26450 421.87,26522 421.87,26522 421.87,26460 421.87,26460"];
		lay3_ln2	[fillcolor=lightsteelblue,
			height=0.94444,
			label="LayerNorm 2\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 3",
			pos="421.87,26248",
			shape=rectangle,
			width=2.8194];
		lay3_res2 -> lay3_ln2	[pos="e,421.87,26282 421.87,26354 421.87,26354 421.87,26292 421.87,26292"];
		layer3_output	[fillcolor=lightyellow,
			height=1.8889,
			label="Output Transfer\nTo: GPU 4\nSize: 524MB\nGPU: 3",
			pos="421.87,26074",
			shape=parallelogram,
			width=3.8014];
		lay3_ln2 -> layer3_output	[pos="e,421.87,26142 421.87,26214 421.87,26214 421.87,26152 421.87,26152"];
	}
	subgraph cluster_layer4_gpu4 {
		graph [bb="147.87,23846,661.87,25980",
			color=green,
			fillcolor=lightyellow,
			label="Layer 4 on GPU 4\nCache-capacity: 11.8GB",
			lheight=0.42,
			lp="404.87,25961",
			lwidth=2.36,
			style="rounded,dashed"
		];
		layer4_input	[fillcolor=lightyellow,
			height=1.8889,
			label="Input Transfer\nFrom: GPU 3\nSize: 524MB\nGPU: 4",
			pos="421.87,25866",
			shape=parallelogram,
			width=3.4558];
		lay4_qkv_proj	[fillcolor=lightcoral,
			height=0.94444,
			label="QKV Projection\nInput: [128,10000,4096]\nOutput: [128,10000,32,128]\nGPU: 4",
			pos="399.87,25692",
			shape=rectangle,
			width=3.0139];
		layer4_input -> lay4_qkv_proj	[pos="e,402.91,25726 402.91,25798 402.91,25798 402.91,25736 402.91,25736"];
		lay4_res1	[fillcolor=lightgray,
			height=1.3356,
			label="Residual Add 1\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 4",
			pos="421.87,25118",
			width=6.4425];
		layer4_input -> lay4_res1	[pos="e,552.5,25158 520.54,25865 538.93,25865 552.5,25865 552.5,25865 552.5,25865 552.5,25168 552.5,25168"];
		lay4_attn_score	[fillcolor=lightpink,
			height=0.94444,
			label="Scaled Dot-Product Attention\nInput: [128,10000,32,128], [128,10000,32,128]\nOutput: [128,10000,32,128]\nGPU: 4",
			pos="364.87,25552",
			shape=rectangle,
			width=4.9306];
		lay4_qkv_proj -> lay4_attn_score	[pos="e,399.87,25586 399.87,25658 399.87,25658 399.87,25596 399.87,25596"];
		lay4_attn_concat	[fillcolor=lightpink,
			height=0.94444,
			label="Concat Heads\nInput: [128,10000,32,128]\nOutput: [128,10000,4096]\nGPU: 4",
			pos="388.87,25412",
			shape=rectangle,
			width=2.8472];
		lay4_attn_score -> lay4_attn_concat	[pos="e,388.87,25446 388.87,25518 388.87,25518 388.87,25456 388.87,25456"];
		lay4_attn_out	[fillcolor=lightcoral,
			height=0.94444,
			label="Attention Output Projection\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 4",
			pos="412.87,25272",
			shape=rectangle,
			width=2.9861];
		lay4_attn_concat -> lay4_attn_out	[pos="e,398.37,25306 398.37,25378 398.37,25378 398.37,25316 398.37,25316"];
		lay4_attn_out -> lay4_res1	[pos="e,412.87,25166 412.87,25238 412.87,25238 412.87,25176 412.87,25176"];
		lay4_ln1	[fillcolor=lightsteelblue,
			height=0.94444,
			label="LayerNorm 1\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 4",
			pos="452.87,24964",
			shape=rectangle,
			width=2.8194];
		lay4_res1 -> lay4_ln1	[pos="e,452.87,24998 452.87,25070 452.87,25070 452.87,25008 452.87,25008"];
		lay4_mlp_gate	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Gate Projection\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nGPU: 4",
			pos="288.87,24824",
			shape=rectangle,
			width=2.9444];
		lay4_ln1 -> lay4_mlp_gate	[pos="e,373.12,24858 373.12,24930 373.12,24930 373.12,24868 373.12,24868"];
		lay4_mlp_up	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Up Projection\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nGPU: 4",
			pos="509.87,24684",
			shape=rectangle,
			width=2.9444];
		lay4_ln1 -> lay4_mlp_up	[pos="e,479.12,24718 479.12,24930 479.12,24930 479.12,24728 479.12,24728"];
		lay4_res2	[fillcolor=lightgray,
			height=1.3356,
			label="Residual Add 2\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 4",
			pos="421.87,24250",
			width=6.4425];
		lay4_ln1 -> lay4_res2	[pos="e,634.84,24269 554.49,24963 596.17,24963 634.84,24963 634.84,24963 634.84,24963 634.84,24279 634.84,24279"];
		lay4_mlp_act	[height=0.94444,
			label="GELU Activation\nInput: [128,10000,16384]\nOutput: [128,10000,16384]\nGPU: 4",
			pos="261.87,24684",
			shape=rectangle,
			width=2.9444];
		lay4_mlp_gate -> lay4_mlp_act	[pos="e,275.37,24718 275.37,24790 275.37,24790 275.37,24728 275.37,24728"];
		lay4_mlp_mul	[height=0.94444,
			label="Element-wise Mul\nInput: [128,10000,16384], [128,10000,16384]\nOutput: [128,10000,16384]\nGPU: 4",
			pos="421.87,24544",
			shape=rectangle,
			width=4.8056];
		lay4_mlp_up -> lay4_mlp_mul	[pos="e,499.37,24578 499.37,24650 499.37,24650 499.37,24588 499.37,24588"];
		lay4_mlp_act -> lay4_mlp_mul	[pos="e,308.37,24578 308.37,24650 308.37,24650 308.37,24588 308.37,24588"];
		lay4_mlp_down	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Down Projection\nInput: [128,10000,16384]\nOutput: [128,10000,4096]\nGPU: 4",
			pos="421.87,24404",
			shape=rectangle,
			width=2.8194];
		lay4_mlp_mul -> lay4_mlp_down	[pos="e,421.87,24438 421.87,24510 421.87,24510 421.87,24448 421.87,24448"];
		lay4_mlp_down -> lay4_res2	[pos="e,421.87,24298 421.87,24370 421.87,24370 421.87,24308 421.87,24308"];
		lay4_ln2	[fillcolor=lightsteelblue,
			height=0.94444,
			label="LayerNorm 2\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 4",
			pos="421.87,24096",
			shape=rectangle,
			width=2.8194];
		lay4_res2 -> lay4_ln2	[pos="e,421.87,24130 421.87,24201 421.87,24201 421.87,24140 421.87,24140"];
		layer4_output	[fillcolor=lightyellow,
			height=1.8889,
			label="Output Transfer\nTo: GPU 5\nSize: 524MB\nGPU: 4",
			pos="421.87,23922",
			shape=parallelogram,
			width=3.8014];
		lay4_ln2 -> layer4_output	[pos="e,421.87,23990 421.87,24061 421.87,24061 421.87,24000 421.87,24000"];
	}
	subgraph cluster_layer5_gpu5 {
		graph [bb="147.87,21693,661.87,23828",
			color=green,
			fillcolor=lightyellow,
			label="Layer 5 on GPU 5\nCache-capacity: 11.8GB",
			lheight=0.42,
			lp="404.87,23809",
			lwidth=2.36,
			style="rounded,dashed"
		];
		layer5_input	[fillcolor=lightyellow,
			height=1.8889,
			label="Input Transfer\nFrom: GPU 4\nSize: 524MB\nGPU: 5",
			pos="421.87,23714",
			shape=parallelogram,
			width=3.4558];
		lay5_qkv_proj	[fillcolor=lightcoral,
			height=0.94444,
			label="QKV Projection\nInput: [128,10000,4096]\nOutput: [128,10000,32,128]\nGPU: 5",
			pos="386.87,23540",
			shape=rectangle,
			width=3.0139];
		layer5_input -> lay5_qkv_proj	[pos="e,396.41,23574 396.41,23645 396.41,23645 396.41,23584 396.41,23584"];
		lay5_res1	[fillcolor=lightgray,
			height=1.3356,
			label="Residual Add 1\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 5",
			pos="421.87,22966",
			width=6.4425];
		layer5_input -> lay5_res1	[pos="e,537.82,23007 537.82,23714 537.82,23714 537.82,23017 537.82,23017"];
		lay5_attn_score	[fillcolor=lightpink,
			height=0.94444,
			label="Scaled Dot-Product Attention\nInput: [128,10000,32,128], [128,10000,32,128]\nOutput: [128,10000,32,128]\nGPU: 5",
			pos="351.87,23400",
			shape=rectangle,
			width=4.9306];
		lay5_qkv_proj -> lay5_attn_score	[pos="e,386.87,23434 386.87,23505 386.87,23505 386.87,23444 386.87,23444"];
		lay5_attn_concat	[fillcolor=lightpink,
			height=0.94444,
			label="Concat Heads\nInput: [128,10000,32,128]\nOutput: [128,10000,4096]\nGPU: 5",
			pos="369.87,23260",
			shape=rectangle,
			width=2.8472];
		lay5_attn_score -> lay5_attn_concat	[pos="e,369.87,23294 369.87,23365 369.87,23365 369.87,23304 369.87,23304"];
		lay5_attn_out	[fillcolor=lightcoral,
			height=0.94444,
			label="Attention Output Projection\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 5",
			pos="404.87,23120",
			shape=rectangle,
			width=2.9861];
		lay5_attn_concat -> lay5_attn_out	[pos="e,384.87,23154 384.87,23225 384.87,23225 384.87,23164 384.87,23164"];
		lay5_attn_out -> lay5_res1	[pos="e,404.87,23014 404.87,23085 404.87,23085 404.87,23024 404.87,23024"];
		lay5_ln1	[fillcolor=lightsteelblue,
			height=0.94444,
			label="LayerNorm 1\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 5",
			pos="452.87,22811",
			shape=rectangle,
			width=2.8194];
		lay5_res1 -> lay5_ln1	[pos="e,452.87,22846 452.87,22918 452.87,22918 452.87,22856 452.87,22856"];
		lay5_mlp_gate	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Gate Projection\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nGPU: 5",
			pos="288.87,22671",
			shape=rectangle,
			width=2.9444];
		lay5_ln1 -> lay5_mlp_gate	[pos="e,373.12,22706 373.12,22777 373.12,22777 373.12,22716 373.12,22716"];
		lay5_mlp_up	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Up Projection\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nGPU: 5",
			pos="509.87,22531",
			shape=rectangle,
			width=2.9444];
		lay5_ln1 -> lay5_mlp_up	[pos="e,479.12,22566 479.12,22777 479.12,22777 479.12,22576 479.12,22576"];
		lay5_res2	[fillcolor=lightgray,
			height=1.3356,
			label="Residual Add 2\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 5",
			pos="421.87,22097",
			width=6.4425];
		lay5_ln1 -> lay5_res2	[pos="e,634.84,22117 554.49,22811 596.17,22811 634.84,22811 634.84,22811 634.84,22811 634.84,22127 634.84,22127"];
		lay5_mlp_act	[height=0.94444,
			label="GELU Activation\nInput: [128,10000,16384]\nOutput: [128,10000,16384]\nGPU: 5",
			pos="261.87,22531",
			shape=rectangle,
			width=2.9444];
		lay5_mlp_gate -> lay5_mlp_act	[pos="e,275.37,22566 275.37,22637 275.37,22637 275.37,22576 275.37,22576"];
		lay5_mlp_mul	[height=0.94444,
			label="Element-wise Mul\nInput: [128,10000,16384], [128,10000,16384]\nOutput: [128,10000,16384]\nGPU: 5",
			pos="421.87,22391",
			shape=rectangle,
			width=4.8056];
		lay5_mlp_up -> lay5_mlp_mul	[pos="e,499.37,22426 499.37,22497 499.37,22497 499.37,22436 499.37,22436"];
		lay5_mlp_act -> lay5_mlp_mul	[pos="e,308.37,22426 308.37,22497 308.37,22497 308.37,22436 308.37,22436"];
		lay5_mlp_down	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Down Projection\nInput: [128,10000,16384]\nOutput: [128,10000,4096]\nGPU: 5",
			pos="421.87,22251",
			shape=rectangle,
			width=2.8194];
		lay5_mlp_mul -> lay5_mlp_down	[pos="e,421.87,22286 421.87,22357 421.87,22357 421.87,22296 421.87,22296"];
		lay5_mlp_down -> lay5_res2	[pos="e,421.87,22146 421.87,22217 421.87,22217 421.87,22156 421.87,22156"];
		lay5_ln2	[fillcolor=lightsteelblue,
			height=0.94444,
			label="LayerNorm 2\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 5",
			pos="421.87,21943",
			shape=rectangle,
			width=2.8194];
		lay5_res2 -> lay5_ln2	[pos="e,421.87,21978 421.87,22049 421.87,22049 421.87,21988 421.87,21988"];
		layer5_output	[fillcolor=lightyellow,
			height=1.8889,
			label="Output Transfer\nTo: GPU 6\nSize: 524MB\nGPU: 5",
			pos="421.87,21769",
			shape=parallelogram,
			width=3.8014];
		lay5_ln2 -> layer5_output	[pos="e,421.87,21837 421.87,21909 421.87,21909 421.87,21847 421.87,21847"];
	}
	subgraph cluster_layer6_gpu6 {
		graph [bb="156.87,19541,670.87,21675",
			color=green,
			fillcolor=lightyellow,
			label="Layer 6 on GPU 6\nCache-capacity: 11.8GB",
			lheight=0.42,
			lp="413.87,21656",
			lwidth=2.36,
			style="rounded,dashed"
		];
		layer6_input	[fillcolor=lightyellow,
			height=1.8889,
			label="Input Transfer\nFrom: GPU 5\nSize: 524MB\nGPU: 6",
			pos="421.87,21561",
			shape=parallelogram,
			width=3.4558];
		lay6_qkv_proj	[fillcolor=lightcoral,
			height=0.94444,
			label="QKV Projection\nInput: [128,10000,4096]\nOutput: [128,10000,32,128]\nGPU: 6",
			pos="395.87,21387",
			shape=rectangle,
			width=3.0139];
		layer6_input -> lay6_qkv_proj	[pos="e,400.91,21421 400.91,21493 400.91,21493 400.91,21431 400.91,21431"];
		lay6_res1	[fillcolor=lightgray,
			height=1.3356,
			label="Residual Add 1\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 6",
			pos="430.87,20813",
			width=6.4425];
		layer6_input -> lay6_res1	[pos="e,542.32,20856 542.32,21561 542.32,21561 542.32,20866 542.32,20866"];
		lay6_attn_score	[fillcolor=lightpink,
			height=0.94444,
			label="Scaled Dot-Product Attention\nInput: [128,10000,32,128], [128,10000,32,128]\nOutput: [128,10000,32,128]\nGPU: 6",
			pos="360.87,21247",
			shape=rectangle,
			width=4.9306];
		lay6_qkv_proj -> lay6_attn_score	[pos="e,395.87,21282 395.87,21353 395.87,21353 395.87,21292 395.87,21292"];
		lay6_attn_concat	[fillcolor=lightpink,
			height=0.94444,
			label="Concat Heads\nInput: [128,10000,32,128]\nOutput: [128,10000,4096]\nGPU: 6",
			pos="378.87,21107",
			shape=rectangle,
			width=2.8472];
		lay6_attn_score -> lay6_attn_concat	[pos="e,378.87,21142 378.87,21213 378.87,21213 378.87,21152 378.87,21152"];
		lay6_attn_out	[fillcolor=lightcoral,
			height=0.94444,
			label="Attention Output Projection\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 6",
			pos="413.87,20967",
			shape=rectangle,
			width=2.9861];
		lay6_attn_concat -> lay6_attn_out	[pos="e,393.87,21002 393.87,21073 393.87,21073 393.87,21012 393.87,21012"];
		lay6_attn_out -> lay6_res1	[pos="e,413.87,20861 413.87,20933 413.87,20933 413.87,20871 413.87,20871"];
		lay6_ln1	[fillcolor=lightsteelblue,
			height=0.94444,
			label="LayerNorm 1\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 6",
			pos="461.87,20659",
			shape=rectangle,
			width=2.8194];
		lay6_res1 -> lay6_ln1	[pos="e,461.87,20693 461.87,20765 461.87,20765 461.87,20703 461.87,20703"];
		lay6_mlp_gate	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Gate Projection\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nGPU: 6",
			pos="297.87,20519",
			shape=rectangle,
			width=2.9444];
		lay6_ln1 -> lay6_mlp_gate	[pos="e,382.12,20554 382.12,20625 382.12,20625 382.12,20564 382.12,20564"];
		lay6_mlp_up	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Up Projection\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nGPU: 6",
			pos="518.87,20379",
			shape=rectangle,
			width=2.9444];
		lay6_ln1 -> lay6_mlp_up	[pos="e,488.12,20413 488.12,20625 488.12,20625 488.12,20423 488.12,20423"];
		lay6_res2	[fillcolor=lightgray,
			height=1.3356,
			label="Residual Add 2\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 6",
			pos="430.87,19945",
			width=6.4425];
		lay6_ln1 -> lay6_res2	[pos="e,643.84,19964 563.49,20659 605.17,20659 643.84,20659 643.84,20659 643.84,20659 643.84,19974 643.84,19974"];
		lay6_mlp_act	[height=0.94444,
			label="GELU Activation\nInput: [128,10000,16384]\nOutput: [128,10000,16384]\nGPU: 6",
			pos="270.87,20379",
			shape=rectangle,
			width=2.9444];
		lay6_mlp_gate -> lay6_mlp_act	[pos="e,284.37,20414 284.37,20485 284.37,20485 284.37,20424 284.37,20424"];
		lay6_mlp_mul	[height=0.94444,
			label="Element-wise Mul\nInput: [128,10000,16384], [128,10000,16384]\nOutput: [128,10000,16384]\nGPU: 6",
			pos="430.87,20239",
			shape=rectangle,
			width=4.8056];
		lay6_mlp_up -> lay6_mlp_mul	[pos="e,508.37,20274 508.37,20345 508.37,20345 508.37,20284 508.37,20284"];
		lay6_mlp_act -> lay6_mlp_mul	[pos="e,317.37,20274 317.37,20345 317.37,20345 317.37,20284 317.37,20284"];
		lay6_mlp_down	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Down Projection\nInput: [128,10000,16384]\nOutput: [128,10000,4096]\nGPU: 6",
			pos="430.87,20099",
			shape=rectangle,
			width=2.8194];
		lay6_mlp_mul -> lay6_mlp_down	[pos="e,430.87,20134 430.87,20205 430.87,20205 430.87,20144 430.87,20144"];
		lay6_mlp_down -> lay6_res2	[pos="e,430.87,19993 430.87,20065 430.87,20065 430.87,20003 430.87,20003"];
		lay6_ln2	[fillcolor=lightsteelblue,
			height=0.94444,
			label="LayerNorm 2\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 6",
			pos="430.87,19791",
			shape=rectangle,
			width=2.8194];
		lay6_res2 -> lay6_ln2	[pos="e,430.87,19825 430.87,19897 430.87,19897 430.87,19835 430.87,19835"];
		layer6_output	[fillcolor=lightyellow,
			height=1.8889,
			label="Output Transfer\nTo: GPU 7\nSize: 524MB\nGPU: 6",
			pos="430.87,19617",
			shape=parallelogram,
			width=3.8014];
		lay6_ln2 -> layer6_output	[pos="e,430.87,19685 430.87,19757 430.87,19757 430.87,19695 430.87,19695"];
	}
	subgraph cluster_layer7_gpu7 {
		graph [bb="147.87,17389,661.87,19523",
			color=green,
			fillcolor=lightyellow,
			label="Layer 7 on GPU 7\nCache-capacity: 11.8GB",
			lheight=0.42,
			lp="404.87,19504",
			lwidth=2.36,
			style="rounded,dashed"
		];
		layer7_input	[fillcolor=lightyellow,
			height=1.8889,
			label="Input Transfer\nFrom: GPU 6\nSize: 524MB\nGPU: 7",
			pos="430.87,19409",
			shape=parallelogram,
			width=3.4558];
		lay7_qkv_proj	[fillcolor=lightcoral,
			height=0.94444,
			label="QKV Projection\nInput: [128,10000,4096]\nOutput: [128,10000,32,128]\nGPU: 7",
			pos="386.87,19235",
			shape=rectangle,
			width=3.0139];
		layer7_input -> lay7_qkv_proj	[pos="e,400.91,19269 400.91,19341 400.91,19341 400.91,19279 400.91,19279"];
		lay7_res1	[fillcolor=lightgray,
			height=1.3356,
			label="Residual Add 1\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 7",
			pos="421.87,18661",
			width=6.4425];
		layer7_input -> lay7_res1	[pos="e,542.32,18702 542.32,19409 542.32,19409 542.32,18712 542.32,18712"];
		lay7_attn_score	[fillcolor=lightpink,
			height=0.94444,
			label="Scaled Dot-Product Attention\nInput: [128,10000,32,128], [128,10000,32,128]\nOutput: [128,10000,32,128]\nGPU: 7",
			pos="351.87,19095",
			shape=rectangle,
			width=4.9306];
		lay7_qkv_proj -> lay7_attn_score	[pos="e,386.87,19129 386.87,19201 386.87,19201 386.87,19139 386.87,19139"];
		lay7_attn_concat	[fillcolor=lightpink,
			height=0.94444,
			label="Concat Heads\nInput: [128,10000,32,128]\nOutput: [128,10000,4096]\nGPU: 7",
			pos="369.87,18955",
			shape=rectangle,
			width=2.8472];
		lay7_attn_score -> lay7_attn_concat	[pos="e,369.87,18989 369.87,19061 369.87,19061 369.87,18999 369.87,18999"];
		lay7_attn_out	[fillcolor=lightcoral,
			height=0.94444,
			label="Attention Output Projection\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 7",
			pos="404.87,18815",
			shape=rectangle,
			width=2.9861];
		lay7_attn_concat -> lay7_attn_out	[pos="e,384.87,18849 384.87,18921 384.87,18921 384.87,18859 384.87,18859"];
		lay7_attn_out -> lay7_res1	[pos="e,404.87,18709 404.87,18781 404.87,18781 404.87,18719 404.87,18719"];
		lay7_ln1	[fillcolor=lightsteelblue,
			height=0.94444,
			label="LayerNorm 1\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 7",
			pos="452.87,18507",
			shape=rectangle,
			width=2.8194];
		lay7_res1 -> lay7_ln1	[pos="e,452.87,18541 452.87,18613 452.87,18613 452.87,18551 452.87,18551"];
		lay7_mlp_gate	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Gate Projection\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nGPU: 7",
			pos="288.87,18367",
			shape=rectangle,
			width=2.9444];
		lay7_ln1 -> lay7_mlp_gate	[pos="e,373.12,18401 373.12,18473 373.12,18473 373.12,18411 373.12,18411"];
		lay7_mlp_up	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Up Projection\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nGPU: 7",
			pos="509.87,18227",
			shape=rectangle,
			width=2.9444];
		lay7_ln1 -> lay7_mlp_up	[pos="e,479.12,18261 479.12,18473 479.12,18473 479.12,18271 479.12,18271"];
		lay7_res2	[fillcolor=lightgray,
			height=1.3356,
			label="Residual Add 2\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 7",
			pos="421.87,17793",
			width=6.4425];
		lay7_ln1 -> lay7_res2	[pos="e,634.84,17812 554.49,18506 596.17,18506 634.84,18506 634.84,18506 634.84,18506 634.84,17822 634.84,17822"];
		lay7_mlp_act	[height=0.94444,
			label="GELU Activation\nInput: [128,10000,16384]\nOutput: [128,10000,16384]\nGPU: 7",
			pos="261.87,18227",
			shape=rectangle,
			width=2.9444];
		lay7_mlp_gate -> lay7_mlp_act	[pos="e,275.37,18261 275.37,18333 275.37,18333 275.37,18271 275.37,18271"];
		lay7_mlp_mul	[height=0.94444,
			label="Element-wise Mul\nInput: [128,10000,16384], [128,10000,16384]\nOutput: [128,10000,16384]\nGPU: 7",
			pos="421.87,18087",
			shape=rectangle,
			width=4.8056];
		lay7_mlp_up -> lay7_mlp_mul	[pos="e,499.37,18121 499.37,18193 499.37,18193 499.37,18131 499.37,18131"];
		lay7_mlp_act -> lay7_mlp_mul	[pos="e,308.37,18121 308.37,18193 308.37,18193 308.37,18131 308.37,18131"];
		lay7_mlp_down	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Down Projection\nInput: [128,10000,16384]\nOutput: [128,10000,4096]\nGPU: 7",
			pos="421.87,17947",
			shape=rectangle,
			width=2.8194];
		lay7_mlp_mul -> lay7_mlp_down	[pos="e,421.87,17981 421.87,18053 421.87,18053 421.87,17991 421.87,17991"];
		lay7_mlp_down -> lay7_res2	[pos="e,421.87,17841 421.87,17913 421.87,17913 421.87,17851 421.87,17851"];
		lay7_ln2	[fillcolor=lightsteelblue,
			height=0.94444,
			label="LayerNorm 2\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 7",
			pos="421.87,17639",
			shape=rectangle,
			width=2.8194];
		lay7_res2 -> lay7_ln2	[pos="e,421.87,17673 421.87,17744 421.87,17744 421.87,17683 421.87,17683"];
		layer7_output	[fillcolor=lightyellow,
			height=1.8889,
			label="Output Transfer\nTo: GPU 8\nSize: 524MB\nGPU: 7",
			pos="421.87,17465",
			shape=parallelogram,
			width=3.8014];
		lay7_ln2 -> layer7_output	[pos="e,421.87,17533 421.87,17604 421.87,17604 421.87,17543 421.87,17543"];
	}
	subgraph cluster_layer8_gpu8 {
		graph [bb="169.87,15236,683.87,17371",
			color=green,
			fillcolor=lightyellow,
			label="Layer 8 on GPU 8\nCache-capacity: 11.8GB",
			lheight=0.42,
			lp="426.87,17352",
			lwidth=2.36,
			style="rounded,dashed"
		];
		layer8_input	[fillcolor=lightyellow,
			height=1.8889,
			label="Input Transfer\nFrom: GPU 7\nSize: 524MB\nGPU: 8",
			pos="421.87,17257",
			shape=parallelogram,
			width=3.4558];
		lay8_qkv_proj	[fillcolor=lightcoral,
			height=0.94444,
			label="QKV Projection\nInput: [128,10000,4096]\nOutput: [128,10000,32,128]\nGPU: 8",
			pos="413.87,17083",
			shape=rectangle,
			width=3.0139];
		layer8_input -> lay8_qkv_proj	[pos="e,413.87,17117 413.87,17188 413.87,17188 413.87,17127 413.87,17127"];
		lay8_res1	[fillcolor=lightgray,
			height=1.3356,
			label="Residual Add 1\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 8",
			pos="443.87,16509",
			width=6.4425];
		layer8_input -> lay8_res1	[pos="e,606.26,16543 520.54,17256 564.38,17256 606.26,17256 606.26,17256 606.26,17256 606.26,16553 606.26,16553"];
		lay8_attn_score	[fillcolor=lightpink,
			height=0.94444,
			label="Scaled Dot-Product Attention\nInput: [128,10000,32,128], [128,10000,32,128]\nOutput: [128,10000,32,128]\nGPU: 8",
			pos="378.87,16943",
			shape=rectangle,
			width=4.9306];
		lay8_qkv_proj -> lay8_attn_score	[pos="e,413.87,16977 413.87,17048 413.87,17048 413.87,16987 413.87,16987"];
		lay8_attn_concat	[fillcolor=lightpink,
			height=0.94444,
			label="Concat Heads\nInput: [128,10000,32,128]\nOutput: [128,10000,4096]\nGPU: 8",
			pos="402.87,16803",
			shape=rectangle,
			width=2.8472];
		lay8_attn_score -> lay8_attn_concat	[pos="e,402.87,16837 402.87,16908 402.87,16908 402.87,16847 402.87,16847"];
		lay8_attn_out	[fillcolor=lightcoral,
			height=0.94444,
			label="Attention Output Projection\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 8",
			pos="420.87,16663",
			shape=rectangle,
			width=2.9861];
		lay8_attn_concat -> lay8_attn_out	[pos="e,409.37,16697 409.37,16768 409.37,16768 409.37,16707 409.37,16707"];
		lay8_attn_out -> lay8_res1	[pos="e,420.87,16557 420.87,16628 420.87,16628 420.87,16567 420.87,16567"];
		lay8_ln1	[fillcolor=lightsteelblue,
			height=0.94444,
			label="LayerNorm 1\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 8",
			pos="474.87,16354",
			shape=rectangle,
			width=2.8194];
		lay8_res1 -> lay8_ln1	[pos="e,474.87,16389 474.87,16461 474.87,16461 474.87,16399 474.87,16399"];
		lay8_mlp_gate	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Gate Projection\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nGPU: 8",
			pos="310.87,16214",
			shape=rectangle,
			width=2.9444];
		lay8_ln1 -> lay8_mlp_gate	[pos="e,395.12,16249 395.12,16320 395.12,16320 395.12,16259 395.12,16259"];
		lay8_mlp_up	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Up Projection\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nGPU: 8",
			pos="531.87,16074",
			shape=rectangle,
			width=2.9444];
		lay8_ln1 -> lay8_mlp_up	[pos="e,501.12,16109 501.12,16320 501.12,16320 501.12,16119 501.12,16119"];
		lay8_res2	[fillcolor=lightgray,
			height=1.3356,
			label="Residual Add 2\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 8",
			pos="443.87,15640",
			width=6.4425];
		lay8_ln1 -> lay8_res2	[pos="e,656.84,15660 576.49,16354 618.17,16354 656.84,16354 656.84,16354 656.84,16354 656.84,15670 656.84,15670"];
		lay8_mlp_act	[height=0.94444,
			label="GELU Activation\nInput: [128,10000,16384]\nOutput: [128,10000,16384]\nGPU: 8",
			pos="283.87,16074",
			shape=rectangle,
			width=2.9444];
		lay8_mlp_gate -> lay8_mlp_act	[pos="e,297.37,16109 297.37,16180 297.37,16180 297.37,16119 297.37,16119"];
		lay8_mlp_mul	[height=0.94444,
			label="Element-wise Mul\nInput: [128,10000,16384], [128,10000,16384]\nOutput: [128,10000,16384]\nGPU: 8",
			pos="443.87,15934",
			shape=rectangle,
			width=4.8056];
		lay8_mlp_up -> lay8_mlp_mul	[pos="e,521.37,15969 521.37,16040 521.37,16040 521.37,15979 521.37,15979"];
		lay8_mlp_act -> lay8_mlp_mul	[pos="e,330.37,15969 330.37,16040 330.37,16040 330.37,15979 330.37,15979"];
		lay8_mlp_down	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Down Projection\nInput: [128,10000,16384]\nOutput: [128,10000,4096]\nGPU: 8",
			pos="443.87,15794",
			shape=rectangle,
			width=2.8194];
		lay8_mlp_mul -> lay8_mlp_down	[pos="e,443.87,15829 443.87,15900 443.87,15900 443.87,15839 443.87,15839"];
		lay8_mlp_down -> lay8_res2	[pos="e,443.87,15689 443.87,15760 443.87,15760 443.87,15699 443.87,15699"];
		lay8_ln2	[fillcolor=lightsteelblue,
			height=0.94444,
			label="LayerNorm 2\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 8",
			pos="443.87,15486",
			shape=rectangle,
			width=2.8194];
		lay8_res2 -> lay8_ln2	[pos="e,443.87,15521 443.87,15592 443.87,15592 443.87,15531 443.87,15531"];
		layer8_output	[fillcolor=lightyellow,
			height=1.8889,
			label="Output Transfer\nTo: GPU 9\nSize: 524MB\nGPU: 8",
			pos="443.87,15312",
			shape=parallelogram,
			width=3.8014];
		lay8_ln2 -> layer8_output	[pos="e,443.87,15380 443.87,15452 443.87,15452 443.87,15390 443.87,15390"];
	}
	subgraph cluster_layer9_gpu9 {
		graph [bb="147.87,13084,661.87,15218",
			color=green,
			fillcolor=lightyellow,
			label="Layer 9 on GPU 9\nCache-capacity: 11.8GB",
			lheight=0.42,
			lp="404.87,15199",
			lwidth=2.36,
			style="rounded,dashed"
		];
		layer9_input	[fillcolor=lightyellow,
			height=1.8889,
			label="Input Transfer\nFrom: GPU 8\nSize: 524MB\nGPU: 9",
			pos="443.87,15104",
			shape=parallelogram,
			width=3.4558];
		lay9_qkv_proj	[fillcolor=lightcoral,
			height=0.94444,
			label="QKV Projection\nInput: [128,10000,4096]\nOutput: [128,10000,32,128]\nGPU: 9",
			pos="399.87,14930",
			shape=rectangle,
			width=3.0139];
		layer9_input -> lay9_qkv_proj	[pos="e,413.91,14964 413.91,15036 413.91,15036 413.91,14974 413.91,14974"];
		lay9_res1	[fillcolor=lightgray,
			height=1.3356,
			label="Residual Add 1\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 9",
			pos="421.87,14356",
			width=6.4425];
		layer9_input -> lay9_res1	[pos="e,555.32,14396 555.32,15104 555.32,15104 555.32,14406 555.32,14406"];
		lay9_attn_score	[fillcolor=lightpink,
			height=0.94444,
			label="Scaled Dot-Product Attention\nInput: [128,10000,32,128], [128,10000,32,128]\nOutput: [128,10000,32,128]\nGPU: 9",
			pos="364.87,14790",
			shape=rectangle,
			width=4.9306];
		lay9_qkv_proj -> lay9_attn_score	[pos="e,399.87,14825 399.87,14896 399.87,14896 399.87,14835 399.87,14835"];
		lay9_attn_concat	[fillcolor=lightpink,
			height=0.94444,
			label="Concat Heads\nInput: [128,10000,32,128]\nOutput: [128,10000,4096]\nGPU: 9",
			pos="388.87,14650",
			shape=rectangle,
			width=2.8472];
		lay9_attn_score -> lay9_attn_concat	[pos="e,388.87,14685 388.87,14756 388.87,14756 388.87,14695 388.87,14695"];
		lay9_attn_out	[fillcolor=lightcoral,
			height=0.94444,
			label="Attention Output Projection\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 9",
			pos="412.87,14510",
			shape=rectangle,
			width=2.9861];
		lay9_attn_concat -> lay9_attn_out	[pos="e,398.37,14545 398.37,14616 398.37,14616 398.37,14555 398.37,14555"];
		lay9_attn_out -> lay9_res1	[pos="e,412.87,14404 412.87,14476 412.87,14476 412.87,14414 412.87,14414"];
		lay9_ln1	[fillcolor=lightsteelblue,
			height=0.94444,
			label="LayerNorm 1\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 9",
			pos="452.87,14202",
			shape=rectangle,
			width=2.8194];
		lay9_res1 -> lay9_ln1	[pos="e,452.87,14236 452.87,14308 452.87,14308 452.87,14246 452.87,14246"];
		lay9_mlp_gate	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Gate Projection\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nGPU: 9",
			pos="288.87,14062",
			shape=rectangle,
			width=2.9444];
		lay9_ln1 -> lay9_mlp_gate	[pos="e,373.12,14097 373.12,14168 373.12,14168 373.12,14107 373.12,14107"];
		lay9_mlp_up	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Up Projection\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nGPU: 9",
			pos="509.87,13922",
			shape=rectangle,
			width=2.9444];
		lay9_ln1 -> lay9_mlp_up	[pos="e,479.12,13956 479.12,14168 479.12,14168 479.12,13966 479.12,13966"];
		lay9_res2	[fillcolor=lightgray,
			height=1.3356,
			label="Residual Add 2\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 9",
			pos="421.87,13488",
			width=6.4425];
		lay9_ln1 -> lay9_res2	[pos="e,634.84,13507 554.49,14202 596.17,14202 634.84,14202 634.84,14202 634.84,14202 634.84,13517 634.84,13517"];
		lay9_mlp_act	[height=0.94444,
			label="GELU Activation\nInput: [128,10000,16384]\nOutput: [128,10000,16384]\nGPU: 9",
			pos="261.87,13922",
			shape=rectangle,
			width=2.9444];
		lay9_mlp_gate -> lay9_mlp_act	[pos="e,275.37,13957 275.37,14028 275.37,14028 275.37,13967 275.37,13967"];
		lay9_mlp_mul	[height=0.94444,
			label="Element-wise Mul\nInput: [128,10000,16384], [128,10000,16384]\nOutput: [128,10000,16384]\nGPU: 9",
			pos="421.87,13782",
			shape=rectangle,
			width=4.8056];
		lay9_mlp_up -> lay9_mlp_mul	[pos="e,499.37,13817 499.37,13888 499.37,13888 499.37,13827 499.37,13827"];
		lay9_mlp_act -> lay9_mlp_mul	[pos="e,308.37,13817 308.37,13888 308.37,13888 308.37,13827 308.37,13827"];
		lay9_mlp_down	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Down Projection\nInput: [128,10000,16384]\nOutput: [128,10000,4096]\nGPU: 9",
			pos="421.87,13642",
			shape=rectangle,
			width=2.8194];
		lay9_mlp_mul -> lay9_mlp_down	[pos="e,421.87,13677 421.87,13748 421.87,13748 421.87,13687 421.87,13687"];
		lay9_mlp_down -> lay9_res2	[pos="e,421.87,13536 421.87,13608 421.87,13608 421.87,13546 421.87,13546"];
		lay9_ln2	[fillcolor=lightsteelblue,
			height=0.94444,
			label="LayerNorm 2\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 9",
			pos="421.87,13334",
			shape=rectangle,
			width=2.8194];
		lay9_res2 -> lay9_ln2	[pos="e,421.87,13368 421.87,13440 421.87,13440 421.87,13378 421.87,13378"];
		layer9_output	[fillcolor=lightyellow,
			height=1.8889,
			label="Output Transfer\nTo: GPU 10\nSize: 524MB\nGPU: 9",
			pos="421.87,13160",
			shape=parallelogram,
			width=3.8014];
		lay9_ln2 -> layer9_output	[pos="e,421.87,13228 421.87,13300 421.87,13300 421.87,13238 421.87,13238"];
	}
	subgraph cluster_layer10_gpu10 {
		graph [bb="147.87,10932,661.87,13066",
			color=green,
			fillcolor=lightyellow,
			label="Layer 10 on GPU 10\nCache-capacity: 11.8GB",
			lheight=0.42,
			lp="404.87,13047",
			lwidth=2.36,
			style="rounded,dashed"
		];
		layer10_input	[fillcolor=lightyellow,
			height=1.8889,
			label="Input Transfer\nFrom: GPU 9\nSize: 524MB\nGPU: 10",
			pos="421.87,12952",
			shape=parallelogram,
			width=3.4558];
		lay10_qkv_proj	[fillcolor=lightcoral,
			height=0.94444,
			label="QKV Projection\nInput: [128,10000,4096]\nOutput: [128,10000,32,128]\nGPU: 10",
			pos="399.87,12778",
			shape=rectangle,
			width=3.0139];
		layer10_input -> lay10_qkv_proj	[pos="e,402.91,12812 402.91,12884 402.91,12884 402.91,12822 402.91,12822"];
		lay10_res1	[fillcolor=lightgray,
			height=1.3356,
			label="Residual Add 1\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 10",
			pos="421.87,12204",
			width=6.4425];
		layer10_input -> lay10_res1	[pos="e,552.5,12244 520.54,12951 538.93,12951 552.5,12951 552.5,12951 552.5,12951 552.5,12254 552.5,12254"];
		lay10_attn_score	[fillcolor=lightpink,
			height=0.94444,
			label="Scaled Dot-Product Attention\nInput: [128,10000,32,128], [128,10000,32,128]\nOutput: [128,10000,32,128]\nGPU: 10",
			pos="364.87,12638",
			shape=rectangle,
			width=4.9306];
		lay10_qkv_proj -> lay10_attn_score	[pos="e,399.87,12672 399.87,12744 399.87,12744 399.87,12682 399.87,12682"];
		lay10_attn_concat	[fillcolor=lightpink,
			height=0.94444,
			label="Concat Heads\nInput: [128,10000,32,128]\nOutput: [128,10000,4096]\nGPU: 10",
			pos="388.87,12498",
			shape=rectangle,
			width=2.8472];
		lay10_attn_score -> lay10_attn_concat	[pos="e,388.87,12532 388.87,12604 388.87,12604 388.87,12542 388.87,12542"];
		lay10_attn_out	[fillcolor=lightcoral,
			height=0.94444,
			label="Attention Output Projection\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 10",
			pos="412.87,12358",
			shape=rectangle,
			width=2.9861];
		lay10_attn_concat -> lay10_attn_out	[pos="e,398.37,12392 398.37,12464 398.37,12464 398.37,12402 398.37,12402"];
		lay10_attn_out -> lay10_res1	[pos="e,412.87,12252 412.87,12324 412.87,12324 412.87,12262 412.87,12262"];
		lay10_ln1	[fillcolor=lightsteelblue,
			height=0.94444,
			label="LayerNorm 1\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 10",
			pos="452.87,12050",
			shape=rectangle,
			width=2.8194];
		lay10_res1 -> lay10_ln1	[pos="e,452.87,12084 452.87,12156 452.87,12156 452.87,12094 452.87,12094"];
		lay10_mlp_gate	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Gate Projection\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nGPU: 10",
			pos="288.87,11910",
			shape=rectangle,
			width=2.9444];
		lay10_ln1 -> lay10_mlp_gate	[pos="e,373.12,11944 373.12,12016 373.12,12016 373.12,11954 373.12,11954"];
		lay10_mlp_up	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Up Projection\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nGPU: 10",
			pos="509.87,11770",
			shape=rectangle,
			width=2.9444];
		lay10_ln1 -> lay10_mlp_up	[pos="e,479.12,11804 479.12,12016 479.12,12016 479.12,11814 479.12,11814"];
		lay10_res2	[fillcolor=lightgray,
			height=1.3356,
			label="Residual Add 2\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 10",
			pos="421.87,11336",
			width=6.4425];
		lay10_ln1 -> lay10_res2	[pos="e,634.84,11355 554.49,12049 596.17,12049 634.84,12049 634.84,12049 634.84,12049 634.84,11365 634.84,11365"];
		lay10_mlp_act	[height=0.94444,
			label="GELU Activation\nInput: [128,10000,16384]\nOutput: [128,10000,16384]\nGPU: 10",
			pos="261.87,11770",
			shape=rectangle,
			width=2.9444];
		lay10_mlp_gate -> lay10_mlp_act	[pos="e,275.37,11804 275.37,11876 275.37,11876 275.37,11814 275.37,11814"];
		lay10_mlp_mul	[height=0.94444,
			label="Element-wise Mul\nInput: [128,10000,16384], [128,10000,16384]\nOutput: [128,10000,16384]\nGPU: 10",
			pos="421.87,11630",
			shape=rectangle,
			width=4.8056];
		lay10_mlp_up -> lay10_mlp_mul	[pos="e,499.37,11664 499.37,11736 499.37,11736 499.37,11674 499.37,11674"];
		lay10_mlp_act -> lay10_mlp_mul	[pos="e,308.37,11664 308.37,11736 308.37,11736 308.37,11674 308.37,11674"];
		lay10_mlp_down	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Down Projection\nInput: [128,10000,16384]\nOutput: [128,10000,4096]\nGPU: 10",
			pos="421.87,11490",
			shape=rectangle,
			width=2.8194];
		lay10_mlp_mul -> lay10_mlp_down	[pos="e,421.87,11524 421.87,11596 421.87,11596 421.87,11534 421.87,11534"];
		lay10_mlp_down -> lay10_res2	[pos="e,421.87,11384 421.87,11456 421.87,11456 421.87,11394 421.87,11394"];
		lay10_ln2	[fillcolor=lightsteelblue,
			height=0.94444,
			label="LayerNorm 2\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 10",
			pos="421.87,11182",
			shape=rectangle,
			width=2.8194];
		lay10_res2 -> lay10_ln2	[pos="e,421.87,11216 421.87,11287 421.87,11287 421.87,11226 421.87,11226"];
		layer10_output	[fillcolor=lightyellow,
			height=1.8889,
			label="Output Transfer\nTo: GPU 11\nSize: 524MB\nGPU: 10",
			pos="421.87,11008",
			shape=parallelogram,
			width=3.8014];
		lay10_ln2 -> layer10_output	[pos="e,421.87,11076 421.87,11147 421.87,11147 421.87,11086 421.87,11086"];
	}
	subgraph cluster_layer11_gpu11 {
		graph [bb="166.87,8779.3,680.87,10914",
			color=green,
			fillcolor=lightyellow,
			label="Layer 11 on GPU 11\nCache-capacity: 11.8GB",
			lheight=0.42,
			lp="423.87,10895",
			lwidth=2.36,
			style="rounded,dashed"
		];
		layer11_input	[fillcolor=lightyellow,
			height=1.8889,
			label="Input Transfer\nFrom: GPU 10\nSize: 524MB\nGPU: 11",
			pos="421.87,10800",
			shape=parallelogram,
			width=3.4558];
		lay11_qkv_proj	[fillcolor=lightcoral,
			height=0.94444,
			label="QKV Projection\nInput: [128,10000,4096]\nOutput: [128,10000,32,128]\nGPU: 11",
			pos="404.87,10626",
			shape=rectangle,
			width=3.0139];
		layer11_input -> lay11_qkv_proj	[pos="e,405.41,10660 405.41,10731 405.41,10731 405.41,10670 405.41,10670"];
		lay11_res1	[fillcolor=lightgray,
			height=1.3356,
			label="Residual Add 1\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 11",
			pos="440.87,10052",
			width=6.4425];
		layer11_input -> lay11_res1	[pos="e,553.05,10094 520.62,10799 539.26,10799 553.05,10799 553.05,10799 553.05,10799 553.05,10104 553.05,10104"];
		lay11_attn_score	[fillcolor=lightpink,
			height=0.94444,
			label="Scaled Dot-Product Attention\nInput: [128,10000,32,128], [128,10000,32,128]\nOutput: [128,10000,32,128]\nGPU: 11",
			pos="369.87,10486",
			shape=rectangle,
			width=4.9306];
		lay11_qkv_proj -> lay11_attn_score	[pos="e,404.87,10520 404.87,10591 404.87,10591 404.87,10530 404.87,10530"];
		lay11_attn_concat	[fillcolor=lightpink,
			height=0.94444,
			label="Concat Heads\nInput: [128,10000,32,128]\nOutput: [128,10000,4096]\nGPU: 11",
			pos="386.87,10346",
			shape=rectangle,
			width=2.8472];
		lay11_attn_score -> lay11_attn_concat	[pos="e,386.87,10380 386.87,10451 386.87,10451 386.87,10390 386.87,10390"];
		lay11_attn_out	[fillcolor=lightcoral,
			height=0.94444,
			label="Attention Output Projection\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 11",
			pos="421.87,10206",
			shape=rectangle,
			width=2.9861];
		lay11_attn_concat -> lay11_attn_out	[pos="e,401.87,10240 401.87,10311 401.87,10311 401.87,10250 401.87,10250"];
		lay11_attn_out -> lay11_res1	[pos="e,421.87,10100 421.87,10171 421.87,10171 421.87,10110 421.87,10110"];
		lay11_ln1	[fillcolor=lightsteelblue,
			height=0.94444,
			label="LayerNorm 1\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 11",
			pos="471.87,9897.5",
			shape=rectangle,
			width=2.8194];
		lay11_res1 -> lay11_ln1	[pos="e,471.87,9931.7 471.87,10004 471.87,10004 471.87,9941.7 471.87,9941.7"];
		lay11_mlp_gate	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Gate Projection\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nGPU: 11",
			pos="307.87,9757.5",
			shape=rectangle,
			width=2.9444];
		lay11_ln1 -> lay11_mlp_gate	[pos="e,392.12,9791.9 392.12,9863.3 392.12,9863.3 392.12,9801.9 392.12,9801.9"];
		lay11_mlp_up	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Up Projection\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nGPU: 11",
			pos="528.87,9617.5",
			shape=rectangle,
			width=2.9444];
		lay11_ln1 -> lay11_mlp_up	[pos="e,498.12,9651.8 498.12,9863.4 498.12,9863.4 498.12,9661.8 498.12,9661.8"];
		lay11_res2	[fillcolor=lightgray,
			height=1.3356,
			label="Residual Add 2\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 11",
			pos="440.87,9183.4",
			width=6.4425];
		lay11_ln1 -> lay11_res2	[pos="e,653.84,9202.5 573.49,9897 615.17,9897 653.84,9897 653.84,9897 653.84,9897 653.84,9212.5 653.84,9212.5"];
		lay11_mlp_act	[height=0.94444,
			label="GELU Activation\nInput: [128,10000,16384]\nOutput: [128,10000,16384]\nGPU: 11",
			pos="280.87,9617.5",
			shape=rectangle,
			width=2.9444];
		lay11_mlp_gate -> lay11_mlp_act	[pos="e,294.37,9651.9 294.37,9723.3 294.37,9723.3 294.37,9661.9 294.37,9661.9"];
		lay11_mlp_mul	[height=0.94444,
			label="Element-wise Mul\nInput: [128,10000,16384], [128,10000,16384]\nOutput: [128,10000,16384]\nGPU: 11",
			pos="440.87,9477.5",
			shape=rectangle,
			width=4.8056];
		lay11_mlp_up -> lay11_mlp_mul	[pos="e,518.37,9511.9 518.37,9583.3 518.37,9583.3 518.37,9521.9 518.37,9521.9"];
		lay11_mlp_act -> lay11_mlp_mul	[pos="e,327.37,9511.9 327.37,9583.3 327.37,9583.3 327.37,9521.9 327.37,9521.9"];
		lay11_mlp_down	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Down Projection\nInput: [128,10000,16384]\nOutput: [128,10000,4096]\nGPU: 11",
			pos="440.87,9337.5",
			shape=rectangle,
			width=2.8194];
		lay11_mlp_mul -> lay11_mlp_down	[pos="e,440.87,9371.9 440.87,9443.3 440.87,9443.3 440.87,9381.9 440.87,9381.9"];
		lay11_mlp_down -> lay11_res2	[pos="e,440.87,9231.5 440.87,9303.3 440.87,9303.3 440.87,9241.5 440.87,9241.5"];
		lay11_ln2	[fillcolor=lightsteelblue,
			height=0.94444,
			label="LayerNorm 2\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 11",
			pos="440.87,9029.3",
			shape=rectangle,
			width=2.8194];
		lay11_res2 -> lay11_ln2	[pos="e,440.87,9063.8 440.87,9135.1 440.87,9135.1 440.87,9073.8 440.87,9073.8"];
		layer11_output	[fillcolor=lightyellow,
			height=1.8889,
			label="Output Transfer\nTo: GPU 12\nSize: 524MB\nGPU: 11",
			pos="440.87,8855.3",
			shape=parallelogram,
			width=3.8014];
		lay11_ln2 -> layer11_output	[pos="e,440.87,8923.5 440.87,8995 440.87,8995 440.87,8933.5 440.87,8933.5"];
	}
	subgraph cluster_layer12_gpu12 {
		graph [bb="164.87,6627,678.87,8761.3",
			color=green,
			fillcolor=lightyellow,
			label="Layer 12 on GPU 12\nCache-capacity: 11.8GB",
			lheight=0.42,
			lp="421.87,8742.3",
			lwidth=2.36,
			style="rounded,dashed"
		];
		layer12_input	[fillcolor=lightyellow,
			height=1.8889,
			label="Input Transfer\nFrom: GPU 11\nSize: 524MB\nGPU: 12",
			pos="440.87,8647.3",
			shape=parallelogram,
			width=3.4558];
		lay12_qkv_proj	[fillcolor=lightcoral,
			height=0.94444,
			label="QKV Projection\nInput: [128,10000,4096]\nOutput: [128,10000,32,128]\nGPU: 12",
			pos="403.87,8473.3",
			shape=rectangle,
			width=3.0139];
		layer12_input -> lay12_qkv_proj	[pos="e,414.41,8507.4 414.41,8579.1 414.41,8579.1 414.41,8517.4 414.41,8517.4"];
		lay12_res1	[fillcolor=lightgray,
			height=1.3356,
			label="Residual Add 1\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 12",
			pos="438.87,7899.2",
			width=6.4425];
		layer12_input -> lay12_res1	[pos="e,555.82,7941 555.82,8647.2 555.82,8647.2 555.82,7951 555.82,7951"];
		lay12_attn_score	[fillcolor=lightpink,
			height=0.94444,
			label="Scaled Dot-Product Attention\nInput: [128,10000,32,128], [128,10000,32,128]\nOutput: [128,10000,32,128]\nGPU: 12",
			pos="368.87,8333.3",
			shape=rectangle,
			width=4.9306];
		lay12_qkv_proj -> lay12_attn_score	[pos="e,403.87,8367.7 403.87,8439.1 403.87,8439.1 403.87,8377.7 403.87,8377.7"];
		lay12_attn_concat	[fillcolor=lightpink,
			height=0.94444,
			label="Concat Heads\nInput: [128,10000,32,128]\nOutput: [128,10000,4096]\nGPU: 12",
			pos="386.87,8193.3",
			shape=rectangle,
			width=2.8472];
		lay12_attn_score -> lay12_attn_concat	[pos="e,386.87,8227.7 386.87,8299.1 386.87,8299.1 386.87,8237.7 386.87,8237.7"];
		lay12_attn_out	[fillcolor=lightcoral,
			height=0.94444,
			label="Attention Output Projection\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 12",
			pos="421.87,8053.3",
			shape=rectangle,
			width=2.9861];
		lay12_attn_concat -> lay12_attn_out	[pos="e,401.87,8087.7 401.87,8159.1 401.87,8159.1 401.87,8097.7 401.87,8097.7"];
		lay12_attn_out -> lay12_res1	[pos="e,421.87,7947.4 421.87,8019.1 421.87,8019.1 421.87,7957.4 421.87,7957.4"];
		lay12_ln1	[fillcolor=lightsteelblue,
			height=0.94444,
			label="LayerNorm 1\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 12",
			pos="469.87,7745.2",
			shape=rectangle,
			width=2.8194];
		lay12_res1 -> lay12_ln1	[pos="e,469.87,7779.3 469.87,7851.3 469.87,7851.3 469.87,7789.3 469.87,7789.3"];
		lay12_mlp_gate	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Gate Projection\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nGPU: 12",
			pos="305.87,7605.2",
			shape=rectangle,
			width=2.9444];
		lay12_ln1 -> lay12_mlp_gate	[pos="e,390.12,7639.5 390.12,7710.9 390.12,7710.9 390.12,7649.5 390.12,7649.5"];
		lay12_mlp_up	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Up Projection\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nGPU: 12",
			pos="526.87,7465.2",
			shape=rectangle,
			width=2.9444];
		lay12_ln1 -> lay12_mlp_up	[pos="e,496.12,7499.4 496.12,7711.1 496.12,7711.1 496.12,7509.4 496.12,7509.4"];
		lay12_res2	[fillcolor=lightgray,
			height=1.3356,
			label="Residual Add 2\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 12",
			pos="438.87,7031.1",
			width=6.4425];
		lay12_ln1 -> lay12_res2	[pos="e,651.84,7050.2 571.49,7745 613.17,7745 651.84,7745 651.84,7745 651.84,7745 651.84,7060.2 651.84,7060.2"];
		lay12_mlp_act	[height=0.94444,
			label="GELU Activation\nInput: [128,10000,16384]\nOutput: [128,10000,16384]\nGPU: 12",
			pos="278.87,7465.2",
			shape=rectangle,
			width=2.9444];
		lay12_mlp_gate -> lay12_mlp_act	[pos="e,292.37,7499.5 292.37,7570.9 292.37,7570.9 292.37,7509.5 292.37,7509.5"];
		lay12_mlp_mul	[height=0.94444,
			label="Element-wise Mul\nInput: [128,10000,16384], [128,10000,16384]\nOutput: [128,10000,16384]\nGPU: 12",
			pos="438.87,7325.2",
			shape=rectangle,
			width=4.8056];
		lay12_mlp_up -> lay12_mlp_mul	[pos="e,516.37,7359.5 516.37,7430.9 516.37,7430.9 516.37,7369.5 516.37,7369.5"];
		lay12_mlp_act -> lay12_mlp_mul	[pos="e,325.37,7359.5 325.37,7430.9 325.37,7430.9 325.37,7369.5 325.37,7369.5"];
		lay12_mlp_down	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Down Projection\nInput: [128,10000,16384]\nOutput: [128,10000,4096]\nGPU: 12",
			pos="438.87,7185.2",
			shape=rectangle,
			width=2.8194];
		lay12_mlp_mul -> lay12_mlp_down	[pos="e,438.87,7219.5 438.87,7290.9 438.87,7290.9 438.87,7229.5 438.87,7229.5"];
		lay12_mlp_down -> lay12_res2	[pos="e,438.87,7079.2 438.87,7151 438.87,7151 438.87,7089.2 438.87,7089.2"];
		lay12_ln2	[fillcolor=lightsteelblue,
			height=0.94444,
			label="LayerNorm 2\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 12",
			pos="438.87,6877",
			shape=rectangle,
			width=2.8194];
		lay12_res2 -> lay12_ln2	[pos="e,438.87,6911.5 438.87,6982.8 438.87,6982.8 438.87,6921.5 438.87,6921.5"];
		layer12_output	[fillcolor=lightyellow,
			height=1.8889,
			label="Output Transfer\nTo: GPU 13\nSize: 524MB\nGPU: 12",
			pos="438.87,6703",
			shape=parallelogram,
			width=3.8014];
		lay12_ln2 -> layer12_output	[pos="e,438.87,6771.1 438.87,6842.6 438.87,6842.6 438.87,6781.1 438.87,6781.1"];
	}
	subgraph cluster_layer13_gpu13 {
		graph [bb="172.87,4474.7,686.87,6609",
			color=green,
			fillcolor=lightyellow,
			label="Layer 13 on GPU 13\nCache-capacity: 11.8GB",
			lheight=0.42,
			lp="429.87,6590",
			lwidth=2.36,
			style="rounded,dashed"
		];
		layer13_input	[fillcolor=lightyellow,
			height=1.8889,
			label="Input Transfer\nFrom: GPU 12\nSize: 524MB\nGPU: 13",
			pos="438.87,6495",
			shape=parallelogram,
			width=3.4558];
		lay13_qkv_proj	[fillcolor=lightcoral,
			height=0.94444,
			label="QKV Projection\nInput: [128,10000,4096]\nOutput: [128,10000,32,128]\nGPU: 13",
			pos="438.87,6321",
			shape=rectangle,
			width=3.0139];
		layer13_input -> lay13_qkv_proj	[pos="e,438.87,6355.1 438.87,6426.7 438.87,6426.7 438.87,6365.1 438.87,6365.1"];
		lay13_res1	[fillcolor=lightgray,
			height=1.3356,
			label="Residual Add 1\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 13",
			pos="446.87,5746.9",
			width=6.4425];
		layer13_input -> lay13_res1	[pos="e,557.32,5789.5 557.32,6494.9 557.32,6494.9 557.32,5799.5 557.32,5799.5"];
		lay13_attn_score	[fillcolor=lightpink,
			height=0.94444,
			label="Scaled Dot-Product Attention\nInput: [128,10000,32,128], [128,10000,32,128]\nOutput: [128,10000,32,128]\nGPU: 13",
			pos="373.87,6181",
			shape=rectangle,
			width=4.9306];
		lay13_qkv_proj -> lay13_attn_score	[pos="e,438.87,6215.4 438.87,6286.8 438.87,6286.8 438.87,6225.4 438.87,6225.4"];
		lay13_attn_concat	[fillcolor=lightpink,
			height=0.94444,
			label="Concat Heads\nInput: [128,10000,32,128]\nOutput: [128,10000,4096]\nGPU: 13",
			pos="406.87,6041",
			shape=rectangle,
			width=2.8472];
		lay13_attn_score -> lay13_attn_concat	[pos="e,406.87,6075.4 406.87,6146.8 406.87,6146.8 406.87,6085.4 406.87,6085.4"];
		lay13_attn_out	[fillcolor=lightcoral,
			height=0.94444,
			label="Attention Output Projection\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 13",
			pos="441.87,5901",
			shape=rectangle,
			width=2.9861];
		lay13_attn_concat -> lay13_attn_out	[pos="e,421.87,5935.4 421.87,6006.8 421.87,6006.8 421.87,5945.4 421.87,5945.4"];
		lay13_attn_out -> lay13_res1	[pos="e,441.87,5795 441.87,5866.8 441.87,5866.8 441.87,5805 441.87,5805"];
		lay13_ln1	[fillcolor=lightsteelblue,
			height=0.94444,
			label="LayerNorm 1\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 13",
			pos="477.87,5592.8",
			shape=rectangle,
			width=2.8194];
		lay13_res1 -> lay13_ln1	[pos="e,477.87,5627 477.87,5699 477.87,5699 477.87,5637 477.87,5637"];
		lay13_mlp_gate	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Gate Projection\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nGPU: 13",
			pos="313.87,5452.8",
			shape=rectangle,
			width=2.9444];
		lay13_ln1 -> lay13_mlp_gate	[pos="e,398.12,5487.2 398.12,5558.6 398.12,5558.6 398.12,5497.2 398.12,5497.2"];
		lay13_mlp_up	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Up Projection\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nGPU: 13",
			pos="534.87,5312.8",
			shape=rectangle,
			width=2.9444];
		lay13_ln1 -> lay13_mlp_up	[pos="e,504.12,5347.1 504.12,5558.8 504.12,5558.8 504.12,5357.1 504.12,5357.1"];
		lay13_res2	[fillcolor=lightgray,
			height=1.3356,
			label="Residual Add 2\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 13",
			pos="446.87,4878.7",
			width=6.4425];
		lay13_ln1 -> lay13_res2	[pos="e,659.84,4897.8 579.49,5592 621.17,5592 659.84,5592 659.84,5592 659.84,5592 659.84,4907.8 659.84,4907.8"];
		lay13_mlp_act	[height=0.94444,
			label="GELU Activation\nInput: [128,10000,16384]\nOutput: [128,10000,16384]\nGPU: 13",
			pos="286.87,5312.8",
			shape=rectangle,
			width=2.9444];
		lay13_mlp_gate -> lay13_mlp_act	[pos="e,300.37,5347.2 300.37,5418.6 300.37,5418.6 300.37,5357.2 300.37,5357.2"];
		lay13_mlp_mul	[height=0.94444,
			label="Element-wise Mul\nInput: [128,10000,16384], [128,10000,16384]\nOutput: [128,10000,16384]\nGPU: 13",
			pos="446.87,5172.8",
			shape=rectangle,
			width=4.8056];
		lay13_mlp_up -> lay13_mlp_mul	[pos="e,524.37,5207.2 524.37,5278.6 524.37,5278.6 524.37,5217.2 524.37,5217.2"];
		lay13_mlp_act -> lay13_mlp_mul	[pos="e,333.37,5207.2 333.37,5278.6 333.37,5278.6 333.37,5217.2 333.37,5217.2"];
		lay13_mlp_down	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Down Projection\nInput: [128,10000,16384]\nOutput: [128,10000,4096]\nGPU: 13",
			pos="446.87,5032.8",
			shape=rectangle,
			width=2.8194];
		lay13_mlp_mul -> lay13_mlp_down	[pos="e,446.87,5067.2 446.87,5138.6 446.87,5138.6 446.87,5077.2 446.87,5077.2"];
		lay13_mlp_down -> lay13_res2	[pos="e,446.87,4926.9 446.87,4998.6 446.87,4998.6 446.87,4936.9 446.87,4936.9"];
		lay13_ln2	[fillcolor=lightsteelblue,
			height=0.94444,
			label="LayerNorm 2\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 13",
			pos="446.87,4724.7",
			shape=rectangle,
			width=2.8194];
		lay13_res2 -> lay13_ln2	[pos="e,446.87,4759.1 446.87,4830.4 446.87,4830.4 446.87,4769.1 446.87,4769.1"];
		layer13_output	[fillcolor=lightyellow,
			height=1.8889,
			label="Output Transfer\nTo: GPU 14\nSize: 524MB\nGPU: 13",
			pos="446.87,4550.7",
			shape=parallelogram,
			width=3.8014];
		lay13_ln2 -> layer13_output	[pos="e,446.87,4618.8 446.87,4690.3 446.87,4690.3 446.87,4628.8 446.87,4628.8"];
	}
	subgraph cluster_layer14_gpu14 {
		graph [bb="180.87,2322.3,694.87,4456.7",
			color=green,
			fillcolor=lightyellow,
			label="Layer 14 on GPU 14\nCache-capacity: 11.8GB",
			lheight=0.42,
			lp="437.87,4437.7",
			lwidth=2.36,
			style="rounded,dashed"
		];
		layer14_input	[fillcolor=lightyellow,
			height=1.8889,
			label="Input Transfer\nFrom: GPU 13\nSize: 524MB\nGPU: 14",
			pos="446.87,4342.7",
			shape=parallelogram,
			width=3.4558];
		lay14_qkv_proj	[fillcolor=lightcoral,
			height=0.94444,
			label="QKV Projection\nInput: [128,10000,4096]\nOutput: [128,10000,32,128]\nGPU: 14",
			pos="417.87,4168.7",
			shape=rectangle,
			width=3.0139];
		layer14_input -> lay14_qkv_proj	[pos="e,424.41,4202.8 424.41,4274.4 424.41,4274.4 424.41,4212.8 424.41,4212.8"];
		lay14_res1	[fillcolor=lightgray,
			height=1.3356,
			label="Residual Add 1\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 14",
			pos="454.87,3594.6",
			width=6.4425];
		layer14_input -> lay14_res1	[pos="e,565.82,3636.9 565.82,4342.5 565.82,4342.5 565.82,3646.9 565.82,3646.9"];
		lay14_attn_score	[fillcolor=lightpink,
			height=0.94444,
			label="Scaled Dot-Product Attention\nInput: [128,10000,32,128], [128,10000,32,128]\nOutput: [128,10000,32,128]\nGPU: 14",
			pos="382.87,4028.7",
			shape=rectangle,
			width=4.9306];
		lay14_qkv_proj -> lay14_attn_score	[pos="e,417.87,4063 417.87,4134.4 417.87,4134.4 417.87,4073 417.87,4073"];
		lay14_attn_concat	[fillcolor=lightpink,
			height=0.94444,
			label="Concat Heads\nInput: [128,10000,32,128]\nOutput: [128,10000,4096]\nGPU: 14",
			pos="404.87,3888.7",
			shape=rectangle,
			width=2.8472];
		lay14_attn_score -> lay14_attn_concat	[pos="e,404.87,3923 404.87,3994.4 404.87,3994.4 404.87,3933 404.87,3933"];
		lay14_attn_out	[fillcolor=lightcoral,
			height=0.94444,
			label="Attention Output Projection\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 14",
			pos="439.87,3748.7",
			shape=rectangle,
			width=2.9861];
		lay14_attn_concat -> lay14_attn_out	[pos="e,419.87,3783 419.87,3854.4 419.87,3854.4 419.87,3793 419.87,3793"];
		lay14_attn_out -> lay14_res1	[pos="e,439.87,3642.7 439.87,3714.5 439.87,3714.5 439.87,3652.7 439.87,3652.7"];
		lay14_ln1	[fillcolor=lightsteelblue,
			height=0.94444,
			label="LayerNorm 1\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 14",
			pos="485.87,3440.5",
			shape=rectangle,
			width=2.8194];
		lay14_res1 -> lay14_ln1	[pos="e,485.87,3474.7 485.87,3546.7 485.87,3546.7 485.87,3484.7 485.87,3484.7"];
		lay14_mlp_gate	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Gate Projection\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nGPU: 14",
			pos="321.87,3300.5",
			shape=rectangle,
			width=2.9444];
		lay14_ln1 -> lay14_mlp_gate	[pos="e,406.12,3334.9 406.12,3406.3 406.12,3406.3 406.12,3344.9 406.12,3344.9"];
		lay14_mlp_up	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Up Projection\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nGPU: 14",
			pos="542.87,3160.5",
			shape=rectangle,
			width=2.9444];
		lay14_ln1 -> lay14_mlp_up	[pos="e,512.12,3194.8 512.12,3406.4 512.12,3406.4 512.12,3204.8 512.12,3204.8"];
		lay14_res2	[fillcolor=lightgray,
			height=1.3356,
			label="Residual Add 2\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 14",
			pos="454.87,2726.4",
			width=6.4425];
		lay14_ln1 -> lay14_res2	[pos="e,667.84,2745.5 587.49,3440 629.17,3440 667.84,3440 667.84,3440 667.84,3440 667.84,2755.5 667.84,2755.5"];
		lay14_mlp_act	[height=0.94444,
			label="GELU Activation\nInput: [128,10000,16384]\nOutput: [128,10000,16384]\nGPU: 14",
			pos="294.87,3160.5",
			shape=rectangle,
			width=2.9444];
		lay14_mlp_gate -> lay14_mlp_act	[pos="e,308.37,3194.9 308.37,3266.3 308.37,3266.3 308.37,3204.9 308.37,3204.9"];
		lay14_mlp_mul	[height=0.94444,
			label="Element-wise Mul\nInput: [128,10000,16384], [128,10000,16384]\nOutput: [128,10000,16384]\nGPU: 14",
			pos="454.87,3020.5",
			shape=rectangle,
			width=4.8056];
		lay14_mlp_up -> lay14_mlp_mul	[pos="e,532.37,3054.9 532.37,3126.3 532.37,3126.3 532.37,3064.9 532.37,3064.9"];
		lay14_mlp_act -> lay14_mlp_mul	[pos="e,341.37,3054.9 341.37,3126.3 341.37,3126.3 341.37,3064.9 341.37,3064.9"];
		lay14_mlp_down	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Down Projection\nInput: [128,10000,16384]\nOutput: [128,10000,4096]\nGPU: 14",
			pos="454.87,2880.5",
			shape=rectangle,
			width=2.8194];
		lay14_mlp_mul -> lay14_mlp_down	[pos="e,454.87,2914.9 454.87,2986.3 454.87,2986.3 454.87,2924.9 454.87,2924.9"];
		lay14_mlp_down -> lay14_res2	[pos="e,454.87,2774.5 454.87,2846.3 454.87,2846.3 454.87,2784.5 454.87,2784.5"];
		lay14_ln2	[fillcolor=lightsteelblue,
			height=0.94444,
			label="LayerNorm 2\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 14",
			pos="454.87,2572.3",
			shape=rectangle,
			width=2.8194];
		lay14_res2 -> lay14_ln2	[pos="e,454.87,2606.8 454.87,2678.1 454.87,2678.1 454.87,2616.8 454.87,2616.8"];
		layer14_output	[fillcolor=lightyellow,
			height=1.8889,
			label="Output Transfer\nTo: GPU 15\nSize: 524MB\nGPU: 14",
			pos="454.87,2398.3",
			shape=parallelogram,
			width=3.8014];
		lay14_ln2 -> layer14_output	[pos="e,454.87,2466.5 454.87,2538 454.87,2538 454.87,2476.5 454.87,2476.5"];
	}
	subgraph cluster_layer15_gpu15 {
		graph [bb="161.87,170,675.87,2304.3",
			color=green,
			fillcolor=lightyellow,
			label="Layer 15 on GPU 15\nCache-capacity: 11.8GB",
			lheight=0.42,
			lp="418.87,2285.3",
			lwidth=2.36,
			style="rounded,dashed"
		];
		layer15_input	[fillcolor=lightyellow,
			height=1.8889,
			label="Input Transfer\nFrom: GPU 14\nSize: 524MB\nGPU: 15",
			pos="454.87,2190.3",
			shape=parallelogram,
			width=3.4558];
		lay15_qkv_proj	[fillcolor=lightcoral,
			height=0.94444,
			label="QKV Projection\nInput: [128,10000,4096]\nOutput: [128,10000,32,128]\nGPU: 15",
			pos="428.87,2016.3",
			shape=rectangle,
			width=3.0139];
		layer15_input -> lay15_qkv_proj	[pos="e,433.91,2050.4 433.91,2122.1 433.91,2122.1 433.91,2060.4 433.91,2060.4"];
		lay15_res1	[fillcolor=lightgray,
			height=1.3356,
			label="Residual Add 1\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 15",
			pos="435.87,1442.2",
			width=6.4425];
		layer15_input -> lay15_res1	[pos="e,568.32,1481.9 568.32,2190.2 568.32,2190.2 568.32,1491.9 568.32,1491.9"];
		lay15_attn_score	[fillcolor=lightpink,
			height=0.94444,
			label="Scaled Dot-Product Attention\nInput: [128,10000,32,128], [128,10000,32,128]\nOutput: [128,10000,32,128]\nGPU: 15",
			pos="379.87,1876.3",
			shape=rectangle,
			width=4.9306];
		lay15_qkv_proj -> lay15_attn_score	[pos="e,428.87,1910.7 428.87,1982.1 428.87,1982.1 428.87,1920.7 428.87,1920.7"];
		lay15_attn_concat	[fillcolor=lightpink,
			height=0.94444,
			label="Concat Heads\nInput: [128,10000,32,128]\nOutput: [128,10000,4096]\nGPU: 15",
			pos="409.87,1736.3",
			shape=rectangle,
			width=2.8472];
		lay15_attn_score -> lay15_attn_concat	[pos="e,409.87,1770.7 409.87,1842.1 409.87,1842.1 409.87,1780.7 409.87,1780.7"];
		lay15_attn_out	[fillcolor=lightcoral,
			height=0.94444,
			label="Attention Output Projection\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 15",
			pos="424.87,1596.3",
			shape=rectangle,
			width=2.9861];
		lay15_attn_concat -> lay15_attn_out	[pos="e,414.87,1630.7 414.87,1702.1 414.87,1702.1 414.87,1640.7 414.87,1640.7"];
		lay15_attn_out -> lay15_res1	[pos="e,424.87,1490.4 424.87,1562.1 424.87,1562.1 424.87,1500.4 424.87,1500.4"];
		lay15_ln1	[fillcolor=lightsteelblue,
			height=0.94444,
			label="LayerNorm 1\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 15",
			pos="466.87,1288.2",
			shape=rectangle,
			width=2.8194];
		lay15_res1 -> lay15_ln1	[pos="e,466.87,1322.4 466.87,1394.3 466.87,1394.3 466.87,1332.4 466.87,1332.4"];
		lay15_mlp_gate	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Gate Projection\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nGPU: 15",
			pos="302.87,1148.2",
			shape=rectangle,
			width=2.9444];
		lay15_ln1 -> lay15_mlp_gate	[pos="e,387.12,1182.5 387.12,1253.9 387.12,1253.9 387.12,1192.5 387.12,1192.5"];
		lay15_mlp_up	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Up Projection\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nGPU: 15",
			pos="523.87,1008.2",
			shape=rectangle,
			width=2.9444];
		lay15_ln1 -> lay15_mlp_up	[pos="e,493.12,1042.4 493.12,1254.1 493.12,1254.1 493.12,1052.4 493.12,1052.4"];
		lay15_res2	[fillcolor=lightgray,
			height=1.3356,
			label="Residual Add 2\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 15",
			pos="435.87,574.08",
			width=6.4425];
		lay15_ln1 -> lay15_res2	[pos="e,648.84,593.18 568.49,1288 610.17,1288 648.84,1288 648.84,1288 648.84,1288 648.84,603.18 648.84,603.18"];
		lay15_mlp_act	[height=0.94444,
			label="GELU Activation\nInput: [128,10000,16384]\nOutput: [128,10000,16384]\nGPU: 15",
			pos="275.87,1008.2",
			shape=rectangle,
			width=2.9444];
		lay15_mlp_gate -> lay15_mlp_act	[pos="e,289.37,1042.5 289.37,1113.9 289.37,1113.9 289.37,1052.5 289.37,1052.5"];
		lay15_mlp_mul	[height=0.94444,
			label="Element-wise Mul\nInput: [128,10000,16384], [128,10000,16384]\nOutput: [128,10000,16384]\nGPU: 15",
			pos="435.87,868.17",
			shape=rectangle,
			width=4.8056];
		lay15_mlp_up -> lay15_mlp_mul	[pos="e,513.37,902.55 513.37,973.92 513.37,973.92 513.37,912.55 513.37,912.55"];
		lay15_mlp_act -> lay15_mlp_mul	[pos="e,322.37,902.55 322.37,973.92 322.37,973.92 322.37,912.55 322.37,912.55"];
		lay15_mlp_down	[fillcolor=lightseagreen,
			height=0.94444,
			label="MLP Down Projection\nInput: [128,10000,16384]\nOutput: [128,10000,4096]\nGPU: 15",
			pos="435.87,728.17",
			shape=rectangle,
			width=2.8194];
		lay15_mlp_mul -> lay15_mlp_down	[pos="e,435.87,762.55 435.87,833.92 435.87,833.92 435.87,772.55 435.87,772.55"];
		lay15_mlp_down -> lay15_res2	[pos="e,435.87,622.21 435.87,693.97 435.87,693.97 435.87,632.21 435.87,632.21"];
		lay15_ln2	[fillcolor=lightsteelblue,
			height=0.94444,
			label="LayerNorm 2\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nGPU: 15",
			pos="435.87,420",
			shape=rectangle,
			width=2.8194];
		lay15_res2 -> lay15_ln2	[pos="e,435.87,454.48 435.87,525.75 435.87,525.75 435.87,464.48 435.87,464.48"];
		layer15_output	[fillcolor=lightgreen,
			height=1.8889,
			label="Model Output\nTo: Final Output\nSize: 524MB\nGPU: 15",
			pos="435.87,246",
			shape=parallelogram,
			width=3.8302];
		lay15_ln2 -> layer15_output	[pos="e,435.87,314.14 435.87,385.62 435.87,385.62 435.87,324.14 435.87,324.14"];
	}
	input	[fillcolor=lightgreen,
		height=1.4722,
		label="Model Input\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]",
		pos="475.87,34668",
		shape=parallelogram,
		width=13.219];
	input -> layer0_input	[pos="e,475.87,34544 475.87,34615 475.87,34615 475.87,34554 475.87,34554"];
	layer0_output -> layer1_input	[pos="e,430.87,32391 430.87,32463 430.87,32463 430.87,32401 430.87,32401"];
	layer1_output -> layer2_input	[pos="e,421.87,30239 421.87,30311 421.87,30311 421.87,30249 421.87,30249"];
	layer2_output -> layer3_input	[pos="e,421.87,28087 421.87,28158 421.87,28158 421.87,28097 421.87,28097"];
	layer3_output -> layer4_input	[pos="e,421.87,25934 421.87,26006 421.87,26006 421.87,25944 421.87,25944"];
	layer4_output -> layer5_input	[pos="e,421.87,23782 421.87,23854 421.87,23854 421.87,23792 421.87,23792"];
	layer5_output -> layer6_input	[pos="e,421.87,21630 421.87,21701 421.87,21701 421.87,21640 421.87,21640"];
	layer6_output -> layer7_input	[pos="e,430.87,19477 430.87,19549 430.87,19549 430.87,19487 430.87,19487"];
	layer7_output -> layer8_input	[pos="e,421.87,17325 421.87,17397 421.87,17397 421.87,17335 421.87,17335"];
	layer8_output -> layer9_input	[pos="e,443.87,15173 443.87,15244 443.87,15244 443.87,15183 443.87,15183"];
	layer9_output -> layer10_input	[pos="e,421.87,13020 421.87,13092 421.87,13092 421.87,13030 421.87,13030"];
	layer10_output -> layer11_input	[pos="e,421.87,10868 421.87,10940 421.87,10940 421.87,10878 421.87,10878"];
	layer11_output -> layer12_input	[pos="e,440.87,8715.6 440.87,8787.2 440.87,8787.2 440.87,8725.6 440.87,8725.6"];
	layer12_output -> layer13_input	[pos="e,438.87,6563.3 438.87,6634.9 438.87,6634.9 438.87,6573.3 438.87,6573.3"];
	layer13_output -> layer14_input	[pos="e,446.87,4410.9 446.87,4482.6 446.87,4482.6 446.87,4420.9 446.87,4420.9"];
	layer14_output -> layer15_input	[pos="e,454.87,2258.6 454.87,2330.2 454.87,2330.2 454.87,2268.6 454.87,2268.6"];
	final_output	[fillcolor=lightgreen,
		height=1.4722,
		label="Final Model Output\nInput: [128,10000,4096]\nOutput: [128,10000,4096]",
		pos="435.87,53",
		shape=parallelogram,
		width=5.8461];
	layer15_output -> final_output	[pos="e,435.87,106.19 435.87,177.96 435.87,177.96 435.87,116.19 435.87,116.19"];
}
