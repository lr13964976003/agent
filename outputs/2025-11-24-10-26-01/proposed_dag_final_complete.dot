digraph proposed_layer_wise_final {
    graph [rankdir=TB, splines=ortho, nodesep=0.3, ranksep=0.8];
    node [shape=box, style=filled, fontsize=10];
    
    // Input node
    input [label="Model Input\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]", 
           shape=parallelogram, fillcolor=lightgreen];

    // Output node
    output [label="Model Output\nInput: [batch_size=128, seq_len=10000, hidden_size=4096]\nOutput: [batch_size=128, seq_len=10000, hidden_size=4096]", 
            shape=parallelogram, fillcolor=lightgreen];

    // Transfer nodes between GPUs
    t0_1 [label="Transfer\nGPU: 0 → 1\nSize: 5.24GB\nInput: [128,10000,4096]\nOutput: [128,10000,4096]", 
         shape=ellipse, fillcolor=lightblue, style=dashed];
    t1_2 [label="Transfer\nGPU: 1 → 2\nSize: 5.24GB\nInput: [128,10000,4096]\nOutput: [128,10000,4096]", 
         shape=ellipse, fillcolor=lightblue, style=dashed];
    t2_3 [label="Transfer\nGPU: 2 → 3\nSize: 5.24GB\nInput: [128,10000,4096]\nOutput: [128,10000,4096]", 
         shape=ellipse, fillcolor=lightblue, style=dashed];
    t3_4 [label="Transfer\nGPU: 3 → 4\nSize: 5.24GB\nInput: [128,10000,4096]\nOutput: [128,10000,4096]", 
         shape=ellipse, fillcolor=lightblue, style=dashed];
    t4_5 [label="Transfer\nGPU: 4 → 5\nSize: 5.24GB\nInput: [128,10000,4096]\nOutput: [128,10000,4096]", 
         shape=ellipse, fillcolor=lightblue, style=dashed];
    t5_6 [label="Transfer\nGPU: 5 → 6\nSize: 5.24GB\nInput: [128,10000,4096]\nOutput: [128,10000,4096]", 
         shape=ellipse, fillcolor=lightblue, style=dashed];
    t6_7 [label="Transfer\nGPU: 6 → 7\nSize: 5.24GB\nInput: [128,10000,4096]\nOutput: [128,10000,4096]", 
         shape=ellipse, fillcolor=lightblue, style=dashed];
    t7_8 [label="Transfer\nGPU: 7 → 8\nSize: 5.24GB\nInput: [128,10000,4096]\nOutput: [128,10000,4096]", 
         shape=ellipse, fillcolor=lightblue, style=dashed];
    t8_9 [label="Transfer\nGPU: 8 → 9\nSize: 5.24GB\nInput: [128,10000,4096]\nOutput: [128,10000,4096]", 
         shape=ellipse, fillcolor=lightblue, style=dashed];
    t9_10 [label="Transfer\nGPU: 9 → 10\nSize: 5.24GB\nInput: [128,10000,4096]\nOutput: [128,10000,4096]", 
          shape=ellipse, fillcolor=lightblue, style=dashed];
    t10_11 [label="Transfer\nGPU: 10 → 11\nSize: 5.24GB\nInput: [128,10000,4096]\nOutput: [128,10000,4096]", 
           shape=ellipse, fillcolor=lightblue, style=dashed];
    t11_12 [label="Transfer\nGPU: 11 → 12\nSize: 5.24GB\nInput: [128,10000,4096]\nOutput: [128,10000,4096]", 
           shape=ellipse, fillcolor=lightblue, style=dashed];
    t12_13 [label="Transfer\nGPU: 12 → 13\nSize: 5.24GB\nInput: [128,10000,4096]\nOutput: [128,10000,4096]", 
           shape=ellipse, fillcolor=lightblue, style=dashed];
    t13_14 [label="Transfer\nGPU: 13 → 14\nSize: 5.24GB\nInput: [128,10000,4096]\nOutput: [128,10000,4096]", 
           shape=ellipse, fillcolor=lightblue, style=dashed];
    t14_15 [label="Transfer\nGPU: 14 → 15\nSize: 5.24GB\nInput: [128,10000,4096]\nOutput: [128,10000,4096]", 
           shape=ellipse, fillcolor=lightblue, style=dashed];

    // Define all 16 layers with complete operator detail
    // Layer 0 on GPU 0
    l0_qkv [label="QKV Projection\nGPU: 0\nInput: [128,10000,4096]\nOutput: [128,10000,32,128]\nWeights: 1.56GB", 
           fillcolor=lightcoral];
    l0_attn [label="Multi-Head Attention\nGPU: 0\nInput: [128,10000,32,128]\nOutput: [128,10000,4096]\nActivations: 10.49GB", 
            fillcolor=lightpink];
    l0_out [label="Output Projection\nGPU: 0\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nWeights: 1.56GB", 
           fillcolor=lightcoral];
    l0_res1 [label="Residual Add 1\nGPU: 0\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]", 
            fillcolor=lightgray];
    l0_norm1 [label="Layer Norm 1\nGPU: 0\nInput: [128,10000,4096]\nOutput: [128,10000,4096]", 
             fillcolor=lightyellow];
    
    l0_mlp_gate [label="MLP Gate\nGPU: 0\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nWeights: 1.56GB", 
                fillcolor=lightseagreen];
    l0_mlp_up [label="MLP Up\nGPU: 0\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nWeights: 1.56GB", 
              fillcolor=lightseagreen];
    l0_act [label="GELU Activation\nGPU: 0\nInput: [128,10000,16384]\nOutput: [128,10000,16384]", 
           fillcolor=lightcyan];
    l0_mlp_down [label="MLP Down\nGPU: 0\nInput: [128,10000,16384]\nOutput: [128,10000,4096]\nWeights: 1.56GB", 
                fillcolor=lightseagreen];
    l0_res2 [label="Residual Add 2\nGPU: 0\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]", 
            fillcolor=lightgray];
    l0_norm2 [label="Layer Norm 2\nGPU: 0\nInput: [128,10000,4096]\nOutput: [128,10000,4096]", 
             fillcolor=lightyellow];

    // Layer 1 on GPU 1
    l1_qkv [label="QKV Projection\nGPU: 1\nInput: [128,10000,4096]\nOutput: [128,10000,32,128]\nWeights: 1.56GB", 
           fillcolor=lightcoral];
    l1_attn [label="Multi-Head Attention\nGPU: 1\nInput: [128,10000,32,128]\nOutput: [128,10000,4096]\nActivations: 10.49GB", 
            fillcolor=lightpink];
    l1_out [label="Output Projection\nGPU: 1\nInput: [128,10000,4096]\nOutput: [128,10000,4096]\nWeights: 1.56GB", 
           fillcolor=lightcoral];
    l1_res1 [label="Residual Add 1\nGPU: 1\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]", 
            fillcolor=lightgray];
    l1_norm1 [label="Layer Norm 1\nGPU: 1\nInput: [128,10000,4096]\nOutput: [128,10000,4096]", 
             fillcolor=lightyellow];
    
    l1_mlp_gate [label="MLP Gate\nGPU: 1\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nWeights: 1.56GB", 
                fillcolor=lightseagreen];
    l1_mlp_up [label="MLP Up\nGPU: 1\nInput: [128,10000,4096]\nOutput: [128,10000,16384]\nWeights: 1.56GB", 
              fillcolor=lightseagreen];
    l1_act [label="GELU Activation\nGPU: 1\nInput: [128,10000,16384]\nOutput: [128,10000,16384]", 
           fillcolor=lightcyan];
    l1_mlp_down [label="MLP Down\nGPU: 1\nInput: [128,10000,16384]\nOutput: [128,10000,4096]\nWeights: 1.56GB", 
                fillcolor=lightseagreen];
    l1_res2 [label="Residual Add 2\nGPU: 1\nInput: [128,10000,4096], [128,10000,4096]\nOutput: [128,10000,4096]", 
            fillcolor=lightgray];
    l1_norm2 [label="Layer Norm 2\nGPU: 1\nInput: [128,10000,4096]\nOutput: [128,10000,4096]", 
             fillcolor=lightyellow];

    // Layer 2 on GPU 2
    l2_qkv [label="QKV Projection\nGPU: 2\nInput: [128,10000,4096]\nOutput: [128,10000,32,128]\nWeights: 1.56GB", 
           fillcolor=lightcoral];
    l2_attn [label=