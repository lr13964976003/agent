digraph proposed_layer_wise_simple {
    graph [rankdir=TB, splines=ortho, nodesep=0.5, ranksep=1.0];
    node [shape=ellipse, style=filled, fillcolor=lightblue];
    
    // Input
    input [label="Input\n[batch_size=128, seq_len=10000, hidden_size=4096]", 
           shape=parallelogram, fillcolor=lightgreen];
    
    // Output
    output [label="Output\n[batch_size=128, seq_len=10000, hidden_size=4096]", 
            shape=parallelogram, fillcolor=lightgreen];
    
    // Define all layers with simplified structure
    layer0 [label="Layer 0\nGPU 0\nAttention + MLP\nCache-optimized", 
            shape=rectangle, fillcolor=lightcoral];
    layer1 [label="Layer 1\nGPU 1\nAttention + MLP\nCache-optimized", 
            shape=rectangle, fillcolor=lightcoral];
    layer2 [label="Layer 2\nGPU 2\nAttention + MLP\nCache-optimized", 
            shape=rectangle, fillcolor=lightcoral];
    layer3 [label="Layer 3\nGPU 3\nAttention + MLP\nCache-optimized", 
            shape=rectangle, fillcolor=lightcoral];
    layer4 [label="Layer 4\nGPU 4\nAttention + MLP\nCache-optimized", 
            shape=rectangle, fillcolor=lightcoral];
    layer5 [label="Layer 5\nGPU 5\nAttention + MLP\nCache-optimized", 
            shape=rectangle, fillcolor=lightcoral];
    layer6 [label="Layer 6\nGPU 6\nAttention + MLP\nCache-optimized", 
            shape=rectangle, fillcolor=lightcoral];
    layer7 [label="Layer 7\nGPU 7\nAttention + MLP\nCache-optimized", 
            shape=rectangle, fillcolor=lightcoral];
    layer8 [label="Layer 8\nGPU 8\nAttention + MLP\nCache-optimized", 
            shape=rectangle, fillcolor=lightcoral];
    layer9 [label="Layer 9\nGPU 9\nAttention + MLP\nCache-optimized", 
            shape=rectangle, fillcolor=lightcoral];
    layer10 [label="Layer 10\nGPU 10\nAttention + MLP\nCache-optimized", 
             shape=rectangle, fillcolor=lightcoral];
    layer11 [label="Layer 11\nGPU 11\nAttention + MLP\nCache-optimized", 
             shape=rectangle, fillcolor=lightcoral];
    layer12 [label="Layer 12\nGPU 12\nAttention + MLP\nCache-optimized", 
             shape=rectangle, fillcolor=lightcoral];
    layer13 [label="Layer 13\nGPU 13\nAttention + MLP\nCache-optimized", 
             shape=rectangle, fillcolor=lightcoral];
    layer14 [label="Layer 14\nGPU 14\nAttention + MLP\nCache-optimized", 
             shape=rectangle, fillcolor=lightcoral];
    layer15 [label="Layer 15\nGPU 15\nAttention + MLP\nCache-optimized", 
             shape=rectangle, fillcolor=lightcoral];
    
    // Transfer nodes
    transfer01 [label="Transfer\nSize: 5.24GB", 
                shape=ellipse, fillcolor=lightblue, style=dashed];
    transfer12 [label="Transfer\nSize: 5.24GB", 
                shape=ellipse, fillcolor=lightblue, style=dashed];
    transfer23 [label="Transfer\nSize: 5.24GB", 
                shape=ellipse, fillcolor=lightblue, style=dashed];
    transfer34 [label="Transfer\nSize: 5.24GB", 
                shape=ellipse, fillcolor=lightblue, style=dashed];
    transfer45 [label="Transfer\nSize: 5.24GB", 
                shape=ellipse, fillcolor=lightblue, style=dashed];
    transfer56 [label="Transfer\nSize: 5.24GB", 
                shape=ellipse, fillcolor=lightblue, style=dashed];
    transfer67 [label="Transfer\nSize: 5.24GB", 
                shape=ellipse, fillcolor=lightblue, style=dashed];
    transfer78 [label="Transfer\nSize: 5.24GB", 
                shape=ellipse, fillcolor=lightblue, style=dashed];
    transfer89 [label="Transfer\nSize: 5.24GB", 
                shape=ellipse, fillcolor=lightblue, style=dashed];
    transfer910 [label="Transfer\nSize: 5.24GB", 
                 shape=ellipse, fillcolor=lightblue, style=dashed];
    transfer1011 [label="Transfer\nSize: 5.24GB", 
                  shape=ellipse, fillcolor=lightblue, style=dashed];
    transfer1112 [label="Transfer\nSize: 5.24GB", 
                  shape=ellipse, fillcolor=lightblue, style=dashed];
    transfer1213 [label="Transfer\nSize: 5.24GB", 
                  shape=ellipse, fillcolor=lightblue, style=dashed];
    transfer1314 [label="Transfer\nSize: 5.24GB", 
                  shape=ellipse, fillcolor=lightblue, style=dashed];
    transfer1415 [label="Transfer\nSize: 5.24GB", 
                  shape=ellipse, fillcolor=lightblue, style=dashed];
    
    // Connections
    input -> layer0;
    layer0 -> transfer01;
    transfer01 -> layer1;
    layer1 -> transfer12;
    transfer12 -> layer2;
    layer2 -> transfer23;
    transfer23 -> layer3;
    layer3 -> transfer34;
    transfer34 -> layer4;
    layer4 -> transfer45;
    transfer45 -> layer5;
    layer5 -> transfer56;
    transfer56 -> layer6;
    layer6 -> transfer67;
    transfer67 -> layer7;
    layer7 -> transfer78;
    transfer78 -> layer8;
    layer8 -> transfer89;
    transfer89 -> layer9;
    layer9 -> transfer910;
    transfer910 -> layer10;
    layer10 -> transfer1011;
    transfer1011 -> layer11;
    layer11 -> transfer1112;
    transfer1112 -> layer12;
    layer12 -> transfer1213;
    transfer1213 -> layer13;
    layer13 -> transfer1314;
    transfer1314 -> layer14;
    layer14 -> transfer1415;
    transfer1415 -> layer15;
    layer15 -> output;
}