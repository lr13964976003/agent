// Current Strategy: EP64-TP8-PP2-DP2
digraph {
	nodesep=0.5 rankdir=TB ranksep=1.0
	node [fillcolor=lightblue shape=rectangle style=filled]
	node [fillcolor=lightgreen shape=ellipse style=filled]
	node [fillcolor=lightyellow shape=parallelogram style=filled]
	input [label="Input\n[batch_size=128, seq_len=1024, hidden=1024]" fillcolor=white shape=ellipse]
	subgraph cluster_stage0 {
		fillcolor=lightgray label="Pipeline Stage 0 (Layers 0-7)\nGPUs: 0-1023" style="rounded,filled"
		layer0_attn_qkv_tp [label="Layer 0 Attention QKV\nTP8 [GPUs: 0-7]\nInput: [128,1024,1024]\nOutput: [128,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_attn_out_tp [label="Layer 0 Attention Output\nTP8 [GPUs: 0-7]\nInput: [128,1024,1024]\nOutput: [128,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_route [label="Layer 0 Expert Routing\nEP64 [GPUs: 0-63]\nInput: [128,1024,1024]\nOutput: [128,1024,1024]" fillcolor=lightyellow shape=parallelogram]
		layer0_expert_0 [label="Expert 0\nEP64 [GPUs: 0-15]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_1 [label="Expert 1\nEP64 [GPUs: 16-31]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_2 [label="Expert 2\nEP64 [GPUs: 32-47]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_3 [label="Expert 3\nEP64 [GPUs: 48-63]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_4 [label="Expert 4\nEP64 [GPUs: 64-79]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_5 [label="Expert 5\nEP64 [GPUs: 80-95]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_6 [label="Expert 6\nEP64 [GPUs: 96-111]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_7 [label="Expert 7\nEP64 [GPUs: 112-127]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_8 [label="Expert 8\nEP64 [GPUs: 128-143]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_9 [label="Expert 9\nEP64 [GPUs: 144-159]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_10 [label="Expert 10\nEP64 [GPUs: 160-175]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_11 [label="Expert 11\nEP64 [GPUs: 176-191]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_12 [label="Expert 12\nEP64 [GPUs: 192-207]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_13 [label="Expert 13\nEP64 [GPUs: 208-223]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_14 [label="Expert 14\nEP64 [GPUs: 224-239]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_15 [label="Expert 15\nEP64 [GPUs: 240-255]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_16 [label="Expert 16\nEP64 [GPUs: 256-271]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_17 [label="Expert 17\nEP64 [GPUs: 272-287]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_18 [label="Expert 18\nEP64 [GPUs: 288-303]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_19 [label="Expert 19\nEP64 [GPUs: 304-319]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_20 [label="Expert 20\nEP64 [GPUs: 320-335]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_21 [label="Expert 21\nEP64 [GPUs: 336-351]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_22 [label="Expert 22\nEP64 [GPUs: 352-367]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_23 [label="Expert 23\nEP64 [GPUs: 368-383]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_24 [label="Expert 24\nEP64 [GPUs: 384-399]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_25 [label="Expert 25\nEP64 [GPUs: 400-415]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_26 [label="Expert 26\nEP64 [GPUs: 416-431]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_27 [label="Expert 27\nEP64 [GPUs: 432-447]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_28 [label="Expert 28\nEP64 [GPUs: 448-463]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_29 [label="Expert 29\nEP64 [GPUs: 464-479]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_30 [label="Expert 30\nEP64 [GPUs: 480-495]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_31 [label="Expert 31\nEP64 [GPUs: 496-511]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_32 [label="Expert 32\nEP64 [GPUs: 512-527]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_33 [label="Expert 33\nEP64 [GPUs: 528-543]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_34 [label="Expert 34\nEP64 [GPUs: 544-559]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_35 [label="Expert 35\nEP64 [GPUs: 560-575]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_36 [label="Expert 36\nEP64 [GPUs: 576-591]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_37 [label="Expert 37\nEP64 [GPUs: 592-607]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_38 [label="Expert 38\nEP64 [GPUs: 608-623]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_39 [label="Expert 39\nEP64 [GPUs: 624-639]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_40 [label="Expert 40\nEP64 [GPUs: 640-655]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_41 [label="Expert 41\nEP64 [GPUs: 656-671]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_42 [label="Expert 42\nEP64 [GPUs: 672-687]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_43 [label="Expert 43\nEP64 [GPUs: 688-703]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_44 [label="Expert 44\nEP64 [GPUs: 704-719]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_45 [label="Expert 45\nEP64 [GPUs: 720-735]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_46 [label="Expert 46\nEP64 [GPUs: 736-751]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_47 [label="Expert 47\nEP64 [GPUs: 752-767]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_48 [label="Expert 48\nEP64 [GPUs: 768-783]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_49 [label="Expert 49\nEP64 [GPUs: 784-799]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_50 [label="Expert 50\nEP64 [GPUs: 800-815]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_51 [label="Expert 51\nEP64 [GPUs: 816-831]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_52 [label="Expert 52\nEP64 [GPUs: 832-847]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_53 [label="Expert 53\nEP64 [GPUs: 848-863]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_54 [label="Expert 54\nEP64 [GPUs: 864-879]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_55 [label="Expert 55\nEP64 [GPUs: 880-895]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_56 [label="Expert 56\nEP64 [GPUs: 896-911]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_57 [label="Expert 57\nEP64 [GPUs: 912-927]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_58 [label="Expert 58\nEP64 [GPUs: 928-943]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_59 [label="Expert 59\nEP64 [GPUs: 944-959]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_60 [label="Expert 60\nEP64 [GPUs: 960-975]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_61 [label="Expert 61\nEP64 [GPUs: 976-991]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_62 [label="Expert 62\nEP64 [GPUs: 992-1007]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_63 [label="Expert 63\nEP64 [GPUs: 1008-1023]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_combine [label="Layer 0 Expert Combine\nEP64 [GPUs: 0-63]\nInput: [128,1024,1024]\nOutput: [128,1024,1024]" fillcolor=lightyellow shape=parallelogram]
		layer0_attn_allreduce [label="Attention All-Reduce\nTP8 [GPUs: 0-7]" fillcolor=lightgreen shape=ellipse]
		layer0_moe_alltoall [label="MoE All-to-All\nEP64 [GPUs: 0-63]" fillcolor=lightgreen shape=ellipse]
	}
	subgraph cluster_stage1 {
		fillcolor=lightgray label="Pipeline Stage 1 (Layers 8-15)\nGPUs: 1024-2047" style="rounded,filled"
		layer8_attn_qkv_tp [label="Layer 8 Attention QKV\nTP8 [GPUs: 1024-1031]\nInput: [128,1024,1024]\nOutput: [128,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_attn_out_tp [label="Layer 8 Attention Output\nTP8 [GPUs: 1024-1031]\nInput: [128,1024,1024]\nOutput: [128,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_route [label="Layer 8 Expert Routing\nEP64 [GPUs: 1024-1087]\nInput: [128,1024,1024]\nOutput: [128,1024,1024]" fillcolor=lightyellow shape=parallelogram]
		layer8_expert_0 [label="Expert 0\nEP64 [GPUs: 1024-1039]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_1 [label="Expert 1\nEP64 [GPUs: 1040-1055]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_2 [label="Expert 2\nEP64 [GPUs: 1056-1071]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_3 [label="Expert 3\nEP64 [GPUs: 1072-1087]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_4 [label="Expert 4\nEP64 [GPUs: 1088-1103]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_5 [label="Expert 5\nEP64 [GPUs: 1104-1119]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_6 [label="Expert 6\nEP64 [GPUs: 1120-1135]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_7 [label="Expert 7\nEP64 [GPUs: 1136-1151]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_8 [label="Expert 8\nEP64 [GPUs: 1152-1167]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_9 [label="Expert 9\nEP64 [GPUs: 1168-1183]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_10 [label="Expert 10\nEP64 [GPUs: 1184-1199]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_11 [label="Expert 11\nEP64 [GPUs: 1200-1215]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_12 [label="Expert 12\nEP64 [GPUs: 1216-1231]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_13 [label="Expert 13\nEP64 [GPUs: 1232-1247]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_14 [label="Expert 14\nEP64 [GPUs: 1248-1263]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_15 [label="Expert 15\nEP64 [GPUs: 1264-1279]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_16 [label="Expert 16\nEP64 [GPUs: 1280-1295]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_17 [label="Expert 17\nEP64 [GPUs: 1296-1311]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_18 [label="Expert 18\nEP64 [GPUs: 1312-1327]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_19 [label="Expert 19\nEP64 [GPUs: 1328-1343]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_20 [label="Expert 20\nEP64 [GPUs: 1344-1359]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_21 [label="Expert 21\nEP64 [GPUs: 1360-1375]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_22 [label="Expert 22\nEP64 [GPUs: 1376-1391]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_23 [label="Expert 23\nEP64 [GPUs: 1392-1407]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_24 [label="Expert 24\nEP64 [GPUs: 1408-1423]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_25 [label="Expert 25\nEP64 [GPUs: 1424-1439]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_26 [label="Expert 26\nEP64 [GPUs: 1440-1455]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_27 [label="Expert 27\nEP64 [GPUs: 1456-1471]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_28 [label="Expert 28\nEP64 [GPUs: 1472-1487]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_29 [label="Expert 29\nEP64 [GPUs: 1488-1503]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_30 [label="Expert 30\nEP64 [GPUs: 1504-1519]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_31 [label="Expert 31\nEP64 [GPUs: 1520-1535]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_32 [label="Expert 32\nEP64 [GPUs: 1536-1551]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_33 [label="Expert 33\nEP64 [GPUs: 1552-1567]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_34 [label="Expert 34\nEP64 [GPUs: 1568-1583]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_35 [label="Expert 35\nEP64 [GPUs: 1584-1599]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_36 [label="Expert 36\nEP64 [GPUs: 1600-1615]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_37 [label="Expert 37\nEP64 [GPUs: 1616-1631]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_38 [label="Expert 38\nEP64 [GPUs: 1632-1647]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_39 [label="Expert 39\nEP64 [GPUs: 1648-1663]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_40 [label="Expert 40\nEP64 [GPUs: 1664-1679]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_41 [label="Expert 41\nEP64 [GPUs: 1680-1695]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_42 [label="Expert 42\nEP64 [GPUs: 1696-1711]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_43 [label="Expert 43\nEP64 [GPUs: 1712-1727]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_44 [label="Expert 44\nEP64 [GPUs: 1728-1743]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_45 [label="Expert 45\nEP64 [GPUs: 1744-1759]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_46 [label="Expert 46\nEP64 [GPUs: 1760-1775]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_47 [label="Expert 47\nEP64 [GPUs: 1776-1791]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_48 [label="Expert 48\nEP64 [GPUs: 1792-1807]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_49 [label="Expert 49\nEP64 [GPUs: 1808-1823]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_50 [label="Expert 50\nEP64 [GPUs: 1824-1839]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_51 [label="Expert 51\nEP64 [GPUs: 1840-1855]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_52 [label="Expert 52\nEP64 [GPUs: 1856-1871]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_53 [label="Expert 53\nEP64 [GPUs: 1872-1887]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_54 [label="Expert 54\nEP64 [GPUs: 1888-1903]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_55 [label="Expert 55\nEP64 [GPUs: 1904-1919]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_56 [label="Expert 56\nEP64 [GPUs: 1920-1935]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_57 [label="Expert 57\nEP64 [GPUs: 1936-1951]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_58 [label="Expert 58\nEP64 [GPUs: 1952-1967]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_59 [label="Expert 59\nEP64 [GPUs: 1968-1983]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_60 [label="Expert 60\nEP64 [GPUs: 1984-1999]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_61 [label="Expert 61\nEP64 [GPUs: 2000-2015]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_62 [label="Expert 62\nEP64 [GPUs: 2016-2031]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_63 [label="Expert 63\nEP64 [GPUs: 2032-2047]\nInput: [2,1024,1024]\nOutput: [2,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_combine [label="Layer 8 Expert Combine\nEP64 [GPUs: 1024-1087]\nInput: [128,1024,1024]\nOutput: [128,1024,1024]" fillcolor=lightyellow shape=parallelogram]
		layer8_attn_allreduce [label="Attention All-Reduce\nTP8 [GPUs: 1024-1031]" fillcolor=lightgreen shape=ellipse]
		layer8_moe_alltoall [label="MoE All-to-All\nEP64 [GPUs: 1024-1087]" fillcolor=lightgreen shape=ellipse]
	}
	output [label="Output\n[batch_size=128, seq_len=1024, hidden=1024]" fillcolor=white shape=ellipse]
	input -> layer0_attn_qkv_tp
	layer0_attn_qkv_tp -> layer0_attn_allreduce
	layer0_attn_allreduce -> layer0_attn_out_tp
	layer0_attn_out_tp -> layer0_route
	layer0_route -> layer0_moe_alltoall
	layer0_moe_alltoall -> layer0_expert_0
	layer0_expert_0 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_1
	layer0_expert_1 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_2
	layer0_expert_2 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_3
	layer0_expert_3 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_4
	layer0_expert_4 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_5
	layer0_expert_5 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_6
	layer0_expert_6 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_7
	layer0_expert_7 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_8
	layer0_expert_8 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_9
	layer0_expert_9 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_10
	layer0_expert_10 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_11
	layer0_expert_11 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_12
	layer0_expert_12 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_13
	layer0_expert_13 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_14
	layer0_expert_14 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_15
	layer0_expert_15 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_16
	layer0_expert_16 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_17
	layer0_expert_17 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_18
	layer0_expert_18 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_19
	layer0_expert_19 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_20
	layer0_expert_20 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_21
	layer0_expert_21 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_22
	layer0_expert_22 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_23
	layer0_expert_23 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_24
	layer0_expert_24 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_25
	layer0_expert_25 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_26
	layer0_expert_26 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_27
	layer0_expert_27 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_28
	layer0_expert_28 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_29
	layer0_expert_29 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_30
	layer0_expert_30 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_31
	layer0_expert_31 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_32
	layer0_expert_32 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_33
	layer0_expert_33 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_34
	layer0_expert_34 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_35
	layer0_expert_35 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_36
	layer0_expert_36 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_37
	layer0_expert_37 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_38
	layer0_expert_38 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_39
	layer0_expert_39 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_40
	layer0_expert_40 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_41
	layer0_expert_41 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_42
	layer0_expert_42 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_43
	layer0_expert_43 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_44
	layer0_expert_44 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_45
	layer0_expert_45 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_46
	layer0_expert_46 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_47
	layer0_expert_47 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_48
	layer0_expert_48 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_49
	layer0_expert_49 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_50
	layer0_expert_50 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_51
	layer0_expert_51 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_52
	layer0_expert_52 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_53
	layer0_expert_53 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_54
	layer0_expert_54 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_55
	layer0_expert_55 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_56
	layer0_expert_56 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_57
	layer0_expert_57 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_58
	layer0_expert_58 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_59
	layer0_expert_59 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_60
	layer0_expert_60 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_61
	layer0_expert_61 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_62
	layer0_expert_62 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_63
	layer0_expert_63 -> layer0_combine [style=dashed]
	layer0_combine -> layer8_attn_qkv_tp [lhead=cluster_stage1]
	layer8_attn_qkv_tp -> layer8_attn_allreduce
	layer8_attn_allreduce -> layer8_attn_out_tp
	layer8_attn_out_tp -> layer8_route
	layer8_route -> layer8_moe_alltoall
	layer8_moe_alltoall -> layer8_expert_0
	layer8_expert_0 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_1
	layer8_expert_1 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_2
	layer8_expert_2 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_3
	layer8_expert_3 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_4
	layer8_expert_4 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_5
	layer8_expert_5 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_6
	layer8_expert_6 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_7
	layer8_expert_7 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_8
	layer8_expert_8 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_9
	layer8_expert_9 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_10
	layer8_expert_10 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_11
	layer8_expert_11 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_12
	layer8_expert_12 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_13
	layer8_expert_13 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_14
	layer8_expert_14 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_15
	layer8_expert_15 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_16
	layer8_expert_16 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_17
	layer8_expert_17 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_18
	layer8_expert_18 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_19
	layer8_expert_19 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_20
	layer8_expert_20 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_21
	layer8_expert_21 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_22
	layer8_expert_22 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_23
	layer8_expert_23 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_24
	layer8_expert_24 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_25
	layer8_expert_25 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_26
	layer8_expert_26 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_27
	layer8_expert_27 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_28
	layer8_expert_28 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_29
	layer8_expert_29 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_30
	layer8_expert_30 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_31
	layer8_expert_31 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_32
	layer8_expert_32 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_33
	layer8_expert_33 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_34
	layer8_expert_34 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_35
	layer8_expert_35 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_36
	layer8_expert_36 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_37
	layer8_expert_37 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_38
	layer8_expert_38 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_39
	layer8_expert_39 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_40
	layer8_expert_40 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_41
	layer8_expert_41 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_42
	layer8_expert_42 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_43
	layer8_expert_43 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_44
	layer8_expert_44 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_45
	layer8_expert_45 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_46
	layer8_expert_46 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_47
	layer8_expert_47 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_48
	layer8_expert_48 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_49
	layer8_expert_49 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_50
	layer8_expert_50 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_51
	layer8_expert_51 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_52
	layer8_expert_52 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_53
	layer8_expert_53 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_54
	layer8_expert_54 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_55
	layer8_expert_55 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_56
	layer8_expert_56 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_57
	layer8_expert_57 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_58
	layer8_expert_58 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_59
	layer8_expert_59 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_60
	layer8_expert_60 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_61
	layer8_expert_61 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_62
	layer8_expert_62 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_63
	layer8_expert_63 -> layer8_combine [style=dashed]
	layer8_combine -> output
}
