// Optimal Strategy: EP32-TP4-PP4-DP8
digraph {
	nodesep=0.5 rankdir=TB ranksep=1.0
	node [fillcolor=lightblue shape=rectangle style=filled]
	node [fillcolor=lightgreen shape=ellipse style=filled]
	node [fillcolor=lightyellow shape=parallelogram style=filled]
	input [label="Input\n[batch_size=128, seq_len=1024, hidden=1024]\nDP8: 16 seqs per GPU" fillcolor=white shape=ellipse]
	subgraph cluster_stage0 {
		fillcolor=lightgray label="Pipeline Stage 0 (Layers 0-3)\nGPUs: 0-127" style="rounded,filled"
		layer0_attn_qkv_tp [label="Layer 0 Attention QKV\nTP4 [GPUs: 0-3]\nInput: [16,1024,1024]\nOutput: [16,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_attn_score [label="Layer 0 Attention Score\nTP4 [GPUs: 0-3]\nInput: [16,16,1024,64]\nOutput: [16,16,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_attn_out_tp [label="Layer 0 Attention Output\nTP4 [GPUs: 0-3]\nInput: [16,1024,1024]\nOutput: [16,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_route [label="Layer 0 Expert Routing\nEP32 [GPUs: 0-31]\nInput: [16,1024,1024]\nOutput: [16,1024,1024]" fillcolor=lightyellow shape=parallelogram]
		layer0_expert_group_0 [label="Expert Group 0\n(2 experts)\nEP32 [GPUs: 0-3]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_group_1 [label="Expert Group 1\n(2 experts)\nEP32 [GPUs: 4-7]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_group_2 [label="Expert Group 2\n(2 experts)\nEP32 [GPUs: 8-11]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_group_3 [label="Expert Group 3\n(2 experts)\nEP32 [GPUs: 12-15]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_group_4 [label="Expert Group 4\n(2 experts)\nEP32 [GPUs: 16-19]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_group_5 [label="Expert Group 5\n(2 experts)\nEP32 [GPUs: 20-23]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_group_6 [label="Expert Group 6\n(2 experts)\nEP32 [GPUs: 24-27]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_group_7 [label="Expert Group 7\n(2 experts)\nEP32 [GPUs: 28-31]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_group_8 [label="Expert Group 8\n(2 experts)\nEP32 [GPUs: 32-35]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_group_9 [label="Expert Group 9\n(2 experts)\nEP32 [GPUs: 36-39]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_group_10 [label="Expert Group 10\n(2 experts)\nEP32 [GPUs: 40-43]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_group_11 [label="Expert Group 11\n(2 experts)\nEP32 [GPUs: 44-47]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_group_12 [label="Expert Group 12\n(2 experts)\nEP32 [GPUs: 48-51]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_group_13 [label="Expert Group 13\n(2 experts)\nEP32 [GPUs: 52-55]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_group_14 [label="Expert Group 14\n(2 experts)\nEP32 [GPUs: 56-59]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_group_15 [label="Expert Group 15\n(2 experts)\nEP32 [GPUs: 60-63]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_group_16 [label="Expert Group 16\n(2 experts)\nEP32 [GPUs: 64-67]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_group_17 [label="Expert Group 17\n(2 experts)\nEP32 [GPUs: 68-71]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_group_18 [label="Expert Group 18\n(2 experts)\nEP32 [GPUs: 72-75]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_group_19 [label="Expert Group 19\n(2 experts)\nEP32 [GPUs: 76-79]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_group_20 [label="Expert Group 20\n(2 experts)\nEP32 [GPUs: 80-83]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_group_21 [label="Expert Group 21\n(2 experts)\nEP32 [GPUs: 84-87]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_group_22 [label="Expert Group 22\n(2 experts)\nEP32 [GPUs: 88-91]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_group_23 [label="Expert Group 23\n(2 experts)\nEP32 [GPUs: 92-95]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_group_24 [label="Expert Group 24\n(2 experts)\nEP32 [GPUs: 96-99]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_group_25 [label="Expert Group 25\n(2 experts)\nEP32 [GPUs: 100-103]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_group_26 [label="Expert Group 26\n(2 experts)\nEP32 [GPUs: 104-107]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_group_27 [label="Expert Group 27\n(2 experts)\nEP32 [GPUs: 108-111]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_group_28 [label="Expert Group 28\n(2 experts)\nEP32 [GPUs: 112-115]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_group_29 [label="Expert Group 29\n(2 experts)\nEP32 [GPUs: 116-119]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_group_30 [label="Expert Group 30\n(2 experts)\nEP32 [GPUs: 120-123]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_expert_group_31 [label="Expert Group 31\n(2 experts)\nEP32 [GPUs: 124-127]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer0_combine [label="Layer 0 Expert Combine\nEP32 [GPUs: 0-31]\nInput: [16,1024,1024]\nOutput: [16,1024,1024]" fillcolor=lightyellow shape=parallelogram]
		layer0_attn_allreduce [label="Attention All-Reduce\nTP4 [GPUs: 0-3]" fillcolor=lightgreen shape=ellipse]
		layer0_moe_alltoall [label="MoE All-to-All\nEP32 [GPUs: 0-31]" fillcolor=lightgreen shape=ellipse]
	}
	subgraph cluster_stage1 {
		fillcolor=lightgray label="Pipeline Stage 1 (Layers 4-7)\nGPUs: 128-255" style="rounded,filled"
		layer4_attn_qkv_tp [label="Layer 4 Attention QKV\nTP4 [GPUs: 128-131]\nInput: [16,1024,1024]\nOutput: [16,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer4_attn_score [label="Layer 4 Attention Score\nTP4 [GPUs: 128-131]\nInput: [16,16,1024,64]\nOutput: [16,16,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer4_attn_out_tp [label="Layer 4 Attention Output\nTP4 [GPUs: 128-131]\nInput: [16,1024,1024]\nOutput: [16,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer4_route [label="Layer 4 Expert Routing\nEP32 [GPUs: 128-159]\nInput: [16,1024,1024]\nOutput: [16,1024,1024]" fillcolor=lightyellow shape=parallelogram]
		layer4_expert_group_0 [label="Expert Group 0\n(2 experts)\nEP32 [GPUs: 128-131]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer4_expert_group_1 [label="Expert Group 1\n(2 experts)\nEP32 [GPUs: 132-135]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer4_expert_group_2 [label="Expert Group 2\n(2 experts)\nEP32 [GPUs: 136-139]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer4_expert_group_3 [label="Expert Group 3\n(2 experts)\nEP32 [GPUs: 140-143]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer4_expert_group_4 [label="Expert Group 4\n(2 experts)\nEP32 [GPUs: 144-147]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer4_expert_group_5 [label="Expert Group 5\n(2 experts)\nEP32 [GPUs: 148-151]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer4_expert_group_6 [label="Expert Group 6\n(2 experts)\nEP32 [GPUs: 152-155]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer4_expert_group_7 [label="Expert Group 7\n(2 experts)\nEP32 [GPUs: 156-159]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer4_expert_group_8 [label="Expert Group 8\n(2 experts)\nEP32 [GPUs: 160-163]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer4_expert_group_9 [label="Expert Group 9\n(2 experts)\nEP32 [GPUs: 164-167]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer4_expert_group_10 [label="Expert Group 10\n(2 experts)\nEP32 [GPUs: 168-171]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer4_expert_group_11 [label="Expert Group 11\n(2 experts)\nEP32 [GPUs: 172-175]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer4_expert_group_12 [label="Expert Group 12\n(2 experts)\nEP32 [GPUs: 176-179]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer4_expert_group_13 [label="Expert Group 13\n(2 experts)\nEP32 [GPUs: 180-183]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer4_expert_group_14 [label="Expert Group 14\n(2 experts)\nEP32 [GPUs: 184-187]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer4_expert_group_15 [label="Expert Group 15\n(2 experts)\nEP32 [GPUs: 188-191]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer4_expert_group_16 [label="Expert Group 16\n(2 experts)\nEP32 [GPUs: 192-195]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer4_expert_group_17 [label="Expert Group 17\n(2 experts)\nEP32 [GPUs: 196-199]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer4_expert_group_18 [label="Expert Group 18\n(2 experts)\nEP32 [GPUs: 200-203]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer4_expert_group_19 [label="Expert Group 19\n(2 experts)\nEP32 [GPUs: 204-207]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer4_expert_group_20 [label="Expert Group 20\n(2 experts)\nEP32 [GPUs: 208-211]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer4_expert_group_21 [label="Expert Group 21\n(2 experts)\nEP32 [GPUs: 212-215]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer4_expert_group_22 [label="Expert Group 22\n(2 experts)\nEP32 [GPUs: 216-219]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer4_expert_group_23 [label="Expert Group 23\n(2 experts)\nEP32 [GPUs: 220-223]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer4_expert_group_24 [label="Expert Group 24\n(2 experts)\nEP32 [GPUs: 224-227]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer4_expert_group_25 [label="Expert Group 25\n(2 experts)\nEP32 [GPUs: 228-231]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer4_expert_group_26 [label="Expert Group 26\n(2 experts)\nEP32 [GPUs: 232-235]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer4_expert_group_27 [label="Expert Group 27\n(2 experts)\nEP32 [GPUs: 236-239]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer4_expert_group_28 [label="Expert Group 28\n(2 experts)\nEP32 [GPUs: 240-243]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer4_expert_group_29 [label="Expert Group 29\n(2 experts)\nEP32 [GPUs: 244-247]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer4_expert_group_30 [label="Expert Group 30\n(2 experts)\nEP32 [GPUs: 248-251]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer4_expert_group_31 [label="Expert Group 31\n(2 experts)\nEP32 [GPUs: 252-255]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer4_combine [label="Layer 4 Expert Combine\nEP32 [GPUs: 128-159]\nInput: [16,1024,1024]\nOutput: [16,1024,1024]" fillcolor=lightyellow shape=parallelogram]
		layer4_attn_allreduce [label="Attention All-Reduce\nTP4 [GPUs: 128-131]" fillcolor=lightgreen shape=ellipse]
		layer4_moe_alltoall [label="MoE All-to-All\nEP32 [GPUs: 128-159]" fillcolor=lightgreen shape=ellipse]
	}
	subgraph cluster_stage2 {
		fillcolor=lightgray label="Pipeline Stage 2 (Layers 8-11)\nGPUs: 256-383" style="rounded,filled"
		layer8_attn_qkv_tp [label="Layer 8 Attention QKV\nTP4 [GPUs: 256-259]\nInput: [16,1024,1024]\nOutput: [16,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_attn_score [label="Layer 8 Attention Score\nTP4 [GPUs: 256-259]\nInput: [16,16,1024,64]\nOutput: [16,16,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_attn_out_tp [label="Layer 8 Attention Output\nTP4 [GPUs: 256-259]\nInput: [16,1024,1024]\nOutput: [16,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_route [label="Layer 8 Expert Routing\nEP32 [GPUs: 256-287]\nInput: [16,1024,1024]\nOutput: [16,1024,1024]" fillcolor=lightyellow shape=parallelogram]
		layer8_expert_group_0 [label="Expert Group 0\n(2 experts)\nEP32 [GPUs: 256-259]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_group_1 [label="Expert Group 1\n(2 experts)\nEP32 [GPUs: 260-263]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_group_2 [label="Expert Group 2\n(2 experts)\nEP32 [GPUs: 264-267]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_group_3 [label="Expert Group 3\n(2 experts)\nEP32 [GPUs: 268-271]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_group_4 [label="Expert Group 4\n(2 experts)\nEP32 [GPUs: 272-275]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_group_5 [label="Expert Group 5\n(2 experts)\nEP32 [GPUs: 276-279]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_group_6 [label="Expert Group 6\n(2 experts)\nEP32 [GPUs: 280-283]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_group_7 [label="Expert Group 7\n(2 experts)\nEP32 [GPUs: 284-287]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_group_8 [label="Expert Group 8\n(2 experts)\nEP32 [GPUs: 288-291]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_group_9 [label="Expert Group 9\n(2 experts)\nEP32 [GPUs: 292-295]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_group_10 [label="Expert Group 10\n(2 experts)\nEP32 [GPUs: 296-299]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_group_11 [label="Expert Group 11\n(2 experts)\nEP32 [GPUs: 300-303]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_group_12 [label="Expert Group 12\n(2 experts)\nEP32 [GPUs: 304-307]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_group_13 [label="Expert Group 13\n(2 experts)\nEP32 [GPUs: 308-311]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_group_14 [label="Expert Group 14\n(2 experts)\nEP32 [GPUs: 312-315]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_group_15 [label="Expert Group 15\n(2 experts)\nEP32 [GPUs: 316-319]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_group_16 [label="Expert Group 16\n(2 experts)\nEP32 [GPUs: 320-323]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_group_17 [label="Expert Group 17\n(2 experts)\nEP32 [GPUs: 324-327]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_group_18 [label="Expert Group 18\n(2 experts)\nEP32 [GPUs: 328-331]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_group_19 [label="Expert Group 19\n(2 experts)\nEP32 [GPUs: 332-335]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_group_20 [label="Expert Group 20\n(2 experts)\nEP32 [GPUs: 336-339]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_group_21 [label="Expert Group 21\n(2 experts)\nEP32 [GPUs: 340-343]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_group_22 [label="Expert Group 22\n(2 experts)\nEP32 [GPUs: 344-347]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_group_23 [label="Expert Group 23\n(2 experts)\nEP32 [GPUs: 348-351]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_group_24 [label="Expert Group 24\n(2 experts)\nEP32 [GPUs: 352-355]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_group_25 [label="Expert Group 25\n(2 experts)\nEP32 [GPUs: 356-359]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_group_26 [label="Expert Group 26\n(2 experts)\nEP32 [GPUs: 360-363]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_group_27 [label="Expert Group 27\n(2 experts)\nEP32 [GPUs: 364-367]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_group_28 [label="Expert Group 28\n(2 experts)\nEP32 [GPUs: 368-371]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_group_29 [label="Expert Group 29\n(2 experts)\nEP32 [GPUs: 372-375]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_group_30 [label="Expert Group 30\n(2 experts)\nEP32 [GPUs: 376-379]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_expert_group_31 [label="Expert Group 31\n(2 experts)\nEP32 [GPUs: 380-383]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer8_combine [label="Layer 8 Expert Combine\nEP32 [GPUs: 256-287]\nInput: [16,1024,1024]\nOutput: [16,1024,1024]" fillcolor=lightyellow shape=parallelogram]
		layer8_attn_allreduce [label="Attention All-Reduce\nTP4 [GPUs: 256-259]" fillcolor=lightgreen shape=ellipse]
		layer8_moe_alltoall [label="MoE All-to-All\nEP32 [GPUs: 256-287]" fillcolor=lightgreen shape=ellipse]
	}
	subgraph cluster_stage3 {
		fillcolor=lightgray label="Pipeline Stage 3 (Layers 12-15)\nGPUs: 384-511" style="rounded,filled"
		layer12_attn_qkv_tp [label="Layer 12 Attention QKV\nTP4 [GPUs: 384-387]\nInput: [16,1024,1024]\nOutput: [16,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer12_attn_score [label="Layer 12 Attention Score\nTP4 [GPUs: 384-387]\nInput: [16,16,1024,64]\nOutput: [16,16,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer12_attn_out_tp [label="Layer 12 Attention Output\nTP4 [GPUs: 384-387]\nInput: [16,1024,1024]\nOutput: [16,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer12_route [label="Layer 12 Expert Routing\nEP32 [GPUs: 384-415]\nInput: [16,1024,1024]\nOutput: [16,1024,1024]" fillcolor=lightyellow shape=parallelogram]
		layer12_expert_group_0 [label="Expert Group 0\n(2 experts)\nEP32 [GPUs: 384-387]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer12_expert_group_1 [label="Expert Group 1\n(2 experts)\nEP32 [GPUs: 388-391]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer12_expert_group_2 [label="Expert Group 2\n(2 experts)\nEP32 [GPUs: 392-395]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer12_expert_group_3 [label="Expert Group 3\n(2 experts)\nEP32 [GPUs: 396-399]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer12_expert_group_4 [label="Expert Group 4\n(2 experts)\nEP32 [GPUs: 400-403]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer12_expert_group_5 [label="Expert Group 5\n(2 experts)\nEP32 [GPUs: 404-407]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer12_expert_group_6 [label="Expert Group 6\n(2 experts)\nEP32 [GPUs: 408-411]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer12_expert_group_7 [label="Expert Group 7\n(2 experts)\nEP32 [GPUs: 412-415]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer12_expert_group_8 [label="Expert Group 8\n(2 experts)\nEP32 [GPUs: 416-419]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer12_expert_group_9 [label="Expert Group 9\n(2 experts)\nEP32 [GPUs: 420-423]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer12_expert_group_10 [label="Expert Group 10\n(2 experts)\nEP32 [GPUs: 424-427]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer12_expert_group_11 [label="Expert Group 11\n(2 experts)\nEP32 [GPUs: 428-431]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer12_expert_group_12 [label="Expert Group 12\n(2 experts)\nEP32 [GPUs: 432-435]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer12_expert_group_13 [label="Expert Group 13\n(2 experts)\nEP32 [GPUs: 436-439]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer12_expert_group_14 [label="Expert Group 14\n(2 experts)\nEP32 [GPUs: 440-443]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer12_expert_group_15 [label="Expert Group 15\n(2 experts)\nEP32 [GPUs: 444-447]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer12_expert_group_16 [label="Expert Group 16\n(2 experts)\nEP32 [GPUs: 448-451]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer12_expert_group_17 [label="Expert Group 17\n(2 experts)\nEP32 [GPUs: 452-455]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer12_expert_group_18 [label="Expert Group 18\n(2 experts)\nEP32 [GPUs: 456-459]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer12_expert_group_19 [label="Expert Group 19\n(2 experts)\nEP32 [GPUs: 460-463]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer12_expert_group_20 [label="Expert Group 20\n(2 experts)\nEP32 [GPUs: 464-467]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer12_expert_group_21 [label="Expert Group 21\n(2 experts)\nEP32 [GPUs: 468-471]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer12_expert_group_22 [label="Expert Group 22\n(2 experts)\nEP32 [GPUs: 472-475]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer12_expert_group_23 [label="Expert Group 23\n(2 experts)\nEP32 [GPUs: 476-479]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer12_expert_group_24 [label="Expert Group 24\n(2 experts)\nEP32 [GPUs: 480-483]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer12_expert_group_25 [label="Expert Group 25\n(2 experts)\nEP32 [GPUs: 484-487]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer12_expert_group_26 [label="Expert Group 26\n(2 experts)\nEP32 [GPUs: 488-491]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer12_expert_group_27 [label="Expert Group 27\n(2 experts)\nEP32 [GPUs: 492-495]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer12_expert_group_28 [label="Expert Group 28\n(2 experts)\nEP32 [GPUs: 496-499]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer12_expert_group_29 [label="Expert Group 29\n(2 experts)\nEP32 [GPUs: 500-503]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer12_expert_group_30 [label="Expert Group 30\n(2 experts)\nEP32 [GPUs: 504-507]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer12_expert_group_31 [label="Expert Group 31\n(2 experts)\nEP32 [GPUs: 508-511]\nInput: [1,1024,1024]\nOutput: [1,1024,1024]" fillcolor=lightblue shape=rectangle]
		layer12_combine [label="Layer 12 Expert Combine\nEP32 [GPUs: 384-415]\nInput: [16,1024,1024]\nOutput: [16,1024,1024]" fillcolor=lightyellow shape=parallelogram]
		layer12_attn_allreduce [label="Attention All-Reduce\nTP4 [GPUs: 384-387]" fillcolor=lightgreen shape=ellipse]
		layer12_moe_alltoall [label="MoE All-to-All\nEP32 [GPUs: 384-415]" fillcolor=lightgreen shape=ellipse]
	}
	output [label="Output\n[batch_size=128, seq_len=1024, hidden=1024]\nDP8: Aggregated from 8 groups" fillcolor=white shape=ellipse]
	input -> layer0_attn_qkv_tp
	layer0_attn_qkv_tp -> layer0_attn_score
	layer0_attn_score -> layer0_attn_allreduce
	layer0_attn_allreduce -> layer0_attn_out_tp
	layer0_attn_out_tp -> layer0_route
	layer0_route -> layer0_moe_alltoall
	layer0_moe_alltoall -> layer0_expert_group_0
	layer0_expert_group_0 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_group_1
	layer0_expert_group_1 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_group_2
	layer0_expert_group_2 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_group_3
	layer0_expert_group_3 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_group_4
	layer0_expert_group_4 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_group_5
	layer0_expert_group_5 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_group_6
	layer0_expert_group_6 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_group_7
	layer0_expert_group_7 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_group_8
	layer0_expert_group_8 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_group_9
	layer0_expert_group_9 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_group_10
	layer0_expert_group_10 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_group_11
	layer0_expert_group_11 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_group_12
	layer0_expert_group_12 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_group_13
	layer0_expert_group_13 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_group_14
	layer0_expert_group_14 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_group_15
	layer0_expert_group_15 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_group_16
	layer0_expert_group_16 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_group_17
	layer0_expert_group_17 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_group_18
	layer0_expert_group_18 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_group_19
	layer0_expert_group_19 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_group_20
	layer0_expert_group_20 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_group_21
	layer0_expert_group_21 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_group_22
	layer0_expert_group_22 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_group_23
	layer0_expert_group_23 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_group_24
	layer0_expert_group_24 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_group_25
	layer0_expert_group_25 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_group_26
	layer0_expert_group_26 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_group_27
	layer0_expert_group_27 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_group_28
	layer0_expert_group_28 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_group_29
	layer0_expert_group_29 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_group_30
	layer0_expert_group_30 -> layer0_combine [style=dashed]
	layer0_moe_alltoall -> layer0_expert_group_31
	layer0_expert_group_31 -> layer0_combine [style=dashed]
	layer0_combine -> layer4_attn_qkv_tp [lhead=cluster_stage1]
	layer4_attn_qkv_tp -> layer4_attn_score
	layer4_attn_score -> layer4_attn_allreduce
	layer4_attn_allreduce -> layer4_attn_out_tp
	layer4_attn_out_tp -> layer4_route
	layer4_route -> layer4_moe_alltoall
	layer4_moe_alltoall -> layer4_expert_group_0
	layer4_expert_group_0 -> layer4_combine [style=dashed]
	layer4_moe_alltoall -> layer4_expert_group_1
	layer4_expert_group_1 -> layer4_combine [style=dashed]
	layer4_moe_alltoall -> layer4_expert_group_2
	layer4_expert_group_2 -> layer4_combine [style=dashed]
	layer4_moe_alltoall -> layer4_expert_group_3
	layer4_expert_group_3 -> layer4_combine [style=dashed]
	layer4_moe_alltoall -> layer4_expert_group_4
	layer4_expert_group_4 -> layer4_combine [style=dashed]
	layer4_moe_alltoall -> layer4_expert_group_5
	layer4_expert_group_5 -> layer4_combine [style=dashed]
	layer4_moe_alltoall -> layer4_expert_group_6
	layer4_expert_group_6 -> layer4_combine [style=dashed]
	layer4_moe_alltoall -> layer4_expert_group_7
	layer4_expert_group_7 -> layer4_combine [style=dashed]
	layer4_moe_alltoall -> layer4_expert_group_8
	layer4_expert_group_8 -> layer4_combine [style=dashed]
	layer4_moe_alltoall -> layer4_expert_group_9
	layer4_expert_group_9 -> layer4_combine [style=dashed]
	layer4_moe_alltoall -> layer4_expert_group_10
	layer4_expert_group_10 -> layer4_combine [style=dashed]
	layer4_moe_alltoall -> layer4_expert_group_11
	layer4_expert_group_11 -> layer4_combine [style=dashed]
	layer4_moe_alltoall -> layer4_expert_group_12
	layer4_expert_group_12 -> layer4_combine [style=dashed]
	layer4_moe_alltoall -> layer4_expert_group_13
	layer4_expert_group_13 -> layer4_combine [style=dashed]
	layer4_moe_alltoall -> layer4_expert_group_14
	layer4_expert_group_14 -> layer4_combine [style=dashed]
	layer4_moe_alltoall -> layer4_expert_group_15
	layer4_expert_group_15 -> layer4_combine [style=dashed]
	layer4_moe_alltoall -> layer4_expert_group_16
	layer4_expert_group_16 -> layer4_combine [style=dashed]
	layer4_moe_alltoall -> layer4_expert_group_17
	layer4_expert_group_17 -> layer4_combine [style=dashed]
	layer4_moe_alltoall -> layer4_expert_group_18
	layer4_expert_group_18 -> layer4_combine [style=dashed]
	layer4_moe_alltoall -> layer4_expert_group_19
	layer4_expert_group_19 -> layer4_combine [style=dashed]
	layer4_moe_alltoall -> layer4_expert_group_20
	layer4_expert_group_20 -> layer4_combine [style=dashed]
	layer4_moe_alltoall -> layer4_expert_group_21
	layer4_expert_group_21 -> layer4_combine [style=dashed]
	layer4_moe_alltoall -> layer4_expert_group_22
	layer4_expert_group_22 -> layer4_combine [style=dashed]
	layer4_moe_alltoall -> layer4_expert_group_23
	layer4_expert_group_23 -> layer4_combine [style=dashed]
	layer4_moe_alltoall -> layer4_expert_group_24
	layer4_expert_group_24 -> layer4_combine [style=dashed]
	layer4_moe_alltoall -> layer4_expert_group_25
	layer4_expert_group_25 -> layer4_combine [style=dashed]
	layer4_moe_alltoall -> layer4_expert_group_26
	layer4_expert_group_26 -> layer4_combine [style=dashed]
	layer4_moe_alltoall -> layer4_expert_group_27
	layer4_expert_group_27 -> layer4_combine [style=dashed]
	layer4_moe_alltoall -> layer4_expert_group_28
	layer4_expert_group_28 -> layer4_combine [style=dashed]
	layer4_moe_alltoall -> layer4_expert_group_29
	layer4_expert_group_29 -> layer4_combine [style=dashed]
	layer4_moe_alltoall -> layer4_expert_group_30
	layer4_expert_group_30 -> layer4_combine [style=dashed]
	layer4_moe_alltoall -> layer4_expert_group_31
	layer4_expert_group_31 -> layer4_combine [style=dashed]
	layer4_combine -> layer8_attn_qkv_tp [lhead=cluster_stage2]
	layer8_attn_qkv_tp -> layer8_attn_score
	layer8_attn_score -> layer8_attn_allreduce
	layer8_attn_allreduce -> layer8_attn_out_tp
	layer8_attn_out_tp -> layer8_route
	layer8_route -> layer8_moe_alltoall
	layer8_moe_alltoall -> layer8_expert_group_0
	layer8_expert_group_0 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_group_1
	layer8_expert_group_1 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_group_2
	layer8_expert_group_2 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_group_3
	layer8_expert_group_3 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_group_4
	layer8_expert_group_4 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_group_5
	layer8_expert_group_5 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_group_6
	layer8_expert_group_6 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_group_7
	layer8_expert_group_7 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_group_8
	layer8_expert_group_8 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_group_9
	layer8_expert_group_9 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_group_10
	layer8_expert_group_10 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_group_11
	layer8_expert_group_11 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_group_12
	layer8_expert_group_12 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_group_13
	layer8_expert_group_13 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_group_14
	layer8_expert_group_14 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_group_15
	layer8_expert_group_15 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_group_16
	layer8_expert_group_16 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_group_17
	layer8_expert_group_17 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_group_18
	layer8_expert_group_18 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_group_19
	layer8_expert_group_19 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_group_20
	layer8_expert_group_20 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_group_21
	layer8_expert_group_21 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_group_22
	layer8_expert_group_22 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_group_23
	layer8_expert_group_23 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_group_24
	layer8_expert_group_24 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_group_25
	layer8_expert_group_25 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_group_26
	layer8_expert_group_26 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_group_27
	layer8_expert_group_27 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_group_28
	layer8_expert_group_28 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_group_29
	layer8_expert_group_29 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_group_30
	layer8_expert_group_30 -> layer8_combine [style=dashed]
	layer8_moe_alltoall -> layer8_expert_group_31
	layer8_expert_group_31 -> layer8_combine [style=dashed]
	layer8_combine -> layer12_attn_qkv_tp [lhead=cluster_stage3]
	layer12_attn_qkv_tp -> layer12_attn_score
	layer12_attn_score -> layer12_attn_allreduce
	layer12_attn_allreduce -> layer12_attn_out_tp
	layer12_attn_out_tp -> layer12_route
	layer12_route -> layer12_moe_alltoall
	layer12_moe_alltoall -> layer12_expert_group_0
	layer12_expert_group_0 -> layer12_combine [style=dashed]
	layer12_moe_alltoall -> layer12_expert_group_1
	layer12_expert_group_1 -> layer12_combine [style=dashed]
	layer12_moe_alltoall -> layer12_expert_group_2
	layer12_expert_group_2 -> layer12_combine [style=dashed]
	layer12_moe_alltoall -> layer12_expert_group_3
	layer12_expert_group_3 -> layer12_combine [style=dashed]
	layer12_moe_alltoall -> layer12_expert_group_4
	layer12_expert_group_4 -> layer12_combine [style=dashed]
	layer12_moe_alltoall -> layer12_expert_group_5
	layer12_expert_group_5 -> layer12_combine [style=dashed]
	layer12_moe_alltoall -> layer12_expert_group_6
	layer12_expert_group_6 -> layer12_combine [style=dashed]
	layer12_moe_alltoall -> layer12_expert_group_7
	layer12_expert_group_7 -> layer12_combine [style=dashed]
	layer12_moe_alltoall -> layer12_expert_group_8
	layer12_expert_group_8 -> layer12_combine [style=dashed]
	layer12_moe_alltoall -> layer12_expert_group_9
	layer12_expert_group_9 -> layer12_combine [style=dashed]
	layer12_moe_alltoall -> layer12_expert_group_10
	layer12_expert_group_10 -> layer12_combine [style=dashed]
	layer12_moe_alltoall -> layer12_expert_group_11
	layer12_expert_group_11 -> layer12_combine [style=dashed]
	layer12_moe_alltoall -> layer12_expert_group_12
	layer12_expert_group_12 -> layer12_combine [style=dashed]
	layer12_moe_alltoall -> layer12_expert_group_13
	layer12_expert_group_13 -> layer12_combine [style=dashed]
	layer12_moe_alltoall -> layer12_expert_group_14
	layer12_expert_group_14 -> layer12_combine [style=dashed]
	layer12_moe_alltoall -> layer12_expert_group_15
	layer12_expert_group_15 -> layer12_combine [style=dashed]
	layer12_moe_alltoall -> layer12_expert_group_16
	layer12_expert_group_16 -> layer12_combine [style=dashed]
	layer12_moe_alltoall -> layer12_expert_group_17
	layer12_expert_group_17 -> layer12_combine [style=dashed]
	layer12_moe_alltoall -> layer12_expert_group_18
	layer12_expert_group_18 -> layer12_combine [style=dashed]
	layer12_moe_alltoall -> layer12_expert_group_19
	layer12_expert_group_19 -> layer12_combine [style=dashed]
	layer12_moe_alltoall -> layer12_expert_group_20
	layer12_expert_group_20 -> layer12_combine [style=dashed]
	layer12_moe_alltoall -> layer12_expert_group_21
	layer12_expert_group_21 -> layer12_combine [style=dashed]
	layer12_moe_alltoall -> layer12_expert_group_22
	layer12_expert_group_22 -> layer12_combine [style=dashed]
	layer12_moe_alltoall -> layer12_expert_group_23
	layer12_expert_group_23 -> layer12_combine [style=dashed]
	layer12_moe_alltoall -> layer12_expert_group_24
	layer12_expert_group_24 -> layer12_combine [style=dashed]
	layer12_moe_alltoall -> layer12_expert_group_25
	layer12_expert_group_25 -> layer12_combine [style=dashed]
	layer12_moe_alltoall -> layer12_expert_group_26
	layer12_expert_group_26 -> layer12_combine [style=dashed]
	layer12_moe_alltoall -> layer12_expert_group_27
	layer12_expert_group_27 -> layer12_combine [style=dashed]
	layer12_moe_alltoall -> layer12_expert_group_28
	layer12_expert_group_28 -> layer12_combine [style=dashed]
	layer12_moe_alltoall -> layer12_expert_group_29
	layer12_expert_group_29 -> layer12_combine [style=dashed]
	layer12_moe_alltoall -> layer12_expert_group_30
	layer12_expert_group_30 -> layer12_combine [style=dashed]
	layer12_moe_alltoall -> layer12_expert_group_31
	layer12_expert_group_31 -> layer12_combine [style=dashed]
	layer12_combine -> output
}
