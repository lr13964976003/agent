{
  "parallel_strategy": {
    "ep_degree": 16,
    "tp_degree": 1,
    "pp_degree": 1,
    "dp_degree": 1,
    "strategy_name": "EP16_TP1_PP1_DP1"
  },
  "model_config": {
    "layers": 16,
    "experts_per_layer": 64,
    "experts_per_gpu": 4,
    "token_dim": 1024,
    "batch_size": 128,
    "micro_batch_size": 128,
    "seq_length": 1024
  },
  "hardware_config": {
    "total_gpus": 16,
    "gpu_memory_gb": 80,
    "gpu_flops": 19500000000000.0,
    "memory_bandwidth": 2039000000000.0
  },
  "validation_results": {
    "gpu_count": {
      "required": 16,
      "available": 16,
      "valid": true,
      "utilization": "16/16 = 100.0%"
    },
    "expert_distribution": {
      "total_experts": 1024,
      "experts_per_gpu": 4,
      "perfect_balance": true,
      "imbalance_ratio": 0
    },
    "memory_usage": {
      "required_gb": 114.527434592,
      "available_gb": 80,
      "utilization_percent": 133.32748156040907,
      "valid": false
    },
    "load_balancing": {
      "experts_per_gpu": 4,
      "expert_distribution": "Perfectly balanced",
      "ep_efficiency": "Optimal"
    }
  },
  "performance_metrics": {
    "latency_ms": 12604.130127416305,
    "throughput_tokens_s": 10399.130973338197,
    "compute_latency_ms": 12603.076923076924,
    "memory_latency_ms": 1.05320433938205
  },
  "optimization_status": "OPTIMAL_FOR_CURRENT_HARDWARE"
}