digraph Cross_Node_Expert_Parallelism {
	fontname=Arial fontsize=12 rankdir=TB
	node [fillcolor=lightblue shape=ellipse style=filled]
	node [fillcolor=lightgreen shape=rectangle style=filled]
	node [fillcolor=yellow shape=parallelogram style=filled]
	node [fillcolor=orange shape=diamond style=filled]
	input [label="Input\n[batch_size=128, seq_len=10000, d_model=4096]" fillcolor=lightblue shape=ellipse]
	gating [label="Gating Mechanism\nSelect top-K experts per token\n[batch_size=128, seq_len=10000, d_model=4096]→[batch_size=128, seq_len=10000, num_experts=16]" fillcolor=yellow shape=parallelogram]
	token_split [label="Token Split by Expert\nSplit tokens across 16 experts\n[batch_size=128, seq_len=10000, d_model=4096]→16×[variable_batch, d_model=4096]" fillcolor=yellow shape=parallelogram]
	input -> gating
	gating -> token_split [label=expert_selection style=dashed]
	expert_0_gpu_0 [label="Expert 0\nGPU 0\nMLP: 4096→16384→4096\nInput: [variable_batch, d_model=4096]\nOutput: [variable_batch, d_model=4096]" fillcolor=lightgreen shape=rectangle]
	token_split -> expert_0_gpu_0 [label=expert_0_tokens]
	expert_1_gpu_1 [label="Expert 1\nGPU 1\nMLP: 4096→16384→4096\nInput: [variable_batch, d_model=4096]\nOutput: [variable_batch, d_model=4096]" fillcolor=lightgreen shape=rectangle]
	token_split -> expert_1_gpu_1 [label=expert_1_tokens]
	expert_2_gpu_2 [label="Expert 2\nGPU 2\nMLP: 4096→16384→4096\nInput: [variable_batch, d_model=4096]\nOutput: [variable_batch, d_model=4096]" fillcolor=lightgreen shape=rectangle]
	token_split -> expert_2_gpu_2 [label=expert_2_tokens]
	expert_3_gpu_3 [label="Expert 3\nGPU 3\nMLP: 4096→16384→4096\nInput: [variable_batch, d_model=4096]\nOutput: [variable_batch, d_model=4096]" fillcolor=lightgreen shape=rectangle]
	token_split -> expert_3_gpu_3 [label=expert_3_tokens]
	expert_4_gpu_4 [label="Expert 4\nGPU 4\nMLP: 4096→16384→4096\nInput: [variable_batch, d_model=4096]\nOutput: [variable_batch, d_model=4096]" fillcolor=lightgreen shape=rectangle]
	token_split -> expert_4_gpu_4 [label=expert_4_tokens]
	expert_5_gpu_5 [label="Expert 5\nGPU 5\nMLP: 4096→16384→4096\nInput: [variable_batch, d_model=4096]\nOutput: [variable_batch, d_model=4096]" fillcolor=lightgreen shape=rectangle]
	token_split -> expert_5_gpu_5 [label=expert_5_tokens]
	expert_6_gpu_6 [label="Expert 6\nGPU 6\nMLP: 4096→16384→4096\nInput: [variable_batch, d_model=4096]\nOutput: [variable_batch, d_model=4096]" fillcolor=lightgreen shape=rectangle]
	token_split -> expert_6_gpu_6 [label=expert_6_tokens]
	expert_7_gpu_7 [label="Expert 7\nGPU 7\nMLP: 4096→16384→4096\nInput: [variable_batch, d_model=4096]\nOutput: [variable_batch, d_model=4096]" fillcolor=lightgreen shape=rectangle]
	token_split -> expert_7_gpu_7 [label=expert_7_tokens]
	expert_8_gpu_8 [label="Expert 8\nGPU 8\nMLP: 4096→16384→4096\nInput: [variable_batch, d_model=4096]\nOutput: [variable_batch, d_model=4096]" fillcolor=lightgreen shape=rectangle]
	token_split -> expert_8_gpu_8 [label=expert_8_tokens]
	expert_9_gpu_9 [label="Expert 9\nGPU 9\nMLP: 4096→16384→4096\nInput: [variable_batch, d_model=4096]\nOutput: [variable_batch, d_model=4096]" fillcolor=lightgreen shape=rectangle]
	token_split -> expert_9_gpu_9 [label=expert_9_tokens]
	expert_10_gpu_10 [label="Expert 10\nGPU 10\nMLP: 4096→16384→4096\nInput: [variable_batch, d_model=4096]\nOutput: [variable_batch, d_model=4096]" fillcolor=lightgreen shape=rectangle]
	token_split -> expert_10_gpu_10 [label=expert_10_tokens]
	expert_11_gpu_11 [label="Expert 11\nGPU 11\nMLP: 4096→16384→4096\nInput: [variable_batch, d_model=4096]\nOutput: [variable_batch, d_model=4096]" fillcolor=lightgreen shape=rectangle]
	token_split -> expert_11_gpu_11 [label=expert_11_tokens]
	expert_12_gpu_12 [label="Expert 12\nGPU 12\nMLP: 4096→16384→4096\nInput: [variable_batch, d_model=4096]\nOutput: [variable_batch, d_model=4096]" fillcolor=lightgreen shape=rectangle]
	token_split -> expert_12_gpu_12 [label=expert_12_tokens]
	expert_13_gpu_13 [label="Expert 13\nGPU 13\nMLP: 4096→16384→4096\nInput: [variable_batch, d_model=4096]\nOutput: [variable_batch, d_model=4096]" fillcolor=lightgreen shape=rectangle]
	token_split -> expert_13_gpu_13 [label=expert_13_tokens]
	expert_14_gpu_14 [label="Expert 14\nGPU 14\nMLP: 4096→16384→4096\nInput: [variable_batch, d_model=4096]\nOutput: [variable_batch, d_model=4096]" fillcolor=lightgreen shape=rectangle]
	token_split -> expert_14_gpu_14 [label=expert_14_tokens]
	expert_15_gpu_15 [label="Expert 15\nGPU 15\nMLP: 4096→16384→4096\nInput: [variable_batch, d_model=4096]\nOutput: [variable_batch, d_model=4096]" fillcolor=lightgreen shape=rectangle]
	token_split -> expert_15_gpu_15 [label=expert_15_tokens]
	expert_agg [label="Expert Output Aggregation\nCombine outputs from 16 experts\n16×[variable_batch, d_model=4096]→[batch_size=128, seq_len=10000, d_model=4096]" fillcolor=yellow shape=parallelogram]
	expert_0_gpu_0 -> expert_agg
	expert_1_gpu_1 -> expert_agg
	expert_2_gpu_2 -> expert_agg
	expert_3_gpu_3 -> expert_agg
	expert_4_gpu_4 -> expert_agg
	expert_5_gpu_5 -> expert_agg
	expert_6_gpu_6 -> expert_agg
	expert_7_gpu_7 -> expert_agg
	expert_8_gpu_8 -> expert_agg
	expert_9_gpu_9 -> expert_agg
	expert_10_gpu_10 -> expert_agg
	expert_11_gpu_11 -> expert_agg
	expert_12_gpu_12 -> expert_agg
	expert_13_gpu_13 -> expert_agg
	expert_14_gpu_14 -> expert_agg
	expert_15_gpu_15 -> expert_agg
	output [label="Output\n[batch_size=128, seq_len=10000, d_model=4096]" fillcolor=lightblue shape=ellipse]
	expert_agg -> output
}
