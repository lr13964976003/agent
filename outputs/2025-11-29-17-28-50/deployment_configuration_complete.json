{
  "deployment_configurations": {
    "baseline": {
      "name": "Baseline TP=8 PP=2 Deployment",
      "parallel_strategy": {
        "tensor_parallelism": 8,
        "pipeline_parallelism": 2,
        "expert_parallelism": 1,
        "data_parallelism": 1
      },
      "model_specifications": {
        "layers": 16,
        "experts_per_layer": 16,
        "token_dimension": 4096,
        "mha_heads": 32,
        "mha_head_dimension": 128,
        "mlp_hidden_size": 16384,
        "precision": "BF16",
        "batch_size": 128,
        "sequence_length": 10000
      },
      "device_mapping": {
        "GPU_0": {
          "pipeline_stage": 0,
          "tensor_parallel_rank": 0,
          "layers": "0-7",
          "experts": "Expert_0, Expert_1, Expert_2, Expert_3, Expert_4, Expert_5, Expert_6, Expert_7",
          "shard_responsibility": "Tensor parallel shard 0 for all layers in stage 0"
        },
        "GPU_1": {
          "pipeline_stage": 0,
          "tensor_parallel_rank": 1,
          "layers": "0-7",
          "experts": "Expert_0, Expert_1, Expert_2, Expert_3, Expert_4, Expert_5, Expert_6, Expert_7",
          "shard_responsibility": "Tensor parallel shard 1 for all layers in stage 0"
        },
        "GPU_2": {
          "pipeline_stage": 0,
          "tensor_parallel_rank": 2,
          "layers": "0-7",
          "experts": "Expert_0, Expert_1, Expert_2, Expert_3, Expert_4, Expert_5, Expert_6, Expert_7",
          "shard_responsibility": "Tensor parallel shard 2 for all layers in stage 0"
        },
        "GPU_3": {
          "pipeline_stage": 0,
          "tensor_parallel_rank": 3,
          "layers": "0-7",
          "experts": "Expert_0, Expert_1, Expert_2, Expert_3, Expert_4, Expert_5, Expert_6, Expert_7",
          "shard_responsibility": "Tensor parallel shard 3 for all layers in stage 0"
        },
        "GPU_4": {
          "pipeline_stage": 0,
          "tensor_parallel_rank": 4,
          "layers": "0-7",
          "experts": "Expert_0, Expert_1, Expert_2, Expert_3, Expert_4, Expert_5, Expert_6, Expert_7",
          "shard_responsibility": "Tensor parallel shard 4 for all layers in stage 0"
        },
        "GPU_5": {
          "pipeline_stage": 0,
          "tensor_parallel_rank": 5,
          "layers": "0-7",
          "experts": "Expert_0, Expert_1, Expert_2, Expert_3, Expert_4, Expert_5, Expert_6, Expert_7",
          "shard_responsibility": "Tensor parallel shard 5 for all layers in stage 0"
        },
        "GPU_6": {
          "pipeline_stage": 0,
          "tensor_parallel_rank": 6,
          "layers": "0-7",
          "experts": "Expert_0, Expert_1, Expert_2, Expert_3, Expert_4, Expert_5, Expert_6, Expert_7",
          "shard_responsibility": "Tensor parallel shard 6 for all layers in stage 0"
        },
        "GPU_7": {
          "pipeline_stage": 0,
          "tensor_parallel_rank": 7,
          "layers": "0-7",
          "experts": "Expert_0, Expert_1, Expert_2, Expert_3, Expert_4, Expert_5, Expert_6, Expert_7",
          "shard_responsibility": "Tensor parallel shard 7 for all layers in stage 0"
        },
        "GPU_8": {
          "pipeline_stage": 1,
          "tensor_parallel_rank": 0,
          "layers": "8-15",
          "experts": "Expert_8, Expert_9, Expert_10, Expert_11, Expert_12, Expert_13, Expert_14, Expert_15",
          "shard_responsibility": "Tensor parallel shard 0 for all layers in stage 1"
        },
        "GPU_9": {
          "pipeline_stage": 1,
          "tensor_parallel_rank": 1,
          "layers": "8-15",
          "experts": "Expert_8, Expert_9, Expert_10, Expert_11, Expert_12, Expert_13, Expert_14, Expert_15",
          "shard_responsibility": "Tensor parallel shard 1 for all layers in stage 1"
        },
        "GPU_10": {
          "pipeline_stage": 1,
          "tensor_parallel_rank": 2,
          "layers": "8-15",
          "experts": "Expert_8, Expert_9, Expert_10, Expert_11, Expert_12, Expert_13, Expert_14, Expert_15",
          "shard_responsibility": "Tensor parallel shard 2 for all layers in stage 1"
        },
        "GPU_11": {
          "pipeline_stage": 1,
          "tensor_parallel_rank": 3,
          "layers": "8-15",
          "experts": "Expert_8, Expert_9, Expert_10, Expert_11, Expert_12, Expert_13, Expert_14, Expert_15",
          "shard_responsibility": "Tensor parallel shard 3 for all layers in stage 1"
        },
        "GPU_12": {
          "pipeline_stage": 1,
          "tensor_parallel_rank": 4,
          "layers": "8-15",
          "experts": "Expert_8, Expert_9, Expert_10, Expert_11, Expert_12, Expert_13, Expert_14, Expert_15",
          "shard_responsibility": "Tensor parallel shard 4 for all layers in stage 1"
        },
        "GPU_13": {
          "pipeline_stage": 1,
          "tensor_parallel_rank": 5,
          "layers": "8-15",
          "experts": "Expert_8, Expert_9, Expert_10, Expert_11, Expert_12, Expert_13, Expert_14, Expert_15",
          "shard_responsibility": "Tensor parallel shard 5 for all layers in stage 1"
        },
        "GPU_14": {
          "pipeline_stage": 1,
          "tensor_parallel_rank": 6,
          "layers": "8-15",
          "experts": "Expert_8, Expert_9, Expert_10, Expert_11, Expert_12, Expert_13, Expert_14, Expert_15",
          "shard_responsibility": "Tensor parallel shard 6 for all layers in stage 1"
        },
        "GPU_15": {
          "pipeline_stage": 1,
          "tensor_parallel_rank": 7,
          "layers": "8-15",
          "experts": "Expert_8, Expert_9, Expert_10, Expert_11, Expert_12, Expert_13, Expert_14, Expert_15",
          "shard_responsibility": "Tensor parallel shard 7 for all layers in stage 1"
        }
      },
      "performance_metrics": {
        "throughput": {
          "value": 120000,
          "unit": "tokens_per_second"
        },
        "latency": {
          "value": 8.3,
          "unit": "ms_per_token"
        }
      }
    },
    "proposed": {
      "name": "Proposed Cross-Node Expert Parallelism",
      "parallel_strategy": {
        "expert_parallelism": 16,
        "tensor_parallelism": 1,
        "pipeline_parallelism": 1,
        "data_parallelism": 1
      },
      "model_specifications": {
        "layers": 16,
        "experts_per_layer": 16,
        "token_dimension": 4096,
        "mha_heads": 32,
        "mha_head_dimension": 128,
        "mlp_hidden_size": 16384,
        "precision": "BF16",
        "batch_size": 128,
        "sequence_length": 10000
      },
      "device_mapping": {
        "layer_0": {
          "GPU_0": {
            "expert_id": 0,
            "responsibility": "Expert 0 for Layer 0 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 0, sends processed tokens to next layer"
          },
          "GPU_1": {
            "expert_id": 1,
            "responsibility": "Expert 1 for Layer 0 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 1, sends processed tokens to next layer"
          },
          "GPU_2": {
            "expert_id": 2,
            "responsibility": "Expert 2 for Layer 0 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 2, sends processed tokens to next layer"
          },
          "GPU_3": {
            "expert_id": 3,
            "responsibility": "Expert 3 for Layer 0 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 3, sends processed tokens to next layer"
          },
          "GPU_4": {
            "expert_id": 4,
            "responsibility": "Expert 4 for Layer 0 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 4, sends processed tokens to next layer"
          },
          "GPU_5": {
            "expert_id": 5,
            "responsibility": "Expert 5 for Layer 0 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 5, sends processed tokens to next layer"
          },
          "GPU_6": {
            "expert_id": 6,
            "responsibility": "Expert 6 for Layer 0 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 6, sends processed tokens to next layer"
          },
          "GPU_7": {
            "expert_id": 7,
            "responsibility": "Expert 7 for Layer 0 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 7, sends processed tokens to next layer"
          },
          "GPU_8": {
            "expert_id": 8,
            "responsibility": "Expert 8 for Layer 0 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 8, sends processed tokens to next layer"
          },
          "GPU_9": {
            "expert_id": 9,
            "responsibility": "Expert 9 for Layer 0 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 9, sends processed tokens to next layer"
          },
          "GPU_10": {
            "expert_id": 10,
            "responsibility": "Expert 10 for Layer 0 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 10, sends processed tokens to next layer"
          },
          "GPU_11": {
            "expert_id": 11,
            "responsibility": "Expert 11 for Layer 0 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 11, sends processed tokens to next layer"
          },
          "GPU_12": {
            "expert_id": 12,
            "responsibility": "Expert 12 for Layer 0 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 12, sends processed tokens to next layer"
          },
          "GPU_13": {
            "expert_id": 13,
            "responsibility": "Expert 13 for Layer 0 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 13, sends processed tokens to next layer"
          },
          "GPU_14": {
            "expert_id": 14,
            "responsibility": "Expert 14 for Layer 0 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 14, sends processed tokens to next layer"
          },
          "GPU_15": {
            "expert_id": 15,
            "responsibility": "Expert 15 for Layer 0 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 15, sends processed tokens to next layer"
          }
        },
        "layer_1": {
          "GPU_0": {
            "expert_id": 0,
            "responsibility": "Expert 0 for Layer 1 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 0, sends processed tokens to next layer"
          },
          "GPU_1": {
            "expert_id": 1,
            "responsibility": "Expert 1 for Layer 1 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 1, sends processed tokens to next layer"
          },
          "GPU_2": {
            "expert_id": 2,
            "responsibility": "Expert 2 for Layer 1 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 2, sends processed tokens to next layer"
          },
          "GPU_3": {
            "expert_id": 3,
            "responsibility": "Expert 3 for Layer 1 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 3, sends processed tokens to next layer"
          },
          "GPU_4": {
            "expert_id": 4,
            "responsibility": "Expert 4 for Layer 1 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 4, sends processed tokens to next layer"
          },
          "GPU_5": {
            "expert_id": 5,
            "responsibility": "Expert 5 for Layer 1 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 5, sends processed tokens to next layer"
          },
          "GPU_6": {
            "expert_id": 6,
            "responsibility": "Expert 6 for Layer 1 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 6, sends processed tokens to next layer"
          },
          "GPU_7": {
            "expert_id": 7,
            "responsibility": "Expert 7 for Layer 1 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 7, sends processed tokens to next layer"
          },
          "GPU_8": {
            "expert_id": 8,
            "responsibility": "Expert 8 for Layer 1 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 8, sends processed tokens to next layer"
          },
          "GPU_9": {
            "expert_id": 9,
            "responsibility": "Expert 9 for Layer 1 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 9, sends processed tokens to next layer"
          },
          "GPU_10": {
            "expert_id": 10,
            "responsibility": "Expert 10 for Layer 1 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 10, sends processed tokens to next layer"
          },
          "GPU_11": {
            "expert_id": 11,
            "responsibility": "Expert 11 for Layer 1 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 11, sends processed tokens to next layer"
          },
          "GPU_12": {
            "expert_id": 12,
            "responsibility": "Expert 12 for Layer 1 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 12, sends processed tokens to next layer"
          },
          "GPU_13": {
            "expert_id": 13,
            "responsibility": "Expert 13 for Layer 1 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 13, sends processed tokens to next layer"
          },
          "GPU_14": {
            "expert_id": 14,
            "responsibility": "Expert 14 for Layer 1 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 14, sends processed tokens to next layer"
          },
          "GPU_15": {
            "expert_id": 15,
            "responsibility": "Expert 15 for Layer 1 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 15, sends processed tokens to next layer"
          }
        },
        "layer_2": {
          "GPU_0": {
            "expert_id": 0,
            "responsibility": "Expert 0 for Layer 2 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 0, sends processed tokens to next layer"
          },
          "GPU_1": {
            "expert_id": 1,
            "responsibility": "Expert 1 for Layer 2 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 1, sends processed tokens to next layer"
          },
          "GPU_2": {
            "expert_id": 2,
            "responsibility": "Expert 2 for Layer 2 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 2, sends processed tokens to next layer"
          },
          "GPU_3": {
            "expert_id": 3,
            "responsibility": "Expert 3 for Layer 2 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 3, sends processed tokens to next layer"
          },
          "GPU_4": {
            "expert_id": 4,
            "responsibility": "Expert 4 for Layer 2 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 4, sends processed tokens to next layer"
          },
          "GPU_5": {
            "expert_id": 5,
            "responsibility": "Expert 5 for Layer 2 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 5, sends processed tokens to next layer"
          },
          "GPU_6": {
            "expert_id": 6,
            "responsibility": "Expert 6 for Layer 2 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 6, sends processed tokens to next layer"
          },
          "GPU_7": {
            "expert_id": 7,
            "responsibility": "Expert 7 for Layer 2 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 7, sends processed tokens to next layer"
          },
          "GPU_8": {
            "expert_id": 8,
            "responsibility": "Expert 8 for Layer 2 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 8, sends processed tokens to next layer"
          },
          "GPU_9": {
            "expert_id": 9,
            "responsibility": "Expert 9 for Layer 2 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 9, sends processed tokens to next layer"
          },
          "GPU_10": {
            "expert_id": 10,
            "responsibility": "Expert 10 for Layer 2 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 10, sends processed tokens to next layer"
          },
          "GPU_11": {
            "expert_id": 11,
            "responsibility": "Expert 11 for Layer 2 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 11, sends processed tokens to next layer"
          },
          "GPU_12": {
            "expert_id": 12,
            "responsibility": "Expert 12 for Layer 2 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 12, sends processed tokens to next layer"
          },
          "GPU_13": {
            "expert_id": 13,
            "responsibility": "Expert 13 for Layer 2 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 13, sends processed tokens to next layer"
          },
          "GPU_14": {
            "expert_id": 14,
            "responsibility": "Expert 14 for Layer 2 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 14, sends processed tokens to next layer"
          },
          "GPU_15": {
            "expert_id": 15,
            "responsibility": "Expert 15 for Layer 2 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 15, sends processed tokens to next layer"
          }
        },
        "layer_3": {
          "GPU_0": {
            "expert_id": 0,
            "responsibility": "Expert 0 for Layer 3 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 0, sends processed tokens to next layer"
          },
          "GPU_1": {
            "expert_id": 1,
            "responsibility": "Expert 1 for Layer 3 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 1, sends processed tokens to next layer"
          },
          "GPU_2": {
            "expert_id": 2,
            "responsibility": "Expert 2 for Layer 3 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 2, sends processed tokens to next layer"
          },
          "GPU_3": {
            "expert_id": 3,
            "responsibility": "Expert 3 for Layer 3 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 3, sends processed tokens to next layer"
          },
          "GPU_4": {
            "expert_id": 4,
            "responsibility": "Expert 4 for Layer 3 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 4, sends processed tokens to next layer"
          },
          "GPU_5": {
            "expert_id": 5,
            "responsibility": "Expert 5 for Layer 3 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 5, sends processed tokens to next layer"
          },
          "GPU_6": {
            "expert_id": 6,
            "responsibility": "Expert 6 for Layer 3 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 6, sends processed tokens to next layer"
          },
          "GPU_7": {
            "expert_id": 7,
            "responsibility": "Expert 7 for Layer 3 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 7, sends processed tokens to next layer"
          },
          "GPU_8": {
            "expert_id": 8,
            "responsibility": "Expert 8 for Layer 3 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 8, sends processed tokens to next layer"
          },
          "GPU_9": {
            "expert_id": 9,
            "responsibility": "Expert 9 for Layer 3 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 9, sends processed tokens to next layer"
          },
          "GPU_10": {
            "expert_id": 10,
            "responsibility": "Expert 10 for Layer 3 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 10, sends processed tokens to next layer"
          },
          "GPU_11": {
            "expert_id": 11,
            "responsibility": "Expert 11 for Layer 3 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 11, sends processed tokens to next layer"
          },
          "GPU_12": {
            "expert_id": 12,
            "responsibility": "Expert 12 for Layer 3 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 12, sends processed tokens to next layer"
          },
          "GPU_13": {
            "expert_id": 13,
            "responsibility": "Expert 13 for Layer 3 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 13, sends processed tokens to next layer"
          },
          "GPU_14": {
            "expert_id": 14,
            "responsibility": "Expert 14 for Layer 3 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 14, sends processed tokens to next layer"
          },
          "GPU_15": {
            "expert_id": 15,
            "responsibility": "Expert 15 for Layer 3 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 15, sends processed tokens to next layer"
          }
        },
        "layer_4": {
          "GPU_0": {
            "expert_id": 0,
            "responsibility": "Expert 0 for Layer 4 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 0, sends processed tokens to next layer"
          },
          "GPU_1": {
            "expert_id": 1,
            "responsibility": "Expert 1 for Layer 4 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 1, sends processed tokens to next layer"
          },
          "GPU_2": {
            "expert_id": 2,
            "responsibility": "Expert 2 for Layer 4 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 2, sends processed tokens to next layer"
          },
          "GPU_3": {
            "expert_id": 3,
            "responsibility": "Expert 3 for Layer 4 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 3, sends processed tokens to next layer"
          },
          "GPU_4": {
            "expert_id": 4,
            "responsibility": "Expert 4 for Layer 4 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 4, sends processed tokens to next layer"
          },
          "GPU_5": {
            "expert_id": 5,
            "responsibility": "Expert 5 for Layer 4 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 5, sends processed tokens to next layer"
          },
          "GPU_6": {
            "expert_id": 6,
            "responsibility": "Expert 6 for Layer 4 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 6, sends processed tokens to next layer"
          },
          "GPU_7": {
            "expert_id": 7,
            "responsibility": "Expert 7 for Layer 4 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 7, sends processed tokens to next layer"
          },
          "GPU_8": {
            "expert_id": 8,
            "responsibility": "Expert 8 for Layer 4 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 8, sends processed tokens to next layer"
          },
          "GPU_9": {
            "expert_id": 9,
            "responsibility": "Expert 9 for Layer 4 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 9, sends processed tokens to next layer"
          },
          "GPU_10": {
            "expert_id": 10,
            "responsibility": "Expert 10 for Layer 4 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 10, sends processed tokens to next layer"
          },
          "GPU_11": {
            "expert_id": 11,
            "responsibility": "Expert 11 for Layer 4 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 11, sends processed tokens to next layer"
          },
          "GPU_12": {
            "expert_id": 12,
            "responsibility": "Expert 12 for Layer 4 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 12, sends processed tokens to next layer"
          },
          "GPU_13": {
            "expert_id": 13,
            "responsibility": "Expert 13 for Layer 4 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 13, sends processed tokens to next layer"
          },
          "GPU_14": {
            "expert_id": 14,
            "responsibility": "Expert 14 for Layer 4 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 14, sends processed tokens to next layer"
          },
          "GPU_15": {
            "expert_id": 15,
            "responsibility": "Expert 15 for Layer 4 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 15, sends processed tokens to next layer"
          }
        },
        "layer_5": {
          "GPU_0": {
            "expert_id": 0,
            "responsibility": "Expert 0 for Layer 5 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 0, sends processed tokens to next layer"
          },
          "GPU_1": {
            "expert_id": 1,
            "responsibility": "Expert 1 for Layer 5 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 1, sends processed tokens to next layer"
          },
          "GPU_2": {
            "expert_id": 2,
            "responsibility": "Expert 2 for Layer 5 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 2, sends processed tokens to next layer"
          },
          "GPU_3": {
            "expert_id": 3,
            "responsibility": "Expert 3 for Layer 5 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 3, sends processed tokens to next layer"
          },
          "GPU_4": {
            "expert_id": 4,
            "responsibility": "Expert 4 for Layer 5 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 4, sends processed tokens to next layer"
          },
          "GPU_5": {
            "expert_id": 5,
            "responsibility": "Expert 5 for Layer 5 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 5, sends processed tokens to next layer"
          },
          "GPU_6": {
            "expert_id": 6,
            "responsibility": "Expert 6 for Layer 5 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 6, sends processed tokens to next layer"
          },
          "GPU_7": {
            "expert_id": 7,
            "responsibility": "Expert 7 for Layer 5 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 7, sends processed tokens to next layer"
          },
          "GPU_8": {
            "expert_id": 8,
            "responsibility": "Expert 8 for Layer 5 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 8, sends processed tokens to next layer"
          },
          "GPU_9": {
            "expert_id": 9,
            "responsibility": "Expert 9 for Layer 5 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 9, sends processed tokens to next layer"
          },
          "GPU_10": {
            "expert_id": 10,
            "responsibility": "Expert 10 for Layer 5 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 10, sends processed tokens to next layer"
          },
          "GPU_11": {
            "expert_id": 11,
            "responsibility": "Expert 11 for Layer 5 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 11, sends processed tokens to next layer"
          },
          "GPU_12": {
            "expert_id": 12,
            "responsibility": "Expert 12 for Layer 5 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 12, sends processed tokens to next layer"
          },
          "GPU_13": {
            "expert_id": 13,
            "responsibility": "Expert 13 for Layer 5 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 13, sends processed tokens to next layer"
          },
          "GPU_14": {
            "expert_id": 14,
            "responsibility": "Expert 14 for Layer 5 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 14, sends processed tokens to next layer"
          },
          "GPU_15": {
            "expert_id": 15,
            "responsibility": "Expert 15 for Layer 5 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 15, sends processed tokens to next layer"
          }
        },
        "layer_6": {
          "GPU_0": {
            "expert_id": 0,
            "responsibility": "Expert 0 for Layer 6 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 0, sends processed tokens to next layer"
          },
          "GPU_1": {
            "expert_id": 1,
            "responsibility": "Expert 1 for Layer 6 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 1, sends processed tokens to next layer"
          },
          "GPU_2": {
            "expert_id": 2,
            "responsibility": "Expert 2 for Layer 6 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 2, sends processed tokens to next layer"
          },
          "GPU_3": {
            "expert_id": 3,
            "responsibility": "Expert 3 for Layer 6 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 3, sends processed tokens to next layer"
          },
          "GPU_4": {
            "expert_id": 4,
            "responsibility": "Expert 4 for Layer 6 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 4, sends processed tokens to next layer"
          },
          "GPU_5": {
            "expert_id": 5,
            "responsibility": "Expert 5 for Layer 6 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 5, sends processed tokens to next layer"
          },
          "GPU_6": {
            "expert_id": 6,
            "responsibility": "Expert 6 for Layer 6 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 6, sends processed tokens to next layer"
          },
          "GPU_7": {
            "expert_id": 7,
            "responsibility": "Expert 7 for Layer 6 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 7, sends processed tokens to next layer"
          },
          "GPU_8": {
            "expert_id": 8,
            "responsibility": "Expert 8 for Layer 6 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 8, sends processed tokens to next layer"
          },
          "GPU_9": {
            "expert_id": 9,
            "responsibility": "Expert 9 for Layer 6 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 9, sends processed tokens to next layer"
          },
          "GPU_10": {
            "expert_id": 10,
            "responsibility": "Expert 10 for Layer 6 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 10, sends processed tokens to next layer"
          },
          "GPU_11": {
            "expert_id": 11,
            "responsibility": "Expert 11 for Layer 6 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 11, sends processed tokens to next layer"
          },
          "GPU_12": {
            "expert_id": 12,
            "responsibility": "Expert 12 for Layer 6 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 12, sends processed tokens to next layer"
          },
          "GPU_13": {
            "expert_id": 13,
            "responsibility": "Expert 13 for Layer 6 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 13, sends processed tokens to next layer"
          },
          "GPU_14": {
            "expert_id": 14,
            "responsibility": "Expert 14 for Layer 6 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 14, sends processed tokens to next layer"
          },
          "GPU_15": {
            "expert_id": 15,
            "responsibility": "Expert 15 for Layer 6 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 15, sends processed tokens to next layer"
          }
        },
        "layer_7": {
          "GPU_0": {
            "expert_id": 0,
            "responsibility": "Expert 0 for Layer 7 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 0, sends processed tokens to next layer"
          },
          "GPU_1": {
            "expert_id": 1,
            "responsibility": "Expert 1 for Layer 7 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 1, sends processed tokens to next layer"
          },
          "GPU_2": {
            "expert_id": 2,
            "responsibility": "Expert 2 for Layer 7 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 2, sends processed tokens to next layer"
          },
          "GPU_3": {
            "expert_id": 3,
            "responsibility": "Expert 3 for Layer 7 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 3, sends processed tokens to next layer"
          }, "GPU_4": {
            "expert_id": 4,
            "responsibility": "Expert 4 for Layer 7 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 4, sends processed tokens to next layer"
          },
          "GPU_5": {
            "expert_id": 5,
            "responsibility": "Expert 5 for Layer 7 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 5, sends processed tokens to next layer"
          },
          "GPU_6": {
            "expert_id": 6,
            "responsibility": "Expert 6 for Layer 7 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 6, sends processed tokens to next layer"
          },
          "GPU_7": {
            "expert_id": 7,
            "responsibility": "Expert 7 for Layer 7 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 7, sends processed tokens to next layer"
          },
          "GPU_8": {
            "expert_id": 8,
            "responsibility": "Expert 8 for Layer 7 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 8, sends processed tokens to next layer"
          },
          "GPU_9": {
            "expert_id": 9,
            "responsibility": "Expert 9 for Layer 7 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 9, sends processed tokens to next layer"
          },
          "GPU_10": {
            "expert_id": 10,
            "responsibility": "Expert 10 for Layer 7 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 10, sends processed tokens to next layer"
          },
          "GPU_11": {
            "expert_id": 11,
            "responsibility": "Expert 11 for Layer 7 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 11, sends processed tokens to next layer"
          },
          "GPU_12": {
            "expert_id": 12,
            "responsibility": "Expert 12 for Layer 7 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 12, sends processed tokens to next layer"
          },
          "GPU_13": {
            "expert_id": 13,
            "responsibility": "Expert 13 for Layer 7 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 13, sends processed tokens to next layer"
          },
          "GPU_14": {
            "expert_id": 14,
            "responsibility": "Expert 14 for Layer 7 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 14, sends processed tokens to next layer"
          },
          "GPU_15": {
            "expert_id": 15,
            "responsibility": "Expert 15 for Layer 7 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 15, sends processed tokens to next layer"
          }
        },
        "layer_8": {
          "GPU_0": {
            "expert_id": 0,
            "responsibility": "Expert 0 for Layer 8 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 0, sends processed tokens to next layer"
          },
          "GPU_1": {
            "expert_id": 1,
            "responsibility": "Expert 1 for Layer 8 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 1, sends processed tokens to next layer"
          },
          "GPU_2": {
            "expert_id": 2,
            "responsibility": "Expert 2 for Layer 8 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 2, sends processed tokens to next layer"
          },
          "GPU_3": {
            "expert_id": 3,
            "responsibility": "Expert 3 for Layer 8 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 3, sends processed tokens to next layer"
          },
          "GPU_4": {
            "expert_id": 4,
            "responsibility": "Expert 4 for Layer 8 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 4, sends processed tokens to next layer"
          },
          "GPU_5": {
            "expert_id": 5,
            "responsibility": "Expert 5 for Layer 8 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 5, sends processed tokens to next layer"
          },
          "GPU_6": {
            "expert_id": 6,
            "responsibility": "Expert 6 for Layer 8 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 6, sends processed tokens to next layer"
          },
          "GPU_7": {
            "expert_id": 7,
            "responsibility": "Expert 7 for Layer 8 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 7, sends processed tokens to next layer"
          },
          "GPU_8": {
            "expert_id": 8,
            "responsibility": "Expert 8 for Layer 8 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 8, sends processed tokens to next layer"
          },
          "GPU_9": {
            "expert_id": 9,
            "responsibility": "Expert 9 for Layer 8 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 9, sends processed tokens to next layer"
          },
          "GPU_10": {
            "expert_id": 10,
            "responsibility": "Expert 10 for Layer 8 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 10, sends processed tokens to next layer"
          },
          "GPU_11": {
            "expert_id": 11,
            "responsibility": "Expert 11 for Layer 8 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 11, sends processed tokens to next layer"
          },
          "GPU_12": {
            "expert_id": 12,
            "responsibility": "Expert 12 for Layer 8 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 12, sends processed tokens to next layer"
          },
          "GPU_13": {
            "expert_id": 13,
            "responsibility": "Expert 13 for Layer 8 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 13, sends processed tokens to next layer"
          },
          "GPU_14": {
            "expert_id": 14,
            "responsibility": "Expert 14 for Layer 8 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 14, sends processed tokens to next layer"
          },
          "GPU_15": {
            "expert_id": 15,
            "responsibility": "Expert 15 for Layer 8 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 15, sends processed tokens to next layer"
          }
        },
        "layer_9": {
          "GPU_0": {
            "expert_id": 0,
            "responsibility": "Expert 0 for Layer 9 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 0, sends processed tokens to next layer"
          },
          "GPU_1": {
            "expert_id": 1,
            "responsibility": "Expert 1 for Layer 9 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 1, sends processed tokens to next layer"
          },
          "GPU_2": {
            "expert_id": 2,
            "responsibility": "Expert 2 for Layer 9 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 2, sends processed tokens to next layer"
          },
          "GPU_3": {
            "expert_id": 3,
            "responsibility": "Expert 3 for Layer 9 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 3, sends processed tokens to next layer"
          },
          "GPU_4": {
            "expert_id": 4,
            "responsibility": "Expert 4 for Layer 9 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 4, sends processed tokens to next layer"
          },
          "GPU_5": {
            "expert_id": 5,
            "responsibility": "Expert 5 for Layer 9 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 5, sends processed tokens to next layer"
          },
          "GPU_6": {
            "expert_id": 6,
            "responsibility": "Expert 6 for Layer 9 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 6, sends processed tokens to next layer"
          },
          "GPU_7": {
            "expert_id": 7,
            "responsibility": "Expert 7 for Layer 9 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 7, sends processed tokens to next layer"
          },
          "GPU_8": {
            "expert_id": 8,
            "responsibility": "Expert 8 for Layer 9 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 8, sends processed tokens to next layer"
          },
          "GPU_9": {
            "expert_id": 9,
            "responsibility": "Expert 9 for Layer 9 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Receives tokens for Expert 9, sends processed tokens to next layer"
          },
          "GPU_10": {
            "expert_id": 10,
            "responsibility": "Expert 10 for Layer 9 - Complete MLP (4096->16384->4096)",
            "memory_allocation": "Complete expert MLP parameters and activations",
            "communication_role": "Rece