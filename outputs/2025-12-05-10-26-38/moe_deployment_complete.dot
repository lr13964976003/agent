digraph MoE_Deployment_Complete {
    graph [bgcolor=white, rankdir=TB, splines=ortho, ranksep=1.5, nodesep=0.8];
    node [shape=rectangle, style=filled, fillcolor=lightblue, fontname="Arial", fontsize=10];
    edge [fontname="Arial", fontsize=9];
    
    # Input node - ellipse
    input [shape=ellipse, fillcolor=white, label="Input\n[batch_size=128, seq_len=1024, hidden=1024]\nGPU: ALL"];
    
    # Data parallel split - parallelogram  
    dp_split [shape=parallelogram, fillcolor=lightpink, label="Data Parallel Split\n[batch_size=64, seq_len=1024, hidden=1024]\nGPU: Routing"];
    input -> dp_split;
        layer0_attn_qkv_gpu0 [fillcolor=lightblue, label="Layer0 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 0"];\n    layer0_attn_score_gpu0 [fillcolor=lightblue, label="Layer0 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 0"];\n    layer0_attn_out_gpu0 [fillcolor=lightblue, label="Layer0 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 0"];\n    layer0_attn_qkv_gpu0 -> layer0_attn_score_gpu0;\n    layer0_attn_score_gpu0 -> layer0_attn_out_gpu0;\n    layer0_attn_qkv_gpu1 [fillcolor=lightblue, label="Layer0 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 1"];\n    layer0_attn_score_gpu1 [fillcolor=lightblue, label="Layer0 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 1"];\n    layer0_attn_out_gpu1 [fillcolor=lightblue, label="Layer0 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 1"];\n    layer0_attn_qkv_gpu1 -> layer0_attn_score_gpu1;\n    layer0_attn_score_gpu1 -> layer0_attn_out_gpu1;\n    layer0_attn_qkv_gpu2 [fillcolor=lightblue, label="Layer0 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 2"];\n    layer0_attn_score_gpu2 [fillcolor=lightblue, label="Layer0 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 2"];\n    layer0_attn_out_gpu2 [fillcolor=lightblue, label="Layer0 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 2"];\n    layer0_attn_qkv_gpu2 -> layer0_attn_score_gpu2;\n    layer0_attn_score_gpu2 -> layer0_attn_out_gpu2;\n    layer0_attn_qkv_gpu3 [fillcolor=lightblue, label="Layer0 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 3"];\n    layer0_attn_score_gpu3 [fillcolor=lightblue, label="Layer0 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 3"];\n    layer0_attn_out_gpu3 [fillcolor=lightblue, label="Layer0 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 3"];\n    layer0_attn_qkv_gpu3 -> layer0_attn_score_gpu3;\n    layer0_attn_score_gpu3 -> layer0_attn_out_gpu3;\n    layer0_attn_allreduce [shape=ellipse, fillcolor=lightgray, label="Layer0 Attention\nAll-Reduce Sum\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1024]\nGPU: 0,1,2,3"];\n    layer0_attn_out_gpu0 -> layer0_attn_allreduce;\n    layer0_attn_out_gpu1 -> layer0_attn_allreduce;\n    layer0_attn_out_gpu2 -> layer0_attn_allreduce;\n    layer0_attn_out_gpu3 -> layer0_attn_allreduce;\n    dp_split -> layer0_attn_qkv_gpu0;\n    dp_split -> layer0_attn_qkv_gpu1;\n    dp_split -> layer0_attn_qkv_gpu2;\n    dp_split -> layer0_attn_qkv_gpu3;\n    layer0_moe_route [shape=parallelogram, fillcolor=lightblue, label="Layer0 MoE Routing\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1]\nGPU: 0,1,2,3"];\n    layer0_attn_allreduce -> layer0_moe_route;\n    layer0_moe_route_gpu0 [shape=parallelogram, fillcolor=lightblue, label="Layer0 MoE Route\nGPU: 0"];\n    layer0_moe_route -> layer0_moe_route_gpu0;\n    layer0_moe_route_gpu1 [shape=parallelogram, fillcolor=lightblue, label="Layer0 MoE Route\nGPU: 1"];\n    layer0_moe_route -> layer0_moe_route_gpu1;\n    layer0_moe_route_gpu2 [shape=parallelogram, fillcolor=lightblue, label="Layer0 MoE Route\nGPU: 2"];\n    layer0_moe_route -> layer0_moe_route_gpu2;\n    layer0_moe_route_gpu3 [shape=parallelogram, fillcolor=lightblue, label="Layer0 MoE Route\nGPU: 3"];\n    layer0_moe_route -> layer0_moe_route_gpu3;\n    layer0_moe_all2all [shape=ellipse, fillcolor=lightgray, label="Layer0 MoE\nAll-to-All Communication\nGPU: 0-15"];\n    layer0_moe_route_gpu0 -> layer0_moe_all2all;\n    layer0_moe_route_gpu1 -> layer0_moe_all2all;\n    layer0_moe_route_gpu2 -> layer0_moe_all2all;\n    layer0_moe_route_gpu3 -> layer0_moe_all2all;\n    layer0_expert0 [fillcolor=lightblue, label="Layer0 Expert 0_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 0"];\n    layer0_moe_all2all -> layer0_expert0;\n    layer0_expert1 [fillcolor=lightblue, label="Layer0 Expert 0_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 1"];\n    layer0_moe_all2all -> layer0_expert1;\n    layer0_expert2 [fillcolor=lightblue, label="Layer0 Expert 0_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 2"];\n    layer0_moe_all2all -> layer0_expert2;\n    layer0_expert3 [fillcolor=lightblue, label="Layer0 Expert 0_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 3"];\n    layer0_moe_all2all -> layer0_expert3;\n    layer0_expert4 [fillcolor=lightgreen, label="Layer0 Expert 1_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 4"];\n    layer0_moe_all2all -> layer0_expert4;\n    layer0_expert5 [fillcolor=lightgreen, label="Layer0 Expert 1_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 5"];\n    layer0_moe_all2all -> layer0_expert5;\n    layer0_expert6 [fillcolor=lightgreen, label="Layer0 Expert 1_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 6"];\n    layer0_moe_all2all -> layer0_expert6;\n    layer0_expert7 [fillcolor=lightgreen, label="Layer0 Expert 1_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 7"];\n    layer0_moe_all2all -> layer0_expert7;\n    layer0_expert8 [fillcolor=lightyellow, label="Layer0 Expert 2_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 8"];\n    layer0_moe_all2all -> layer0_expert8;\n    layer0_expert9 [fillcolor=lightyellow, label="Layer0 Expert 2_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 9"];\n    layer0_moe_all2all -> layer0_expert9;\n    layer0_expert10 [fillcolor=lightyellow, label="Layer0 Expert 2_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 10"];\n    layer0_moe_all2all -> layer0_expert10;\n    layer0_expert11 [fillcolor=lightyellow, label="Layer0 Expert 2_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 11"];\n    layer0_moe_all2all -> layer0_expert11;\n    layer0_expert12 [fillcolor=lightcoral, label="Layer0 Expert 3_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 12"];\n    layer0_moe_all2all -> layer0_expert12;\n    layer0_expert13 [fillcolor=lightcoral, label="Layer0 Expert 3_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 13"];\n    layer0_moe_all2all -> layer0_expert13;\n    layer0_expert14 [fillcolor=lightcoral, label="Layer0 Expert 3_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 14"];\n    layer0_moe_all2all -> layer0_expert14;\n    layer0_expert15 [fillcolor=lightcoral, label="Layer0 Expert 3_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 15"];\n    layer0_moe_all2all -> layer0_expert15;\n    layer0_moe_agg [shape=parallelogram, fillcolor=lightblue, label="Layer0 MoE\nOutput Aggregation\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1024]\nGPU: 0,1,2,3"];\n    layer0_expert0 -> layer0_moe_agg;\n    layer0_expert1 -> layer0_moe_agg;\n    layer0_expert2 -> layer0_moe_agg;\n    layer0_expert3 -> layer0_moe_agg;\n    layer0_expert4 -> layer0_moe_agg;\n    layer0_expert5 -> layer0_moe_agg;\n    layer0_expert6 -> layer0_moe_agg;\n    layer0_expert7 -> layer0_moe_agg;\n    layer0_expert8 -> layer0_moe_agg;\n    layer0_expert9 -> layer0_moe_agg;\n    layer0_expert10 -> layer0_moe_agg;\n    layer0_expert11 -> layer0_moe_agg;\n    layer0_expert12 -> layer0_moe_agg;\n    layer0_expert13 -> layer0_moe_agg;\n    layer0_expert14 -> layer0_moe_agg;\n    layer0_expert15 -> layer0_moe_agg;\n    layer1_attn_qkv_gpu0 [fillcolor=lightblue, label="Layer1 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 0"];\n    layer1_attn_score_gpu0 [fillcolor=lightblue, label="Layer1 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 0"];\n    layer1_attn_out_gpu0 [fillcolor=lightblue, label="Layer1 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 0"];\n    layer1_attn_qkv_gpu0 -> layer1_attn_score_gpu0;\n    layer1_attn_score_gpu0 -> layer1_attn_out_gpu0;\n    layer1_attn_qkv_gpu1 [fillcolor=lightblue, label="Layer1 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 1"];\n    layer1_attn_score_gpu1 [fillcolor=lightblue, label="Layer1 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 1"];\n    layer1_attn_out_gpu1 [fillcolor=lightblue, label="Layer1 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 1"];\n    layer1_attn_qkv_gpu1 -> layer1_attn_score_gpu1;\n    layer1_attn_score_gpu1 -> layer1_attn_out_gpu1;\n    layer1_attn_qkv_gpu2 [fillcolor=lightblue, label="Layer1 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 2"];\n    layer1_attn_score_gpu2 [fillcolor=lightblue, label="Layer1 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 2"];\n    layer1_attn_out_gpu2 [fillcolor=lightblue, label="Layer1 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 2"];\n    layer1_attn_qkv_gpu2 -> layer1_attn_score_gpu2;\n    layer1_attn_score_gpu2 -> layer1_attn_out_gpu2;\n    layer1_attn_qkv_gpu3 [fillcolor=lightblue, label="Layer1 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 3"];\n    layer1_attn_score_gpu3 [fillcolor=lightblue, label="Layer1 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 3"];\n    layer1_attn_out_gpu3 [fillcolor=lightblue, label="Layer1 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 3"];\n    layer1_attn_qkv_gpu3 -> layer1_attn_score_gpu3;\n    layer1_attn_score_gpu3 -> layer1_attn_out_gpu3;\n    layer1_attn_allreduce [shape=ellipse, fillcolor=lightgray, label="Layer1 Attention\nAll-Reduce Sum\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1024]\nGPU: 0,1,2,3"];\n    layer1_attn_out_gpu0 -> layer1_attn_allreduce;\n    layer1_attn_out_gpu1 -> layer1_attn_allreduce;\n    layer1_attn_out_gpu2 -> layer1_attn_allreduce;\n    layer1_attn_out_gpu3 -> layer1_attn_allreduce;\n    layer0_moe_agg -> layer1_attn_qkv_gpu0;\n    layer0_moe_agg -> layer1_attn_qkv_gpu1;\n    layer0_moe_agg -> layer1_attn_qkv_gpu2;\n    layer0_moe_agg -> layer1_attn_qkv_gpu3;\n    layer1_moe_route [shape=parallelogram, fillcolor=lightblue, label="Layer1 MoE Routing\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1]\nGPU: 0,1,2,3"];\n    layer1_attn_allreduce -> layer1_moe_route;\n    layer1_moe_route_gpu0 [shape=parallelogram, fillcolor=lightblue, label="Layer1 MoE Route\nGPU: 0"];\n    layer1_moe_route -> layer1_moe_route_gpu0;\n    layer1_moe_route_gpu1 [shape=parallelogram, fillcolor=lightblue, label="Layer1 MoE Route\nGPU: 1"];\n    layer1_moe_route -> layer1_moe_route_gpu1;\n    layer1_moe_route_gpu2 [shape=parallelogram, fillcolor=lightblue, label="Layer1 MoE Route\nGPU: 2"];\n    layer1_moe_route -> layer1_moe_route_gpu2;\n    layer1_moe_route_gpu3 [shape=parallelogram, fillcolor=lightblue, label="Layer1 MoE Route\nGPU: 3"];\n    layer1_moe_route -> layer1_moe_route_gpu3;\n    layer1_moe_all2all [shape=ellipse, fillcolor=lightgray, label="Layer1 MoE\nAll-to-All Communication\nGPU: 0-15"];\n    layer1_moe_route_gpu0 -> layer1_moe_all2all;\n    layer1_moe_route_gpu1 -> layer1_moe_all2all;\n    layer1_moe_route_gpu2 -> layer1_moe_all2all;\n    layer1_moe_route_gpu3 -> layer1_moe_all2all;\n    layer1_expert0 [fillcolor=lightblue, label="Layer1 Expert 0_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 0"];\n    layer1_moe_all2all -> layer1_expert0;\n    layer1_expert1 [fillcolor=lightblue, label="Layer1 Expert 0_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 1"];\n    layer1_moe_all2all -> layer1_expert1;\n    layer1_expert2 [fillcolor=lightblue, label="Layer1 Expert 0_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 2"];\n    layer1_moe_all2all -> layer1_expert2;\n    layer1_expert3 [fillcolor=lightblue, label="Layer1 Expert 0_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 3"];\n    layer1_moe_all2all -> layer1_expert3;\n    layer1_expert4 [fillcolor=lightgreen, label="Layer1 Expert 1_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 4"];\n    layer1_moe_all2all -> layer1_expert4;\n    layer1_expert5 [fillcolor=lightgreen, label="Layer1 Expert 1_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 5"];\n    layer1_moe_all2all -> layer1_expert5;\n    layer1_expert6 [fillcolor=lightgreen, label="Layer1 Expert 1_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 6"];\n    layer1_moe_all2all -> layer1_expert6;\n    layer1_expert7 [fillcolor=lightgreen, label="Layer1 Expert 1_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 7"];\n    layer1_moe_all2all -> layer1_expert7;\n    layer1_expert8 [fillcolor=lightyellow, label="Layer1 Expert 2_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 8"];\n    layer1_moe_all2all -> layer1_expert8;\n    layer1_expert9 [fillcolor=lightyellow, label="Layer1 Expert 2_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 9"];\n    layer1_moe_all2all -> layer1_expert9;\n    layer1_expert10 [fillcolor=lightyellow, label="Layer1 Expert 2_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 10"];\n    layer1_moe_all2all -> layer1_expert10;\n    layer1_expert11 [fillcolor=lightyellow, label="Layer1 Expert 2_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 11"];\n    layer1_moe_all2all -> layer1_expert11;\n    layer1_expert12 [fillcolor=lightcoral, label="Layer1 Expert 3_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 12"];\n    layer1_moe_all2all -> layer1_expert12;\n    layer1_expert13 [fillcolor=lightcoral, label="Layer1 Expert 3_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 13"];\n    layer1_moe_all2all -> layer1_expert13;\n    layer1_expert14 [fillcolor=lightcoral, label="Layer1 Expert 3_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 14"];\n    layer1_moe_all2all -> layer1_expert14;\n    layer1_expert15 [fillcolor=lightcoral, label="Layer1 Expert 3_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 15"];\n    layer1_moe_all2all -> layer1_expert15;\n    layer1_moe_agg [shape=parallelogram, fillcolor=lightblue, label="Layer1 MoE\nOutput Aggregation\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1024]\nGPU: 0,1,2,3"];\n    layer1_expert0 -> layer1_moe_agg;\n    layer1_expert1 -> layer1_moe_agg;\n    layer1_expert2 -> layer1_moe_agg;\n    layer1_expert3 -> layer1_moe_agg;\n    layer1_expert4 -> layer1_moe_agg;\n    layer1_expert5 -> layer1_moe_agg;\n    layer1_expert6 -> layer1_moe_agg;\n    layer1_expert7 -> layer1_moe_agg;\n    layer1_expert8 -> layer1_moe_agg;\n    layer1_expert9 -> layer1_moe_agg;\n    layer1_expert10 -> layer1_moe_agg;\n    layer1_expert11 -> layer1_moe_agg;\n    layer1_expert12 -> layer1_moe_agg;\n    layer1_expert13 -> layer1_moe_agg;\n    layer1_expert14 -> layer1_moe_agg;\n    layer1_expert15 -> layer1_moe_agg;\n    layer2_attn_qkv_gpu0 [fillcolor=lightblue, label="Layer2 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 0"];\n    layer2_attn_score_gpu0 [fillcolor=lightblue, label="Layer2 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 0"];\n    layer2_attn_out_gpu0 [fillcolor=lightblue, label="Layer2 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 0"];\n    layer2_attn_qkv_gpu0 -> layer2_attn_score_gpu0;\n    layer2_attn_score_gpu0 -> layer2_attn_out_gpu0;\n    layer2_attn_qkv_gpu1 [fillcolor=lightblue, label="Layer2 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 1"];\n    layer2_attn_score_gpu1 [fillcolor=lightblue, label="Layer2 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 1"];\n    layer2_attn_out_gpu1 [fillcolor=lightblue, label="Layer2 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 1"];\n    layer2_attn_qkv_gpu1 -> layer2_attn_score_gpu1;\n    layer2_attn_score_gpu1 -> layer2_attn_out_gpu1;\n    layer2_attn_qkv_gpu2 [fillcolor=lightblue, label="Layer2 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 2"];\n    layer2_attn_score_gpu2 [fillcolor=lightblue, label="Layer2 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 2"];\n    layer2_attn_out_gpu2 [fillcolor=lightblue, label="Layer2 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 2"];\n    layer2_attn_qkv_gpu2 -> layer2_attn_score_gpu2;\n    layer2_attn_score_gpu2 -> layer2_attn_out_gpu2;\n    layer2_attn_qkv_gpu3 [fillcolor=lightblue, label="Layer2 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 3"];\n    layer2_attn_score_gpu3 [fillcolor=lightblue, label="Layer2 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 3"];\n    layer2_attn_out_gpu3 [fillcolor=lightblue, label="Layer2 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 3"];\n    layer2_attn_qkv_gpu3 -> layer2_attn_score_gpu3;\n    layer2_attn_score_gpu3 -> layer2_attn_out_gpu3;\n    layer2_attn_allreduce [shape=ellipse, fillcolor=lightgray, label="Layer2 Attention\nAll-Reduce Sum\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1024]\nGPU: 0,1,2,3"];\n    layer2_attn_out_gpu0 -> layer2_attn_allreduce;\n    layer2_attn_out_gpu1 -> layer2_attn_allreduce;\n    layer2_attn_out_gpu2 -> layer2_attn_allreduce;\n    layer2_attn_out_gpu3 -> layer2_attn_allreduce;\n    layer1_moe_agg -> layer2_attn_qkv_gpu0;\n    layer1_moe_agg -> layer2_attn_qkv_gpu1;\n    layer1_moe_agg -> layer2_attn_qkv_gpu2;\n    layer1_moe_agg -> layer2_attn_qkv_gpu3;\n    layer2_moe_route [shape=parallelogram, fillcolor=lightblue, label="Layer2 MoE Routing\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1]\nGPU: 0,1,2,3"];\n    layer2_attn_allreduce -> layer2_moe_route;\n    layer2_moe_route_gpu0 [shape=parallelogram, fillcolor=lightblue, label="Layer2 MoE Route\nGPU: 0"];\n    layer2_moe_route -> layer2_moe_route_gpu0;\n    layer2_moe_route_gpu1 [shape=parallelogram, fillcolor=lightblue, label="Layer2 MoE Route\nGPU: 1"];\n    layer2_moe_route -> layer2_moe_route_gpu1;\n    layer2_moe_route_gpu2 [shape=parallelogram, fillcolor=lightblue, label="Layer2 MoE Route\nGPU: 2"];\n    layer2_moe_route -> layer2_moe_route_gpu2;\n    layer2_moe_route_gpu3 [shape=parallelogram, fillcolor=lightblue, label="Layer2 MoE Route\nGPU: 3"];\n    layer2_moe_route -> layer2_moe_route_gpu3;\n    layer2_moe_all2all [shape=ellipse, fillcolor=lightgray, label="Layer2 MoE\nAll-to-All Communication\nGPU: 0-15"];\n    layer2_moe_route_gpu0 -> layer2_moe_all2all;\n    layer2_moe_route_gpu1 -> layer2_moe_all2all;\n    layer2_moe_route_gpu2 -> layer2_moe_all2all;\n    layer2_moe_route_gpu3 -> layer2_moe_all2all;\n    layer2_expert0 [fillcolor=lightblue, label="Layer2 Expert 0_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 0"];\n    layer2_moe_all2all -> layer2_expert0;\n    layer2_expert1 [fillcolor=lightblue, label="Layer2 Expert 0_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 1"];\n    layer2_moe_all2all -> layer2_expert1;\n    layer2_expert2 [fillcolor=lightblue, label="Layer2 Expert 0_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 2"];\n    layer2_moe_all2all -> layer2_expert2;\n    layer2_expert3 [fillcolor=lightblue, label="Layer2 Expert 0_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 3"];\n    layer2_moe_all2all -> layer2_expert3;\n    layer2_expert4 [fillcolor=lightgreen, label="Layer2 Expert 1_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 4"];\n    layer2_moe_all2all -> layer2_expert4;\n    layer2_expert5 [fillcolor=lightgreen, label="Layer2 Expert 1_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 5"];\n    layer2_moe_all2all -> layer2_expert5;\n    layer2_expert6 [fillcolor=lightgreen, label="Layer2 Expert 1_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 6"];\n    layer2_moe_all2all -> layer2_expert6;\n    layer2_expert7 [fillcolor=lightgreen, label="Layer2 Expert 1_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 7"];\n    layer2_moe_all2all -> layer2_expert7;\n    layer2_expert8 [fillcolor=lightyellow, label="Layer2 Expert 2_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 8"];\n    layer2_moe_all2all -> layer2_expert8;\n    layer2_expert9 [fillcolor=lightyellow, label="Layer2 Expert 2_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 9"];\n    layer2_moe_all2all -> layer2_expert9;\n    layer2_expert10 [fillcolor=lightyellow, label="Layer2 Expert 2_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 10"];\n    layer2_moe_all2all -> layer2_expert10;\n    layer2_expert11 [fillcolor=lightyellow, label="Layer2 Expert 2_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 11"];\n    layer2_moe_all2all -> layer2_expert11;\n    layer2_expert12 [fillcolor=lightcoral, label="Layer2 Expert 3_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 12"];\n    layer2_moe_all2all -> layer2_expert12;\n    layer2_expert13 [fillcolor=lightcoral, label="Layer2 Expert 3_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 13"];\n    layer2_moe_all2all -> layer2_expert13;\n    layer2_expert14 [fillcolor=lightcoral, label="Layer2 Expert 3_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 14"];\n    layer2_moe_all2all -> layer2_expert14;\n    layer2_expert15 [fillcolor=lightcoral, label="Layer2 Expert 3_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 15"];\n    layer2_moe_all2all -> layer2_expert15;\n    layer2_moe_agg [shape=parallelogram, fillcolor=lightblue, label="Layer2 MoE\nOutput Aggregation\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1024]\nGPU: 0,1,2,3"];\n    layer2_expert0 -> layer2_moe_agg;\n    layer2_expert1 -> layer2_moe_agg;\n    layer2_expert2 -> layer2_moe_agg;\n    layer2_expert3 -> layer2_moe_agg;\n    layer2_expert4 -> layer2_moe_agg;\n    layer2_expert5 -> layer2_moe_agg;\n    layer2_expert6 -> layer2_moe_agg;\n    layer2_expert7 -> layer2_moe_agg;\n    layer2_expert8 -> layer2_moe_agg;\n    layer2_expert9 -> layer2_moe_agg;\n    layer2_expert10 -> layer2_moe_agg;\n    layer2_expert11 -> layer2_moe_agg;\n    layer2_expert12 -> layer2_moe_agg;\n    layer2_expert13 -> layer2_moe_agg;\n    layer2_expert14 -> layer2_moe_agg;\n    layer2_expert15 -> layer2_moe_agg;\n    layer3_attn_qkv_gpu0 [fillcolor=lightblue, label="Layer3 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 0"];\n    layer3_attn_score_gpu0 [fillcolor=lightblue, label="Layer3 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 0"];\n    layer3_attn_out_gpu0 [fillcolor=lightblue, label="Layer3 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 0"];\n    layer3_attn_qkv_gpu0 -> layer3_attn_score_gpu0;\n    layer3_attn_score_gpu0 -> layer3_attn_out_gpu0;\n    layer3_attn_qkv_gpu1 [fillcolor=lightblue, label="Layer3 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 1"];\n    layer3_attn_score_gpu1 [fillcolor=lightblue, label="Layer3 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 1"];\n    layer3_attn_out_gpu1 [fillcolor=lightblue, label="Layer3 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 1"];\n    layer3_attn_qkv_gpu1 -> layer3_attn_score_gpu1;\n    layer3_attn_score_gpu1 -> layer3_attn_out_gpu1;\n    layer3_attn_qkv_gpu2 [fillcolor=lightblue, label="Layer3 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 2"];\n    layer3_attn_score_gpu2 [fillcolor=lightblue, label="Layer3 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 2"];\n    layer3_attn_out_gpu2 [fillcolor=lightblue, label="Layer3 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 2"];\n    layer3_attn_qkv_gpu2 -> layer3_attn_score_gpu2;\n    layer3_attn_score_gpu2 -> layer3_attn_out_gpu2;\n    layer3_attn_qkv_gpu3 [fillcolor=lightblue, label="Layer3 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 3"];\n    layer3_attn_score_gpu3 [fillcolor=lightblue, label="Layer3 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 3"];\n    layer3_attn_out_gpu3 [fillcolor=lightblue, label="Layer3 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 3"];\n    layer3_attn_qkv_gpu3 -> layer3_attn_score_gpu3;\n    layer3_attn_score_gpu3 -> layer3_attn_out_gpu3;\n    layer3_attn_allreduce [shape=ellipse, fillcolor=lightgray, label="Layer3 Attention\nAll-Reduce Sum\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1024]\nGPU: 0,1,2,3"];\n    layer3_attn_out_gpu0 -> layer3_attn_allreduce;\n    layer3_attn_out_gpu1 -> layer3_attn_allreduce;\n    layer3_attn_out_gpu2 -> layer3_attn_allreduce;\n    layer3_attn_out_gpu3 -> layer3_attn_allreduce;\n    layer2_moe_agg -> layer3_attn_qkv_gpu0;\n    layer2_moe_agg -> layer3_attn_qkv_gpu1;\n    layer2_moe_agg -> layer3_attn_qkv_gpu2;\n    layer2_moe_agg -> layer3_attn_qkv_gpu3;\n    layer3_moe_route [shape=parallelogram, fillcolor=lightblue, label="Layer3 MoE Routing\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1]\nGPU: 0,1,2,3"];\n    layer3_attn_allreduce -> layer3_moe_route;\n    layer3_moe_route_gpu0 [shape=parallelogram, fillcolor=lightblue, label="Layer3 MoE Route\nGPU: 0"];\n    layer3_moe_route -> layer3_moe_route_gpu0;\n    layer3_moe_route_gpu1 [shape=parallelogram, fillcolor=lightblue, label="Layer3 MoE Route\nGPU: 1"];\n    layer3_moe_route -> layer3_moe_route_gpu1;\n    layer3_moe_route_gpu2 [shape=parallelogram, fillcolor=lightblue, label="Layer3 MoE Route\nGPU: 2"];\n    layer3_moe_route -> layer3_moe_route_gpu2;\n    layer3_moe_route_gpu3 [shape=parallelogram, fillcolor=lightblue, label="Layer3 MoE Route\nGPU: 3"];\n    layer3_moe_route -> layer3_moe_route_gpu3;\n    layer3_moe_all2all [shape=ellipse, fillcolor=lightgray, label="Layer3 MoE\nAll-to-All Communication\nGPU: 0-15"];\n    layer3_moe_route_gpu0 -> layer3_moe_all2all;\n    layer3_moe_route_gpu1 -> layer3_moe_all2all;\n    layer3_moe_route_gpu2 -> layer3_moe_all2all;\n    layer3_moe_route_gpu3 -> layer3_moe_all2all;\n    layer3_expert0 [fillcolor=lightblue, label="Layer3 Expert 0_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 0"];\n    layer3_moe_all2all -> layer3_expert0;\n    layer3_expert1 [fillcolor=lightblue, label="Layer3 Expert 0_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 1"];\n    layer3_moe_all2all -> layer3_expert1;\n    layer3_expert2 [fillcolor=lightblue, label="Layer3 Expert 0_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 2"];\n    layer3_moe_all2all -> layer3_expert2;\n    layer3_expert3 [fillcolor=lightblue, label="Layer3 Expert 0_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 3"];\n    layer3_moe_all2all -> layer3_expert3;\n    layer3_expert4 [fillcolor=lightgreen, label="Layer3 Expert 1_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 4"];\n    layer3_moe_all2all -> layer3_expert4;\n    layer3_expert5 [fillcolor=lightgreen, label="Layer3 Expert 1_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 5"];\n    layer3_moe_all2all -> layer3_expert5;\n    layer3_expert6 [fillcolor=lightgreen, label="Layer3 Expert 1_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 6"];\n    layer3_moe_all2all -> layer3_expert6;\n    layer3_expert7 [fillcolor=lightgreen, label="Layer3 Expert 1_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 7"];\n    layer3_moe_all2all -> layer3_expert7;\n    layer3_expert8 [fillcolor=lightyellow, label="Layer3 Expert 2_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 8"];\n    layer3_moe_all2all -> layer3_expert8;\n    layer3_expert9 [fillcolor=lightyellow, label="Layer3 Expert 2_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 9"];\n    layer3_moe_all2all -> layer3_expert9;\n    layer3_expert10 [fillcolor=lightyellow, label="Layer3 Expert 2_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 10"];\n    layer3_moe_all2all -> layer3_expert10;\n    layer3_expert11 [fillcolor=lightyellow, label="Layer3 Expert 2_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 11"];\n    layer3_moe_all2all -> layer3_expert11;\n    layer3_expert12 [fillcolor=lightcoral, label="Layer3 Expert 3_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 12"];\n    layer3_moe_all2all -> layer3_expert12;\n    layer3_expert13 [fillcolor=lightcoral, label="Layer3 Expert 3_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 13"];\n    layer3_moe_all2all -> layer3_expert13;\n    layer3_expert14 [fillcolor=lightcoral, label="Layer3 Expert 3_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 14"];\n    layer3_moe_all2all -> layer3_expert14;\n    layer3_expert15 [fillcolor=lightcoral, label="Layer3 Expert 3_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 15"];\n    layer3_moe_all2all -> layer3_expert15;\n    layer3_moe_agg [shape=parallelogram, fillcolor=lightblue, label="Layer3 MoE\nOutput Aggregation\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1024]\nGPU: 0,1,2,3"];\n    layer3_expert0 -> layer3_moe_agg;\n    layer3_expert1 -> layer3_moe_agg;\n    layer3_expert2 -> layer3_moe_agg;\n    layer3_expert3 -> layer3_moe_agg;\n    layer3_expert4 -> layer3_moe_agg;\n    layer3_expert5 -> layer3_moe_agg;\n    layer3_expert6 -> layer3_moe_agg;\n    layer3_expert7 -> layer3_moe_agg;\n    layer3_expert8 -> layer3_moe_agg;\n    layer3_expert9 -> layer3_moe_agg;\n    layer3_expert10 -> layer3_moe_agg;\n    layer3_expert11 -> layer3_moe_agg;\n    layer3_expert12 -> layer3_moe_agg;\n    layer3_expert13 -> layer3_moe_agg;\n    layer3_expert14 -> layer3_moe_agg;\n    layer3_expert15 -> layer3_moe_agg;\n    layer4_attn_qkv_gpu4 [fillcolor=lightgreen, label="Layer4 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 4"];\n    layer4_attn_score_gpu4 [fillcolor=lightgreen, label="Layer4 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 4"];\n    layer4_attn_out_gpu4 [fillcolor=lightgreen, label="Layer4 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 4"];\n    layer4_attn_qkv_gpu4 -> layer4_attn_score_gpu4;\n    layer4_attn_score_gpu4 -> layer4_attn_out_gpu4;\n    layer4_attn_qkv_gpu5 [fillcolor=lightgreen, label="Layer4 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 5"];\n    layer4_attn_score_gpu5 [fillcolor=lightgreen, label="Layer4 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 5"];\n    layer4_attn_out_gpu5 [fillcolor=lightgreen, label="Layer4 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 5"];\n    layer4_attn_qkv_gpu5 -> layer4_attn_score_gpu5;\n    layer4_attn_score_gpu5 -> layer4_attn_out_gpu5;\n    layer4_attn_qkv_gpu6 [fillcolor=lightgreen, label="Layer4 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 6"];\n    layer4_attn_score_gpu6 [fillcolor=lightgreen, label="Layer4 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 6"];\n    layer4_attn_out_gpu6 [fillcolor=lightgreen, label="Layer4 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 6"];\n    layer4_attn_qkv_gpu6 -> layer4_attn_score_gpu6;\n    layer4_attn_score_gpu6 -> layer4_attn_out_gpu6;\n    layer4_attn_qkv_gpu7 [fillcolor=lightgreen, label="Layer4 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 7"];\n    layer4_attn_score_gpu7 [fillcolor=lightgreen, label="Layer4 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 7"];\n    layer4_attn_out_gpu7 [fillcolor=lightgreen, label="Layer4 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 7"];\n    layer4_attn_qkv_gpu7 -> layer4_attn_score_gpu7;\n    layer4_attn_score_gpu7 -> layer4_attn_out_gpu7;\n    layer4_attn_allreduce [shape=ellipse, fillcolor=lightgray, label="Layer4 Attention\nAll-Reduce Sum\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1024]\nGPU: 4,5,6,7"];\n    layer4_attn_out_gpu4 -> layer4_attn_allreduce;\n    layer4_attn_out_gpu5 -> layer4_attn_allreduce;\n    layer4_attn_out_gpu6 -> layer4_attn_allreduce;\n    layer4_attn_out_gpu7 -> layer4_attn_allreduce;\n    layer3_moe_agg -> layer4_attn_qkv_gpu4;\n    layer3_moe_agg -> layer4_attn_qkv_gpu5;\n    layer3_moe_agg -> layer4_attn_qkv_gpu6;\n    layer3_moe_agg -> layer4_attn_qkv_gpu7;\n    layer4_moe_route [shape=parallelogram, fillcolor=lightgreen, label="Layer4 MoE Routing\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1]\nGPU: 4,5,6,7"];\n    layer4_attn_allreduce -> layer4_moe_route;\n    layer4_moe_route_gpu4 [shape=parallelogram, fillcolor=lightgreen, label="Layer4 MoE Route\nGPU: 4"];\n    layer4_moe_route -> layer4_moe_route_gpu4;\n    layer4_moe_route_gpu5 [shape=parallelogram, fillcolor=lightgreen, label="Layer4 MoE Route\nGPU: 5"];\n    layer4_moe_route -> layer4_moe_route_gpu5;\n    layer4_moe_route_gpu6 [shape=parallelogram, fillcolor=lightgreen, label="Layer4 MoE Route\nGPU: 6"];\n    layer4_moe_route -> layer4_moe_route_gpu6;\n    layer4_moe_route_gpu7 [shape=parallelogram, fillcolor=lightgreen, label="Layer4 MoE Route\nGPU: 7"];\n    layer4_moe_route -> layer4_moe_route_gpu7;\n    layer4_moe_all2all [shape=ellipse, fillcolor=lightgray, label="Layer4 MoE\nAll-to-All Communication\nGPU: 0-15"];\n    layer4_moe_route_gpu4 -> layer4_moe_all2all;\n    layer4_moe_route_gpu5 -> layer4_moe_all2all;\n    layer4_moe_route_gpu6 -> layer4_moe_all2all;\n    layer4_moe_route_gpu7 -> layer4_moe_all2all;\n    layer4_expert0 [fillcolor=lightblue, label="Layer4 Expert 0_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 0"];\n    layer4_moe_all2all -> layer4_expert0;\n    layer4_expert1 [fillcolor=lightblue, label="Layer4 Expert 0_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 1"];\n    layer4_moe_all2all -> layer4_expert1;\n    layer4_expert2 [fillcolor=lightblue, label="Layer4 Expert 0_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 2"];\n    layer4_moe_all2all -> layer4_expert2;\n    layer4_expert3 [fillcolor=lightblue, label="Layer4 Expert 0_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 3"];\n    layer4_moe_all2all -> layer4_expert3;\n    layer4_expert4 [fillcolor=lightgreen, label="Layer4 Expert 1_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 4"];\n    layer4_moe_all2all -> layer4_expert4;\n    layer4_expert5 [fillcolor=lightgreen, label="Layer4 Expert 1_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 5"];\n    layer4_moe_all2all -> layer4_expert5;\n    layer4_expert6 [fillcolor=lightgreen, label="Layer4 Expert 1_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 6"];\n    layer4_moe_all2all -> layer4_expert6;\n    layer4_expert7 [fillcolor=lightgreen, label="Layer4 Expert 1_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 7"];\n    layer4_moe_all2all -> layer4_expert7;\n    layer4_expert8 [fillcolor=lightyellow, label="Layer4 Expert 2_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 8"];\n    layer4_moe_all2all -> layer4_expert8;\n    layer4_expert9 [fillcolor=lightyellow, label="Layer4 Expert 2_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 9"];\n    layer4_moe_all2all -> layer4_expert9;\n    layer4_expert10 [fillcolor=lightyellow, label="Layer4 Expert 2_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 10"];\n    layer4_moe_all2all -> layer4_expert10;\n    layer4_expert11 [fillcolor=lightyellow, label="Layer4 Expert 2_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 11"];\n    layer4_moe_all2all -> layer4_expert11;\n    layer4_expert12 [fillcolor=lightcoral, label="Layer4 Expert 3_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 12"];\n    layer4_moe_all2all -> layer4_expert12;\n    layer4_expert13 [fillcolor=lightcoral, label="Layer4 Expert 3_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 13"];\n    layer4_moe_all2all -> layer4_expert13;\n    layer4_expert14 [fillcolor=lightcoral, label="Layer4 Expert 3_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 14"];\n    layer4_moe_all2all -> layer4_expert14;\n    layer4_expert15 [fillcolor=lightcoral, label="Layer4 Expert 3_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 15"];\n    layer4_moe_all2all -> layer4_expert15;\n    layer4_moe_agg [shape=parallelogram, fillcolor=lightgreen, label="Layer4 MoE\nOutput Aggregation\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1024]\nGPU: 4,5,6,7"];\n    layer4_expert0 -> layer4_moe_agg;\n    layer4_expert1 -> layer4_moe_agg;\n    layer4_expert2 -> layer4_moe_agg;\n    layer4_expert3 -> layer4_moe_agg;\n    layer4_expert4 -> layer4_moe_agg;\n    layer4_expert5 -> layer4_moe_agg;\n    layer4_expert6 -> layer4_moe_agg;\n    layer4_expert7 -> layer4_moe_agg;\n    layer4_expert8 -> layer4_moe_agg;\n    layer4_expert9 -> layer4_moe_agg;\n    layer4_expert10 -> layer4_moe_agg;\n    layer4_expert11 -> layer4_moe_agg;\n    layer4_expert12 -> layer4_moe_agg;\n    layer4_expert13 -> layer4_moe_agg;\n    layer4_expert14 -> layer4_moe_agg;\n    layer4_expert15 -> layer4_moe_agg;\n    layer5_attn_qkv_gpu4 [fillcolor=lightgreen, label="Layer5 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 4"];\n    layer5_attn_score_gpu4 [fillcolor=lightgreen, label="Layer5 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 4"];\n    layer5_attn_out_gpu4 [fillcolor=lightgreen, label="Layer5 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 4"];\n    layer5_attn_qkv_gpu4 -> layer5_attn_score_gpu4;\n    layer5_attn_score_gpu4 -> layer5_attn_out_gpu4;\n    layer5_attn_qkv_gpu5 [fillcolor=lightgreen, label="Layer5 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 5"];\n    layer5_attn_score_gpu5 [fillcolor=lightgreen, label="Layer5 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 5"];\n    layer5_attn_out_gpu5 [fillcolor=lightgreen, label="Layer5 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 5"];\n    layer5_attn_qkv_gpu5 -> layer5_attn_score_gpu5;\n    layer5_attn_score_gpu5 -> layer5_attn_out_gpu5;\n    layer5_attn_qkv_gpu6 [fillcolor=lightgreen, label="Layer5 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 6"];\n    layer5_attn_score_gpu6 [fillcolor=lightgreen, label="Layer5 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 6"];\n    layer5_attn_out_gpu6 [fillcolor=lightgreen, label="Layer5 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 6"];\n    layer5_attn_qkv_gpu6 -> layer5_attn_score_gpu6;\n    layer5_attn_score_gpu6 -> layer5_attn_out_gpu6;\n    layer5_attn_qkv_gpu7 [fillcolor=lightgreen, label="Layer5 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 7"];\n    layer5_attn_score_gpu7 [fillcolor=lightgreen, label="Layer5 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 7"];\n    layer5_attn_out_gpu7 [fillcolor=lightgreen, label="Layer5 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 7"];\n    layer5_attn_qkv_gpu7 -> layer5_attn_score_gpu7;\n    layer5_attn_score_gpu7 -> layer5_attn_out_gpu7;\n    layer5_attn_allreduce [shape=ellipse, fillcolor=lightgray, label="Layer5 Attention\nAll-Reduce Sum\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1024]\nGPU: 4,5,6,7"];\n    layer5_attn_out_gpu4 -> layer5_attn_allreduce;\n    layer5_attn_out_gpu5 -> layer5_attn_allreduce;\n    layer5_attn_out_gpu6 -> layer5_attn_allreduce;\n    layer5_attn_out_gpu7 -> layer5_attn_allreduce;\n    layer4_moe_agg -> layer5_attn_qkv_gpu4;\n    layer4_moe_agg -> layer5_attn_qkv_gpu5;\n    layer4_moe_agg -> layer5_attn_qkv_gpu6;\n    layer4_moe_agg -> layer5_attn_qkv_gpu7;\n    layer5_moe_route [shape=parallelogram, fillcolor=lightgreen, label="Layer5 MoE Routing\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1]\nGPU: 4,5,6,7"];\n    layer5_attn_allreduce -> layer5_moe_route;\n    layer5_moe_route_gpu4 [shape=parallelogram, fillcolor=lightgreen, label="Layer5 MoE Route\nGPU: 4"];\n    layer5_moe_route -> layer5_moe_route_gpu4;\n    layer5_moe_route_gpu5 [shape=parallelogram, fillcolor=lightgreen, label="Layer5 MoE Route\nGPU: 5"];\n    layer5_moe_route -> layer5_moe_route_gpu5;\n    layer5_moe_route_gpu6 [shape=parallelogram, fillcolor=lightgreen, label="Layer5 MoE Route\nGPU: 6"];\n    layer5_moe_route -> layer5_moe_route_gpu6;\n    layer5_moe_route_gpu7 [shape=parallelogram, fillcolor=lightgreen, label="Layer5 MoE Route\nGPU: 7"];\n    layer5_moe_route -> layer5_moe_route_gpu7;\n    layer5_moe_all2all [shape=ellipse, fillcolor=lightgray, label="Layer5 MoE\nAll-to-All Communication\nGPU: 0-15"];\n    layer5_moe_route_gpu4 -> layer5_moe_all2all;\n    layer5_moe_route_gpu5 -> layer5_moe_all2all;\n    layer5_moe_route_gpu6 -> layer5_moe_all2all;\n    layer5_moe_route_gpu7 -> layer5_moe_all2all;\n    layer5_expert0 [fillcolor=lightblue, label="Layer5 Expert 0_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 0"];\n    layer5_moe_all2all -> layer5_expert0;\n    layer5_expert1 [fillcolor=lightblue, label="Layer5 Expert 0_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 1"];\n    layer5_moe_all2all -> layer5_expert1;\n    layer5_expert2 [fillcolor=lightblue, label="Layer5 Expert 0_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 2"];\n    layer5_moe_all2all -> layer5_expert2;\n    layer5_expert3 [fillcolor=lightblue, label="Layer5 Expert 0_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 3"];\n    layer5_moe_all2all -> layer5_expert3;\n    layer5_expert4 [fillcolor=lightgreen, label="Layer5 Expert 1_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 4"];\n    layer5_moe_all2all -> layer5_expert4;\n    layer5_expert5 [fillcolor=lightgreen, label="Layer5 Expert 1_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 5"];\n    layer5_moe_all2all -> layer5_expert5;\n    layer5_expert6 [fillcolor=lightgreen, label="Layer5 Expert 1_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 6"];\n    layer5_moe_all2all -> layer5_expert6;\n    layer5_expert7 [fillcolor=lightgreen, label="Layer5 Expert 1_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 7"];\n    layer5_moe_all2all -> layer5_expert7;\n    layer5_expert8 [fillcolor=lightyellow, label="Layer5 Expert 2_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 8"];\n    layer5_moe_all2all -> layer5_expert8;\n    layer5_expert9 [fillcolor=lightyellow, label="Layer5 Expert 2_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 9"];\n    layer5_moe_all2all -> layer5_expert9;\n    layer5_expert10 [fillcolor=lightyellow, label="Layer5 Expert 2_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 10"];\n    layer5_moe_all2all -> layer5_expert10;\n    layer5_expert11 [fillcolor=lightyellow, label="Layer5 Expert 2_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 11"];\n    layer5_moe_all2all -> layer5_expert11;\n    layer5_expert12 [fillcolor=lightcoral, label="Layer5 Expert 3_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 12"];\n    layer5_moe_all2all -> layer5_expert12;\n    layer5_expert13 [fillcolor=lightcoral, label="Layer5 Expert 3_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 13"];\n    layer5_moe_all2all -> layer5_expert13;\n    layer5_expert14 [fillcolor=lightcoral, label="Layer5 Expert 3_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 14"];\n    layer5_moe_all2all -> layer5_expert14;\n    layer5_expert15 [fillcolor=lightcoral, label="Layer5 Expert 3_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 15"];\n    layer5_moe_all2all -> layer5_expert15;\n    layer5_moe_agg [shape=parallelogram, fillcolor=lightgreen, label="Layer5 MoE\nOutput Aggregation\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1024]\nGPU: 4,5,6,7"];\n    layer5_expert0 -> layer5_moe_agg;\n    layer5_expert1 -> layer5_moe_agg;\n    layer5_expert2 -> layer5_moe_agg;\n    layer5_expert3 -> layer5_moe_agg;\n    layer5_expert4 -> layer5_moe_agg;\n    layer5_expert5 -> layer5_moe_agg;\n    layer5_expert6 -> layer5_moe_agg;\n    layer5_expert7 -> layer5_moe_agg;\n    layer5_expert8 -> layer5_moe_agg;\n    layer5_expert9 -> layer5_moe_agg;\n    layer5_expert10 -> layer5_moe_agg;\n    layer5_expert11 -> layer5_moe_agg;\n    layer5_expert12 -> layer5_moe_agg;\n    layer5_expert13 -> layer5_moe_agg;\n    layer5_expert14 -> layer5_moe_agg;\n    layer5_expert15 -> layer5_moe_agg;\n    layer6_attn_qkv_gpu4 [fillcolor=lightgreen, label="Layer6 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 4"];\n    layer6_attn_score_gpu4 [fillcolor=lightgreen, label="Layer6 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 4"];\n    layer6_attn_out_gpu4 [fillcolor=lightgreen, label="Layer6 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 4"];\n    layer6_attn_qkv_gpu4 -> layer6_attn_score_gpu4;\n    layer6_attn_score_gpu4 -> layer6_attn_out_gpu4;\n    layer6_attn_qkv_gpu5 [fillcolor=lightgreen, label="Layer6 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 5"];\n    layer6_attn_score_gpu5 [fillcolor=lightgreen, label="Layer6 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 5"];\n    layer6_attn_out_gpu5 [fillcolor=lightgreen, label="Layer6 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 5"];\n    layer6_attn_qkv_gpu5 -> layer6_attn_score_gpu5;\n    layer6_attn_score_gpu5 -> layer6_attn_out_gpu5;\n    layer6_attn_qkv_gpu6 [fillcolor=lightgreen, label="Layer6 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 6"];\n    layer6_attn_score_gpu6 [fillcolor=lightgreen, label="Layer6 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 6"];\n    layer6_attn_out_gpu6 [fillcolor=lightgreen, label="Layer6 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 6"];\n    layer6_attn_qkv_gpu6 -> layer6_attn_score_gpu6;\n    layer6_attn_score_gpu6 -> layer6_attn_out_gpu6;\n    layer6_attn_qkv_gpu7 [fillcolor=lightgreen, label="Layer6 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 7"];\n    layer6_attn_score_gpu7 [fillcolor=lightgreen, label="Layer6 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 7"];\n    layer6_attn_out_gpu7 [fillcolor=lightgreen, label="Layer6 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 7"];\n    layer6_attn_qkv_gpu7 -> layer6_attn_score_gpu7;\n    layer6_attn_score_gpu7 -> layer6_attn_out_gpu7;\n    layer6_attn_allreduce [shape=ellipse, fillcolor=lightgray, label="Layer6 Attention\nAll-Reduce Sum\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1024]\nGPU: 4,5,6,7"];\n    layer6_attn_out_gpu4 -> layer6_attn_allreduce;\n    layer6_attn_out_gpu5 -> layer6_attn_allreduce;\n    layer6_attn_out_gpu6 -> layer6_attn_allreduce;\n    layer6_attn_out_gpu7 -> layer6_attn_allreduce;\n    layer5_moe_agg -> layer6_attn_qkv_gpu4;\n    layer5_moe_agg -> layer6_attn_qkv_gpu5;\n    layer5_moe_agg -> layer6_attn_qkv_gpu6;\n    layer5_moe_agg -> layer6_attn_qkv_gpu7;\n    layer6_moe_route [shape=parallelogram, fillcolor=lightgreen, label="Layer6 MoE Routing\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1]\nGPU: 4,5,6,7"];\n    layer6_attn_allreduce -> layer6_moe_route;\n    layer6_moe_route_gpu4 [shape=parallelogram, fillcolor=lightgreen, label="Layer6 MoE Route\nGPU: 4"];\n    layer6_moe_route -> layer6_moe_route_gpu4;\n    layer6_moe_route_gpu5 [shape=parallelogram, fillcolor=lightgreen, label="Layer6 MoE Route\nGPU: 5"];\n    layer6_moe_route -> layer6_moe_route_gpu5;\n    layer6_moe_route_gpu6 [shape=parallelogram, fillcolor=lightgreen, label="Layer6 MoE Route\nGPU: 6"];\n    layer6_moe_route -> layer6_moe_route_gpu6;\n    layer6_moe_route_gpu7 [shape=parallelogram, fillcolor=lightgreen, label="Layer6 MoE Route\nGPU: 7"];\n    layer6_moe_route -> layer6_moe_route_gpu7;\n    layer6_moe_all2all [shape=ellipse, fillcolor=lightgray, label="Layer6 MoE\nAll-to-All Communication\nGPU: 0-15"];\n    layer6_moe_route_gpu4 -> layer6_moe_all2all;\n    layer6_moe_route_gpu5 -> layer6_moe_all2all;\n    layer6_moe_route_gpu6 -> layer6_moe_all2all;\n    layer6_moe_route_gpu7 -> layer6_moe_all2all;\n    layer6_expert0 [fillcolor=lightblue, label="Layer6 Expert 0_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 0"];\n    layer6_moe_all2all -> layer6_expert0;\n    layer6_expert1 [fillcolor=lightblue, label="Layer6 Expert 0_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 1"];\n    layer6_moe_all2all -> layer6_expert1;\n    layer6_expert2 [fillcolor=lightblue, label="Layer6 Expert 0_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 2"];\n    layer6_moe_all2all -> layer6_expert2;\n    layer6_expert3 [fillcolor=lightblue, label="Layer6 Expert 0_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 3"];\n    layer6_moe_all2all -> layer6_expert3;\n    layer6_expert4 [fillcolor=lightgreen, label="Layer6 Expert 1_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 4"];\n    layer6_moe_all2all -> layer6_expert4;\n    layer6_expert5 [fillcolor=lightgreen, label="Layer6 Expert 1_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 5"];\n    layer6_moe_all2all -> layer6_expert5;\n    layer6_expert6 [fillcolor=lightgreen, label="Layer6 Expert 1_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 6"];\n    layer6_moe_all2all -> layer6_expert6;\n    layer6_expert7 [fillcolor=lightgreen, label="Layer6 Expert 1_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 7"];\n    layer6_moe_all2all -> layer6_expert7;\n    layer6_expert8 [fillcolor=lightyellow, label="Layer6 Expert 2_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 8"];\n    layer6_moe_all2all -> layer6_expert8;\n    layer6_expert9 [fillcolor=lightyellow, label="Layer6 Expert 2_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 9"];\n    layer6_moe_all2all -> layer6_expert9;\n    layer6_expert10 [fillcolor=lightyellow, label="Layer6 Expert 2_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 10"];\n    layer6_moe_all2all -> layer6_expert10;\n    layer6_expert11 [fillcolor=lightyellow, label="Layer6 Expert 2_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 11"];\n    layer6_moe_all2all -> layer6_expert11;\n    layer6_expert12 [fillcolor=lightcoral, label="Layer6 Expert 3_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 12"];\n    layer6_moe_all2all -> layer6_expert12;\n    layer6_expert13 [fillcolor=lightcoral, label="Layer6 Expert 3_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 13"];\n    layer6_moe_all2all -> layer6_expert13;\n    layer6_expert14 [fillcolor=lightcoral, label="Layer6 Expert 3_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 14"];\n    layer6_moe_all2all -> layer6_expert14;\n    layer6_expert15 [fillcolor=lightcoral, label="Layer6 Expert 3_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 15"];\n    layer6_moe_all2all -> layer6_expert15;\n    layer6_moe_agg [shape=parallelogram, fillcolor=lightgreen, label="Layer6 MoE\nOutput Aggregation\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1024]\nGPU: 4,5,6,7"];\n    layer6_expert0 -> layer6_moe_agg;\n    layer6_expert1 -> layer6_moe_agg;\n    layer6_expert2 -> layer6_moe_agg;\n    layer6_expert3 -> layer6_moe_agg;\n    layer6_expert4 -> layer6_moe_agg;\n    layer6_expert5 -> layer6_moe_agg;\n    layer6_expert6 -> layer6_moe_agg;\n    layer6_expert7 -> layer6_moe_agg;\n    layer6_expert8 -> layer6_moe_agg;\n    layer6_expert9 -> layer6_moe_agg;\n    layer6_expert10 -> layer6_moe_agg;\n    layer6_expert11 -> layer6_moe_agg;\n    layer6_expert12 -> layer6_moe_agg;\n    layer6_expert13 -> layer6_moe_agg;\n    layer6_expert14 -> layer6_moe_agg;\n    layer6_expert15 -> layer6_moe_agg;\n    layer7_attn_qkv_gpu4 [fillcolor=lightgreen, label="Layer7 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 4"];\n    layer7_attn_score_gpu4 [fillcolor=lightgreen, label="Layer7 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 4"];\n    layer7_attn_out_gpu4 [fillcolor=lightgreen, label="Layer7 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 4"];\n    layer7_attn_qkv_gpu4 -> layer7_attn_score_gpu4;\n    layer7_attn_score_gpu4 -> layer7_attn_out_gpu4;\n    layer7_attn_qkv_gpu5 [fillcolor=lightgreen, label="Layer7 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 5"];\n    layer7_attn_score_gpu5 [fillcolor=lightgreen, label="Layer7 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 5"];\n    layer7_attn_out_gpu5 [fillcolor=lightgreen, label="Layer7 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 5"];\n    layer7_attn_qkv_gpu5 -> layer7_attn_score_gpu5;\n    layer7_attn_score_gpu5 -> layer7_attn_out_gpu5;\n    layer7_attn_qkv_gpu6 [fillcolor=lightgreen, label="Layer7 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 6"];\n    layer7_attn_score_gpu6 [fillcolor=lightgreen, label="Layer7 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 6"];\n    layer7_attn_out_gpu6 [fillcolor=lightgreen, label="Layer7 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 6"];\n    layer7_attn_qkv_gpu6 -> layer7_attn_score_gpu6;\n    layer7_attn_score_gpu6 -> layer7_attn_out_gpu6;\n    layer7_attn_qkv_gpu7 [fillcolor=lightgreen, label="Layer7 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 7"];\n    layer7_attn_score_gpu7 [fillcolor=lightgreen, label="Layer7 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 7"];\n    layer7_attn_out_gpu7 [fillcolor=lightgreen, label="Layer7 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 7"];\n    layer7_attn_qkv_gpu7 -> layer7_attn_score_gpu7;\n    layer7_attn_score_gpu7 -> layer7_attn_out_gpu7;\n    layer7_attn_allreduce [shape=ellipse, fillcolor=lightgray, label="Layer7 Attention\nAll-Reduce Sum\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1024]\nGPU: 4,5,6,7"];\n    layer7_attn_out_gpu4 -> layer7_attn_allreduce;\n    layer7_attn_out_gpu5 -> layer7_attn_allreduce;\n    layer7_attn_out_gpu6 -> layer7_attn_allreduce;\n    layer7_attn_out_gpu7 -> layer7_attn_allreduce;\n    layer6_moe_agg -> layer7_attn_qkv_gpu4;\n    layer6_moe_agg -> layer7_attn_qkv_gpu5;\n    layer6_moe_agg -> layer7_attn_qkv_gpu6;\n    layer6_moe_agg -> layer7_attn_qkv_gpu7;\n    layer7_moe_route [shape=parallelogram, fillcolor=lightgreen, label="Layer7 MoE Routing\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1]\nGPU: 4,5,6,7"];\n    layer7_attn_allreduce -> layer7_moe_route;\n    layer7_moe_route_gpu4 [shape=parallelogram, fillcolor=lightgreen, label="Layer7 MoE Route\nGPU: 4"];\n    layer7_moe_route -> layer7_moe_route_gpu4;\n    layer7_moe_route_gpu5 [shape=parallelogram, fillcolor=lightgreen, label="Layer7 MoE Route\nGPU: 5"];\n    layer7_moe_route -> layer7_moe_route_gpu5;\n    layer7_moe_route_gpu6 [shape=parallelogram, fillcolor=lightgreen, label="Layer7 MoE Route\nGPU: 6"];\n    layer7_moe_route -> layer7_moe_route_gpu6;\n    layer7_moe_route_gpu7 [shape=parallelogram, fillcolor=lightgreen, label="Layer7 MoE Route\nGPU: 7"];\n    layer7_moe_route -> layer7_moe_route_gpu7;\n    layer7_moe_all2all [shape=ellipse, fillcolor=lightgray, label="Layer7 MoE\nAll-to-All Communication\nGPU: 0-15"];\n    layer7_moe_route_gpu4 -> layer7_moe_all2all;\n    layer7_moe_route_gpu5 -> layer7_moe_all2all;\n    layer7_moe_route_gpu6 -> layer7_moe_all2all;\n    layer7_moe_route_gpu7 -> layer7_moe_all2all;\n    layer7_expert0 [fillcolor=lightblue, label="Layer7 Expert 0_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 0"];\n    layer7_moe_all2all -> layer7_expert0;\n    layer7_expert1 [fillcolor=lightblue, label="Layer7 Expert 0_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 1"];\n    layer7_moe_all2all -> layer7_expert1;\n    layer7_expert2 [fillcolor=lightblue, label="Layer7 Expert 0_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 2"];\n    layer7_moe_all2all -> layer7_expert2;\n    layer7_expert3 [fillcolor=lightblue, label="Layer7 Expert 0_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 3"];\n    layer7_moe_all2all -> layer7_expert3;\n    layer7_expert4 [fillcolor=lightgreen, label="Layer7 Expert 1_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 4"];\n    layer7_moe_all2all -> layer7_expert4;\n    layer7_expert5 [fillcolor=lightgreen, label="Layer7 Expert 1_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 5"];\n    layer7_moe_all2all -> layer7_expert5;\n    layer7_expert6 [fillcolor=lightgreen, label="Layer7 Expert 1_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 6"];\n    layer7_moe_all2all -> layer7_expert6;\n    layer7_expert7 [fillcolor=lightgreen, label="Layer7 Expert 1_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 7"];\n    layer7_moe_all2all -> layer7_expert7;\n    layer7_expert8 [fillcolor=lightyellow, label="Layer7 Expert 2_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 8"];\n    layer7_moe_all2all -> layer7_expert8;\n    layer7_expert9 [fillcolor=lightyellow, label="Layer7 Expert 2_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 9"];\n    layer7_moe_all2all -> layer7_expert9;\n    layer7_expert10 [fillcolor=lightyellow, label="Layer7 Expert 2_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 10"];\n    layer7_moe_all2all -> layer7_expert10;\n    layer7_expert11 [fillcolor=lightyellow, label="Layer7 Expert 2_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 11"];\n    layer7_moe_all2all -> layer7_expert11;\n    layer7_expert12 [fillcolor=lightcoral, label="Layer7 Expert 3_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 12"];\n    layer7_moe_all2all -> layer7_expert12;\n    layer7_expert13 [fillcolor=lightcoral, label="Layer7 Expert 3_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 13"];\n    layer7_moe_all2all -> layer7_expert13;\n    layer7_expert14 [fillcolor=lightcoral, label="Layer7 Expert 3_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 14"];\n    layer7_moe_all2all -> layer7_expert14;\n    layer7_expert15 [fillcolor=lightcoral, label="Layer7 Expert 3_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 15"];\n    layer7_moe_all2all -> layer7_expert15;\n    layer7_moe_agg [shape=parallelogram, fillcolor=lightgreen, label="Layer7 MoE\nOutput Aggregation\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1024]\nGPU: 4,5,6,7"];\n    layer7_expert0 -> layer7_moe_agg;\n    layer7_expert1 -> layer7_moe_agg;\n    layer7_expert2 -> layer7_moe_agg;\n    layer7_expert3 -> layer7_moe_agg;\n    layer7_expert4 -> layer7_moe_agg;\n    layer7_expert5 -> layer7_moe_agg;\n    layer7_expert6 -> layer7_moe_agg;\n    layer7_expert7 -> layer7_moe_agg;\n    layer7_expert8 -> layer7_moe_agg;\n    layer7_expert9 -> layer7_moe_agg;\n    layer7_expert10 -> layer7_moe_agg;\n    layer7_expert11 -> layer7_moe_agg;\n    layer7_expert12 -> layer7_moe_agg;\n    layer7_expert13 -> layer7_moe_agg;\n    layer7_expert14 -> layer7_moe_agg;\n    layer7_expert15 -> layer7_moe_agg;\n    layer8_attn_qkv_gpu8 [fillcolor=lightyellow, label="Layer8 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 8"];\n    layer8_attn_score_gpu8 [fillcolor=lightyellow, label="Layer8 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 8"];\n    layer8_attn_out_gpu8 [fillcolor=lightyellow, label="Layer8 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 8"];\n    layer8_attn_qkv_gpu8 -> layer8_attn_score_gpu8;\n    layer8_attn_score_gpu8 -> layer8_attn_out_gpu8;\n    layer8_attn_qkv_gpu9 [fillcolor=lightyellow, label="Layer8 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 9"];\n    layer8_attn_score_gpu9 [fillcolor=lightyellow, label="Layer8 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 9"];\n    layer8_attn_out_gpu9 [fillcolor=lightyellow, label="Layer8 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 9"];\n    layer8_attn_qkv_gpu9 -> layer8_attn_score_gpu9;\n    layer8_attn_score_gpu9 -> layer8_attn_out_gpu9;\n    layer8_attn_qkv_gpu10 [fillcolor=lightyellow, label="Layer8 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 10"];\n    layer8_attn_score_gpu10 [fillcolor=lightyellow, label="Layer8 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 10"];\n    layer8_attn_out_gpu10 [fillcolor=lightyellow, label="Layer8 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 10"];\n    layer8_attn_qkv_gpu10 -> layer8_attn_score_gpu10;\n    layer8_attn_score_gpu10 -> layer8_attn_out_gpu10;\n    layer8_attn_qkv_gpu11 [fillcolor=lightyellow, label="Layer8 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 11"];\n    layer8_attn_score_gpu11 [fillcolor=lightyellow, label="Layer8 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 11"];\n    layer8_attn_out_gpu11 [fillcolor=lightyellow, label="Layer8 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 11"];\n    layer8_attn_qkv_gpu11 -> layer8_attn_score_gpu11;\n    layer8_attn_score_gpu11 -> layer8_attn_out_gpu11;\n    layer8_attn_allreduce [shape=ellipse, fillcolor=lightgray, label="Layer8 Attention\nAll-Reduce Sum\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1024]\nGPU: 8,9,10,11"];\n    layer8_attn_out_gpu8 -> layer8_attn_allreduce;\n    layer8_attn_out_gpu9 -> layer8_attn_allreduce;\n    layer8_attn_out_gpu10 -> layer8_attn_allreduce;\n    layer8_attn_out_gpu11 -> layer8_attn_allreduce;\n    layer7_moe_agg -> layer8_attn_qkv_gpu8;\n    layer7_moe_agg -> layer8_attn_qkv_gpu9;\n    layer7_moe_agg -> layer8_attn_qkv_gpu10;\n    layer7_moe_agg -> layer8_attn_qkv_gpu11;\n    layer8_moe_route [shape=parallelogram, fillcolor=lightyellow, label="Layer8 MoE Routing\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1]\nGPU: 8,9,10,11"];\n    layer8_attn_allreduce -> layer8_moe_route;\n    layer8_moe_route_gpu8 [shape=parallelogram, fillcolor=lightyellow, label="Layer8 MoE Route\nGPU: 8"];\n    layer8_moe_route -> layer8_moe_route_gpu8;\n    layer8_moe_route_gpu9 [shape=parallelogram, fillcolor=lightyellow, label="Layer8 MoE Route\nGPU: 9"];\n    layer8_moe_route -> layer8_moe_route_gpu9;\n    layer8_moe_route_gpu10 [shape=parallelogram, fillcolor=lightyellow, label="Layer8 MoE Route\nGPU: 10"];\n    layer8_moe_route -> layer8_moe_route_gpu10;\n    layer8_moe_route_gpu11 [shape=parallelogram, fillcolor=lightyellow, label="Layer8 MoE Route\nGPU: 11"];\n    layer8_moe_route -> layer8_moe_route_gpu11;\n    layer8_moe_all2all [shape=ellipse, fillcolor=lightgray, label="Layer8 MoE\nAll-to-All Communication\nGPU: 0-15"];\n    layer8_moe_route_gpu8 -> layer8_moe_all2all;\n    layer8_moe_route_gpu9 -> layer8_moe_all2all;\n    layer8_moe_route_gpu10 -> layer8_moe_all2all;\n    layer8_moe_route_gpu11 -> layer8_moe_all2all;\n    layer8_expert0 [fillcolor=lightblue, label="Layer8 Expert 0_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 0"];\n    layer8_moe_all2all -> layer8_expert0;\n    layer8_expert1 [fillcolor=lightblue, label="Layer8 Expert 0_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 1"];\n    layer8_moe_all2all -> layer8_expert1;\n    layer8_expert2 [fillcolor=lightblue, label="Layer8 Expert 0_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 2"];\n    layer8_moe_all2all -> layer8_expert2;\n    layer8_expert3 [fillcolor=lightblue, label="Layer8 Expert 0_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 3"];\n    layer8_moe_all2all -> layer8_expert3;\n    layer8_expert4 [fillcolor=lightgreen, label="Layer8 Expert 1_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 4"];\n    layer8_moe_all2all -> layer8_expert4;\n    layer8_expert5 [fillcolor=lightgreen, label="Layer8 Expert 1_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 5"];\n    layer8_moe_all2all -> layer8_expert5;\n    layer8_expert6 [fillcolor=lightgreen, label="Layer8 Expert 1_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 6"];\n    layer8_moe_all2all -> layer8_expert6;\n    layer8_expert7 [fillcolor=lightgreen, label="Layer8 Expert 1_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 7"];\n    layer8_moe_all2all -> layer8_expert7;\n    layer8_expert8 [fillcolor=lightyellow, label="Layer8 Expert 2_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 8"];\n    layer8_moe_all2all -> layer8_expert8;\n    layer8_expert9 [fillcolor=lightyellow, label="Layer8 Expert 2_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 9"];\n    layer8_moe_all2all -> layer8_expert9;\n    layer8_expert10 [fillcolor=lightyellow, label="Layer8 Expert 2_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 10"];\n    layer8_moe_all2all -> layer8_expert10;\n    layer8_expert11 [fillcolor=lightyellow, label="Layer8 Expert 2_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 11"];\n    layer8_moe_all2all -> layer8_expert11;\n    layer8_expert12 [fillcolor=lightcoral, label="Layer8 Expert 3_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 12"];\n    layer8_moe_all2all -> layer8_expert12;\n    layer8_expert13 [fillcolor=lightcoral, label="Layer8 Expert 3_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 13"];\n    layer8_moe_all2all -> layer8_expert13;\n    layer8_expert14 [fillcolor=lightcoral, label="Layer8 Expert 3_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 14"];\n    layer8_moe_all2all -> layer8_expert14;\n    layer8_expert15 [fillcolor=lightcoral, label="Layer8 Expert 3_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 15"];\n    layer8_moe_all2all -> layer8_expert15;\n    layer8_moe_agg [shape=parallelogram, fillcolor=lightyellow, label="Layer8 MoE\nOutput Aggregation\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1024]\nGPU: 8,9,10,11"];\n    layer8_expert0 -> layer8_moe_agg;\n    layer8_expert1 -> layer8_moe_agg;\n    layer8_expert2 -> layer8_moe_agg;\n    layer8_expert3 -> layer8_moe_agg;\n    layer8_expert4 -> layer8_moe_agg;\n    layer8_expert5 -> layer8_moe_agg;\n    layer8_expert6 -> layer8_moe_agg;\n    layer8_expert7 -> layer8_moe_agg;\n    layer8_expert8 -> layer8_moe_agg;\n    layer8_expert9 -> layer8_moe_agg;\n    layer8_expert10 -> layer8_moe_agg;\n    layer8_expert11 -> layer8_moe_agg;\n    layer8_expert12 -> layer8_moe_agg;\n    layer8_expert13 -> layer8_moe_agg;\n    layer8_expert14 -> layer8_moe_agg;\n    layer8_expert15 -> layer8_moe_agg;\n    layer9_attn_qkv_gpu8 [fillcolor=lightyellow, label="Layer9 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 8"];\n    layer9_attn_score_gpu8 [fillcolor=lightyellow, label="Layer9 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 8"];\n    layer9_attn_out_gpu8 [fillcolor=lightyellow, label="Layer9 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 8"];\n    layer9_attn_qkv_gpu8 -> layer9_attn_score_gpu8;\n    layer9_attn_score_gpu8 -> layer9_attn_out_gpu8;\n    layer9_attn_qkv_gpu9 [fillcolor=lightyellow, label="Layer9 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 9"];\n    layer9_attn_score_gpu9 [fillcolor=lightyellow, label="Layer9 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 9"];\n    layer9_attn_out_gpu9 [fillcolor=lightyellow, label="Layer9 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 9"];\n    layer9_attn_qkv_gpu9 -> layer9_attn_score_gpu9;\n    layer9_attn_score_gpu9 -> layer9_attn_out_gpu9;\n    layer9_attn_qkv_gpu10 [fillcolor=lightyellow, label="Layer9 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 10"];\n    layer9_attn_score_gpu10 [fillcolor=lightyellow, label="Layer9 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 10"];\n    layer9_attn_out_gpu10 [fillcolor=lightyellow, label="Layer9 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 10"];\n    layer9_attn_qkv_gpu10 -> layer9_attn_score_gpu10;\n    layer9_attn_score_gpu10 -> layer9_attn_out_gpu10;\n    layer9_attn_qkv_gpu11 [fillcolor=lightyellow, label="Layer9 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 11"];\n    layer9_attn_score_gpu11 [fillcolor=lightyellow, label="Layer9 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 11"];\n    layer9_attn_out_gpu11 [fillcolor=lightyellow, label="Layer9 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 11"];\n    layer9_attn_qkv_gpu11 -> layer9_attn_score_gpu11;\n    layer9_attn_score_gpu11 -> layer9_attn_out_gpu11;\n    layer9_attn_allreduce [shape=ellipse, fillcolor=lightgray, label="Layer9 Attention\nAll-Reduce Sum\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1024]\nGPU: 8,9,10,11"];\n    layer9_attn_out_gpu8 -> layer9_attn_allreduce;\n    layer9_attn_out_gpu9 -> layer9_attn_allreduce;\n    layer9_attn_out_gpu10 -> layer9_attn_allreduce;\n    layer9_attn_out_gpu11 -> layer9_attn_allreduce;\n    layer8_moe_agg -> layer9_attn_qkv_gpu8;\n    layer8_moe_agg -> layer9_attn_qkv_gpu9;\n    layer8_moe_agg -> layer9_attn_qkv_gpu10;\n    layer8_moe_agg -> layer9_attn_qkv_gpu11;\n    layer9_moe_route [shape=parallelogram, fillcolor=lightyellow, label="Layer9 MoE Routing\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1]\nGPU: 8,9,10,11"];\n    layer9_attn_allreduce -> layer9_moe_route;\n    layer9_moe_route_gpu8 [shape=parallelogram, fillcolor=lightyellow, label="Layer9 MoE Route\nGPU: 8"];\n    layer9_moe_route -> layer9_moe_route_gpu8;\n    layer9_moe_route_gpu9 [shape=parallelogram, fillcolor=lightyellow, label="Layer9 MoE Route\nGPU: 9"];\n    layer9_moe_route -> layer9_moe_route_gpu9;\n    layer9_moe_route_gpu10 [shape=parallelogram, fillcolor=lightyellow, label="Layer9 MoE Route\nGPU: 10"];\n    layer9_moe_route -> layer9_moe_route_gpu10;\n    layer9_moe_route_gpu11 [shape=parallelogram, fillcolor=lightyellow, label="Layer9 MoE Route\nGPU: 11"];\n    layer9_moe_route -> layer9_moe_route_gpu11;\n    layer9_moe_all2all [shape=ellipse, fillcolor=lightgray, label="Layer9 MoE\nAll-to-All Communication\nGPU: 0-15"];\n    layer9_moe_route_gpu8 -> layer9_moe_all2all;\n    layer9_moe_route_gpu9 -> layer9_moe_all2all;\n    layer9_moe_route_gpu10 -> layer9_moe_all2all;\n    layer9_moe_route_gpu11 -> layer9_moe_all2all;\n    layer9_expert0 [fillcolor=lightblue, label="Layer9 Expert 0_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 0"];\n    layer9_moe_all2all -> layer9_expert0;\n    layer9_expert1 [fillcolor=lightblue, label="Layer9 Expert 0_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 1"];\n    layer9_moe_all2all -> layer9_expert1;\n    layer9_expert2 [fillcolor=lightblue, label="Layer9 Expert 0_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 2"];\n    layer9_moe_all2all -> layer9_expert2;\n    layer9_expert3 [fillcolor=lightblue, label="Layer9 Expert 0_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 3"];\n    layer9_moe_all2all -> layer9_expert3;\n    layer9_expert4 [fillcolor=lightgreen, label="Layer9 Expert 1_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 4"];\n    layer9_moe_all2all -> layer9_expert4;\n    layer9_expert5 [fillcolor=lightgreen, label="Layer9 Expert 1_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 5"];\n    layer9_moe_all2all -> layer9_expert5;\n    layer9_expert6 [fillcolor=lightgreen, label="Layer9 Expert 1_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 6"];\n    layer9_moe_all2all -> layer9_expert6;\n    layer9_expert7 [fillcolor=lightgreen, label="Layer9 Expert 1_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 7"];\n    layer9_moe_all2all -> layer9_expert7;\n    layer9_expert8 [fillcolor=lightyellow, label="Layer9 Expert 2_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 8"];\n    layer9_moe_all2all -> layer9_expert8;\n    layer9_expert9 [fillcolor=lightyellow, label="Layer9 Expert 2_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 9"];\n    layer9_moe_all2all -> layer9_expert9;\n    layer9_expert10 [fillcolor=lightyellow, label="Layer9 Expert 2_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 10"];\n    layer9_moe_all2all -> layer9_expert10;\n    layer9_expert11 [fillcolor=lightyellow, label="Layer9 Expert 2_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 11"];\n    layer9_moe_all2all -> layer9_expert11;\n    layer9_expert12 [fillcolor=lightcoral, label="Layer9 Expert 3_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 12"];\n    layer9_moe_all2all -> layer9_expert12;\n    layer9_expert13 [fillcolor=lightcoral, label="Layer9 Expert 3_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 13"];\n    layer9_moe_all2all -> layer9_expert13;\n    layer9_expert14 [fillcolor=lightcoral, label="Layer9 Expert 3_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 14"];\n    layer9_moe_all2all -> layer9_expert14;\n    layer9_expert15 [fillcolor=lightcoral, label="Layer9 Expert 3_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 15"];\n    layer9_moe_all2all -> layer9_expert15;\n    layer9_moe_agg [shape=parallelogram, fillcolor=lightyellow, label="Layer9 MoE\nOutput Aggregation\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1024]\nGPU: 8,9,10,11"];\n    layer9_expert0 -> layer9_moe_agg;\n    layer9_expert1 -> layer9_moe_agg;\n    layer9_expert2 -> layer9_moe_agg;\n    layer9_expert3 -> layer9_moe_agg;\n    layer9_expert4 -> layer9_moe_agg;\n    layer9_expert5 -> layer9_moe_agg;\n    layer9_expert6 -> layer9_moe_agg;\n    layer9_expert7 -> layer9_moe_agg;\n    layer9_expert8 -> layer9_moe_agg;\n    layer9_expert9 -> layer9_moe_agg;\n    layer9_expert10 -> layer9_moe_agg;\n    layer9_expert11 -> layer9_moe_agg;\n    layer9_expert12 -> layer9_moe_agg;\n    layer9_expert13 -> layer9_moe_agg;\n    layer9_expert14 -> layer9_moe_agg;\n    layer9_expert15 -> layer9_moe_agg;\n    layer10_attn_qkv_gpu8 [fillcolor=lightyellow, label="Layer10 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 8"];\n    layer10_attn_score_gpu8 [fillcolor=lightyellow, label="Layer10 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 8"];\n    layer10_attn_out_gpu8 [fillcolor=lightyellow, label="Layer10 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 8"];\n    layer10_attn_qkv_gpu8 -> layer10_attn_score_gpu8;\n    layer10_attn_score_gpu8 -> layer10_attn_out_gpu8;\n    layer10_attn_qkv_gpu9 [fillcolor=lightyellow, label="Layer10 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 9"];\n    layer10_attn_score_gpu9 [fillcolor=lightyellow, label="Layer10 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 9"];\n    layer10_attn_out_gpu9 [fillcolor=lightyellow, label="Layer10 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 9"];\n    layer10_attn_qkv_gpu9 -> layer10_attn_score_gpu9;\n    layer10_attn_score_gpu9 -> layer10_attn_out_gpu9;\n    layer10_attn_qkv_gpu10 [fillcolor=lightyellow, label="Layer10 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 10"];\n    layer10_attn_score_gpu10 [fillcolor=lightyellow, label="Layer10 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 10"];\n    layer10_attn_out_gpu10 [fillcolor=lightyellow, label="Layer10 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 10"];\n    layer10_attn_qkv_gpu10 -> layer10_attn_score_gpu10;\n    layer10_attn_score_gpu10 -> layer10_attn_out_gpu10;\n    layer10_attn_qkv_gpu11 [fillcolor=lightyellow, label="Layer10 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 11"];\n    layer10_attn_score_gpu11 [fillcolor=lightyellow, label="Layer10 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 11"];\n    layer10_attn_out_gpu11 [fillcolor=lightyellow, label="Layer10 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 11"];\n    layer10_attn_qkv_gpu11 -> layer10_attn_score_gpu11;\n    layer10_attn_score_gpu11 -> layer10_attn_out_gpu11;\n    layer10_attn_allreduce [shape=ellipse, fillcolor=lightgray, label="Layer10 Attention\nAll-Reduce Sum\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1024]\nGPU: 8,9,10,11"];\n    layer10_attn_out_gpu8 -> layer10_attn_allreduce;\n    layer10_attn_out_gpu9 -> layer10_attn_allreduce;\n    layer10_attn_out_gpu10 -> layer10_attn_allreduce;\n    layer10_attn_out_gpu11 -> layer10_attn_allreduce;\n    layer9_moe_agg -> layer10_attn_qkv_gpu8;\n    layer9_moe_agg -> layer10_attn_qkv_gpu9;\n    layer9_moe_agg -> layer10_attn_qkv_gpu10;\n    layer9_moe_agg -> layer10_attn_qkv_gpu11;\n    layer10_moe_route [shape=parallelogram, fillcolor=lightyellow, label="Layer10 MoE Routing\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1]\nGPU: 8,9,10,11"];\n    layer10_attn_allreduce -> layer10_moe_route;\n    layer10_moe_route_gpu8 [shape=parallelogram, fillcolor=lightyellow, label="Layer10 MoE Route\nGPU: 8"];\n    layer10_moe_route -> layer10_moe_route_gpu8;\n    layer10_moe_route_gpu9 [shape=parallelogram, fillcolor=lightyellow, label="Layer10 MoE Route\nGPU: 9"];\n    layer10_moe_route -> layer10_moe_route_gpu9;\n    layer10_moe_route_gpu10 [shape=parallelogram, fillcolor=lightyellow, label="Layer10 MoE Route\nGPU: 10"];\n    layer10_moe_route -> layer10_moe_route_gpu10;\n    layer10_moe_route_gpu11 [shape=parallelogram, fillcolor=lightyellow, label="Layer10 MoE Route\nGPU: 11"];\n    layer10_moe_route -> layer10_moe_route_gpu11;\n    layer10_moe_all2all [shape=ellipse, fillcolor=lightgray, label="Layer10 MoE\nAll-to-All Communication\nGPU: 0-15"];\n    layer10_moe_route_gpu8 -> layer10_moe_all2all;\n    layer10_moe_route_gpu9 -> layer10_moe_all2all;\n    layer10_moe_route_gpu10 -> layer10_moe_all2all;\n    layer10_moe_route_gpu11 -> layer10_moe_all2all;\n    layer10_expert0 [fillcolor=lightblue, label="Layer10 Expert 0_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 0"];\n    layer10_moe_all2all -> layer10_expert0;\n    layer10_expert1 [fillcolor=lightblue, label="Layer10 Expert 0_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 1"];\n    layer10_moe_all2all -> layer10_expert1;\n    layer10_expert2 [fillcolor=lightblue, label="Layer10 Expert 0_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 2"];\n    layer10_moe_all2all -> layer10_expert2;\n    layer10_expert3 [fillcolor=lightblue, label="Layer10 Expert 0_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 3"];\n    layer10_moe_all2all -> layer10_expert3;\n    layer10_expert4 [fillcolor=lightgreen, label="Layer10 Expert 1_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 4"];\n    layer10_moe_all2all -> layer10_expert4;\n    layer10_expert5 [fillcolor=lightgreen, label="Layer10 Expert 1_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 5"];\n    layer10_moe_all2all -> layer10_expert5;\n    layer10_expert6 [fillcolor=lightgreen, label="Layer10 Expert 1_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 6"];\n    layer10_moe_all2all -> layer10_expert6;\n    layer10_expert7 [fillcolor=lightgreen, label="Layer10 Expert 1_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 7"];\n    layer10_moe_all2all -> layer10_expert7;\n    layer10_expert8 [fillcolor=lightyellow, label="Layer10 Expert 2_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 8"];\n    layer10_moe_all2all -> layer10_expert8;\n    layer10_expert9 [fillcolor=lightyellow, label="Layer10 Expert 2_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 9"];\n    layer10_moe_all2all -> layer10_expert9;\n    layer10_expert10 [fillcolor=lightyellow, label="Layer10 Expert 2_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 10"];\n    layer10_moe_all2all -> layer10_expert10;\n    layer10_expert11 [fillcolor=lightyellow, label="Layer10 Expert 2_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 11"];\n    layer10_moe_all2all -> layer10_expert11;\n    layer10_expert12 [fillcolor=lightcoral, label="Layer10 Expert 3_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 12"];\n    layer10_moe_all2all -> layer10_expert12;\n    layer10_expert13 [fillcolor=lightcoral, label="Layer10 Expert 3_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 13"];\n    layer10_moe_all2all -> layer10_expert13;\n    layer10_expert14 [fillcolor=lightcoral, label="Layer10 Expert 3_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 14"];\n    layer10_moe_all2all -> layer10_expert14;\n    layer10_expert15 [fillcolor=lightcoral, label="Layer10 Expert 3_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 15"];\n    layer10_moe_all2all -> layer10_expert15;\n    layer10_moe_agg [shape=parallelogram, fillcolor=lightyellow, label="Layer10 MoE\nOutput Aggregation\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1024]\nGPU: 8,9,10,11"];\n    layer10_expert0 -> layer10_moe_agg;\n    layer10_expert1 -> layer10_moe_agg;\n    layer10_expert2 -> layer10_moe_agg;\n    layer10_expert3 -> layer10_moe_agg;\n    layer10_expert4 -> layer10_moe_agg;\n    layer10_expert5 -> layer10_moe_agg;\n    layer10_expert6 -> layer10_moe_agg;\n    layer10_expert7 -> layer10_moe_agg;\n    layer10_expert8 -> layer10_moe_agg;\n    layer10_expert9 -> layer10_moe_agg;\n    layer10_expert10 -> layer10_moe_agg;\n    layer10_expert11 -> layer10_moe_agg;\n    layer10_expert12 -> layer10_moe_agg;\n    layer10_expert13 -> layer10_moe_agg;\n    layer10_expert14 -> layer10_moe_agg;\n    layer10_expert15 -> layer10_moe_agg;\n    layer11_attn_qkv_gpu8 [fillcolor=lightyellow, label="Layer11 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 8"];\n    layer11_attn_score_gpu8 [fillcolor=lightyellow, label="Layer11 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 8"];\n    layer11_attn_out_gpu8 [fillcolor=lightyellow, label="Layer11 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 8"];\n    layer11_attn_qkv_gpu8 -> layer11_attn_score_gpu8;\n    layer11_attn_score_gpu8 -> layer11_attn_out_gpu8;\n    layer11_attn_qkv_gpu9 [fillcolor=lightyellow, label="Layer11 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 9"];\n    layer11_attn_score_gpu9 [fillcolor=lightyellow, label="Layer11 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 9"];\n    layer11_attn_out_gpu9 [fillcolor=lightyellow, label="Layer11 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 9"];\n    layer11_attn_qkv_gpu9 -> layer11_attn_score_gpu9;\n    layer11_attn_score_gpu9 -> layer11_attn_out_gpu9;\n    layer11_attn_qkv_gpu10 [fillcolor=lightyellow, label="Layer11 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 10"];\n    layer11_attn_score_gpu10 [fillcolor=lightyellow, label="Layer11 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 10"];\n    layer11_attn_out_gpu10 [fillcolor=lightyellow, label="Layer11 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 10"];\n    layer11_attn_qkv_gpu10 -> layer11_attn_score_gpu10;\n    layer11_attn_score_gpu10 -> layer11_attn_out_gpu10;\n    layer11_attn_qkv_gpu11 [fillcolor=lightyellow, label="Layer11 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 11"];\n    layer11_attn_score_gpu11 [fillcolor=lightyellow, label="Layer11 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 11"];\n    layer11_attn_out_gpu11 [fillcolor=lightyellow, label="Layer11 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 11"];\n    layer11_attn_qkv_gpu11 -> layer11_attn_score_gpu11;\n    layer11_attn_score_gpu11 -> layer11_attn_out_gpu11;\n    layer11_attn_allreduce [shape=ellipse, fillcolor=lightgray, label="Layer11 Attention\nAll-Reduce Sum\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1024]\nGPU: 8,9,10,11"];\n    layer11_attn_out_gpu8 -> layer11_attn_allreduce;\n    layer11_attn_out_gpu9 -> layer11_attn_allreduce;\n    layer11_attn_out_gpu10 -> layer11_attn_allreduce;\n    layer11_attn_out_gpu11 -> layer11_attn_allreduce;\n    layer10_moe_agg -> layer11_attn_qkv_gpu8;\n    layer10_moe_agg -> layer11_attn_qkv_gpu9;\n    layer10_moe_agg -> layer11_attn_qkv_gpu10;\n    layer10_moe_agg -> layer11_attn_qkv_gpu11;\n    layer11_moe_route [shape=parallelogram, fillcolor=lightyellow, label="Layer11 MoE Routing\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1]\nGPU: 8,9,10,11"];\n    layer11_attn_allreduce -> layer11_moe_route;\n    layer11_moe_route_gpu8 [shape=parallelogram, fillcolor=lightyellow, label="Layer11 MoE Route\nGPU: 8"];\n    layer11_moe_route -> layer11_moe_route_gpu8;\n    layer11_moe_route_gpu9 [shape=parallelogram, fillcolor=lightyellow, label="Layer11 MoE Route\nGPU: 9"];\n    layer11_moe_route -> layer11_moe_route_gpu9;\n    layer11_moe_route_gpu10 [shape=parallelogram, fillcolor=lightyellow, label="Layer11 MoE Route\nGPU: 10"];\n    layer11_moe_route -> layer11_moe_route_gpu10;\n    layer11_moe_route_gpu11 [shape=parallelogram, fillcolor=lightyellow, label="Layer11 MoE Route\nGPU: 11"];\n    layer11_moe_route -> layer11_moe_route_gpu11;\n    layer11_moe_all2all [shape=ellipse, fillcolor=lightgray, label="Layer11 MoE\nAll-to-All Communication\nGPU: 0-15"];\n    layer11_moe_route_gpu8 -> layer11_moe_all2all;\n    layer11_moe_route_gpu9 -> layer11_moe_all2all;\n    layer11_moe_route_gpu10 -> layer11_moe_all2all;\n    layer11_moe_route_gpu11 -> layer11_moe_all2all;\n    layer11_expert0 [fillcolor=lightblue, label="Layer11 Expert 0_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 0"];\n    layer11_moe_all2all -> layer11_expert0;\n    layer11_expert1 [fillcolor=lightblue, label="Layer11 Expert 0_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 1"];\n    layer11_moe_all2all -> layer11_expert1;\n    layer11_expert2 [fillcolor=lightblue, label="Layer11 Expert 0_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 2"];\n    layer11_moe_all2all -> layer11_expert2;\n    layer11_expert3 [fillcolor=lightblue, label="Layer11 Expert 0_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 3"];\n    layer11_moe_all2all -> layer11_expert3;\n    layer11_expert4 [fillcolor=lightgreen, label="Layer11 Expert 1_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 4"];\n    layer11_moe_all2all -> layer11_expert4;\n    layer11_expert5 [fillcolor=lightgreen, label="Layer11 Expert 1_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 5"];\n    layer11_moe_all2all -> layer11_expert5;\n    layer11_expert6 [fillcolor=lightgreen, label="Layer11 Expert 1_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 6"];\n    layer11_moe_all2all -> layer11_expert6;\n    layer11_expert7 [fillcolor=lightgreen, label="Layer11 Expert 1_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 7"];\n    layer11_moe_all2all -> layer11_expert7;\n    layer11_expert8 [fillcolor=lightyellow, label="Layer11 Expert 2_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 8"];\n    layer11_moe_all2all -> layer11_expert8;\n    layer11_expert9 [fillcolor=lightyellow, label="Layer11 Expert 2_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 9"];\n    layer11_moe_all2all -> layer11_expert9;\n    layer11_expert10 [fillcolor=lightyellow, label="Layer11 Expert 2_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 10"];\n    layer11_moe_all2all -> layer11_expert10;\n    layer11_expert11 [fillcolor=lightyellow, label="Layer11 Expert 2_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 11"];\n    layer11_moe_all2all -> layer11_expert11;\n    layer11_expert12 [fillcolor=lightcoral, label="Layer11 Expert 3_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 12"];\n    layer11_moe_all2all -> layer11_expert12;\n    layer11_expert13 [fillcolor=lightcoral, label="Layer11 Expert 3_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 13"];\n    layer11_moe_all2all -> layer11_expert13;\n    layer11_expert14 [fillcolor=lightcoral, label="Layer11 Expert 3_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 14"];\n    layer11_moe_all2all -> layer11_expert14;\n    layer11_expert15 [fillcolor=lightcoral, label="Layer11 Expert 3_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 15"];\n    layer11_moe_all2all -> layer11_expert15;\n    layer11_moe_agg [shape=parallelogram, fillcolor=lightyellow, label="Layer11 MoE\nOutput Aggregation\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1024]\nGPU: 8,9,10,11"];\n    layer11_expert0 -> layer11_moe_agg;\n    layer11_expert1 -> layer11_moe_agg;\n    layer11_expert2 -> layer11_moe_agg;\n    layer11_expert3 -> layer11_moe_agg;\n    layer11_expert4 -> layer11_moe_agg;\n    layer11_expert5 -> layer11_moe_agg;\n    layer11_expert6 -> layer11_moe_agg;\n    layer11_expert7 -> layer11_moe_agg;\n    layer11_expert8 -> layer11_moe_agg;\n    layer11_expert9 -> layer11_moe_agg;\n    layer11_expert10 -> layer11_moe_agg;\n    layer11_expert11 -> layer11_moe_agg;\n    layer11_expert12 -> layer11_moe_agg;\n    layer11_expert13 -> layer11_moe_agg;\n    layer11_expert14 -> layer11_moe_agg;\n    layer11_expert15 -> layer11_moe_agg;\n    layer12_attn_qkv_gpu12 [fillcolor=lightcoral, label="Layer12 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 12"];\n    layer12_attn_score_gpu12 [fillcolor=lightcoral, label="Layer12 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 12"];\n    layer12_attn_out_gpu12 [fillcolor=lightcoral, label="Layer12 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 12"];\n    layer12_attn_qkv_gpu12 -> layer12_attn_score_gpu12;\n    layer12_attn_score_gpu12 -> layer12_attn_out_gpu12;\n    layer12_attn_qkv_gpu13 [fillcolor=lightcoral, label="Layer12 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 13"];\n    layer12_attn_score_gpu13 [fillcolor=lightcoral, label="Layer12 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 13"];\n    layer12_attn_out_gpu13 [fillcolor=lightcoral, label="Layer12 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 13"];\n    layer12_attn_qkv_gpu13 -> layer12_attn_score_gpu13;\n    layer12_attn_score_gpu13 -> layer12_attn_out_gpu13;\n    layer12_attn_qkv_gpu14 [fillcolor=lightcoral, label="Layer12 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 14"];\n    layer12_attn_score_gpu14 [fillcolor=lightcoral, label="Layer12 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 14"];\n    layer12_attn_out_gpu14 [fillcolor=lightcoral, label="Layer12 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 14"];\n    layer12_attn_qkv_gpu14 -> layer12_attn_score_gpu14;\n    layer12_attn_score_gpu14 -> layer12_attn_out_gpu14;\n    layer12_attn_qkv_gpu15 [fillcolor=lightcoral, label="Layer12 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 15"];\n    layer12_attn_score_gpu15 [fillcolor=lightcoral, label="Layer12 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 15"];\n    layer12_attn_out_gpu15 [fillcolor=lightcoral, label="Layer12 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 15"];\n    layer12_attn_qkv_gpu15 -> layer12_attn_score_gpu15;\n    layer12_attn_score_gpu15 -> layer12_attn_out_gpu15;\n    layer12_attn_allreduce [shape=ellipse, fillcolor=lightgray, label="Layer12 Attention\nAll-Reduce Sum\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1024]\nGPU: 12,13,14,15"];\n    layer12_attn_out_gpu12 -> layer12_attn_allreduce;\n    layer12_attn_out_gpu13 -> layer12_attn_allreduce;\n    layer12_attn_out_gpu14 -> layer12_attn_allreduce;\n    layer12_attn_out_gpu15 -> layer12_attn_allreduce;\n    layer11_moe_agg -> layer12_attn_qkv_gpu12;\n    layer11_moe_agg -> layer12_attn_qkv_gpu13;\n    layer11_moe_agg -> layer12_attn_qkv_gpu14;\n    layer11_moe_agg -> layer12_attn_qkv_gpu15;\n    layer12_moe_route [shape=parallelogram, fillcolor=lightcoral, label="Layer12 MoE Routing\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1]\nGPU: 12,13,14,15"];\n    layer12_attn_allreduce -> layer12_moe_route;\n    layer12_moe_route_gpu12 [shape=parallelogram, fillcolor=lightcoral, label="Layer12 MoE Route\nGPU: 12"];\n    layer12_moe_route -> layer12_moe_route_gpu12;\n    layer12_moe_route_gpu13 [shape=parallelogram, fillcolor=lightcoral, label="Layer12 MoE Route\nGPU: 13"];\n    layer12_moe_route -> layer12_moe_route_gpu13;\n    layer12_moe_route_gpu14 [shape=parallelogram, fillcolor=lightcoral, label="Layer12 MoE Route\nGPU: 14"];\n    layer12_moe_route -> layer12_moe_route_gpu14;\n    layer12_moe_route_gpu15 [shape=parallelogram, fillcolor=lightcoral, label="Layer12 MoE Route\nGPU: 15"];\n    layer12_moe_route -> layer12_moe_route_gpu15;\n    layer12_moe_all2all [shape=ellipse, fillcolor=lightgray, label="Layer12 MoE\nAll-to-All Communication\nGPU: 0-15"];\n    layer12_moe_route_gpu12 -> layer12_moe_all2all;\n    layer12_moe_route_gpu13 -> layer12_moe_all2all;\n    layer12_moe_route_gpu14 -> layer12_moe_all2all;\n    layer12_moe_route_gpu15 -> layer12_moe_all2all;\n    layer12_expert0 [fillcolor=lightblue, label="Layer12 Expert 0_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 0"];\n    layer12_moe_all2all -> layer12_expert0;\n    layer12_expert1 [fillcolor=lightblue, label="Layer12 Expert 0_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 1"];\n    layer12_moe_all2all -> layer12_expert1;\n    layer12_expert2 [fillcolor=lightblue, label="Layer12 Expert 0_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 2"];\n    layer12_moe_all2all -> layer12_expert2;\n    layer12_expert3 [fillcolor=lightblue, label="Layer12 Expert 0_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 3"];\n    layer12_moe_all2all -> layer12_expert3;\n    layer12_expert4 [fillcolor=lightgreen, label="Layer12 Expert 1_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 4"];\n    layer12_moe_all2all -> layer12_expert4;\n    layer12_expert5 [fillcolor=lightgreen, label="Layer12 Expert 1_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 5"];\n    layer12_moe_all2all -> layer12_expert5;\n    layer12_expert6 [fillcolor=lightgreen, label="Layer12 Expert 1_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 6"];\n    layer12_moe_all2all -> layer12_expert6;\n    layer12_expert7 [fillcolor=lightgreen, label="Layer12 Expert 1_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 7"];\n    layer12_moe_all2all -> layer12_expert7;\n    layer12_expert8 [fillcolor=lightyellow, label="Layer12 Expert 2_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 8"];\n    layer12_moe_all2all -> layer12_expert8;\n    layer12_expert9 [fillcolor=lightyellow, label="Layer12 Expert 2_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 9"];\n    layer12_moe_all2all -> layer12_expert9;\n    layer12_expert10 [fillcolor=lightyellow, label="Layer12 Expert 2_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 10"];\n    layer12_moe_all2all -> layer12_expert10;\n    layer12_expert11 [fillcolor=lightyellow, label="Layer12 Expert 2_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 11"];\n    layer12_moe_all2all -> layer12_expert11;\n    layer12_expert12 [fillcolor=lightcoral, label="Layer12 Expert 3_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 12"];\n    layer12_moe_all2all -> layer12_expert12;\n    layer12_expert13 [fillcolor=lightcoral, label="Layer12 Expert 3_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 13"];\n    layer12_moe_all2all -> layer12_expert13;\n    layer12_expert14 [fillcolor=lightcoral, label="Layer12 Expert 3_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 14"];\n    layer12_moe_all2all -> layer12_expert14;\n    layer12_expert15 [fillcolor=lightcoral, label="Layer12 Expert 3_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 15"];\n    layer12_moe_all2all -> layer12_expert15;\n    layer12_moe_agg [shape=parallelogram, fillcolor=lightcoral, label="Layer12 MoE\nOutput Aggregation\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1024]\nGPU: 12,13,14,15"];\n    layer12_expert0 -> layer12_moe_agg;\n    layer12_expert1 -> layer12_moe_agg;\n    layer12_expert2 -> layer12_moe_agg;\n    layer12_expert3 -> layer12_moe_agg;\n    layer12_expert4 -> layer12_moe_agg;\n    layer12_expert5 -> layer12_moe_agg;\n    layer12_expert6 -> layer12_moe_agg;\n    layer12_expert7 -> layer12_moe_agg;\n    layer12_expert8 -> layer12_moe_agg;\n    layer12_expert9 -> layer12_moe_agg;\n    layer12_expert10 -> layer12_moe_agg;\n    layer12_expert11 -> layer12_moe_agg;\n    layer12_expert12 -> layer12_moe_agg;\n    layer12_expert13 -> layer12_moe_agg;\n    layer12_expert14 -> layer12_moe_agg;\n    layer12_expert15 -> layer12_moe_agg;\n    layer13_attn_qkv_gpu12 [fillcolor=lightcoral, label="Layer13 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 12"];\n    layer13_attn_score_gpu12 [fillcolor=lightcoral, label="Layer13 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 12"];\n    layer13_attn_out_gpu12 [fillcolor=lightcoral, label="Layer13 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 12"];\n    layer13_attn_qkv_gpu12 -> layer13_attn_score_gpu12;\n    layer13_attn_score_gpu12 -> layer13_attn_out_gpu12;\n    layer13_attn_qkv_gpu13 [fillcolor=lightcoral, label="Layer13 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 13"];\n    layer13_attn_score_gpu13 [fillcolor=lightcoral, label="Layer13 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 13"];\n    layer13_attn_out_gpu13 [fillcolor=lightcoral, label="Layer13 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 13"];\n    layer13_attn_qkv_gpu13 -> layer13_attn_score_gpu13;\n    layer13_attn_score_gpu13 -> layer13_attn_out_gpu13;\n    layer13_attn_qkv_gpu14 [fillcolor=lightcoral, label="Layer13 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 14"];\n    layer13_attn_score_gpu14 [fillcolor=lightcoral, label="Layer13 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 14"];\n    layer13_attn_out_gpu14 [fillcolor=lightcoral, label="Layer13 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 14"];\n    layer13_attn_qkv_gpu14 -> layer13_attn_score_gpu14;\n    layer13_attn_score_gpu14 -> layer13_attn_out_gpu14;\n    layer13_attn_qkv_gpu15 [fillcolor=lightcoral, label="Layer13 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 15"];\n    layer13_attn_score_gpu15 [fillcolor=lightcoral, label="Layer13 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 15"];\n    layer13_attn_out_gpu15 [fillcolor=lightcoral, label="Layer13 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 15"];\n    layer13_attn_qkv_gpu15 -> layer13_attn_score_gpu15;\n    layer13_attn_score_gpu15 -> layer13_attn_out_gpu15;\n    layer13_attn_allreduce [shape=ellipse, fillcolor=lightgray, label="Layer13 Attention\nAll-Reduce Sum\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1024]\nGPU: 12,13,14,15"];\n    layer13_attn_out_gpu12 -> layer13_attn_allreduce;\n    layer13_attn_out_gpu13 -> layer13_attn_allreduce;\n    layer13_attn_out_gpu14 -> layer13_attn_allreduce;\n    layer13_attn_out_gpu15 -> layer13_attn_allreduce;\n    layer12_moe_agg -> layer13_attn_qkv_gpu12;\n    layer12_moe_agg -> layer13_attn_qkv_gpu13;\n    layer12_moe_agg -> layer13_attn_qkv_gpu14;\n    layer12_moe_agg -> layer13_attn_qkv_gpu15;\n    layer13_moe_route [shape=parallelogram, fillcolor=lightcoral, label="Layer13 MoE Routing\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1]\nGPU: 12,13,14,15"];\n    layer13_attn_allreduce -> layer13_moe_route;\n    layer13_moe_route_gpu12 [shape=parallelogram, fillcolor=lightcoral, label="Layer13 MoE Route\nGPU: 12"];\n    layer13_moe_route -> layer13_moe_route_gpu12;\n    layer13_moe_route_gpu13 [shape=parallelogram, fillcolor=lightcoral, label="Layer13 MoE Route\nGPU: 13"];\n    layer13_moe_route -> layer13_moe_route_gpu13;\n    layer13_moe_route_gpu14 [shape=parallelogram, fillcolor=lightcoral, label="Layer13 MoE Route\nGPU: 14"];\n    layer13_moe_route -> layer13_moe_route_gpu14;\n    layer13_moe_route_gpu15 [shape=parallelogram, fillcolor=lightcoral, label="Layer13 MoE Route\nGPU: 15"];\n    layer13_moe_route -> layer13_moe_route_gpu15;\n    layer13_moe_all2all [shape=ellipse, fillcolor=lightgray, label="Layer13 MoE\nAll-to-All Communication\nGPU: 0-15"];\n    layer13_moe_route_gpu12 -> layer13_moe_all2all;\n    layer13_moe_route_gpu13 -> layer13_moe_all2all;\n    layer13_moe_route_gpu14 -> layer13_moe_all2all;\n    layer13_moe_route_gpu15 -> layer13_moe_all2all;\n    layer13_expert0 [fillcolor=lightblue, label="Layer13 Expert 0_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 0"];\n    layer13_moe_all2all -> layer13_expert0;\n    layer13_expert1 [fillcolor=lightblue, label="Layer13 Expert 0_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 1"];\n    layer13_moe_all2all -> layer13_expert1;\n    layer13_expert2 [fillcolor=lightblue, label="Layer13 Expert 0_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 2"];\n    layer13_moe_all2all -> layer13_expert2;\n    layer13_expert3 [fillcolor=lightblue, label="Layer13 Expert 0_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 3"];\n    layer13_moe_all2all -> layer13_expert3;\n    layer13_expert4 [fillcolor=lightgreen, label="Layer13 Expert 1_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 4"];\n    layer13_moe_all2all -> layer13_expert4;\n    layer13_expert5 [fillcolor=lightgreen, label="Layer13 Expert 1_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 5"];\n    layer13_moe_all2all -> layer13_expert5;\n    layer13_expert6 [fillcolor=lightgreen, label="Layer13 Expert 1_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 6"];\n    layer13_moe_all2all -> layer13_expert6;\n    layer13_expert7 [fillcolor=lightgreen, label="Layer13 Expert 1_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 7"];\n    layer13_moe_all2all -> layer13_expert7;\n    layer13_expert8 [fillcolor=lightyellow, label="Layer13 Expert 2_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 8"];\n    layer13_moe_all2all -> layer13_expert8;\n    layer13_expert9 [fillcolor=lightyellow, label="Layer13 Expert 2_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 9"];\n    layer13_moe_all2all -> layer13_expert9;\n    layer13_expert10 [fillcolor=lightyellow, label="Layer13 Expert 2_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 10"];\n    layer13_moe_all2all -> layer13_expert10;\n    layer13_expert11 [fillcolor=lightyellow, label="Layer13 Expert 2_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 11"];\n    layer13_moe_all2all -> layer13_expert11;\n    layer13_expert12 [fillcolor=lightcoral, label="Layer13 Expert 3_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 12"];\n    layer13_moe_all2all -> layer13_expert12;\n    layer13_expert13 [fillcolor=lightcoral, label="Layer13 Expert 3_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 13"];\n    layer13_moe_all2all -> layer13_expert13;\n    layer13_expert14 [fillcolor=lightcoral, label="Layer13 Expert 3_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 14"];\n    layer13_moe_all2all -> layer13_expert14;\n    layer13_expert15 [fillcolor=lightcoral, label="Layer13 Expert 3_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 15"];\n    layer13_moe_all2all -> layer13_expert15;\n    layer13_moe_agg [shape=parallelogram, fillcolor=lightcoral, label="Layer13 MoE\nOutput Aggregation\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1024]\nGPU: 12,13,14,15"];\n    layer13_expert0 -> layer13_moe_agg;\n    layer13_expert1 -> layer13_moe_agg;\n    layer13_expert2 -> layer13_moe_agg;\n    layer13_expert3 -> layer13_moe_agg;\n    layer13_expert4 -> layer13_moe_agg;\n    layer13_expert5 -> layer13_moe_agg;\n    layer13_expert6 -> layer13_moe_agg;\n    layer13_expert7 -> layer13_moe_agg;\n    layer13_expert8 -> layer13_moe_agg;\n    layer13_expert9 -> layer13_moe_agg;\n    layer13_expert10 -> layer13_moe_agg;\n    layer13_expert11 -> layer13_moe_agg;\n    layer13_expert12 -> layer13_moe_agg;\n    layer13_expert13 -> layer13_moe_agg;\n    layer13_expert14 -> layer13_moe_agg;\n    layer13_expert15 -> layer13_moe_agg;\n    layer14_attn_qkv_gpu12 [fillcolor=lightcoral, label="Layer14 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 12"];\n    layer14_attn_score_gpu12 [fillcolor=lightcoral, label="Layer14 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 12"];\n    layer14_attn_out_gpu12 [fillcolor=lightcoral, label="Layer14 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 12"];\n    layer14_attn_qkv_gpu12 -> layer14_attn_score_gpu12;\n    layer14_attn_score_gpu12 -> layer14_attn_out_gpu12;\n    layer14_attn_qkv_gpu13 [fillcolor=lightcoral, label="Layer14 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 13"];\n    layer14_attn_score_gpu13 [fillcolor=lightcoral, label="Layer14 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 13"];\n    layer14_attn_out_gpu13 [fillcolor=lightcoral, label="Layer14 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 13"];\n    layer14_attn_qkv_gpu13 -> layer14_attn_score_gpu13;\n    layer14_attn_score_gpu13 -> layer14_attn_out_gpu13;\n    layer14_attn_qkv_gpu14 [fillcolor=lightcoral, label="Layer14 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 14"];\n    layer14_attn_score_gpu14 [fillcolor=lightcoral, label="Layer14 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 14"];\n    layer14_attn_out_gpu14 [fillcolor=lightcoral, label="Layer14 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 14"];\n    layer14_attn_qkv_gpu14 -> layer14_attn_score_gpu14;\n    layer14_attn_score_gpu14 -> layer14_attn_out_gpu14;\n    layer14_attn_qkv_gpu15 [fillcolor=lightcoral, label="Layer14 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 15"];\n    layer14_attn_score_gpu15 [fillcolor=lightcoral, label="Layer14 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 15"];\n    layer14_attn_out_gpu15 [fillcolor=lightcoral, label="Layer14 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 15"];\n    layer14_attn_qkv_gpu15 -> layer14_attn_score_gpu15;\n    layer14_attn_score_gpu15 -> layer14_attn_out_gpu15;\n    layer14_attn_allreduce [shape=ellipse, fillcolor=lightgray, label="Layer14 Attention\nAll-Reduce Sum\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1024]\nGPU: 12,13,14,15"];\n    layer14_attn_out_gpu12 -> layer14_attn_allreduce;\n    layer14_attn_out_gpu13 -> layer14_attn_allreduce;\n    layer14_attn_out_gpu14 -> layer14_attn_allreduce;\n    layer14_attn_out_gpu15 -> layer14_attn_allreduce;\n    layer13_moe_agg -> layer14_attn_qkv_gpu12;\n    layer13_moe_agg -> layer14_attn_qkv_gpu13;\n    layer13_moe_agg -> layer14_attn_qkv_gpu14;\n    layer13_moe_agg -> layer14_attn_qkv_gpu15;\n    layer14_moe_route [shape=parallelogram, fillcolor=lightcoral, label="Layer14 MoE Routing\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1]\nGPU: 12,13,14,15"];\n    layer14_attn_allreduce -> layer14_moe_route;\n    layer14_moe_route_gpu12 [shape=parallelogram, fillcolor=lightcoral, label="Layer14 MoE Route\nGPU: 12"];\n    layer14_moe_route -> layer14_moe_route_gpu12;\n    layer14_moe_route_gpu13 [shape=parallelogram, fillcolor=lightcoral, label="Layer14 MoE Route\nGPU: 13"];\n    layer14_moe_route -> layer14_moe_route_gpu13;\n    layer14_moe_route_gpu14 [shape=parallelogram, fillcolor=lightcoral, label="Layer14 MoE Route\nGPU: 14"];\n    layer14_moe_route -> layer14_moe_route_gpu14;\n    layer14_moe_route_gpu15 [shape=parallelogram, fillcolor=lightcoral, label="Layer14 MoE Route\nGPU: 15"];\n    layer14_moe_route -> layer14_moe_route_gpu15;\n    layer14_moe_all2all [shape=ellipse, fillcolor=lightgray, label="Layer14 MoE\nAll-to-All Communication\nGPU: 0-15"];\n    layer14_moe_route_gpu12 -> layer14_moe_all2all;\n    layer14_moe_route_gpu13 -> layer14_moe_all2all;\n    layer14_moe_route_gpu14 -> layer14_moe_all2all;\n    layer14_moe_route_gpu15 -> layer14_moe_all2all;\n    layer14_expert0 [fillcolor=lightblue, label="Layer14 Expert 0_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 0"];\n    layer14_moe_all2all -> layer14_expert0;\n    layer14_expert1 [fillcolor=lightblue, label="Layer14 Expert 0_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 1"];\n    layer14_moe_all2all -> layer14_expert1;\n    layer14_expert2 [fillcolor=lightblue, label="Layer14 Expert 0_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 2"];\n    layer14_moe_all2all -> layer14_expert2;\n    layer14_expert3 [fillcolor=lightblue, label="Layer14 Expert 0_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 3"];\n    layer14_moe_all2all -> layer14_expert3;\n    layer14_expert4 [fillcolor=lightgreen, label="Layer14 Expert 1_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 4"];\n    layer14_moe_all2all -> layer14_expert4;\n    layer14_expert5 [fillcolor=lightgreen, label="Layer14 Expert 1_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 5"];\n    layer14_moe_all2all -> layer14_expert5;\n    layer14_expert6 [fillcolor=lightgreen, label="Layer14 Expert 1_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 6"];\n    layer14_moe_all2all -> layer14_expert6;\n    layer14_expert7 [fillcolor=lightgreen, label="Layer14 Expert 1_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 7"];\n    layer14_moe_all2all -> layer14_expert7;\n    layer14_expert8 [fillcolor=lightyellow, label="Layer14 Expert 2_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 8"];\n    layer14_moe_all2all -> layer14_expert8;\n    layer14_expert9 [fillcolor=lightyellow, label="Layer14 Expert 2_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 9"];\n    layer14_moe_all2all -> layer14_expert9;\n    layer14_expert10 [fillcolor=lightyellow, label="Layer14 Expert 2_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 10"];\n    layer14_moe_all2all -> layer14_expert10;\n    layer14_expert11 [fillcolor=lightyellow, label="Layer14 Expert 2_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 11"];\n    layer14_moe_all2all -> layer14_expert11;\n    layer14_expert12 [fillcolor=lightcoral, label="Layer14 Expert 3_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 12"];\n    layer14_moe_all2all -> layer14_expert12;\n    layer14_expert13 [fillcolor=lightcoral, label="Layer14 Expert 3_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 13"];\n    layer14_moe_all2all -> layer14_expert13;\n    layer14_expert14 [fillcolor=lightcoral, label="Layer14 Expert 3_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 14"];\n    layer14_moe_all2all -> layer14_expert14;\n    layer14_expert15 [fillcolor=lightcoral, label="Layer14 Expert 3_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 15"];\n    layer14_moe_all2all -> layer14_expert15;\n    layer14_moe_agg [shape=parallelogram, fillcolor=lightcoral, label="Layer14 MoE\nOutput Aggregation\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1024]\nGPU: 12,13,14,15"];\n    layer14_expert0 -> layer14_moe_agg;\n    layer14_expert1 -> layer14_moe_agg;\n    layer14_expert2 -> layer14_moe_agg;\n    layer14_expert3 -> layer14_moe_agg;\n    layer14_expert4 -> layer14_moe_agg;\n    layer14_expert5 -> layer14_moe_agg;\n    layer14_expert6 -> layer14_moe_agg;\n    layer14_expert7 -> layer14_moe_agg;\n    layer14_expert8 -> layer14_moe_agg;\n    layer14_expert9 -> layer14_moe_agg;\n    layer14_expert10 -> layer14_moe_agg;\n    layer14_expert11 -> layer14_moe_agg;\n    layer14_expert12 -> layer14_moe_agg;\n    layer14_expert13 -> layer14_moe_agg;\n    layer14_expert14 -> layer14_moe_agg;\n    layer14_expert15 -> layer14_moe_agg;\n    layer15_attn_qkv_gpu12 [fillcolor=lightcoral, label="Layer15 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 12"];\n    layer15_attn_score_gpu12 [fillcolor=lightcoral, label="Layer15 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 12"];\n    layer15_attn_out_gpu12 [fillcolor=lightcoral, label="Layer15 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 12"];\n    layer15_attn_qkv_gpu12 -> layer15_attn_score_gpu12;\n    layer15_attn_score_gpu12 -> layer15_attn_out_gpu12;\n    layer15_attn_qkv_gpu13 [fillcolor=lightcoral, label="Layer15 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 13"];\n    layer15_attn_score_gpu13 [fillcolor=lightcoral, label="Layer15 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 13"];\n    layer15_attn_out_gpu13 [fillcolor=lightcoral, label="Layer15 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 13"];\n    layer15_attn_qkv_gpu13 -> layer15_attn_score_gpu13;\n    layer15_attn_score_gpu13 -> layer15_attn_out_gpu13;\n    layer15_attn_qkv_gpu14 [fillcolor=lightcoral, label="Layer15 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 14"];\n    layer15_attn_score_gpu14 [fillcolor=lightcoral, label="Layer15 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 14"];\n    layer15_attn_out_gpu14 [fillcolor=lightcoral, label="Layer15 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 14"];\n    layer15_attn_qkv_gpu14 -> layer15_attn_score_gpu14;\n    layer15_attn_score_gpu14 -> layer15_attn_out_gpu14;\n    layer15_attn_qkv_gpu15 [fillcolor=lightcoral, label="Layer15 Attention QKV Proj\n(Column Parallel)\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 256]\nGPU: 15"];\n    layer15_attn_score_gpu15 [fillcolor=lightcoral, label="Layer15 Attention Scores\nInput: [64, 4, 1024, 1024]\nOutput: [64, 4, 1024, 1024]\nGPU: 15"];\n    layer15_attn_out_gpu15 [fillcolor=lightcoral, label="Layer15 Attention Output\n(Row Parallel)\nInput: [64, 1024, 256]\nOutput: [64, 1024, 256]\nGPU: 15"];\n    layer15_attn_qkv_gpu15 -> layer15_attn_score_gpu15;\n    layer15_attn_score_gpu15 -> layer15_attn_out_gpu15;\n    layer15_attn_allreduce [shape=ellipse, fillcolor=lightgray, label="Layer15 Attention\nAll-Reduce Sum\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1024]\nGPU: 12,13,14,15"];\n    layer15_attn_out_gpu12 -> layer15_attn_allreduce;\n    layer15_attn_out_gpu13 -> layer15_attn_allreduce;\n    layer15_attn_out_gpu14 -> layer15_attn_allreduce;\n    layer15_attn_out_gpu15 -> layer15_attn_allreduce;\n    layer14_moe_agg -> layer15_attn_qkv_gpu12;\n    layer14_moe_agg -> layer15_attn_qkv_gpu13;\n    layer14_moe_agg -> layer15_attn_qkv_gpu14;\n    layer14_moe_agg -> layer15_attn_qkv_gpu15;\n    layer15_moe_route [shape=parallelogram, fillcolor=lightcoral, label="Layer15 MoE Routing\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1]\nGPU: 12,13,14,15"];\n    layer15_attn_allreduce -> layer15_moe_route;\n    layer15_moe_route_gpu12 [shape=parallelogram, fillcolor=lightcoral, label="Layer15 MoE Route\nGPU: 12"];\n    layer15_moe_route -> layer15_moe_route_gpu12;\n    layer15_moe_route_gpu13 [shape=parallelogram, fillcolor=lightcoral, label="Layer15 MoE Route\nGPU: 13"];\n    layer15_moe_route -> layer15_moe_route_gpu13;\n    layer15_moe_route_gpu14 [shape=parallelogram, fillcolor=lightcoral, label="Layer15 MoE Route\nGPU: 14"];\n    layer15_moe_route -> layer15_moe_route_gpu14;\n    layer15_moe_route_gpu15 [shape=parallelogram, fillcolor=lightcoral, label="Layer15 MoE Route\nGPU: 15"];\n    layer15_moe_route -> layer15_moe_route_gpu15;\n    layer15_moe_all2all [shape=ellipse, fillcolor=lightgray, label="Layer15 MoE\nAll-to-All Communication\nGPU: 0-15"];\n    layer15_moe_route_gpu12 -> layer15_moe_all2all;\n    layer15_moe_route_gpu13 -> layer15_moe_all2all;\n    layer15_moe_route_gpu14 -> layer15_moe_all2all;\n    layer15_moe_route_gpu15 -> layer15_moe_all2all;\n    layer15_expert0 [fillcolor=lightblue, label="Layer15 Expert 0_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 0"];\n    layer15_moe_all2all -> layer15_expert0;\n    layer15_expert1 [fillcolor=lightblue, label="Layer15 Expert 0_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 1"];\n    layer15_moe_all2all -> layer15_expert1;\n    layer15_expert2 [fillcolor=lightblue, label="Layer15 Expert 0_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 2"];\n    layer15_moe_all2all -> layer15_expert2;\n    layer15_expert3 [fillcolor=lightblue, label="Layer15 Expert 0_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 3"];\n    layer15_moe_all2all -> layer15_expert3;\n    layer15_expert4 [fillcolor=lightgreen, label="Layer15 Expert 1_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 4"];\n    layer15_moe_all2all -> layer15_expert4;\n    layer15_expert5 [fillcolor=lightgreen, label="Layer15 Expert 1_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 5"];\n    layer15_moe_all2all -> layer15_expert5;\n    layer15_expert6 [fillcolor=lightgreen, label="Layer15 Expert 1_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 6"];\n    layer15_moe_all2all -> layer15_expert6;\n    layer15_expert7 [fillcolor=lightgreen, label="Layer15 Expert 1_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 7"];\n    layer15_moe_all2all -> layer15_expert7;\n    layer15_expert8 [fillcolor=lightyellow, label="Layer15 Expert 2_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 8"];\n    layer15_moe_all2all -> layer15_expert8;\n    layer15_expert9 [fillcolor=lightyellow, label="Layer15 Expert 2_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 9"];\n    layer15_moe_all2all -> layer15_expert9;\n    layer15_expert10 [fillcolor=lightyellow, label="Layer15 Expert 2_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 10"];\n    layer15_moe_all2all -> layer15_expert10;\n    layer15_expert11 [fillcolor=lightyellow, label="Layer15 Expert 2_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 11"];\n    layer15_moe_all2all -> layer15_expert11;\n    layer15_expert12 [fillcolor=lightcoral, label="Layer15 Expert 3_0\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 12"];\n    layer15_moe_all2all -> layer15_expert12;\n    layer15_expert13 [fillcolor=lightcoral, label="Layer15 Expert 3_1\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 13"];\n    layer15_moe_all2all -> layer15_expert13;\n    layer15_expert14 [fillcolor=lightcoral, label="Layer15 Expert 3_2\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 14"];\n    layer15_moe_all2all -> layer15_expert14;\n    layer15_expert15 [fillcolor=lightcoral, label="Layer15 Expert 3_3\nInput: [~70, 1024, 1024]\nOutput: [~70, 1024, 2048]\nGPU: 15"];\n    layer15_moe_all2all -> layer15_expert15;\n    layer15_moe_agg [shape=parallelogram, fillcolor=lightcoral, label="Layer15 MoE\nOutput Aggregation\nInput: [64, 1024, 1024]\nOutput: [64, 1024, 1024]\nGPU: 12,13,14,15"];\n    layer15_expert0 -> layer15_moe_agg;\n    layer15_expert1 -> layer15_moe_agg;\n    layer15_expert2 -> layer15_moe_agg;\n    layer15_expert3 -> layer15_moe_agg;\n    layer15_expert4 -> layer15_moe_agg;\n    layer15_expert5 -> layer15_moe_agg;\n    layer15_expert6 -> layer15_moe_agg;\n    layer15_expert7 -> layer15_moe_agg;\n    layer15_expert8 -> layer15_moe_agg;\n    layer15_expert9 -> layer15_moe_agg;\n    layer15_expert10 -> layer15_moe_agg;\n    layer15_expert11 -> layer15_moe_agg;\n    layer15_expert12 -> layer15_moe_agg;\n    layer15_expert13 -> layer15_moe_agg;\n    layer15_expert14 -> layer15_moe_agg;\n    layer15_expert15 -> layer15_moe_agg;\n    output_agg [shape=parallelogram, fillcolor=lightpink, label="Output Aggregation\nAll-Reduce Sum\nInput: [128, 1024, 1024]\nOutput: [128, 1024, 1024]\nGPU: 12,13,14,15"];\n    output [shape=ellipse, fillcolor=white, label="Final Output\n[batch_size=128, seq_len=1024, hidden=1024]\nGPU: ALL"];\n    layer15_moe_agg -> output_agg;\n    output_agg -> output;\n}